==========================================
Experiment 1: Fine-tuning GPT-2 on German
Job ID: 2149234
Start time: Thu Jan  1 05:08:06 AM CET 2026
==========================================
Thu Jan  1 05:08:09 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.28.03              Driver Version: 560.28.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA L40                     On  |   00000000:81:00.0 Off |                  Off |
| N/A   28C    P8             35W /  300W |       1MiB /  49140MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Rank 0 received experiment_id: 2026-01-01__05-08-20_ab1b864305b4b8b1
Instantiated <class 'int'>: settings -> training_target -> num_target_tokens
Instantiated <class 'int'>: settings -> training_target -> num_target_steps -> config -> global_num_tokens
Instantiated <class 'int'>: settings -> training_target -> num_target_steps
Instantiated <class 'modalities.models.huggingface.huggingface_model.HuggingFacePretrainedModel'>: model_raw

Wrapped layer classes: [<class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>]

Instantiated <class 'torch.distributed.fsdp.fully_sharded_data_parallel.FullyShardedDataParallel'>: wrapped_model
=> optimizer groups:
all (148 modules with 124,439,808 parameters): weight_decay = 0.01
=> all (148 modules with 124,439,808 parameters)
Instantiated <class 'torch.optim.adamw.AdamW'>: optimizer
Instantiated <class 'int'>: lr_scheduler -> config -> total_steps -> config -> global_num_tokens
Instantiated <class 'int'>: lr_scheduler -> config -> total_steps
Instantiated <class 'torch.optim.lr_scheduler.OneCycleLR'>: lr_scheduler
Instantiated <class 'modalities.checkpointing.stateful.app_state.AppState'>: app_state
Instantiated <class 'modalities.loss_functions.CLMCrossEntropyLoss'>: loss_fn
Instantiated <class 'modalities.dataloader.dataset.PackedMemMapDatasetContinuous'>: train_dataset
Instantiated <class 'modalities.dataloader.samplers.ResumableDistributedSampler'>: train_dataloader -> config -> batch_sampler -> config -> sampler
Instantiated <class 'torch.utils.data.sampler.BatchSampler'>: train_dataloader -> config -> batch_sampler
Instantiated <class 'modalities.models.gpt2.collator.GPT2LLMCollateFn'>: collate_fn
Instantiated <class 'modalities.dataloader.dataloader.LLMDataLoader'>: train_dataloader
Instantiated <class 'int'>: progress_subscriber -> config -> num_target_steps -> config -> global_num_tokens
Instantiated <class 'int'>: progress_subscriber -> config -> num_target_steps
Instantiated <class 'modalities.logging_broker.subscriber_impl.progress_subscriber.RichProgressSubscriber'>: progress_subscriber
Instantiated <class 'modalities.logging_broker.subscriber_impl.results_subscriber.WandBEvaluationResultSubscriber'>: evaluation_subscriber
Instantiated <class 'modalities.checkpointing.checkpoint_saving_strategies.SaveKMostRecentCheckpointsStrategy'>: checkpoint_saving -> config -> checkpoint_saving_strategy
Instantiated <class 'modalities.checkpointing.fsdp.fsdp_checkpoint_saving.FSDP1CheckpointSaving'>: checkpoint_saving -> config -> checkpoint_saving_execution
Instantiated <class 'modalities.checkpointing.checkpoint_saving.CheckpointSaving'>: checkpoint_saving
Instantiated <class 'modalities.training.gradient_clipping.fsdp_gradient_clipper.FSDP1GradientClipper'>: gradient_clipper
Model initialized at 2026-01-01 05:08:23.561085.



======================== Training Report ========================
Training target: 
	num_target_tokens: 1474945024
	num_target_steps: 180047 
Intervals: 
	training_log_interval_in_steps: 100
	checkpointing_interval_in_steps: 5000
	evaluation_interval_in_steps: 1000
Step profile: 
	gradient_accumulation_steps: 4
	local_train_micro_batch_size: 4
	sequence_length: 512
	dp_degree: 1
CUDA environment settings: 
	local_rank: 0
	world_size: 1
	global_rank: 0
Consistency enforcement: 
	enforce_tokens_per_step_consistency: True
	enforce_last_step_logged: False
	enforce_last_step_evaluated: False
	enforce_last_step_checkpointed: False
Training progress: 
	global_num_seen_tokens: 0
	num_seen_steps: 0
	num_seen_samples: 0
	last_step: -1
Warnings: 
	[38;5;214mNumber of tokens in the dataset (1474952704) does not match the number of target tokens (1474945024). Missing 0.00% of tokens in the dataset.
	Last step will not be logged. Since remaining_steps (180047) is not a multiple of training_log_interval_in_steps (100).
	Last step will not be evaluated. Since remaining_steps (180047) is not a multiple of evaluation_interval_in_steps (1000).
	Last step will not be checkpointed. Since remaining_steps (180047) is not a multiple of checkpointing_interval_in_steps (5000). [0m 
====================================================================



Start model training at 2026-01-01 05:08:23.561417.
2026-01-01T05:08:42 | step: 100 | train samples/s: 90.7 | train mfu (16-bit): -1.0 | lr mean: 5.342026270227507e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.38 | train loss last: 4.22 | consumed tokens: 819200.0 | grad norm avg: 2.93 | grad norm last: 2.57 | 
2026-01-01T05:09:01 | step: 200 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 6.35770720691653e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.24 | train loss last: 4.03 | consumed tokens: 1638400.0 | grad norm avg: 2.67 | grad norm last: 2.84 | 
2026-01-01T05:09:20 | step: 300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 8.01616351964185e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.2 | train loss last: 3.66 | consumed tokens: 2457600.0 | grad norm avg: 2.71 | grad norm last: 2.59 | 
2026-01-01T05:09:38 | step: 400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.026697464112658e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.12 | train loss last: 3.67 | consumed tokens: 3276800.0 | grad norm avg: 2.8 | grad norm last: 2.59 | 
2026-01-01T05:09:56 | step: 500 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.3041709280514624e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.07 | train loss last: 4.38 | consumed tokens: 4096000.0 | grad norm avg: 2.85 | grad norm last: 2.62 | 
2026-01-01T05:10:14 | step: 600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.6256009985227138e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.01 | train loss last: 4.34 | consumed tokens: 4915200.0 | grad norm avg: 2.84 | grad norm last: 2.62 | 
2026-01-01T05:10:32 | step: 700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.981215609703213e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.98 | train loss last: 4.09 | consumed tokens: 5734400.0 | grad norm avg: 2.86 | grad norm last: 2.87 | 
2026-01-01T05:10:50 | step: 800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 2.360202961426694e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.91 | train loss last: 3.81 | consumed tokens: 6553600.0 | grad norm avg: 2.78 | grad norm last: 2.68 | 
2026-01-01T05:11:08 | step: 900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.7510410291142762e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.87 | train loss last: 3.72 | consumed tokens: 7372800.0 | grad norm avg: 2.78 | grad norm last: 2.5 | 
2026-01-01T05:11:26 | step: 1000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.1418472644872963e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.85 | train loss last: 3.95 | consumed tokens: 8192000.0 | grad norm avg: 2.65 | grad norm last: 2.86 | 
2026-01-01T05:11:44 | step: 1100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.520740574458614e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.78 | train loss last: 3.72 | consumed tokens: 9011200.0 | grad norm avg: 2.56 | grad norm last: 2.38 | 
2026-01-01T05:12:02 | step: 1200 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.876201662933454e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.72 | train loss last: 3.58 | consumed tokens: 9830400.0 | grad norm avg: 2.38 | grad norm last: 2.29 | 
2026-01-01T05:12:20 | step: 1300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.1974235500674695e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.69 | train loss last: 3.73 | consumed tokens: 10649600.0 | grad norm avg: 2.32 | grad norm last: 2.4 | 
2026-01-01T05:12:38 | step: 1400 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.474640445550904e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.62 | train loss last: 3.48 | consumed tokens: 11468800.0 | grad norm avg: 2.17 | grad norm last: 2.18 | 
2026-01-01T05:12:56 | step: 1500 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.6994238800834864e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.61 | train loss last: 3.5 | consumed tokens: 12288000.0 | grad norm avg: 2.07 | grad norm last: 1.96 | 
2026-01-01T05:13:14 | step: 1600 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.8649406380718574e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.6 | train loss last: 3.2 | consumed tokens: 13107200.0 | grad norm avg: 1.96 | grad norm last: 2.0 | 
2026-01-01T05:13:33 | step: 1700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.966157939634286e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.55 | train loss last: 3.19 | consumed tokens: 13926400.0 | grad norm avg: 1.85 | grad norm last: 1.83 | 
2026-01-01T05:13:51 | step: 1800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.999999873689376e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.52 | train loss last: 3.97 | consumed tokens: 14745600.0 | grad norm avg: 1.78 | grad norm last: 1.75 | 
2026-01-01T05:14:09 | step: 1900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.999996235710569e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.23 | consumed tokens: 15564800.0 | grad norm avg: 1.7 | grad norm last: 1.72 | 
2026-01-01T05:14:27 | step: 2000 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.999984230380505e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.27 | consumed tokens: 16384000.0 | grad norm avg: 1.64 | grad norm last: 1.63 | 
2026-01-01T05:14:45 | step: 2100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.999964949092828e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.28 | consumed tokens: 17203200.0 | grad norm avg: 1.59 | grad norm last: 1.47 | 
2026-01-01T05:15:03 | step: 2200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.9999376642517745e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.34 | consumed tokens: 18022400.0 | grad norm avg: 1.55 | grad norm last: 1.48 | 
2026-01-01T05:15:21 | step: 2300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.9999027396552265e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.03 | consumed tokens: 18841600.0 | grad norm avg: 1.48 | grad norm last: 1.53 | 
2026-01-01T05:15:39 | step: 2400 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.9998601753031835e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.52 | consumed tokens: 19660800.0 | grad norm avg: 1.46 | grad norm last: 1.35 | 
2026-01-01T05:15:57 | step: 2500 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.999809607397765e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.45 | consumed tokens: 20480000.0 | grad norm avg: 1.42 | grad norm last: 1.38 | 
2026-01-01T05:16:16 | step: 2600 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.9997513997368515e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.44 | consumed tokens: 21299200.0 | grad norm avg: 1.36 | grad norm last: 1.36 | 
2026-01-01T05:16:34 | step: 2700 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.999685552320443e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.03 | consumed tokens: 22118400.0 | grad norm avg: 1.34 | grad norm last: 1.3 | 
2026-01-01T05:16:52 | step: 2800 | train samples/s: 94.9 | train mfu (16-bit): -1.0 | lr mean: 4.999611701350659e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 2.98 | consumed tokens: 22937600.0 | grad norm avg: 1.32 | grad norm last: 1.28 | 
2026-01-01T05:17:10 | step: 2900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.99953021062538e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.2 | consumed tokens: 23756800.0 | grad norm avg: 1.3 | grad norm last: 1.26 | 
2026-01-01T05:17:28 | step: 3000 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.9994410801446065e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.77 | consumed tokens: 24576000.0 | grad norm avg: 1.27 | grad norm last: 1.44 | 
2026-01-01T05:17:47 | step: 3100 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.999343946110457e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.23 | consumed tokens: 25395200.0 | grad norm avg: 1.25 | grad norm last: 1.35 | 
2026-01-01T05:18:05 | step: 3200 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.999239172320813e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.33 | consumed tokens: 26214400.0 | grad norm avg: 1.24 | grad norm last: 1.19 | 
2026-01-01T05:18:23 | step: 3300 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.999126758775674e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.58 | consumed tokens: 27033600.0 | grad norm avg: 1.23 | grad norm last: 1.21 | 
2026-01-01T05:18:41 | step: 3400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.999006341677159e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.17 | consumed tokens: 27852800.0 | grad norm avg: 1.22 | grad norm last: 1.2 | 
2026-01-01T05:18:59 | step: 3500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.9988782848231494e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.06 | consumed tokens: 28672000.0 | grad norm avg: 1.2 | grad norm last: 1.24 | 
2026-01-01T05:19:17 | step: 3600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.998742588213645e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.44 | consumed tokens: 29491200.0 | grad norm avg: 1.18 | grad norm last: 1.22 | 
2026-01-01T05:19:35 | step: 3700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.998598888050765e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.34 | consumed tokens: 30310400.0 | grad norm avg: 1.19 | grad norm last: 1.17 | 
2026-01-01T05:19:53 | step: 3800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.99844754813239e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.25 | consumed tokens: 31129600.0 | grad norm avg: 1.17 | grad norm last: 1.1 | 
2026-01-01T05:20:11 | step: 3900 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.99828856845852e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.31 | consumed tokens: 31948800.0 | grad norm avg: 1.16 | grad norm last: 1.23 | 
2026-01-01T05:20:30 | step: 4000 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.998121949029155e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.19 | consumed tokens: 32768000.0 | grad norm avg: 1.15 | grad norm last: 1.14 | 
2026-01-01T05:20:48 | step: 4100 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 4.997947326046415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.0 | consumed tokens: 33587200.0 | grad norm avg: 1.14 | grad norm last: 1.11 | 
2026-01-01T05:21:06 | step: 4200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9977650633081794e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.23 | consumed tokens: 34406400.0 | grad norm avg: 1.15 | grad norm last: 1.17 | 
2026-01-01T05:21:24 | step: 4300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9975747970165685e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.95 | consumed tokens: 35225600.0 | grad norm avg: 1.14 | grad norm last: 1.07 | 
2026-01-01T05:21:42 | step: 4400 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9973772547673434e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.23 | consumed tokens: 36044800.0 | grad norm avg: 1.12 | grad norm last: 1.08 | 
2026-01-01T05:22:00 | step: 4500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.997171708964743e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.42 | consumed tokens: 36864000.0 | grad norm avg: 1.12 | grad norm last: 1.09 | 
2026-01-01T05:22:18 | step: 4600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.9969581596087664e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.88 | consumed tokens: 37683200.0 | grad norm avg: 1.12 | grad norm last: 1.1 | 
2026-01-01T05:22:36 | step: 4700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.996737334295176e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.69 | consumed tokens: 38502400.0 | grad norm avg: 1.11 | grad norm last: 1.11 | 
2026-01-01T05:22:54 | step: 4800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.99650850542821e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.08 | consumed tokens: 39321600.0 | grad norm avg: 1.11 | grad norm last: 1.08 | 
2026-01-01T05:23:13 | step: 4900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.996271673007868e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.31 | consumed tokens: 40140800.0 | grad norm avg: 1.1 | grad norm last: 1.05 | 
2026-01-01T05:23:31 | step: 5000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.9960275646299124e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.0 | consumed tokens: 40960000.0 | grad norm avg: 1.11 | grad norm last: 1.15 | 
2026-01-01T05:23:50 | step: 5100 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.995775452698581e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.98 | consumed tokens: 41779200.0 | grad norm avg: 1.08 | grad norm last: 1.04 | 
2026-01-01T05:24:08 | step: 5200 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.9955157010117546e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.52 | consumed tokens: 42598400.0 | grad norm avg: 1.09 | grad norm last: 1.1 | 
2026-01-01T05:24:26 | step: 5300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.995248309569433e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.58 | consumed tokens: 43417600.0 | grad norm avg: 1.08 | grad norm last: 1.04 | 
2026-01-01T05:24:45 | step: 5400 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.9949729145737365e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.05 | consumed tokens: 44236800.0 | grad norm avg: 1.14 | grad norm last: 1.17 | 
2026-01-01T05:25:03 | step: 5500 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.994689879822545e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.2 | consumed tokens: 45056000.0 | grad norm avg: 1.09 | grad norm last: 1.19 | 
2026-01-01T05:25:21 | step: 5600 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.994399205315858e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.06 | consumed tokens: 45875200.0 | grad norm avg: 1.07 | grad norm last: 1.05 | 
2026-01-01T05:25:39 | step: 5700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.994100527255796e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.33 | consumed tokens: 46694400.0 | grad norm avg: 1.08 | grad norm last: 1.14 | 
2026-01-01T05:25:57 | step: 5800 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.993794209440239e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.92 | consumed tokens: 47513600.0 | grad norm avg: 1.08 | grad norm last: 1.0 | 
2026-01-01T05:26:15 | step: 5900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.993480251869187e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.0 | consumed tokens: 48332800.0 | grad norm avg: 1.07 | grad norm last: 1.08 | 
2026-01-01T05:26:33 | step: 6000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.99315865454264e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.47 | consumed tokens: 49152000.0 | grad norm avg: 1.07 | grad norm last: 1.09 | 
2026-01-01T05:26:52 | step: 6100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.9928290536627173e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.28 | consumed tokens: 49971200.0 | grad norm avg: 1.07 | grad norm last: 1.18 | 
2026-01-01T05:27:10 | step: 6200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9924918130273e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.84 | consumed tokens: 50790400.0 | grad norm avg: 1.08 | grad norm last: 1.03 | 
2026-01-01T05:27:28 | step: 6300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9921469326363876e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.52 | consumed tokens: 51609600.0 | grad norm avg: 1.08 | grad norm last: 1.05 | 
2026-01-01T05:27:46 | step: 6400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.9917944124899805e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.95 | consumed tokens: 52428800.0 | grad norm avg: 1.07 | grad norm last: 1.06 | 
2026-01-01T05:28:04 | step: 6500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.991433888790198e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.3 | consumed tokens: 53248000.0 | grad norm avg: 1.06 | grad norm last: 1.02 | 
2026-01-01T05:28:22 | step: 6600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.99106572533492e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.67 | consumed tokens: 54067200.0 | grad norm avg: 1.09 | grad norm last: 1.07 | 
2026-01-01T05:28:40 | step: 6700 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 4.9906899221241474e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.5 | consumed tokens: 54886400.0 | grad norm avg: 1.08 | grad norm last: 1.04 | 
2026-01-01T05:28:58 | step: 6800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.99030647915788e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.89 | consumed tokens: 55705600.0 | grad norm avg: 1.07 | grad norm last: 1.18 | 
2026-01-01T05:29:17 | step: 6900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.989915032638237e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.97 | consumed tokens: 56524800.0 | grad norm avg: 1.08 | grad norm last: 1.15 | 
2026-01-01T05:29:35 | step: 7000 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.989515946363099e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.91 | consumed tokens: 57344000.0 | grad norm avg: 1.08 | grad norm last: 1.13 | 
2026-01-01T05:29:53 | step: 7100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.989109220332466e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.8 | consumed tokens: 58163200.0 | grad norm avg: 1.08 | grad norm last: 1.15 | 
2026-01-01T05:30:11 | step: 7200 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.988694854546338e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.94 | consumed tokens: 58982400.0 | grad norm avg: 1.09 | grad norm last: 1.0 | 
2026-01-01T05:30:29 | step: 7300 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.988272485206835e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.12 | consumed tokens: 59801600.0 | grad norm avg: 1.09 | grad norm last: 1.08 | 
2026-01-01T05:30:47 | step: 7400 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.987842476111837e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.41 | consumed tokens: 60620800.0 | grad norm avg: 1.08 | grad norm last: 1.08 | 
2026-01-01T05:31:06 | step: 7500 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.9874048272613436e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.03 | consumed tokens: 61440000.0 | grad norm avg: 1.08 | grad norm last: 1.04 | 
2026-01-01T05:31:24 | step: 7600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.9869595386553556e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.16 | consumed tokens: 62259200.0 | grad norm avg: 1.07 | grad norm last: 1.22 | 
2026-01-01T05:31:42 | step: 7700 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.9865066102938727e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.92 | consumed tokens: 63078400.0 | grad norm avg: 1.07 | grad norm last: 1.06 | 
2026-01-01T05:32:00 | step: 7800 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.986045678379014e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 2.64 | consumed tokens: 63897600.0 | grad norm avg: 1.07 | grad norm last: 1.29 | 
2026-01-01T05:32:18 | step: 7900 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.985577106708661e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.17 | consumed tokens: 64716800.0 | grad norm avg: 1.06 | grad norm last: 1.01 | 
2026-01-01T05:32:36 | step: 8000 | train samples/s: 95.3 | train mfu (16-bit): -1.0 | lr mean: 4.9851008952828124e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.84 | consumed tokens: 65536000.0 | grad norm avg: 1.08 | grad norm last: 1.04 | 
2026-01-01T05:32:55 | step: 8100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.984617044101469e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.88 | consumed tokens: 66355200.0 | grad norm avg: 1.08 | grad norm last: 1.01 | 
2026-01-01T05:33:13 | step: 8200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.9841251893667504e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.06 | consumed tokens: 67174400.0 | grad norm avg: 1.08 | grad norm last: 1.08 | 
2026-01-01T05:33:31 | step: 8300 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.9836260586744174e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 3.25 | consumed tokens: 67993600.0 | grad norm avg: 1.09 | grad norm last: 1.13 | 
2026-01-01T05:33:49 | step: 8400 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.983118924428709e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.64 | consumed tokens: 68812800.0 | grad norm avg: 1.07 | grad norm last: 1.29 | 
2026-01-01T05:34:07 | step: 8500 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.9826041504275054e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.99 | train loss last: 3.0 | consumed tokens: 69632000.0 | grad norm avg: 1.09 | grad norm last: 0.98 | 
2026-01-01T05:34:25 | step: 8600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.982081736670807e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.99 | train loss last: 3.14 | consumed tokens: 70451200.0 | grad norm avg: 1.08 | grad norm last: 1.18 | 
2026-01-01T05:34:43 | step: 8700 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.981551319360733e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 2.88 | consumed tokens: 71270400.0 | grad norm avg: 1.08 | grad norm last: 1.04 | 
2026-01-01T05:35:02 | step: 8800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.981013626093045e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.98 | train loss last: 2.77 | consumed tokens: 72089600.0 | grad norm avg: 1.07 | grad norm last: 1.22 | 
2026-01-01T05:35:20 | step: 8900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.980467929271981e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 3.06 | consumed tokens: 72908800.0 | grad norm avg: 1.09 | grad norm last: 1.19 | 
2026-01-01T05:35:38 | step: 9000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9799145926954225e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.98 | train loss last: 2.64 | consumed tokens: 73728000.0 | grad norm avg: 1.07 | grad norm last: 1.0 | 
2026-01-01T05:35:56 | step: 9100 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.979353616363369e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 3.03 | consumed tokens: 74547200.0 | grad norm avg: 1.08 | grad norm last: 1.11 | 
2026-01-01T05:36:14 | step: 9200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.9787850002758205e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 2.88 | consumed tokens: 75366400.0 | grad norm avg: 1.08 | grad norm last: 1.14 | 
2026-01-01T05:36:32 | step: 9300 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 4.978208744432777e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.86 | consumed tokens: 76185600.0 | grad norm avg: 1.08 | grad norm last: 1.14 | 
2026-01-01T05:36:51 | step: 9400 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.977624485036358e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.99 | train loss last: 2.94 | consumed tokens: 77004800.0 | grad norm avg: 1.1 | grad norm last: 1.03 | 
2026-01-01T05:37:09 | step: 9500 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.977032949682325e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.98 | train loss last: 3.28 | consumed tokens: 77824000.0 | grad norm avg: 1.09 | grad norm last: 1.11 | 
2026-01-01T05:37:27 | step: 9600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.9764334107749164e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.98 | train loss last: 2.88 | consumed tokens: 78643200.0 | grad norm avg: 1.09 | grad norm last: 1.08 | 
2026-01-01T05:37:45 | step: 9700 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.975826232112013e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.98 | train loss last: 3.12 | consumed tokens: 79462400.0 | grad norm avg: 1.09 | grad norm last: 1.01 | 
2026-01-01T05:38:03 | step: 9800 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.975211413693614e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.99 | train loss last: 2.69 | consumed tokens: 80281600.0 | grad norm avg: 1.09 | grad norm last: 1.1 | 
2026-01-01T05:38:21 | step: 9900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.974588955519721e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.97 | train loss last: 3.19 | consumed tokens: 81100800.0 | grad norm avg: 1.1 | grad norm last: 1.0 | 
2026-01-01T05:38:39 | step: 10000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.9739588575903326e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.96 | train loss last: 2.95 | consumed tokens: 81920000.0 | grad norm avg: 1.08 | grad norm last: 1.1 | 
2026-01-01T05:38:59 | step: 10100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9733211199054495e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.96 | train loss last: 2.64 | consumed tokens: 82739200.0 | grad norm avg: 1.09 | grad norm last: 1.01 | 
2026-01-01T05:39:17 | step: 10200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.972675378667191e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.97 | train loss last: 3.73 | consumed tokens: 83558400.0 | grad norm avg: 1.1 | grad norm last: 1.1 | 
2026-01-01T05:39:35 | step: 10300 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.972022361471318e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.94 | train loss last: 3.08 | consumed tokens: 84377600.0 | grad norm avg: 1.1 | grad norm last: 1.07 | 
2026-01-01T05:39:53 | step: 10400 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.971361340722069e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.96 | train loss last: 2.53 | consumed tokens: 85196800.0 | grad norm avg: 1.11 | grad norm last: 1.07 | 
2026-01-01T05:40:12 | step: 10500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.9706930440152064e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.93 | train loss last: 3.66 | consumed tokens: 86016000.0 | grad norm avg: 1.11 | grad norm last: 1.12 | 
2026-01-01T05:40:30 | step: 10600 | train samples/s: 95.2 | train mfu (16-bit): -1.0 | lr mean: 4.970016743754968e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.94 | train loss last: 3.33 | consumed tokens: 86835200.0 | grad norm avg: 1.08 | grad norm last: 1.11 | 
2026-01-01T05:40:48 | step: 10700 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.969332803739235e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.95 | train loss last: 2.62 | consumed tokens: 87654400.0 | grad norm avg: 1.1 | grad norm last: 0.99 | 
2026-01-01T05:41:06 | step: 10800 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.968641223968007e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.94 | train loss last: 3.17 | consumed tokens: 88473600.0 | grad norm avg: 1.1 | grad norm last: 1.01 | 
2026-01-01T05:41:24 | step: 10900 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.9679420044412836e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.93 | train loss last: 2.61 | consumed tokens: 89292800.0 | grad norm avg: 1.11 | grad norm last: 1.03 | 
2026-01-01T05:41:43 | step: 11000 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.967235145159066e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.94 | train loss last: 2.81 | consumed tokens: 90112000.0 | grad norm avg: 1.11 | grad norm last: 1.19 | 
2026-01-01T05:42:01 | step: 11100 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.966520646121353e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.91 | train loss last: 3.22 | consumed tokens: 90931200.0 | grad norm avg: 1.13 | grad norm last: 1.21 | 
2026-01-01T05:42:19 | step: 11200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.965798507328145e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.96 | train loss last: 2.94 | consumed tokens: 91750400.0 | grad norm avg: 1.11 | grad norm last: 1.2 | 
2026-01-01T05:42:37 | step: 11300 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.9650687287794426e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.97 | train loss last: 3.14 | consumed tokens: 92569600.0 | grad norm avg: 1.13 | grad norm last: 1.06 | 
2026-01-01T05:42:55 | step: 11400 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.964331310475245e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.92 | train loss last: 3.22 | consumed tokens: 93388800.0 | grad norm avg: 1.12 | grad norm last: 1.31 | 
2026-01-01T05:43:13 | step: 11500 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.963586252415553e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.91 | train loss last: 2.72 | consumed tokens: 94208000.0 | grad norm avg: 1.13 | grad norm last: 1.12 | 
2026-01-01T05:43:32 | step: 11600 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.9628335546003655e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.93 | train loss last: 2.58 | consumed tokens: 95027200.0 | grad norm avg: 1.12 | grad norm last: 1.0 | 
2026-01-01T05:43:50 | step: 11700 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.962073217029683e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.93 | train loss last: 3.05 | consumed tokens: 95846400.0 | grad norm avg: 1.12 | grad norm last: 1.15 | 
2026-01-01T05:44:08 | step: 11800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.9613048759056255e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.93 | train loss last: 2.77 | consumed tokens: 96665600.0 | grad norm avg: 1.11 | grad norm last: 1.16 | 
2026-01-01T05:44:26 | step: 11900 | train samples/s: 95.3 | train mfu (16-bit): -1.0 | lr mean: 4.9605292588239536e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.94 | train loss last: 3.12 | consumed tokens: 97484800.0 | grad norm avg: 1.12 | grad norm last: 1.11 | 
2026-01-01T05:44:44 | step: 12000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.959746001986787e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.95 | train loss last: 2.56 | consumed tokens: 98304000.0 | grad norm avg: 1.13 | grad norm last: 1.26 | 
2026-01-01T05:45:02 | step: 12100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.958955105394125e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.92 | train loss last: 3.3 | consumed tokens: 99123200.0 | grad norm avg: 1.13 | grad norm last: 1.12 | 
2026-01-01T05:45:21 | step: 12200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.9581565690459684e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.9 | train loss last: 3.02 | consumed tokens: 99942400.0 | grad norm avg: 1.13 | grad norm last: 1.04 | 
2026-01-01T05:45:39 | step: 12300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.957350392942317e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.92 | train loss last: 2.89 | consumed tokens: 100761600.0 | grad norm avg: 1.11 | grad norm last: 1.09 | 
2026-01-01T05:45:57 | step: 12400 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.9565365770831704e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.9 | train loss last: 3.2 | consumed tokens: 101580800.0 | grad norm avg: 1.14 | grad norm last: 1.06 | 
2026-01-01T05:46:15 | step: 12500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.955715121468529e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.91 | train loss last: 2.28 | consumed tokens: 102400000.0 | grad norm avg: 1.14 | grad norm last: 1.16 | 
2026-01-01T05:46:33 | step: 12600 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.954886026098393e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.92 | train loss last: 2.8 | consumed tokens: 103219200.0 | grad norm avg: 1.13 | grad norm last: 1.09 | 
2026-01-01T05:46:51 | step: 12700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.954049290972762e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.88 | train loss last: 2.73 | consumed tokens: 104038400.0 | grad norm avg: 1.11 | grad norm last: 1.03 | 
2026-01-01T05:47:09 | step: 12800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.953204916091636e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.89 | train loss last: 2.86 | consumed tokens: 104857600.0 | grad norm avg: 1.12 | grad norm last: 1.15 | 
2026-01-01T05:47:27 | step: 12900 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.9523532652528957e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.9 | train loss last: 2.95 | consumed tokens: 105676800.0 | grad norm avg: 1.13 | grad norm last: 1.15 | 
2026-01-01T05:47:45 | step: 13000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.95149361086078e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.89 | train loss last: 2.89 | consumed tokens: 106496000.0 | grad norm avg: 1.14 | grad norm last: 1.12 | 
2026-01-01T05:48:03 | step: 13100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.950626316713169e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.9 | train loss last: 2.75 | consumed tokens: 107315200.0 | grad norm avg: 1.14 | grad norm last: 1.09 | 
2026-01-01T05:48:22 | step: 13200 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 4.9497517466079444e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.91 | train loss last: 2.92 | consumed tokens: 108134400.0 | grad norm avg: 1.13 | grad norm last: 1.14 | 
2026-01-01T05:48:40 | step: 13300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.948869172949344e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.92 | train loss last: 2.97 | consumed tokens: 108953600.0 | grad norm avg: 1.12 | grad norm last: 1.11 | 
2026-01-01T05:48:58 | step: 13400 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.947979323333129e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.92 | train loss last: 2.95 | consumed tokens: 109772800.0 | grad norm avg: 1.11 | grad norm last: 1.14 | 
2026-01-01T05:49:16 | step: 13500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.94708183396142e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.89 | train loss last: 2.72 | consumed tokens: 110592000.0 | grad norm avg: 1.13 | grad norm last: 1.17 | 
2026-01-01T05:49:34 | step: 13600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.9461767048342153e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.88 | train loss last: 3.22 | consumed tokens: 111411200.0 | grad norm avg: 1.13 | grad norm last: 1.03 | 
2026-01-01T05:49:52 | step: 13700 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.945263935951516e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.9 | train loss last: 3.33 | consumed tokens: 112230400.0 | grad norm avg: 1.15 | grad norm last: 1.13 | 
2026-01-01T05:50:10 | step: 13800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.944343527313322e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.89 | train loss last: 2.64 | consumed tokens: 113049600.0 | grad norm avg: 1.15 | grad norm last: 1.26 | 
2026-01-01T05:50:28 | step: 13900 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.9434158427175134e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.89 | train loss last: 2.83 | consumed tokens: 113868800.0 | grad norm avg: 1.13 | grad norm last: 1.09 | 
2026-01-01T05:50:46 | step: 14000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.9424801545683295e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.87 | train loss last: 2.52 | consumed tokens: 114688000.0 | grad norm avg: 1.13 | grad norm last: 1.31 | 
2026-01-01T05:51:04 | step: 14100 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.941537190461531e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.91 | train loss last: 2.44 | consumed tokens: 115507200.0 | grad norm avg: 1.14 | grad norm last: 1.2 | 
2026-01-01T05:51:22 | step: 14200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.940586586599238e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.88 | train loss last: 3.03 | consumed tokens: 116326400.0 | grad norm avg: 1.14 | grad norm last: 1.1 | 
2026-01-01T05:51:40 | step: 14300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.93962834298145e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.88 | train loss last: 2.42 | consumed tokens: 117145600.0 | grad norm avg: 1.15 | grad norm last: 1.09 | 
2026-01-01T05:51:58 | step: 14400 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 4.938662823406048e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.89 | train loss last: 3.02 | consumed tokens: 117964800.0 | grad norm avg: 1.15 | grad norm last: 1.11 | 
2026-01-01T05:52:16 | step: 14500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9376893002772704e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.89 | train loss last: 3.19 | consumed tokens: 118784000.0 | grad norm avg: 1.13 | grad norm last: 1.11 | 
2026-01-01T05:52:34 | step: 14600 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.9367085011908785e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.87 | train loss last: 3.06 | consumed tokens: 119603200.0 | grad norm avg: 1.14 | grad norm last: 1.22 | 
2026-01-01T05:52:52 | step: 14700 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.9357200623489916e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.86 | train loss last: 3.39 | consumed tokens: 120422400.0 | grad norm avg: 1.14 | grad norm last: 1.1 | 
2026-01-01T05:53:10 | step: 14800 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.93472398375161e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.88 | train loss last: 2.75 | consumed tokens: 121241600.0 | grad norm avg: 1.16 | grad norm last: 1.08 | 
2026-01-01T05:53:28 | step: 14900 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.933720265398733e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.86 | train loss last: 2.97 | consumed tokens: 122060800.0 | grad norm avg: 1.14 | grad norm last: 1.15 | 
2026-01-01T05:53:46 | step: 15000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.9327092710882425e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.88 | train loss last: 2.64 | consumed tokens: 122880000.0 | grad norm avg: 1.16 | grad norm last: 1.18 | 
2026-01-01T05:54:05 | step: 15100 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.931690637022257e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.86 | train loss last: 2.78 | consumed tokens: 123699200.0 | grad norm avg: 1.13 | grad norm last: 1.11 | 
2026-01-01T05:54:23 | step: 15200 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.930664363200776e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.86 | train loss last: 3.19 | consumed tokens: 124518400.0 | grad norm avg: 1.16 | grad norm last: 1.15 | 
2026-01-01T05:54:41 | step: 15300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.929630449623801e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.88 | train loss last: 2.61 | consumed tokens: 125337600.0 | grad norm avg: 1.16 | grad norm last: 1.07 | 
2026-01-01T05:54:59 | step: 15400 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.928589260089211e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.87 | train loss last: 2.73 | consumed tokens: 126156800.0 | grad norm avg: 1.16 | grad norm last: 1.35 | 
2026-01-01T05:55:17 | step: 15500 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.9275404307991266e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.85 | train loss last: 2.67 | consumed tokens: 126976000.0 | grad norm avg: 1.13 | grad norm last: 1.04 | 
2026-01-01T05:55:35 | step: 15600 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.926483961753547e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.87 | train loss last: 3.03 | consumed tokens: 127795200.0 | grad norm avg: 1.15 | grad norm last: 1.23 | 
2026-01-01T05:55:53 | step: 15700 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.925419852952473e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.87 | train loss last: 2.81 | consumed tokens: 128614400.0 | grad norm avg: 1.16 | grad norm last: 1.19 | 
2026-01-01T05:56:11 | step: 15800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.9243484681937844e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.86 | train loss last: 2.97 | consumed tokens: 129433600.0 | grad norm avg: 1.14 | grad norm last: 1.25 | 
2026-01-01T05:56:29 | step: 15900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.923269443679601e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.84 | train loss last: 2.67 | consumed tokens: 130252800.0 | grad norm avg: 1.14 | grad norm last: 1.19 | 
2026-01-01T05:56:47 | step: 16000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.9221831432078034e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.85 | train loss last: 2.72 | consumed tokens: 131072000.0 | grad norm avg: 1.14 | grad norm last: 1.13 | 
2026-01-01T05:57:05 | step: 16100 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.921089202980511e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.81 | train loss last: 2.83 | consumed tokens: 131891200.0 | grad norm avg: 1.14 | grad norm last: 1.1 | 
2026-01-01T05:57:23 | step: 16200 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.9199876229977235e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.84 | train loss last: 2.55 | consumed tokens: 132710400.0 | grad norm avg: 1.17 | grad norm last: 1.07 | 
2026-01-01T05:57:41 | step: 16300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.918878403259441e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.86 | train loss last: 3.36 | consumed tokens: 133529600.0 | grad norm avg: 1.17 | grad norm last: 1.2 | 
2026-01-01T05:57:59 | step: 16400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.917761907563545e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.83 | train loss last: 3.02 | consumed tokens: 134348800.0 | grad norm avg: 1.15 | grad norm last: 1.13 | 
2026-01-01T05:58:17 | step: 16500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.916638135910034e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.85 | train loss last: 2.66 | consumed tokens: 135168000.0 | grad norm avg: 1.16 | grad norm last: 1.14 | 
2026-01-01T05:58:35 | step: 16600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.915506360703148e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.87 | train loss last: 2.64 | consumed tokens: 135987200.0 | grad norm avg: 1.16 | grad norm last: 1.37 | 
2026-01-01T05:58:53 | step: 16700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.9143673095386475e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.83 | train loss last: 2.73 | consumed tokens: 136806400.0 | grad norm avg: 1.17 | grad norm last: 1.09 | 
2026-01-01T05:59:10 | step: 16800 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.913220982416533e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.86 | train loss last: 2.84 | consumed tokens: 137625600.0 | grad norm avg: 1.15 | grad norm last: 1.17 | 
2026-01-01T05:59:28 | step: 16900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.9120670155389234e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.83 | train loss last: 2.73 | consumed tokens: 138444800.0 | grad norm avg: 1.15 | grad norm last: 1.18 | 
2026-01-01T05:59:46 | step: 17000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.910905408905819e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.84 | train loss last: 2.53 | consumed tokens: 139264000.0 | grad norm avg: 1.15 | grad norm last: 1.1 | 
2026-01-01T06:00:05 | step: 17100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.9097365263151005e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.84 | train loss last: 2.55 | consumed tokens: 140083200.0 | grad norm avg: 1.16 | grad norm last: 1.15 | 
2026-01-01T06:00:22 | step: 17200 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.908560003968887e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.82 | train loss last: 3.06 | consumed tokens: 140902400.0 | grad norm avg: 1.16 | grad norm last: 1.15 | 
2026-01-01T06:00:40 | step: 17300 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.9073762056650594e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.83 | train loss last: 2.59 | consumed tokens: 141721600.0 | grad norm avg: 1.15 | grad norm last: 1.16 | 
2026-01-01T06:00:58 | step: 17400 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.906184767605737e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.85 | train loss last: 3.34 | consumed tokens: 142540800.0 | grad norm avg: 1.16 | grad norm last: 1.17 | 
2026-01-01T06:01:16 | step: 17500 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.9049856897909194e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.83 | train loss last: 2.83 | consumed tokens: 143360000.0 | grad norm avg: 1.15 | grad norm last: 1.19 | 
2026-01-01T06:01:34 | step: 17600 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.903779336018488e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.85 | train loss last: 3.03 | consumed tokens: 144179200.0 | grad norm avg: 1.15 | grad norm last: 1.16 | 
2026-01-01T06:01:52 | step: 17700 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.902565706288442e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.85 | train loss last: 2.84 | consumed tokens: 144998400.0 | grad norm avg: 1.16 | grad norm last: 1.1 | 
2026-01-01T06:02:10 | step: 17800 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.901344436802901e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.83 | train loss last: 2.28 | consumed tokens: 145817600.0 | grad norm avg: 1.18 | grad norm last: 1.11 | 
2026-01-01T06:02:28 | step: 17900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.9001158913597465e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.82 | train loss last: 2.73 | consumed tokens: 146636800.0 | grad norm avg: 1.18 | grad norm last: 1.1 | 
2026-01-01T06:02:46 | step: 18000 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.898879706161097e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.87 | train loss last: 2.8 | consumed tokens: 147456000.0 | grad norm avg: 1.16 | grad norm last: 1.25 | 
2026-01-01T06:03:04 | step: 18100 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.897635881206952e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.83 | train loss last: 2.52 | consumed tokens: 148275200.0 | grad norm avg: 1.14 | grad norm last: 1.16 | 
2026-01-01T06:03:22 | step: 18200 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.896385144093074e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.82 | train loss last: 2.66 | consumed tokens: 149094400.0 | grad norm avg: 1.16 | grad norm last: 1.23 | 
2026-01-01T06:03:40 | step: 18300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.89512640342582e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.83 | train loss last: 2.83 | consumed tokens: 149913600.0 | grad norm avg: 1.15 | grad norm last: 1.16 | 
2026-01-01T06:03:58 | step: 18400 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.893860750598833e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.83 | train loss last: 2.73 | consumed tokens: 150732800.0 | grad norm avg: 1.15 | grad norm last: 1.11 | 
2026-01-01T06:04:16 | step: 18500 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.892587458016351e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.79 | train loss last: 3.19 | consumed tokens: 151552000.0 | grad norm avg: 1.16 | grad norm last: 1.21 | 
2026-01-01T06:04:34 | step: 18600 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.891306525678374e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.83 | train loss last: 2.62 | consumed tokens: 152371200.0 | grad norm avg: 1.15 | grad norm last: 1.05 | 
2026-01-01T06:04:52 | step: 18700 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.890018317382783e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.81 | train loss last: 3.08 | consumed tokens: 153190400.0 | grad norm avg: 1.16 | grad norm last: 1.22 | 
2026-01-01T06:05:10 | step: 18800 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.888722833129577e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.82 | train loss last: 2.89 | consumed tokens: 154009600.0 | grad norm avg: 1.15 | grad norm last: 1.21 | 
2026-01-01T06:05:28 | step: 18900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.887419709120877e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.83 | train loss last: 2.97 | consumed tokens: 154828800.0 | grad norm avg: 1.16 | grad norm last: 1.16 | 
2026-01-01T06:05:46 | step: 19000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.8861093091545627e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.8 | train loss last: 3.77 | consumed tokens: 155648000.0 | grad norm avg: 1.15 | grad norm last: 1.07 | 
2026-01-01T06:06:04 | step: 19100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.884791633230634e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.8 | train loss last: 2.8 | consumed tokens: 156467200.0 | grad norm avg: 1.16 | grad norm last: 1.14 | 
2026-01-01T06:06:22 | step: 19200 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.8834663175512105e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.79 | train loss last: 2.5 | consumed tokens: 157286400.0 | grad norm avg: 1.16 | grad norm last: 1.15 | 
2026-01-01T06:06:40 | step: 19300 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.882133725914173e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.83 | train loss last: 3.12 | consumed tokens: 158105600.0 | grad norm avg: 1.16 | grad norm last: 1.08 | 
2026-01-01T06:06:58 | step: 19400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.880793858319521e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.84 | train loss last: 2.3 | consumed tokens: 158924800.0 | grad norm avg: 1.16 | grad norm last: 1.18 | 
2026-01-01T06:07:16 | step: 19500 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.879446350969374e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.85 | train loss last: 3.05 | consumed tokens: 159744000.0 | grad norm avg: 1.18 | grad norm last: 1.17 | 
2026-01-01T06:07:34 | step: 19600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.878091567661613e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.79 | train loss last: 2.91 | consumed tokens: 160563200.0 | grad norm avg: 1.16 | grad norm last: 1.14 | 
2026-01-01T06:07:52 | step: 19700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.876729508396238e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.8 | train loss last: 2.67 | consumed tokens: 161382400.0 | grad norm avg: 1.16 | grad norm last: 1.36 | 
2026-01-01T06:08:10 | step: 19800 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.875359809375368e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.82 | train loss last: 2.75 | consumed tokens: 162201600.0 | grad norm avg: 1.15 | grad norm last: 1.07 | 
2026-01-01T06:08:28 | step: 19900 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.873982834396884e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.83 | train loss last: 2.61 | consumed tokens: 163020800.0 | grad norm avg: 1.16 | grad norm last: 1.1 | 
2026-01-01T06:08:46 | step: 20000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.8725985834607854e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.82 | train loss last: 3.03 | consumed tokens: 163840000.0 | grad norm avg: 1.17 | grad norm last: 1.19 | 
2026-01-01T06:09:05 | step: 20100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.871207056567073e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.8 | train loss last: 3.33 | consumed tokens: 164659200.0 | grad norm avg: 1.16 | grad norm last: 1.0 | 
2026-01-01T06:09:23 | step: 20200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.869808253715746e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.8 | train loss last: 2.89 | consumed tokens: 165478400.0 | grad norm avg: 1.16 | grad norm last: 1.08 | 
2026-01-01T06:09:41 | step: 20300 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.8684018111089244e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.79 | train loss last: 2.95 | consumed tokens: 166297600.0 | grad norm avg: 1.17 | grad norm last: 1.24 | 
2026-01-01T06:09:59 | step: 20400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.8669880925444886e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.8 | train loss last: 2.55 | consumed tokens: 167116800.0 | grad norm avg: 1.15 | grad norm last: 1.1 | 
2026-01-01T06:10:17 | step: 20500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.8655670980224386e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.79 | train loss last: 2.95 | consumed tokens: 167936000.0 | grad norm avg: 1.17 | grad norm last: 1.16 | 
2026-01-01T06:10:35 | step: 20600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.8641388275427744e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.79 | train loss last: 1.84 | consumed tokens: 168755200.0 | grad norm avg: 1.18 | grad norm last: 1.2 | 
2026-01-01T06:10:53 | step: 20700 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.862702917307615e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.8 | train loss last: 2.27 | consumed tokens: 169574400.0 | grad norm avg: 1.17 | grad norm last: 1.17 | 
2026-01-01T06:11:11 | step: 20800 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.861260094912723e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.82 | train loss last: 2.92 | consumed tokens: 170393600.0 | grad norm avg: 1.15 | grad norm last: 1.05 | 
2026-01-01T06:11:29 | step: 20900 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.859809632762335e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.8 | train loss last: 2.89 | consumed tokens: 171212800.0 | grad norm avg: 1.15 | grad norm last: 1.1 | 
2026-01-01T06:11:47 | step: 21000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.8583518946543336e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.77 | train loss last: 2.94 | consumed tokens: 172032000.0 | grad norm avg: 1.18 | grad norm last: 1.15 | 
2026-01-01T06:12:05 | step: 21100 | train samples/s: 94.9 | train mfu (16-bit): -1.0 | lr mean: 4.856886880588718e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.82 | train loss last: 2.77 | consumed tokens: 172851200.0 | grad norm avg: 1.18 | grad norm last: 1.19 | 
2026-01-01T06:12:23 | step: 21200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.855414590565488e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.81 | train loss last: 3.11 | consumed tokens: 173670400.0 | grad norm avg: 1.15 | grad norm last: 1.27 | 
2026-01-01T06:12:41 | step: 21300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.8539350245846435e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.8 | train loss last: 2.48 | consumed tokens: 174489600.0 | grad norm avg: 1.14 | grad norm last: 1.18 | 
2026-01-01T06:12:59 | step: 21400 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.8524478188483045e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.8 | train loss last: 3.09 | consumed tokens: 175308800.0 | grad norm avg: 1.17 | grad norm last: 1.25 | 
2026-01-01T06:13:17 | step: 21500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.850953700952232e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.8 | train loss last: 2.52 | consumed tokens: 176128000.0 | grad norm avg: 1.17 | grad norm last: 1.14 | 
2026-01-01T06:13:35 | step: 21600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.849452307098545e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.79 | train loss last: 2.92 | consumed tokens: 176947200.0 | grad norm avg: 1.16 | grad norm last: 1.18 | 
2026-01-01T06:13:53 | step: 21700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.8479432734893635e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.78 | train loss last: 2.8 | consumed tokens: 177766400.0 | grad norm avg: 1.17 | grad norm last: 1.06 | 
2026-01-01T06:14:11 | step: 21800 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.8464273277204484e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.82 | train loss last: 2.86 | consumed tokens: 178585600.0 | grad norm avg: 1.18 | grad norm last: 1.16 | 
2026-01-01T06:14:29 | step: 21900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.8449037421960384e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.81 | train loss last: 2.33 | consumed tokens: 179404800.0 | grad norm avg: 1.18 | grad norm last: 1.17 | 
2026-01-01T06:14:47 | step: 22000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.843373244511895e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.78 | train loss last: 2.84 | consumed tokens: 180224000.0 | grad norm avg: 1.18 | grad norm last: 1.21 | 
2026-01-01T06:15:05 | step: 22100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.8418351070722565e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.79 | train loss last: 3.0 | consumed tokens: 181043200.0 | grad norm avg: 1.19 | grad norm last: 1.1 | 
2026-01-01T06:15:23 | step: 22200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.8402900574728847e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.78 | train loss last: 2.88 | consumed tokens: 181862400.0 | grad norm avg: 1.17 | grad norm last: 1.18 | 
2026-01-01T06:15:41 | step: 22300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.8387377319158986e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.77 | train loss last: 2.61 | consumed tokens: 182681600.0 | grad norm avg: 1.19 | grad norm last: 1.17 | 
2026-01-01T06:16:00 | step: 22400 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.837177766603418e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.8 | train loss last: 2.97 | consumed tokens: 183500800.0 | grad norm avg: 1.17 | grad norm last: 1.15 | 
2026-01-01T06:16:18 | step: 22500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.835610889131203e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.78 | train loss last: 2.83 | consumed tokens: 184320000.0 | grad norm avg: 1.18 | grad norm last: 1.19 | 
2026-01-01T06:16:36 | step: 22600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.834036735701375e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.77 | train loss last: 2.38 | consumed tokens: 185139200.0 | grad norm avg: 1.18 | grad norm last: 1.06 | 
2026-01-01T06:16:54 | step: 22700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.832455306313932e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.78 | train loss last: 2.77 | consumed tokens: 185958400.0 | grad norm avg: 1.16 | grad norm last: 1.27 | 
2026-01-01T06:17:12 | step: 22800 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.830866600968875e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.78 | train loss last: 2.47 | consumed tokens: 186777600.0 | grad norm avg: 1.17 | grad norm last: 1.19 | 
2026-01-01T06:17:30 | step: 22900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.829270619666204e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.8 | train loss last: 2.3 | consumed tokens: 187596800.0 | grad norm avg: 1.17 | grad norm last: 1.14 | 
2026-01-01T06:17:48 | step: 23000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.8276673624059185e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.8 | train loss last: 2.98 | consumed tokens: 188416000.0 | grad norm avg: 1.18 | grad norm last: 1.13 | 
2026-01-01T06:18:06 | step: 23100 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.826056829188019e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.76 | train loss last: 2.53 | consumed tokens: 189235200.0 | grad norm avg: 1.19 | grad norm last: 1.19 | 
2026-01-01T06:18:24 | step: 23200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.824439383810386e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.77 | train loss last: 2.61 | consumed tokens: 190054400.0 | grad norm avg: 1.18 | grad norm last: 1.26 | 
2026-01-01T06:18:41 | step: 23300 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.822814662475139e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.8 | train loss last: 2.41 | consumed tokens: 190873600.0 | grad norm avg: 1.15 | grad norm last: 1.08 | 
2026-01-01T06:19:00 | step: 23400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.8211826651822776e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.76 | train loss last: 3.36 | consumed tokens: 191692800.0 | grad norm avg: 1.18 | grad norm last: 1.26 | 
2026-01-01T06:19:18 | step: 23500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.819543391931802e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.78 | train loss last: 2.73 | consumed tokens: 192512000.0 | grad norm avg: 1.19 | grad norm last: 1.16 | 
2026-01-01T06:19:35 | step: 23600 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.817896842723712e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.78 | train loss last: 2.72 | consumed tokens: 193331200.0 | grad norm avg: 1.19 | grad norm last: 1.14 | 
2026-01-01T06:19:54 | step: 23700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.816243381355889e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.76 | train loss last: 2.59 | consumed tokens: 194150400.0 | grad norm avg: 1.17 | grad norm last: 1.19 | 
2026-01-01T06:20:12 | step: 23800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.814582280232571e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.76 | train loss last: 2.88 | consumed tokens: 194969600.0 | grad norm avg: 1.18 | grad norm last: 1.27 | 
2026-01-01T06:20:30 | step: 23900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.8129142669495195e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.74 | train loss last: 2.53 | consumed tokens: 195788800.0 | grad norm avg: 1.16 | grad norm last: 1.07 | 
2026-01-01T06:20:48 | step: 24000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.8112393415067345e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.76 | train loss last: 2.47 | consumed tokens: 196608000.0 | grad norm avg: 1.16 | grad norm last: 1.32 | 
2026-01-01T06:21:06 | step: 24100 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.8095567763084546e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.78 | train loss last: 2.88 | consumed tokens: 197427200.0 | grad norm avg: 1.18 | grad norm last: 1.17 | 
2026-01-01T06:21:23 | step: 24200 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.807867298950441e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.76 | train loss last: 3.23 | consumed tokens: 198246400.0 | grad norm avg: 1.18 | grad norm last: 1.18 | 
2026-01-01T06:21:41 | step: 24300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.806170909432694e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.79 | train loss last: 3.12 | consumed tokens: 199065600.0 | grad norm avg: 1.18 | grad norm last: 1.13 | 
2026-01-01T06:21:59 | step: 24400 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.8044668801594526e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.77 | train loss last: 2.95 | consumed tokens: 199884800.0 | grad norm avg: 1.18 | grad norm last: 1.18 | 
2026-01-01T06:22:17 | step: 24500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.802755938726477e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.74 | train loss last: 2.11 | consumed tokens: 200704000.0 | grad norm avg: 1.17 | grad norm last: 1.03 | 
2026-01-01T06:22:35 | step: 24600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.801037721335888e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.76 | train loss last: 3.03 | consumed tokens: 201523200.0 | grad norm avg: 1.19 | grad norm last: 1.05 | 
2026-01-01T06:22:53 | step: 24700 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 4.799312591785565e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.76 | train loss last: 2.59 | consumed tokens: 202342400.0 | grad norm avg: 1.19 | grad norm last: 1.09 | 
2026-01-01T06:23:11 | step: 24800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.797580186277628e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.78 | train loss last: 2.94 | consumed tokens: 203161600.0 | grad norm avg: 1.17 | grad norm last: 1.11 | 
2026-01-01T06:23:29 | step: 24900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.795840504812077e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.77 | train loss last: 2.8 | consumed tokens: 203980800.0 | grad norm avg: 1.18 | grad norm last: 1.11 | 
2026-01-01T06:23:47 | step: 25000 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.794093911186792e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.75 | train loss last: 2.7 | consumed tokens: 204800000.0 | grad norm avg: 1.19 | grad norm last: 1.51 | 
2026-01-01T06:24:07 | step: 25100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.792340041603893e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.76 | train loss last: 2.45 | consumed tokens: 205619200.0 | grad norm avg: 1.19 | grad norm last: 1.15 | 
2026-01-01T06:24:25 | step: 25200 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.7905792598612607e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.77 | train loss last: 2.83 | consumed tokens: 206438400.0 | grad norm avg: 1.19 | grad norm last: 1.21 | 
2026-01-01T06:24:43 | step: 25300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.788811202161014e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.74 | train loss last: 2.89 | consumed tokens: 207257600.0 | grad norm avg: 1.19 | grad norm last: 1.19 | 
2026-01-01T06:25:01 | step: 25400 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.787036232301034e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.75 | train loss last: 2.5 | consumed tokens: 208076800.0 | grad norm avg: 1.19 | grad norm last: 1.17 | 
2026-01-01T06:25:19 | step: 25500 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.78525398648344e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.76 | train loss last: 3.42 | consumed tokens: 208896000.0 | grad norm avg: 1.2 | grad norm last: 1.17 | 
2026-01-01T06:25:37 | step: 25600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.783464828506112e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.74 | train loss last: 2.78 | consumed tokens: 209715200.0 | grad norm avg: 1.19 | grad norm last: 1.12 | 
2026-01-01T06:25:55 | step: 25700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.78166839457117e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.77 | train loss last: 2.61 | consumed tokens: 210534400.0 | grad norm avg: 1.19 | grad norm last: 1.11 | 
2026-01-01T06:26:13 | step: 25800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.779865048476495e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.73 | train loss last: 3.0 | consumed tokens: 211353600.0 | grad norm avg: 1.19 | grad norm last: 1.14 | 
2026-01-01T06:26:31 | step: 25900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.778054426424205e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.75 | train loss last: 2.36 | consumed tokens: 212172800.0 | grad norm avg: 1.2 | grad norm last: 1.18 | 
2026-01-01T06:26:49 | step: 26000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.776236892212182e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.75 | train loss last: 2.67 | consumed tokens: 212992000.0 | grad norm avg: 1.18 | grad norm last: 1.34 | 
2026-01-01T06:27:07 | step: 26100 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.774412082042545e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.75 | train loss last: 2.83 | consumed tokens: 213811200.0 | grad norm avg: 1.18 | grad norm last: 1.19 | 
2026-01-01T06:27:25 | step: 26200 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.7725803597131744e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.74 | train loss last: 2.77 | consumed tokens: 214630400.0 | grad norm avg: 1.19 | grad norm last: 1.17 | 
2026-01-01T06:27:43 | step: 26300 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.77074172522407e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.75 | train loss last: 2.86 | consumed tokens: 215449600.0 | grad norm avg: 1.2 | grad norm last: 1.15 | 
2026-01-01T06:28:01 | step: 26400 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.768895814777352e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.74 | train loss last: 2.89 | consumed tokens: 216268800.0 | grad norm avg: 1.19 | grad norm last: 1.15 | 
2026-01-01T06:28:19 | step: 26500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.7670429921709e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.73 | train loss last: 2.5 | consumed tokens: 217088000.0 | grad norm avg: 1.19 | grad norm last: 1.27 | 
2026-01-01T06:28:37 | step: 26600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.765183257404715e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.71 | train loss last: 2.84 | consumed tokens: 217907200.0 | grad norm avg: 1.19 | grad norm last: 1.04 | 
2026-01-01T06:28:55 | step: 26700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.7633162466809154e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.73 | train loss last: 2.55 | consumed tokens: 218726400.0 | grad norm avg: 1.2 | grad norm last: 1.14 | 
2026-01-01T06:29:13 | step: 26800 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.7614423237973824e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.76 | train loss last: 2.56 | consumed tokens: 219545600.0 | grad norm avg: 1.19 | grad norm last: 1.16 | 
2026-01-01T06:29:31 | step: 26900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.759561488754116e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.75 | train loss last: 2.7 | consumed tokens: 220364800.0 | grad norm avg: 1.21 | grad norm last: 1.15 | 
2026-01-01T06:29:49 | step: 27000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.7576733777532354e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.74 | train loss last: 2.34 | consumed tokens: 221184000.0 | grad norm avg: 1.21 | grad norm last: 1.14 | 
2026-01-01T06:30:07 | step: 27100 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.755778354592621e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.78 | train loss last: 2.56 | consumed tokens: 222003200.0 | grad norm avg: 1.21 | grad norm last: 1.27 | 
2026-01-01T06:30:25 | step: 27200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.753876419272274e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.73 | train loss last: 2.81 | consumed tokens: 222822400.0 | grad norm avg: 1.23 | grad norm last: 1.07 | 
2026-01-01T06:30:43 | step: 27300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.751967571792193e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.77 | train loss last: 3.14 | consumed tokens: 223641600.0 | grad norm avg: 1.22 | grad norm last: 1.13 | 
2026-01-01T06:31:01 | step: 27400 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.750051812152378e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.76 | train loss last: 2.33 | consumed tokens: 224460800.0 | grad norm avg: 1.18 | grad norm last: 1.04 | 
2026-01-01T06:31:19 | step: 27500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.7481287765549496e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.76 | train loss last: 2.25 | consumed tokens: 225280000.0 | grad norm avg: 1.18 | grad norm last: 1.2 | 
2026-01-01T06:31:37 | step: 27600 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.7461988287977874e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.73 | train loss last: 2.83 | consumed tokens: 226099200.0 | grad norm avg: 1.19 | grad norm last: 1.26 | 
2026-01-01T06:31:55 | step: 27700 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.744261968880892e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.77 | train loss last: 2.55 | consumed tokens: 226918400.0 | grad norm avg: 1.21 | grad norm last: 1.13 | 
2026-01-01T06:32:13 | step: 27800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.742318196804263e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.75 | train loss last: 3.09 | consumed tokens: 227737600.0 | grad norm avg: 1.19 | grad norm last: 1.17 | 
2026-01-01T06:32:31 | step: 27900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.7403671487700194e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.77 | train loss last: 2.56 | consumed tokens: 228556800.0 | grad norm avg: 1.19 | grad norm last: 1.11 | 
2026-01-01T06:32:49 | step: 28000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.7384095523739234e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.73 | train loss last: 3.11 | consumed tokens: 229376000.0 | grad norm avg: 1.21 | grad norm last: 1.21 | 
2026-01-01T06:33:07 | step: 28100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.736444680020213e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.74 | train loss last: 2.83 | consumed tokens: 230195200.0 | grad norm avg: 1.19 | grad norm last: 1.09 | 
2026-01-01T06:33:25 | step: 28200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.73447325930465e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.76 | train loss last: 2.81 | consumed tokens: 231014400.0 | grad norm avg: 1.2 | grad norm last: 1.19 | 
2026-01-01T06:33:43 | step: 28300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.732494562631473e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.74 | train loss last: 2.62 | consumed tokens: 231833600.0 | grad norm avg: 1.2 | grad norm last: 1.13 | 
2026-01-01T06:34:01 | step: 28400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.730509317596443e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.73 | train loss last: 2.69 | consumed tokens: 232652800.0 | grad norm avg: 1.22 | grad norm last: 1.14 | 
2026-01-01T06:34:19 | step: 28500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.728516796603799e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.72 | train loss last: 2.27 | consumed tokens: 233472000.0 | grad norm avg: 1.2 | grad norm last: 1.22 | 
2026-01-01T06:34:37 | step: 28600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.726517363451421e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.69 | train loss last: 2.69 | consumed tokens: 234291200.0 | grad norm avg: 1.21 | grad norm last: 1.14 | 
2026-01-01T06:34:55 | step: 28700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.72451101813931e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.74 | train loss last: 2.67 | consumed tokens: 235110400.0 | grad norm avg: 1.22 | grad norm last: 1.25 | 
2026-01-01T06:35:13 | step: 28800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.722498124465346e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.74 | train loss last: 3.03 | consumed tokens: 235929600.0 | grad norm avg: 1.21 | grad norm last: 1.34 | 
2026-01-01T06:35:31 | step: 28900 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.720477954833768e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.74 | train loss last: 2.45 | consumed tokens: 236748800.0 | grad norm avg: 1.18 | grad norm last: 1.29 | 
2026-01-01T06:35:49 | step: 29000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.7184512368403375e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.72 | train loss last: 2.83 | consumed tokens: 237568000.0 | grad norm avg: 1.2 | grad norm last: 1.27 | 
2026-01-01T06:36:07 | step: 29100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.7164172428892925e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.71 | train loss last: 2.88 | consumed tokens: 238387200.0 | grad norm avg: 1.21 | grad norm last: 1.14 | 
2026-01-01T06:36:25 | step: 29200 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.714376700576395e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.73 | train loss last: 2.73 | consumed tokens: 239206400.0 | grad norm avg: 1.19 | grad norm last: 1.48 | 
2026-01-01T06:36:43 | step: 29300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.712328882305883e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.72 | train loss last: 2.8 | consumed tokens: 240025600.0 | grad norm avg: 1.21 | grad norm last: 1.23 | 
2026-01-01T06:37:01 | step: 29400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.710274515673518e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.74 | train loss last: 2.78 | consumed tokens: 240844800.0 | grad norm avg: 1.22 | grad norm last: 1.19 | 
2026-01-01T06:37:19 | step: 29500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.70821323688142e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.73 | train loss last: 2.78 | consumed tokens: 241664000.0 | grad norm avg: 1.2 | grad norm last: 1.29 | 
2026-01-01T06:37:37 | step: 29600 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.7061450459295884e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.71 | train loss last: 2.83 | consumed tokens: 242483200.0 | grad norm avg: 1.2 | grad norm last: 1.38 | 
2026-01-01T06:37:55 | step: 29700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.704070306615904e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.74 | train loss last: 2.69 | consumed tokens: 243302400.0 | grad norm avg: 1.21 | grad norm last: 1.26 | 
2026-01-01T06:38:13 | step: 29800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.7019882913446054e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.72 | train loss last: 2.8 | consumed tokens: 244121600.0 | grad norm avg: 1.21 | grad norm last: 1.15 | 
2026-01-01T06:38:31 | step: 29900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.699899727711454e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.72 | train loss last: 2.94 | consumed tokens: 244940800.0 | grad norm avg: 1.22 | grad norm last: 1.19 | 
2026-01-01T06:38:49 | step: 30000 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.697804251918569e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.74 | train loss last: 3.03 | consumed tokens: 245760000.0 | grad norm avg: 1.22 | grad norm last: 1.25 | 
2026-01-01T06:39:09 | step: 30100 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.695701863965951e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.71 | train loss last: 2.27 | consumed tokens: 246579200.0 | grad norm avg: 1.22 | grad norm last: 1.22 | 
2026-01-01T06:39:27 | step: 30200 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.69359292765148e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.73 | train loss last: 2.88 | consumed tokens: 247398400.0 | grad norm avg: 1.22 | grad norm last: 1.17 | 
2026-01-01T06:39:45 | step: 30300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.691477079177275e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.72 | train loss last: 2.47 | consumed tokens: 248217600.0 | grad norm avg: 1.21 | grad norm last: 1.23 | 
2026-01-01T06:40:03 | step: 30400 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.689354318543337e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.7 | train loss last: 2.38 | consumed tokens: 249036800.0 | grad norm avg: 1.21 | grad norm last: 1.1 | 
2026-01-01T06:40:21 | step: 30500 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.687224645749666e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.71 | train loss last: 3.06 | consumed tokens: 249856000.0 | grad norm avg: 1.21 | grad norm last: 1.13 | 
2026-01-01T06:40:39 | step: 30600 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.6850884245941415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.72 | train loss last: 2.64 | consumed tokens: 250675200.0 | grad norm avg: 1.2 | grad norm last: 1.11 | 
2026-01-01T06:40:57 | step: 30700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.682945291278884e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.7 | train loss last: 2.58 | consumed tokens: 251494400.0 | grad norm avg: 1.22 | grad norm last: 1.32 | 
2026-01-01T06:41:15 | step: 30800 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.680795609601773e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.69 | train loss last: 2.12 | consumed tokens: 252313600.0 | grad norm avg: 1.19 | grad norm last: 1.22 | 
2026-01-01T06:41:33 | step: 30900 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.6786390157649294e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.74 | train loss last: 1.98 | consumed tokens: 253132800.0 | grad norm avg: 1.22 | grad norm last: 1.17 | 
2026-01-01T06:41:51 | step: 31000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.676475509768352e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.72 | train loss last: 3.08 | consumed tokens: 253952000.0 | grad norm avg: 1.23 | grad norm last: 1.18 | 
2026-01-01T06:42:09 | step: 31100 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.674305455409922e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.71 | train loss last: 2.5 | consumed tokens: 254771200.0 | grad norm avg: 1.2 | grad norm last: 1.23 | 
2026-01-01T06:42:27 | step: 31200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.672128488891758e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.73 | train loss last: 2.52 | consumed tokens: 255590400.0 | grad norm avg: 1.21 | grad norm last: 1.34 | 
2026-01-01T06:42:45 | step: 31300 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.6699449740117416e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.7 | train loss last: 2.59 | consumed tokens: 256409600.0 | grad norm avg: 1.2 | grad norm last: 1.25 | 
2026-01-01T06:43:03 | step: 31400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.6677545469719917e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.68 | train loss last: 2.98 | consumed tokens: 257228800.0 | grad norm avg: 1.2 | grad norm last: 1.55 | 
2026-01-01T06:43:21 | step: 31500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.665557571570389e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.71 | train loss last: 2.91 | consumed tokens: 258048000.0 | grad norm avg: 1.24 | grad norm last: 1.26 | 
2026-01-01T06:43:39 | step: 31600 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.663353684009053e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.72 | train loss last: 2.66 | consumed tokens: 258867200.0 | grad norm avg: 1.22 | grad norm last: 1.14 | 
2026-01-01T06:43:57 | step: 31700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.661143248085864e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.73 | train loss last: 2.17 | consumed tokens: 259686400.0 | grad norm avg: 1.21 | grad norm last: 1.14 | 
2026-01-01T06:44:15 | step: 31800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.6589259000029415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.69 | train loss last: 2.5 | consumed tokens: 260505600.0 | grad norm avg: 1.2 | grad norm last: 1.13 | 
2026-01-01T06:44:33 | step: 31900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.656702003558166e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.68 | train loss last: 2.97 | consumed tokens: 261324800.0 | grad norm avg: 1.19 | grad norm last: 1.15 | 
2026-01-01T06:44:50 | step: 32000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.6544715587515384e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.71 | train loss last: 2.7 | consumed tokens: 262144000.0 | grad norm avg: 1.2 | grad norm last: 1.14 | 
2026-01-01T06:45:08 | step: 32100 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.652234201785177e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.71 | train loss last: 3.22 | consumed tokens: 262963200.0 | grad norm avg: 1.22 | grad norm last: 1.2 | 
2026-01-01T06:45:26 | step: 32200 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.649990296456963e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.73 | train loss last: 2.48 | consumed tokens: 263782400.0 | grad norm avg: 1.2 | grad norm last: 1.35 | 
2026-01-01T06:45:44 | step: 32300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.647739478969015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.7 | train loss last: 2.55 | consumed tokens: 264601600.0 | grad norm avg: 1.2 | grad norm last: 1.26 | 
2026-01-01T06:46:02 | step: 32400 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.645482113119215e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.7 | train loss last: 2.41 | consumed tokens: 265420800.0 | grad norm avg: 1.2 | grad norm last: 1.1 | 
2026-01-01T06:46:20 | step: 32500 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 4.6432181989075616e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.72 | train loss last: 2.53 | consumed tokens: 266240000.0 | grad norm avg: 1.21 | grad norm last: 1.13 | 
2026-01-01T06:46:38 | step: 32600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.640947736334056e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.71 | train loss last: 3.08 | consumed tokens: 267059200.0 | grad norm avg: 1.21 | grad norm last: 1.1 | 
2026-01-01T06:46:56 | step: 32700 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.638670361600816e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.7 | train loss last: 2.84 | consumed tokens: 267878400.0 | grad norm avg: 1.21 | grad norm last: 1.27 | 
2026-01-01T06:47:14 | step: 32800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.636386438505724e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.69 | train loss last: 2.72 | consumed tokens: 268697600.0 | grad norm avg: 1.21 | grad norm last: 1.21 | 
2026-01-01T06:47:32 | step: 32900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.634095967048779e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.71 | train loss last: 2.86 | consumed tokens: 269516800.0 | grad norm avg: 1.22 | grad norm last: 1.31 | 
2026-01-01T06:47:50 | step: 33000 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.6317989472299814e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.7 | train loss last: 2.83 | consumed tokens: 270336000.0 | grad norm avg: 1.2 | grad norm last: 1.29 | 
2026-01-01T06:48:08 | step: 33100 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.62949501525145e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.71 | train loss last: 3.03 | consumed tokens: 271155200.0 | grad norm avg: 1.2 | grad norm last: 1.34 | 
2026-01-01T06:48:26 | step: 33200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.627184898708947e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.7 | train loss last: 2.28 | consumed tokens: 271974400.0 | grad norm avg: 1.21 | grad norm last: 1.26 | 
2026-01-01T06:48:44 | step: 33300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.62486787000671e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.67 | train loss last: 2.25 | consumed tokens: 272793600.0 | grad norm avg: 1.21 | grad norm last: 1.27 | 
2026-01-01T06:49:02 | step: 33400 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.622544292942621e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.69 | train loss last: 3.16 | consumed tokens: 273612800.0 | grad norm avg: 1.21 | grad norm last: 1.25 | 
2026-01-01T06:49:20 | step: 33500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.6202141675166786e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.7 | train loss last: 2.22 | consumed tokens: 274432000.0 | grad norm avg: 1.21 | grad norm last: 1.11 | 
2026-01-01T06:49:38 | step: 33600 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.6178774937288836e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.69 | train loss last: 2.98 | consumed tokens: 275251200.0 | grad norm avg: 1.2 | grad norm last: 1.11 | 
2026-01-01T06:49:56 | step: 33700 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.615534271579236e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.71 | train loss last: 2.22 | consumed tokens: 276070400.0 | grad norm avg: 1.2 | grad norm last: 1.27 | 
2026-01-01T06:50:14 | step: 33800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.6131841372698545e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.7 | train loss last: 2.58 | consumed tokens: 276889600.0 | grad norm avg: 1.2 | grad norm last: 1.16 | 
2026-01-01T06:50:32 | step: 33900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.610827818396501e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.71 | train loss last: 2.31 | consumed tokens: 277708800.0 | grad norm avg: 1.19 | grad norm last: 1.2 | 
2026-01-01T06:50:50 | step: 34000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.608464951161295e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.71 | train loss last: 2.53 | consumed tokens: 278528000.0 | grad norm avg: 1.21 | grad norm last: 1.15 | 
2026-01-01T06:51:09 | step: 34100 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.6060955355642363e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.71 | train loss last: 2.56 | consumed tokens: 279347200.0 | grad norm avg: 1.21 | grad norm last: 1.25 | 
2026-01-01T06:51:27 | step: 34200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.603719571605325e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.69 | train loss last: 2.69 | consumed tokens: 280166400.0 | grad norm avg: 1.22 | grad norm last: 1.19 | 
2026-01-01T06:51:45 | step: 34300 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.60133669548668e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.7 | train loss last: 3.0 | consumed tokens: 280985600.0 | grad norm avg: 1.21 | grad norm last: 1.11 | 
2026-01-01T06:52:03 | step: 34400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.5989476348040625e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.72 | train loss last: 2.69 | consumed tokens: 281804800.0 | grad norm avg: 1.2 | grad norm last: 1.27 | 
2026-01-01T06:52:21 | step: 34500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.5965520257595927e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.69 | train loss last: 2.66 | consumed tokens: 282624000.0 | grad norm avg: 1.2 | grad norm last: 1.21 | 
2026-01-01T06:52:39 | step: 34600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.594150232151151e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.69 | train loss last: 3.09 | consumed tokens: 283443200.0 | grad norm avg: 1.21 | grad norm last: 1.23 | 
2026-01-01T06:52:57 | step: 34700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.591741526382975e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.71 | train loss last: 2.97 | consumed tokens: 284262400.0 | grad norm avg: 1.22 | grad norm last: 1.33 | 
2026-01-01T06:53:15 | step: 34800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.589326272252947e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.72 | train loss last: 2.62 | consumed tokens: 285081600.0 | grad norm avg: 1.21 | grad norm last: 1.11 | 
2026-01-01T06:53:33 | step: 34900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.586904833558947e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.7 | train loss last: 2.64 | consumed tokens: 285900800.0 | grad norm avg: 1.22 | grad norm last: 1.34 | 
2026-01-01T06:53:51 | step: 35000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.584476846503094e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.69 | train loss last: 2.52 | consumed tokens: 286720000.0 | grad norm avg: 1.22 | grad norm last: 1.21 | 
2026-01-01T06:54:10 | step: 35100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.582042311085388e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.68 | train loss last: 2.38 | consumed tokens: 287539200.0 | grad norm avg: 1.23 | grad norm last: 1.2 | 
2026-01-01T06:54:28 | step: 35200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.5796012273058295e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.68 | train loss last: 2.61 | consumed tokens: 288358400.0 | grad norm avg: 1.24 | grad norm last: 1.39 | 
2026-01-01T06:54:46 | step: 35300 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.577153958962299e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.69 | train loss last: 2.84 | consumed tokens: 289177600.0 | grad norm avg: 1.21 | grad norm last: 1.12 | 
2026-01-01T06:55:04 | step: 35400 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.5747001422569156e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.67 | train loss last: 2.95 | consumed tokens: 289996800.0 | grad norm avg: 1.2 | grad norm last: 1.22 | 
2026-01-01T06:55:22 | step: 35500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.5722397771896794e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.69 | train loss last: 2.47 | consumed tokens: 290816000.0 | grad norm avg: 1.2 | grad norm last: 1.15 | 
2026-01-01T06:55:40 | step: 35600 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.5697728637605906e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.7 | consumed tokens: 291635200.0 | grad norm avg: 1.23 | grad norm last: 1.4 | 
2026-01-01T06:55:58 | step: 35700 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.5672997657675296e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.68 | train loss last: 2.44 | consumed tokens: 292454400.0 | grad norm avg: 1.22 | grad norm last: 1.3 | 
2026-01-01T06:56:16 | step: 35800 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 4.564820119412616e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.7 | train loss last: 2.22 | consumed tokens: 293273600.0 | grad norm avg: 1.21 | grad norm last: 1.29 | 
2026-01-01T06:56:34 | step: 35900 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.56233428849373e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.68 | train loss last: 2.16 | consumed tokens: 294092800.0 | grad norm avg: 1.21 | grad norm last: 1.14 | 
2026-01-01T06:56:52 | step: 36000 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.5598419092129916e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.68 | train loss last: 2.55 | consumed tokens: 294912000.0 | grad norm avg: 1.23 | grad norm last: 1.25 | 
2026-01-01T06:57:10 | step: 36100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.5573429815704e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.68 | train loss last: 2.67 | consumed tokens: 295731200.0 | grad norm avg: 1.22 | grad norm last: 1.14 | 
2026-01-01T06:57:28 | step: 36200 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.554837869363837e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.67 | train loss last: 2.81 | consumed tokens: 296550400.0 | grad norm avg: 1.21 | grad norm last: 1.23 | 
2026-01-01T06:57:46 | step: 36300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.5523265725933015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.68 | train loss last: 2.59 | consumed tokens: 297369600.0 | grad norm avg: 1.21 | grad norm last: 1.03 | 
2026-01-01T06:58:04 | step: 36400 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.5498087274609134e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 3.09 | consumed tokens: 298188800.0 | grad norm avg: 1.23 | grad norm last: 1.12 | 
2026-01-01T06:58:22 | step: 36500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.5472843339666724e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.69 | train loss last: 2.2 | consumed tokens: 299008000.0 | grad norm avg: 1.22 | grad norm last: 1.24 | 
2026-01-01T06:58:40 | step: 36600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.5447537559084594e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.68 | train loss last: 2.3 | consumed tokens: 299827200.0 | grad norm avg: 1.21 | grad norm last: 1.06 | 
2026-01-01T06:58:58 | step: 36700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.542216629488394e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.69 | train loss last: 2.89 | consumed tokens: 300646400.0 | grad norm avg: 1.21 | grad norm last: 1.29 | 
2026-01-01T06:59:16 | step: 36800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.5396736823022366e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.68 | train loss last: 2.48 | consumed tokens: 301465600.0 | grad norm avg: 1.22 | grad norm last: 1.18 | 
2026-01-01T06:59:34 | step: 36900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.537123822956346e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.69 | train loss last: 2.44 | consumed tokens: 302284800.0 | grad norm avg: 1.22 | grad norm last: 1.09 | 
2026-01-01T06:59:52 | step: 37000 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.534568142844364e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.67 | train loss last: 2.83 | consumed tokens: 303104000.0 | grad norm avg: 1.22 | grad norm last: 1.19 | 
2026-01-01T07:00:10 | step: 37100 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.5320055505726486e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.52 | consumed tokens: 303923200.0 | grad norm avg: 1.25 | grad norm last: 1.15 | 
2026-01-01T07:00:28 | step: 37200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.529437137534842e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.69 | train loss last: 3.16 | consumed tokens: 304742400.0 | grad norm avg: 1.21 | grad norm last: 1.13 | 
2026-01-01T07:00:46 | step: 37300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.5268621761351824e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.25 | consumed tokens: 305561600.0 | grad norm avg: 1.22 | grad norm last: 1.24 | 
2026-01-01T07:01:04 | step: 37400 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.524281030171551e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.69 | train loss last: 2.7 | consumed tokens: 306380800.0 | grad norm avg: 1.22 | grad norm last: 1.13 | 
2026-01-01T07:01:22 | step: 37500 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.521693699643947e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 2.5 | consumed tokens: 307200000.0 | grad norm avg: 1.22 | grad norm last: 1.25 | 
2026-01-01T07:01:40 | step: 37600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.5191001845523715e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.68 | train loss last: 2.78 | consumed tokens: 308019200.0 | grad norm avg: 1.23 | grad norm last: 1.26 | 
2026-01-01T07:01:58 | step: 37700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.516500121098943e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.67 | consumed tokens: 308838400.0 | grad norm avg: 1.23 | grad norm last: 1.13 | 
2026-01-01T07:02:16 | step: 37800 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.5138938730815426e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.53 | consumed tokens: 309657600.0 | grad norm avg: 1.23 | grad norm last: 1.3 | 
2026-01-01T07:02:34 | step: 37900 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.51128144050017e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 2.64 | consumed tokens: 310476800.0 | grad norm avg: 1.22 | grad norm last: 1.1 | 
2026-01-01T07:02:52 | step: 38000 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.5086628233548254e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.68 | train loss last: 2.48 | consumed tokens: 311296000.0 | grad norm avg: 1.22 | grad norm last: 1.1 | 
2026-01-01T07:03:10 | step: 38100 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.506038021645509e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.68 | train loss last: 2.28 | consumed tokens: 312115200.0 | grad norm avg: 1.24 | grad norm last: 1.21 | 
2026-01-01T07:03:28 | step: 38200 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.503406671574339e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.52 | consumed tokens: 312934400.0 | grad norm avg: 1.24 | grad norm last: 1.26 | 
2026-01-01T07:03:46 | step: 38300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.5007695007370785e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.68 | train loss last: 2.59 | consumed tokens: 313753600.0 | grad norm avg: 1.23 | grad norm last: 1.14 | 
2026-01-01T07:04:04 | step: 38400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.498125781537965e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 3.12 | consumed tokens: 314572800.0 | grad norm avg: 1.23 | grad norm last: 1.12 | 
2026-01-01T07:04:22 | step: 38500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.495475877774879e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.61 | consumed tokens: 315392000.0 | grad norm avg: 1.22 | grad norm last: 1.25 | 
2026-01-01T07:04:40 | step: 38600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.4928201532457024e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 2.58 | consumed tokens: 316211200.0 | grad norm avg: 1.22 | grad norm last: 1.06 | 
2026-01-01T07:04:58 | step: 38700 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.490157880354673e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.68 | train loss last: 2.48 | consumed tokens: 317030400.0 | grad norm avg: 1.22 | grad norm last: 1.25 | 
2026-01-01T07:05:16 | step: 38800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.487489422899671e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.56 | consumed tokens: 317849600.0 | grad norm avg: 1.23 | grad norm last: 1.07 | 
2026-01-01T07:05:34 | step: 38900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.484815144678578e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.67 | train loss last: 3.36 | consumed tokens: 318668800.0 | grad norm avg: 1.22 | grad norm last: 1.29 | 
2026-01-01T07:05:52 | step: 39000 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.482134318095632e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.69 | train loss last: 2.8 | consumed tokens: 319488000.0 | grad norm avg: 1.23 | grad norm last: 1.23 | 
2026-01-01T07:06:10 | step: 39100 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.479447670746595e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.68 | train loss last: 2.66 | consumed tokens: 320307200.0 | grad norm avg: 1.23 | grad norm last: 1.15 | 
2026-01-01T07:06:28 | step: 39200 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.4767548388335854e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.67 | train loss last: 2.41 | consumed tokens: 321126400.0 | grad norm avg: 1.23 | grad norm last: 1.3 | 
2026-01-01T07:06:46 | step: 39300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.474055822356604e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.69 | consumed tokens: 321945600.0 | grad norm avg: 1.22 | grad norm last: 1.22 | 
2026-01-01T07:07:04 | step: 39400 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.4713506213156506e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.73 | consumed tokens: 322764800.0 | grad norm avg: 1.21 | grad norm last: 1.19 | 
2026-01-01T07:07:23 | step: 39500 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.468639235710725e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.68 | train loss last: 2.86 | consumed tokens: 323584000.0 | grad norm avg: 1.22 | grad norm last: 1.3 | 
2026-01-01T07:07:41 | step: 39600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.465921665541828e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.67 | train loss last: 2.86 | consumed tokens: 324403200.0 | grad norm avg: 1.21 | grad norm last: 1.21 | 
2026-01-01T07:07:59 | step: 39700 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.463198274606839e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.59 | consumed tokens: 325222400.0 | grad norm avg: 1.2 | grad norm last: 1.12 | 
2026-01-01T07:08:17 | step: 39800 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.460468699107878e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.69 | train loss last: 2.66 | consumed tokens: 326041600.0 | grad norm avg: 1.2 | grad norm last: 1.22 | 
2026-01-01T07:08:35 | step: 39900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.457732939044945e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.68 | train loss last: 2.23 | consumed tokens: 326860800.0 | grad norm avg: 1.24 | grad norm last: 1.27 | 
2026-01-01T07:08:53 | step: 40000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.45499099441804e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 2.39 | consumed tokens: 327680000.0 | grad norm avg: 1.21 | grad norm last: 1.19 | 
2026-01-01T07:09:12 | step: 40100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.4522432290250435e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 2.69 | consumed tokens: 328499200.0 | grad norm avg: 1.23 | grad norm last: 1.29 | 
2026-01-01T07:09:30 | step: 40200 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.449489279068075e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.77 | consumed tokens: 329318400.0 | grad norm avg: 1.24 | grad norm last: 1.27 | 
2026-01-01T07:09:50 | step: 40300 | train samples/s: 88.2 | train mfu (16-bit): -1.0 | lr mean: 4.4467295083450153e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 2.83 | consumed tokens: 330137600.0 | grad norm avg: 1.23 | grad norm last: 1.19 | 
2026-01-01T07:10:10 | step: 40400 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.4439635530579835e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.53 | consumed tokens: 330956800.0 | grad norm avg: 1.22 | grad norm last: 1.12 | 
2026-01-01T07:10:28 | step: 40500 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.4411914132069796e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.69 | train loss last: 3.14 | consumed tokens: 331776000.0 | grad norm avg: 1.23 | grad norm last: 1.14 | 
2026-01-01T07:10:46 | step: 40600 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.4384134525898844e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.41 | consumed tokens: 332595200.0 | grad norm avg: 1.22 | grad norm last: 1.23 | 
2026-01-01T07:11:05 | step: 40700 | train samples/s: 95.2 | train mfu (16-bit): -1.0 | lr mean: 4.435629307408817e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.7 | train loss last: 2.69 | consumed tokens: 333414400.0 | grad norm avg: 1.22 | grad norm last: 1.28 | 
2026-01-01T07:11:23 | step: 40800 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.4328393414616585e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.68 | train loss last: 3.19 | consumed tokens: 334233600.0 | grad norm avg: 1.23 | grad norm last: 1.26 | 
2026-01-01T07:11:41 | step: 40900 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.4300435547484085e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 3.11 | consumed tokens: 335052800.0 | grad norm avg: 1.23 | grad norm last: 1.25 | 
2026-01-01T07:11:59 | step: 41000 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.427241219673306e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.67 | train loss last: 3.34 | consumed tokens: 335872000.0 | grad norm avg: 1.22 | grad norm last: 1.1 | 
2026-01-01T07:12:17 | step: 41100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.4244334276299924e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.67 | train loss last: 2.92 | consumed tokens: 336691200.0 | grad norm avg: 1.24 | grad norm last: 1.35 | 
2026-01-01T07:12:35 | step: 41200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.421619451022707e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 1.92 | consumed tokens: 337510400.0 | grad norm avg: 1.23 | grad norm last: 1.14 | 
2026-01-01T07:12:53 | step: 41300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.4187992898514494e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 2.73 | consumed tokens: 338329600.0 | grad norm avg: 1.23 | grad norm last: 1.11 | 
2026-01-01T07:13:11 | step: 41400 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.415973671711981e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.68 | train loss last: 2.39 | consumed tokens: 339148800.0 | grad norm avg: 1.23 | grad norm last: 1.35 | 
2026-01-01T07:13:29 | step: 41500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.413141869008541e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.67 | train loss last: 3.38 | consumed tokens: 339968000.0 | grad norm avg: 1.24 | grad norm last: 1.25 | 
2026-01-01T07:13:47 | step: 41600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.410303881741129e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.7 | train loss last: 2.89 | consumed tokens: 340787200.0 | grad norm avg: 1.23 | grad norm last: 1.22 | 
2026-01-01T07:14:06 | step: 41700 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.407460073707625e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 3.23 | consumed tokens: 341606400.0 | grad norm avg: 1.23 | grad norm last: 1.17 | 
2026-01-01T07:14:24 | step: 41800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.40461044490803e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 2.81 | consumed tokens: 342425600.0 | grad norm avg: 1.22 | grad norm last: 1.18 | 
2026-01-01T07:14:42 | step: 41900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.401754995342344e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 3.27 | consumed tokens: 343244800.0 | grad norm avg: 1.23 | grad norm last: 1.19 | 
2026-01-01T07:15:00 | step: 42000 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.3988937250105664e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.39 | consumed tokens: 344064000.0 | grad norm avg: 1.23 | grad norm last: 1.12 | 
2026-01-01T07:15:18 | step: 42100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.396026270114817e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 2.95 | consumed tokens: 344883200.0 | grad norm avg: 1.24 | grad norm last: 1.19 | 
2026-01-01T07:15:36 | step: 42200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.393152994452976e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 3.03 | consumed tokens: 345702400.0 | grad norm avg: 1.24 | grad norm last: 1.14 | 
2026-01-01T07:15:54 | step: 42300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.390274261822924e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 3.42 | consumed tokens: 346521600.0 | grad norm avg: 1.23 | grad norm last: 1.18 | 
2026-01-01T07:16:12 | step: 42400 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.3873889808310196e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 3.36 | consumed tokens: 347340800.0 | grad norm avg: 1.23 | grad norm last: 1.22 | 
2026-01-01T07:16:30 | step: 42500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.3844982428709045e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 1.63 | consumed tokens: 348160000.0 | grad norm avg: 1.24 | grad norm last: 1.11 | 
2026-01-01T07:16:49 | step: 42600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.381601684144698e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.67 | train loss last: 2.36 | consumed tokens: 348979200.0 | grad norm avg: 1.23 | grad norm last: 1.18 | 
2026-01-01T07:17:07 | step: 42700 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.3786993046524e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 2.53 | consumed tokens: 349798400.0 | grad norm avg: 1.25 | grad norm last: 1.18 | 
2026-01-01T07:17:25 | step: 42800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.375791104394011e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.83 | consumed tokens: 350617600.0 | grad norm avg: 1.23 | grad norm last: 1.23 | 
2026-01-01T07:17:43 | step: 42900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.37287671957165e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 3.08 | consumed tokens: 351436800.0 | grad norm avg: 1.25 | grad norm last: 1.12 | 
2026-01-01T07:18:01 | step: 43000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.369956877781078e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.48 | consumed tokens: 352256000.0 | grad norm avg: 1.23 | grad norm last: 1.42 | 
2026-01-01T07:18:19 | step: 43100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.367031215224415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 3.27 | consumed tokens: 353075200.0 | grad norm avg: 1.23 | grad norm last: 1.21 | 
2026-01-01T07:18:37 | step: 43200 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.3640997319016606e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 2.98 | consumed tokens: 353894400.0 | grad norm avg: 1.22 | grad norm last: 1.17 | 
2026-01-01T07:18:55 | step: 43300 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.361162427812815e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.8 | consumed tokens: 354713600.0 | grad norm avg: 1.22 | grad norm last: 1.19 | 
2026-01-01T07:19:14 | step: 43400 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.3582193029578775e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 3.02 | consumed tokens: 355532800.0 | grad norm avg: 1.23 | grad norm last: 1.3 | 
2026-01-01T07:19:32 | step: 43500 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.355270357336849e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.33 | consumed tokens: 356352000.0 | grad norm avg: 1.25 | grad norm last: 1.25 | 
2026-01-01T07:19:50 | step: 43600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.35231595474761e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 2.11 | consumed tokens: 357171200.0 | grad norm avg: 1.22 | grad norm last: 1.13 | 
2026-01-01T07:20:08 | step: 43700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.3493553675943986e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.53 | consumed tokens: 357990400.0 | grad norm avg: 1.23 | grad norm last: 1.23 | 
2026-01-01T07:20:26 | step: 43800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.346389323472977e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 2.33 | consumed tokens: 358809600.0 | grad norm avg: 1.24 | grad norm last: 1.26 | 
2026-01-01T07:20:44 | step: 43900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.3434174585854635e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 2.48 | consumed tokens: 359628800.0 | grad norm avg: 1.24 | grad norm last: 1.23 | 
2026-01-01T07:21:02 | step: 44000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.3404401367297396e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 2.69 | consumed tokens: 360448000.0 | grad norm avg: 1.24 | grad norm last: 1.28 | 
2026-01-01T07:21:20 | step: 44100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.337456630310044e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.64 | consumed tokens: 361267200.0 | grad norm avg: 1.24 | grad norm last: 1.26 | 
2026-01-01T07:21:38 | step: 44200 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.334468030720018e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.66 | consumed tokens: 362086400.0 | grad norm avg: 1.24 | grad norm last: 1.29 | 
2026-01-01T07:21:56 | step: 44300 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 4.33147324656602e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 2.7 | consumed tokens: 362905600.0 | grad norm avg: 1.24 | grad norm last: 1.28 | 
2026-01-01T07:22:14 | step: 44400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.3284730054438114e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 2.73 | consumed tokens: 363724800.0 | grad norm avg: 1.24 | grad norm last: 1.26 | 
2026-01-01T07:22:32 | step: 44500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.3254669435555115e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 2.45 | consumed tokens: 364544000.0 | grad norm avg: 1.23 | grad norm last: 1.2 | 
2026-01-01T07:22:50 | step: 44600 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.322455424699001e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 2.77 | consumed tokens: 365363200.0 | grad norm avg: 1.25 | grad norm last: 1.17 | 
2026-01-01T07:23:08 | step: 44700 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.319438085076399e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.48 | consumed tokens: 366182400.0 | grad norm avg: 1.22 | grad norm last: 1.2 | 
2026-01-01T07:23:26 | step: 44800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.316414924687706e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 2.39 | consumed tokens: 367001600.0 | grad norm avg: 1.24 | grad norm last: 1.24 | 
2026-01-01T07:23:44 | step: 44900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.313386307330802e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 3.23 | consumed tokens: 367820800.0 | grad norm avg: 1.26 | grad norm last: 1.26 | 
2026-01-01T07:24:02 | step: 45000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.3103522330056876e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 2.61 | consumed tokens: 368640000.0 | grad norm avg: 1.25 | grad norm last: 1.41 | 
2026-01-01T07:24:22 | step: 45100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.307312337914482e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 2.84 | consumed tokens: 369459200.0 | grad norm avg: 1.25 | grad norm last: 1.19 | 
2026-01-01T07:24:40 | step: 45200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.304266985855065e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 2.53 | consumed tokens: 370278400.0 | grad norm avg: 1.24 | grad norm last: 1.14 | 
2026-01-01T07:24:58 | step: 45300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.301216176827438e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.42 | consumed tokens: 371097600.0 | grad norm avg: 1.25 | grad norm last: 1.34 | 
2026-01-01T07:25:16 | step: 45400 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.29815954703372e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.45 | consumed tokens: 371916800.0 | grad norm avg: 1.23 | grad norm last: 1.17 | 
2026-01-01T07:25:34 | step: 45500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.29509709647391e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.67 | train loss last: 2.0 | consumed tokens: 372736000.0 | grad norm avg: 1.24 | grad norm last: 1.27 | 
2026-01-01T07:25:52 | step: 45600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.29202955274377e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.3 | consumed tokens: 373555200.0 | grad norm avg: 1.23 | grad norm last: 1.25 | 
2026-01-01T07:26:10 | step: 45700 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.288956188247539e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 2.66 | consumed tokens: 374374400.0 | grad norm avg: 1.25 | grad norm last: 1.16 | 
2026-01-01T07:26:28 | step: 45800 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.2858773667830974e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.25 | consumed tokens: 375193600.0 | grad norm avg: 1.26 | grad norm last: 1.26 | 
2026-01-01T07:26:46 | step: 45900 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 4.282792724552564e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.78 | consumed tokens: 376012800.0 | grad norm avg: 1.24 | grad norm last: 1.19 | 
2026-01-01T07:27:04 | step: 46000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.279702989151701e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.58 | consumed tokens: 376832000.0 | grad norm avg: 1.23 | grad norm last: 1.34 | 
2026-01-01T07:27:22 | step: 46100 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.276607432984747e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.45 | consumed tokens: 377651200.0 | grad norm avg: 1.25 | grad norm last: 1.2 | 
2026-01-01T07:27:40 | step: 46200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.273506419849582e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.61 | consumed tokens: 378470400.0 | grad norm avg: 1.26 | grad norm last: 1.41 | 
2026-01-01T07:27:58 | step: 46300 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.2703999497462064e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 2.58 | consumed tokens: 379289600.0 | grad norm avg: 1.22 | grad norm last: 1.19 | 
2026-01-01T07:28:16 | step: 46400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.26728802267462e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.16 | consumed tokens: 380108800.0 | grad norm avg: 1.25 | grad norm last: 1.13 | 
2026-01-01T07:28:34 | step: 46500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.264170638634823e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 2.34 | consumed tokens: 380928000.0 | grad norm avg: 1.24 | grad norm last: 1.26 | 
2026-01-01T07:28:52 | step: 46600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.261047797626816e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 3.05 | consumed tokens: 381747200.0 | grad norm avg: 1.25 | grad norm last: 1.35 | 
2026-01-01T07:29:10 | step: 46700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.2579194996505976e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 2.66 | consumed tokens: 382566400.0 | grad norm avg: 1.25 | grad norm last: 1.15 | 
2026-01-01T07:29:28 | step: 46800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.254785380908288e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.94 | consumed tokens: 383385600.0 | grad norm avg: 1.25 | grad norm last: 1.23 | 
2026-01-01T07:29:46 | step: 46900 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.2516461689956486e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.7 | consumed tokens: 384204800.0 | grad norm avg: 1.25 | grad norm last: 1.21 | 
2026-01-01T07:30:04 | step: 47000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.2485015001147985e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 2.62 | consumed tokens: 385024000.0 | grad norm avg: 1.23 | grad norm last: 1.23 | 
2026-01-01T07:30:22 | step: 47100 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.245351374265738e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.33 | consumed tokens: 385843200.0 | grad norm avg: 1.26 | grad norm last: 1.31 | 
2026-01-01T07:30:41 | step: 47200 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.2421957914484665e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 3.06 | consumed tokens: 386662400.0 | grad norm avg: 1.24 | grad norm last: 1.34 | 
2026-01-01T07:30:59 | step: 47300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.2390347516629845e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.94 | consumed tokens: 387481600.0 | grad norm avg: 1.24 | grad norm last: 1.22 | 
2026-01-01T07:31:17 | step: 47400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.2358686187071726e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.72 | consumed tokens: 388300800.0 | grad norm avg: 1.25 | grad norm last: 2.07 | 
2026-01-01T07:31:35 | step: 47500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.232696664985269e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.58 | consumed tokens: 389120000.0 | grad norm avg: 1.21 | grad norm last: 1.37 | 
2026-01-01T07:31:53 | step: 47600 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.229519618093036e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.28 | consumed tokens: 389939200.0 | grad norm avg: 1.25 | grad norm last: 1.26 | 
2026-01-01T07:32:11 | step: 47700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.226337114232592e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 2.27 | consumed tokens: 390758400.0 | grad norm avg: 1.25 | grad norm last: 1.23 | 
2026-01-01T07:32:29 | step: 47800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.2231495172018185e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 3.09 | consumed tokens: 391577600.0 | grad norm avg: 1.25 | grad norm last: 1.16 | 
2026-01-01T07:32:47 | step: 47900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.2199560994049534e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.77 | consumed tokens: 392396800.0 | grad norm avg: 1.24 | grad norm last: 1.26 | 
2026-01-01T07:33:05 | step: 48000 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.2167575884377584e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.64 | consumed tokens: 393216000.0 | grad norm avg: 1.23 | grad norm last: 1.15 | 
2026-01-01T07:33:23 | step: 48100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.2135539843002334e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 2.61 | consumed tokens: 394035200.0 | grad norm avg: 1.27 | grad norm last: 1.17 | 
2026-01-01T07:33:41 | step: 48200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.210344923194498e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 2.91 | consumed tokens: 394854400.0 | grad norm avg: 1.25 | grad norm last: 1.29 | 
2026-01-01T07:33:59 | step: 48300 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.2071304051205516e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 3.02 | consumed tokens: 395673600.0 | grad norm avg: 1.26 | grad norm last: 1.24 | 
2026-01-01T07:34:17 | step: 48400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.203910430078395e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.81 | consumed tokens: 396492800.0 | grad norm avg: 1.23 | grad norm last: 1.12 | 
2026-01-01T07:34:35 | step: 48500 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.200685361865908e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.33 | consumed tokens: 397312000.0 | grad norm avg: 1.25 | grad norm last: 1.36 | 
2026-01-01T07:34:53 | step: 48600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.197455200483091e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 2.55 | consumed tokens: 398131200.0 | grad norm avg: 1.24 | grad norm last: 1.22 | 
2026-01-01T07:35:11 | step: 48700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.194219582132064e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 3.08 | consumed tokens: 398950400.0 | grad norm avg: 1.26 | grad norm last: 1.15 | 
2026-01-01T07:35:29 | step: 48800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.1909788706107065e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.28 | consumed tokens: 399769600.0 | grad norm avg: 1.24 | grad norm last: 1.22 | 
2026-01-01T07:35:47 | step: 48900 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.1877327021211386e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.77 | consumed tokens: 400588800.0 | grad norm avg: 1.23 | grad norm last: 1.27 | 
2026-01-01T07:36:05 | step: 49000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.184481440461241e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.39 | consumed tokens: 401408000.0 | grad norm avg: 1.25 | grad norm last: 1.2 | 
2026-01-01T07:36:24 | step: 49100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.181225085631013e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.53 | consumed tokens: 402227200.0 | grad norm avg: 1.24 | grad norm last: 1.11 | 
2026-01-01T07:36:42 | step: 49200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.1779632738325745e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 3.69 | consumed tokens: 403046400.0 | grad norm avg: 1.25 | grad norm last: 1.25 | 
2026-01-01T07:37:00 | step: 49300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.174696368863806e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.31 | consumed tokens: 403865600.0 | grad norm avg: 1.24 | grad norm last: 1.26 | 
2026-01-01T07:37:18 | step: 49400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.171424006926827e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.41 | consumed tokens: 404684800.0 | grad norm avg: 1.27 | grad norm last: 1.28 | 
2026-01-01T07:37:36 | step: 49500 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.168146915617399e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 2.28 | consumed tokens: 405504000.0 | grad norm avg: 1.25 | grad norm last: 1.24 | 
2026-01-01T07:37:54 | step: 49600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.16486436733976e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 2.72 | consumed tokens: 406323200.0 | grad norm avg: 1.25 | grad norm last: 1.38 | 
2026-01-01T07:38:12 | step: 49700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.161576725891791e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.66 | train loss last: 2.05 | consumed tokens: 407142400.0 | grad norm avg: 1.24 | grad norm last: 1.23 | 
2026-01-01T07:38:30 | step: 49800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.158283627475612e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 2.8 | consumed tokens: 407961600.0 | grad norm avg: 1.24 | grad norm last: 1.26 | 
2026-01-01T07:38:48 | step: 49900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.154985799686983e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 3.11 | consumed tokens: 408780800.0 | grad norm avg: 1.24 | grad norm last: 1.11 | 
2026-01-01T07:39:06 | step: 50000 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.151682514930144e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 3.11 | consumed tokens: 409600000.0 | grad norm avg: 1.25 | grad norm last: 1.27 | 
2026-01-01T07:39:25 | step: 50100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.1483745008008555e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.2 | consumed tokens: 410419200.0 | grad norm avg: 1.26 | grad norm last: 1.32 | 
2026-01-01T07:39:44 | step: 50200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.145061029703356e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.77 | consumed tokens: 411238400.0 | grad norm avg: 1.26 | grad norm last: 1.24 | 
2026-01-01T07:40:02 | step: 50300 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.141742829233408e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.55 | consumed tokens: 412057600.0 | grad norm avg: 1.26 | grad norm last: 1.16 | 
2026-01-01T07:40:20 | step: 50400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.138419171795249e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.55 | consumed tokens: 412876800.0 | grad norm avg: 1.26 | grad norm last: 1.24 | 
2026-01-01T07:40:38 | step: 50500 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.13509042118676e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.88 | consumed tokens: 413696000.0 | grad norm avg: 1.26 | grad norm last: 1.52 | 
2026-01-01T07:40:56 | step: 50600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.131756941205822e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.64 | consumed tokens: 414515200.0 | grad norm avg: 1.25 | grad norm last: 1.27 | 
2026-01-01T07:41:14 | step: 50700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.128418004256673e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.5 | consumed tokens: 415334400.0 | grad norm avg: 1.24 | grad norm last: 1.13 | 
2026-01-01T07:41:32 | step: 50800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.125074337935075e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.61 | consumed tokens: 416153600.0 | grad norm avg: 1.26 | grad norm last: 1.25 | 
2026-01-01T07:41:50 | step: 50900 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.121725578443147e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.52 | consumed tokens: 416972800.0 | grad norm avg: 1.26 | grad norm last: 1.19 | 
2026-01-01T07:42:08 | step: 51000 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.1183717257808894e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.52 | consumed tokens: 417792000.0 | grad norm avg: 1.24 | grad norm last: 1.19 | 
2026-01-01T07:42:26 | step: 51100 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.1150127799483016e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.69 | consumed tokens: 418611200.0 | grad norm avg: 1.25 | grad norm last: 1.28 | 
2026-01-01T07:42:44 | step: 51200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.111648740945384e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 3.11 | consumed tokens: 419430400.0 | grad norm avg: 1.25 | grad norm last: 1.19 | 
2026-01-01T07:43:02 | step: 51300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.108279972570017e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.84 | consumed tokens: 420249600.0 | grad norm avg: 1.28 | grad norm last: 1.26 | 
2026-01-01T07:43:20 | step: 51400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.10490611102432e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.78 | consumed tokens: 421068800.0 | grad norm avg: 1.27 | grad norm last: 1.19 | 
2026-01-01T07:43:38 | step: 51500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.1015271563082933e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.36 | consumed tokens: 421888000.0 | grad norm avg: 1.26 | grad norm last: 1.28 | 
2026-01-01T07:43:56 | step: 51600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.0981434722198173e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.44 | consumed tokens: 422707200.0 | grad norm avg: 1.26 | grad norm last: 1.25 | 
2026-01-01T07:44:14 | step: 51700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.0947546949610114e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 2.8 | consumed tokens: 423526400.0 | grad norm avg: 1.25 | grad norm last: 1.2 | 
2026-01-01T07:44:32 | step: 51800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.0913608245318756e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.81 | consumed tokens: 424345600.0 | grad norm avg: 1.27 | grad norm last: 1.29 | 
2026-01-01T07:44:50 | step: 51900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.0879622247302905e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.7 | consumed tokens: 425164800.0 | grad norm avg: 1.25 | grad norm last: 1.14 | 
2026-01-01T07:45:08 | step: 52000 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.0845585317583755e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.67 | consumed tokens: 425984000.0 | grad norm avg: 1.28 | grad norm last: 1.5 | 
2026-01-01T07:45:26 | step: 52100 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.081150109414011e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.06 | consumed tokens: 426803200.0 | grad norm avg: 1.28 | grad norm last: 1.27 | 
2026-01-01T07:45:44 | step: 52200 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.077736593899317e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.66 | consumed tokens: 427622400.0 | grad norm avg: 1.25 | grad norm last: 1.27 | 
2026-01-01T07:46:02 | step: 52300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.074318349012174e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.38 | consumed tokens: 428441600.0 | grad norm avg: 1.26 | grad norm last: 1.22 | 
2026-01-01T07:46:20 | step: 52400 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.070895374752581e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.67 | train loss last: 2.8 | consumed tokens: 429260800.0 | grad norm avg: 1.27 | grad norm last: 1.34 | 
2026-01-01T07:46:38 | step: 52500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.0674673073226586e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.81 | consumed tokens: 430080000.0 | grad norm avg: 1.27 | grad norm last: 1.17 | 
2026-01-01T07:46:56 | step: 52600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.064034146722406e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.65 | train loss last: 2.98 | consumed tokens: 430899200.0 | grad norm avg: 1.27 | grad norm last: 1.17 | 
2026-01-01T07:47:14 | step: 52700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.060596620547585e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 2.62 | consumed tokens: 431718400.0 | grad norm avg: 1.27 | grad norm last: 1.16 | 
2026-01-01T07:47:32 | step: 52800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.057154001202434e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.47 | consumed tokens: 432537600.0 | grad norm avg: 1.27 | grad norm last: 1.25 | 
2026-01-01T07:47:50 | step: 52900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.053706652484834e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.95 | consumed tokens: 433356800.0 | grad norm avg: 1.27 | grad norm last: 1.22 | 
2026-01-01T07:48:09 | step: 53000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.050254210596904e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.53 | consumed tokens: 434176000.0 | grad norm avg: 1.26 | grad norm last: 1.44 | 
2026-01-01T07:48:27 | step: 53100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.046797039336525e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.69 | consumed tokens: 434995200.0 | grad norm avg: 1.27 | grad norm last: 1.15 | 
2026-01-01T07:48:45 | step: 53200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.0433351387036964e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.38 | consumed tokens: 435814400.0 | grad norm avg: 1.26 | grad norm last: 1.14 | 
2026-01-01T07:49:03 | step: 53300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.039868508698419e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.36 | consumed tokens: 436633600.0 | grad norm avg: 1.26 | grad norm last: 1.31 | 
2026-01-01T07:49:21 | step: 53400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.036397149320692e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.89 | consumed tokens: 437452800.0 | grad norm avg: 1.27 | grad norm last: 1.2 | 
2026-01-01T07:49:39 | step: 53500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.032921060570516e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 2.25 | consumed tokens: 438272000.0 | grad norm avg: 1.26 | grad norm last: 1.16 | 
2026-01-01T07:49:57 | step: 53600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.0294402424478903e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.38 | consumed tokens: 439091200.0 | grad norm avg: 1.26 | grad norm last: 1.15 | 
2026-01-01T07:50:15 | step: 53700 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.025954331154935e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.95 | consumed tokens: 439910400.0 | grad norm avg: 1.29 | grad norm last: 1.13 | 
2026-01-01T07:50:33 | step: 53800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.022464054287411e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.28 | consumed tokens: 440729600.0 | grad norm avg: 1.27 | grad norm last: 1.31 | 
2026-01-01T07:50:51 | step: 53900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.018969048047438e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.72 | consumed tokens: 441548800.0 | grad norm avg: 1.27 | grad norm last: 1.16 | 
2026-01-01T07:51:09 | step: 54000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.015468948637135e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.78 | consumed tokens: 442368000.0 | grad norm avg: 1.27 | grad norm last: 1.25 | 
2026-01-01T07:51:27 | step: 54100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.011964483652264e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.63 | train loss last: 2.69 | consumed tokens: 443187200.0 | grad norm avg: 1.27 | grad norm last: 1.26 | 
2026-01-01T07:51:45 | step: 54200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.008455289294943e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.08 | consumed tokens: 444006400.0 | grad norm avg: 1.26 | grad norm last: 1.37 | 
2026-01-01T07:52:03 | step: 54300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.004941365565173e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.86 | consumed tokens: 444825600.0 | grad norm avg: 1.26 | grad norm last: 1.39 | 
2026-01-01T07:52:21 | step: 54400 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.001422712462954e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 3.22 | consumed tokens: 445644800.0 | grad norm avg: 1.27 | grad norm last: 1.23 | 
2026-01-01T07:52:39 | step: 54500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.997899329988286e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.61 | consumed tokens: 446464000.0 | grad norm avg: 1.28 | grad norm last: 1.3 | 
2026-01-01T07:52:57 | step: 54600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.994371581939049e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.86 | consumed tokens: 447283200.0 | grad norm avg: 1.27 | grad norm last: 1.17 | 
2026-01-01T07:53:16 | step: 54700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.990839104517363e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.23 | consumed tokens: 448102400.0 | grad norm avg: 1.29 | grad norm last: 1.25 | 
2026-01-01T07:53:34 | step: 54800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.987301897723228e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.83 | consumed tokens: 448921600.0 | grad norm avg: 1.28 | grad norm last: 1.22 | 
2026-01-01T07:53:52 | step: 54900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.983760325354524e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.77 | consumed tokens: 449740800.0 | grad norm avg: 1.27 | grad norm last: 1.16 | 
2026-01-01T07:54:10 | step: 55000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.98021365981549e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.66 | consumed tokens: 450560000.0 | grad norm avg: 1.24 | grad norm last: 1.25 | 
2026-01-01T07:54:29 | step: 55100 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 3.976662992499769e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.64 | consumed tokens: 451379200.0 | grad norm avg: 1.26 | grad norm last: 1.25 | 
2026-01-01T07:54:47 | step: 55200 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.973107232013717e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.88 | consumed tokens: 452198400.0 | grad norm avg: 1.26 | grad norm last: 1.29 | 
2026-01-01T07:55:05 | step: 55300 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.9695471059530973e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.52 | consumed tokens: 453017600.0 | grad norm avg: 1.26 | grad norm last: 1.22 | 
2026-01-01T07:55:24 | step: 55400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.965982614317909e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 3.0 | consumed tokens: 453836800.0 | grad norm avg: 1.27 | grad norm last: 1.2 | 
2026-01-01T07:55:42 | step: 55500 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.962413393310271e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.67 | consumed tokens: 454656000.0 | grad norm avg: 1.27 | grad norm last: 1.37 | 
2026-01-01T07:56:00 | step: 55600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.958839806728065e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 3.17 | consumed tokens: 455475200.0 | grad norm avg: 1.28 | grad norm last: 1.24 | 
2026-01-01T07:56:18 | step: 55700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.9552614907734096e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.59 | consumed tokens: 456294400.0 | grad norm avg: 1.3 | grad norm last: 1.34 | 
2026-01-01T07:56:36 | step: 55800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.951678809244186e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.8 | consumed tokens: 457113600.0 | grad norm avg: 1.29 | grad norm last: 1.22 | 
2026-01-01T07:56:54 | step: 55900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 3.9480913983425125e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.8 | consumed tokens: 457932800.0 | grad norm avg: 1.26 | grad norm last: 1.38 | 
2026-01-01T07:57:12 | step: 56000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.944499621866271e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.38 | consumed tokens: 458752000.0 | grad norm avg: 1.28 | grad norm last: 1.21 | 
2026-01-01T07:57:30 | step: 56100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.940903479815461e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.42 | consumed tokens: 459571200.0 | grad norm avg: 1.28 | grad norm last: 1.37 | 
2026-01-01T07:57:49 | step: 56200 | train samples/s: 91.9 | train mfu (16-bit): -1.0 | lr mean: 3.9373026083922014e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 1.77 | consumed tokens: 460390400.0 | grad norm avg: 1.27 | grad norm last: 1.17 | 
2026-01-01T07:58:07 | step: 56300 | train samples/s: 95.2 | train mfu (16-bit): -1.0 | lr mean: 3.9336973713943735e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.73 | consumed tokens: 461209600.0 | grad norm avg: 1.28 | grad norm last: 1.36 | 
2026-01-01T07:58:25 | step: 56400 | train samples/s: 94.9 | train mfu (16-bit): -1.0 | lr mean: 3.930087768821977e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.59 | consumed tokens: 462028800.0 | grad norm avg: 1.28 | grad norm last: 1.25 | 
2026-01-01T07:58:44 | step: 56500 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.926473800675012e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.8 | consumed tokens: 462848000.0 | grad norm avg: 1.29 | grad norm last: 1.15 | 
2026-01-01T07:59:02 | step: 56600 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.922855466953479e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.91 | consumed tokens: 463667200.0 | grad norm avg: 1.29 | grad norm last: 1.29 | 
2026-01-01T07:59:20 | step: 56700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.919232403859496e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.53 | consumed tokens: 464486400.0 | grad norm avg: 1.28 | grad norm last: 1.28 | 
2026-01-01T07:59:38 | step: 56800 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.915605338988826e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 3.23 | consumed tokens: 465305600.0 | grad norm avg: 1.29 | grad norm last: 1.22 | 
2026-01-01T07:59:56 | step: 56900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.911973544745706e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.16 | consumed tokens: 466124800.0 | grad norm avg: 1.28 | grad norm last: 1.21 | 
2026-01-01T08:00:14 | step: 57000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.908337384928018e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.33 | consumed tokens: 466944000.0 | grad norm avg: 1.29 | grad norm last: 1.28 | 
2026-01-01T08:00:32 | step: 57100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.904697223333642e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.86 | consumed tokens: 467763200.0 | grad norm avg: 1.28 | grad norm last: 1.26 | 
2026-01-01T08:00:50 | step: 57200 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.901052332366817e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.2 | consumed tokens: 468582400.0 | grad norm avg: 1.28 | grad norm last: 1.33 | 
2026-01-01T08:01:08 | step: 57300 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.897403075825423e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.2 | consumed tokens: 469401600.0 | grad norm avg: 1.27 | grad norm last: 1.23 | 
2026-01-01T08:01:26 | step: 57400 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.8937498175073415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.42 | consumed tokens: 470220800.0 | grad norm avg: 1.27 | grad norm last: 1.25 | 
2026-01-01T08:01:44 | step: 57500 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.890091829816811e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 3.12 | consumed tokens: 471040000.0 | grad norm avg: 1.27 | grad norm last: 1.27 | 
2026-01-01T08:02:02 | step: 57600 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.886429840349592e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.84 | consumed tokens: 471859200.0 | grad norm avg: 1.27 | grad norm last: 1.47 | 
2026-01-01T08:02:20 | step: 57700 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 3.882763485307805e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.17 | consumed tokens: 472678400.0 | grad norm avg: 1.28 | grad norm last: 1.34 | 
2026-01-01T08:02:38 | step: 57800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.87909276469145e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.56 | consumed tokens: 473497600.0 | grad norm avg: 1.26 | grad norm last: 1.26 | 
2026-01-01T08:02:56 | step: 57900 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.8754176785005257e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.38 | consumed tokens: 474316800.0 | grad norm avg: 1.28 | grad norm last: 1.33 | 
2026-01-01T08:03:14 | step: 58000 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.871738590532914e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.92 | consumed tokens: 475136000.0 | grad norm avg: 1.3 | grad norm last: 1.27 | 
2026-01-01T08:03:32 | step: 58100 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.8680551369907334e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.64 | consumed tokens: 475955200.0 | grad norm avg: 1.27 | grad norm last: 1.27 | 
2026-01-01T08:03:50 | step: 58200 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.8643673178739846e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.64 | train loss last: 2.89 | consumed tokens: 476774400.0 | grad norm avg: 1.28 | grad norm last: 1.19 | 
2026-01-01T08:04:08 | step: 58300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.860675496980548e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.73 | consumed tokens: 477593600.0 | grad norm avg: 1.28 | grad norm last: 1.38 | 
2026-01-01T08:04:26 | step: 58400 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.856979310512543e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.89 | consumed tokens: 478412800.0 | grad norm avg: 1.28 | grad norm last: 1.46 | 
2026-01-01T08:04:44 | step: 58500 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.85327912226785e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.66 | consumed tokens: 479232000.0 | grad norm avg: 1.28 | grad norm last: 1.24 | 
2026-01-01T08:05:02 | step: 58600 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.849574568448588e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.83 | consumed tokens: 480051200.0 | grad norm avg: 1.27 | grad norm last: 1.42 | 
2026-01-01T08:05:20 | step: 58700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.845865649054758e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.67 | consumed tokens: 480870400.0 | grad norm avg: 1.27 | grad norm last: 1.34 | 
2026-01-01T08:05:38 | step: 58800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.8421527278842404e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.58 | consumed tokens: 481689600.0 | grad norm avg: 1.29 | grad norm last: 1.28 | 
2026-01-01T08:05:56 | step: 58900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.838435804937035e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.59 | consumed tokens: 482508800.0 | grad norm avg: 1.29 | grad norm last: 1.26 | 
2026-01-01T08:06:14 | step: 59000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.834714516415261e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.92 | consumed tokens: 483328000.0 | grad norm avg: 1.28 | grad norm last: 1.17 | 
2026-01-01T08:06:32 | step: 59100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.830989226116799e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.05 | consumed tokens: 484147200.0 | grad norm avg: 1.28 | grad norm last: 1.31 | 
2026-01-01T08:06:50 | step: 59200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.8272595702437684e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.67 | consumed tokens: 484966400.0 | grad norm avg: 1.28 | grad norm last: 1.2 | 
2026-01-01T08:07:08 | step: 59300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.82352591259405e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.31 | consumed tokens: 485785600.0 | grad norm avg: 1.29 | grad norm last: 1.24 | 
2026-01-01T08:07:26 | step: 59400 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 3.819788253167644e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.5 | consumed tokens: 486604800.0 | grad norm avg: 1.3 | grad norm last: 1.41 | 
2026-01-01T08:07:44 | step: 59500 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 3.81604659196455e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.47 | consumed tokens: 487424000.0 | grad norm avg: 1.27 | grad norm last: 1.32 | 
2026-01-01T08:08:02 | step: 59600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.812300565186888e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.53 | consumed tokens: 488243200.0 | grad norm avg: 1.3 | grad norm last: 1.42 | 
2026-01-01T08:08:20 | step: 59700 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.808550536632538e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.78 | consumed tokens: 489062400.0 | grad norm avg: 1.3 | grad norm last: 1.28 | 
2026-01-01T08:08:38 | step: 59800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.8047965063015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 3.2 | consumed tokens: 489881600.0 | grad norm avg: 1.29 | grad norm last: 1.2 | 
2026-01-01T08:08:56 | step: 59900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 3.801038474193774e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.47 | consumed tokens: 490700800.0 | grad norm avg: 1.3 | grad norm last: 1.37 | 
2026-01-01T08:09:14 | step: 60000 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 3.7972764403093606e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.77 | consumed tokens: 491520000.0 | grad norm avg: 1.29 | grad norm last: 1.19 | 
2026-01-01T08:09:33 | step: 60100 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.793510404648259e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 1.86 | consumed tokens: 492339200.0 | grad norm avg: 1.3 | grad norm last: 1.36 | 
2026-01-01T08:09:51 | step: 60200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.78974036721047e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.28 | consumed tokens: 493158400.0 | grad norm avg: 1.27 | grad norm last: 1.43 | 
2026-01-01T08:10:10 | step: 60300 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 3.7859659641981125e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.67 | consumed tokens: 493977600.0 | grad norm avg: 1.3 | grad norm last: 1.29 | 
2026-01-01T08:10:28 | step: 60400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.782187923206948e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.42 | consumed tokens: 494796800.0 | grad norm avg: 1.27 | grad norm last: 1.27 | 
2026-01-01T08:10:46 | step: 60500 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.778405880439095e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.84 | consumed tokens: 495616000.0 | grad norm avg: 1.26 | grad norm last: 1.26 | 
2026-01-01T08:11:04 | step: 60600 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.774619835894555e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.92 | consumed tokens: 496435200.0 | grad norm avg: 1.27 | grad norm last: 1.34 | 
2026-01-01T08:11:22 | step: 60700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.770829789573327e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.38 | consumed tokens: 497254400.0 | grad norm avg: 1.27 | grad norm last: 1.28 | 
2026-01-01T08:11:40 | step: 60800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.7670361052732915e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.61 | consumed tokens: 498073600.0 | grad norm avg: 1.28 | grad norm last: 1.21 | 
2026-01-01T08:11:58 | step: 60900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.763238055398688e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.33 | consumed tokens: 498892800.0 | grad norm avg: 1.28 | grad norm last: 1.22 | 
2026-01-01T08:12:16 | step: 61000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.759436367545277e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.66 | consumed tokens: 499712000.0 | grad norm avg: 1.3 | grad norm last: 1.41 | 
2026-01-01T08:12:34 | step: 61100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.755630677915178e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.44 | consumed tokens: 500531200.0 | grad norm avg: 1.27 | grad norm last: 1.25 | 
2026-01-01T08:12:52 | step: 61200 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.751820986508392e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.23 | consumed tokens: 501350400.0 | grad norm avg: 1.29 | grad norm last: 1.21 | 
2026-01-01T08:13:10 | step: 61300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.748007657122798e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.66 | consumed tokens: 502169600.0 | grad norm avg: 1.28 | grad norm last: 1.36 | 
2026-01-01T08:13:28 | step: 61400 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 3.744190325960517e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 3.06 | consumed tokens: 502988800.0 | grad norm avg: 1.28 | grad norm last: 1.23 | 
2026-01-01T08:13:46 | step: 61500 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.740368993021548e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.58 | consumed tokens: 503808000.0 | grad norm avg: 1.3 | grad norm last: 1.22 | 
2026-01-01T08:14:04 | step: 61600 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 3.7365440221037716e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.64 | consumed tokens: 504627200.0 | grad norm avg: 1.27 | grad norm last: 1.31 | 
2026-01-01T08:14:22 | step: 61700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.7327150494093075e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.42 | consumed tokens: 505446400.0 | grad norm avg: 1.28 | grad norm last: 1.3 | 
2026-01-01T08:14:40 | step: 61800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.7288824387360364e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.48 | consumed tokens: 506265600.0 | grad norm avg: 1.28 | grad norm last: 1.37 | 
2026-01-01T08:14:58 | step: 61900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.7250458262860775e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.61 | consumed tokens: 507084800.0 | grad norm avg: 1.29 | grad norm last: 1.27 | 
2026-01-01T08:15:16 | step: 62000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.7212055758573115e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.08 | consumed tokens: 507904000.0 | grad norm avg: 1.28 | grad norm last: 1.22 | 
2026-01-01T08:15:34 | step: 62100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.7173616874497384e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.47 | consumed tokens: 508723200.0 | grad norm avg: 1.28 | grad norm last: 1.21 | 
2026-01-01T08:15:52 | step: 62200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.7135137972654775e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.03 | consumed tokens: 509542400.0 | grad norm avg: 1.27 | grad norm last: 1.2 | 
2026-01-01T08:16:10 | step: 62300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.709661905304529e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.66 | consumed tokens: 510361600.0 | grad norm avg: 1.28 | grad norm last: 1.36 | 
2026-01-01T08:16:28 | step: 62400 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.705806739162654e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.41 | consumed tokens: 511180800.0 | grad norm avg: 1.27 | grad norm last: 1.28 | 
2026-01-01T08:16:46 | step: 62500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.701947571244091e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.39 | consumed tokens: 512000000.0 | grad norm avg: 1.26 | grad norm last: 1.32 | 
2026-01-01T08:17:04 | step: 62600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.698084765346721e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.7 | consumed tokens: 512819200.0 | grad norm avg: 1.28 | grad norm last: 1.19 | 
2026-01-01T08:17:22 | step: 62700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.694218321470544e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.41 | consumed tokens: 513638400.0 | grad norm avg: 1.27 | grad norm last: 1.41 | 
2026-01-01T08:17:40 | step: 62800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.690347875817679e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.23 | consumed tokens: 514457600.0 | grad norm avg: 1.27 | grad norm last: 1.27 | 
2026-01-01T08:17:58 | step: 62900 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 3.6864741559838876e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.45 | consumed tokens: 515276800.0 | grad norm avg: 1.29 | grad norm last: 1.24 | 
2026-01-01T08:18:16 | step: 63000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.6825964343734086e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 3.7 | consumed tokens: 516096000.0 | grad norm avg: 1.3 | grad norm last: 1.31 | 
2026-01-01T08:18:34 | step: 63100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.6787150747841224e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.97 | consumed tokens: 516915200.0 | grad norm avg: 1.29 | grad norm last: 1.21 | 
2026-01-01T08:18:52 | step: 63200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.674830077216029e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.59 | consumed tokens: 517734400.0 | grad norm avg: 1.28 | grad norm last: 1.3 | 
2026-01-01T08:19:11 | step: 63300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.6709418054670095e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.58 | consumed tokens: 518553600.0 | grad norm avg: 1.28 | grad norm last: 1.31 | 
2026-01-01T08:19:29 | step: 63400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.667049531941302e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.78 | consumed tokens: 519372800.0 | grad norm avg: 1.27 | grad norm last: 1.34 | 
2026-01-01T08:19:47 | step: 63500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.6631536204367876e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.91 | consumed tokens: 520192000.0 | grad norm avg: 1.29 | grad norm last: 1.5 | 
2026-01-01T08:20:05 | step: 63600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.659254070953466e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.72 | consumed tokens: 521011200.0 | grad norm avg: 1.27 | grad norm last: 1.19 | 
2026-01-01T08:20:23 | step: 63700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.655351247289218e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.27 | consumed tokens: 521830400.0 | grad norm avg: 1.27 | grad norm last: 1.36 | 
2026-01-01T08:20:41 | step: 63800 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.651444421848282e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.95 | consumed tokens: 522649600.0 | grad norm avg: 1.28 | grad norm last: 1.31 | 
2026-01-01T08:20:59 | step: 63900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.64753432222642e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.69 | consumed tokens: 523468800.0 | grad norm avg: 1.31 | grad norm last: 1.26 | 
2026-01-01T08:21:17 | step: 64000 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.643620584625751e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.42 | consumed tokens: 524288000.0 | grad norm avg: 1.3 | grad norm last: 1.43 | 
2026-01-01T08:21:35 | step: 64100 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.6397032090462744e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.28 | consumed tokens: 525107200.0 | grad norm avg: 1.3 | grad norm last: 1.24 | 
2026-01-01T08:21:53 | step: 64200 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.635782559285872e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.5 | consumed tokens: 525926400.0 | grad norm avg: 1.29 | grad norm last: 1.33 | 
2026-01-01T08:22:11 | step: 64300 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.631858271546662e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 3.08 | consumed tokens: 526745600.0 | grad norm avg: 1.28 | grad norm last: 1.26 | 
2026-01-01T08:22:29 | step: 64400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.627930345828645e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.77 | consumed tokens: 527564800.0 | grad norm avg: 1.28 | grad norm last: 1.24 | 
2026-01-01T08:22:47 | step: 64500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.6239991459297016e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.39 | consumed tokens: 528384000.0 | grad norm avg: 1.29 | grad norm last: 1.38 | 
2026-01-01T08:23:05 | step: 64600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.620064308051951e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.48 | consumed tokens: 529203200.0 | grad norm avg: 1.29 | grad norm last: 1.19 | 
2026-01-01T08:23:23 | step: 64700 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.616125832195394e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.17 | consumed tokens: 530022400.0 | grad norm avg: 1.3 | grad norm last: 1.15 | 
2026-01-01T08:23:41 | step: 64800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.61218408215791e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.67 | consumed tokens: 530841600.0 | grad norm avg: 1.29 | grad norm last: 1.23 | 
2026-01-01T08:23:59 | step: 64900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.6082390579394996e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 3.23 | consumed tokens: 531660800.0 | grad norm avg: 1.3 | grad norm last: 1.16 | 
2026-01-01T08:24:17 | step: 65000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.604290395742282e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.2 | consumed tokens: 532480000.0 | grad norm avg: 1.32 | grad norm last: 1.28 | 
2026-01-01T08:24:37 | step: 65100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.6003384593641385e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.72 | consumed tokens: 533299200.0 | grad norm avg: 1.3 | grad norm last: 1.16 | 
2026-01-01T08:24:55 | step: 65200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.596382885007188e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.05 | consumed tokens: 534118400.0 | grad norm avg: 1.32 | grad norm last: 1.18 | 
2026-01-01T08:25:13 | step: 65300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.5924240364693105e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.83 | consumed tokens: 534937600.0 | grad norm avg: 1.3 | grad norm last: 1.21 | 
2026-01-01T08:25:31 | step: 65400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.588461913750507e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.2 | consumed tokens: 535756800.0 | grad norm avg: 1.3 | grad norm last: 1.2 | 
2026-01-01T08:25:49 | step: 65500 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 3.584496153052896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.61 | consumed tokens: 536576000.0 | grad norm avg: 1.29 | grad norm last: 1.26 | 
2026-01-01T08:26:07 | step: 65600 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.580527118174359e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.48 | consumed tokens: 537395200.0 | grad norm avg: 1.28 | grad norm last: 1.33 | 
2026-01-01T08:26:25 | step: 65700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.576554809114896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.17 | consumed tokens: 538214400.0 | grad norm avg: 1.3 | grad norm last: 1.34 | 
2026-01-01T08:26:43 | step: 65800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.572579225874506e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.78 | consumed tokens: 539033600.0 | grad norm avg: 1.32 | grad norm last: 1.23 | 
2026-01-01T08:27:01 | step: 65900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.568600004655309e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.33 | consumed tokens: 539852800.0 | grad norm avg: 1.31 | grad norm last: 1.29 | 
2026-01-01T08:27:20 | step: 66000 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.5646178730530664e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 3.06 | consumed tokens: 540672000.0 | grad norm avg: 1.3 | grad norm last: 1.33 | 
2026-01-01T08:27:38 | step: 66100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.560632103472017e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.33 | consumed tokens: 541491200.0 | grad norm avg: 1.3 | grad norm last: 1.27 | 
2026-01-01T08:27:56 | step: 66200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.5566434235079214e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.6 | train loss last: 2.59 | consumed tokens: 542310400.0 | grad norm avg: 1.31 | grad norm last: 1.39 | 
2026-01-01T08:28:14 | step: 66300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.552651105565019e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.28 | consumed tokens: 543129600.0 | grad norm avg: 1.34 | grad norm last: 1.27 | 
2026-01-01T08:28:32 | step: 66400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.548655877239071e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.44 | consumed tokens: 543948800.0 | grad norm avg: 1.3 | grad norm last: 1.29 | 
2026-01-01T08:28:50 | step: 66500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.5446570109343156e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.67 | consumed tokens: 544768000.0 | grad norm avg: 1.32 | grad norm last: 1.35 | 
2026-01-01T08:29:08 | step: 66600 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.540655234246515e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.89 | consumed tokens: 545587200.0 | grad norm avg: 1.3 | grad norm last: 1.32 | 
2026-01-01T08:29:26 | step: 66700 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 3.5366501833777875e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.34 | consumed tokens: 546406400.0 | grad norm avg: 1.3 | grad norm last: 1.33 | 
2026-01-01T08:29:44 | step: 66800 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 3.532641858328134e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.7 | consumed tokens: 547225600.0 | grad norm avg: 1.31 | grad norm last: 1.3 | 
2026-01-01T08:30:02 | step: 66900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.528630259097554e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.3 | consumed tokens: 548044800.0 | grad norm avg: 1.3 | grad norm last: 1.22 | 
2026-01-01T08:30:20 | step: 67000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.5246153856860474e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.44 | consumed tokens: 548864000.0 | grad norm avg: 1.32 | grad norm last: 1.18 | 
2026-01-01T08:30:38 | step: 67100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.520597601891495e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.47 | consumed tokens: 549683200.0 | grad norm avg: 1.31 | grad norm last: 1.35 | 
2026-01-01T08:30:56 | step: 67200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.516576543916017e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.61 | train loss last: 2.89 | consumed tokens: 550502400.0 | grad norm avg: 1.31 | grad norm last: 1.23 | 
2026-01-01T08:31:14 | step: 67300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.512552211759612e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.78 | consumed tokens: 551321600.0 | grad norm avg: 1.31 | grad norm last: 1.21 | 
2026-01-01T08:31:32 | step: 67400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.5085249692201614e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.56 | consumed tokens: 552140800.0 | grad norm avg: 1.33 | grad norm last: 1.42 | 
2026-01-01T08:31:50 | step: 67500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.5044944524997845e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.73 | consumed tokens: 552960000.0 | grad norm avg: 1.32 | grad norm last: 1.28 | 
2026-01-01T08:32:08 | step: 67600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.500460661598481e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.58 | consumed tokens: 553779200.0 | grad norm avg: 1.33 | grad norm last: 1.29 | 
2026-01-01T08:32:26 | step: 67700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.496423960314132e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.27 | consumed tokens: 554598400.0 | grad norm avg: 1.31 | grad norm last: 1.37 | 
2026-01-01T08:32:44 | step: 67800 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.4923843486467376e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.31 | consumed tokens: 555417600.0 | grad norm avg: 1.34 | grad norm last: 1.19 | 
2026-01-01T08:33:02 | step: 67900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.4883414627984166e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.17 | consumed tokens: 556236800.0 | grad norm avg: 1.34 | grad norm last: 1.3 | 
2026-01-01T08:33:20 | step: 68000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.48429566656705e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.73 | consumed tokens: 557056000.0 | grad norm avg: 1.31 | grad norm last: 1.49 | 
2026-01-01T08:33:38 | step: 68100 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 3.480246596154757e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.48 | consumed tokens: 557875200.0 | grad norm avg: 1.32 | grad norm last: 1.41 | 
2026-01-01T08:33:56 | step: 68200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.476194615359418e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.44 | consumed tokens: 558694400.0 | grad norm avg: 1.32 | grad norm last: 1.43 | 
2026-01-01T08:34:14 | step: 68300 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.472139360383153e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.62 | train loss last: 2.75 | consumed tokens: 559513600.0 | grad norm avg: 1.34 | grad norm last: 1.36 | 
2026-01-01T08:34:32 | step: 68400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.468081558821723e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.36 | consumed tokens: 560332800.0 | grad norm avg: 1.32 | grad norm last: 1.37 | 
2026-01-01T08:34:50 | step: 68500 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 3.4640204830793664e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 1.86 | consumed tokens: 561152000.0 | grad norm avg: 1.31 | grad norm last: 1.27 | 
2026-01-01T08:35:08 | step: 68600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.459956496953964e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.62 | consumed tokens: 561971200.0 | grad norm avg: 1.31 | grad norm last: 1.27 | 
2026-01-01T08:35:26 | step: 68700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.455889236647636e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 1.8 | consumed tokens: 562790400.0 | grad norm avg: 1.32 | grad norm last: 1.26 | 
2026-01-01T08:35:45 | step: 68800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.451819429756142e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.12 | consumed tokens: 563609600.0 | grad norm avg: 1.31 | grad norm last: 1.4 | 
2026-01-01T08:36:03 | step: 68900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.447746348683722e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.48 | consumed tokens: 564428800.0 | grad norm avg: 1.32 | grad norm last: 1.22 | 
2026-01-01T08:36:21 | step: 69000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.4436707210261375e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 3.02 | consumed tokens: 565248000.0 | grad norm avg: 1.31 | grad norm last: 1.39 | 
2026-01-01T08:36:39 | step: 69100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.439591819187626e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.44 | consumed tokens: 566067200.0 | grad norm avg: 1.31 | grad norm last: 1.44 | 
2026-01-01T08:36:57 | step: 69200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.4355100069660693e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.44 | consumed tokens: 566886400.0 | grad norm avg: 1.33 | grad norm last: 1.31 | 
2026-01-01T08:37:15 | step: 69300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.4314256481593475e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.47 | consumed tokens: 567705600.0 | grad norm avg: 1.3 | grad norm last: 1.29 | 
2026-01-01T08:37:33 | step: 69400 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 3.427338015171699e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.42 | consumed tokens: 568524800.0 | grad norm avg: 1.31 | grad norm last: 1.28 | 
2026-01-01T08:37:51 | step: 69500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.423247835598886e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.62 | consumed tokens: 569344000.0 | grad norm avg: 1.31 | grad norm last: 1.3 | 
2026-01-01T08:38:09 | step: 69600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.4191543818451464e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.44 | consumed tokens: 570163200.0 | grad norm avg: 1.33 | grad norm last: 1.36 | 
2026-01-01T08:38:27 | step: 69700 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.415058381506242e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.69 | consumed tokens: 570982400.0 | grad norm avg: 1.32 | grad norm last: 1.27 | 
2026-01-01T08:38:45 | step: 69800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.4109594707842916e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.61 | consumed tokens: 571801600.0 | grad norm avg: 1.31 | grad norm last: 1.2 | 
2026-01-01T08:39:03 | step: 69900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.4068580134771764e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.11 | consumed tokens: 572620800.0 | grad norm avg: 1.31 | grad norm last: 1.33 | 
2026-01-01T08:39:21 | step: 70000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.402753281989135e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.34 | consumed tokens: 573440000.0 | grad norm avg: 1.31 | grad norm last: 1.42 | 
2026-01-01T08:39:41 | step: 70100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.398646003915928e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.69 | consumed tokens: 574259200.0 | grad norm avg: 1.31 | grad norm last: 1.2 | 
2026-01-01T08:39:59 | step: 70200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.394535815459676e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.38 | consumed tokens: 575078400.0 | grad norm avg: 1.34 | grad norm last: 1.56 | 
2026-01-01T08:40:17 | step: 70300 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.390423080418259e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.58 | consumed tokens: 575897600.0 | grad norm avg: 1.34 | grad norm last: 1.19 | 
2026-01-01T08:40:35 | step: 70400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.386307434993796e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.0 | consumed tokens: 576716800.0 | grad norm avg: 1.34 | grad norm last: 1.4 | 
2026-01-01T08:40:53 | step: 70500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.3821888791862875e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.62 | consumed tokens: 577536000.0 | grad norm avg: 1.34 | grad norm last: 1.24 | 
2026-01-01T08:41:11 | step: 70600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.378067776793614e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.23 | consumed tokens: 578355200.0 | grad norm avg: 1.34 | grad norm last: 1.42 | 
2026-01-01T08:41:29 | step: 70700 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.3739441278157756e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.31 | consumed tokens: 579174400.0 | grad norm avg: 1.33 | grad norm last: 1.35 | 
2026-01-01T08:41:47 | step: 70800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.3698175684548914e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.41 | consumed tokens: 579993600.0 | grad norm avg: 1.32 | grad norm last: 1.22 | 
2026-01-01T08:42:06 | step: 70900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.3656884625088423e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.83 | consumed tokens: 580812800.0 | grad norm avg: 1.33 | grad norm last: 1.28 | 
2026-01-01T08:42:24 | step: 71000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.3615564461797476e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.73 | consumed tokens: 581632000.0 | grad norm avg: 1.33 | grad norm last: 1.54 | 
2026-01-01T08:42:42 | step: 71100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.357421883265488e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.33 | consumed tokens: 582451200.0 | grad norm avg: 1.31 | grad norm last: 1.39 | 
2026-01-01T08:43:00 | step: 71200 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.3532844099681824e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.73 | consumed tokens: 583270400.0 | grad norm avg: 1.33 | grad norm last: 1.31 | 
2026-01-01T08:43:18 | step: 71300 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.349144753883593e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.28 | consumed tokens: 584089600.0 | grad norm avg: 1.32 | grad norm last: 1.23 | 
2026-01-01T08:43:36 | step: 71400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.3450021874159575e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.41 | consumed tokens: 584908800.0 | grad norm avg: 1.31 | grad norm last: 1.43 | 
2026-01-01T08:43:54 | step: 71500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.340857074363157e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.56 | consumed tokens: 585728000.0 | grad norm avg: 1.32 | grad norm last: 1.23 | 
2026-01-01T08:44:12 | step: 71600 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.336709414725192e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.83 | consumed tokens: 586547200.0 | grad norm avg: 1.33 | grad norm last: 1.35 | 
2026-01-01T08:44:30 | step: 71700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.332558844704181e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.91 | consumed tokens: 587366400.0 | grad norm avg: 1.35 | grad norm last: 1.76 | 
2026-01-01T08:44:48 | step: 71800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.328406091895886e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.45 | consumed tokens: 588185600.0 | grad norm avg: 1.31 | grad norm last: 1.15 | 
2026-01-01T08:45:06 | step: 71900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.3242507925024256e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.81 | consumed tokens: 589004800.0 | grad norm avg: 1.32 | grad norm last: 1.2 | 
2026-01-01T08:45:24 | step: 72000 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 3.32009258272592e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.61 | consumed tokens: 589824000.0 | grad norm avg: 1.34 | grad norm last: 1.45 | 
2026-01-01T08:45:42 | step: 72100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.31593219016213e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.42 | consumed tokens: 590643200.0 | grad norm avg: 1.32 | grad norm last: 1.55 | 
2026-01-01T08:46:01 | step: 72200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.311768887215294e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.45 | consumed tokens: 591462400.0 | grad norm avg: 1.33 | grad norm last: 1.22 | 
2026-01-01T08:46:19 | step: 72300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.307603401481174e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.19 | consumed tokens: 592281600.0 | grad norm avg: 1.32 | grad norm last: 1.37 | 
2026-01-01T08:46:37 | step: 72400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.303435369161889e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 3.05 | consumed tokens: 593100800.0 | grad norm avg: 1.33 | grad norm last: 1.38 | 
2026-01-01T08:46:55 | step: 72500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.299264790257439e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.31 | consumed tokens: 593920000.0 | grad norm avg: 1.33 | grad norm last: 1.32 | 
2026-01-01T08:47:13 | step: 72600 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.295091664767824e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.34 | consumed tokens: 594739200.0 | grad norm avg: 1.33 | grad norm last: 1.32 | 
2026-01-01T08:47:31 | step: 72700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.290915992693044e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.22 | consumed tokens: 595558400.0 | grad norm avg: 1.32 | grad norm last: 1.2 | 
2026-01-01T08:47:49 | step: 72800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.28673813783098e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.84 | consumed tokens: 596377600.0 | grad norm avg: 1.33 | grad norm last: 1.32 | 
2026-01-01T08:48:07 | step: 72900 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.282557736383751e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.59 | train loss last: 2.81 | consumed tokens: 597196800.0 | grad norm avg: 1.33 | grad norm last: 1.28 | 
2026-01-01T08:48:25 | step: 73000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.278374788351357e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.89 | consumed tokens: 598016000.0 | grad norm avg: 1.33 | grad norm last: 1.16 | 
2026-01-01T08:48:43 | step: 73100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.274189657531679e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.19 | consumed tokens: 598835200.0 | grad norm avg: 1.34 | grad norm last: 1.3 | 
2026-01-01T08:49:01 | step: 73200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.2700019801268354e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.02 | consumed tokens: 599654400.0 | grad norm avg: 1.35 | grad norm last: 1.25 | 
2026-01-01T08:49:19 | step: 73300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.265812119934708e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.42 | consumed tokens: 600473600.0 | grad norm avg: 1.33 | grad norm last: 1.21 | 
2026-01-01T08:49:38 | step: 73400 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 3.2616197131574154e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.55 | consumed tokens: 601292800.0 | grad norm avg: 1.35 | grad norm last: 1.32 | 
2026-01-01T08:49:56 | step: 73500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.257424759794958e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 3.06 | consumed tokens: 602112000.0 | grad norm avg: 1.33 | grad norm last: 1.37 | 
2026-01-01T08:50:14 | step: 73600 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.253227623645216e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.38 | consumed tokens: 602931200.0 | grad norm avg: 1.34 | grad norm last: 1.4 | 
2026-01-01T08:50:32 | step: 73700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.24902830470819e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.72 | consumed tokens: 603750400.0 | grad norm avg: 1.32 | grad norm last: 1.34 | 
2026-01-01T08:50:50 | step: 73800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.244826439185999e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.83 | consumed tokens: 604569600.0 | grad norm avg: 1.33 | grad norm last: 1.3 | 
2026-01-01T08:51:08 | step: 73900 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.240622390876524e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.33 | consumed tokens: 605388800.0 | grad norm avg: 1.33 | grad norm last: 1.31 | 
2026-01-01T08:51:26 | step: 74000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.236416159779765e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.33 | consumed tokens: 606208000.0 | grad norm avg: 1.33 | grad norm last: 1.3 | 
2026-01-01T08:51:44 | step: 74100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.23220738209784e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.7 | consumed tokens: 607027200.0 | grad norm avg: 1.33 | grad norm last: 1.38 | 
2026-01-01T08:52:02 | step: 74200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.2279967854265124e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.69 | consumed tokens: 607846400.0 | grad norm avg: 1.34 | grad norm last: 1.33 | 
2026-01-01T08:52:20 | step: 74300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.2237836421700194e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.75 | consumed tokens: 608665600.0 | grad norm avg: 1.35 | grad norm last: 1.26 | 
2026-01-01T08:52:38 | step: 74400 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.2195679523283616e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.97 | consumed tokens: 609484800.0 | grad norm avg: 1.34 | grad norm last: 1.25 | 
2026-01-01T08:52:56 | step: 74500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.2153504434973e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.58 | consumed tokens: 610304000.0 | grad norm avg: 1.34 | grad norm last: 1.29 | 
2026-01-01T08:53:15 | step: 74600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.2111307518789545e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.23 | consumed tokens: 611123200.0 | grad norm avg: 1.33 | grad norm last: 1.38 | 
2026-01-01T08:53:33 | step: 74700 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.206908513675444e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 1.98 | consumed tokens: 611942400.0 | grad norm avg: 1.31 | grad norm last: 1.33 | 
2026-01-01T08:53:51 | step: 74800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.2026844564825296e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.45 | consumed tokens: 612761600.0 | grad norm avg: 1.33 | grad norm last: 1.42 | 
2026-01-01T08:54:09 | step: 74900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.1984578527044505e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.61 | consumed tokens: 613580800.0 | grad norm avg: 1.34 | grad norm last: 1.32 | 
2026-01-01T08:54:27 | step: 75000 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 3.194229429936968e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.44 | consumed tokens: 614400000.0 | grad norm avg: 1.34 | grad norm last: 1.45 | 
2026-01-01T08:54:47 | step: 75100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.189998824382201e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 1.96 | consumed tokens: 615219200.0 | grad norm avg: 1.33 | grad norm last: 1.33 | 
2026-01-01T08:55:05 | step: 75200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.1857660360401496e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.64 | consumed tokens: 616038400.0 | grad norm avg: 1.33 | grad norm last: 1.19 | 
2026-01-01T08:55:23 | step: 75300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.181531064910814e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.67 | consumed tokens: 616857600.0 | grad norm avg: 1.36 | grad norm last: 1.27 | 
2026-01-01T08:55:41 | step: 75400 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.1772939109941944e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.62 | consumed tokens: 617676800.0 | grad norm avg: 1.32 | grad norm last: 1.43 | 
2026-01-01T08:55:59 | step: 75500 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.1730545742902905e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.91 | consumed tokens: 618496000.0 | grad norm avg: 1.35 | grad norm last: 1.36 | 
2026-01-01T08:56:17 | step: 75600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.168813418596983e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.22 | consumed tokens: 619315200.0 | grad norm avg: 1.35 | grad norm last: 1.32 | 
2026-01-01T08:56:35 | step: 75700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.164570080116391e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.66 | consumed tokens: 620134400.0 | grad norm avg: 1.33 | grad norm last: 1.29 | 
2026-01-01T08:56:53 | step: 75800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.160324558848515e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.55 | consumed tokens: 620953600.0 | grad norm avg: 1.33 | grad norm last: 1.31 | 
2026-01-01T08:57:12 | step: 75900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.1560772185912356e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.64 | consumed tokens: 621772800.0 | grad norm avg: 1.33 | grad norm last: 1.51 | 
2026-01-01T08:57:30 | step: 76000 | train samples/s: 95.2 | train mfu (16-bit): -1.0 | lr mean: 3.151827695546672e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.77 | consumed tokens: 622592000.0 | grad norm avg: 1.33 | grad norm last: 1.34 | 
2026-01-01T08:57:48 | step: 76100 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 3.1475763535127044e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.17 | consumed tokens: 623411200.0 | grad norm avg: 1.33 | grad norm last: 1.37 | 
2026-01-01T08:58:06 | step: 76200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.143322828691453e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.58 | train loss last: 2.66 | consumed tokens: 624230400.0 | grad norm avg: 1.33 | grad norm last: 1.42 | 
2026-01-01T08:58:24 | step: 76300 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.1390674848807976e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.52 | consumed tokens: 625049600.0 | grad norm avg: 1.34 | grad norm last: 1.36 | 
2026-01-01T08:58:42 | step: 76400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.134809958282858e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.42 | consumed tokens: 625868800.0 | grad norm avg: 1.31 | grad norm last: 1.34 | 
2026-01-01T08:59:00 | step: 76500 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.130550612695515e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.64 | consumed tokens: 626688000.0 | grad norm avg: 1.35 | grad norm last: 1.32 | 
2026-01-01T08:59:19 | step: 76600 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.126289084320888e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.67 | consumed tokens: 627507200.0 | grad norm avg: 1.33 | grad norm last: 1.37 | 
2026-01-01T08:59:37 | step: 76700 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.122025736956857e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.53 | consumed tokens: 628326400.0 | grad norm avg: 1.34 | grad norm last: 1.18 | 
2026-01-01T08:59:55 | step: 76800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.117760570603423e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.22 | consumed tokens: 629145600.0 | grad norm avg: 1.32 | grad norm last: 1.24 | 
2026-01-01T09:00:13 | step: 76900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.113493585260585e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.73 | consumed tokens: 629964800.0 | grad norm avg: 1.34 | grad norm last: 1.44 | 
2026-01-01T09:00:31 | step: 77000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.109224417130463e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.7 | consumed tokens: 630784000.0 | grad norm avg: 1.35 | grad norm last: 1.23 | 
2026-01-01T09:00:49 | step: 77100 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.104953430010937e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.62 | consumed tokens: 631603200.0 | grad norm avg: 1.33 | grad norm last: 1.38 | 
2026-01-01T09:01:07 | step: 77200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.100680623902008e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.73 | consumed tokens: 632422400.0 | grad norm avg: 1.34 | grad norm last: 1.17 | 
2026-01-01T09:01:25 | step: 77300 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 3.096405998803675e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.73 | consumed tokens: 633241600.0 | grad norm avg: 1.32 | grad norm last: 1.41 | 
2026-01-01T09:01:43 | step: 77400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.092129554715939e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.42 | consumed tokens: 634060800.0 | grad norm avg: 1.34 | grad norm last: 1.27 | 
2026-01-01T09:02:01 | step: 77500 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.087851291638799e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.08 | consumed tokens: 634880000.0 | grad norm avg: 1.32 | grad norm last: 1.42 | 
2026-01-01T09:02:20 | step: 77600 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 3.0835712095722556e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.64 | consumed tokens: 635699200.0 | grad norm avg: 1.32 | grad norm last: 1.21 | 
2026-01-01T09:02:38 | step: 77700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.079289308516309e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.89 | consumed tokens: 636518400.0 | grad norm avg: 1.32 | grad norm last: 1.3 | 
2026-01-01T09:02:56 | step: 77800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.075005588470958e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.7 | consumed tokens: 637337600.0 | grad norm avg: 1.34 | grad norm last: 1.41 | 
2026-01-01T09:03:14 | step: 77900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.070720049436204e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.48 | consumed tokens: 638156800.0 | grad norm avg: 1.34 | grad norm last: 1.21 | 
2026-01-01T09:03:32 | step: 78000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.0664326914120466e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.25 | consumed tokens: 638976000.0 | grad norm avg: 1.35 | grad norm last: 1.36 | 
2026-01-01T09:03:50 | step: 78100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.062143878196366e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.25 | consumed tokens: 639795200.0 | grad norm avg: 1.33 | grad norm last: 1.28 | 
2026-01-01T09:04:08 | step: 78200 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.0578528821934015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.33 | consumed tokens: 640614400.0 | grad norm avg: 1.33 | grad norm last: 1.31 | 
2026-01-01T09:04:26 | step: 78300 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 3.053560430998914e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 3.72 | consumed tokens: 641433600.0 | grad norm avg: 1.34 | grad norm last: 1.31 | 
2026-01-01T09:04:44 | step: 78400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.049266160815023e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.39 | consumed tokens: 642252800.0 | grad norm avg: 1.34 | grad norm last: 1.26 | 
2026-01-01T09:05:02 | step: 78500 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.0449702535406686e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.45 | consumed tokens: 643072000.0 | grad norm avg: 1.33 | grad norm last: 1.42 | 
2026-01-01T09:05:21 | step: 78600 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 3.0406727091758512e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.5 | consumed tokens: 643891200.0 | grad norm avg: 1.33 | grad norm last: 1.37 | 
2026-01-01T09:05:39 | step: 78700 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.0363735277205706e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.8 | consumed tokens: 644710400.0 | grad norm avg: 1.37 | grad norm last: 1.25 | 
2026-01-01T09:05:57 | step: 78800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.0320725272758864e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.67 | consumed tokens: 645529600.0 | grad norm avg: 1.36 | grad norm last: 1.42 | 
2026-01-01T09:06:15 | step: 78900 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.027769889740739e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.38 | consumed tokens: 646348800.0 | grad norm avg: 1.38 | grad norm last: 1.29 | 
2026-01-01T09:06:33 | step: 79000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.0234657970140688e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.33 | consumed tokens: 647168000.0 | grad norm avg: 1.35 | grad norm last: 1.35 | 
2026-01-01T09:06:51 | step: 79100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.019159885297995e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.67 | consumed tokens: 647987200.0 | grad norm avg: 1.35 | grad norm last: 1.37 | 
2026-01-01T09:07:09 | step: 79200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.0148525183903985e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.47 | consumed tokens: 648806400.0 | grad norm avg: 1.35 | grad norm last: 1.38 | 
2026-01-01T09:07:27 | step: 79300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.0105435143923387e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.48 | consumed tokens: 649625600.0 | grad norm avg: 1.34 | grad norm last: 1.45 | 
2026-01-01T09:07:46 | step: 79400 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.0062328733038157e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.33 | consumed tokens: 650444800.0 | grad norm avg: 1.37 | grad norm last: 1.28 | 
2026-01-01T09:08:04 | step: 79500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.00192077702377e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.61 | consumed tokens: 651264000.0 | grad norm avg: 1.32 | grad norm last: 1.37 | 
2026-01-01T09:08:22 | step: 79600 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 2.997607043653261e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.36 | consumed tokens: 652083200.0 | grad norm avg: 1.33 | grad norm last: 1.48 | 
2026-01-01T09:08:40 | step: 79700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.993291855091229e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.38 | consumed tokens: 652902400.0 | grad norm avg: 1.35 | grad norm last: 1.37 | 
2026-01-01T09:08:58 | step: 79800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.988975029438734e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.98 | consumed tokens: 653721600.0 | grad norm avg: 1.37 | grad norm last: 1.36 | 
2026-01-01T09:09:16 | step: 79900 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 2.9846567485947162e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.97 | consumed tokens: 654540800.0 | grad norm avg: 1.35 | grad norm last: 1.36 | 
2026-01-01T09:09:34 | step: 80000 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.9803370125591755e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.38 | consumed tokens: 655360000.0 | grad norm avg: 1.34 | grad norm last: 1.37 | 
2026-01-01T09:09:54 | step: 80100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.976015821332112e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.39 | consumed tokens: 656179200.0 | grad norm avg: 1.36 | grad norm last: 1.52 | 
2026-01-01T09:10:12 | step: 80200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.9716929930145852e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.28 | consumed tokens: 656998400.0 | grad norm avg: 1.37 | grad norm last: 1.29 | 
2026-01-01T09:10:30 | step: 80300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.967368891404476e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.55 | consumed tokens: 657817600.0 | grad norm avg: 1.32 | grad norm last: 1.24 | 
2026-01-01T09:10:48 | step: 80400 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 2.9630431527039036e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 1.92 | consumed tokens: 658636800.0 | grad norm avg: 1.33 | grad norm last: 1.2 | 
2026-01-01T09:11:06 | step: 80500 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.9587161407107487e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.5 | consumed tokens: 659456000.0 | grad norm avg: 1.35 | grad norm last: 1.3 | 
2026-01-01T09:11:24 | step: 80600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.954387673526071e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.05 | consumed tokens: 660275200.0 | grad norm avg: 1.34 | grad norm last: 1.3 | 
2026-01-01T09:11:43 | step: 80700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.9500577511498705e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.66 | consumed tokens: 661094400.0 | grad norm avg: 1.34 | grad norm last: 1.25 | 
2026-01-01T09:12:01 | step: 80800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.945726373582147e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.31 | consumed tokens: 661913600.0 | grad norm avg: 1.36 | grad norm last: 1.56 | 
2026-01-01T09:12:19 | step: 80900 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.9413937227218412e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.66 | consumed tokens: 662732800.0 | grad norm avg: 1.36 | grad norm last: 1.33 | 
2026-01-01T09:12:37 | step: 81000 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 2.9370597985689528e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.58 | consumed tokens: 663552000.0 | grad norm avg: 1.35 | grad norm last: 1.37 | 
2026-01-01T09:12:55 | step: 81100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.9327244192245416e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.83 | consumed tokens: 664371200.0 | grad norm avg: 1.35 | grad norm last: 1.5 | 
2026-01-01T09:13:13 | step: 81200 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 2.928387766587548e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 3.08 | consumed tokens: 665190400.0 | grad norm avg: 1.37 | grad norm last: 1.36 | 
2026-01-01T09:13:31 | step: 81300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.9240496587590314e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.38 | consumed tokens: 666009600.0 | grad norm avg: 1.35 | grad norm last: 1.34 | 
2026-01-01T09:13:50 | step: 81400 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.9197102776379324e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.39 | consumed tokens: 666828800.0 | grad norm avg: 1.35 | grad norm last: 1.28 | 
2026-01-01T09:14:08 | step: 81500 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 2.9153698051231913e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.75 | consumed tokens: 667648000.0 | grad norm avg: 1.36 | grad norm last: 1.43 | 
2026-01-01T09:14:26 | step: 81600 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.9110278774169274e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.78 | consumed tokens: 668467200.0 | grad norm avg: 1.36 | grad norm last: 1.45 | 
2026-01-01T09:14:44 | step: 81700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 2.906684676418081e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.25 | consumed tokens: 669286400.0 | grad norm avg: 1.34 | grad norm last: 1.28 | 
2026-01-01T09:15:02 | step: 81800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.902340202126652e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.97 | consumed tokens: 670105600.0 | grad norm avg: 1.35 | grad norm last: 1.48 | 
2026-01-01T09:15:20 | step: 81900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.8979944545426406e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.56 | consumed tokens: 670924800.0 | grad norm avg: 1.37 | grad norm last: 1.36 | 
2026-01-01T09:15:38 | step: 82000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.893647615564987e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.31 | consumed tokens: 671744000.0 | grad norm avg: 1.36 | grad norm last: 1.4 | 
2026-01-01T09:15:56 | step: 82100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.889299503294751e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.77 | consumed tokens: 672563200.0 | grad norm avg: 1.36 | grad norm last: 1.28 | 
2026-01-01T09:16:15 | step: 82200 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 2.8849501177319326e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.38 | consumed tokens: 673382400.0 | grad norm avg: 1.35 | grad norm last: 1.35 | 
2026-01-01T09:16:33 | step: 82300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.880599640775472e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.7 | consumed tokens: 674201600.0 | grad norm avg: 1.35 | grad norm last: 1.38 | 
2026-01-01T09:16:51 | step: 82400 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.8762478905264288e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.69 | consumed tokens: 675020800.0 | grad norm avg: 1.35 | grad norm last: 1.3 | 
2026-01-01T09:17:09 | step: 82500 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 2.8718950488837436e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.53 | consumed tokens: 675840000.0 | grad norm avg: 1.35 | grad norm last: 1.46 | 
2026-01-01T09:17:27 | step: 82600 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.8675411158474162e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.58 | consumed tokens: 676659200.0 | grad norm avg: 1.36 | grad norm last: 1.27 | 
2026-01-01T09:17:45 | step: 82700 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.8631859095185064e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.69 | consumed tokens: 677478400.0 | grad norm avg: 1.36 | grad norm last: 1.34 | 
2026-01-01T09:18:03 | step: 82800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.8588297936948948e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.27 | consumed tokens: 678297600.0 | grad norm avg: 1.37 | grad norm last: 1.57 | 
2026-01-01T09:18:21 | step: 82900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.8544724045787007e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.75 | consumed tokens: 679116800.0 | grad norm avg: 1.36 | grad norm last: 1.36 | 
2026-01-01T09:18:40 | step: 83000 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.8501139240688644e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.44 | consumed tokens: 679936000.0 | grad norm avg: 1.35 | grad norm last: 1.27 | 
2026-01-01T09:18:58 | step: 83100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.845754352165386e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.97 | consumed tokens: 680755200.0 | grad norm avg: 1.34 | grad norm last: 1.37 | 
2026-01-01T09:19:16 | step: 83200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.8413936888682656e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.55 | consumed tokens: 681574400.0 | grad norm avg: 1.35 | grad norm last: 1.27 | 
2026-01-01T09:19:34 | step: 83300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.8370321160764433e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 2.31 | consumed tokens: 682393600.0 | grad norm avg: 1.37 | grad norm last: 1.38 | 
2026-01-01T09:19:52 | step: 83400 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.832669451890979e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.34 | consumed tokens: 683212800.0 | grad norm avg: 1.36 | grad norm last: 1.22 | 
2026-01-01T09:20:10 | step: 83500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.8283056963118725e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.61 | consumed tokens: 684032000.0 | grad norm avg: 1.36 | grad norm last: 1.45 | 
2026-01-01T09:20:28 | step: 83600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.8239410312380642e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.52 | consumed tokens: 684851200.0 | grad norm avg: 1.36 | grad norm last: 1.48 | 
2026-01-01T09:20:46 | step: 83700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.8195752747706138e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.55 | consumed tokens: 685670400.0 | grad norm avg: 1.36 | grad norm last: 1.39 | 
2026-01-01T09:21:04 | step: 83800 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.8152086088084616e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.45 | consumed tokens: 686489600.0 | grad norm avg: 1.35 | grad norm last: 1.5 | 
2026-01-01T09:21:22 | step: 83900 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.8108408514526673e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.67 | consumed tokens: 687308800.0 | grad norm avg: 1.36 | grad norm last: 1.36 | 
2026-01-01T09:21:41 | step: 84000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.8064721846021712e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.69 | consumed tokens: 688128000.0 | grad norm avg: 1.35 | grad norm last: 1.35 | 
2026-01-01T09:21:59 | step: 84100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 2.8021026082569733e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 1.98 | consumed tokens: 688947200.0 | grad norm avg: 1.37 | grad norm last: 1.33 | 
2026-01-01T09:22:17 | step: 84200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.7977321224170737e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.3 | consumed tokens: 689766400.0 | grad norm avg: 1.35 | grad norm last: 1.33 | 
2026-01-01T09:22:35 | step: 84300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.7933607270824723e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.27 | consumed tokens: 690585600.0 | grad norm avg: 1.36 | grad norm last: 1.26 | 
2026-01-01T09:22:53 | step: 84400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.788988422253169e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.56 | consumed tokens: 691404800.0 | grad norm avg: 1.35 | grad norm last: 1.34 | 
2026-01-01T09:23:11 | step: 84500 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.7846150260302238e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.78 | consumed tokens: 692224000.0 | grad norm avg: 1.34 | grad norm last: 1.27 | 
2026-01-01T09:23:29 | step: 84600 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.7802410841104575e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.39 | consumed tokens: 693043200.0 | grad norm avg: 1.36 | grad norm last: 1.35 | 
2026-01-01T09:23:47 | step: 84700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.775866050797049e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.78 | consumed tokens: 693862400.0 | grad norm avg: 1.36 | grad norm last: 1.39 | 
2026-01-01T09:24:05 | step: 84800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.771490289887879e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 3.33 | consumed tokens: 694681600.0 | grad norm avg: 1.36 | grad norm last: 1.3 | 
2026-01-01T09:24:23 | step: 84900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.7671136194840074e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.8 | consumed tokens: 695500800.0 | grad norm avg: 1.36 | grad norm last: 1.34 | 
2026-01-01T09:24:41 | step: 85000 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.762736039585434e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.05 | consumed tokens: 696320000.0 | grad norm avg: 1.38 | grad norm last: 1.23 | 
2026-01-01T09:25:01 | step: 85100 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 2.7583579139900394e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.7 | consumed tokens: 697139200.0 | grad norm avg: 1.35 | grad norm last: 1.35 | 
2026-01-01T09:25:19 | step: 85200 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 2.7539786970010027e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.53 | consumed tokens: 697958400.0 | grad norm avg: 1.34 | grad norm last: 1.54 | 
2026-01-01T09:25:37 | step: 85300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.749598934315145e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.5 | consumed tokens: 698777600.0 | grad norm avg: 1.35 | grad norm last: 1.4 | 
2026-01-01T09:25:55 | step: 85400 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.7452182621345855e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.53 | consumed tokens: 699596800.0 | grad norm avg: 1.36 | grad norm last: 1.65 | 
2026-01-01T09:26:13 | step: 85500 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.7408368623582646e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.86 | consumed tokens: 700416000.0 | grad norm avg: 1.36 | grad norm last: 1.54 | 
2026-01-01T09:26:32 | step: 85600 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 2.7364547349861823e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.16 | consumed tokens: 701235200.0 | grad norm avg: 1.35 | grad norm last: 1.39 | 
2026-01-01T09:26:50 | step: 85700 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.7320718800183386e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 3.12 | consumed tokens: 702054400.0 | grad norm avg: 1.38 | grad norm last: 1.37 | 
2026-01-01T09:27:08 | step: 85800 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.7276882974547334e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.59 | consumed tokens: 702873600.0 | grad norm avg: 1.37 | grad norm last: 1.36 | 
2026-01-01T09:27:26 | step: 85900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.7233041691943072e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.69 | consumed tokens: 703692800.0 | grad norm avg: 1.38 | grad norm last: 1.6 | 
2026-01-01T09:27:44 | step: 86000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.7189191314391792e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.73 | consumed tokens: 704512000.0 | grad norm avg: 1.36 | grad norm last: 1.45 | 
2026-01-01T09:28:02 | step: 86100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.71453354798723e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.55 | consumed tokens: 705331200.0 | grad norm avg: 1.35 | grad norm last: 1.41 | 
2026-01-01T09:28:20 | step: 86200 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.7101472369395196e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.48 | consumed tokens: 706150400.0 | grad norm avg: 1.37 | grad norm last: 1.34 | 
2026-01-01T09:28:38 | step: 86300 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 2.705760380194988e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.58 | consumed tokens: 706969600.0 | grad norm avg: 1.38 | grad norm last: 1.55 | 
2026-01-01T09:28:57 | step: 86400 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 2.701372795854695e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.5 | consumed tokens: 707788800.0 | grad norm avg: 1.38 | grad norm last: 1.32 | 
2026-01-01T09:29:15 | step: 86500 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.696984665817581e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.89 | consumed tokens: 708608000.0 | grad norm avg: 1.34 | grad norm last: 1.2 | 
2026-01-01T09:29:33 | step: 86600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.6925958081847057e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.75 | consumed tokens: 709427200.0 | grad norm avg: 1.38 | grad norm last: 1.39 | 
2026-01-01T09:29:51 | step: 86700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 2.6882065867539495e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.31 | consumed tokens: 710246400.0 | grad norm avg: 1.36 | grad norm last: 1.26 | 
2026-01-01T09:30:09 | step: 86800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.683816637727432e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.31 | consumed tokens: 711065600.0 | grad norm avg: 1.36 | grad norm last: 1.32 | 
2026-01-01T09:30:27 | step: 86900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.6794261430040933e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.61 | consumed tokens: 711884800.0 | grad norm avg: 1.36 | grad norm last: 1.33 | 
2026-01-01T09:30:45 | step: 87000 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.6750349206849933e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.64 | consumed tokens: 712704000.0 | grad norm avg: 1.36 | grad norm last: 1.3 | 
2026-01-01T09:31:03 | step: 87100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.6706433345680125e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.72 | consumed tokens: 713523200.0 | grad norm avg: 1.36 | grad norm last: 1.33 | 
2026-01-01T09:31:21 | step: 87200 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.666251384653151e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.47 | consumed tokens: 714342400.0 | grad norm avg: 1.36 | grad norm last: 1.25 | 
2026-01-01T09:31:39 | step: 87300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.661858707142528e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.52 | consumed tokens: 715161600.0 | grad norm avg: 1.35 | grad norm last: 1.41 | 
2026-01-01T09:31:58 | step: 87400 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.6574654839350842e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.72 | consumed tokens: 715980800.0 | grad norm avg: 1.37 | grad norm last: 1.38 | 
2026-01-01T09:32:16 | step: 87500 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 2.6530718969297595e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.53 | consumed tokens: 716800000.0 | grad norm avg: 1.39 | grad norm last: 1.5 | 
2026-01-01T09:32:34 | step: 87600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.648677946126554e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 3.12 | consumed tokens: 717619200.0 | grad norm avg: 1.36 | grad norm last: 1.39 | 
2026-01-01T09:32:52 | step: 87700 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.6442834496265277e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.67 | consumed tokens: 718438400.0 | grad norm avg: 1.37 | grad norm last: 1.22 | 
2026-01-01T09:33:10 | step: 87800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.6398884074296802e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.42 | consumed tokens: 719257600.0 | grad norm avg: 1.38 | grad norm last: 1.49 | 
2026-01-01T09:33:28 | step: 87900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.635493001434952e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.08 | consumed tokens: 720076800.0 | grad norm avg: 1.38 | grad norm last: 1.44 | 
2026-01-01T09:33:46 | step: 88000 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.631097231642343e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.48 | consumed tokens: 720896000.0 | grad norm avg: 1.37 | grad norm last: 1.37 | 
2026-01-01T09:34:04 | step: 88100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.6267010980518535e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.53 | consumed tokens: 721715200.0 | grad norm avg: 1.38 | grad norm last: 1.31 | 
2026-01-01T09:34:22 | step: 88200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.6223044187645428e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.33 | consumed tokens: 722534400.0 | grad norm avg: 1.38 | grad norm last: 1.44 | 
2026-01-01T09:34:41 | step: 88300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.6179075575782917e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.83 | consumed tokens: 723353600.0 | grad norm avg: 1.37 | grad norm last: 1.49 | 
2026-01-01T09:34:59 | step: 88400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.6135101506952196e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.56 | train loss last: 2.47 | consumed tokens: 724172800.0 | grad norm avg: 1.35 | grad norm last: 1.32 | 
2026-01-01T09:35:17 | step: 88500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 2.6091125619132072e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.05 | consumed tokens: 724992000.0 | grad norm avg: 1.37 | grad norm last: 1.42 | 
2026-01-01T09:35:35 | step: 88600 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.604714609333314e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.91 | consumed tokens: 725811200.0 | grad norm avg: 1.36 | grad norm last: 1.54 | 
2026-01-01T09:35:53 | step: 88700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.60031629295554e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.45 | consumed tokens: 726630400.0 | grad norm avg: 1.41 | grad norm last: 1.45 | 
2026-01-01T09:36:11 | step: 88800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.5959176127798855e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.16 | consumed tokens: 727449600.0 | grad norm avg: 1.37 | grad norm last: 1.38 | 
2026-01-01T09:36:29 | step: 88900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.5915187507052906e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.36 | consumed tokens: 728268800.0 | grad norm avg: 1.36 | grad norm last: 1.49 | 
2026-01-01T09:36:47 | step: 89000 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 2.587119524832815e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.73 | consumed tokens: 729088000.0 | grad norm avg: 1.4 | grad norm last: 1.31 | 
2026-01-01T09:37:06 | step: 89100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.582720117061399e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.98 | consumed tokens: 729907200.0 | grad norm avg: 1.37 | grad norm last: 1.31 | 
2026-01-01T09:37:24 | step: 89200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.5783203454921022e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.25 | consumed tokens: 730726400.0 | grad norm avg: 1.37 | grad norm last: 1.21 | 
2026-01-01T09:37:42 | step: 89300 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 2.573920392023865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.55 | consumed tokens: 731545600.0 | grad norm avg: 1.38 | grad norm last: 1.45 | 
2026-01-01T09:38:00 | step: 89400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.5695202566566877e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.22 | consumed tokens: 732364800.0 | grad norm avg: 1.36 | grad norm last: 1.27 | 
2026-01-01T09:38:18 | step: 89500 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.56511993939057e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.28 | consumed tokens: 733184000.0 | grad norm avg: 1.38 | grad norm last: 1.3 | 
2026-01-01T09:38:36 | step: 89600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.5607194402255118e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 3.03 | consumed tokens: 734003200.0 | grad norm avg: 1.36 | grad norm last: 1.27 | 
2026-01-01T09:38:54 | step: 89700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.5563187591615133e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.45 | consumed tokens: 734822400.0 | grad norm avg: 1.37 | grad norm last: 1.39 | 
2026-01-01T09:39:12 | step: 89800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.551917714299634e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 1.84 | consumed tokens: 735641600.0 | grad norm avg: 1.38 | grad norm last: 1.36 | 
2026-01-01T09:39:30 | step: 89900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.547516669437755e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.56 | consumed tokens: 736460800.0 | grad norm avg: 1.38 | grad norm last: 1.31 | 
2026-01-01T09:39:48 | step: 90000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.5431154426769353e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.0 | consumed tokens: 737280000.0 | grad norm avg: 1.35 | grad norm last: 1.31 | 
2026-01-01T09:40:08 | step: 90100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.5387142159161158e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.45 | consumed tokens: 738099200.0 | grad norm avg: 1.37 | grad norm last: 1.33 | 
2026-01-01T09:40:26 | step: 90200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.534312807256356e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.69 | consumed tokens: 738918400.0 | grad norm avg: 1.34 | grad norm last: 1.3 | 
2026-01-01T09:40:44 | step: 90300 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 2.5299112166976556e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 3.12 | consumed tokens: 739737600.0 | grad norm avg: 1.36 | grad norm last: 1.28 | 
2026-01-01T09:41:02 | step: 90400 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 2.5255096261389554e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.64 | consumed tokens: 740556800.0 | grad norm avg: 1.34 | grad norm last: 1.32 | 
2026-01-01T09:41:21 | step: 90500 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.521108035580255e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.5 | consumed tokens: 741376000.0 | grad norm avg: 1.36 | grad norm last: 1.39 | 
2026-01-01T09:41:39 | step: 90600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.5167062631226145e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 1.65 | consumed tokens: 742195200.0 | grad norm avg: 1.35 | grad norm last: 1.29 | 
2026-01-01T09:41:57 | step: 90700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.512304490664974e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.52 | consumed tokens: 743014400.0 | grad norm avg: 1.36 | grad norm last: 1.38 | 
2026-01-01T09:42:15 | step: 90800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.507902536308393e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.53 | consumed tokens: 743833600.0 | grad norm avg: 1.38 | grad norm last: 1.53 | 
2026-01-01T09:42:33 | step: 90900 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 2.5035007638507523e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.41 | consumed tokens: 744652800.0 | grad norm avg: 1.36 | grad norm last: 1.31 | 
2026-01-01T09:42:51 | step: 91000 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.4990989913931116e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.19 | consumed tokens: 745472000.0 | grad norm avg: 1.38 | grad norm last: 1.61 | 
2026-01-01T09:43:09 | step: 91100 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.4946970370365307e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.55 | consumed tokens: 746291200.0 | grad norm avg: 1.36 | grad norm last: 1.37 | 
2026-01-01T09:43:28 | step: 91200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.49029526457889e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.75 | consumed tokens: 747110400.0 | grad norm avg: 1.36 | grad norm last: 1.36 | 
2026-01-01T09:43:46 | step: 91300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.4858934921212494e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.03 | consumed tokens: 747929600.0 | grad norm avg: 1.38 | grad norm last: 1.43 | 
2026-01-01T09:44:04 | step: 91400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 2.4814917196636088e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.95 | consumed tokens: 748748800.0 | grad norm avg: 1.38 | grad norm last: 1.47 | 
2026-01-01T09:44:22 | step: 91500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.4770901291049086e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.61 | consumed tokens: 749568000.0 | grad norm avg: 1.38 | grad norm last: 1.48 | 
2026-01-01T09:44:40 | step: 91600 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.4726885385462083e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 3.17 | consumed tokens: 750387200.0 | grad norm avg: 1.37 | grad norm last: 1.4 | 
2026-01-01T09:44:58 | step: 91700 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 2.4682871298864484e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.09 | consumed tokens: 751206400.0 | grad norm avg: 1.35 | grad norm last: 1.27 | 
2026-01-01T09:45:16 | step: 91800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.4638857212266885e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.56 | consumed tokens: 752025600.0 | grad norm avg: 1.37 | grad norm last: 1.29 | 
2026-01-01T09:45:34 | step: 91900 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 2.459484494465869e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.33 | consumed tokens: 752844800.0 | grad norm avg: 1.37 | grad norm last: 1.34 | 
2026-01-01T09:45:52 | step: 92000 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.4550834496039897e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 1.91 | consumed tokens: 753664000.0 | grad norm avg: 1.38 | grad norm last: 1.29 | 
2026-01-01T09:46:11 | step: 92100 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 2.4506824047421105e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.52 | consumed tokens: 754483200.0 | grad norm avg: 1.36 | grad norm last: 1.27 | 
2026-01-01T09:46:29 | step: 92200 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 2.4462815417791717e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.58 | consumed tokens: 755302400.0 | grad norm avg: 1.4 | grad norm last: 1.41 | 
2026-01-01T09:46:47 | step: 92300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.4418808607151732e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 3.16 | consumed tokens: 756121600.0 | grad norm avg: 1.37 | grad norm last: 1.46 | 
2026-01-01T09:47:05 | step: 92400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.4374805434490554e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.33 | consumed tokens: 756940800.0 | grad norm avg: 1.38 | grad norm last: 1.26 | 
2026-01-01T09:47:23 | step: 92500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.4330802261829376e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 3.02 | consumed tokens: 757760000.0 | grad norm avg: 1.38 | grad norm last: 1.47 | 
2026-01-01T09:47:41 | step: 92600 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 2.4286802727147005e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.58 | consumed tokens: 758579200.0 | grad norm avg: 1.37 | grad norm last: 1.35 | 
2026-01-01T09:47:59 | step: 92700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.424280501145404e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.28 | consumed tokens: 759398400.0 | grad norm avg: 1.37 | grad norm last: 1.32 | 
2026-01-01T09:48:18 | step: 92800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.4198809114750475e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.69 | consumed tokens: 760217600.0 | grad norm avg: 1.38 | grad norm last: 1.43 | 
2026-01-01T09:48:36 | step: 92900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.4154815037036315e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.16 | consumed tokens: 761036800.0 | grad norm avg: 1.37 | grad norm last: 1.31 | 
2026-01-01T09:48:54 | step: 93000 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 2.411082459730096e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.53 | consumed tokens: 761856000.0 | grad norm avg: 1.35 | grad norm last: 1.4 | 
2026-01-01T09:49:12 | step: 93100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.4066837795544416e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.5 | consumed tokens: 762675200.0 | grad norm avg: 1.37 | grad norm last: 1.36 | 
2026-01-01T09:49:30 | step: 93200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.4022852812777273e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.89 | consumed tokens: 763494400.0 | grad norm avg: 1.37 | grad norm last: 1.36 | 
2026-01-01T09:49:48 | step: 93300 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 2.3978871467988938e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 3.17 | consumed tokens: 764313600.0 | grad norm avg: 1.38 | grad norm last: 1.36 | 
2026-01-01T09:50:06 | step: 93400 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.393489376117941e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.52 | consumed tokens: 765132800.0 | grad norm avg: 1.37 | grad norm last: 1.46 | 
2026-01-01T09:50:25 | step: 93500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.389091969234869e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.25 | consumed tokens: 765952000.0 | grad norm avg: 1.38 | grad norm last: 1.4 | 
2026-01-01T09:50:43 | step: 93600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.384694744250737e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 1.59 | consumed tokens: 766771200.0 | grad norm avg: 1.38 | grad norm last: 1.43 | 
2026-01-01T09:51:01 | step: 93700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.3802980649634264e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.67 | consumed tokens: 767590400.0 | grad norm avg: 1.4 | grad norm last: 1.34 | 
2026-01-01T09:51:19 | step: 93800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.3759017494739965e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.23 | consumed tokens: 768409600.0 | grad norm avg: 1.38 | grad norm last: 1.38 | 
2026-01-01T09:51:37 | step: 93900 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 2.371505615883507e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 3.03 | consumed tokens: 769228800.0 | grad norm avg: 1.4 | grad norm last: 1.49 | 
2026-01-01T09:51:55 | step: 94000 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.3671100279898383e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.57 | train loss last: 3.08 | consumed tokens: 770048000.0 | grad norm avg: 1.4 | grad norm last: 1.33 | 
2026-01-01T09:52:13 | step: 94100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.3627149857929908e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.53 | consumed tokens: 770867200.0 | grad norm avg: 1.37 | grad norm last: 1.42 | 
2026-01-01T09:52:31 | step: 94200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.358320307394024e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.03 | consumed tokens: 771686400.0 | grad norm avg: 1.39 | grad norm last: 1.26 | 
2026-01-01T09:52:50 | step: 94300 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 2.353925992792938e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 1.83 | consumed tokens: 772505600.0 | grad norm avg: 1.38 | grad norm last: 1.38 | 
2026-01-01T09:53:08 | step: 94400 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.349532223888673e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.19 | consumed tokens: 773324800.0 | grad norm avg: 1.38 | grad norm last: 1.45 | 
2026-01-01T09:53:26 | step: 94500 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 2.3451388187822886e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.05 | consumed tokens: 774144000.0 | grad norm avg: 1.4 | grad norm last: 1.37 | 
2026-01-01T09:53:44 | step: 94600 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.3407459593727253e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.77 | consumed tokens: 774963200.0 | grad norm avg: 1.39 | grad norm last: 1.37 | 
2026-01-01T09:54:02 | step: 94700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.336353645659983e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.19 | consumed tokens: 775782400.0 | grad norm avg: 1.39 | grad norm last: 1.44 | 
2026-01-01T09:54:20 | step: 94800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.331961877644062e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.53 | consumed tokens: 776601600.0 | grad norm avg: 1.38 | grad norm last: 1.27 | 
2026-01-01T09:54:39 | step: 94900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.3275704734260216e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.34 | consumed tokens: 777420800.0 | grad norm avg: 1.39 | grad norm last: 1.26 | 
2026-01-01T09:54:57 | step: 95000 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.3231797968037426e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.98 | consumed tokens: 778240000.0 | grad norm avg: 1.38 | grad norm last: 1.37 | 
2026-01-01T09:55:16 | step: 95100 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.3187894839793444e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 3.11 | consumed tokens: 779059200.0 | grad norm avg: 1.37 | grad norm last: 1.46 | 
2026-01-01T09:55:35 | step: 95200 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 2.3143998987507075e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.67 | consumed tokens: 779878400.0 | grad norm avg: 1.38 | grad norm last: 1.46 | 
2026-01-01T09:55:53 | step: 95300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.3100108592188917e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.25 | consumed tokens: 780697600.0 | grad norm avg: 1.37 | grad norm last: 1.51 | 
2026-01-01T09:56:11 | step: 95400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.305622365383897e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.41 | consumed tokens: 781516800.0 | grad norm avg: 1.39 | grad norm last: 1.47 | 
2026-01-01T09:56:29 | step: 95500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.3012345991446637e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.67 | consumed tokens: 782336000.0 | grad norm avg: 1.39 | grad norm last: 1.51 | 
2026-01-01T09:56:47 | step: 95600 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 2.2968473786022514e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.38 | consumed tokens: 783155200.0 | grad norm avg: 1.39 | grad norm last: 1.27 | 
2026-01-01T09:57:05 | step: 95700 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 2.2924608856556006e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.73 | consumed tokens: 783974400.0 | grad norm avg: 1.38 | grad norm last: 1.47 | 
2026-01-01T09:57:23 | step: 95800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.2880749384057708e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.11 | consumed tokens: 784793600.0 | grad norm avg: 1.38 | grad norm last: 1.4 | 
2026-01-01T09:57:42 | step: 95900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.2836897187517025e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 2.75 | consumed tokens: 785612800.0 | grad norm avg: 1.39 | grad norm last: 1.48 | 
2026-01-01T09:58:00 | step: 96000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.2793050447944552e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.3 | consumed tokens: 786432000.0 | grad norm avg: 1.39 | grad norm last: 1.35 | 
2026-01-01T09:58:18 | step: 96100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.2749210984329693e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.91 | consumed tokens: 787251200.0 | grad norm avg: 1.39 | grad norm last: 1.63 | 
2026-01-01T09:58:36 | step: 96200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.2705380615661852e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.44 | consumed tokens: 788070400.0 | grad norm avg: 1.37 | grad norm last: 1.54 | 
2026-01-01T09:58:54 | step: 96300 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.2661555703962222e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.8 | consumed tokens: 788889600.0 | grad norm avg: 1.4 | grad norm last: 1.45 | 
2026-01-01T09:59:12 | step: 96400 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.2617738068220206e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.61 | consumed tokens: 789708800.0 | grad norm avg: 1.39 | grad norm last: 1.49 | 
2026-01-01T09:59:30 | step: 96500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.2573929527425207e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 3.17 | consumed tokens: 790528000.0 | grad norm avg: 1.4 | grad norm last: 1.31 | 
2026-01-01T09:59:48 | step: 96600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.253012644359842e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.34 | consumed tokens: 791347200.0 | grad norm avg: 1.39 | grad norm last: 1.46 | 
2026-01-01T10:00:06 | step: 96700 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.248633245471865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.41 | consumed tokens: 792166400.0 | grad norm avg: 1.4 | grad norm last: 1.33 | 
2026-01-01T10:00:25 | step: 96800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.2442545741796494e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.64 | consumed tokens: 792985600.0 | grad norm avg: 1.39 | grad norm last: 1.24 | 
2026-01-01T10:00:43 | step: 96900 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 2.2398768123821355e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.41 | consumed tokens: 793804800.0 | grad norm avg: 1.39 | grad norm last: 1.43 | 
2026-01-01T10:01:01 | step: 97000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.235499778180383e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.75 | consumed tokens: 794624000.0 | grad norm avg: 1.38 | grad norm last: 1.28 | 
2026-01-01T10:01:19 | step: 97100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.2311234715743922e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.94 | consumed tokens: 795443200.0 | grad norm avg: 1.39 | grad norm last: 1.54 | 
2026-01-01T10:01:37 | step: 97200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.2267482563620433e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.19 | consumed tokens: 796262400.0 | grad norm avg: 1.39 | grad norm last: 1.37 | 
2026-01-01T10:01:55 | step: 97300 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 2.222373768745456e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.55 | train loss last: 3.2 | consumed tokens: 797081600.0 | grad norm avg: 1.39 | grad norm last: 1.38 | 
2026-01-01T10:02:14 | step: 97400 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.21800000872463e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.55 | consumed tokens: 797900800.0 | grad norm avg: 1.39 | grad norm last: 1.41 | 
2026-01-01T10:02:32 | step: 97500 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.213627340097446e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.42 | consumed tokens: 798720000.0 | grad norm avg: 1.37 | grad norm last: 1.29 | 
2026-01-01T10:02:50 | step: 97600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.2092553990660235e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 1.62 | consumed tokens: 799539200.0 | grad norm avg: 1.41 | grad norm last: 1.46 | 
2026-01-01T10:03:08 | step: 97700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.2048845494282432e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.75 | consumed tokens: 800358400.0 | grad norm avg: 1.39 | grad norm last: 1.3 | 
2026-01-01T10:03:26 | step: 97800 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 2.2005146092851646e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.56 | consumed tokens: 801177600.0 | grad norm avg: 1.4 | grad norm last: 1.49 | 
2026-01-01T10:03:44 | step: 97900 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.1961453967378475e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.48 | consumed tokens: 801996800.0 | grad norm avg: 1.39 | grad norm last: 1.39 | 
2026-01-01T10:04:02 | step: 98000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.1917772755841725e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.36 | consumed tokens: 802816000.0 | grad norm avg: 1.39 | grad norm last: 1.31 | 
2026-01-01T10:04:20 | step: 98100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.1874102458241396e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.84 | consumed tokens: 803635200.0 | grad norm avg: 1.38 | grad norm last: 1.41 | 
2026-01-01T10:04:39 | step: 98200 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 2.183043943659868e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.59 | consumed tokens: 804454400.0 | grad norm avg: 1.39 | grad norm last: 1.39 | 
2026-01-01T10:04:57 | step: 98300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.1786787328892387e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.11 | consumed tokens: 805273600.0 | grad norm avg: 1.42 | grad norm last: 1.34 | 
2026-01-01T10:05:15 | step: 98400 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 2.1743146135122515e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 3.09 | consumed tokens: 806092800.0 | grad norm avg: 1.39 | grad norm last: 1.44 | 
2026-01-01T10:05:33 | step: 98500 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.169951403629966e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 1.83 | consumed tokens: 806912000.0 | grad norm avg: 1.39 | grad norm last: 1.34 | 
2026-01-01T10:05:51 | step: 98600 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.1655892851413228e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.08 | consumed tokens: 807731200.0 | grad norm avg: 1.4 | grad norm last: 1.41 | 
2026-01-01T10:06:09 | step: 98700 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.1612282580463216e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.0 | consumed tokens: 808550400.0 | grad norm avg: 1.4 | grad norm last: 1.35 | 
2026-01-01T10:06:28 | step: 98800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.1568683223449625e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 1.66 | consumed tokens: 809369600.0 | grad norm avg: 1.39 | grad norm last: 1.26 | 
2026-01-01T10:06:46 | step: 98900 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.1525092961383052e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.42 | consumed tokens: 810188800.0 | grad norm avg: 1.39 | grad norm last: 1.43 | 
2026-01-01T10:07:04 | step: 99000 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.14815136132529e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.61 | consumed tokens: 811008000.0 | grad norm avg: 1.4 | grad norm last: 1.48 | 
2026-01-01T10:07:22 | step: 99100 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.1437946998048574e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.75 | consumed tokens: 811827200.0 | grad norm avg: 1.4 | grad norm last: 1.43 | 
2026-01-01T10:07:40 | step: 99200 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.1394391296780668e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.55 | consumed tokens: 812646400.0 | grad norm avg: 1.39 | grad norm last: 1.35 | 
2026-01-01T10:07:58 | step: 99300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.135084469045978e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.83 | consumed tokens: 813465600.0 | grad norm avg: 1.42 | grad norm last: 1.48 | 
2026-01-01T10:08:16 | step: 99400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.1307310817064717e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.86 | consumed tokens: 814284800.0 | grad norm avg: 1.4 | grad norm last: 1.42 | 
2026-01-01T10:08:35 | step: 99500 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 2.126378967659548e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.52 | consumed tokens: 815104000.0 | grad norm avg: 1.38 | grad norm last: 1.4 | 
2026-01-01T10:08:53 | step: 99600 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.1220279450062662e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.33 | consumed tokens: 815923200.0 | grad norm avg: 1.4 | grad norm last: 1.42 | 
2026-01-01T10:09:11 | step: 99700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.1176780137466267e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.59 | consumed tokens: 816742400.0 | grad norm avg: 1.39 | grad norm last: 1.44 | 
2026-01-01T10:09:29 | step: 99800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.1133293557795696e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.62 | consumed tokens: 817561600.0 | grad norm avg: 1.4 | grad norm last: 1.49 | 
2026-01-01T10:09:47 | step: 99900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.108981971105095e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.66 | consumed tokens: 818380800.0 | grad norm avg: 1.38 | grad norm last: 1.31 | 
2026-01-01T10:10:05 | step: 100000 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.1046356778242625e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.55 | consumed tokens: 819200000.0 | grad norm avg: 1.42 | grad norm last: 1.6 | 
2026-01-01T10:10:25 | step: 100100 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.1002906578360125e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.33 | consumed tokens: 820019200.0 | grad norm avg: 1.4 | grad norm last: 1.37 | 
2026-01-01T10:10:43 | step: 100200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.095946911140345e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.48 | consumed tokens: 820838400.0 | grad norm avg: 1.39 | grad norm last: 1.24 | 
2026-01-01T10:11:01 | step: 100300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.09160443773726e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.31 | consumed tokens: 821657600.0 | grad norm avg: 1.41 | grad norm last: 1.43 | 
2026-01-01T10:11:19 | step: 100400 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.0872632376267575e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.73 | consumed tokens: 822476800.0 | grad norm avg: 1.38 | grad norm last: 1.41 | 
2026-01-01T10:11:37 | step: 100500 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 2.0829233108088374e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.28 | consumed tokens: 823296000.0 | grad norm avg: 1.4 | grad norm last: 1.59 | 
2026-01-01T10:11:55 | step: 100600 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 2.0785846572835e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.88 | consumed tokens: 824115200.0 | grad norm avg: 1.39 | grad norm last: 1.43 | 
2026-01-01T10:12:14 | step: 100700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.0742472770507447e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.31 | consumed tokens: 824934400.0 | grad norm avg: 1.41 | grad norm last: 1.54 | 
2026-01-01T10:12:32 | step: 100800 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 2.0699113520095125e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.41 | consumed tokens: 825753600.0 | grad norm avg: 1.4 | grad norm last: 1.48 | 
2026-01-01T10:12:50 | step: 100900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.0655767002608627e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.34 | consumed tokens: 826572800.0 | grad norm avg: 1.41 | grad norm last: 1.47 | 
2026-01-01T10:13:08 | step: 101000 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.0612435037037358e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.08 | consumed tokens: 827392000.0 | grad norm avg: 1.39 | grad norm last: 1.27 | 
2026-01-01T10:13:26 | step: 101100 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 2.0569115804391913e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.62 | consumed tokens: 828211200.0 | grad norm avg: 1.41 | grad norm last: 1.35 | 
2026-01-01T10:13:45 | step: 101200 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 2.0525809304672293e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.12 | consumed tokens: 829030400.0 | grad norm avg: 1.42 | grad norm last: 1.51 | 
2026-01-01T10:14:03 | step: 101300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.0482519175857306e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 1.95 | consumed tokens: 829849600.0 | grad norm avg: 1.4 | grad norm last: 1.44 | 
2026-01-01T10:14:21 | step: 101400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.0439241779968143e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.36 | consumed tokens: 830668800.0 | grad norm avg: 1.41 | grad norm last: 1.31 | 
2026-01-01T10:14:39 | step: 101500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.0395978935994208e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.86 | consumed tokens: 831488000.0 | grad norm avg: 1.4 | grad norm last: 1.53 | 
2026-01-01T10:14:57 | step: 101600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.03527306439355e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 3.19 | consumed tokens: 832307200.0 | grad norm avg: 1.4 | grad norm last: 1.46 | 
2026-01-01T10:15:15 | step: 101700 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.0309496903792024e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.27 | consumed tokens: 833126400.0 | grad norm avg: 1.4 | grad norm last: 1.25 | 
2026-01-01T10:15:33 | step: 101800 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.0266277715563774e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.22 | consumed tokens: 833945600.0 | grad norm avg: 1.38 | grad norm last: 1.26 | 
2026-01-01T10:15:51 | step: 101900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.0223073079250753e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.28 | consumed tokens: 834764800.0 | grad norm avg: 1.39 | grad norm last: 1.19 | 
2026-01-01T10:16:09 | step: 102000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.017988299485296e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.92 | consumed tokens: 835584000.0 | grad norm avg: 1.39 | grad norm last: 1.31 | 
2026-01-01T10:16:28 | step: 102100 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 2.0136707462370396e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.28 | consumed tokens: 836403200.0 | grad norm avg: 1.38 | grad norm last: 1.35 | 
2026-01-01T10:16:46 | step: 102200 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 2.0093548300792463e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.55 | consumed tokens: 837222400.0 | grad norm avg: 1.4 | grad norm last: 1.48 | 
2026-01-01T10:17:04 | step: 102300 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.0050405510119162e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.42 | consumed tokens: 838041600.0 | grad norm avg: 1.39 | grad norm last: 1.57 | 
2026-01-01T10:17:22 | step: 102400 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.0007275452371687e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.48 | consumed tokens: 838860800.0 | grad norm avg: 1.4 | grad norm last: 1.4 | 
2026-01-01T10:17:40 | step: 102500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.9964163584518246e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.48 | consumed tokens: 839680000.0 | grad norm avg: 1.42 | grad norm last: 1.33 | 
2026-01-01T10:17:58 | step: 102600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.9921066268580034e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.66 | consumed tokens: 840499200.0 | grad norm avg: 1.39 | grad norm last: 1.42 | 
2026-01-01T10:18:17 | step: 102700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.987798350455705e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.61 | consumed tokens: 841318400.0 | grad norm avg: 1.43 | grad norm last: 1.3 | 
2026-01-01T10:18:35 | step: 102800 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.9834918930428103e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.41 | consumed tokens: 842137600.0 | grad norm avg: 1.42 | grad norm last: 1.34 | 
2026-01-01T10:18:53 | step: 102900 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 1.9791868908214383e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.52 | consumed tokens: 842956800.0 | grad norm avg: 1.41 | grad norm last: 1.32 | 
2026-01-01T10:19:11 | step: 103000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.97488370758947e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.91 | consumed tokens: 843776000.0 | grad norm avg: 1.4 | grad norm last: 1.39 | 
2026-01-01T10:19:29 | step: 103100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.9705819795490243e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.36 | consumed tokens: 844595200.0 | grad norm avg: 1.39 | grad norm last: 1.2 | 
2026-01-01T10:19:47 | step: 103200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.966281888599042e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.36 | consumed tokens: 845414400.0 | grad norm avg: 1.4 | grad norm last: 1.35 | 
2026-01-01T10:20:05 | step: 103300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.961983616638463e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.77 | consumed tokens: 846233600.0 | grad norm avg: 1.38 | grad norm last: 1.39 | 
2026-01-01T10:20:24 | step: 103400 | train samples/s: 95.3 | train mfu (16-bit): -1.0 | lr mean: 1.9576869817683473e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.47 | consumed tokens: 847052800.0 | grad norm avg: 1.39 | grad norm last: 1.38 | 
2026-01-01T10:20:42 | step: 103500 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 1.953391983988695e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.27 | consumed tokens: 847872000.0 | grad norm avg: 1.4 | grad norm last: 1.42 | 
2026-01-01T10:21:00 | step: 103600 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.9490986232995056e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.97 | consumed tokens: 848691200.0 | grad norm avg: 1.4 | grad norm last: 1.4 | 
2026-01-01T10:21:18 | step: 103700 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.9448070815997198e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.39 | consumed tokens: 849510400.0 | grad norm avg: 1.42 | grad norm last: 1.49 | 
2026-01-01T10:21:36 | step: 103800 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.9405173588893376e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.59 | consumed tokens: 850329600.0 | grad norm avg: 1.42 | grad norm last: 1.56 | 
2026-01-01T10:21:54 | step: 103900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.9362292732694186e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.06 | consumed tokens: 851148800.0 | grad norm avg: 1.43 | grad norm last: 1.41 | 
2026-01-01T10:22:12 | step: 104000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.9319428247399628e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.95 | consumed tokens: 851968000.0 | grad norm avg: 1.39 | grad norm last: 1.34 | 
2026-01-01T10:22:30 | step: 104100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.927658377098851e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.75 | consumed tokens: 852787200.0 | grad norm avg: 1.39 | grad norm last: 1.47 | 
2026-01-01T10:22:48 | step: 104200 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.9233755665482022e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.36 | consumed tokens: 853606400.0 | grad norm avg: 1.4 | grad norm last: 1.34 | 
2026-01-01T10:23:06 | step: 104300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.919094574986957e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.59 | consumed tokens: 854425600.0 | grad norm avg: 1.4 | grad norm last: 1.39 | 
2026-01-01T10:23:24 | step: 104400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.9148154024151154e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.33 | consumed tokens: 855244800.0 | grad norm avg: 1.4 | grad norm last: 1.41 | 
2026-01-01T10:23:42 | step: 104500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.9105380488326773e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.44 | consumed tokens: 856064000.0 | grad norm avg: 1.42 | grad norm last: 1.44 | 
2026-01-01T10:24:01 | step: 104600 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.906262696138583e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.45 | consumed tokens: 856883200.0 | grad norm avg: 1.4 | grad norm last: 1.45 | 
2026-01-01T10:24:19 | step: 104700 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 1.901988980534952e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.38 | consumed tokens: 857702400.0 | grad norm avg: 1.39 | grad norm last: 1.54 | 
2026-01-01T10:24:37 | step: 104800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.897717265819665e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 3.34 | consumed tokens: 858521600.0 | grad norm avg: 1.41 | grad norm last: 1.44 | 
2026-01-01T10:24:55 | step: 104900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.8934473700937815e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.7 | consumed tokens: 859340800.0 | grad norm avg: 1.42 | grad norm last: 1.7 | 
2026-01-01T10:25:13 | step: 105000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.8891792933573015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.69 | consumed tokens: 860160000.0 | grad norm avg: 1.41 | grad norm last: 1.44 | 
2026-01-01T10:25:32 | step: 105100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.8849132175091654e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.69 | consumed tokens: 860979200.0 | grad norm avg: 1.41 | grad norm last: 1.45 | 
2026-01-01T10:25:50 | step: 105200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.8806491425493732e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.2 | consumed tokens: 861798400.0 | grad norm avg: 1.4 | grad norm last: 1.33 | 
2026-01-01T10:26:09 | step: 105300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.8763868865789846e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 3.14 | consumed tokens: 862617600.0 | grad norm avg: 1.41 | grad norm last: 1.35 | 
2026-01-01T10:26:27 | step: 105400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.8721266314969398e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.7 | consumed tokens: 863436800.0 | grad norm avg: 1.41 | grad norm last: 1.4 | 
2026-01-01T10:26:45 | step: 105500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.8678681954042986e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.73 | consumed tokens: 864256000.0 | grad norm avg: 1.41 | grad norm last: 1.36 | 
2026-01-01T10:27:03 | step: 105600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.8636119420989417e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.5 | consumed tokens: 865075200.0 | grad norm avg: 1.4 | grad norm last: 1.34 | 
2026-01-01T10:27:21 | step: 105700 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.8593575077829883e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 3.03 | consumed tokens: 865894400.0 | grad norm avg: 1.42 | grad norm last: 1.32 | 
2026-01-01T10:27:39 | step: 105800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.8551050743553787e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 1.95 | consumed tokens: 866713600.0 | grad norm avg: 1.41 | grad norm last: 1.29 | 
2026-01-01T10:27:57 | step: 105900 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.850854641816113e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.38 | consumed tokens: 867532800.0 | grad norm avg: 1.42 | grad norm last: 1.38 | 
2026-01-01T10:28:15 | step: 106000 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.8466063920641318e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.53 | consumed tokens: 868352000.0 | grad norm avg: 1.41 | grad norm last: 1.36 | 
2026-01-01T10:28:33 | step: 106100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.8423601432004943e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.73 | consumed tokens: 869171200.0 | grad norm avg: 1.41 | grad norm last: 1.32 | 
2026-01-01T10:28:51 | step: 106200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.8381157133262604e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.44 | consumed tokens: 869990400.0 | grad norm avg: 1.4 | grad norm last: 1.37 | 
2026-01-01T10:29:09 | step: 106300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.833873648138251e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.7 | consumed tokens: 870809600.0 | grad norm avg: 1.41 | grad norm last: 1.44 | 
2026-01-01T10:29:27 | step: 106400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.8296334019396454e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.09 | consumed tokens: 871628800.0 | grad norm avg: 1.41 | grad norm last: 1.41 | 
2026-01-01T10:29:45 | step: 106500 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.8253955204272643e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.67 | consumed tokens: 872448000.0 | grad norm avg: 1.39 | grad norm last: 1.46 | 
2026-01-01T10:30:03 | step: 106600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.8211594579042867e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.12 | consumed tokens: 873267200.0 | grad norm avg: 1.42 | grad norm last: 1.39 | 
2026-01-01T10:30:21 | step: 106700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.8169257600675337e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.44 | consumed tokens: 874086400.0 | grad norm avg: 1.4 | grad norm last: 1.2 | 
2026-01-01T10:30:39 | step: 106800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.8126940631191246e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.33 | consumed tokens: 874905600.0 | grad norm avg: 1.42 | grad norm last: 1.31 | 
2026-01-01T10:30:58 | step: 106900 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 1.8084645489579998e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.19 | consumed tokens: 875724800.0 | grad norm avg: 1.41 | grad norm last: 1.42 | 
2026-01-01T10:31:16 | step: 107000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.804237035685219e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.59 | consumed tokens: 876544000.0 | grad norm avg: 1.4 | grad norm last: 1.45 | 
2026-01-01T10:31:34 | step: 107100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.8000118870986626e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.67 | consumed tokens: 877363200.0 | grad norm avg: 1.42 | grad norm last: 1.58 | 
2026-01-01T10:31:52 | step: 107200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.7957889212993905e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.41 | consumed tokens: 878182400.0 | grad norm avg: 1.4 | grad norm last: 1.37 | 
2026-01-01T10:32:10 | step: 107300 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 1.7915679563884623e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.72 | consumed tokens: 879001600.0 | grad norm avg: 1.41 | grad norm last: 1.43 | 
2026-01-01T10:32:28 | step: 107400 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.7873493561637588e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.48 | consumed tokens: 879820800.0 | grad norm avg: 1.41 | grad norm last: 1.39 | 
2026-01-01T10:32:46 | step: 107500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.7831329387263395e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.55 | consumed tokens: 880640000.0 | grad norm avg: 1.41 | grad norm last: 1.44 | 
2026-01-01T10:33:04 | step: 107600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.7789188859751448e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.72 | consumed tokens: 881459200.0 | grad norm avg: 1.41 | grad norm last: 1.35 | 
2026-01-01T10:33:22 | step: 107700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.774706834112294e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.75 | consumed tokens: 882278400.0 | grad norm avg: 1.41 | grad norm last: 1.46 | 
2026-01-01T10:33:40 | step: 107800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.7704973288346082e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.66 | consumed tokens: 883097600.0 | grad norm avg: 1.43 | grad norm last: 1.29 | 
2026-01-01T10:33:58 | step: 107900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.7662898244452663e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.27 | consumed tokens: 883916800.0 | grad norm avg: 1.42 | grad norm last: 1.46 | 
2026-01-01T10:34:17 | step: 108000 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.762084684742149e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.38 | consumed tokens: 884736000.0 | grad norm avg: 1.44 | grad norm last: 1.47 | 
2026-01-01T10:34:35 | step: 108100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.7578819097252563e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.55 | consumed tokens: 885555200.0 | grad norm avg: 1.42 | grad norm last: 1.31 | 
2026-01-01T10:34:53 | step: 108200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.7536814993945882e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.61 | consumed tokens: 886374400.0 | grad norm avg: 1.43 | grad norm last: 1.34 | 
2026-01-01T10:35:11 | step: 108300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.7494832718512043e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.81 | consumed tokens: 887193600.0 | grad norm avg: 1.41 | grad norm last: 1.36 | 
2026-01-01T10:35:29 | step: 108400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.745287408994045e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.0 | consumed tokens: 888012800.0 | grad norm avg: 1.42 | grad norm last: 1.45 | 
2026-01-01T10:35:47 | step: 108500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.741094092722051e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.41 | consumed tokens: 888832000.0 | grad norm avg: 1.43 | grad norm last: 1.39 | 
2026-01-01T10:36:05 | step: 108600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.736902959237341e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.22 | consumed tokens: 889651200.0 | grad norm avg: 1.41 | grad norm last: 1.42 | 
2026-01-01T10:36:23 | step: 108700 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 1.7327141904388554e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.47 | consumed tokens: 890470400.0 | grad norm avg: 1.43 | grad norm last: 1.4 | 
2026-01-01T10:36:41 | step: 108800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.7285277863265947e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.8 | consumed tokens: 891289600.0 | grad norm avg: 1.41 | grad norm last: 1.59 | 
2026-01-01T10:36:59 | step: 108900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.7243439287994988e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.39 | consumed tokens: 892108800.0 | grad norm avg: 1.43 | grad norm last: 1.39 | 
2026-01-01T10:37:17 | step: 109000 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.7201624359586276e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.28 | consumed tokens: 892928000.0 | grad norm avg: 1.44 | grad norm last: 1.4 | 
2026-01-01T10:37:35 | step: 109100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.715983307803981e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 3.06 | consumed tokens: 893747200.0 | grad norm avg: 1.43 | grad norm last: 1.41 | 
2026-01-01T10:37:53 | step: 109200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 1.7118067262344994e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.2 | consumed tokens: 894566400.0 | grad norm avg: 1.43 | grad norm last: 1.35 | 
2026-01-01T10:38:12 | step: 109300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.7076325093512423e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.78 | consumed tokens: 895385600.0 | grad norm avg: 1.44 | grad norm last: 1.46 | 
2026-01-01T10:38:30 | step: 109400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.7034608390531503e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.33 | consumed tokens: 896204800.0 | grad norm avg: 1.41 | grad norm last: 1.39 | 
2026-01-01T10:38:48 | step: 109500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.6992915334412828e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.58 | consumed tokens: 897024000.0 | grad norm avg: 1.43 | grad norm last: 1.59 | 
2026-01-01T10:39:06 | step: 109600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.6951247744145803e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.28 | consumed tokens: 897843200.0 | grad norm avg: 1.42 | grad norm last: 1.35 | 
2026-01-01T10:39:24 | step: 109700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.6909605619730428e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.83 | consumed tokens: 898662400.0 | grad norm avg: 1.42 | grad norm last: 1.32 | 
2026-01-01T10:39:42 | step: 109800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.6867988961166702e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.81 | consumed tokens: 899481600.0 | grad norm avg: 1.4 | grad norm last: 1.32 | 
2026-01-01T10:40:00 | step: 109900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.6826395949465223e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.53 | consumed tokens: 900300800.0 | grad norm avg: 1.41 | grad norm last: 1.29 | 
2026-01-01T10:40:18 | step: 110000 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 1.6784830222604796e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.84 | consumed tokens: 901120000.0 | grad norm avg: 1.41 | grad norm last: 1.37 | 
2026-01-01T10:40:37 | step: 110100 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.674328996159602e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.78 | consumed tokens: 901939200.0 | grad norm avg: 1.42 | grad norm last: 1.43 | 
2026-01-01T10:40:55 | step: 110200 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.6701775166438892e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 1.64 | consumed tokens: 902758400.0 | grad norm avg: 1.42 | grad norm last: 1.35 | 
2026-01-01T10:41:14 | step: 110300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.6660285837133415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.69 | consumed tokens: 903577600.0 | grad norm avg: 1.43 | grad norm last: 1.51 | 
2026-01-01T10:41:32 | step: 110400 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 1.6618821973679587e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.66 | consumed tokens: 904396800.0 | grad norm avg: 1.41 | grad norm last: 1.39 | 
2026-01-01T10:41:50 | step: 110500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.6577385395066813e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.02 | consumed tokens: 905216000.0 | grad norm avg: 1.43 | grad norm last: 1.59 | 
2026-01-01T10:42:08 | step: 110600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.6535974282305688e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.52 | consumed tokens: 906035200.0 | grad norm avg: 1.42 | grad norm last: 1.48 | 
2026-01-01T10:42:26 | step: 110700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.6494590454385616e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.34 | consumed tokens: 906854400.0 | grad norm avg: 1.42 | grad norm last: 1.49 | 
2026-01-01T10:42:44 | step: 110800 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.6453232092317194e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.22 | consumed tokens: 907673600.0 | grad norm avg: 1.41 | grad norm last: 1.44 | 
2026-01-01T10:43:02 | step: 110900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.6411901015089825e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.38 | consumed tokens: 908492800.0 | grad norm avg: 1.43 | grad norm last: 1.31 | 
2026-01-01T10:43:20 | step: 111000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.637059722270351e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.44 | consumed tokens: 909312000.0 | grad norm avg: 1.43 | grad norm last: 1.28 | 
2026-01-01T10:43:38 | step: 111100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.6329318896168843e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.45 | consumed tokens: 910131200.0 | grad norm avg: 1.43 | grad norm last: 1.47 | 
2026-01-01T10:43:56 | step: 111200 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.628806785447523e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.27 | consumed tokens: 910950400.0 | grad norm avg: 1.41 | grad norm last: 1.46 | 
2026-01-01T10:44:14 | step: 111300 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 1.6246845916612074e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.23 | consumed tokens: 911769600.0 | grad norm avg: 1.42 | grad norm last: 1.28 | 
2026-01-01T10:44:32 | step: 111400 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.6205649444600567e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.66 | consumed tokens: 912588800.0 | grad norm avg: 1.41 | grad norm last: 1.58 | 
2026-01-01T10:44:51 | step: 111500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.6164480257430114e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.48 | consumed tokens: 913408000.0 | grad norm avg: 1.43 | grad norm last: 1.4 | 
2026-01-01T10:45:09 | step: 111600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.6123338355100714e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.44 | consumed tokens: 914227200.0 | grad norm avg: 1.42 | grad norm last: 1.4 | 
2026-01-01T10:45:27 | step: 111700 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.608222555660177e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.72 | consumed tokens: 915046400.0 | grad norm avg: 1.41 | grad norm last: 1.47 | 
2026-01-01T10:45:45 | step: 111800 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.604114004294388e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.83 | consumed tokens: 915865600.0 | grad norm avg: 1.43 | grad norm last: 1.48 | 
2026-01-01T10:46:03 | step: 111900 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.6000081814127043e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.38 | consumed tokens: 916684800.0 | grad norm avg: 1.41 | grad norm last: 1.43 | 
2026-01-01T10:46:21 | step: 112000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.595905087015126e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.94 | consumed tokens: 917504000.0 | grad norm avg: 1.41 | grad norm last: 1.53 | 
2026-01-01T10:46:39 | step: 112100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.5918049030005932e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.62 | consumed tokens: 918323200.0 | grad norm avg: 1.42 | grad norm last: 1.31 | 
2026-01-01T10:46:57 | step: 112200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.587707629369106e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.67 | consumed tokens: 919142400.0 | grad norm avg: 1.43 | grad norm last: 1.51 | 
2026-01-01T10:47:15 | step: 112300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.5836130842217244e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.81 | consumed tokens: 919961600.0 | grad norm avg: 1.42 | grad norm last: 1.58 | 
2026-01-01T10:47:33 | step: 112400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.5795214494573884e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.5 | consumed tokens: 920780800.0 | grad norm avg: 1.42 | grad norm last: 1.54 | 
2026-01-01T10:47:51 | step: 112500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.575432725076098e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.53 | consumed tokens: 921600000.0 | grad norm avg: 1.43 | grad norm last: 1.39 | 
2026-01-01T10:48:09 | step: 112600 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 1.571346729178913e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.36 | consumed tokens: 922419200.0 | grad norm avg: 1.44 | grad norm last: 1.46 | 
2026-01-01T10:48:28 | step: 112700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.567263825563714e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.34 | consumed tokens: 923238400.0 | grad norm avg: 1.41 | grad norm last: 1.26 | 
2026-01-01T10:48:46 | step: 112800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.5631836504326202e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.7 | consumed tokens: 924057600.0 | grad norm avg: 1.42 | grad norm last: 1.32 | 
2026-01-01T10:49:04 | step: 112900 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.5591065675835125e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.48 | consumed tokens: 924876800.0 | grad norm avg: 1.44 | grad norm last: 1.54 | 
2026-01-01T10:49:22 | step: 113000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.55503221321851e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.66 | consumed tokens: 925696000.0 | grad norm avg: 1.45 | grad norm last: 1.42 | 
2026-01-01T10:49:40 | step: 113100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.5509609511354938e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 1.98 | consumed tokens: 926515200.0 | grad norm avg: 1.43 | grad norm last: 1.54 | 
2026-01-01T10:49:58 | step: 113200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.546892599435523e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.38 | consumed tokens: 927334400.0 | grad norm avg: 1.43 | grad norm last: 1.65 | 
2026-01-01T10:50:16 | step: 113300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.542827158118598e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.56 | consumed tokens: 928153600.0 | grad norm avg: 1.45 | grad norm last: 1.38 | 
2026-01-01T10:50:34 | step: 113400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.5387648090836592e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.36 | consumed tokens: 928972800.0 | grad norm avg: 1.45 | grad norm last: 1.49 | 
2026-01-01T10:50:52 | step: 113500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.534705370431766e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.7 | consumed tokens: 929792000.0 | grad norm avg: 1.44 | grad norm last: 1.46 | 
2026-01-01T10:51:10 | step: 113600 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.5306488421629183e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 3.17 | consumed tokens: 930611200.0 | grad norm avg: 1.45 | grad norm last: 1.41 | 
2026-01-01T10:51:28 | step: 113700 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.526595588074997e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.3 | consumed tokens: 931430400.0 | grad norm avg: 1.43 | grad norm last: 1.4 | 
2026-01-01T10:51:46 | step: 113800 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.5225451534206513e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.06 | consumed tokens: 932249600.0 | grad norm avg: 1.43 | grad norm last: 1.45 | 
2026-01-01T10:52:04 | step: 113900 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 1.5184979019977618e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.14 | consumed tokens: 933068800.0 | grad norm avg: 1.45 | grad norm last: 1.39 | 
2026-01-01T10:52:22 | step: 114000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.5144536519073881e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.69 | consumed tokens: 933888000.0 | grad norm avg: 1.41 | grad norm last: 1.33 | 
2026-01-01T10:52:40 | step: 114100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.5104124031495303e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 1.95 | consumed tokens: 934707200.0 | grad norm avg: 1.42 | grad norm last: 1.41 | 
2026-01-01T10:52:59 | step: 114200 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.5063743376231287e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.44 | consumed tokens: 935526400.0 | grad norm avg: 1.45 | grad norm last: 1.42 | 
2026-01-01T10:53:17 | step: 114300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.5023392734292429e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.64 | consumed tokens: 936345600.0 | grad norm avg: 1.42 | grad norm last: 1.5 | 
2026-01-01T10:53:35 | step: 114400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.4983073924668133e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.88 | consumed tokens: 937164800.0 | grad norm avg: 1.44 | grad norm last: 1.46 | 
2026-01-01T10:53:53 | step: 114500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.4942786037863698e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.83 | consumed tokens: 937984000.0 | grad norm avg: 1.44 | grad norm last: 1.48 | 
2026-01-01T10:54:11 | step: 114600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.4902529983373825e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.27 | consumed tokens: 938803200.0 | grad norm avg: 1.44 | grad norm last: 1.36 | 
2026-01-01T10:54:29 | step: 114700 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.4862304851703811e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.11 | consumed tokens: 939622400.0 | grad norm avg: 1.43 | grad norm last: 1.41 | 
2026-01-01T10:54:47 | step: 114800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.4822110642853659e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.42 | consumed tokens: 940441600.0 | grad norm avg: 1.42 | grad norm last: 1.36 | 
2026-01-01T10:55:05 | step: 114900 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.478194917581277e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.64 | consumed tokens: 941260800.0 | grad norm avg: 1.45 | grad norm last: 1.52 | 
2026-01-01T10:55:23 | step: 115000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.4741819541086443e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.47 | consumed tokens: 942080000.0 | grad norm avg: 1.44 | grad norm last: 1.63 | 
2026-01-01T10:55:42 | step: 115100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.4701720829179976e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.72 | consumed tokens: 942899200.0 | grad norm avg: 1.43 | grad norm last: 1.42 | 
2026-01-01T10:56:01 | step: 115200 | train samples/s: 94.9 | train mfu (16-bit): -1.0 | lr mean: 1.4661654859082773e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.52 | consumed tokens: 943718400.0 | grad norm avg: 1.44 | grad norm last: 1.38 | 
2026-01-01T10:56:19 | step: 115300 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.4621621630794834e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.34 | consumed tokens: 944537600.0 | grad norm avg: 1.45 | grad norm last: 1.31 | 
2026-01-01T10:56:37 | step: 115400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.4581620234821457e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.42 | consumed tokens: 945356800.0 | grad norm avg: 1.44 | grad norm last: 1.58 | 
2026-01-01T10:56:55 | step: 115500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.4541650671162643e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.25 | consumed tokens: 946176000.0 | grad norm avg: 1.46 | grad norm last: 1.28 | 
2026-01-01T10:57:13 | step: 115600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.4501714758807793e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.78 | consumed tokens: 946995200.0 | grad norm avg: 1.44 | grad norm last: 1.5 | 
2026-01-01T10:57:31 | step: 115700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.4461810678767506e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.05 | consumed tokens: 947814400.0 | grad norm avg: 1.43 | grad norm last: 1.48 | 
2026-01-01T10:57:49 | step: 115800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.4421939340536483e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.56 | consumed tokens: 948633600.0 | grad norm avg: 1.45 | grad norm last: 1.33 | 
2026-01-01T10:58:07 | step: 115900 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.4382101653609425e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 3.19 | consumed tokens: 949452800.0 | grad norm avg: 1.44 | grad norm last: 1.48 | 
2026-01-01T10:58:25 | step: 116000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.4342296708491631e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.03 | consumed tokens: 950272000.0 | grad norm avg: 1.44 | grad norm last: 1.48 | 
2026-01-01T10:58:43 | step: 116100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.43025245051831e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.38 | consumed tokens: 951091200.0 | grad norm avg: 1.45 | grad norm last: 1.37 | 
2026-01-01T10:59:01 | step: 116200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.4262785953178536e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.05 | consumed tokens: 951910400.0 | grad norm avg: 1.44 | grad norm last: 1.38 | 
2026-01-01T10:59:20 | step: 116300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.4223081052477937e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.47 | consumed tokens: 952729600.0 | grad norm avg: 1.43 | grad norm last: 1.41 | 
2026-01-01T10:59:38 | step: 116400 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.4183409803081304e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 3.05 | consumed tokens: 953548800.0 | grad norm avg: 1.45 | grad norm last: 1.52 | 
2026-01-01T10:59:56 | step: 116500 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 1.4143772204988636e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.47 | consumed tokens: 954368000.0 | grad norm avg: 1.45 | grad norm last: 1.4 | 
2026-01-01T11:00:14 | step: 116600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.4104168258199934e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.88 | consumed tokens: 955187200.0 | grad norm avg: 1.46 | grad norm last: 1.44 | 
2026-01-01T11:00:32 | step: 116700 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.4064597962715197e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 1.82 | consumed tokens: 956006400.0 | grad norm avg: 1.45 | grad norm last: 1.49 | 
2026-01-01T11:00:50 | step: 116800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.4025062228029128e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.54 | train loss last: 2.66 | consumed tokens: 956825600.0 | grad norm avg: 1.44 | grad norm last: 1.43 | 
2026-01-01T11:01:08 | step: 116900 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.3985560144647025e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.55 | consumed tokens: 957644800.0 | grad norm avg: 1.43 | grad norm last: 1.49 | 
2026-01-01T11:01:26 | step: 117000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.3946092622063588e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.45 | consumed tokens: 958464000.0 | grad norm avg: 1.43 | grad norm last: 1.5 | 
2026-01-01T11:01:44 | step: 117100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.390665966027882e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 3.55 | consumed tokens: 959283200.0 | grad norm avg: 1.42 | grad norm last: 1.4 | 
2026-01-01T11:02:02 | step: 117200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.3867260349798016e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.7 | consumed tokens: 960102400.0 | grad norm avg: 1.46 | grad norm last: 1.44 | 
2026-01-01T11:02:20 | step: 117300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.3827896509610582e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.34 | consumed tokens: 960921600.0 | grad norm avg: 1.46 | grad norm last: 1.24 | 
2026-01-01T11:02:38 | step: 117400 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.3788567230221815e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.69 | consumed tokens: 961740800.0 | grad norm avg: 1.44 | grad norm last: 1.44 | 
2026-01-01T11:02:56 | step: 117500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.3749273421126418e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.7 | consumed tokens: 962560000.0 | grad norm avg: 1.44 | grad norm last: 1.6 | 
2026-01-01T11:03:14 | step: 117600 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.3710014172829688e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 3.42 | consumed tokens: 963379200.0 | grad norm avg: 1.46 | grad norm last: 1.45 | 
2026-01-01T11:03:32 | step: 117700 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.3670789485331625e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.52 | consumed tokens: 964198400.0 | grad norm avg: 1.45 | grad norm last: 1.41 | 
2026-01-01T11:03:51 | step: 117800 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 1.3631601177621633e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.41 | consumed tokens: 965017600.0 | grad norm avg: 1.46 | grad norm last: 1.62 | 
2026-01-01T11:04:09 | step: 117900 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.3592447430710308e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 1.73 | consumed tokens: 965836800.0 | grad norm avg: 1.45 | grad norm last: 1.39 | 
2026-01-01T11:04:27 | step: 118000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.3553330063587055e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.47 | consumed tokens: 966656000.0 | grad norm avg: 1.44 | grad norm last: 1.42 | 
2026-01-01T11:04:45 | step: 118100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.3514247257262468e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.22 | consumed tokens: 967475200.0 | grad norm avg: 1.44 | grad norm last: 1.47 | 
2026-01-01T11:05:03 | step: 118200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.3475200830725953e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 3.33 | consumed tokens: 968294400.0 | grad norm avg: 1.42 | grad norm last: 1.33 | 
2026-01-01T11:05:21 | step: 118300 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 1.3436189874482807e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.8 | consumed tokens: 969113600.0 | grad norm avg: 1.44 | grad norm last: 1.42 | 
2026-01-01T11:05:39 | step: 118400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.3397215298027731e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.34 | consumed tokens: 969932800.0 | grad norm avg: 1.44 | grad norm last: 1.41 | 
2026-01-01T11:05:57 | step: 118500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.3358277101360727e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.22 | consumed tokens: 970752000.0 | grad norm avg: 1.42 | grad norm last: 1.52 | 
2026-01-01T11:06:15 | step: 118600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.3319374374987092e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.89 | consumed tokens: 971571200.0 | grad norm avg: 1.45 | grad norm last: 1.42 | 
2026-01-01T11:06:33 | step: 118700 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.328050893789623e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.73 | consumed tokens: 972390400.0 | grad norm avg: 1.44 | grad norm last: 1.56 | 
2026-01-01T11:06:52 | step: 118800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.3241678971098736e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.5 | consumed tokens: 973209600.0 | grad norm avg: 1.43 | grad norm last: 1.48 | 
2026-01-01T11:07:10 | step: 118900 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.3202886293584015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.86 | consumed tokens: 974028800.0 | grad norm avg: 1.45 | grad norm last: 1.44 | 
2026-01-01T11:07:28 | step: 119000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.3164129995857365e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.75 | consumed tokens: 974848000.0 | grad norm avg: 1.43 | grad norm last: 1.5 | 
2026-01-01T11:07:46 | step: 119100 | train samples/s: 95.3 | train mfu (16-bit): -1.0 | lr mean: 1.3125410987413488e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 2.06 | consumed tokens: 975667200.0 | grad norm avg: 1.45 | grad norm last: 1.45 | 
2026-01-01T11:08:04 | step: 119200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.3086729268252384e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.89 | consumed tokens: 976486400.0 | grad norm avg: 1.43 | grad norm last: 1.4 | 
2026-01-01T11:08:23 | step: 119300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.304808392887935e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.44 | consumed tokens: 977305600.0 | grad norm avg: 1.43 | grad norm last: 1.46 | 
2026-01-01T11:08:41 | step: 119400 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 1.300947587878909e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.44 | consumed tokens: 978124800.0 | grad norm avg: 1.42 | grad norm last: 1.55 | 
2026-01-01T11:08:59 | step: 119500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.2970905117981602e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.44 | consumed tokens: 978944000.0 | grad norm avg: 1.45 | grad norm last: 1.42 | 
2026-01-01T11:09:17 | step: 119600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.2932371646456886e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.19 | consumed tokens: 979763200.0 | grad norm avg: 1.43 | grad norm last: 1.43 | 
2026-01-01T11:09:35 | step: 119700 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.2893876373709645e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.61 | consumed tokens: 980582400.0 | grad norm avg: 1.45 | grad norm last: 1.45 | 
2026-01-01T11:09:53 | step: 119800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.2855418390245177e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.58 | consumed tokens: 981401600.0 | grad norm avg: 1.43 | grad norm last: 1.45 | 
2026-01-01T11:10:11 | step: 119900 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 1.2816997696063481e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.53 | consumed tokens: 982220800.0 | grad norm avg: 1.43 | grad norm last: 1.53 | 
2026-01-01T11:10:30 | step: 120000 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 1.277861520065926e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.66 | consumed tokens: 983040000.0 | grad norm avg: 1.45 | grad norm last: 1.48 | 
2026-01-01T11:10:49 | step: 120100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.2740270904032513e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.58 | consumed tokens: 983859200.0 | grad norm avg: 1.46 | grad norm last: 1.54 | 
2026-01-01T11:11:07 | step: 120200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.2701964806183241e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.77 | consumed tokens: 984678400.0 | grad norm avg: 1.45 | grad norm last: 1.34 | 
2026-01-01T11:11:25 | step: 120300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.2663697816606145e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.48 | consumed tokens: 985497600.0 | grad norm avg: 1.44 | grad norm last: 1.38 | 
2026-01-01T11:11:44 | step: 120400 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 1.2625468116311822e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.25 | consumed tokens: 986316800.0 | grad norm avg: 1.44 | grad norm last: 1.51 | 
2026-01-01T11:12:02 | step: 120500 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 1.2587277524289675e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.88 | consumed tokens: 987136000.0 | grad norm avg: 1.45 | grad norm last: 1.36 | 
2026-01-01T11:12:20 | step: 120600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.2549125131045002e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 1.89 | consumed tokens: 987955200.0 | grad norm avg: 1.44 | grad norm last: 1.44 | 
2026-01-01T11:12:38 | step: 120700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.2511011846072506e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 1.95 | consumed tokens: 988774400.0 | grad norm avg: 1.43 | grad norm last: 1.39 | 
2026-01-01T11:12:56 | step: 120800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.2472936759877484e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.11 | consumed tokens: 989593600.0 | grad norm avg: 1.44 | grad norm last: 1.44 | 
2026-01-01T11:13:14 | step: 120900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.2434900781954639e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.75 | consumed tokens: 990412800.0 | grad norm avg: 1.44 | grad norm last: 1.46 | 
2026-01-01T11:13:32 | step: 121000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.2396904821798671e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.2 | consumed tokens: 991232000.0 | grad norm avg: 1.44 | grad norm last: 1.46 | 
2026-01-01T11:13:50 | step: 121100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 1.2358947060420178e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.62 | consumed tokens: 992051200.0 | grad norm avg: 1.45 | grad norm last: 1.56 | 
2026-01-01T11:14:08 | step: 121200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.2321029316808563e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.27 | consumed tokens: 992870400.0 | grad norm avg: 1.45 | grad norm last: 1.3 | 
2026-01-01T11:14:26 | step: 121300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.2283150681469124e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.52 | consumed tokens: 993689600.0 | grad norm avg: 1.44 | grad norm last: 1.35 | 
2026-01-01T11:14:44 | step: 121400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.2245312063896563e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.55 | consumed tokens: 994508800.0 | grad norm avg: 1.44 | grad norm last: 1.57 | 
2026-01-01T11:15:02 | step: 121500 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.2207512554596178e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.78 | consumed tokens: 995328000.0 | grad norm avg: 1.44 | grad norm last: 1.47 | 
2026-01-01T11:15:21 | step: 121600 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.2169753972557373e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.64 | consumed tokens: 996147200.0 | grad norm avg: 1.44 | grad norm last: 1.52 | 
2026-01-01T11:15:39 | step: 121700 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 1.2132034498790745e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.41 | consumed tokens: 996966400.0 | grad norm avg: 1.45 | grad norm last: 1.49 | 
2026-01-01T11:15:57 | step: 121800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.2094355042790994e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.2 | consumed tokens: 997785600.0 | grad norm avg: 1.44 | grad norm last: 1.37 | 
2026-01-01T11:16:15 | step: 121900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.2056715604558121e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.89 | consumed tokens: 998604800.0 | grad norm avg: 1.45 | grad norm last: 1.59 | 
2026-01-01T11:16:33 | step: 122000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.2019116184092127e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.95 | consumed tokens: 999424000.0 | grad norm avg: 1.46 | grad norm last: 1.4 | 
2026-01-01T11:16:51 | step: 122100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.1981557690887712e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.3 | consumed tokens: 1000243200.0 | grad norm avg: 1.45 | grad norm last: 1.37 | 
2026-01-01T11:17:09 | step: 122200 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 1.1944040124944877e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 1.94 | consumed tokens: 1001062400.0 | grad norm avg: 1.44 | grad norm last: 1.37 | 
2026-01-01T11:17:27 | step: 122300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.190656257676892e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 1.54 | consumed tokens: 1001881600.0 | grad norm avg: 1.42 | grad norm last: 1.4 | 
2026-01-01T11:17:45 | step: 122400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.1869125955854543e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.34 | consumed tokens: 1002700800.0 | grad norm avg: 1.45 | grad norm last: 1.36 | 
2026-01-01T11:18:03 | step: 122500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.1831730262201745e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.75 | consumed tokens: 1003520000.0 | grad norm avg: 1.46 | grad norm last: 1.39 | 
2026-01-01T11:18:22 | step: 122600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.1794375495810527e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.48 | consumed tokens: 1004339200.0 | grad norm avg: 1.46 | grad norm last: 1.37 | 
2026-01-01T11:18:40 | step: 122700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.175706165668089e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.2 | consumed tokens: 1005158400.0 | grad norm avg: 1.46 | grad norm last: 1.44 | 
2026-01-01T11:18:58 | step: 122800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.1719789654307533e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 1.66 | consumed tokens: 1005977600.0 | grad norm avg: 1.43 | grad norm last: 1.34 | 
2026-01-01T11:19:16 | step: 122900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.1682558579195756e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.64 | consumed tokens: 1006796800.0 | grad norm avg: 1.45 | grad norm last: 1.33 | 
2026-01-01T11:19:34 | step: 123000 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 1.164536843134556e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.5 | consumed tokens: 1007616000.0 | grad norm avg: 1.45 | grad norm last: 1.44 | 
2026-01-01T11:19:52 | step: 123100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.1608220120251644e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.33 | consumed tokens: 1008435200.0 | grad norm avg: 1.45 | grad norm last: 1.5 | 
2026-01-01T11:20:10 | step: 123200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.157111364591401e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 3.02 | consumed tokens: 1009254400.0 | grad norm avg: 1.44 | grad norm last: 1.28 | 
2026-01-01T11:20:29 | step: 123300 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 1.1534049008332659e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.08 | consumed tokens: 1010073600.0 | grad norm avg: 1.46 | grad norm last: 1.47 | 
2026-01-01T11:20:47 | step: 123400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.1497026207507588e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.48 | consumed tokens: 1010892800.0 | grad norm avg: 1.44 | grad norm last: 1.47 | 
2026-01-01T11:21:05 | step: 123500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.14600461529335e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.28 | consumed tokens: 1011712000.0 | grad norm avg: 1.46 | grad norm last: 1.63 | 
2026-01-01T11:21:23 | step: 123600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.1423107025620993e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.33 | consumed tokens: 1012531200.0 | grad norm avg: 1.47 | grad norm last: 1.42 | 
2026-01-01T11:21:41 | step: 123700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.1386210644559469e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.42 | consumed tokens: 1013350400.0 | grad norm avg: 1.46 | grad norm last: 1.42 | 
2026-01-01T11:21:59 | step: 123800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.1349357009748928e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.77 | consumed tokens: 1014169600.0 | grad norm avg: 1.45 | grad norm last: 1.29 | 
2026-01-01T11:22:17 | step: 123900 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.1312545211694669e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.08 | consumed tokens: 1014988800.0 | grad norm avg: 1.43 | grad norm last: 1.39 | 
2026-01-01T11:22:35 | step: 124000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.1275777069386095e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 1.97 | consumed tokens: 1015808000.0 | grad norm avg: 1.45 | grad norm last: 1.37 | 
2026-01-01T11:22:53 | step: 124100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.1239050763833802e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.77 | consumed tokens: 1016627200.0 | grad norm avg: 1.47 | grad norm last: 1.48 | 
2026-01-01T11:23:11 | step: 124200 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.1202367204532493e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 1.99 | consumed tokens: 1017446400.0 | grad norm avg: 1.44 | grad norm last: 1.52 | 
2026-01-01T11:23:30 | step: 124300 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 1.1165726391482167e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 1.81 | consumed tokens: 1018265600.0 | grad norm avg: 1.46 | grad norm last: 1.39 | 
2026-01-01T11:23:48 | step: 124400 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.1129129234177526e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.14 | consumed tokens: 1019084800.0 | grad norm avg: 1.44 | grad norm last: 1.45 | 
2026-01-01T11:24:06 | step: 124500 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 1.1092574823123869e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.17 | consumed tokens: 1019904000.0 | grad norm avg: 1.46 | grad norm last: 1.48 | 
2026-01-01T11:24:24 | step: 124600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.1056064067815896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.75 | consumed tokens: 1020723200.0 | grad norm avg: 1.44 | grad norm last: 1.48 | 
2026-01-01T11:24:42 | step: 124700 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.1019596968253609e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.36 | consumed tokens: 1021542400.0 | grad norm avg: 1.44 | grad norm last: 1.48 | 
2026-01-01T11:25:00 | step: 124800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.0983172614942305e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.53 | consumed tokens: 1022361600.0 | grad norm avg: 1.47 | grad norm last: 1.46 | 
2026-01-01T11:25:18 | step: 124900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.0946791917376686e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 1.99 | consumed tokens: 1023180800.0 | grad norm avg: 1.46 | grad norm last: 1.4 | 
2026-01-01T11:25:36 | step: 125000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.0910455785051454e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.53 | consumed tokens: 1024000000.0 | grad norm avg: 1.45 | grad norm last: 1.46 | 
2026-01-01T11:25:56 | step: 125100 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 1.0874163308471907e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.67 | consumed tokens: 1024819200.0 | grad norm avg: 1.46 | grad norm last: 1.36 | 
2026-01-01T11:26:14 | step: 125200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.0837913578143343e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.8 | consumed tokens: 1025638400.0 | grad norm avg: 1.46 | grad norm last: 1.47 | 
2026-01-01T11:26:32 | step: 125300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.0801709322549868e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.77 | consumed tokens: 1026457600.0 | grad norm avg: 1.44 | grad norm last: 1.53 | 
2026-01-01T11:26:50 | step: 125400 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 1.0765548722702079e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.69 | consumed tokens: 1027276800.0 | grad norm avg: 1.44 | grad norm last: 1.58 | 
2026-01-01T11:27:08 | step: 125500 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.0729432688094676e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.16 | consumed tokens: 1028096000.0 | grad norm avg: 1.45 | grad norm last: 1.44 | 
2026-01-01T11:27:27 | step: 125600 | train samples/s: 95.0 | train mfu (16-bit): -1.0 | lr mean: 1.0693360309232958e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.73 | consumed tokens: 1028915200.0 | grad norm avg: 1.45 | grad norm last: 1.31 | 
2026-01-01T11:27:45 | step: 125700 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 1.0657333405106328e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.34 | consumed tokens: 1029734400.0 | grad norm avg: 1.44 | grad norm last: 1.45 | 
2026-01-01T11:28:03 | step: 125800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.0621350156725384e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.58 | consumed tokens: 1030553600.0 | grad norm avg: 1.44 | grad norm last: 1.5 | 
2026-01-01T11:28:21 | step: 125900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.0585412383079529e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.53 | consumed tokens: 1031372800.0 | grad norm avg: 1.45 | grad norm last: 1.46 | 
2026-01-01T11:28:39 | step: 126000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.054951917467406e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.84 | consumed tokens: 1032192000.0 | grad norm avg: 1.46 | grad norm last: 1.54 | 
2026-01-01T11:28:57 | step: 126100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.0513670531508978e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.03 | consumed tokens: 1033011200.0 | grad norm avg: 1.45 | grad norm last: 1.43 | 
2026-01-01T11:29:16 | step: 126200 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.0477868272573687e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.25 | consumed tokens: 1033830400.0 | grad norm avg: 1.44 | grad norm last: 1.33 | 
2026-01-01T11:29:34 | step: 126300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.0442109669384081e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.53 | consumed tokens: 1034649600.0 | grad norm avg: 1.46 | grad norm last: 1.36 | 
2026-01-01T11:29:52 | step: 126400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.0406397450424265e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.61 | consumed tokens: 1035468800.0 | grad norm avg: 1.46 | grad norm last: 1.4 | 
2026-01-01T11:30:10 | step: 126500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.0370729796704836e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.42 | consumed tokens: 1036288000.0 | grad norm avg: 1.43 | grad norm last: 1.53 | 
2026-01-01T11:30:28 | step: 126600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.0335108527215198e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 1.93 | consumed tokens: 1037107200.0 | grad norm avg: 1.45 | grad norm last: 1.46 | 
2026-01-01T11:30:46 | step: 126700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 1.0299532732460648e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.52 | consumed tokens: 1037926400.0 | grad norm avg: 1.46 | grad norm last: 1.42 | 
2026-01-01T11:31:04 | step: 126800 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 1.0264002412441187e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.61 | consumed tokens: 1038745600.0 | grad norm avg: 1.46 | grad norm last: 1.48 | 
2026-01-01T11:31:22 | step: 126900 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.0228517567156814e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.22 | consumed tokens: 1039564800.0 | grad norm avg: 1.46 | grad norm last: 1.5 | 
2026-01-01T11:31:41 | step: 127000 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.0193079106102232e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.06 | consumed tokens: 1040384000.0 | grad norm avg: 1.47 | grad norm last: 1.46 | 
2026-01-01T11:31:59 | step: 127100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.015768702927744e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.33 | consumed tokens: 1041203200.0 | grad norm avg: 1.46 | grad norm last: 1.4 | 
2026-01-01T11:32:17 | step: 127200 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.0122340427187737e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 3.03 | consumed tokens: 1042022400.0 | grad norm avg: 1.48 | grad norm last: 1.35 | 
2026-01-01T11:32:35 | step: 127300 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.0087040209327824e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.66 | consumed tokens: 1042841600.0 | grad norm avg: 1.46 | grad norm last: 1.37 | 
2026-01-01T11:32:53 | step: 127400 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 1.0051787285192404e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.92 | consumed tokens: 1043660800.0 | grad norm avg: 1.46 | grad norm last: 1.41 | 
2026-01-01T11:33:11 | step: 127500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.0016579835792072e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.75 | consumed tokens: 1044480000.0 | grad norm avg: 1.46 | grad norm last: 1.6 | 
2026-01-01T11:33:29 | step: 127600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 9.981419680116232e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.44 | train loss last: 2.48 | consumed tokens: 1045299200.0 | grad norm avg: 1.44 | grad norm last: 1.44 | 
2026-01-01T11:33:47 | step: 127700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 9.946305908670183e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.45 | consumed tokens: 1046118400.0 | grad norm avg: 1.47 | grad norm last: 1.82 | 
2026-01-01T11:34:05 | step: 127800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 9.911239430948626e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.44 | consumed tokens: 1046937600.0 | grad norm avg: 1.47 | grad norm last: 1.61 | 
2026-01-01T11:34:24 | step: 127900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 9.87621933745686e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.39 | consumed tokens: 1047756800.0 | grad norm avg: 1.46 | grad norm last: 1.5 | 
2026-01-01T11:34:42 | step: 128000 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 9.841246537689585e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.5 | consumed tokens: 1048576000.0 | grad norm avg: 1.47 | grad norm last: 1.57 | 
2026-01-01T11:35:00 | step: 128100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 9.806321031646803e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.23 | consumed tokens: 1049395200.0 | grad norm avg: 1.45 | grad norm last: 1.41 | 
2026-01-01T11:35:18 | step: 128200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 9.771442819328513e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.36 | consumed tokens: 1050214400.0 | grad norm avg: 1.45 | grad norm last: 1.42 | 
2026-01-01T11:35:36 | step: 128300 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 9.736610991240013e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 3.03 | consumed tokens: 1051033600.0 | grad norm avg: 1.46 | grad norm last: 1.45 | 
2026-01-01T11:35:54 | step: 128400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 9.70182827586541e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.22 | consumed tokens: 1051852800.0 | grad norm avg: 1.45 | grad norm last: 1.35 | 
2026-01-01T11:36:12 | step: 128500 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 9.667091944720596e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.33 | consumed tokens: 1052672000.0 | grad norm avg: 1.46 | grad norm last: 1.36 | 
2026-01-01T11:36:31 | step: 128600 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 9.632403816794977e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.67 | consumed tokens: 1053491200.0 | grad norm avg: 1.44 | grad norm last: 1.35 | 
2026-01-01T11:36:49 | step: 128700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 9.597763892088551e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.36 | consumed tokens: 1054310400.0 | grad norm avg: 1.47 | grad norm last: 1.61 | 
2026-01-01T11:37:07 | step: 128800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 9.563171261106618e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.31 | consumed tokens: 1055129600.0 | grad norm avg: 1.47 | grad norm last: 1.6 | 
2026-01-01T11:37:25 | step: 128900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 9.528626833343878e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.53 | consumed tokens: 1055948800.0 | grad norm avg: 1.47 | grad norm last: 1.42 | 
2026-01-01T11:37:43 | step: 129000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 9.494130608800333e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.05 | consumed tokens: 1056768000.0 | grad norm avg: 1.45 | grad norm last: 1.4 | 
2026-01-01T11:38:01 | step: 129100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 9.459682587475982e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 3.12 | consumed tokens: 1057587200.0 | grad norm avg: 1.47 | grad norm last: 1.42 | 
2026-01-01T11:38:19 | step: 129200 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 9.425282769370824e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.53 | consumed tokens: 1058406400.0 | grad norm avg: 1.45 | grad norm last: 1.41 | 
2026-01-01T11:38:37 | step: 129300 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 9.39093115448486e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.38 | consumed tokens: 1059225600.0 | grad norm avg: 1.46 | grad norm last: 1.53 | 
2026-01-01T11:38:55 | step: 129400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 9.356628652312793e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.33 | consumed tokens: 1060044800.0 | grad norm avg: 1.47 | grad norm last: 1.52 | 
2026-01-01T11:39:13 | step: 129500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 9.322374353359919e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.22 | consumed tokens: 1060864000.0 | grad norm avg: 1.47 | grad norm last: 1.41 | 
2026-01-01T11:39:31 | step: 129600 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 9.288169167120941e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.41 | consumed tokens: 1061683200.0 | grad norm avg: 1.45 | grad norm last: 1.49 | 
2026-01-01T11:39:50 | step: 129700 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 9.254013093595859e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.39 | consumed tokens: 1062502400.0 | grad norm avg: 1.45 | grad norm last: 1.43 | 
2026-01-01T11:40:08 | step: 129800 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 9.219906132784672e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.56 | consumed tokens: 1063321600.0 | grad norm avg: 1.48 | grad norm last: 1.49 | 
2026-01-01T11:40:26 | step: 129900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 9.18584737519268e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.19 | consumed tokens: 1064140800.0 | grad norm avg: 1.46 | grad norm last: 1.4 | 
2026-01-01T11:40:44 | step: 130000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 9.151838639809284e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.38 | consumed tokens: 1064960000.0 | grad norm avg: 1.47 | grad norm last: 1.54 | 
2026-01-01T11:41:03 | step: 130100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 9.117879017139785e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.3 | consumed tokens: 1065779200.0 | grad norm avg: 1.47 | grad norm last: 1.44 | 
2026-01-01T11:41:21 | step: 130200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 9.083968507184181e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.78 | consumed tokens: 1066598400.0 | grad norm avg: 1.45 | grad norm last: 1.45 | 
2026-01-01T11:41:40 | step: 130300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 9.050108019437175e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 3.0 | consumed tokens: 1067417600.0 | grad norm avg: 1.45 | grad norm last: 1.43 | 
2026-01-01T11:41:58 | step: 130400 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 9.016296644404065e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.59 | consumed tokens: 1068236800.0 | grad norm avg: 1.46 | grad norm last: 1.44 | 
2026-01-01T11:42:16 | step: 130500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 8.982535291579552e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.53 | consumed tokens: 1069056000.0 | grad norm avg: 1.49 | grad norm last: 1.6 | 
2026-01-01T11:42:34 | step: 130600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 8.948823051468935e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.55 | consumed tokens: 1069875200.0 | grad norm avg: 1.45 | grad norm last: 1.35 | 
2026-01-01T11:42:52 | step: 130700 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 8.915161743061617e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.25 | consumed tokens: 1070694400.0 | grad norm avg: 1.49 | grad norm last: 1.59 | 
2026-01-01T11:43:10 | step: 130800 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 8.881550456862897e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.22 | consumed tokens: 1071513600.0 | grad norm avg: 1.47 | grad norm last: 1.64 | 
2026-01-01T11:43:29 | step: 130900 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 8.847988283378072e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.22 | consumed tokens: 1072332800.0 | grad norm avg: 1.45 | grad norm last: 1.46 | 
2026-01-01T11:43:47 | step: 131000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 8.814477041596547e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.39 | consumed tokens: 1073152000.0 | grad norm avg: 1.46 | grad norm last: 1.36 | 
2026-01-01T11:44:05 | step: 131100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 8.78101673151832e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.53 | train loss last: 3.22 | consumed tokens: 1073971200.0 | grad norm avg: 1.48 | grad norm last: 1.62 | 
2026-01-01T11:44:23 | step: 131200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 8.747606443648692e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.25 | consumed tokens: 1074790400.0 | grad norm avg: 1.43 | grad norm last: 1.47 | 
2026-01-01T11:44:41 | step: 131300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 8.714246177987661e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.3 | consumed tokens: 1075609600.0 | grad norm avg: 1.46 | grad norm last: 1.41 | 
2026-01-01T11:44:59 | step: 131400 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 8.68093684402993e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.38 | consumed tokens: 1076428800.0 | grad norm avg: 1.44 | grad norm last: 1.37 | 
2026-01-01T11:45:17 | step: 131500 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 8.647678441775497e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.34 | consumed tokens: 1077248000.0 | grad norm avg: 1.46 | grad norm last: 1.53 | 
2026-01-01T11:45:35 | step: 131600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 8.614470971224364e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.25 | consumed tokens: 1078067200.0 | grad norm avg: 1.46 | grad norm last: 1.47 | 
2026-01-01T11:45:53 | step: 131700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 8.58131443237653e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.42 | consumed tokens: 1078886400.0 | grad norm avg: 1.47 | grad norm last: 1.31 | 
2026-01-01T11:46:11 | step: 131800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 8.548208825231995e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.53 | consumed tokens: 1079705600.0 | grad norm avg: 1.46 | grad norm last: 1.4 | 
2026-01-01T11:46:29 | step: 131900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 8.515155059285462e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.41 | consumed tokens: 1080524800.0 | grad norm avg: 1.47 | grad norm last: 1.53 | 
2026-01-01T11:46:47 | step: 132000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 8.482152225042228e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.86 | consumed tokens: 1081344000.0 | grad norm avg: 1.47 | grad norm last: 1.43 | 
2026-01-01T11:47:06 | step: 132100 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 8.449200322502293e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.33 | consumed tokens: 1082163200.0 | grad norm avg: 1.48 | grad norm last: 1.42 | 
2026-01-01T11:47:24 | step: 132200 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 8.416300261160359e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.66 | consumed tokens: 1082982400.0 | grad norm avg: 1.46 | grad norm last: 1.54 | 
2026-01-01T11:47:42 | step: 132300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 8.383452041016426e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.5 | consumed tokens: 1083801600.0 | grad norm avg: 1.48 | grad norm last: 1.53 | 
2026-01-01T11:48:00 | step: 132400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 8.350654752575792e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.61 | consumed tokens: 1084620800.0 | grad norm avg: 1.48 | grad norm last: 1.35 | 
2026-01-01T11:48:18 | step: 132500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 8.317910214827862e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.61 | consumed tokens: 1085440000.0 | grad norm avg: 1.49 | grad norm last: 1.51 | 
2026-01-01T11:48:36 | step: 132600 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 8.28521660878323e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.75 | consumed tokens: 1086259200.0 | grad norm avg: 1.47 | grad norm last: 1.51 | 
2026-01-01T11:48:54 | step: 132700 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 8.252575753431302e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.86 | consumed tokens: 1087078400.0 | grad norm avg: 1.48 | grad norm last: 1.52 | 
2026-01-01T11:49:12 | step: 132800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 8.219986739277374e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.53 | consumed tokens: 1087897600.0 | grad norm avg: 1.49 | grad norm last: 1.43 | 
2026-01-01T11:49:30 | step: 132900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 8.187449566321447e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.7 | consumed tokens: 1088716800.0 | grad norm avg: 1.45 | grad norm last: 1.57 | 
2026-01-01T11:49:48 | step: 133000 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 8.154965144058224e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.61 | consumed tokens: 1089536000.0 | grad norm avg: 1.48 | grad norm last: 1.57 | 
2026-01-01T11:50:07 | step: 133100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 8.122532562993001e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.7 | consumed tokens: 1090355200.0 | grad norm avg: 1.48 | grad norm last: 1.45 | 
2026-01-01T11:50:25 | step: 133200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 8.090153642115183e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.77 | consumed tokens: 1091174400.0 | grad norm avg: 1.48 | grad norm last: 1.49 | 
2026-01-01T11:50:43 | step: 133300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 8.057826562435366e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.7 | consumed tokens: 1091993600.0 | grad norm avg: 1.48 | grad norm last: 1.46 | 
2026-01-01T11:51:01 | step: 133400 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 8.025552233448252e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.86 | consumed tokens: 1092812800.0 | grad norm avg: 1.46 | grad norm last: 1.51 | 
2026-01-01T11:51:19 | step: 133500 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 7.99333065515384e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.22 | consumed tokens: 1093632000.0 | grad norm avg: 1.47 | grad norm last: 1.5 | 
2026-01-01T11:51:37 | step: 133600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 7.961161827552132e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 1.85 | consumed tokens: 1094451200.0 | grad norm avg: 1.47 | grad norm last: 1.54 | 
2026-01-01T11:51:55 | step: 133700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 7.929046660137828e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.44 | train loss last: 2.38 | consumed tokens: 1095270400.0 | grad norm avg: 1.49 | grad norm last: 1.4 | 
2026-01-01T11:52:13 | step: 133800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 7.896984243416227e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.3 | consumed tokens: 1096089600.0 | grad norm avg: 1.45 | grad norm last: 1.44 | 
2026-01-01T11:52:32 | step: 133900 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 7.86497457738733e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.19 | consumed tokens: 1096908800.0 | grad norm avg: 1.47 | grad norm last: 1.5 | 
2026-01-01T11:52:50 | step: 134000 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 7.833018571545836e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.53 | consumed tokens: 1097728000.0 | grad norm avg: 1.47 | grad norm last: 1.55 | 
2026-01-01T11:53:08 | step: 134100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 7.801116225891747e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.55 | consumed tokens: 1098547200.0 | grad norm avg: 1.5 | grad norm last: 1.55 | 
2026-01-01T11:53:26 | step: 134200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 7.769267540425062e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.39 | consumed tokens: 1099366400.0 | grad norm avg: 1.49 | grad norm last: 1.42 | 
2026-01-01T11:53:44 | step: 134300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 7.73747160565108e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.62 | consumed tokens: 1100185600.0 | grad norm avg: 1.46 | grad norm last: 1.54 | 
2026-01-01T11:54:02 | step: 134400 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 7.705730240559205e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.17 | consumed tokens: 1101004800.0 | grad norm avg: 1.46 | grad norm last: 1.42 | 
2026-01-01T11:54:20 | step: 134500 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 7.674041626160033e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.56 | consumed tokens: 1101824000.0 | grad norm avg: 1.46 | grad norm last: 1.46 | 
2026-01-01T11:54:38 | step: 134600 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 7.642407581442967e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 3.16 | consumed tokens: 1102643200.0 | grad norm avg: 1.46 | grad norm last: 1.42 | 
2026-01-01T11:54:57 | step: 134700 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 7.6108276516606566e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.52 | consumed tokens: 1103462400.0 | grad norm avg: 1.46 | grad norm last: 1.33 | 
2026-01-01T11:55:15 | step: 134800 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 7.5793018368131015e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.5 | consumed tokens: 1104281600.0 | grad norm avg: 1.45 | grad norm last: 1.47 | 
2026-01-01T11:55:33 | step: 134900 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 7.547830136900302e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.66 | consumed tokens: 1105100800.0 | grad norm avg: 1.46 | grad norm last: 1.61 | 
2026-01-01T11:55:51 | step: 135000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 7.516412551922258e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.83 | consumed tokens: 1105920000.0 | grad norm avg: 1.47 | grad norm last: 1.47 | 
2026-01-01T11:56:11 | step: 135100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 7.48504953662632e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.25 | consumed tokens: 1106739200.0 | grad norm avg: 1.47 | grad norm last: 1.75 | 
2026-01-01T11:56:29 | step: 135200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 7.453741091012489e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.8 | consumed tokens: 1107558400.0 | grad norm avg: 1.46 | grad norm last: 1.72 | 
2026-01-01T11:56:47 | step: 135300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 7.422486760333413e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.72 | consumed tokens: 1108377600.0 | grad norm avg: 1.47 | grad norm last: 1.5 | 
2026-01-01T11:57:05 | step: 135400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 7.391287454083795e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.69 | consumed tokens: 1109196800.0 | grad norm avg: 1.48 | grad norm last: 1.4 | 
2026-01-01T11:57:23 | step: 135500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 7.3601431722636335e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.7 | consumed tokens: 1110016000.0 | grad norm avg: 1.49 | grad norm last: 1.51 | 
2026-01-01T11:57:41 | step: 135600 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 7.3290534601255786e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.47 | consumed tokens: 1110835200.0 | grad norm avg: 1.49 | grad norm last: 1.38 | 
2026-01-01T11:57:59 | step: 135700 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 7.298018772416981e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.95 | consumed tokens: 1111654400.0 | grad norm avg: 1.48 | grad norm last: 1.35 | 
2026-01-01T11:58:17 | step: 135800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 7.2670391091378406e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.55 | consumed tokens: 1112473600.0 | grad norm avg: 1.47 | grad norm last: 1.58 | 
2026-01-01T11:58:36 | step: 135900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 7.2361144702881575e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.53 | consumed tokens: 1113292800.0 | grad norm avg: 1.49 | grad norm last: 1.45 | 
2026-01-01T11:58:54 | step: 136000 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 7.2052453106152825e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.41 | consumed tokens: 1114112000.0 | grad norm avg: 1.47 | grad norm last: 1.47 | 
2026-01-01T11:59:12 | step: 136100 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 7.174431630119216e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.67 | consumed tokens: 1114931200.0 | grad norm avg: 1.48 | grad norm last: 1.44 | 
2026-01-01T11:59:32 | step: 136200 | train samples/s: 86.0 | train mfu (16-bit): -1.0 | lr mean: 7.143672974052606e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 3.17 | consumed tokens: 1115750400.0 | grad norm avg: 1.48 | grad norm last: 1.45 | 
2026-01-01T11:59:50 | step: 136300 | train samples/s: 94.7 | train mfu (16-bit): -1.0 | lr mean: 7.112970251910156e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.88 | consumed tokens: 1116569600.0 | grad norm avg: 1.49 | grad norm last: 1.49 | 
2026-01-01T12:00:09 | step: 136400 | train samples/s: 94.7 | train mfu (16-bit): -1.0 | lr mean: 7.082323008944513e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.42 | consumed tokens: 1117388800.0 | grad norm avg: 1.48 | grad norm last: 1.53 | 
2026-01-01T12:00:27 | step: 136500 | train samples/s: 95.2 | train mfu (16-bit): -1.0 | lr mean: 7.05173169990303e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 3.0 | consumed tokens: 1118208000.0 | grad norm avg: 1.48 | grad norm last: 1.47 | 
2026-01-01T12:00:45 | step: 136600 | train samples/s: 94.8 | train mfu (16-bit): -1.0 | lr mean: 7.021195870038355e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.56 | consumed tokens: 1119027200.0 | grad norm avg: 1.49 | grad norm last: 1.41 | 
2026-01-01T12:01:04 | step: 136700 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 6.990715974097839e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.12 | consumed tokens: 1119846400.0 | grad norm avg: 1.48 | grad norm last: 1.42 | 
2026-01-01T12:01:22 | step: 136800 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 6.960292466828832e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 1.86 | consumed tokens: 1120665600.0 | grad norm avg: 1.49 | grad norm last: 1.29 | 
2026-01-01T12:01:40 | step: 136900 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 6.929924893483985e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.48 | consumed tokens: 1121484800.0 | grad norm avg: 1.46 | grad norm last: 1.51 | 
2026-01-01T12:01:58 | step: 137000 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 6.899613254063297e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.56 | consumed tokens: 1122304000.0 | grad norm avg: 1.49 | grad norm last: 1.51 | 
2026-01-01T12:02:17 | step: 137100 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 6.86935845806147e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.34 | consumed tokens: 1123123200.0 | grad norm avg: 1.47 | grad norm last: 1.46 | 
2026-01-01T12:02:35 | step: 137200 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 6.839159595983801e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.73 | consumed tokens: 1123942400.0 | grad norm avg: 1.48 | grad norm last: 1.84 | 
2026-01-01T12:02:53 | step: 137300 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 6.809017577324994e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.39 | consumed tokens: 1124761600.0 | grad norm avg: 1.47 | grad norm last: 1.37 | 
2026-01-01T12:03:11 | step: 137400 | train samples/s: 95.1 | train mfu (16-bit): -1.0 | lr mean: 6.778931947337696e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.44 | consumed tokens: 1125580800.0 | grad norm avg: 1.48 | grad norm last: 1.55 | 
2026-01-01T12:03:30 | step: 137500 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 6.7489031607692596e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.52 | consumed tokens: 1126400000.0 | grad norm avg: 1.5 | grad norm last: 1.6 | 
2026-01-01T12:03:48 | step: 137600 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 6.718930762872333e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.94 | consumed tokens: 1127219200.0 | grad norm avg: 1.48 | grad norm last: 1.45 | 
2026-01-01T12:04:06 | step: 137700 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 6.6890156631416176e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.02 | consumed tokens: 1128038400.0 | grad norm avg: 1.46 | grad norm last: 1.44 | 
2026-01-01T12:04:24 | step: 137800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 6.659157406829763e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.88 | consumed tokens: 1128857600.0 | grad norm avg: 1.48 | grad norm last: 1.61 | 
2026-01-01T12:04:42 | step: 137900 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 6.62935599393677e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.91 | consumed tokens: 1129676800.0 | grad norm avg: 1.47 | grad norm last: 1.54 | 
2026-01-01T12:05:01 | step: 138000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 6.599611879209988e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.58 | consumed tokens: 1130496000.0 | grad norm avg: 1.47 | grad norm last: 1.38 | 
2026-01-01T12:05:19 | step: 138100 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 6.569925062649418e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.73 | consumed tokens: 1131315200.0 | grad norm avg: 1.48 | grad norm last: 1.36 | 
2026-01-01T12:05:37 | step: 138200 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 6.540295544255059e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 3.02 | consumed tokens: 1132134400.0 | grad norm avg: 1.48 | grad norm last: 1.51 | 
2026-01-01T12:05:55 | step: 138300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 6.5107233240269125e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 1.94 | consumed tokens: 1132953600.0 | grad norm avg: 1.48 | grad norm last: 1.37 | 
2026-01-01T12:06:13 | step: 138400 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 6.481208401964977e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.78 | consumed tokens: 1133772800.0 | grad norm avg: 1.48 | grad norm last: 1.53 | 
2026-01-01T12:06:31 | step: 138500 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 6.451751687563956e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.45 | train loss last: 2.5 | consumed tokens: 1134592000.0 | grad norm avg: 1.48 | grad norm last: 1.32 | 
2026-01-01T12:06:49 | step: 138600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 6.422352271329146e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.12 | consumed tokens: 1135411200.0 | grad norm avg: 1.49 | grad norm last: 1.62 | 
2026-01-01T12:07:08 | step: 138700 | train samples/s: 95.0 | train mfu (16-bit): -1.0 | lr mean: 6.3930106080078986e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.56 | consumed tokens: 1136230400.0 | grad norm avg: 1.49 | grad norm last: 1.4 | 
2026-01-01T12:07:26 | step: 138800 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 6.363727152347565e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 3.97 | consumed tokens: 1137049600.0 | grad norm avg: 1.49 | grad norm last: 1.43 | 
2026-01-01T12:07:44 | step: 138900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 6.334501449600793e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.56 | consumed tokens: 1137868800.0 | grad norm avg: 1.49 | grad norm last: 1.36 | 
2026-01-01T12:08:02 | step: 139000 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 6.305333954514936e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.55 | consumed tokens: 1138688000.0 | grad norm avg: 1.48 | grad norm last: 1.55 | 
2026-01-01T12:08:20 | step: 139100 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 6.27622421234264e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.58 | consumed tokens: 1139507200.0 | grad norm avg: 1.48 | grad norm last: 1.46 | 
2026-01-01T12:08:39 | step: 139200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 6.2471731325786095e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.34 | consumed tokens: 1140326400.0 | grad norm avg: 1.47 | grad norm last: 1.45 | 
2026-01-01T12:08:57 | step: 139300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 6.218180260475492e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.73 | consumed tokens: 1141145600.0 | grad norm avg: 1.48 | grad norm last: 1.3 | 
2026-01-01T12:09:15 | step: 139400 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 6.189245596033288e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.16 | consumed tokens: 1141964800.0 | grad norm avg: 1.47 | grad norm last: 1.47 | 
2026-01-01T12:09:33 | step: 139500 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 6.160369593999349e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.75 | consumed tokens: 1142784000.0 | grad norm avg: 1.48 | grad norm last: 1.44 | 
2026-01-01T12:09:51 | step: 139600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 6.131552254373673e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.09 | consumed tokens: 1143603200.0 | grad norm avg: 1.5 | grad norm last: 1.6 | 
2026-01-01T12:10:09 | step: 139700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 6.1027935771562625e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.09 | consumed tokens: 1144422400.0 | grad norm avg: 1.5 | grad norm last: 1.46 | 
2026-01-01T12:10:27 | step: 139800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 6.074093562347116e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.48 | consumed tokens: 1145241600.0 | grad norm avg: 1.47 | grad norm last: 1.59 | 
2026-01-01T12:10:45 | step: 139900 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 6.045452664693585e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.47 | consumed tokens: 1146060800.0 | grad norm avg: 1.47 | grad norm last: 1.4 | 
2026-01-01T12:11:04 | step: 140000 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 6.016870429448318e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.45 | consumed tokens: 1146880000.0 | grad norm avg: 1.47 | grad norm last: 1.42 | 
2026-01-01T12:11:23 | step: 140100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 5.988347766106017e-06 | peak memory rank 0 (MB): 4038.04 | train loss avg: 2.5 | train loss last: 2.75 | consumed tokens: 1147699200.0 | grad norm avg: 1.48 | grad norm last: 1.55 | 
2026-01-01T12:11:41 | step: 140200 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 5.9598837651719805e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.25 | consumed tokens: 1148518400.0 | grad norm avg: 1.48 | grad norm last: 1.43 | 
2026-01-01T12:12:00 | step: 140300 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 5.931478881393559e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.66 | consumed tokens: 1149337600.0 | grad norm avg: 1.47 | grad norm last: 1.4 | 
2026-01-01T12:12:18 | step: 140400 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 5.903133569518104e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 1.84 | consumed tokens: 1150156800.0 | grad norm avg: 1.48 | grad norm last: 1.38 | 
2026-01-01T12:12:36 | step: 140500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 5.874847829545615e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.41 | consumed tokens: 1150976000.0 | grad norm avg: 1.47 | grad norm last: 1.48 | 
2026-01-01T12:12:54 | step: 140600 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 5.8466212067287415e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.02 | consumed tokens: 1151795200.0 | grad norm avg: 1.47 | grad norm last: 1.52 | 
2026-01-01T12:13:12 | step: 140700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 5.818454155814834e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.75 | consumed tokens: 1152614400.0 | grad norm avg: 1.48 | grad norm last: 1.47 | 
2026-01-01T12:13:30 | step: 140800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 5.790347131551243e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.55 | consumed tokens: 1153433600.0 | grad norm avg: 1.48 | grad norm last: 1.49 | 
2026-01-01T12:13:48 | step: 140900 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 5.762299679190619e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.84 | consumed tokens: 1154252800.0 | grad norm avg: 1.47 | grad norm last: 1.34 | 
2026-01-01T12:14:06 | step: 141000 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 5.734311798732961e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.89 | consumed tokens: 1155072000.0 | grad norm avg: 1.49 | grad norm last: 1.46 | 
2026-01-01T12:14:25 | step: 141100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 5.70638439967297e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.11 | consumed tokens: 1155891200.0 | grad norm avg: 1.49 | grad norm last: 1.41 | 
2026-01-01T12:14:43 | step: 141200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 5.678516572515946e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.42 | consumed tokens: 1156710400.0 | grad norm avg: 1.48 | grad norm last: 1.57 | 
2026-01-01T12:15:01 | step: 141300 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 5.650708772009239e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.2 | consumed tokens: 1157529600.0 | grad norm avg: 1.47 | grad norm last: 1.4 | 
2026-01-01T12:15:19 | step: 141400 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 5.622961452900199e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 3.14 | consumed tokens: 1158348800.0 | grad norm avg: 1.48 | grad norm last: 1.59 | 
2026-01-01T12:15:37 | step: 141500 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 5.595274160441477e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.48 | consumed tokens: 1159168000.0 | grad norm avg: 1.48 | grad norm last: 1.44 | 
2026-01-01T12:15:55 | step: 141600 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 5.567647349380422e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.83 | consumed tokens: 1159987200.0 | grad norm avg: 1.48 | grad norm last: 1.58 | 
2026-01-01T12:16:13 | step: 141700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 5.540081019717036e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.7 | consumed tokens: 1160806400.0 | grad norm avg: 1.47 | grad norm last: 1.37 | 
2026-01-01T12:16:31 | step: 141800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 5.512575171451317e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.53 | consumed tokens: 1161625600.0 | grad norm avg: 1.49 | grad norm last: 1.57 | 
2026-01-01T12:16:50 | step: 141900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 5.485130259330617e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 1.61 | consumed tokens: 1162444800.0 | grad norm avg: 1.47 | grad norm last: 1.39 | 
2026-01-01T12:17:08 | step: 142000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 5.457745828607585e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.47 | consumed tokens: 1163264000.0 | grad norm avg: 1.47 | grad norm last: 1.4 | 
2026-01-01T12:17:26 | step: 142100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 5.430421879282221e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 1.8 | consumed tokens: 1164083200.0 | grad norm avg: 1.49 | grad norm last: 1.33 | 
2026-01-01T12:17:44 | step: 142200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 5.403158866101876e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.31 | consumed tokens: 1164902400.0 | grad norm avg: 1.5 | grad norm last: 1.54 | 
2026-01-01T12:18:02 | step: 142300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 5.3759572438139e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.14 | consumed tokens: 1165721600.0 | grad norm avg: 1.48 | grad norm last: 1.48 | 
2026-01-01T12:18:20 | step: 142400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 5.3488161029235926e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.02 | consumed tokens: 1166540800.0 | grad norm avg: 1.48 | grad norm last: 1.52 | 
2026-01-01T12:18:38 | step: 142500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 5.3217363529256545e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.41 | consumed tokens: 1167360000.0 | grad norm avg: 1.49 | grad norm last: 1.45 | 
2026-01-01T12:18:56 | step: 142600 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 5.294717993820086e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.53 | consumed tokens: 1168179200.0 | grad norm avg: 1.48 | grad norm last: 1.37 | 
2026-01-01T12:19:14 | step: 142700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 5.2677605708595365e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.42 | consumed tokens: 1168998400.0 | grad norm avg: 1.47 | grad norm last: 1.44 | 
2026-01-01T12:19:33 | step: 142800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 5.2408649935387075e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.36 | consumed tokens: 1169817600.0 | grad norm avg: 1.5 | grad norm last: 1.46 | 
2026-01-01T12:19:51 | step: 142900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 5.214030352362897e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.28 | consumed tokens: 1170636800.0 | grad norm avg: 1.48 | grad norm last: 1.35 | 
2026-01-01T12:20:09 | step: 143000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 5.1872575568268076e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.66 | consumed tokens: 1171456000.0 | grad norm avg: 1.49 | grad norm last: 1.51 | 
2026-01-01T12:20:27 | step: 143100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 5.1605461521830875e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.19 | consumed tokens: 1172275200.0 | grad norm avg: 1.5 | grad norm last: 1.47 | 
2026-01-01T12:20:45 | step: 143200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 5.133896593179088e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.52 | consumed tokens: 1173094400.0 | grad norm avg: 1.47 | grad norm last: 1.54 | 
2026-01-01T12:21:03 | step: 143300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 5.107308879814809e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.69 | consumed tokens: 1173913600.0 | grad norm avg: 1.48 | grad norm last: 1.49 | 
2026-01-01T12:21:21 | step: 143400 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 5.080783012090251e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.5 | consumed tokens: 1174732800.0 | grad norm avg: 1.48 | grad norm last: 1.52 | 
2026-01-01T12:21:39 | step: 143500 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 5.054318990005413e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.58 | consumed tokens: 1175552000.0 | grad norm avg: 1.49 | grad norm last: 1.46 | 
2026-01-01T12:21:57 | step: 143600 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 5.027917268307647e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.48 | consumed tokens: 1176371200.0 | grad norm avg: 1.48 | grad norm last: 1.53 | 
2026-01-01T12:22:15 | step: 143700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 5.001577392249601e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.34 | consumed tokens: 1177190400.0 | grad norm avg: 1.48 | grad norm last: 1.56 | 
2026-01-01T12:22:33 | step: 143800 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.975299816578627e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.06 | consumed tokens: 1178009600.0 | grad norm avg: 1.48 | grad norm last: 1.58 | 
2026-01-01T12:22:52 | step: 143900 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.949084541294724e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.89 | consumed tokens: 1178828800.0 | grad norm avg: 1.48 | grad norm last: 1.49 | 
2026-01-01T12:23:10 | step: 144000 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 4.922931566397892e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 3.2 | consumed tokens: 1179648000.0 | grad norm avg: 1.47 | grad norm last: 1.41 | 
2026-01-01T12:23:28 | step: 144100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.896841346635483e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.78 | consumed tokens: 1180467200.0 | grad norm avg: 1.47 | grad norm last: 1.64 | 
2026-01-01T12:23:46 | step: 144200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.8708134272601455e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.08 | consumed tokens: 1181286400.0 | grad norm avg: 1.48 | grad norm last: 1.46 | 
2026-01-01T12:24:04 | step: 144300 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.844847808271879e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.69 | consumed tokens: 1182105600.0 | grad norm avg: 1.48 | grad norm last: 1.67 | 
2026-01-01T12:24:22 | step: 144400 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.818945399165386e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.64 | consumed tokens: 1182924800.0 | grad norm avg: 1.48 | grad norm last: 1.52 | 
2026-01-01T12:24:41 | step: 144500 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.793105290445965e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.33 | consumed tokens: 1183744000.0 | grad norm avg: 1.5 | grad norm last: 1.51 | 
2026-01-01T12:24:59 | step: 144600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.7673283916083165e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.41 | consumed tokens: 1184563200.0 | grad norm avg: 1.49 | grad norm last: 1.57 | 
2026-01-01T12:25:17 | step: 144700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.7416142479050905e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.66 | consumed tokens: 1185382400.0 | grad norm avg: 1.48 | grad norm last: 1.4 | 
2026-01-01T12:25:35 | step: 144800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.715962859336287e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.31 | consumed tokens: 1186201600.0 | grad norm avg: 1.47 | grad norm last: 1.48 | 
2026-01-01T12:25:53 | step: 144900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.690375135396607e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.38 | consumed tokens: 1187020800.0 | grad norm avg: 1.48 | grad norm last: 1.39 | 
2026-01-01T12:26:11 | step: 145000 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.66485016659135e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.48 | consumed tokens: 1187840000.0 | grad norm avg: 1.47 | grad norm last: 1.45 | 
2026-01-01T12:26:31 | step: 145100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.639388407667866e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.78 | consumed tokens: 1188659200.0 | grad norm avg: 1.49 | grad norm last: 1.47 | 
2026-01-01T12:26:49 | step: 145200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.613990313373506e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.64 | consumed tokens: 1189478400.0 | grad norm avg: 1.48 | grad norm last: 1.44 | 
2026-01-01T12:27:07 | step: 145300 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.588655428960919e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.34 | consumed tokens: 1190297600.0 | grad norm avg: 1.48 | grad norm last: 1.43 | 
2026-01-01T12:27:25 | step: 145400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.563384209177457e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.8 | consumed tokens: 1191116800.0 | grad norm avg: 1.49 | grad norm last: 1.47 | 
2026-01-01T12:27:43 | step: 145500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.5381761992757674e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.31 | consumed tokens: 1191936000.0 | grad norm avg: 1.48 | grad norm last: 1.55 | 
2026-01-01T12:28:01 | step: 145600 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.513031854003202e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.83 | consumed tokens: 1192755200.0 | grad norm avg: 1.5 | grad norm last: 1.55 | 
2026-01-01T12:28:19 | step: 145700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.487951628107112e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.45 | train loss last: 2.38 | consumed tokens: 1193574400.0 | grad norm avg: 1.49 | grad norm last: 1.56 | 
2026-01-01T12:28:37 | step: 145800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.462934612092795e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.31 | consumed tokens: 1194393600.0 | grad norm avg: 1.47 | grad norm last: 1.48 | 
2026-01-01T12:28:56 | step: 145900 | train samples/s: 93.5 | train mfu (16-bit): -1.0 | lr mean: 4.437982170202304e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 1.99 | consumed tokens: 1195212800.0 | grad norm avg: 1.48 | grad norm last: 1.42 | 
2026-01-01T12:29:14 | step: 146000 | train samples/s: 94.9 | train mfu (16-bit): -1.0 | lr mean: 4.413093392940937e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.84 | consumed tokens: 1196032000.0 | grad norm avg: 1.49 | grad norm last: 1.57 | 
2026-01-01T12:29:33 | step: 146100 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 4.388268280308694e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 3.03 | consumed tokens: 1196851200.0 | grad norm avg: 1.5 | grad norm last: 1.57 | 
2026-01-01T12:29:51 | step: 146200 | train samples/s: 95.3 | train mfu (16-bit): -1.0 | lr mean: 4.3635077418002766e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.59 | consumed tokens: 1197670400.0 | grad norm avg: 1.48 | grad norm last: 1.6 | 
2026-01-01T12:30:09 | step: 146300 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.3388113226683345e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 3.03 | consumed tokens: 1198489600.0 | grad norm avg: 1.47 | grad norm last: 1.52 | 
2026-01-01T12:30:28 | step: 146400 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 4.314179022912867e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.5 | consumed tokens: 1199308800.0 | grad norm avg: 1.49 | grad norm last: 1.52 | 
2026-01-01T12:30:46 | step: 146500 | train samples/s: 95.0 | train mfu (16-bit): -1.0 | lr mean: 4.289610842533875e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.28 | consumed tokens: 1200128000.0 | grad norm avg: 1.5 | grad norm last: 1.59 | 
2026-01-01T12:31:05 | step: 146600 | train samples/s: 93.9 | train mfu (16-bit): -1.0 | lr mean: 4.265107236278709e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.61 | consumed tokens: 1200947200.0 | grad norm avg: 1.49 | grad norm last: 1.42 | 
2026-01-01T12:31:23 | step: 146700 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.240668204147369e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.06 | consumed tokens: 1201766400.0 | grad norm avg: 1.49 | grad norm last: 1.34 | 
2026-01-01T12:31:41 | step: 146800 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.216293746139854e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.8 | consumed tokens: 1202585600.0 | grad norm avg: 1.47 | grad norm last: 1.55 | 
2026-01-01T12:31:59 | step: 146900 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.191983862256166e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.91 | consumed tokens: 1203404800.0 | grad norm avg: 1.5 | grad norm last: 1.6 | 
2026-01-01T12:32:18 | step: 147000 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.167739007243654e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.36 | consumed tokens: 1204224000.0 | grad norm avg: 1.49 | grad norm last: 1.49 | 
2026-01-01T12:32:36 | step: 147100 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.143558726354968e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.56 | consumed tokens: 1205043200.0 | grad norm avg: 1.51 | grad norm last: 1.66 | 
2026-01-01T12:32:54 | step: 147200 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 4.119443019590108e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.59 | consumed tokens: 1205862400.0 | grad norm avg: 1.5 | grad norm last: 1.49 | 
2026-01-01T12:33:12 | step: 147300 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.095392796443775e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.62 | consumed tokens: 1206681600.0 | grad norm avg: 1.5 | grad norm last: 1.5 | 
2026-01-01T12:33:31 | step: 147400 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.071407147421269e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.41 | consumed tokens: 1207500800.0 | grad norm avg: 1.49 | grad norm last: 1.52 | 
2026-01-01T12:33:49 | step: 147500 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.047486527269939e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.73 | consumed tokens: 1208320000.0 | grad norm avg: 1.51 | grad norm last: 1.55 | 
2026-01-01T12:34:07 | step: 147600 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.023631390737137e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.73 | consumed tokens: 1209139200.0 | grad norm avg: 1.49 | grad norm last: 1.6 | 
2026-01-01T12:34:25 | step: 147700 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 3.9998412830755115e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.14 | consumed tokens: 1209958400.0 | grad norm avg: 1.48 | grad norm last: 1.44 | 
2026-01-01T12:34:43 | step: 147800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.976116659032414e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.53 | consumed tokens: 1210777600.0 | grad norm avg: 1.49 | grad norm last: 1.46 | 
2026-01-01T12:35:02 | step: 147900 | train samples/s: 95.0 | train mfu (16-bit): -1.0 | lr mean: 3.952457518607844e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 3.3 | consumed tokens: 1211596800.0 | grad norm avg: 1.48 | grad norm last: 1.66 | 
2026-01-01T12:35:20 | step: 148000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.92886340705445e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.03 | consumed tokens: 1212416000.0 | grad norm avg: 1.49 | grad norm last: 1.45 | 
2026-01-01T12:35:38 | step: 148100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.905335233866936e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.81 | consumed tokens: 1213235200.0 | grad norm avg: 1.49 | grad norm last: 1.58 | 
2026-01-01T12:35:56 | step: 148200 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.8818725442979485e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.7 | consumed tokens: 1214054400.0 | grad norm avg: 1.51 | grad norm last: 1.5 | 
2026-01-01T12:36:14 | step: 148300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.858475338347489e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.47 | consumed tokens: 1214873600.0 | grad norm avg: 1.5 | grad norm last: 1.48 | 
2026-01-01T12:36:32 | step: 148400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.835144070762908e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.75 | consumed tokens: 1215692800.0 | grad norm avg: 1.5 | grad norm last: 1.66 | 
2026-01-01T12:36:50 | step: 148500 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.8118787415442057e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.31 | consumed tokens: 1216512000.0 | grad norm avg: 1.51 | grad norm last: 1.47 | 
2026-01-01T12:37:08 | step: 148600 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.7886791233177064e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.7 | consumed tokens: 1217331200.0 | grad norm avg: 1.51 | grad norm last: 1.57 | 
2026-01-01T12:37:26 | step: 148700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.765545670830761e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.23 | consumed tokens: 1218150400.0 | grad norm avg: 1.49 | grad norm last: 1.51 | 
2026-01-01T12:37:45 | step: 148800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.7424781567096943e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.3 | consumed tokens: 1218969600.0 | grad norm avg: 1.51 | grad norm last: 1.47 | 
2026-01-01T12:38:03 | step: 148900 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 3.719476580954506e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.58 | consumed tokens: 1219788800.0 | grad norm avg: 1.5 | grad norm last: 1.58 | 
2026-01-01T12:38:21 | step: 149000 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.6965413983125472e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.66 | consumed tokens: 1220608000.0 | grad norm avg: 1.48 | grad norm last: 1.37 | 
2026-01-01T12:38:39 | step: 149100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.6736723814101424e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.16 | consumed tokens: 1221427200.0 | grad norm avg: 1.49 | grad norm last: 1.56 | 
2026-01-01T12:38:57 | step: 149200 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 3.650869757620967e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.59 | consumed tokens: 1222246400.0 | grad norm avg: 1.49 | grad norm last: 1.47 | 
2026-01-01T12:39:15 | step: 149300 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 3.628133526945021e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.75 | consumed tokens: 1223065600.0 | grad norm avg: 1.5 | grad norm last: 1.53 | 
2026-01-01T12:39:34 | step: 149400 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.6054636893823044e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.56 | consumed tokens: 1223884800.0 | grad norm avg: 1.5 | grad norm last: 1.5 | 
2026-01-01T12:39:52 | step: 149500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.5828602449328173e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.66 | consumed tokens: 1224704000.0 | grad norm avg: 1.49 | grad norm last: 1.44 | 
2026-01-01T12:40:10 | step: 149600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.5603236483439105e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.34 | consumed tokens: 1225523200.0 | grad norm avg: 1.47 | grad norm last: 1.44 | 
2026-01-01T12:40:28 | step: 149700 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.5378536722419085e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.55 | consumed tokens: 1226342400.0 | grad norm avg: 1.51 | grad norm last: 1.45 | 
2026-01-01T12:40:46 | step: 149800 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.515450544000487e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.48 | consumed tokens: 1227161600.0 | grad norm avg: 1.48 | grad norm last: 1.52 | 
2026-01-01T12:41:04 | step: 149900 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.49311403624597e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.33 | consumed tokens: 1227980800.0 | grad norm avg: 1.48 | grad norm last: 1.43 | 
2026-01-01T12:41:22 | step: 150000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.4708443763520336e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.59 | consumed tokens: 1228800000.0 | grad norm avg: 1.48 | grad norm last: 1.61 | 
2026-01-01T12:41:42 | step: 150100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.448641791692353e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.73 | consumed tokens: 1229619200.0 | grad norm avg: 1.48 | grad norm last: 1.49 | 
2026-01-01T12:42:00 | step: 150200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.426506282266928e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.0 | consumed tokens: 1230438400.0 | grad norm avg: 1.5 | grad norm last: 1.48 | 
2026-01-01T12:42:18 | step: 150300 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.4044378480757587e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.7 | consumed tokens: 1231257600.0 | grad norm avg: 1.5 | grad norm last: 1.46 | 
2026-01-01T12:42:36 | step: 150400 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.382436489118845e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.41 | consumed tokens: 1232076800.0 | grad norm avg: 1.49 | grad norm last: 1.45 | 
2026-01-01T12:42:55 | step: 150500 | train samples/s: 95.2 | train mfu (16-bit): -1.0 | lr mean: 3.360502432769863e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.16 | consumed tokens: 1232896000.0 | grad norm avg: 1.48 | grad norm last: 1.57 | 
2026-01-01T12:43:13 | step: 150600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.338635679028812e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.39 | consumed tokens: 1233715200.0 | grad norm avg: 1.49 | grad norm last: 1.44 | 
2026-01-01T12:43:31 | step: 150700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.316836227895692e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.66 | consumed tokens: 1234534400.0 | grad norm avg: 1.49 | grad norm last: 1.47 | 
2026-01-01T12:43:49 | step: 150800 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.2951043067441788e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.45 | train loss last: 2.77 | consumed tokens: 1235353600.0 | grad norm avg: 1.48 | grad norm last: 1.53 | 
2026-01-01T12:44:07 | step: 150900 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.273439915574272e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 1.9 | consumed tokens: 1236172800.0 | grad norm avg: 1.49 | grad norm last: 1.57 | 
2026-01-01T12:44:25 | step: 151000 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 3.251843054385972e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.95 | consumed tokens: 1236992000.0 | grad norm avg: 1.49 | grad norm last: 1.46 | 
2026-01-01T12:44:43 | step: 151100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.230313723179279e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.45 | train loss last: 2.19 | consumed tokens: 1237811200.0 | grad norm avg: 1.48 | grad norm last: 1.33 | 
2026-01-01T12:45:01 | step: 151200 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.2088521493278677e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.42 | consumed tokens: 1238630400.0 | grad norm avg: 1.5 | grad norm last: 1.47 | 
2026-01-01T12:45:19 | step: 151300 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.1874583328317385e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.48 | consumed tokens: 1239449600.0 | grad norm avg: 1.49 | grad norm last: 1.46 | 
2026-01-01T12:45:37 | step: 151400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.166132501064567e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.73 | consumed tokens: 1240268800.0 | grad norm avg: 1.48 | grad norm last: 1.51 | 
2026-01-01T12:45:56 | step: 151500 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.1448744266526774e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.33 | consumed tokens: 1241088000.0 | grad norm avg: 1.49 | grad norm last: 1.39 | 
2026-01-01T12:46:14 | step: 151600 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.1236843369697453e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.36 | consumed tokens: 1241907200.0 | grad norm avg: 1.49 | grad norm last: 1.55 | 
2026-01-01T12:46:32 | step: 151700 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 3.102562232015771e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.69 | consumed tokens: 1242726400.0 | grad norm avg: 1.49 | grad norm last: 1.51 | 
2026-01-01T12:46:50 | step: 151800 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 3.0815083391644293e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.33 | consumed tokens: 1243545600.0 | grad norm avg: 1.48 | grad norm last: 1.58 | 
2026-01-01T12:47:08 | step: 151900 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.0605224310420454e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.62 | consumed tokens: 1244364800.0 | grad norm avg: 1.48 | grad norm last: 1.42 | 
2026-01-01T12:47:26 | step: 152000 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.0396049623959698e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.33 | consumed tokens: 1245184000.0 | grad norm avg: 1.48 | grad norm last: 1.52 | 
2026-01-01T12:47:45 | step: 152100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.018755705852527e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.34 | consumed tokens: 1246003200.0 | grad norm avg: 1.48 | grad norm last: 1.63 | 
2026-01-01T12:48:03 | step: 152200 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 2.997974888785393e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.64 | consumed tokens: 1246822400.0 | grad norm avg: 1.49 | grad norm last: 1.61 | 
2026-01-01T12:48:21 | step: 152300 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.9772622838208918e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.62 | consumed tokens: 1247641600.0 | grad norm avg: 1.49 | grad norm last: 1.29 | 
2026-01-01T12:48:39 | step: 152400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.9566183457063744e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.48 | consumed tokens: 1248460800.0 | grad norm avg: 1.49 | grad norm last: 1.38 | 
2026-01-01T12:48:57 | step: 152500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.9360428470681654e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.56 | consumed tokens: 1249280000.0 | grad norm avg: 1.48 | grad norm last: 1.53 | 
2026-01-01T12:49:15 | step: 152600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.9155360152799403e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.53 | consumed tokens: 1250099200.0 | grad norm avg: 1.49 | grad norm last: 1.56 | 
2026-01-01T12:49:33 | step: 152700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.895097850341699e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.45 | train loss last: 1.75 | consumed tokens: 1250918400.0 | grad norm avg: 1.5 | grad norm last: 1.51 | 
2026-01-01T12:49:51 | step: 152800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.874728579627117e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 3.09 | consumed tokens: 1251737600.0 | grad norm avg: 1.51 | grad norm last: 1.48 | 
2026-01-01T12:50:10 | step: 152900 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.854427975762519e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.7 | consumed tokens: 1252556800.0 | grad norm avg: 1.49 | grad norm last: 1.47 | 
2026-01-01T12:50:28 | step: 153000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.8341962661215803e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.61 | consumed tokens: 1253376000.0 | grad norm avg: 1.51 | grad norm last: 1.45 | 
2026-01-01T12:50:46 | step: 153100 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 2.8140334507043008e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.33 | consumed tokens: 1254195200.0 | grad norm avg: 1.48 | grad norm last: 1.53 | 
2026-01-01T12:51:04 | step: 153200 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.793939756884356e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.53 | consumed tokens: 1255014400.0 | grad norm avg: 1.51 | grad norm last: 1.38 | 
2026-01-01T12:51:22 | step: 153300 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.7739149572880706e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.84 | consumed tokens: 1255833600.0 | grad norm avg: 1.5 | grad norm last: 1.45 | 
2026-01-01T12:51:40 | step: 153400 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.75395927928912e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.36 | consumed tokens: 1256652800.0 | grad norm avg: 1.5 | grad norm last: 1.53 | 
2026-01-01T12:51:59 | step: 153500 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.7340729502611794e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.27 | consumed tokens: 1257472000.0 | grad norm avg: 1.51 | grad norm last: 1.41 | 
2026-01-01T12:52:17 | step: 153600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.7142557428305736e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.36 | consumed tokens: 1258291200.0 | grad norm avg: 1.5 | grad norm last: 1.48 | 
2026-01-01T12:52:35 | step: 153700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.694507884370978e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.47 | consumed tokens: 1259110400.0 | grad norm avg: 1.49 | grad norm last: 1.47 | 
2026-01-01T12:52:53 | step: 153800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.6748293748823926e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.41 | consumed tokens: 1259929600.0 | grad norm avg: 1.49 | grad norm last: 1.54 | 
2026-01-01T12:53:11 | step: 153900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.655220441738493e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.58 | consumed tokens: 1260748800.0 | grad norm avg: 1.51 | grad norm last: 1.53 | 
2026-01-01T12:53:29 | step: 154000 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.6356808575656032e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.41 | consumed tokens: 1261568000.0 | grad norm avg: 1.5 | grad norm last: 1.48 | 
2026-01-01T12:53:47 | step: 154100 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 2.6162108497373993e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.52 | consumed tokens: 1262387200.0 | grad norm avg: 1.48 | grad norm last: 1.42 | 
2026-01-01T12:54:05 | step: 154200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.596810418253881e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.58 | consumed tokens: 1263206400.0 | grad norm avg: 1.49 | grad norm last: 1.46 | 
2026-01-01T12:54:23 | step: 154300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.5774795631150482e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.28 | consumed tokens: 1264025600.0 | grad norm avg: 1.49 | grad norm last: 1.7 | 
2026-01-01T12:54:42 | step: 154400 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 2.5582185116945766e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.3 | consumed tokens: 1264844800.0 | grad norm avg: 1.5 | grad norm last: 1.42 | 
2026-01-01T12:55:00 | step: 154500 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 2.539027263992466e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.61 | consumed tokens: 1265664000.0 | grad norm avg: 1.49 | grad norm last: 1.43 | 
2026-01-01T12:55:18 | step: 154600 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.519906047382392e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.02 | consumed tokens: 1266483200.0 | grad norm avg: 1.5 | grad norm last: 1.4 | 
2026-01-01T12:55:36 | step: 154700 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 2.5008544071170036e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.47 | consumed tokens: 1267302400.0 | grad norm avg: 1.5 | grad norm last: 1.51 | 
2026-01-01T12:55:54 | step: 154800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.481873025317327e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.56 | consumed tokens: 1268121600.0 | grad norm avg: 1.51 | grad norm last: 1.39 | 
2026-01-01T12:56:12 | step: 154900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.4629614472360117e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.31 | consumed tokens: 1268940800.0 | grad norm avg: 1.49 | grad norm last: 1.47 | 
2026-01-01T12:56:31 | step: 155000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.4441201276204083e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.41 | consumed tokens: 1269760000.0 | grad norm avg: 1.5 | grad norm last: 1.55 | 
2026-01-01T12:56:50 | step: 155100 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 2.4253488390968414e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.33 | consumed tokens: 1270579200.0 | grad norm avg: 1.5 | grad norm last: 1.57 | 
2026-01-01T12:57:08 | step: 155200 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.4066478090389865e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.34 | consumed tokens: 1271398400.0 | grad norm avg: 1.5 | grad norm last: 1.38 | 
2026-01-01T12:57:27 | step: 155300 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 2.3880170374468435e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.75 | consumed tokens: 1272217600.0 | grad norm avg: 1.52 | grad norm last: 1.42 | 
2026-01-01T12:57:45 | step: 155400 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.3694565243204124e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.45 | train loss last: 2.25 | consumed tokens: 1273036800.0 | grad norm avg: 1.5 | grad norm last: 1.38 | 
2026-01-01T12:58:03 | step: 155500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.350966497033369e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 1.68 | consumed tokens: 1273856000.0 | grad norm avg: 1.51 | grad norm last: 1.5 | 
2026-01-01T12:58:21 | step: 155600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.3325469555857126e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.56 | consumed tokens: 1274675200.0 | grad norm avg: 1.49 | grad norm last: 1.7 | 
2026-01-01T12:58:39 | step: 155700 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 2.3141976726037683e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.8 | consumed tokens: 1275494400.0 | grad norm avg: 1.48 | grad norm last: 1.41 | 
2026-01-01T12:58:57 | step: 155800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.295919102834887e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.81 | consumed tokens: 1276313600.0 | grad norm avg: 1.5 | grad norm last: 1.41 | 
2026-01-01T12:59:15 | step: 155900 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.2777112462790683e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.36 | consumed tokens: 1277132800.0 | grad norm avg: 1.49 | grad norm last: 1.55 | 
2026-01-01T12:59:34 | step: 156000 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.259573875562637e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 1.8 | consumed tokens: 1277952000.0 | grad norm avg: 1.51 | grad norm last: 1.53 | 
2026-01-01T12:59:52 | step: 156100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.2415072180592688e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.88 | consumed tokens: 1278771200.0 | grad norm avg: 1.51 | grad norm last: 1.55 | 
2026-01-01T13:00:10 | step: 156200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.2235112737689633e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.36 | consumed tokens: 1279590400.0 | grad norm avg: 1.49 | grad norm last: 1.49 | 
2026-01-01T13:00:28 | step: 156300 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.205586270065396e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.08 | consumed tokens: 1280409600.0 | grad norm avg: 1.49 | grad norm last: 1.47 | 
2026-01-01T13:00:46 | step: 156400 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.187732206948567e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.52 | consumed tokens: 1281228800.0 | grad norm avg: 1.5 | grad norm last: 1.57 | 
2026-01-01T13:01:04 | step: 156500 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 2.1699490844184766e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.52 | consumed tokens: 1282048000.0 | grad norm avg: 1.49 | grad norm last: 1.49 | 
2026-01-01T13:01:22 | step: 156600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.1522369024751242e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.69 | consumed tokens: 1282867200.0 | grad norm avg: 1.5 | grad norm last: 1.44 | 
2026-01-01T13:01:40 | step: 156700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.13459566111851e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.72 | consumed tokens: 1283686400.0 | grad norm avg: 1.5 | grad norm last: 1.48 | 
2026-01-01T13:01:59 | step: 156800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.11702558772231e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.78 | consumed tokens: 1284505600.0 | grad norm avg: 1.48 | grad norm last: 1.44 | 
2026-01-01T13:02:17 | step: 156900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.0995269096601987e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.12 | consumed tokens: 1285324800.0 | grad norm avg: 1.5 | grad norm last: 1.46 | 
2026-01-01T13:02:35 | step: 157000 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 2.082099172184826e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.52 | consumed tokens: 1286144000.0 | grad norm avg: 1.49 | grad norm last: 1.6 | 
2026-01-01T13:02:53 | step: 157100 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 2.064742830043542e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.23 | consumed tokens: 1286963200.0 | grad norm avg: 1.49 | grad norm last: 1.62 | 
2026-01-01T13:03:11 | step: 157200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.0474576558626723e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.73 | consumed tokens: 1287782400.0 | grad norm avg: 1.51 | grad norm last: 1.46 | 
2026-01-01T13:03:29 | step: 157300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.030244104389567e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.55 | consumed tokens: 1288601600.0 | grad norm avg: 1.5 | grad norm last: 1.51 | 
2026-01-01T13:03:48 | step: 157400 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.0131017208768753e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.23 | consumed tokens: 1289420800.0 | grad norm avg: 1.51 | grad norm last: 1.53 | 
2026-01-01T13:04:06 | step: 157500 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.9960309600719484e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.09 | consumed tokens: 1290240000.0 | grad norm avg: 1.49 | grad norm last: 1.55 | 
2026-01-01T13:04:24 | step: 157600 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.979031821974786e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.83 | consumed tokens: 1291059200.0 | grad norm avg: 1.51 | grad norm last: 1.48 | 
2026-01-01T13:04:42 | step: 157700 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.962104079211713e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.86 | consumed tokens: 1291878400.0 | grad norm avg: 1.5 | grad norm last: 1.52 | 
2026-01-01T13:05:00 | step: 157800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.9452481865300797e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.08 | consumed tokens: 1292697600.0 | grad norm avg: 1.49 | grad norm last: 1.49 | 
2026-01-01T13:05:18 | step: 157900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.928463916556211e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 1.99 | consumed tokens: 1293516800.0 | grad norm avg: 1.49 | grad norm last: 1.38 | 
2026-01-01T13:05:36 | step: 158000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.9117512692901073e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.38 | consumed tokens: 1294336000.0 | grad norm avg: 1.5 | grad norm last: 1.56 | 
2026-01-01T13:05:55 | step: 158100 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.8951105857922812e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.42 | consumed tokens: 1295155200.0 | grad norm avg: 1.5 | grad norm last: 1.46 | 
2026-01-01T13:06:13 | step: 158200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 1.8785416386890574e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.8 | consumed tokens: 1295974400.0 | grad norm avg: 1.48 | grad norm last: 1.48 | 
2026-01-01T13:06:31 | step: 158300 | train samples/s: 95.2 | train mfu (16-bit): -1.0 | lr mean: 1.8620446553541115e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.52 | consumed tokens: 1296793600.0 | grad norm avg: 1.49 | grad norm last: 1.53 | 
2026-01-01T13:06:49 | step: 158400 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.8456196357874433e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.88 | consumed tokens: 1297612800.0 | grad norm avg: 1.5 | grad norm last: 1.42 | 
2026-01-01T13:07:07 | step: 158500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.8292665799890528e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.73 | consumed tokens: 1298432000.0 | grad norm avg: 1.5 | grad norm last: 1.37 | 
2026-01-01T13:07:25 | step: 158600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.812985601645778e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.28 | consumed tokens: 1299251200.0 | grad norm avg: 1.51 | grad norm last: 1.43 | 
2026-01-01T13:07:43 | step: 158700 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 1.7967767007576185e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.31 | consumed tokens: 1300070400.0 | grad norm avg: 1.53 | grad norm last: 1.5 | 
2026-01-01T13:08:01 | step: 158800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.7806399910114123e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.91 | consumed tokens: 1300889600.0 | grad norm avg: 1.49 | grad norm last: 1.53 | 
2026-01-01T13:08:20 | step: 158900 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.7645754724071594e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.73 | consumed tokens: 1301708800.0 | grad norm avg: 1.5 | grad norm last: 1.44 | 
2026-01-01T13:08:38 | step: 159000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.7485832586316974e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.12 | consumed tokens: 1302528000.0 | grad norm avg: 1.5 | grad norm last: 1.43 | 
2026-01-01T13:08:56 | step: 159100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.7326632359981886e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.7 | consumed tokens: 1303347200.0 | grad norm avg: 1.5 | grad norm last: 1.57 | 
2026-01-01T13:09:14 | step: 159200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.7168156318803085e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.61 | consumed tokens: 1304166400.0 | grad norm avg: 1.5 | grad norm last: 1.68 | 
2026-01-01T13:09:32 | step: 159300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.701040446278057e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.52 | consumed tokens: 1304985600.0 | grad norm avg: 1.5 | grad norm last: 1.48 | 
2026-01-01T13:09:50 | step: 159400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.6853376791914343e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 3.17 | consumed tokens: 1305804800.0 | grad norm avg: 1.5 | grad norm last: 1.45 | 
2026-01-01T13:10:08 | step: 159500 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.669707444307278e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.16 | consumed tokens: 1306624000.0 | grad norm avg: 1.48 | grad norm last: 1.43 | 
2026-01-01T13:10:27 | step: 159600 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 1.654149741625588e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.98 | consumed tokens: 1307443200.0 | grad norm avg: 1.51 | grad norm last: 1.51 | 
2026-01-01T13:10:45 | step: 159700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.638664684833202e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.73 | consumed tokens: 1308262400.0 | grad norm avg: 1.49 | grad norm last: 1.5 | 
2026-01-01T13:11:03 | step: 159800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.6232522739301203e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.56 | consumed tokens: 1309081600.0 | grad norm avg: 1.52 | grad norm last: 1.39 | 
2026-01-01T13:11:21 | step: 159900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.6079125089163426e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.48 | consumed tokens: 1309900800.0 | grad norm avg: 1.51 | grad norm last: 1.59 | 
2026-01-01T13:11:39 | step: 160000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.5926455034787068e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.41 | consumed tokens: 1310720000.0 | grad norm avg: 1.51 | grad norm last: 1.6 | 
2026-01-01T13:11:58 | step: 160100 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 1.5774512576172128e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.45 | train loss last: 1.74 | consumed tokens: 1311539200.0 | grad norm avg: 1.5 | grad norm last: 1.43 | 
2026-01-01T13:12:17 | step: 160200 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.5623298850186984e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.5 | consumed tokens: 1312358400.0 | grad norm avg: 1.5 | grad norm last: 1.39 | 
2026-01-01T13:12:35 | step: 160300 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.5472813856831635e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.48 | consumed tokens: 1313177600.0 | grad norm avg: 1.52 | grad norm last: 1.46 | 
2026-01-01T13:12:53 | step: 160400 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.532305873297446e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.64 | consumed tokens: 1313996800.0 | grad norm avg: 1.5 | grad norm last: 1.59 | 
2026-01-01T13:13:11 | step: 160500 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 1.517403234174708e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.75 | consumed tokens: 1314816000.0 | grad norm avg: 1.51 | grad norm last: 1.38 | 
2026-01-01T13:13:29 | step: 160600 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 1.5025736956886249e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.52 | consumed tokens: 1315635200.0 | grad norm avg: 1.52 | grad norm last: 1.49 | 
2026-01-01T13:13:48 | step: 160700 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.4878172578391968e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.3 | consumed tokens: 1316454400.0 | grad norm avg: 1.51 | grad norm last: 1.43 | 
2026-01-01T13:14:06 | step: 160800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.473133806939586e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.14 | consumed tokens: 1317273600.0 | grad norm avg: 1.5 | grad norm last: 1.4 | 
2026-01-01T13:14:24 | step: 160900 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 1.458523570363468e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.02 | consumed tokens: 1318092800.0 | grad norm avg: 1.5 | grad norm last: 1.49 | 
2026-01-01T13:14:42 | step: 161000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.4439866617976804e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.48 | consumed tokens: 1318912000.0 | grad norm avg: 1.51 | grad norm last: 1.48 | 
2026-01-01T13:15:00 | step: 161100 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.4295228538685478e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.53 | consumed tokens: 1319731200.0 | grad norm avg: 1.5 | grad norm last: 1.5 | 
2026-01-01T13:15:19 | step: 161200 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 1.4151323739497457e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.62 | consumed tokens: 1320550400.0 | grad norm avg: 1.49 | grad norm last: 1.51 | 
2026-01-01T13:15:37 | step: 161300 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 1.4008153357281117e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.67 | consumed tokens: 1321369600.0 | grad norm avg: 1.51 | grad norm last: 1.48 | 
2026-01-01T13:15:55 | step: 161400 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.3865715118299704e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.53 | consumed tokens: 1322188800.0 | grad norm avg: 1.5 | grad norm last: 1.71 | 
2026-01-01T13:16:13 | step: 161500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.372401243315835e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.31 | consumed tokens: 1323008000.0 | grad norm avg: 1.49 | grad norm last: 1.58 | 
2026-01-01T13:16:31 | step: 161600 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.3583044164988678e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.39 | consumed tokens: 1323827200.0 | grad norm avg: 1.5 | grad norm last: 1.45 | 
2026-01-01T13:16:49 | step: 161700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.3442811450659065e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.62 | consumed tokens: 1324646400.0 | grad norm avg: 1.5 | grad norm last: 1.56 | 
2026-01-01T13:17:07 | step: 161800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.330331429016951e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.14 | consumed tokens: 1325465600.0 | grad norm avg: 1.5 | grad norm last: 1.49 | 
2026-01-01T13:17:25 | step: 161900 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.3164552683520014e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.45 | train loss last: 2.14 | consumed tokens: 1326284800.0 | grad norm avg: 1.51 | grad norm last: 1.62 | 
2026-01-01T13:17:44 | step: 162000 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.3026527767578955e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.91 | consumed tokens: 1327104000.0 | grad norm avg: 1.52 | grad norm last: 1.59 | 
2026-01-01T13:18:02 | step: 162100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.2889239542346331e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.45 | train loss last: 2.56 | consumed tokens: 1327923200.0 | grad norm avg: 1.51 | grad norm last: 1.57 | 
2026-01-01T13:18:20 | step: 162200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.2752689144690521e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.61 | consumed tokens: 1328742400.0 | grad norm avg: 1.5 | grad norm last: 1.49 | 
2026-01-01T13:18:38 | step: 162300 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 1.2616876574611524e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.81 | consumed tokens: 1329561600.0 | grad norm avg: 1.51 | grad norm last: 1.53 | 
2026-01-01T13:18:56 | step: 162400 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.248180183210934e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.44 | consumed tokens: 1330380800.0 | grad norm avg: 1.51 | grad norm last: 1.49 | 
2026-01-01T13:19:14 | step: 162500 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 1.234746491718397e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.55 | consumed tokens: 1331200000.0 | grad norm avg: 1.49 | grad norm last: 1.42 | 
2026-01-01T13:19:33 | step: 162600 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 1.2213868103572167e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.14 | consumed tokens: 1332019200.0 | grad norm avg: 1.5 | grad norm last: 1.48 | 
2026-01-01T13:19:51 | step: 162700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.2081010254405555e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.36 | consumed tokens: 1332838400.0 | grad norm avg: 1.5 | grad norm last: 1.43 | 
2026-01-01T13:20:09 | step: 162800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.194889250655251e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.62 | consumed tokens: 1333657600.0 | grad norm avg: 1.51 | grad norm last: 1.51 | 
2026-01-01T13:20:27 | step: 162900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.1817514860013034e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.56 | consumed tokens: 1334476800.0 | grad norm avg: 1.51 | grad norm last: 1.38 | 
2026-01-01T13:20:45 | step: 163000 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.1686878451655502e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.7 | consumed tokens: 1335296000.0 | grad norm avg: 1.51 | grad norm last: 1.53 | 
2026-01-01T13:21:03 | step: 163100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 1.1556982144611538e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.92 | consumed tokens: 1336115200.0 | grad norm avg: 1.51 | grad norm last: 1.6 | 
2026-01-01T13:21:21 | step: 163200 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.1427828212617896e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.66 | consumed tokens: 1336934400.0 | grad norm avg: 1.52 | grad norm last: 1.47 | 
2026-01-01T13:21:39 | step: 163300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.12994155188062e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.42 | consumed tokens: 1337753600.0 | grad norm avg: 1.5 | grad norm last: 1.51 | 
2026-01-01T13:21:57 | step: 163400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.1171745200044825e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.81 | consumed tokens: 1338572800.0 | grad norm avg: 1.52 | grad norm last: 1.59 | 
2026-01-01T13:22:16 | step: 163500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.104481839320215e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.69 | consumed tokens: 1339392000.0 | grad norm avg: 1.49 | grad norm last: 1.37 | 
2026-01-01T13:22:34 | step: 163600 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 1.0918633961409796e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.17 | consumed tokens: 1340211200.0 | grad norm avg: 1.51 | grad norm last: 1.5 | 
2026-01-01T13:22:52 | step: 163700 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.0793193041536142e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.31 | consumed tokens: 1341030400.0 | grad norm avg: 1.5 | grad norm last: 1.4 | 
2026-01-01T13:23:10 | step: 163800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.0668495633581188e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.45 | train loss last: 2.16 | consumed tokens: 1341849600.0 | grad norm avg: 1.51 | grad norm last: 1.47 | 
2026-01-01T13:23:28 | step: 163900 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.054454287441331e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.38 | consumed tokens: 1342668800.0 | grad norm avg: 1.5 | grad norm last: 1.44 | 
2026-01-01T13:23:46 | step: 164000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.0421334764032508e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.75 | consumed tokens: 1343488000.0 | grad norm avg: 1.49 | grad norm last: 1.44 | 
2026-01-01T13:24:04 | step: 164100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.0298871302438783e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.44 | consumed tokens: 1344307200.0 | grad norm avg: 1.5 | grad norm last: 1.32 | 
2026-01-01T13:24:22 | step: 164200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.0177153626500512e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.45 | train loss last: 2.61 | consumed tokens: 1345126400.0 | grad norm avg: 1.5 | grad norm last: 1.6 | 
2026-01-01T13:24:41 | step: 164300 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.0056180599349318e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.44 | consumed tokens: 1345945600.0 | grad norm avg: 1.52 | grad norm last: 1.57 | 
2026-01-01T13:24:59 | step: 164400 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 9.935955631590332e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 3.11 | consumed tokens: 1346764800.0 | grad norm avg: 1.49 | grad norm last: 1.4 | 
2026-01-01T13:25:17 | step: 164500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 9.816475312618422e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.58 | consumed tokens: 1347584000.0 | grad norm avg: 1.51 | grad norm last: 1.47 | 
2026-01-01T13:25:35 | step: 164600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 9.69774305303872e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.19 | consumed tokens: 1348403200.0 | grad norm avg: 1.5 | grad norm last: 1.38 | 
2026-01-01T13:25:53 | step: 164700 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 9.57975771598285e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.42 | consumed tokens: 1349222400.0 | grad norm avg: 1.49 | grad norm last: 1.47 | 
2026-01-01T13:26:11 | step: 164800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 9.462519869885e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.17 | consumed tokens: 1350041600.0 | grad norm avg: 1.51 | grad norm last: 1.48 | 
2026-01-01T13:26:30 | step: 164900 | train samples/s: 95.3 | train mfu (16-bit): -1.0 | lr mean: 9.346030083179357e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.78 | consumed tokens: 1350860800.0 | grad norm avg: 1.51 | grad norm last: 1.41 | 
2026-01-01T13:26:48 | step: 165000 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 9.230288924300112e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.3 | consumed tokens: 1351680000.0 | grad norm avg: 1.51 | grad norm last: 1.47 | 
2026-01-01T13:27:07 | step: 165100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 9.115296393247263e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.22 | consumed tokens: 1352499200.0 | grad norm avg: 1.51 | grad norm last: 1.47 | 
2026-01-01T13:27:25 | step: 165200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 9.001052490020811e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.47 | consumed tokens: 1353318400.0 | grad norm avg: 1.5 | grad norm last: 1.49 | 
2026-01-01T13:27:43 | step: 165300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 8.887558351489133e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.33 | consumed tokens: 1354137600.0 | grad norm avg: 1.5 | grad norm last: 1.51 | 
2026-01-01T13:28:02 | step: 165400 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 8.774813977652229e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.22 | consumed tokens: 1354956800.0 | grad norm avg: 1.51 | grad norm last: 1.49 | 
2026-01-01T13:28:20 | step: 165500 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 8.6628193685101e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.66 | consumed tokens: 1355776000.0 | grad norm avg: 1.51 | grad norm last: 1.61 | 
2026-01-01T13:28:38 | step: 165600 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 8.551575660931121e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.31 | consumed tokens: 1356595200.0 | grad norm avg: 1.52 | grad norm last: 1.55 | 
2026-01-01T13:28:56 | step: 165700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 8.441082854915294e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.48 | consumed tokens: 1357414400.0 | grad norm avg: 1.49 | grad norm last: 1.52 | 
2026-01-01T13:29:14 | step: 165800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 8.331340950462618e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.55 | consumed tokens: 1358233600.0 | grad norm avg: 1.51 | grad norm last: 1.48 | 
2026-01-01T13:29:32 | step: 165900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 8.222350516007282e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.19 | consumed tokens: 1359052800.0 | grad norm avg: 1.51 | grad norm last: 1.46 | 
2026-01-01T13:29:50 | step: 166000 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 8.114111551549286e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 3.16 | consumed tokens: 1359872000.0 | grad norm avg: 1.5 | grad norm last: 1.48 | 
2026-01-01T13:30:08 | step: 166100 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 8.006625193957007e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.92 | consumed tokens: 1360691200.0 | grad norm avg: 1.51 | grad norm last: 1.61 | 
2026-01-01T13:30:27 | step: 166200 | train samples/s: 94.9 | train mfu (16-bit): -1.0 | lr mean: 7.899891443230445e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.58 | consumed tokens: 1361510400.0 | grad norm avg: 1.52 | grad norm last: 1.48 | 
2026-01-01T13:30:45 | step: 166300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 7.7939102993696e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.62 | consumed tokens: 1362329600.0 | grad norm avg: 1.51 | grad norm last: 1.73 | 
2026-01-01T13:31:03 | step: 166400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 7.688682899242849e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.36 | consumed tokens: 1363148800.0 | grad norm avg: 1.51 | grad norm last: 1.51 | 
2026-01-01T13:31:21 | step: 166500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 7.584208105981816e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.61 | consumed tokens: 1363968000.0 | grad norm avg: 1.52 | grad norm last: 1.43 | 
2026-01-01T13:31:39 | step: 166600 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 7.480487624889065e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.14 | consumed tokens: 1364787200.0 | grad norm avg: 1.5 | grad norm last: 1.54 | 
2026-01-01T13:31:57 | step: 166700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 7.377521455964597e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.2 | consumed tokens: 1365606400.0 | grad norm avg: 1.51 | grad norm last: 1.6 | 
2026-01-01T13:32:15 | step: 166800 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 7.275309030774224e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.8 | consumed tokens: 1366425600.0 | grad norm avg: 1.51 | grad norm last: 1.32 | 
2026-01-01T13:32:33 | step: 166900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 7.173852054620511e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.23 | consumed tokens: 1367244800.0 | grad norm avg: 1.49 | grad norm last: 1.44 | 
2026-01-01T13:32:51 | step: 167000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 7.073149959069269e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.45 | train loss last: 2.33 | consumed tokens: 1368064000.0 | grad norm avg: 1.5 | grad norm last: 1.55 | 
2026-01-01T13:33:10 | step: 167100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 6.973203312554688e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.5 | consumed tokens: 1368883200.0 | grad norm avg: 1.5 | grad norm last: 1.46 | 
2026-01-01T13:33:28 | step: 167200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 6.874012115076766e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.98 | consumed tokens: 1369702400.0 | grad norm avg: 1.51 | grad norm last: 1.41 | 
2026-01-01T13:33:46 | step: 167300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 6.775577503503882e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.25 | consumed tokens: 1370521600.0 | grad norm avg: 1.51 | grad norm last: 1.6 | 
2026-01-01T13:34:04 | step: 167400 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 6.677898909401847e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.19 | consumed tokens: 1371340800.0 | grad norm avg: 1.51 | grad norm last: 1.47 | 
2026-01-01T13:34:22 | step: 167500 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 6.580976901204849e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.45 | train loss last: 2.27 | consumed tokens: 1372160000.0 | grad norm avg: 1.5 | grad norm last: 1.64 | 
2026-01-01T13:34:40 | step: 167600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 6.484811478912889e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.8 | consumed tokens: 1372979200.0 | grad norm avg: 1.5 | grad norm last: 1.42 | 
2026-01-01T13:34:58 | step: 167700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 6.389403779394343e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.09 | consumed tokens: 1373798400.0 | grad norm avg: 1.49 | grad norm last: 1.53 | 
2026-01-01T13:35:16 | step: 167800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 6.294753234215023e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.5 | consumed tokens: 1374617600.0 | grad norm avg: 1.52 | grad norm last: 1.4 | 
2026-01-01T13:35:35 | step: 167900 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 6.200860980243306e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.8 | consumed tokens: 1375436800.0 | grad norm avg: 1.49 | grad norm last: 1.55 | 
2026-01-01T13:35:53 | step: 168000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 6.107726449045003e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.38 | consumed tokens: 1376256000.0 | grad norm avg: 1.51 | grad norm last: 1.57 | 
2026-01-01T13:36:11 | step: 168100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 6.015350777488493e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.25 | consumed tokens: 1377075200.0 | grad norm avg: 1.52 | grad norm last: 1.55 | 
2026-01-01T13:36:29 | step: 168200 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 5.923733397139586e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.59 | consumed tokens: 1377894400.0 | grad norm avg: 1.51 | grad norm last: 1.44 | 
2026-01-01T13:36:47 | step: 168300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 5.83287487643247e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.41 | consumed tokens: 1378713600.0 | grad norm avg: 1.51 | grad norm last: 1.4 | 
2026-01-01T13:37:05 | step: 168400 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 5.742776352235524e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.45 | train loss last: 2.62 | consumed tokens: 1379532800.0 | grad norm avg: 1.51 | grad norm last: 1.38 | 
2026-01-01T13:37:23 | step: 168500 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 5.653436687680369e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.59 | consumed tokens: 1380352000.0 | grad norm avg: 1.5 | grad norm last: 1.54 | 
2026-01-01T13:37:41 | step: 168600 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 5.564857019635383e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.95 | consumed tokens: 1381171200.0 | grad norm avg: 1.49 | grad norm last: 1.57 | 
2026-01-01T13:37:59 | step: 168700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 5.477037348100566e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.06 | consumed tokens: 1381990400.0 | grad norm avg: 1.51 | grad norm last: 1.52 | 
2026-01-01T13:38:18 | step: 168800 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 5.389978241510107e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.42 | consumed tokens: 1382809600.0 | grad norm avg: 1.51 | grad norm last: 1.45 | 
2026-01-01T13:38:36 | step: 168900 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 5.303679699864006e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.34 | consumed tokens: 1383628800.0 | grad norm avg: 1.49 | grad norm last: 1.55 | 
2026-01-01T13:38:54 | step: 169000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 5.218141723162262e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.34 | consumed tokens: 1384448000.0 | grad norm avg: 1.51 | grad norm last: 1.35 | 
2026-01-01T13:39:12 | step: 169100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 5.133365448273253e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.52 | consumed tokens: 1385267200.0 | grad norm avg: 1.51 | grad norm last: 1.46 | 
2026-01-01T13:39:30 | step: 169200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 5.04935030676279e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.53 | consumed tokens: 1386086400.0 | grad norm avg: 1.51 | grad norm last: 1.64 | 
2026-01-01T13:39:48 | step: 169300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.966096867065062e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.41 | consumed tokens: 1386905600.0 | grad norm avg: 1.51 | grad norm last: 1.48 | 
2026-01-01T13:40:06 | step: 169400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.883605129180069e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.39 | consumed tokens: 1387724800.0 | grad norm avg: 1.52 | grad norm last: 1.47 | 
2026-01-01T13:40:24 | step: 169500 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.801876229976187e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.28 | consumed tokens: 1388544000.0 | grad norm avg: 1.51 | grad norm last: 1.53 | 
2026-01-01T13:40:42 | step: 169600 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.7209093168021354e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.78 | consumed tokens: 1389363200.0 | grad norm avg: 1.52 | grad norm last: 1.4 | 
2026-01-01T13:41:01 | step: 169700 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.6407052423091955e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.22 | consumed tokens: 1390182400.0 | grad norm avg: 1.52 | grad norm last: 1.58 | 
2026-01-01T13:41:19 | step: 169800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.5612640064973675e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.62 | consumed tokens: 1391001600.0 | grad norm avg: 1.5 | grad norm last: 1.52 | 
2026-01-01T13:41:37 | step: 169900 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.48258617780084e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.41 | consumed tokens: 1391820800.0 | grad norm avg: 1.51 | grad norm last: 1.46 | 
2026-01-01T13:41:55 | step: 170000 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.4046717562196136e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.27 | consumed tokens: 1392640000.0 | grad norm avg: 1.51 | grad norm last: 1.37 | 
2026-01-01T13:42:15 | step: 170100 | train samples/s: 95.1 | train mfu (16-bit): -1.0 | lr mean: 4.3275207417536876e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.69 | consumed tokens: 1393459200.0 | grad norm avg: 1.5 | grad norm last: 1.56 | 
2026-01-01T13:42:33 | step: 170200 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.251133987054345e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.12 | consumed tokens: 1394278400.0 | grad norm avg: 1.5 | grad norm last: 1.38 | 
2026-01-01T13:42:51 | step: 170300 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.1755114921215863e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.86 | consumed tokens: 1395097600.0 | grad norm avg: 1.51 | grad norm last: 1.73 | 
2026-01-01T13:43:09 | step: 170400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.100653256955411e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.39 | consumed tokens: 1395916800.0 | grad norm avg: 1.5 | grad norm last: 1.49 | 
2026-01-01T13:43:27 | step: 170500 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.0265595657729136e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.09 | consumed tokens: 1396736000.0 | grad norm avg: 1.51 | grad norm last: 1.57 | 
2026-01-01T13:43:46 | step: 170600 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 3.9532307027911884e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.52 | train loss last: 2.45 | consumed tokens: 1397555200.0 | grad norm avg: 1.52 | grad norm last: 1.6 | 
2026-01-01T13:44:04 | step: 170700 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.880667236444424e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.52 | consumed tokens: 1398374400.0 | grad norm avg: 1.5 | grad norm last: 1.53 | 
2026-01-01T13:44:22 | step: 170800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.808868882515526e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.45 | train loss last: 2.02 | consumed tokens: 1399193600.0 | grad norm avg: 1.5 | grad norm last: 1.42 | 
2026-01-01T13:44:40 | step: 170900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.7378359252215887e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.22 | consumed tokens: 1400012800.0 | grad norm avg: 1.52 | grad norm last: 1.54 | 
2026-01-01T13:44:58 | step: 171000 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.667568932996801e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.27 | consumed tokens: 1400832000.0 | grad norm avg: 1.51 | grad norm last: 1.59 | 
2026-01-01T13:45:16 | step: 171100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.5980679058411624e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.42 | consumed tokens: 1401651200.0 | grad norm avg: 1.51 | grad norm last: 1.41 | 
2026-01-01T13:45:34 | step: 171200 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 3.5293331279717677e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.39 | consumed tokens: 1402470400.0 | grad norm avg: 1.52 | grad norm last: 1.53 | 
2026-01-01T13:45:53 | step: 171300 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 3.4613645993886166e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.75 | consumed tokens: 1403289600.0 | grad norm avg: 1.5 | grad norm last: 1.41 | 
2026-01-01T13:46:11 | step: 171400 | train samples/s: 95.0 | train mfu (16-bit): -1.0 | lr mean: 3.394162888525898e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.16 | consumed tokens: 1404108800.0 | grad norm avg: 1.51 | grad norm last: 1.52 | 
2026-01-01T13:46:29 | step: 171500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.3277279953836114e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.48 | consumed tokens: 1404928000.0 | grad norm avg: 1.52 | grad norm last: 1.53 | 
2026-01-01T13:46:47 | step: 171600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.262059919961757e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.75 | consumed tokens: 1405747200.0 | grad norm avg: 1.5 | grad norm last: 1.49 | 
2026-01-01T13:47:05 | step: 171700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.197159230694524e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 3.25 | consumed tokens: 1406566400.0 | grad norm avg: 1.51 | grad norm last: 1.51 | 
2026-01-01T13:47:23 | step: 171800 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 3.1330259275819117e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.58 | consumed tokens: 1407385600.0 | grad norm avg: 1.5 | grad norm last: 1.63 | 
2026-01-01T13:47:42 | step: 171900 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 3.069660579058109e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.69 | consumed tokens: 1408204800.0 | grad norm avg: 1.51 | grad norm last: 1.52 | 
2026-01-01T13:48:00 | step: 172000 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.007062616688927e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 1.91 | consumed tokens: 1409024000.0 | grad norm avg: 1.49 | grad norm last: 1.42 | 
2026-01-01T13:48:18 | step: 172100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.945232893125649e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.14 | consumed tokens: 1409843200.0 | grad norm avg: 1.52 | grad norm last: 1.43 | 
2026-01-01T13:48:36 | step: 172200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 2.8841714083682746e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 1.84 | consumed tokens: 1410662400.0 | grad norm avg: 1.52 | grad norm last: 1.6 | 
2026-01-01T13:48:54 | step: 172300 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.8238784466338984e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.48 | consumed tokens: 1411481600.0 | grad norm avg: 1.51 | grad norm last: 1.46 | 
2026-01-01T13:49:12 | step: 172400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.7643540079225204e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.66 | consumed tokens: 1412300800.0 | grad norm avg: 1.49 | grad norm last: 1.47 | 
2026-01-01T13:49:30 | step: 172500 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.705598376451235e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.45 | train loss last: 2.83 | consumed tokens: 1413120000.0 | grad norm avg: 1.51 | grad norm last: 1.5 | 
2026-01-01T13:49:48 | step: 172600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.6476115522200416e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.42 | consumed tokens: 1413939200.0 | grad norm avg: 1.5 | grad norm last: 1.47 | 
2026-01-01T13:50:06 | step: 172700 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 2.5903941036631295e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.83 | consumed tokens: 1414758400.0 | grad norm avg: 1.5 | grad norm last: 1.55 | 
2026-01-01T13:50:25 | step: 172800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.533945746563404e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 1.68 | consumed tokens: 1415577600.0 | grad norm avg: 1.52 | grad norm last: 1.56 | 
2026-01-01T13:50:43 | step: 172900 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.478267049355054e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.73 | consumed tokens: 1416396800.0 | grad norm avg: 1.51 | grad norm last: 1.62 | 
2026-01-01T13:51:01 | step: 173000 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 2.4233580120380793e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.3 | consumed tokens: 1417216000.0 | grad norm avg: 1.52 | grad norm last: 1.42 | 
2026-01-01T13:51:19 | step: 173100 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 2.3692189188295742e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 1.77 | consumed tokens: 1418035200.0 | grad norm avg: 1.51 | grad norm last: 1.6 | 
2026-01-01T13:51:37 | step: 173200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.3158496276209917e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.7 | consumed tokens: 1418854400.0 | grad norm avg: 1.51 | grad norm last: 1.68 | 
2026-01-01T13:51:55 | step: 173300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.2632507068465202e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.33 | consumed tokens: 1419673600.0 | grad norm avg: 1.5 | grad norm last: 1.58 | 
2026-01-01T13:52:13 | step: 173400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.2114220143976127e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.51 | train loss last: 2.92 | consumed tokens: 1420492800.0 | grad norm avg: 1.52 | grad norm last: 1.58 | 
2026-01-01T13:52:32 | step: 173500 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 2.1603639765999105e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.45 | train loss last: 2.5 | consumed tokens: 1421312000.0 | grad norm avg: 1.52 | grad norm last: 1.45 | 
2026-01-01T13:52:50 | step: 173600 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 2.1100764513448667e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.89 | consumed tokens: 1422131200.0 | grad norm avg: 1.5 | grad norm last: 1.58 | 
2026-01-01T13:53:08 | step: 173700 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 2.0605598649581225e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.45 | train loss last: 2.45 | consumed tokens: 1422950400.0 | grad norm avg: 1.5 | grad norm last: 1.5 | 
2026-01-01T13:53:26 | step: 173800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.011814075331131e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.55 | consumed tokens: 1423769600.0 | grad norm avg: 1.51 | grad norm last: 1.47 | 
2026-01-01T13:53:44 | step: 173900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.9638395087895333e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.06 | consumed tokens: 1424588800.0 | grad norm avg: 1.51 | grad norm last: 1.5 | 
2026-01-01T13:54:02 | step: 174000 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 1.9166363074418769e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.55 | consumed tokens: 1425408000.0 | grad norm avg: 1.51 | grad norm last: 1.58 | 
2026-01-01T13:54:21 | step: 174100 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 1.8702044712881616e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.61 | consumed tokens: 1426227200.0 | grad norm avg: 1.53 | grad norm last: 1.48 | 
2026-01-01T13:54:39 | step: 174200 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 1.8245441424369346e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.59 | consumed tokens: 1427046400.0 | grad norm avg: 1.5 | grad norm last: 1.36 | 
2026-01-01T13:54:57 | step: 174300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.7796556051052903e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.62 | consumed tokens: 1427865600.0 | grad norm avg: 1.51 | grad norm last: 1.44 | 
2026-01-01T13:55:15 | step: 174400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.7355388592932286e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.8 | consumed tokens: 1428684800.0 | grad norm avg: 1.51 | grad norm last: 1.49 | 
2026-01-01T13:55:33 | step: 174500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.6921941892178438e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.52 | consumed tokens: 1429504000.0 | grad norm avg: 1.5 | grad norm last: 1.39 | 
2026-01-01T13:55:51 | step: 174600 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.649621594879136e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.0 | consumed tokens: 1430323200.0 | grad norm avg: 1.53 | grad norm last: 1.43 | 
2026-01-01T13:56:09 | step: 174700 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.6078212183856522e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.2 | consumed tokens: 1431142400.0 | grad norm avg: 1.51 | grad norm last: 1.46 | 
2026-01-01T13:56:27 | step: 174800 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 1.5667932018459396e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 3.23 | consumed tokens: 1431961600.0 | grad norm avg: 1.5 | grad norm last: 1.53 | 
2026-01-01T13:56:46 | step: 174900 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.5265376873685454e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.33 | consumed tokens: 1432780800.0 | grad norm avg: 1.51 | grad norm last: 1.3 | 
2026-01-01T13:57:04 | step: 175000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.4870548170620168e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 1.97 | consumed tokens: 1433600000.0 | grad norm avg: 1.5 | grad norm last: 1.65 | 
2026-01-01T13:57:23 | step: 175100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.4483447330349009e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 1.9 | consumed tokens: 1434419200.0 | grad norm avg: 1.52 | grad norm last: 1.53 | 
2026-01-01T13:57:41 | step: 175200 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 1.4104075773957447e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.55 | consumed tokens: 1435238400.0 | grad norm avg: 1.5 | grad norm last: 1.64 | 
2026-01-01T13:58:00 | step: 175300 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 1.3732433501445485e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.73 | consumed tokens: 1436057600.0 | grad norm avg: 1.5 | grad norm last: 1.51 | 
2026-01-01T13:58:18 | step: 175400 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 1.3368523354984063e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.83 | consumed tokens: 1436876800.0 | grad norm avg: 1.51 | grad norm last: 1.52 | 
2026-01-01T13:58:36 | step: 175500 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 1.3012343913487712e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.55 | consumed tokens: 1437696000.0 | grad norm avg: 1.52 | grad norm last: 1.52 | 
2026-01-01T13:58:54 | step: 175600 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.2663898019127373e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 1.94 | consumed tokens: 1438515200.0 | grad norm avg: 1.5 | grad norm last: 1.45 | 
2026-01-01T13:59:12 | step: 175700 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.232318709298852e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.77 | consumed tokens: 1439334400.0 | grad norm avg: 1.5 | grad norm last: 1.48 | 
2026-01-01T13:59:30 | step: 175800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.199021255615662e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.59 | consumed tokens: 1440153600.0 | grad norm avg: 1.52 | grad norm last: 1.4 | 
2026-01-01T13:59:49 | step: 175900 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 1.1664972987546207e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.28 | consumed tokens: 1440972800.0 | grad norm avg: 1.5 | grad norm last: 1.47 | 
2026-01-01T14:00:07 | step: 176000 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.1347471939870957e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.56 | consumed tokens: 1441792000.0 | grad norm avg: 1.5 | grad norm last: 1.46 | 
2026-01-01T14:00:25 | step: 176100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.1037708702588134e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.7 | consumed tokens: 1442611200.0 | grad norm avg: 1.52 | grad norm last: 1.63 | 
2026-01-01T14:00:43 | step: 176200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.0735685407325946e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.45 | consumed tokens: 1443430400.0 | grad norm avg: 1.51 | grad norm last: 1.52 | 
2026-01-01T14:01:01 | step: 176300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.0441402764627128e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.88 | consumed tokens: 1444249600.0 | grad norm avg: 1.5 | grad norm last: 1.41 | 
2026-01-01T14:01:19 | step: 176400 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.0154860774491681e-07 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.67 | consumed tokens: 1445068800.0 | grad norm avg: 1.51 | grad norm last: 1.54 | 
2026-01-01T14:01:37 | step: 176500 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 9.876061568547811e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.17 | consumed tokens: 1445888000.0 | grad norm avg: 1.49 | grad norm last: 1.56 | 
2026-01-01T14:01:56 | step: 176600 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 9.60500514679552e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 1.7 | consumed tokens: 1446707200.0 | grad norm avg: 1.51 | grad norm last: 1.42 | 
2026-01-01T14:02:14 | step: 176700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 9.341692930320278e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.53 | consumed tokens: 1447526400.0 | grad norm avg: 1.5 | grad norm last: 1.5 | 
2026-01-01T14:02:32 | step: 176800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 9.086124919122085e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.53 | consumed tokens: 1448345600.0 | grad norm avg: 1.5 | grad norm last: 1.5 | 
2026-01-01T14:02:50 | step: 176900 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 8.838302534286413e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 3.38 | consumed tokens: 1449164800.0 | grad norm avg: 1.5 | grad norm last: 1.34 | 
2026-01-01T14:03:08 | step: 177000 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 8.598227196898733e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.31 | consumed tokens: 1449984000.0 | grad norm avg: 1.5 | grad norm last: 1.46 | 
2026-01-01T14:03:26 | step: 177100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 8.36589819641631e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.59 | consumed tokens: 1450803200.0 | grad norm avg: 1.5 | grad norm last: 1.5 | 
2026-01-01T14:03:44 | step: 177200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 8.141317664467351e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.72 | consumed tokens: 1451622400.0 | grad norm avg: 1.51 | grad norm last: 1.62 | 
2026-01-01T14:04:03 | step: 177300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 7.92448489050912e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.42 | consumed tokens: 1452441600.0 | grad norm avg: 1.48 | grad norm last: 1.49 | 
2026-01-01T14:04:21 | step: 177400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 7.715401295627089e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.14 | consumed tokens: 1453260800.0 | grad norm avg: 1.5 | grad norm last: 1.44 | 
2026-01-01T14:04:39 | step: 177500 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 7.514067590363993e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.73 | consumed tokens: 1454080000.0 | grad norm avg: 1.5 | grad norm last: 1.57 | 
2026-01-01T14:04:57 | step: 177600 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 7.320484485262568e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.81 | consumed tokens: 1454899200.0 | grad norm avg: 1.5 | grad norm last: 1.47 | 
2026-01-01T14:05:15 | step: 177700 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 7.13465269086555e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 1.97 | consumed tokens: 1455718400.0 | grad norm avg: 1.51 | grad norm last: 1.65 | 
2026-01-01T14:05:33 | step: 177800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 6.95657220717294e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.44 | consumed tokens: 1456537600.0 | grad norm avg: 1.51 | grad norm last: 1.55 | 
2026-01-01T14:05:52 | step: 177900 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 6.786243744727471e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.28 | consumed tokens: 1457356800.0 | grad norm avg: 1.5 | grad norm last: 1.59 | 
2026-01-01T14:06:10 | step: 178000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 6.623668014071882e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.16 | consumed tokens: 1458176000.0 | grad norm avg: 1.51 | grad norm last: 1.46 | 
2026-01-01T14:06:28 | step: 178100 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 6.468845725748906e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.86 | consumed tokens: 1458995200.0 | grad norm avg: 1.51 | grad norm last: 1.39 | 
2026-01-01T14:06:46 | step: 178200 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 6.321776879758545e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.45 | train loss last: 2.19 | consumed tokens: 1459814400.0 | grad norm avg: 1.51 | grad norm last: 1.49 | 
2026-01-01T14:07:04 | step: 178300 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 6.182462186643534e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.53 | consumed tokens: 1460633600.0 | grad norm avg: 1.49 | grad norm last: 1.53 | 
2026-01-01T14:07:22 | step: 178400 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 6.050902356946608e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.46 | train loss last: 2.72 | consumed tokens: 1461452800.0 | grad norm avg: 1.5 | grad norm last: 1.41 | 
2026-01-01T14:07:41 | step: 178500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 5.9270970353964e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.67 | consumed tokens: 1462272000.0 | grad norm avg: 1.5 | grad norm last: 1.57 | 
2026-01-01T14:07:59 | step: 178600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 5.811047287807014e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.56 | consumed tokens: 1463091200.0 | grad norm avg: 1.51 | grad norm last: 1.53 | 
2026-01-01T14:08:17 | step: 178700 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 5.702753114178449e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.5 | train loss last: 2.44 | consumed tokens: 1463910400.0 | grad norm avg: 1.51 | grad norm last: 1.43 | 
2026-01-01T14:08:35 | step: 178800 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 5.602215225053442e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.45 | train loss last: 2.33 | consumed tokens: 1464729600.0 | grad norm avg: 1.49 | grad norm last: 1.49 | 
2026-01-01T14:08:53 | step: 178900 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 5.5094336204319916e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.45 | consumed tokens: 1465548800.0 | grad norm avg: 1.49 | grad norm last: 1.43 | 
2026-01-01T14:09:11 | step: 179000 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 5.4244086555854665e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.36 | consumed tokens: 1466368000.0 | grad norm avg: 1.51 | grad norm last: 1.42 | 
2026-01-01T14:09:29 | step: 179100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 5.3471403305138665e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.92 | consumed tokens: 1467187200.0 | grad norm avg: 1.51 | grad norm last: 1.53 | 
2026-01-01T14:09:47 | step: 179200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 5.277629711031295e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.44 | consumed tokens: 1468006400.0 | grad norm avg: 1.5 | grad norm last: 1.5 | 
2026-01-01T14:10:06 | step: 179300 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 5.215876086595017e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.48 | consumed tokens: 1468825600.0 | grad norm avg: 1.51 | grad norm last: 1.48 | 
2026-01-01T14:10:24 | step: 179400 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 5.161880167747768e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.47 | train loss last: 2.33 | consumed tokens: 1469644800.0 | grad norm avg: 1.5 | grad norm last: 1.43 | 
2026-01-01T14:10:42 | step: 179500 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 5.115641954489547e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.7 | consumed tokens: 1470464000.0 | grad norm avg: 1.51 | grad norm last: 1.38 | 
2026-01-01T14:11:00 | step: 179600 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 5.077161446820355e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.78 | consumed tokens: 1471283200.0 | grad norm avg: 1.5 | grad norm last: 1.57 | 
2026-01-01T14:11:18 | step: 179700 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 5.04643900001156e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.73 | consumed tokens: 1472102400.0 | grad norm avg: 1.5 | grad norm last: 1.56 | 
2026-01-01T14:11:36 | step: 179800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 5.023474969334529e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.09 | consumed tokens: 1472921600.0 | grad norm avg: 1.48 | grad norm last: 1.59 | 
2026-01-01T14:11:55 | step: 179900 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 5.0082686442465274e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.49 | train loss last: 2.47 | consumed tokens: 1473740800.0 | grad norm avg: 1.51 | grad norm last: 1.41 | 
2026-01-01T14:12:13 | step: 180000 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 5.00082073529029e-08 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.48 | train loss last: 2.56 | consumed tokens: 1474560000.0 | grad norm avg: 1.48 | grad norm last: 1.59 | 
Training done at 2026-01-01 14:12:23.537867.
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /home/s472389/modalities_test/wandb_storage/wandb/offline-run-20260101_050822-r5e6riti[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb_storage/wandb/offline-run-20260101_050822-r5e6riti/logs[0m
==========================================
Job finished at: Thu Jan  1 02:12:25 PM CET 2026
==========================================
