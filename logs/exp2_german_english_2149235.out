==========================================
Experiment 2: Fine-tuning GPT-2 on German + English
Job ID: 2149235
Node: jn017
Start time: Thu Jan  1 05:08:06 AM CET 2026
==========================================
Thu Jan  1 05:08:09 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.28.03              Driver Version: 560.28.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA L40                     On  |   00000000:E2:00.0 Off |                  Off |
| N/A   28C    P8             34W /  300W |       1MiB /  49140MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Rank 0 received experiment_id: 2026-01-01__05-08-20_5734a86bbe85efff
Instantiated <class 'int'>: settings -> training_target -> num_target_tokens
Instantiated <class 'int'>: settings -> training_target -> num_target_steps -> config -> global_num_tokens
Instantiated <class 'int'>: settings -> training_target -> num_target_steps
Instantiated <class 'modalities.models.huggingface.huggingface_model.HuggingFacePretrainedModel'>: model_raw

Wrapped layer classes: [<class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>]

Instantiated <class 'torch.distributed.fsdp.fully_sharded_data_parallel.FullyShardedDataParallel'>: wrapped_model
=> optimizer groups:
all (148 modules with 124,439,808 parameters): weight_decay = 0.01
=> all (148 modules with 124,439,808 parameters)
Instantiated <class 'torch.optim.adamw.AdamW'>: optimizer
Instantiated <class 'int'>: lr_scheduler -> config -> total_steps -> config -> global_num_tokens
Instantiated <class 'int'>: lr_scheduler -> config -> total_steps
Instantiated <class 'torch.optim.lr_scheduler.OneCycleLR'>: lr_scheduler
Instantiated <class 'modalities.checkpointing.stateful.app_state.AppState'>: app_state
Instantiated <class 'modalities.loss_functions.CLMCrossEntropyLoss'>: loss_fn
Instantiated <class 'modalities.dataloader.dataset.PackedMemMapDatasetContinuous'>: train_dataset
Instantiated <class 'modalities.dataloader.samplers.ResumableDistributedSampler'>: train_dataloader -> config -> batch_sampler -> config -> sampler
Instantiated <class 'torch.utils.data.sampler.BatchSampler'>: train_dataloader -> config -> batch_sampler
Instantiated <class 'modalities.models.gpt2.collator.GPT2LLMCollateFn'>: collate_fn
Instantiated <class 'modalities.dataloader.dataloader.LLMDataLoader'>: train_dataloader
Instantiated <class 'int'>: progress_subscriber -> config -> num_target_steps -> config -> global_num_tokens
Instantiated <class 'int'>: progress_subscriber -> config -> num_target_steps
Instantiated <class 'modalities.logging_broker.subscriber_impl.progress_subscriber.RichProgressSubscriber'>: progress_subscriber
Instantiated <class 'modalities.logging_broker.subscriber_impl.results_subscriber.WandBEvaluationResultSubscriber'>: evaluation_subscriber
Instantiated <class 'modalities.checkpointing.checkpoint_saving_strategies.SaveKMostRecentCheckpointsStrategy'>: checkpoint_saving -> config -> checkpoint_saving_strategy
Instantiated <class 'modalities.checkpointing.fsdp.fsdp_checkpoint_saving.FSDP1CheckpointSaving'>: checkpoint_saving -> config -> checkpoint_saving_execution
Instantiated <class 'modalities.checkpointing.checkpoint_saving.CheckpointSaving'>: checkpoint_saving
Instantiated <class 'modalities.training.gradient_clipping.fsdp_gradient_clipper.FSDP1GradientClipper'>: gradient_clipper
Model initialized at 2026-01-01 05:08:23.561199.



======================== Training Report ========================
Training target: 
	num_target_tokens: 3512418304
	num_target_steps: 428762 
Intervals: 
	training_log_interval_in_steps: 100
	checkpointing_interval_in_steps: 5000
	evaluation_interval_in_steps: 1000
Step profile: 
	gradient_accumulation_steps: 4
	local_train_micro_batch_size: 4
	sequence_length: 512
	dp_degree: 1
CUDA environment settings: 
	local_rank: 0
	world_size: 1
	global_rank: 0
Consistency enforcement: 
	enforce_tokens_per_step_consistency: True
	enforce_last_step_logged: False
	enforce_last_step_evaluated: False
	enforce_last_step_checkpointed: False
Training progress: 
	global_num_seen_tokens: 0
	num_seen_steps: 0
	num_seen_samples: 0
	last_step: -1
Warnings: 
	[38;5;214mNumber of tokens in the dataset (3512425984) does not match the number of target tokens (3512418304). Missing 0.00% of tokens in the dataset.
	Last step will not be logged. Since remaining_steps (428762) is not a multiple of training_log_interval_in_steps (100).
	Last step will not be evaluated. Since remaining_steps (428762) is not a multiple of evaluation_interval_in_steps (1000).
	Last step will not be checkpointed. Since remaining_steps (428762) is not a multiple of checkpointing_interval_in_steps (5000). [0m 
====================================================================



Start model training at 2026-01-01 05:08:23.561483.
2026-01-01T05:08:42 | step: 100 | train samples/s: 90.9 | train mfu (16-bit): -1.0 | lr mean: 5.060398962086765e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.15 | train loss last: 4.47 | consumed tokens: 819200.0 | grad norm avg: 3.13 | grad norm last: 2.57 | 
2026-01-01T05:09:01 | step: 200 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 5.241270628175698e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.07 | train loss last: 4.16 | consumed tokens: 1638400.0 | grad norm avg: 2.78 | grad norm last: 2.62 | 
2026-01-01T05:09:20 | step: 300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 5.541644895856734e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.1 | train loss last: 3.84 | consumed tokens: 2457600.0 | grad norm avg: 2.68 | grad norm last: 2.7 | 
2026-01-01T05:09:38 | step: 400 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 5.959908321528928e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.99 | train loss last: 4.0 | consumed tokens: 3276800.0 | grad norm avg: 2.59 | grad norm last: 2.59 | 
2026-01-01T05:09:56 | step: 500 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 6.493815817520954e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.98 | train loss last: 3.58 | consumed tokens: 4096000.0 | grad norm avg: 2.55 | grad norm last: 2.42 | 
2026-01-01T05:10:14 | step: 600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 7.140501111280173e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.99 | train loss last: 4.16 | consumed tokens: 4915200.0 | grad norm avg: 2.53 | grad norm last: 2.47 | 
2026-01-01T05:10:32 | step: 700 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 7.896492206782568e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.98 | train loss last: 4.38 | consumed tokens: 5734400.0 | grad norm avg: 2.54 | grad norm last: 2.53 | 
2026-01-01T05:10:50 | step: 800 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 8.757729119679425e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.94 | train loss last: 3.36 | consumed tokens: 6553600.0 | grad norm avg: 2.5 | grad norm last: 2.3 | 
2026-01-01T05:11:08 | step: 900 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 9.719589797896333e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.94 | train loss last: 3.69 | consumed tokens: 7372800.0 | grad norm avg: 2.42 | grad norm last: 2.52 | 
2026-01-01T05:11:26 | step: 1000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.0776910130516626e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.95 | train loss last: 3.75 | consumed tokens: 8192000.0 | grad norm avg: 2.43 | grad norm last: 2.25 | 
2026-01-01T05:11:44 | step: 1100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.1924012142117135e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.93 | train loss last: 3.95 | consumed tokens: 9011200.0 | grad norm avg: 2.35 | grad norm last: 2.16 | 
2026-01-01T05:12:02 | step: 1200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.3154738553566858e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.91 | train loss last: 3.94 | consumed tokens: 9830400.0 | grad norm avg: 2.33 | grad norm last: 2.38 | 
2026-01-01T05:12:20 | step: 1300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.4462480976362713e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.89 | train loss last: 3.56 | consumed tokens: 10649600.0 | grad norm avg: 2.29 | grad norm last: 2.32 | 
2026-01-01T05:12:38 | step: 1400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.5840219930396415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.91 | train loss last: 4.19 | consumed tokens: 11468800.0 | grad norm avg: 2.26 | grad norm last: 2.09 | 
2026-01-01T05:12:56 | step: 1500 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 1.728055576677434e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.85 | train loss last: 3.55 | consumed tokens: 12288000.0 | grad norm avg: 2.22 | grad norm last: 2.11 | 
2026-01-01T05:13:15 | step: 1600 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 1.8775759599520825e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.86 | train loss last: 3.44 | consumed tokens: 13107200.0 | grad norm avg: 2.13 | grad norm last: 2.11 | 
2026-01-01T05:13:33 | step: 1700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.031780059041921e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.88 | train loss last: 3.83 | consumed tokens: 13926400.0 | grad norm avg: 2.12 | grad norm last: 2.05 | 
2026-01-01T05:13:51 | step: 1800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.1898402337683365e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.83 | train loss last: 3.5 | consumed tokens: 14745600.0 | grad norm avg: 2.05 | grad norm last: 1.84 | 
2026-01-01T05:14:09 | step: 1900 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.3509077436756343e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.79 | train loss last: 3.98 | consumed tokens: 15564800.0 | grad norm avg: 2.02 | grad norm last: 2.15 | 
2026-01-01T05:14:27 | step: 2000 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.5141178412013687e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.85 | train loss last: 4.38 | consumed tokens: 16384000.0 | grad norm avg: 1.96 | grad norm last: 1.75 | 
2026-01-01T05:14:45 | step: 2100 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 2.6785943191498518e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.83 | train loss last: 2.92 | consumed tokens: 17203200.0 | grad norm avg: 1.92 | grad norm last: 1.89 | 
2026-01-01T05:15:03 | step: 2200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.8434542400646023e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.8 | train loss last: 3.36 | consumed tokens: 18022400.0 | grad norm avg: 1.85 | grad norm last: 1.83 | 
2026-01-01T05:15:22 | step: 2300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.0078123018029146e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.79 | train loss last: 3.48 | consumed tokens: 18841600.0 | grad norm avg: 1.82 | grad norm last: 1.72 | 
2026-01-01T05:15:40 | step: 2400 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.170786294504069e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.79 | train loss last: 4.19 | consumed tokens: 19660800.0 | grad norm avg: 1.77 | grad norm last: 1.75 | 
2026-01-01T05:15:58 | step: 2500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.3315012842649594e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.79 | train loss last: 3.78 | consumed tokens: 20480000.0 | grad norm avg: 1.71 | grad norm last: 1.74 | 
2026-01-01T05:16:16 | step: 2600 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 3.489094160613604e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.78 | train loss last: 3.73 | consumed tokens: 21299200.0 | grad norm avg: 1.67 | grad norm last: 1.98 | 
2026-01-01T05:16:34 | step: 2700 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 3.6427190934773535e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.77 | train loss last: 3.52 | consumed tokens: 22118400.0 | grad norm avg: 1.63 | grad norm last: 1.68 | 
2026-01-01T05:16:53 | step: 2800 | train samples/s: 95.0 | train mfu (16-bit): -1.0 | lr mean: 3.7915513530606404e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.76 | train loss last: 3.94 | consumed tokens: 22937600.0 | grad norm avg: 1.56 | grad norm last: 1.46 | 
2026-01-01T05:17:11 | step: 2900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.934791675419547e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.74 | train loss last: 4.25 | consumed tokens: 23756800.0 | grad norm avg: 1.55 | grad norm last: 1.72 | 
2026-01-01T05:17:29 | step: 3000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.071670991834253e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.73 | train loss last: 3.25 | consumed tokens: 24576000.0 | grad norm avg: 1.5 | grad norm last: 1.5 | 
2026-01-01T05:17:47 | step: 3100 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.201454430585727e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.72 | train loss last: 3.61 | consumed tokens: 25395200.0 | grad norm avg: 1.5 | grad norm last: 1.43 | 
2026-01-01T05:18:05 | step: 3200 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.3234456825302914e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.71 | train loss last: 3.7 | consumed tokens: 26214400.0 | grad norm avg: 1.46 | grad norm last: 1.53 | 
2026-01-01T05:18:23 | step: 3300 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.436989183886908e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.72 | train loss last: 3.67 | consumed tokens: 27033600.0 | grad norm avg: 1.41 | grad norm last: 1.4 | 
2026-01-01T05:18:41 | step: 3400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.541475573205389e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.69 | train loss last: 3.8 | consumed tokens: 27852800.0 | grad norm avg: 1.38 | grad norm last: 1.42 | 
2026-01-01T05:18:59 | step: 3500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.636344237951562e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.7 | train loss last: 3.77 | consumed tokens: 28672000.0 | grad norm avg: 1.36 | grad norm last: 1.56 | 
2026-01-01T05:19:17 | step: 3600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.7210854972945526e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.71 | train loss last: 4.09 | consumed tokens: 29491200.0 | grad norm avg: 1.33 | grad norm last: 1.3 | 
2026-01-01T05:19:36 | step: 3700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.7952442400855944e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.69 | train loss last: 3.72 | consumed tokens: 30310400.0 | grad norm avg: 1.3 | grad norm last: 1.26 | 
2026-01-01T05:19:54 | step: 3800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.858422471443191e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.68 | train loss last: 3.73 | consumed tokens: 31129600.0 | grad norm avg: 1.28 | grad norm last: 1.28 | 
2026-01-01T05:20:12 | step: 3900 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.910281131742522e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.7 | train loss last: 3.28 | consumed tokens: 31948800.0 | grad norm avg: 1.24 | grad norm last: 1.29 | 
2026-01-01T05:20:30 | step: 4000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.950541915604845e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.69 | train loss last: 3.62 | consumed tokens: 32768000.0 | grad norm avg: 1.22 | grad norm last: 1.3 | 
2026-01-01T05:20:48 | step: 4100 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 4.978988363291137e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.66 | train loss last: 3.7 | consumed tokens: 33587200.0 | grad norm avg: 1.19 | grad norm last: 1.13 | 
2026-01-01T05:21:06 | step: 4200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.995467679691501e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.62 | train loss last: 3.62 | consumed tokens: 34406400.0 | grad norm avg: 1.18 | grad norm last: 1.11 | 
2026-01-01T05:21:24 | step: 4300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.999999873689376e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.65 | train loss last: 3.47 | consumed tokens: 35225600.0 | grad norm avg: 1.16 | grad norm last: 1.24 | 
2026-01-01T05:21:43 | step: 4400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.9999991460936144e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.63 | train loss last: 3.56 | consumed tokens: 36044800.0 | grad norm avg: 1.13 | grad norm last: 1.15 | 
2026-01-01T05:22:01 | step: 4500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.99999696330633e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.66 | train loss last: 3.33 | consumed tokens: 36864000.0 | grad norm avg: 1.13 | grad norm last: 1.04 | 
2026-01-01T05:22:19 | step: 4600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.999993325327523e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.66 | train loss last: 3.45 | consumed tokens: 37683200.0 | grad norm avg: 1.1 | grad norm last: 1.06 | 
2026-01-01T05:22:37 | step: 4700 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.999988232157193e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.63 | train loss last: 3.78 | consumed tokens: 38502400.0 | grad norm avg: 1.1 | grad norm last: 1.06 | 
2026-01-01T05:22:55 | step: 4800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.999982047593221e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.62 | train loss last: 3.97 | consumed tokens: 39321600.0 | grad norm avg: 1.07 | grad norm last: 1.02 | 
2026-01-01T05:23:13 | step: 4900 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.999974407837726e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.61 | train loss last: 3.34 | consumed tokens: 40140800.0 | grad norm avg: 1.08 | grad norm last: 1.07 | 
2026-01-01T05:23:31 | step: 5000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9999653128907084e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.6 | train loss last: 3.58 | consumed tokens: 40960000.0 | grad norm avg: 1.06 | grad norm last: 0.99 | 
2026-01-01T05:23:51 | step: 5100 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.999954762752168e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.61 | train loss last: 3.45 | consumed tokens: 41779200.0 | grad norm avg: 1.04 | grad norm last: 0.99 | 
2026-01-01T05:24:09 | step: 5200 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.9999427574221045e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.6 | train loss last: 4.03 | consumed tokens: 42598400.0 | grad norm avg: 1.04 | grad norm last: 1.08 | 
2026-01-01T05:24:27 | step: 5300 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.999929660698399e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.61 | train loss last: 3.62 | consumed tokens: 43417600.0 | grad norm avg: 1.03 | grad norm last: 1.05 | 
2026-01-01T05:24:45 | step: 5400 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 4.9999151087831706e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.57 | train loss last: 4.72 | consumed tokens: 44236800.0 | grad norm avg: 1.02 | grad norm last: 0.99 | 
2026-01-01T05:25:04 | step: 5500 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.9998994654743e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.62 | train loss last: 3.34 | consumed tokens: 45056000.0 | grad norm avg: 1.01 | grad norm last: 1.06 | 
2026-01-01T05:25:22 | step: 5600 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.999882003176026e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.58 | train loss last: 3.11 | consumed tokens: 45875200.0 | grad norm avg: 1.0 | grad norm last: 1.03 | 
2026-01-01T05:25:40 | step: 5700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.99986344948411e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.63 | train loss last: 3.38 | consumed tokens: 46694400.0 | grad norm avg: 0.99 | grad norm last: 0.93 | 
2026-01-01T05:25:58 | step: 5800 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.999843440600671e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.64 | train loss last: 3.41 | consumed tokens: 47513600.0 | grad norm avg: 1.0 | grad norm last: 1.0 | 
2026-01-01T05:26:16 | step: 5900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.999821976525709e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.61 | train loss last: 3.67 | consumed tokens: 48332800.0 | grad norm avg: 0.98 | grad norm last: 0.91 | 
2026-01-01T05:26:34 | step: 6000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.9997990572592244e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.58 | train loss last: 3.67 | consumed tokens: 49152000.0 | grad norm avg: 0.97 | grad norm last: 0.98 | 
2026-01-01T05:26:52 | step: 6100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.9997750465990975e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.56 | train loss last: 3.83 | consumed tokens: 49971200.0 | grad norm avg: 0.98 | grad norm last: 0.95 | 
2026-01-01T05:27:10 | step: 6200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.999749580747448e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.55 | train loss last: 3.81 | consumed tokens: 50790400.0 | grad norm avg: 0.96 | grad norm last: 0.94 | 
2026-01-01T05:27:28 | step: 6300 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.9997226597042754e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.6 | train loss last: 3.62 | consumed tokens: 51609600.0 | grad norm avg: 0.96 | grad norm last: 0.98 | 
2026-01-01T05:27:46 | step: 6400 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.999694647267461e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.55 | train loss last: 3.03 | consumed tokens: 52428800.0 | grad norm avg: 0.95 | grad norm last: 0.9 | 
2026-01-01T05:28:05 | step: 6500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.999664815841243e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.57 | train loss last: 3.47 | consumed tokens: 53248000.0 | grad norm avg: 0.95 | grad norm last: 1.02 | 
2026-01-01T05:28:23 | step: 6600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.9996338930213824e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.59 | train loss last: 3.92 | consumed tokens: 54067200.0 | grad norm avg: 0.93 | grad norm last: 0.88 | 
2026-01-01T05:28:41 | step: 6700 | train samples/s: 95.2 | train mfu (16-bit): -1.0 | lr mean: 4.999601515009999e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.58 | train loss last: 4.06 | consumed tokens: 54886400.0 | grad norm avg: 0.94 | grad norm last: 0.92 | 
2026-01-01T05:28:59 | step: 6800 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.999568045604974e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.55 | train loss last: 3.2 | consumed tokens: 55705600.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-01T05:29:17 | step: 6900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.999532757210545e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.57 | train loss last: 4.53 | consumed tokens: 56524800.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-01T05:29:35 | step: 7000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.999496377422474e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.58 | train loss last: 4.25 | consumed tokens: 57344000.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-01T05:29:53 | step: 7100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.9994585424428806e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.57 | train loss last: 3.31 | consumed tokens: 58163200.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-01T05:30:11 | step: 7200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.999419616069645e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.57 | train loss last: 4.22 | consumed tokens: 58982400.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-01T05:30:30 | step: 7300 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.999378870707005e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.56 | train loss last: 3.91 | consumed tokens: 59801600.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T05:30:48 | step: 7400 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.999337033950724e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.57 | train loss last: 3.14 | consumed tokens: 60620800.0 | grad norm avg: 0.92 | grad norm last: 1.29 | 
2026-01-01T05:31:06 | step: 7500 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.999293742002919e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.53 | train loss last: 3.12 | consumed tokens: 61440000.0 | grad norm avg: 0.92 | grad norm last: 0.86 | 
2026-01-01T05:31:24 | step: 7600 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.999248994863592e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.57 | train loss last: 3.61 | consumed tokens: 62259200.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-01T05:31:42 | step: 7700 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.999203156330623e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.56 | train loss last: 3.92 | consumed tokens: 63078400.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T05:32:00 | step: 7800 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.9991558626061305e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.58 | train loss last: 3.55 | consumed tokens: 63897600.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T05:32:19 | step: 7900 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.9991071136901155e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.54 | train loss last: 3.58 | consumed tokens: 64716800.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T05:32:37 | step: 8000 | train samples/s: 94.8 | train mfu (16-bit): -1.0 | lr mean: 4.9990569095825776e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.56 | train loss last: 3.23 | consumed tokens: 65536000.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T05:32:55 | step: 8100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.999005250283517e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.54 | train loss last: 3.16 | consumed tokens: 66355200.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T05:33:13 | step: 8200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.998952499590814e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.53 | train loss last: 3.17 | consumed tokens: 67174400.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T05:33:31 | step: 8300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.9988982937065884e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.57 | train loss last: 4.03 | consumed tokens: 67993600.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T05:33:49 | step: 8400 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.99884263263084e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.56 | train loss last: 3.69 | consumed tokens: 68812800.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T05:34:07 | step: 8500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.998785880161449e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.54 | train loss last: 3.19 | consumed tokens: 69632000.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T05:34:26 | step: 8600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.998727308702655e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.54 | train loss last: 3.17 | consumed tokens: 70451200.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T05:34:44 | step: 8700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.998667645850219e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.52 | train loss last: 3.5 | consumed tokens: 71270400.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T05:35:02 | step: 8800 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.9986068916041404e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.54 | train loss last: 3.33 | consumed tokens: 72089600.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T05:35:20 | step: 8900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.9985443183686584e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.53 | train loss last: 3.41 | consumed tokens: 72908800.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T05:35:38 | step: 9000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.998480653739534e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.57 | train loss last: 2.83 | consumed tokens: 73728000.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T05:35:56 | step: 9100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.9984155339188874e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.53 | train loss last: 4.19 | consumed tokens: 74547200.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T05:36:14 | step: 9200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.9983489589067176e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.53 | train loss last: 3.86 | consumed tokens: 75366400.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T05:36:32 | step: 9300 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 4.998280928703025e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.51 | train loss last: 3.69 | consumed tokens: 76185600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T05:36:51 | step: 9400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.99821180710569e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.52 | train loss last: 3.3 | consumed tokens: 77004800.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T05:37:09 | step: 9500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.998141230316833e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.53 | train loss last: 3.48 | consumed tokens: 77824000.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T05:37:27 | step: 9600 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.998069198336452e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.54 | train loss last: 3.83 | consumed tokens: 78643200.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T05:37:45 | step: 9700 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.997995711164549e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.52 | train loss last: 3.17 | consumed tokens: 79462400.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T05:38:03 | step: 9800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.9979211325990036e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.54 | train loss last: 3.2 | consumed tokens: 80281600.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T05:38:21 | step: 9900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9978450988419354e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.53 | train loss last: 3.33 | consumed tokens: 81100800.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T05:38:39 | step: 10000 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.9977676098933443e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.51 | train loss last: 3.62 | consumed tokens: 81920000.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T05:38:59 | step: 10100 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.9976886657532305e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.49 | train loss last: 3.03 | consumed tokens: 82739200.0 | grad norm avg: 0.86 | grad norm last: 0.91 | 
2026-01-01T05:39:17 | step: 10200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9976086302194744e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.53 | train loss last: 4.03 | consumed tokens: 83558400.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T05:39:35 | step: 10300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.997526775696315e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.52 | train loss last: 3.3 | consumed tokens: 84377600.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T05:39:53 | step: 10400 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.997443829779513e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.52 | train loss last: 3.42 | consumed tokens: 85196800.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T05:40:12 | step: 10500 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.9973597924690694e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.51 | train loss last: 3.22 | consumed tokens: 86016000.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T05:40:30 | step: 10600 | train samples/s: 95.0 | train mfu (16-bit): -1.0 | lr mean: 4.997273936169222e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.51 | train loss last: 3.31 | consumed tokens: 86835200.0 | grad norm avg: 0.87 | grad norm last: 0.94 | 
2026-01-01T05:40:48 | step: 10700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.9971869884757325e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.44 | consumed tokens: 87654400.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T05:41:06 | step: 10800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.99709858559072e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.5 | train loss last: 3.41 | consumed tokens: 88473600.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T05:41:24 | step: 10900 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.997008727514185e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.49 | train loss last: 3.22 | consumed tokens: 89292800.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T05:41:43 | step: 11000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.996917778044008e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.53 | train loss last: 3.12 | consumed tokens: 90112000.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T05:42:01 | step: 11100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9968253733823076e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.52 | train loss last: 3.44 | consumed tokens: 90931200.0 | grad norm avg: 0.86 | grad norm last: 0.95 | 
2026-01-01T05:42:19 | step: 11200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.9967315135290846e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.54 | train loss last: 3.77 | consumed tokens: 91750400.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T05:42:37 | step: 11300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.996636198484339e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.5 | train loss last: 3.28 | consumed tokens: 92569600.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T05:42:55 | step: 11400 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.996539792045951e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.51 | train loss last: 3.39 | consumed tokens: 93388800.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T05:43:13 | step: 11500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9964415666181594e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.49 | train loss last: 3.47 | consumed tokens: 94208000.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T05:43:31 | step: 11600 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.996342249796726e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.5 | train loss last: 3.3 | consumed tokens: 95027200.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T05:43:49 | step: 11700 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.99624184158165e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.49 | train loss last: 3.33 | consumed tokens: 95846400.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T05:44:07 | step: 11800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.996139614377171e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.46 | train loss last: 3.12 | consumed tokens: 96665600.0 | grad norm avg: 0.86 | grad norm last: 0.81 | 
2026-01-01T05:44:26 | step: 11900 | train samples/s: 95.0 | train mfu (16-bit): -1.0 | lr mean: 4.9960362957790494e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.5 | train loss last: 2.94 | consumed tokens: 97484800.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T05:44:44 | step: 12000 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.995931521989405e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.48 | train loss last: 3.88 | consumed tokens: 98304000.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T05:45:02 | step: 12100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.995825293008238e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.48 | train loss last: 3.27 | consumed tokens: 99123200.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T05:45:20 | step: 12200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.995717608835548e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.28 | consumed tokens: 99942400.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T05:45:38 | step: 12300 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.995608833269216e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.49 | train loss last: 3.64 | consumed tokens: 100761600.0 | grad norm avg: 0.87 | grad norm last: 1.05 | 
2026-01-01T05:45:57 | step: 12400 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.995498602511361e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.48 | train loss last: 3.91 | consumed tokens: 101580800.0 | grad norm avg: 0.85 | grad norm last: 0.85 | 
2026-01-01T05:46:15 | step: 12500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9953869165619835e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.46 | train loss last: 3.23 | consumed tokens: 102400000.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T05:46:33 | step: 12600 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.995274139218964e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.46 | train loss last: 3.44 | consumed tokens: 103219200.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T05:46:51 | step: 12700 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.99515954288654e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.5 | train loss last: 3.92 | consumed tokens: 104038400.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T05:47:09 | step: 12800 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.995043855160475e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.5 | train loss last: 3.78 | consumed tokens: 104857600.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T05:47:27 | step: 12900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.994927076040767e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.49 | train loss last: 3.7 | consumed tokens: 105676800.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T05:47:45 | step: 13000 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.994808477931656e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.5 | train loss last: 3.88 | consumed tokens: 106496000.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T05:48:04 | step: 13100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.9946887884289026e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.49 | train loss last: 3.39 | consumed tokens: 107315200.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T05:48:22 | step: 13200 | train samples/s: 94.6 | train mfu (16-bit): -1.0 | lr mean: 4.9945676437346265e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.48 | train loss last: 3.69 | consumed tokens: 108134400.0 | grad norm avg: 0.86 | grad norm last: 0.94 | 
2026-01-01T05:48:40 | step: 13300 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.9944450438488275e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.5 | train loss last: 3.45 | consumed tokens: 108953600.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T05:48:58 | step: 13400 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.9943209887715057e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.46 | train loss last: 3.38 | consumed tokens: 109772800.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T05:49:17 | step: 13500 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.994195842300542e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.46 | train loss last: 3.2 | consumed tokens: 110592000.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T05:49:35 | step: 13600 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.994069240638055e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.48 | consumed tokens: 111411200.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T05:49:53 | step: 13700 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.993941183784045e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.46 | train loss last: 3.88 | consumed tokens: 112230400.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T05:50:11 | step: 13800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.993811671738513e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.5 | train loss last: 3.81 | consumed tokens: 113049600.0 | grad norm avg: 0.85 | grad norm last: 0.87 | 
2026-01-01T05:50:29 | step: 13900 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.993681068299338e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.48 | train loss last: 2.91 | consumed tokens: 113868800.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T05:50:47 | step: 14000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.993549009668641e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.49 | train loss last: 3.94 | consumed tokens: 114688000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T05:51:06 | step: 14100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.9934154958464205e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.52 | train loss last: 3.67 | consumed tokens: 115507200.0 | grad norm avg: 0.85 | grad norm last: 0.93 | 
2026-01-01T05:51:24 | step: 14200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.993280890630558e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.5 | train loss last: 3.98 | consumed tokens: 116326400.0 | grad norm avg: 0.85 | grad norm last: 0.81 | 
2026-01-01T05:51:42 | step: 14300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.993144466425292e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.45 | train loss last: 2.97 | consumed tokens: 117145600.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T05:52:00 | step: 14400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.993006950826384e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.06 | consumed tokens: 117964800.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T05:52:18 | step: 14500 | train samples/s: 95.2 | train mfu (16-bit): -1.0 | lr mean: 4.992867980035953e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.46 | train loss last: 3.78 | consumed tokens: 118784000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T05:52:36 | step: 14600 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.99272791785188e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.31 | consumed tokens: 119603200.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T05:52:54 | step: 14700 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.9925860366784036e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.46 | train loss last: 3.58 | consumed tokens: 120422400.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T05:53:13 | step: 14800 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.992443064111285e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.0 | consumed tokens: 121241600.0 | grad norm avg: 0.87 | grad norm last: 0.78 | 
2026-01-01T05:53:31 | step: 14900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.992299000150524e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.45 | train loss last: 3.14 | consumed tokens: 122060800.0 | grad norm avg: 0.85 | grad norm last: 0.87 | 
2026-01-01T05:53:49 | step: 15000 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.99215311720036e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.46 | train loss last: 3.02 | consumed tokens: 122880000.0 | grad norm avg: 0.86 | grad norm last: 0.79 | 
2026-01-01T05:54:08 | step: 15100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.992006142856553e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 5.38 | consumed tokens: 123699200.0 | grad norm avg: 0.86 | grad norm last: 0.81 | 
2026-01-01T05:54:26 | step: 15200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.991857713321224e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.46 | train loss last: 2.83 | consumed tokens: 124518400.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T05:54:44 | step: 15300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.991707828594372e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.46 | train loss last: 2.75 | consumed tokens: 125337600.0 | grad norm avg: 0.86 | grad norm last: 0.78 | 
2026-01-01T05:55:03 | step: 15400 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.9915564886759967e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.53 | consumed tokens: 126156800.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T05:55:21 | step: 15500 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.9914040573639795e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.17 | consumed tokens: 126976000.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T05:55:39 | step: 15600 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.9912501708604395e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.49 | train loss last: 3.31 | consumed tokens: 127795200.0 | grad norm avg: 0.87 | grad norm last: 0.97 | 
2026-01-01T05:55:57 | step: 15700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.991094829165377e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.27 | consumed tokens: 128614400.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T05:56:16 | step: 15800 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 4.990938032278791e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.45 | train loss last: 2.89 | consumed tokens: 129433600.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T05:56:34 | step: 15900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.990780143998563e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.48 | train loss last: 3.39 | consumed tokens: 130252800.0 | grad norm avg: 0.86 | grad norm last: 0.81 | 
2026-01-01T05:56:52 | step: 16000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.990620800526813e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.45 | train loss last: 3.5 | consumed tokens: 131072000.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T05:57:10 | step: 16100 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.990460001863539e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.46 | train loss last: 3.11 | consumed tokens: 131891200.0 | grad norm avg: 0.86 | grad norm last: 0.91 | 
2026-01-01T05:57:28 | step: 16200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.9902981118066236e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.34 | consumed tokens: 132710400.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T05:57:46 | step: 16300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.9901344027603045e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.84 | consumed tokens: 133529600.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T05:58:04 | step: 16400 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.989969602320343e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.59 | consumed tokens: 134348800.0 | grad norm avg: 0.86 | grad norm last: 0.93 | 
2026-01-01T05:58:22 | step: 16500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.98980371048674e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.3 | consumed tokens: 135168000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T05:58:40 | step: 16600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.989635999663733e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.03 | consumed tokens: 135987200.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T05:58:59 | step: 16700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.989467197447084e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.5 | train loss last: 3.55 | consumed tokens: 136806400.0 | grad norm avg: 0.86 | grad norm last: 0.91 | 
2026-01-01T05:59:17 | step: 16800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.989296940038912e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.46 | train loss last: 4.16 | consumed tokens: 137625600.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T05:59:35 | step: 16900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.989125227439217e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.46 | train loss last: 3.89 | consumed tokens: 138444800.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T05:59:53 | step: 17000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9889524234458804e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.52 | consumed tokens: 139264000.0 | grad norm avg: 0.86 | grad norm last: 0.79 | 
2026-01-01T06:00:11 | step: 17100 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 4.98877780046314e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.83 | consumed tokens: 140083200.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T06:00:29 | step: 17200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.9886020860867575e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.45 | train loss last: 4.25 | consumed tokens: 140902400.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T06:00:47 | step: 17300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.988425280316733e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.45 | consumed tokens: 141721600.0 | grad norm avg: 0.86 | grad norm last: 0.92 | 
2026-01-01T06:01:05 | step: 17400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.9882466555573046e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.61 | consumed tokens: 142540800.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T06:01:23 | step: 17500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.988066939404234e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.48 | train loss last: 3.69 | consumed tokens: 143360000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T06:01:41 | step: 17600 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.987885768059641e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.02 | consumed tokens: 144179200.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T06:02:00 | step: 17700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.987703141523525e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.45 | train loss last: 4.19 | consumed tokens: 144998400.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T06:02:18 | step: 17800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.987519423593767e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.45 | train loss last: 3.5 | consumed tokens: 145817600.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T06:02:36 | step: 17900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.987334250472486e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 4.16 | consumed tokens: 146636800.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T06:02:54 | step: 18000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.987147622159682e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.19 | consumed tokens: 147456000.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T06:03:12 | step: 18100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.9869595386553556e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.33 | consumed tokens: 148275200.0 | grad norm avg: 0.86 | grad norm last: 1.01 | 
2026-01-01T06:03:30 | step: 18200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.986770363757387e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.44 | consumed tokens: 149094400.0 | grad norm avg: 0.86 | grad norm last: 0.91 | 
2026-01-01T06:03:48 | step: 18300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.9865793698700145e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.16 | consumed tokens: 149913600.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T06:04:06 | step: 18400 | train samples/s: 95.2 | train mfu (16-bit): -1.0 | lr mean: 4.986387284589e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.25 | consumed tokens: 150732800.0 | grad norm avg: 0.87 | grad norm last: 0.79 | 
2026-01-01T06:04:24 | step: 18500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9861941079143435e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.48 | train loss last: 3.62 | consumed tokens: 151552000.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T06:04:43 | step: 18600 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.9859991122502834e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 4.09 | consumed tokens: 152371200.0 | grad norm avg: 0.86 | grad norm last: 0.81 | 
2026-01-01T06:05:01 | step: 18700 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.985803025192581e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.45 | train loss last: 3.47 | consumed tokens: 153190400.0 | grad norm avg: 0.86 | grad norm last: 0.93 | 
2026-01-01T06:05:19 | step: 18800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.985605482943356e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 4.25 | consumed tokens: 154009600.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T06:05:37 | step: 18900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.985406849300489e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.81 | consumed tokens: 154828800.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T06:05:55 | step: 19000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.985206760466099e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.2 | consumed tokens: 155648000.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T06:06:13 | step: 19100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.985004852642305e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.5 | consumed tokens: 156467200.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T06:06:31 | step: 19200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.98480221722275e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 4.09 | consumed tokens: 157286400.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T06:06:49 | step: 19300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9845977628137916e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.52 | consumed tokens: 158105600.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T06:07:07 | step: 19400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.984392217011191e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.81 | consumed tokens: 158924800.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T06:07:25 | step: 19500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.9841852160170674e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.8 | consumed tokens: 159744000.0 | grad norm avg: 0.87 | grad norm last: 1.02 | 
2026-01-01T06:07:43 | step: 19600 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.983976759831421e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.97 | consumed tokens: 160563200.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T06:08:02 | step: 19700 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 4.9837672122521326e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.42 | consumed tokens: 161382400.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T06:08:20 | step: 19800 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.9835558456834406e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.11 | consumed tokens: 162201600.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T06:08:38 | step: 19900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.9833433877211064e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.45 | train loss last: 3.23 | consumed tokens: 163020800.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T06:08:56 | step: 20000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.98312983836513e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.03 | consumed tokens: 163840000.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T06:09:15 | step: 20100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.98291447001975e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.02 | consumed tokens: 164659200.0 | grad norm avg: 0.86 | grad norm last: 0.93 | 
2026-01-01T06:09:34 | step: 20200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.9826980102807283e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.64 | consumed tokens: 165478400.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T06:09:52 | step: 20300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.9824800953501835e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.45 | train loss last: 3.66 | consumed tokens: 166297600.0 | grad norm avg: 0.85 | grad norm last: 0.81 | 
2026-01-01T06:10:10 | step: 20400 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9822610890259966e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.58 | consumed tokens: 167116800.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T06:10:28 | step: 20500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.982040263712406e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 4.12 | consumed tokens: 167936000.0 | grad norm avg: 0.88 | grad norm last: 0.99 | 
2026-01-01T06:10:46 | step: 20600 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.9818183470051736e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.45 | train loss last: 3.23 | consumed tokens: 168755200.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T06:11:04 | step: 20700 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.981594975106418e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.91 | consumed tokens: 169574400.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T06:11:22 | step: 20800 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.9813705118140206e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.23 | consumed tokens: 170393600.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T06:11:40 | step: 20900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.9811442295322195e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.41 | consumed tokens: 171212800.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T06:11:59 | step: 21000 | train samples/s: 94.3 | train mfu (16-bit): -1.0 | lr mean: 4.980916855856776e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.45 | train loss last: 3.05 | consumed tokens: 172032000.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T06:12:17 | step: 21100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.980688390787691e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.48 | consumed tokens: 172851200.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T06:12:35 | step: 21200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.980458106729202e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.59 | consumed tokens: 173670400.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T06:12:53 | step: 21300 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.980226731277071e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.11 | consumed tokens: 174489600.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T06:13:11 | step: 21400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.979993900633417e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.45 | train loss last: 4.41 | consumed tokens: 175308800.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T06:13:29 | step: 21500 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.9797596147982404e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.36 | consumed tokens: 176128000.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T06:13:47 | step: 21600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.9795242375694215e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.14 | consumed tokens: 176947200.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T06:14:05 | step: 21700 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.97928740514908e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.02 | consumed tokens: 177766400.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T06:14:23 | step: 21800 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.9790491175372154e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.59 | consumed tokens: 178585600.0 | grad norm avg: 0.86 | grad norm last: 0.91 | 
2026-01-01T06:14:42 | step: 21900 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.978809374733828e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.42 | consumed tokens: 179404800.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T06:15:00 | step: 22000 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.9785685405367985e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.06 | consumed tokens: 180224000.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T06:15:18 | step: 22100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.978326251148246e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.06 | consumed tokens: 181043200.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T06:15:36 | step: 22200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.978082506568171e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 4.09 | consumed tokens: 181862400.0 | grad norm avg: 0.88 | grad norm last: 0.98 | 
2026-01-01T06:15:54 | step: 22300 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 4.977837306796573e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.49 | train loss last: 3.39 | consumed tokens: 182681600.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T06:16:12 | step: 22400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.977591015631333e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.42 | consumed tokens: 183500800.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T06:16:30 | step: 22500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.97734326927457e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.8 | consumed tokens: 184320000.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T06:16:48 | step: 22600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.977094431524165e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.41 | consumed tokens: 185139200.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T06:17:06 | step: 22700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.9768437747843564e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.5 | consumed tokens: 185958400.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-01T06:17:24 | step: 22800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.9765920266509056e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 4.16 | consumed tokens: 186777600.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T06:17:43 | step: 22900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.976338823325932e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.88 | consumed tokens: 187596800.0 | grad norm avg: 0.87 | grad norm last: 1.02 | 
2026-01-01T06:18:01 | step: 23000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.9760841648094356e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 2.78 | consumed tokens: 188416000.0 | grad norm avg: 0.87 | grad norm last: 0.94 | 
2026-01-01T06:18:19 | step: 23100 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.975828414899297e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.03 | consumed tokens: 189235200.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T06:18:37 | step: 23200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.975571209797636e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 2.78 | consumed tokens: 190054400.0 | grad norm avg: 0.86 | grad norm last: 0.93 | 
2026-01-01T06:18:55 | step: 23300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.9753125495044515e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.09 | consumed tokens: 190873600.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T06:19:13 | step: 23400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.975052797817625e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.33 | consumed tokens: 191692800.0 | grad norm avg: 0.87 | grad norm last: 0.78 | 
2026-01-01T06:19:31 | step: 23500 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.974791590939276e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.16 | consumed tokens: 192512000.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T06:19:49 | step: 23600 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 4.974528928869404e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 2.81 | consumed tokens: 193331200.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T06:20:07 | step: 23700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.974264811608009e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.47 | consumed tokens: 194150400.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T06:20:25 | step: 23800 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.973999602952972e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.36 | consumed tokens: 194969600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T06:20:43 | step: 23900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.973732939106412e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.56 | consumed tokens: 195788800.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T06:21:02 | step: 24000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9734648200683296e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.08 | consumed tokens: 196608000.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T06:21:20 | step: 24100 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.973195245838724e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.09 | consumed tokens: 197427200.0 | grad norm avg: 0.87 | grad norm last: 0.94 | 
2026-01-01T06:21:38 | step: 24200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.9729245802154765e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.16 | consumed tokens: 198246400.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T06:21:56 | step: 24300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.972652459400706e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 4.03 | consumed tokens: 199065600.0 | grad norm avg: 0.87 | grad norm last: 0.76 | 
2026-01-01T06:22:14 | step: 24400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.972378883394413e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.05 | consumed tokens: 199884800.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T06:22:32 | step: 24500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.972104215994477e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.0 | consumed tokens: 200704000.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T06:22:50 | step: 24600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.971828093403019e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.06 | consumed tokens: 201523200.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-01T06:23:08 | step: 24700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.971550515620038e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.69 | consumed tokens: 202342400.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T06:23:26 | step: 24800 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.971271482645534e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.59 | consumed tokens: 203161600.0 | grad norm avg: 0.87 | grad norm last: 0.96 | 
2026-01-01T06:23:45 | step: 24900 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 4.970991358277388e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.69 | consumed tokens: 203980800.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T06:24:03 | step: 25000 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.970709778717719e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.19 | consumed tokens: 204800000.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T06:24:22 | step: 25100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.970426743966527e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.48 | consumed tokens: 205619200.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T06:24:41 | step: 25200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9701426178216934e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.05 | consumed tokens: 206438400.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T06:24:59 | step: 25300 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.969857036485337e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.27 | consumed tokens: 207257600.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T06:25:17 | step: 25400 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.969569999957457e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 2.81 | consumed tokens: 208076800.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T06:25:35 | step: 25500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.969281508238055e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.17 | consumed tokens: 208896000.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T06:25:53 | step: 25600 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.96899192512501e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.84 | consumed tokens: 209715200.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T06:26:11 | step: 25700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.968700886820443e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.34 | consumed tokens: 210534400.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T06:26:29 | step: 25800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.968408393324353e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.47 | consumed tokens: 211353600.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T06:26:47 | step: 25900 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.9681148084346205e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.98 | consumed tokens: 212172800.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T06:27:06 | step: 26000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.9678194045554847e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.38 | consumed tokens: 212992000.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T06:27:24 | step: 26100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.967522909282707e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.25 | consumed tokens: 213811200.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T06:27:42 | step: 26200 | train samples/s: 95.0 | train mfu (16-bit): -1.0 | lr mean: 4.9672253226162866e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.97 | consumed tokens: 214630400.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T06:28:00 | step: 26300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.9669262807583436e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.58 | consumed tokens: 215449600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T06:28:18 | step: 26400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.966625783708878e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 2.89 | consumed tokens: 216268800.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T06:28:36 | step: 26500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.966323831467889e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.92 | consumed tokens: 217088000.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T06:28:54 | step: 26600 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.966020424035378e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.95 | consumed tokens: 217907200.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T06:29:13 | step: 26700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.965715925209224e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.09 | consumed tokens: 218726400.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T06:29:31 | step: 26800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.965409971191548e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.77 | consumed tokens: 219545600.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T06:29:49 | step: 26900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.965102925780229e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.39 | consumed tokens: 220364800.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T06:30:07 | step: 27000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.964794425177388e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.11 | consumed tokens: 221184000.0 | grad norm avg: 0.87 | grad norm last: 0.78 | 
2026-01-01T06:30:25 | step: 27100 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.964484469383024e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.84 | consumed tokens: 222003200.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T06:30:43 | step: 27200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.9641730583971366e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 2.91 | consumed tokens: 222822400.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T06:31:01 | step: 27300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.9638605560176075e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.05 | consumed tokens: 223641600.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T06:31:19 | step: 27400 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.9635465984465554e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.38 | consumed tokens: 224460800.0 | grad norm avg: 0.87 | grad norm last: 0.73 | 
2026-01-01T06:31:38 | step: 27500 | train samples/s: 95.0 | train mfu (16-bit): -1.0 | lr mean: 4.9632311856839806e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.5 | consumed tokens: 225280000.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T06:31:56 | step: 27600 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.962914317729883e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.2 | consumed tokens: 226099200.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T06:32:14 | step: 27700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.962596358382143e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.12 | consumed tokens: 226918400.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T06:32:32 | step: 27800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.9622769438428804e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.02 | consumed tokens: 227737600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T06:32:50 | step: 27900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.9619564379099756e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.91 | consumed tokens: 228556800.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T06:33:08 | step: 28000 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.961634112987667e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.47 | consumed tokens: 229376000.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T06:33:26 | step: 28100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.961310696671717e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.77 | consumed tokens: 230195200.0 | grad norm avg: 0.88 | grad norm last: 0.98 | 
2026-01-01T06:33:44 | step: 28200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.960986188962124e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.06 | consumed tokens: 231014400.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T06:34:02 | step: 28300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.960659862263128e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 4.03 | consumed tokens: 231833600.0 | grad norm avg: 0.87 | grad norm last: 0.97 | 
2026-01-01T06:34:21 | step: 28400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.96033244417049e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.78 | consumed tokens: 232652800.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T06:34:39 | step: 28500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.960003570886329e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 2.5 | consumed tokens: 233472000.0 | grad norm avg: 0.88 | grad norm last: 1.04 | 
2026-01-01T06:34:57 | step: 28600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.9596736062085256e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.66 | consumed tokens: 234291200.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T06:35:15 | step: 28700 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.959341822541319e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.62 | consumed tokens: 235110400.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T06:35:33 | step: 28800 | train samples/s: 95.2 | train mfu (16-bit): -1.0 | lr mean: 4.9590093112783507e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.69 | consumed tokens: 235929600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T06:35:51 | step: 28900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.958674981025979e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.31 | consumed tokens: 236748800.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T06:36:09 | step: 29000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.958339559379965e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.05 | consumed tokens: 237568000.0 | grad norm avg: 0.87 | grad norm last: 0.99 | 
2026-01-01T06:36:27 | step: 29100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.9580026825424284e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.73 | consumed tokens: 238387200.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T06:36:45 | step: 29200 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.957664350513369e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.25 | consumed tokens: 239206400.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T06:37:04 | step: 29300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.9573245632927865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.86 | consumed tokens: 240025600.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T06:37:22 | step: 29400 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.956983684678562e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 2.59 | consumed tokens: 240844800.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T06:37:40 | step: 29500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.9566417146706954e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 4.31 | consumed tokens: 241664000.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T06:37:58 | step: 29600 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.956297925673425e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.38 | consumed tokens: 242483200.0 | grad norm avg: 0.88 | grad norm last: 0.98 | 
2026-01-01T06:38:16 | step: 29700 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.955953045282513e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.09 | consumed tokens: 243302400.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T06:38:34 | step: 29800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.955606709700078e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.69 | consumed tokens: 244121600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T06:38:53 | step: 29900 | train samples/s: 91.8 | train mfu (16-bit): -1.0 | lr mean: 4.95525891892612e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 4.03 | consumed tokens: 244940800.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T06:39:11 | step: 30000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.95491003675852e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.62 | consumed tokens: 245760000.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T06:39:31 | step: 30100 | train samples/s: 95.2 | train mfu (16-bit): -1.0 | lr mean: 4.954559699399397e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.77 | consumed tokens: 246579200.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T06:39:49 | step: 30200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.954207906848751e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.36 | consumed tokens: 247398400.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T06:40:07 | step: 30300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.953855022904463e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.59 | consumed tokens: 248217600.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T06:40:25 | step: 30400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.9535006837686524e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.72 | consumed tokens: 249036800.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T06:40:43 | step: 30500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.953144889441319e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.36 | consumed tokens: 249856000.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T06:41:01 | step: 30600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.952788003720343e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.62 | consumed tokens: 250675200.0 | grad norm avg: 0.86 | grad norm last: 0.98 | 
2026-01-01T06:41:19 | step: 30700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.9524296628078446e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 4.16 | consumed tokens: 251494400.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T06:41:37 | step: 30800 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.952069866703823e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.09 | consumed tokens: 252313600.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T06:41:55 | step: 30900 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.95170897920616e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.8 | consumed tokens: 253132800.0 | grad norm avg: 0.89 | grad norm last: 0.77 | 
2026-01-01T06:42:13 | step: 31000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.951346272719093e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.69 | consumed tokens: 253952000.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T06:42:31 | step: 31100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.950982838636264e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 2.75 | consumed tokens: 254771200.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T06:42:49 | step: 31200 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.950617585564032e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.39 | consumed tokens: 255590400.0 | grad norm avg: 0.87 | grad norm last: 0.96 | 
2026-01-01T06:43:07 | step: 31300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.950251241098158e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 4.03 | consumed tokens: 256409600.0 | grad norm avg: 0.87 | grad norm last: 0.79 | 
2026-01-01T06:43:25 | step: 31400 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.949883441440761e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.23 | consumed tokens: 257228800.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T06:43:43 | step: 31500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.949514186591841e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 4.31 | consumed tokens: 258048000.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T06:44:02 | step: 31600 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9491438403492793e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.36 | consumed tokens: 258867200.0 | grad norm avg: 0.86 | grad norm last: 0.81 | 
2026-01-01T06:44:20 | step: 31700 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.9487720389151946e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.58 | consumed tokens: 259686400.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T06:44:38 | step: 31800 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.948398782289587e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 2.83 | consumed tokens: 260505600.0 | grad norm avg: 0.87 | grad norm last: 0.98 | 
2026-01-01T06:44:56 | step: 31900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.948024434270337e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.66 | consumed tokens: 261324800.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T06:45:14 | step: 32000 | train samples/s: 95.2 | train mfu (16-bit): -1.0 | lr mean: 4.9476486310595647e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.8 | consumed tokens: 262144000.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T06:45:32 | step: 32100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.947271372657269e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.8 | consumed tokens: 262963200.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T06:45:51 | step: 32200 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.946893022861332e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.28 | consumed tokens: 263782400.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T06:46:09 | step: 32300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.946513217873871e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.3 | consumed tokens: 264601600.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T06:46:27 | step: 32400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.946131957694888e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.61 | consumed tokens: 265420800.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T06:46:45 | step: 32500 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.945749606122263e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.88 | consumed tokens: 266240000.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T06:47:03 | step: 32600 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.9453657993581146e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.3 | consumed tokens: 267059200.0 | grad norm avg: 0.87 | grad norm last: 0.74 | 
2026-01-01T06:47:21 | step: 32700 | train samples/s: 95.0 | train mfu (16-bit): -1.0 | lr mean: 4.9449805374024436e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 2.91 | consumed tokens: 267878400.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T06:47:39 | step: 32800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.94459382025525e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 2.25 | consumed tokens: 268697600.0 | grad norm avg: 0.87 | grad norm last: 0.97 | 
2026-01-01T06:47:58 | step: 32900 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.944206011714414e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.3 | consumed tokens: 269516800.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T06:48:16 | step: 33000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.943816747982055e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 4.25 | consumed tokens: 270336000.0 | grad norm avg: 0.86 | grad norm last: 0.95 | 
2026-01-01T06:48:34 | step: 33100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.943426392856054e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.48 | consumed tokens: 271155200.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T06:48:52 | step: 33200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.94303458253853e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.41 | consumed tokens: 271974400.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T06:49:10 | step: 33300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.9426413170294836e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.09 | consumed tokens: 272793600.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T06:49:28 | step: 33400 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.942246596328914e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.52 | consumed tokens: 273612800.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T06:49:46 | step: 33500 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.9418507842347026e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.5 | consumed tokens: 274432000.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T06:50:04 | step: 33600 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.941453516948968e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.03 | consumed tokens: 275251200.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T06:50:22 | step: 33700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.9410551582695916e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 4.25 | consumed tokens: 276070400.0 | grad norm avg: 0.87 | grad norm last: 0.98 | 
2026-01-01T06:50:40 | step: 33800 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.940655344398692e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.17 | consumed tokens: 276889600.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T06:50:58 | step: 33900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.94025407533627e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.16 | consumed tokens: 277708800.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T06:51:17 | step: 34000 | train samples/s: 95.3 | train mfu (16-bit): -1.0 | lr mean: 4.939851351082325e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.67 | consumed tokens: 278528000.0 | grad norm avg: 0.88 | grad norm last: 1.02 | 
2026-01-01T06:51:35 | step: 34100 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.939447535434738e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.06 | consumed tokens: 279347200.0 | grad norm avg: 0.88 | grad norm last: 0.97 | 
2026-01-01T06:51:53 | step: 34200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.939042264595628e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.22 | consumed tokens: 280166400.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T06:52:11 | step: 34300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.9386359023628756e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.12 | consumed tokens: 280985600.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T06:52:29 | step: 34400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.93822772114072e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.61 | consumed tokens: 281804800.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T06:52:47 | step: 34500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.937818448524922e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 2.97 | consumed tokens: 282624000.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T06:53:05 | step: 34600 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.937408084515482e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.67 | consumed tokens: 283443200.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T06:53:23 | step: 34700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.9369962653145194e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 4.28 | consumed tokens: 284262400.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T06:53:41 | step: 34800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.936582990922034e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.66 | consumed tokens: 285081600.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T06:54:00 | step: 34900 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.936168261338025e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.78 | consumed tokens: 285900800.0 | grad norm avg: 0.88 | grad norm last: 1.02 | 
2026-01-01T06:54:18 | step: 35000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.935752440360375e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 2.73 | consumed tokens: 286720000.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T06:54:37 | step: 35100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.935335164191201e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 2.83 | consumed tokens: 287539200.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T06:54:55 | step: 35200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.934916796628386e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 2.61 | consumed tokens: 288358400.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T06:55:13 | step: 35300 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.934496610076167e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.98 | consumed tokens: 289177600.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T06:55:31 | step: 35400 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.934075695928186e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.39 | consumed tokens: 289996800.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T06:55:50 | step: 35500 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.933652962790802e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.73 | consumed tokens: 290816000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T06:56:08 | step: 35600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.933229138259776e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.27 | consumed tokens: 291635200.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T06:56:26 | step: 35700 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.932803858537227e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.33 | consumed tokens: 292454400.0 | grad norm avg: 0.88 | grad norm last: 1.0 | 
2026-01-01T06:56:44 | step: 35800 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.932377123623155e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.59 | consumed tokens: 293273600.0 | grad norm avg: 0.88 | grad norm last: 0.95 | 
2026-01-01T06:57:02 | step: 35900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.931949297315441e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.05 | consumed tokens: 294092800.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T06:57:20 | step: 36000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.931520015816204e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.34 | consumed tokens: 294912000.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T06:57:38 | step: 36100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.931089642923325e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.77 | consumed tokens: 295731200.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T06:57:57 | step: 36200 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.9306578148389235e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.52 | consumed tokens: 296550400.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T06:58:15 | step: 36300 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.930224531562999e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.56 | consumed tokens: 297369600.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T06:58:33 | step: 36400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.929790156893432e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.25 | consumed tokens: 298188800.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T06:58:51 | step: 36500 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.929353963234462e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 2.36 | consumed tokens: 299008000.0 | grad norm avg: 0.86 | grad norm last: 0.97 | 
2026-01-01T06:59:09 | step: 36600 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.92891704197973e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.22 | consumed tokens: 299827200.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T06:59:27 | step: 36700 | train samples/s: 94.8 | train mfu (16-bit): -1.0 | lr mean: 4.928478301735595e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.48 | consumed tokens: 300646400.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T06:59:45 | step: 36800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.9280384700978175e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.36 | consumed tokens: 301465600.0 | grad norm avg: 0.86 | grad norm last: 0.95 | 
2026-01-01T07:00:04 | step: 36900 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.927597547066398e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 4.06 | consumed tokens: 302284800.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T07:00:22 | step: 37000 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 4.927154805045575e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 2.58 | consumed tokens: 303104000.0 | grad norm avg: 0.86 | grad norm last: 0.94 | 
2026-01-01T07:00:40 | step: 37100 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 4.92671097163111e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.72 | consumed tokens: 303923200.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T07:00:58 | step: 37200 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.926265683025122e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.67 | consumed tokens: 304742400.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T07:01:17 | step: 37300 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 4.9258193030254915e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.67 | consumed tokens: 305561600.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T07:01:35 | step: 37400 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.9253714678343385e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 2.78 | consumed tokens: 306380800.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T07:01:53 | step: 37500 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.9249225412495434e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 2.98 | consumed tokens: 307200000.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T07:02:11 | step: 37600 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 4.924471795675345e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 2.77 | consumed tokens: 308019200.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T07:02:30 | step: 37700 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.924019958707504e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.42 | consumed tokens: 308838400.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T07:02:48 | step: 37800 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.923567030346021e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 2.78 | consumed tokens: 309657600.0 | grad norm avg: 0.88 | grad norm last: 0.79 | 
2026-01-01T07:03:06 | step: 37900 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.923112646793015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 2.67 | consumed tokens: 310476800.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T07:03:25 | step: 38000 | train samples/s: 94.0 | train mfu (16-bit): -1.0 | lr mean: 4.922656808048487e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.02 | consumed tokens: 311296000.0 | grad norm avg: 0.87 | grad norm last: 0.98 | 
2026-01-01T07:03:43 | step: 38100 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.922199514112435e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.69 | consumed tokens: 312115200.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T07:04:01 | step: 38200 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.921741128782742e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.7 | consumed tokens: 312934400.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T07:04:19 | step: 38300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.921281288261525e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.66 | consumed tokens: 313753600.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T07:04:38 | step: 38400 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 4.920820356346667e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 2.95 | consumed tokens: 314572800.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T07:04:56 | step: 38500 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.9203579692402855e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.61 | consumed tokens: 315392000.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T07:05:14 | step: 38600 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.919894126942381e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.55 | consumed tokens: 316211200.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T07:05:32 | step: 38700 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 4.919429193250835e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 2.84 | consumed tokens: 317030400.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T07:05:51 | step: 38800 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 4.918962804367766e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 2.94 | consumed tokens: 317849600.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T07:06:09 | step: 38900 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.918494960293174e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.08 | consumed tokens: 318668800.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T07:06:27 | step: 39000 | train samples/s: 95.3 | train mfu (16-bit): -1.0 | lr mean: 4.91802602482494e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 4.09 | consumed tokens: 319488000.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T07:06:46 | step: 39100 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 4.917555634165183e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.31 | consumed tokens: 320307200.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T07:07:04 | step: 39200 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 4.9170841521117836e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.72 | consumed tokens: 321126400.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T07:07:22 | step: 39300 | train samples/s: 94.1 | train mfu (16-bit): -1.0 | lr mean: 4.916610851068981e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.7 | consumed tokens: 321945600.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T07:07:41 | step: 39400 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.916136822430417e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.27 | consumed tokens: 322764800.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T07:07:59 | step: 39500 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 4.9156609748024493e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.47 | consumed tokens: 323584000.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T07:08:17 | step: 39600 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.9151840357808396e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.45 | consumed tokens: 324403200.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T07:08:35 | step: 39700 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.914705641567707e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.64 | consumed tokens: 325222400.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T07:08:54 | step: 39800 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.9142261559609324e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.27 | consumed tokens: 326041600.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T07:09:12 | step: 39900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.913745215162635e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 4.44 | consumed tokens: 326860800.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T07:09:30 | step: 40000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.913263182970695e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.11 | consumed tokens: 327680000.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T07:09:49 | step: 40100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.912779331789352e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 2.52 | consumed tokens: 328499200.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T07:10:07 | step: 40200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.9122947530122474e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.58 | consumed tokens: 329318400.0 | grad norm avg: 0.87 | grad norm last: 1.04 | 
2026-01-01T07:10:26 | step: 40300 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.911808355245739e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.17 | consumed tokens: 330137600.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T07:10:44 | step: 40400 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.911320866085589e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.44 | consumed tokens: 330956800.0 | grad norm avg: 0.88 | grad norm last: 0.99 | 
2026-01-01T07:11:02 | step: 40500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.910831921733916e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.25 | consumed tokens: 331776000.0 | grad norm avg: 0.88 | grad norm last: 0.99 | 
2026-01-01T07:11:20 | step: 40600 | train samples/s: 95.2 | train mfu (16-bit): -1.0 | lr mean: 4.9103418859886006e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 2.67 | consumed tokens: 332595200.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T07:11:39 | step: 40700 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 4.9098503950517625e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 2.94 | consumed tokens: 333414400.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T07:11:57 | step: 40800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.9093574489234015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.3 | consumed tokens: 334233600.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T07:12:15 | step: 40900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.9088634114013985e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 2.97 | consumed tokens: 335052800.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T07:12:33 | step: 41000 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.9083679186878726e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.3 | consumed tokens: 335872000.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T07:12:51 | step: 41100 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.9078713345807046e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 2.64 | consumed tokens: 336691200.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T07:13:09 | step: 41200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.907373295282014e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.34 | consumed tokens: 337510400.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T07:13:27 | step: 41300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.9068738007918e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.3 | consumed tokens: 338329600.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T07:13:45 | step: 41400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.9063728511100635e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.0 | consumed tokens: 339148800.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T07:14:03 | step: 41500 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.9058711738325655e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.3 | consumed tokens: 339968000.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T07:14:21 | step: 41600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.905367677565664e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.17 | consumed tokens: 340787200.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T07:14:39 | step: 41700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.9048630899051204e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.22 | consumed tokens: 341606400.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T07:14:58 | step: 41800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.904357047053054e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.53 | consumed tokens: 342425600.0 | grad norm avg: 0.88 | grad norm last: 1.0 | 
2026-01-01T07:15:16 | step: 41900 | train samples/s: 95.3 | train mfu (16-bit): -1.0 | lr mean: 4.9038499128073454e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.42 | consumed tokens: 343244800.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T07:15:34 | step: 42000 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.903340959572233e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 2.95 | consumed tokens: 344064000.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T07:15:52 | step: 42100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.90283127874136e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.44 | consumed tokens: 344883200.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T07:16:10 | step: 42200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.902320142718963e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 2.88 | consumed tokens: 345702400.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T07:16:28 | step: 42300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.901807551505044e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 2.97 | consumed tokens: 346521600.0 | grad norm avg: 0.88 | grad norm last: 0.96 | 
2026-01-01T07:16:46 | step: 42400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.901293505099602e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.42 | consumed tokens: 347340800.0 | grad norm avg: 0.9 | grad norm last: 0.81 | 
2026-01-01T07:17:04 | step: 42500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.900778367300518e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.05 | consumed tokens: 348160000.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T07:17:22 | step: 42600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.900261774309911e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.52 | consumed tokens: 348979200.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T07:17:41 | step: 42700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.899744089925662e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.45 | consumed tokens: 349798400.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T07:17:59 | step: 42800 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.89922495034989e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.38 | consumed tokens: 350617600.0 | grad norm avg: 0.89 | grad norm last: 0.77 | 
2026-01-01T07:18:17 | step: 42900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.898704355582595e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.12 | consumed tokens: 351436800.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T07:18:35 | step: 43000 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.898182669421658e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.0 | consumed tokens: 352256000.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T07:18:53 | step: 43100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.897659528069198e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.22 | consumed tokens: 353075200.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T07:19:11 | step: 43200 | train samples/s: 94.8 | train mfu (16-bit): -1.0 | lr mean: 4.897135295323096e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 4.0 | consumed tokens: 353894400.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T07:19:30 | step: 43300 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.8966096073854715e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.17 | consumed tokens: 354713600.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T07:19:48 | step: 43400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.8960828280542046e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.59 | consumed tokens: 355532800.0 | grad norm avg: 0.88 | grad norm last: 0.78 | 
2026-01-01T07:20:06 | step: 43500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.895554229733534e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.05 | consumed tokens: 356352000.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T07:20:24 | step: 43600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.895024903817102e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.33 | consumed tokens: 357171200.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T07:20:42 | step: 43700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.894493758911267e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.12 | consumed tokens: 357990400.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T07:21:00 | step: 43800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.8939615226117894e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.06 | consumed tokens: 358809600.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T07:21:18 | step: 43900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.89342819491867e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.53 | consumed tokens: 359628800.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T07:21:36 | step: 44000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.8928930482361466e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.33 | consumed tokens: 360448000.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T07:21:54 | step: 44100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.892357173957862e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.64 | consumed tokens: 361267200.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T07:22:12 | step: 44200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.891819480690174e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.33 | consumed tokens: 362086400.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T07:22:30 | step: 44300 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.8912806960288435e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.33 | consumed tokens: 362905600.0 | grad norm avg: 0.88 | grad norm last: 0.75 | 
2026-01-01T07:22:48 | step: 44400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.890740819973871e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.39 | consumed tokens: 363724800.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T07:23:07 | step: 44500 | train samples/s: 94.8 | train mfu (16-bit): -1.0 | lr mean: 4.890199124929495e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.5 | consumed tokens: 364544000.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T07:23:25 | step: 44600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.889656702289358e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.47 | consumed tokens: 365363200.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T07:23:43 | step: 44700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.889112460659817e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.45 | consumed tokens: 366182400.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T07:24:01 | step: 44800 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.888567127636634e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.52 | consumed tokens: 367001600.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T07:24:20 | step: 44900 | train samples/s: 95.3 | train mfu (16-bit): -1.0 | lr mean: 4.8880207032198086e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.56 | consumed tokens: 367820800.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T07:24:38 | step: 45000 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.8874728236114606e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.17 | consumed tokens: 368640000.0 | grad norm avg: 0.89 | grad norm last: 1.01 | 
2026-01-01T07:24:57 | step: 45100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.88692348881159e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.42 | consumed tokens: 369459200.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T07:25:15 | step: 45200 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.886372698820196e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.02 | consumed tokens: 370278400.0 | grad norm avg: 0.88 | grad norm last: 0.95 | 
2026-01-01T07:25:33 | step: 45300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.885821181233041e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.19 | consumed tokens: 371097600.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T07:25:51 | step: 45400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.8852678446564823e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.75 | consumed tokens: 371916800.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T07:26:10 | step: 45500 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.8847134166862816e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.8 | consumed tokens: 372736000.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T07:26:28 | step: 45600 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.884157533524558e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 2.75 | consumed tokens: 373555200.0 | grad norm avg: 0.89 | grad norm last: 0.97 | 
2026-01-01T07:26:46 | step: 45700 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.883600558969192e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.02 | consumed tokens: 374374400.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T07:27:04 | step: 45800 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.8830421292223036e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.03 | consumed tokens: 375193600.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T07:27:22 | step: 45900 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.882482608081773e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 4.03 | consumed tokens: 376012800.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T07:27:41 | step: 46000 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 4.8819216317497194e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.5 | consumed tokens: 376832000.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T07:27:59 | step: 46100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.881359200226143e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 2.84 | consumed tokens: 377651200.0 | grad norm avg: 0.89 | grad norm last: 1.0 | 
2026-01-01T07:28:17 | step: 46200 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.8807956773089245e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 2.72 | consumed tokens: 378470400.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T07:28:35 | step: 46300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.880230699200183e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.66 | consumed tokens: 379289600.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T07:28:53 | step: 46400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.8796646296978e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 2.8 | consumed tokens: 380108800.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T07:29:11 | step: 46500 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.8790971050038934e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 2.69 | consumed tokens: 380928000.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T07:29:29 | step: 46600 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.878528125118464e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.19 | consumed tokens: 381747200.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T07:29:47 | step: 46700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.877958053839393e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.08 | consumed tokens: 382566400.0 | grad norm avg: 0.89 | grad norm last: 0.97 | 
2026-01-01T07:30:05 | step: 46800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.877386527368799e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.64 | consumed tokens: 383385600.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T07:30:23 | step: 46900 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.8768139095045626e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.5 | consumed tokens: 384204800.0 | grad norm avg: 0.89 | grad norm last: 0.79 | 
2026-01-01T07:30:42 | step: 47000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.8762398364488035e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 2.78 | consumed tokens: 385024000.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T07:31:00 | step: 47100 | train samples/s: 94.9 | train mfu (16-bit): -1.0 | lr mean: 4.8756646719994023e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.06 | consumed tokens: 385843200.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T07:31:18 | step: 47200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.875088052358478e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.25 | consumed tokens: 386662400.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T07:31:36 | step: 47300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.874510341323912e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.06 | consumed tokens: 387481600.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T07:31:54 | step: 47400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.8739308112999424e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.0 | consumed tokens: 388300800.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T07:32:12 | step: 47500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.873350553680211e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 2.69 | consumed tokens: 389120000.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T07:32:30 | step: 47600 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.8727688408689573e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 2.75 | consumed tokens: 389939200.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T07:32:48 | step: 47700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.8721856728661805e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 2.8 | consumed tokens: 390758400.0 | grad norm avg: 0.88 | grad norm last: 0.8 | 
2026-01-01T07:33:07 | step: 47800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.871601049671881e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.98 | consumed tokens: 391577600.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T07:33:25 | step: 47900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.871015335083939e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.56 | consumed tokens: 392396800.0 | grad norm avg: 0.88 | grad norm last: 0.95 | 
2026-01-01T07:33:43 | step: 48000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.870428529102355e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 2.75 | consumed tokens: 393216000.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T07:34:01 | step: 48100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.8698402679292485e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 4.28 | consumed tokens: 394035200.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T07:34:19 | step: 48200 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.869250551564619e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.56 | consumed tokens: 394854400.0 | grad norm avg: 0.88 | grad norm last: 0.98 | 
2026-01-01T07:34:37 | step: 48300 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.868659743806347e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.42 | consumed tokens: 395673600.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T07:34:56 | step: 48400 | train samples/s: 95.1 | train mfu (16-bit): -1.0 | lr mean: 4.868067480856553e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.61 | consumed tokens: 396492800.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T07:35:14 | step: 48500 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.867474126513116e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 2.77 | consumed tokens: 397312000.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T07:35:32 | step: 48600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.8668793169781566e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.05 | consumed tokens: 398131200.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T07:35:50 | step: 48700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.866283052251674e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.44 | consumed tokens: 398950400.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T07:36:08 | step: 48800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.86568569613155e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.78 | consumed tokens: 399769600.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T07:36:26 | step: 48900 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.865087248617783e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.22 | consumed tokens: 400588800.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T07:36:44 | step: 49000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.864487345912494e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 2.88 | consumed tokens: 401408000.0 | grad norm avg: 0.89 | grad norm last: 0.99 | 
2026-01-01T07:37:02 | step: 49100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.8638859880156815e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.31 | consumed tokens: 402227200.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T07:37:20 | step: 49200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.863283538725227e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.12 | consumed tokens: 403046400.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T07:37:38 | step: 49300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.86267963424325e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.69 | consumed tokens: 403865600.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T07:37:57 | step: 49400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.8620746383676305e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 4.09 | consumed tokens: 404684800.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T07:38:15 | step: 49500 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.8614681873004884e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 2.94 | consumed tokens: 405504000.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T07:38:33 | step: 49600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.860860281041823e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.19 | consumed tokens: 406323200.0 | grad norm avg: 0.89 | grad norm last: 0.79 | 
2026-01-01T07:38:51 | step: 49700 | train samples/s: 95.1 | train mfu (16-bit): -1.0 | lr mean: 4.860251283389516e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.03 | consumed tokens: 407142400.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T07:39:09 | step: 49800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.859641194343567e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.31 | consumed tokens: 407961600.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T07:39:27 | step: 49900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.859029650106095e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 2.73 | consumed tokens: 408780800.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T07:39:46 | step: 50000 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.8584166506771e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.52 | consumed tokens: 409600000.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T07:40:05 | step: 50100 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.857802559854463e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 2.64 | consumed tokens: 410419200.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T07:40:23 | step: 50200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.857187013840303e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.81 | consumed tokens: 411238400.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T07:40:41 | step: 50300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.856570376432501e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.56 | consumed tokens: 412057600.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T07:40:59 | step: 50400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.855952283833176e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 4.06 | consumed tokens: 412876800.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T07:41:17 | step: 50500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.855332736042328e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.06 | consumed tokens: 413696000.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T07:41:36 | step: 50600 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.854712460655719e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 2.86 | consumed tokens: 414515200.0 | grad norm avg: 0.88 | grad norm last: 1.07 | 
2026-01-01T07:41:54 | step: 50700 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.8540903662797064e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.14 | consumed tokens: 415334400.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T07:42:12 | step: 50800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.8534671805100515e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.89 | consumed tokens: 416153600.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T07:42:30 | step: 50900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.8528429033467546e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.09 | consumed tokens: 416972800.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T07:42:48 | step: 51000 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 4.852216807194054e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 2.94 | consumed tokens: 417792000.0 | grad norm avg: 0.88 | grad norm last: 0.76 | 
2026-01-01T07:43:06 | step: 51100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.851589983445592e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.72 | consumed tokens: 418611200.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T07:43:25 | step: 51200 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.8509617045056075e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.16 | consumed tokens: 419430400.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T07:43:43 | step: 51300 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.8503319703741e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.59 | consumed tokens: 420249600.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T07:44:01 | step: 51400 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.84970114484895e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 4.03 | consumed tokens: 421068800.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T07:44:19 | step: 51500 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.849068864132278e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.92 | consumed tokens: 421888000.0 | grad norm avg: 0.89 | grad norm last: 1.01 | 
2026-01-01T07:44:37 | step: 51600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.848435492021963e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 4.0 | consumed tokens: 422707200.0 | grad norm avg: 0.88 | grad norm last: 0.8 | 
2026-01-01T07:44:55 | step: 51700 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.8478006647201255e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.05 | consumed tokens: 423526400.0 | grad norm avg: 0.88 | grad norm last: 1.09 | 
2026-01-01T07:45:13 | step: 51800 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.847164382226765e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.12 | consumed tokens: 424345600.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T07:45:32 | step: 51900 | train samples/s: 95.3 | train mfu (16-bit): -1.0 | lr mean: 4.8465273721376434e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.0 | consumed tokens: 425164800.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T07:45:50 | step: 52000 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 4.845888543059118e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.38 | consumed tokens: 425984000.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T07:46:08 | step: 52100 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 4.8452486225869507e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 4.34 | consumed tokens: 426803200.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T07:46:26 | step: 52200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.844607610721141e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.12 | consumed tokens: 427622400.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T07:46:45 | step: 52300 | train samples/s: 94.7 | train mfu (16-bit): -1.0 | lr mean: 4.843965143663809e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 4.06 | consumed tokens: 428441600.0 | grad norm avg: 0.89 | grad norm last: 1.02 | 
2026-01-01T07:47:03 | step: 52400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.8433212214149535e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.36 | consumed tokens: 429260800.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T07:47:21 | step: 52500 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.842676207772456e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.06 | consumed tokens: 430080000.0 | grad norm avg: 0.89 | grad norm last: 0.99 | 
2026-01-01T07:47:39 | step: 52600 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.8420301027363166e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.31 | consumed tokens: 430899200.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T07:47:57 | step: 52700 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.8413821787107736e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.39 | consumed tokens: 431718400.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T07:48:15 | step: 52800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.840733527089469e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 4.0 | consumed tokens: 432537600.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T07:48:34 | step: 52900 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.840083420276642e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.59 | consumed tokens: 433356800.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T07:48:52 | step: 53000 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.839431858272292e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.19 | consumed tokens: 434176000.0 | grad norm avg: 0.89 | grad norm last: 1.04 | 
2026-01-01T07:49:10 | step: 53100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.8387792048742995e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.48 | consumed tokens: 434995200.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T07:49:28 | step: 53200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.8381250962847844e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.83 | consumed tokens: 435814400.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T07:49:46 | step: 53300 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.837469896301627e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.89 | consumed tokens: 436633600.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T07:50:04 | step: 53400 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.836813241126947e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.55 | consumed tokens: 437452800.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T07:50:22 | step: 53500 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.836155494558625e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.09 | consumed tokens: 438272000.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T07:50:41 | step: 53600 | train samples/s: 94.4 | train mfu (16-bit): -1.0 | lr mean: 4.83549629279878e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 2.72 | consumed tokens: 439091200.0 | grad norm avg: 0.9 | grad norm last: 1.13 | 
2026-01-01T07:50:59 | step: 53700 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.834835999645293e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 2.42 | consumed tokens: 439910400.0 | grad norm avg: 0.88 | grad norm last: 0.78 | 
2026-01-01T07:51:17 | step: 53800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.834174251300283e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.42 | consumed tokens: 440729600.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T07:51:35 | step: 53900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.833511411561631e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.41 | consumed tokens: 441548800.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T07:51:54 | step: 54000 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.832847116631456e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.11 | consumed tokens: 442368000.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T07:52:12 | step: 54100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.8321817303076386e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.06 | consumed tokens: 443187200.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T07:52:30 | step: 54200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.831514888792299e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.64 | consumed tokens: 444006400.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T07:52:48 | step: 54300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.830846955883317e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.42 | consumed tokens: 444825600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T07:53:06 | step: 54400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.830177567782812e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.38 | consumed tokens: 445644800.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T07:53:24 | step: 54500 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.829506724490784e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 2.48 | consumed tokens: 446464000.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T07:53:42 | step: 54600 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.828834789805114e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.19 | consumed tokens: 447283200.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T07:54:01 | step: 54700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.828161763725802e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.3 | consumed tokens: 448102400.0 | grad norm avg: 0.88 | grad norm last: 0.8 | 
2026-01-01T07:54:19 | step: 54800 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.8274872824549675e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.59 | consumed tokens: 448921600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T07:54:37 | step: 54900 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 4.8268117097904906e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.47 | consumed tokens: 449740800.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T07:54:55 | step: 55000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.826134681934491e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.88 | consumed tokens: 450560000.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T07:55:15 | step: 55100 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.825456562684849e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.81 | consumed tokens: 451379200.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T07:55:33 | step: 55200 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.824776988243684e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.45 | consumed tokens: 452198400.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T07:55:51 | step: 55300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.824096322408877e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.92 | consumed tokens: 453017600.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T07:56:09 | step: 55400 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.8234142013825476e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.19 | consumed tokens: 453836800.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T07:56:27 | step: 55500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.822730625164695e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.55 | consumed tokens: 454656000.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T07:56:45 | step: 55600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.822046321351081e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.25 | consumed tokens: 455475200.0 | grad norm avg: 0.88 | grad norm last: 1.0 | 
2026-01-01T07:57:03 | step: 55700 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 4.8213601985480636e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.38 | consumed tokens: 456294400.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T07:57:22 | step: 55800 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.820672984351404e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.72 | consumed tokens: 457113600.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T07:57:40 | step: 55900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.819984678761102e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.88 | consumed tokens: 457932800.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T07:57:58 | step: 56000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.819294917979278e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.73 | consumed tokens: 458752000.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T07:58:16 | step: 56100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.818604065803811e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.27 | consumed tokens: 459571200.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T07:58:34 | step: 56200 | train samples/s: 95.0 | train mfu (16-bit): -1.0 | lr mean: 4.8179117584368214e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.47 | consumed tokens: 460390400.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T07:58:52 | step: 56300 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 4.81721835967619e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.58 | consumed tokens: 461209600.0 | grad norm avg: 0.89 | grad norm last: 0.77 | 
2026-01-01T07:59:10 | step: 56400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.816523505724035e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.55 | consumed tokens: 462028800.0 | grad norm avg: 0.88 | grad norm last: 0.79 | 
2026-01-01T07:59:28 | step: 56500 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.8158275603782386e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.91 | consumed tokens: 462848000.0 | grad norm avg: 0.89 | grad norm last: 0.79 | 
2026-01-01T07:59:47 | step: 56600 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.815130159840919e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 2.62 | consumed tokens: 463667200.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T08:00:05 | step: 56700 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.8144316679099575e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 2.62 | consumed tokens: 464486400.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T08:00:23 | step: 56800 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.813732084585354e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.8 | consumed tokens: 465305600.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T08:00:41 | step: 56900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.8130306822713464e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.14 | consumed tokens: 466124800.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T08:00:59 | step: 57000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.812328552361578e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.06 | consumed tokens: 466944000.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T08:01:17 | step: 57100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.811624967260286e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.0 | consumed tokens: 467763200.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T08:01:36 | step: 57200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.810919926967472e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.55 | consumed tokens: 468582400.0 | grad norm avg: 0.88 | grad norm last: 0.76 | 
2026-01-01T08:01:54 | step: 57300 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.810213795281015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.62 | consumed tokens: 469401600.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T08:02:12 | step: 57400 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.809506208403036e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 2.86 | consumed tokens: 470220800.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T08:02:30 | step: 57500 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 4.8087975301314145e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.2 | consumed tokens: 471040000.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T08:02:48 | step: 57600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.808087760466151e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.5 | consumed tokens: 471859200.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T08:03:06 | step: 57700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.8073765356093645e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.66 | consumed tokens: 472678400.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T08:03:25 | step: 57800 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.806664219358936e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.95 | consumed tokens: 473497600.0 | grad norm avg: 0.88 | grad norm last: 0.75 | 
2026-01-01T08:03:43 | step: 57900 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.8059504479169846e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.55 | consumed tokens: 474316800.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T08:04:01 | step: 58000 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.80523522128351e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.52 | consumed tokens: 475136000.0 | grad norm avg: 0.89 | grad norm last: 0.97 | 
2026-01-01T08:04:19 | step: 58100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.804519267054275e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 4.06 | consumed tokens: 475955200.0 | grad norm avg: 0.88 | grad norm last: 0.79 | 
2026-01-01T08:04:37 | step: 58200 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.8038014938356355e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.08 | consumed tokens: 476774400.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T08:04:55 | step: 58300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.803082993021235e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.33 | consumed tokens: 477593600.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T08:05:13 | step: 58400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.802362673217431e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.48 | consumed tokens: 478412800.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T08:05:31 | step: 58500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.801641625817865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.48 | consumed tokens: 479232000.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T08:05:49 | step: 58600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.800918759428896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.64 | consumed tokens: 480051200.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T08:06:07 | step: 58700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.8001951654441655e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 4.12 | consumed tokens: 480870400.0 | grad norm avg: 0.9 | grad norm last: 0.76 | 
2026-01-01T08:06:25 | step: 58800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.799470116267912e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.58 | consumed tokens: 481689600.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T08:06:44 | step: 58900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.798743611900136e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.95 | consumed tokens: 482508800.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T08:07:02 | step: 59000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.7980160161387175e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.72 | consumed tokens: 483328000.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T08:07:20 | step: 59100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.797287328983657e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.59 | consumed tokens: 484147200.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T08:07:38 | step: 59200 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.796557186637074e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.06 | consumed tokens: 484966400.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T08:07:57 | step: 59300 | train samples/s: 90.7 | train mfu (16-bit): -1.0 | lr mean: 4.795825952896848e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 2.62 | consumed tokens: 485785600.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T08:08:15 | step: 59400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.7950932639651e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.25 | consumed tokens: 486604800.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T08:08:33 | step: 59500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.7943594836397097e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.42 | consumed tokens: 487424000.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T08:08:51 | step: 59600 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.7936242481227964e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.16 | consumed tokens: 488243200.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T08:09:09 | step: 59700 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.792887921212241e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 4.03 | consumed tokens: 489062400.0 | grad norm avg: 0.89 | grad norm last: 0.78 | 
2026-01-01T08:09:27 | step: 59800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.792150139110163e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.25 | consumed tokens: 489881600.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T08:09:45 | step: 59900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.7914112656144425e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 4.0 | consumed tokens: 490700800.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T08:10:03 | step: 60000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.79067130072508e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.44 | consumed tokens: 491520000.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T08:10:23 | step: 60100 | train samples/s: 95.1 | train mfu (16-bit): -1.0 | lr mean: 4.789929880644195e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.17 | consumed tokens: 492339200.0 | grad norm avg: 0.89 | grad norm last: 0.76 | 
2026-01-01T08:10:41 | step: 60200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.7891870053717867e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.45 | consumed tokens: 493158400.0 | grad norm avg: 0.9 | grad norm last: 0.79 | 
2026-01-01T08:10:59 | step: 60300 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.7884430387057364e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.39 | consumed tokens: 493977600.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T08:11:17 | step: 60400 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.787697980646044e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.78 | consumed tokens: 494796800.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T08:11:35 | step: 60500 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.786951467394829e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 2.97 | consumed tokens: 495616000.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T08:11:53 | step: 60600 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.7862038627499714e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.92 | consumed tokens: 496435200.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T08:12:11 | step: 60700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.785455166711472e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.44 | consumed tokens: 497254400.0 | grad norm avg: 0.88 | grad norm last: 0.97 | 
2026-01-01T08:12:29 | step: 60800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.78470501548145e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.78 | consumed tokens: 498073600.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T08:12:47 | step: 60900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.7839534090599045e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.55 | consumed tokens: 498892800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T08:13:05 | step: 61000 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.783200711244717e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.22 | consumed tokens: 499712000.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T08:13:23 | step: 61100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.782446922035888e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.22 | consumed tokens: 500531200.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T08:13:41 | step: 61200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.7816916776355356e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.53 | consumed tokens: 501350400.0 | grad norm avg: 0.89 | grad norm last: 0.79 | 
2026-01-01T08:13:59 | step: 61300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.780935341841541e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 2.95 | consumed tokens: 502169600.0 | grad norm avg: 0.89 | grad norm last: 0.82 | 
2026-01-01T08:14:17 | step: 61400 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.780177550856024e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.02 | consumed tokens: 502988800.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T08:14:35 | step: 61500 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.779418668476865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 2.89 | consumed tokens: 503808000.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T08:14:54 | step: 61600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.778658694704063e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.86 | consumed tokens: 504627200.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T08:15:12 | step: 61700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.777897265739739e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.31 | consumed tokens: 505446400.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T08:15:30 | step: 61800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.7771347453817725e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.28 | consumed tokens: 506265600.0 | grad norm avg: 0.89 | grad norm last: 1.0 | 
2026-01-01T08:15:48 | step: 61900 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.776370769832283e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.16 | consumed tokens: 507084800.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T08:16:06 | step: 62000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.775605702889152e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.67 | consumed tokens: 507904000.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T08:16:24 | step: 62100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.7748391807544976e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.61 | consumed tokens: 508723200.0 | grad norm avg: 0.89 | grad norm last: 0.82 | 
2026-01-01T08:16:42 | step: 62200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.774071567226201e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.27 | consumed tokens: 509542400.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T08:17:00 | step: 62300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.773302862304263e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 2.69 | consumed tokens: 510361600.0 | grad norm avg: 0.88 | grad norm last: 0.95 | 
2026-01-01T08:17:18 | step: 62400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.7725327021908015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.3 | consumed tokens: 511180800.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T08:17:36 | step: 62500 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.7717610868858173e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 4.06 | consumed tokens: 512000000.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T08:17:54 | step: 62600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.770988743985072e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.97 | consumed tokens: 512819200.0 | grad norm avg: 0.89 | grad norm last: 0.76 | 
2026-01-01T08:18:12 | step: 62700 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.7702149458928034e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.84 | consumed tokens: 513638400.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T08:18:30 | step: 62800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.769439692609012e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.95 | consumed tokens: 514457600.0 | grad norm avg: 0.89 | grad norm last: 1.09 | 
2026-01-01T08:18:48 | step: 62900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.768663347931579e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 4.16 | consumed tokens: 515276800.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T08:19:06 | step: 63000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.767885911860503e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.09 | consumed tokens: 516096000.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T08:19:24 | step: 63100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.767107020597905e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.64 | consumed tokens: 516915200.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T08:19:42 | step: 63200 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.7663270379416645e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.41 | consumed tokens: 517734400.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T08:20:00 | step: 63300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.765545600093901e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.33 | consumed tokens: 518553600.0 | grad norm avg: 0.89 | grad norm last: 0.77 | 
2026-01-01T08:20:18 | step: 63400 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.764763070852496e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.33 | consumed tokens: 519372800.0 | grad norm avg: 0.88 | grad norm last: 0.8 | 
2026-01-01T08:20:36 | step: 63500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.763979450217448e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.58 | consumed tokens: 520192000.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T08:20:54 | step: 63600 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.763194374390878e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.53 | consumed tokens: 521011200.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T08:21:12 | step: 63700 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.762408207170665e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.52 | consumed tokens: 521830400.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T08:21:31 | step: 63800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.76162058475893e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.25 | consumed tokens: 522649600.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T08:21:49 | step: 63900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.7608318709535524e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.86 | consumed tokens: 523468800.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T08:22:07 | step: 64000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.760042065754533e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.03 | consumed tokens: 524288000.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T08:22:25 | step: 64100 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 4.7592508053639904e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.3 | consumed tokens: 525107200.0 | grad norm avg: 0.88 | grad norm last: 0.95 | 
2026-01-01T08:22:43 | step: 64200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.758458453579806e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.44 | consumed tokens: 525926400.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T08:23:01 | step: 64300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.7576646466040984e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.3 | consumed tokens: 526745600.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T08:23:19 | step: 64400 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.756869748234749e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 2.94 | consumed tokens: 527564800.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T08:23:37 | step: 64500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.756073758471757e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.47 | consumed tokens: 528384000.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T08:23:55 | step: 64600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.755276313517243e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.22 | consumed tokens: 529203200.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T08:24:13 | step: 64700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.754477777169086e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.08 | consumed tokens: 530022400.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T08:24:31 | step: 64800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.7536777856294066e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.58 | consumed tokens: 530841600.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T08:24:49 | step: 64900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.752876702696085e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.98 | consumed tokens: 531660800.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T08:25:08 | step: 65000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.752074528369121e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.67 | consumed tokens: 532480000.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T08:25:27 | step: 65100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.751270898850635e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.52 | consumed tokens: 533299200.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T08:25:45 | step: 65200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.750466177938506e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.25 | consumed tokens: 534118400.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T08:26:03 | step: 65300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.7496600018348545e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 2.8 | consumed tokens: 534937600.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T08:26:21 | step: 65400 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.7488530981354415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.38 | consumed tokens: 535756800.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T08:26:39 | step: 65500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.748044375446625e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.55 | consumed tokens: 536576000.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T08:26:57 | step: 65600 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.747234925162047e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.39 | consumed tokens: 537395200.0 | grad norm avg: 0.9 | grad norm last: 1.07 | 
2026-01-01T08:27:15 | step: 65700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.7464240196859464e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.28 | consumed tokens: 538214400.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T08:27:33 | step: 65800 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.745611659018323e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.27 | consumed tokens: 539033600.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T08:27:51 | step: 65900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.744798206957057e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.25 | consumed tokens: 539852800.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T08:28:10 | step: 66000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.743983663502149e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.22 | consumed tokens: 540672000.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T08:28:28 | step: 66100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.743168028653599e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.56 | consumed tokens: 541491200.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T08:28:46 | step: 66200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.7423509386135265e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.31 | consumed tokens: 542310400.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T08:29:04 | step: 66300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.741532393381931e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.58 | consumed tokens: 543129600.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T08:29:22 | step: 66400 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.740713120554574e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.08 | consumed tokens: 543948800.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T08:29:39 | step: 66500 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.739892392535694e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.08 | consumed tokens: 544768000.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T08:29:58 | step: 66600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.739070209325291e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.94 | consumed tokens: 545587200.0 | grad norm avg: 0.89 | grad norm last: 0.98 | 
2026-01-01T08:30:16 | step: 66700 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.738247298519127e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 2.52 | consumed tokens: 546406400.0 | grad norm avg: 0.9 | grad norm last: 0.98 | 
2026-01-01T08:30:34 | step: 66800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.7374225687235594e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.7 | consumed tokens: 547225600.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T08:30:52 | step: 66900 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.73659711133223e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.34 | consumed tokens: 548044800.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T08:31:10 | step: 67000 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.735770198749378e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 4.0 | consumed tokens: 548864000.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T08:31:28 | step: 67100 | train samples/s: 94.9 | train mfu (16-bit): -1.0 | lr mean: 4.734942194772884e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.09 | consumed tokens: 549683200.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T08:31:46 | step: 67200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.7341127356048673e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.47 | consumed tokens: 550502400.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T08:32:05 | step: 67300 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 4.733282185043208e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.91 | consumed tokens: 551321600.0 | grad norm avg: 0.89 | grad norm last: 0.79 | 
2026-01-01T08:32:23 | step: 67400 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.732450543087907e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.05 | consumed tokens: 552140800.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T08:32:41 | step: 67500 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.731617445941083e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.34 | consumed tokens: 552960000.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T08:32:59 | step: 67600 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 4.730783257400617e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.94 | consumed tokens: 553779200.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T08:33:18 | step: 67700 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.729947977466509e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.33 | consumed tokens: 554598400.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T08:33:36 | step: 67800 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.7291112423408777e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.95 | consumed tokens: 555417600.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T08:33:54 | step: 67900 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.7282734158216044e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.2 | consumed tokens: 556236800.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T08:34:13 | step: 68000 | train samples/s: 94.1 | train mfu (16-bit): -1.0 | lr mean: 4.727434497908689e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.31 | consumed tokens: 557056000.0 | grad norm avg: 0.89 | grad norm last: 1.02 | 
2026-01-01T08:34:31 | step: 68100 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.726594124804251e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.75 | consumed tokens: 557875200.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T08:34:49 | step: 68200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.7257526603061706e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.83 | consumed tokens: 558694400.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T08:35:07 | step: 68300 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.7249097406165674e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.31 | consumed tokens: 559513600.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T08:35:25 | step: 68400 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 4.724065729533322e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.48 | consumed tokens: 560332800.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T08:35:44 | step: 68500 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.723220627056435e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.09 | consumed tokens: 561152000.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T08:36:02 | step: 68600 | train samples/s: 94.7 | train mfu (16-bit): -1.0 | lr mean: 4.722374433185905e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 4.0 | consumed tokens: 561971200.0 | grad norm avg: 0.88 | grad norm last: 0.96 | 
2026-01-01T08:36:21 | step: 68700 | train samples/s: 90.4 | train mfu (16-bit): -1.0 | lr mean: 4.721526784123853e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.02 | consumed tokens: 562790400.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T08:36:40 | step: 68800 | train samples/s: 93.8 | train mfu (16-bit): -1.0 | lr mean: 4.7206780436681584e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.98 | consumed tokens: 563609600.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T08:36:59 | step: 68900 | train samples/s: 93.5 | train mfu (16-bit): -1.0 | lr mean: 4.719827848020941e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 2.62 | consumed tokens: 564428800.0 | grad norm avg: 0.89 | grad norm last: 0.98 | 
2026-01-01T08:37:17 | step: 69000 | train samples/s: 95.0 | train mfu (16-bit): -1.0 | lr mean: 4.7189765609800816e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.95 | consumed tokens: 565248000.0 | grad norm avg: 0.89 | grad norm last: 0.8 | 
2026-01-01T08:37:35 | step: 69100 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 4.71812418254558e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.78 | consumed tokens: 566067200.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T08:37:54 | step: 69200 | train samples/s: 93.0 | train mfu (16-bit): -1.0 | lr mean: 4.7172703489195555e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.88 | consumed tokens: 566886400.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T08:38:13 | step: 69300 | train samples/s: 92.8 | train mfu (16-bit): -1.0 | lr mean: 4.71641578769777e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.95 | consumed tokens: 567705600.0 | grad norm avg: 0.89 | grad norm last: 0.97 | 
2026-01-01T08:38:31 | step: 69400 | train samples/s: 95.2 | train mfu (16-bit): -1.0 | lr mean: 4.71555940748658e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.56 | consumed tokens: 568524800.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T08:38:50 | step: 69500 | train samples/s: 95.1 | train mfu (16-bit): -1.0 | lr mean: 4.7147022996796295e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.39 | consumed tokens: 569344000.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T08:39:08 | step: 69600 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 4.713843736681156e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.8 | consumed tokens: 570163200.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T08:39:26 | step: 69700 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 4.71298408228904e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.67 | consumed tokens: 570982400.0 | grad norm avg: 0.88 | grad norm last: 0.79 | 
2026-01-01T08:39:44 | step: 69800 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 4.7121229727054015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.31 | consumed tokens: 571801600.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T08:40:02 | step: 69900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.711260771728121e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.83 | consumed tokens: 572620800.0 | grad norm avg: 0.9 | grad norm last: 1.02 | 
2026-01-01T08:40:21 | step: 70000 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.710397479357198e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.05 | consumed tokens: 573440000.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T08:40:40 | step: 70100 | train samples/s: 95.2 | train mfu (16-bit): -1.0 | lr mean: 4.709533095592633e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.42 | consumed tokens: 574259200.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T08:41:00 | step: 70200 | train samples/s: 86.2 | train mfu (16-bit): -1.0 | lr mean: 4.708667256636545e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.39 | consumed tokens: 575078400.0 | grad norm avg: 0.89 | grad norm last: 0.97 | 
2026-01-01T08:41:21 | step: 70300 | train samples/s: 81.6 | train mfu (16-bit): -1.0 | lr mean: 4.707800326286815e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.53 | consumed tokens: 575897600.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T08:41:42 | step: 70400 | train samples/s: 80.7 | train mfu (16-bit): -1.0 | lr mean: 4.706931940745562e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.41 | consumed tokens: 576716800.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T08:42:02 | step: 70500 | train samples/s: 88.6 | train mfu (16-bit): -1.0 | lr mean: 4.7060624638106674e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.62 | consumed tokens: 577536000.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T08:42:21 | step: 70600 | train samples/s: 93.2 | train mfu (16-bit): -1.0 | lr mean: 4.7051918954821303e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.36 | consumed tokens: 578355200.0 | grad norm avg: 0.89 | grad norm last: 0.82 | 
2026-01-01T08:42:39 | step: 70700 | train samples/s: 95.0 | train mfu (16-bit): -1.0 | lr mean: 4.704320235759951e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.56 | consumed tokens: 579174400.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T08:42:57 | step: 70800 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 4.703447120846249e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.78 | consumed tokens: 579993600.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T08:43:16 | step: 70900 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 4.702572914538905e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.33 | consumed tokens: 580812800.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T08:43:34 | step: 71000 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 4.701697616837919e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.81 | consumed tokens: 581632000.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T08:43:52 | step: 71100 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.7008208639454097e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.02 | consumed tokens: 582451200.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T08:44:11 | step: 71200 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 4.6999430196592584e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.5 | consumed tokens: 583270400.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T08:44:29 | step: 71300 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.699064083979465e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.08 | consumed tokens: 584089600.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T08:44:47 | step: 71400 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.698183693108149e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.72 | consumed tokens: 584908800.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T08:45:05 | step: 71500 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.6973022108431906e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.73 | consumed tokens: 585728000.0 | grad norm avg: 0.88 | grad norm last: 0.75 | 
2026-01-01T08:45:23 | step: 71600 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.69641963718459e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.5 | consumed tokens: 586547200.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T08:45:42 | step: 71700 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.695535608334467e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.34 | consumed tokens: 587366400.0 | grad norm avg: 0.88 | grad norm last: 0.95 | 
2026-01-01T08:46:00 | step: 71800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.6946504880907014e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.33 | consumed tokens: 588185600.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T08:46:18 | step: 71900 | train samples/s: 95.1 | train mfu (16-bit): -1.0 | lr mean: 4.693764276453294e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.78 | consumed tokens: 589004800.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T08:46:36 | step: 72000 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 4.692876973422244e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.59 | consumed tokens: 589824000.0 | grad norm avg: 0.89 | grad norm last: 0.82 | 
2026-01-01T08:46:55 | step: 72100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.691988215199672e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.36 | consumed tokens: 590643200.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T08:47:13 | step: 72200 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.691098365583457e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.55 | consumed tokens: 591462400.0 | grad norm avg: 0.9 | grad norm last: 0.98 | 
2026-01-01T08:47:31 | step: 72300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.6902074245736e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.41 | consumed tokens: 592281600.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T08:47:49 | step: 72400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.689315028372221e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.53 | consumed tokens: 593100800.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T08:48:07 | step: 72500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.688421540777199e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.12 | consumed tokens: 593920000.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T08:48:25 | step: 72600 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.687526961788535e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.55 | consumed tokens: 594739200.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T08:48:43 | step: 72700 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.6866309276083484e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.28 | consumed tokens: 595558400.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T08:49:01 | step: 72800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.6857341658324e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.39 | consumed tokens: 596377600.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T08:49:19 | step: 72900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.6848359488649294e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.19 | consumed tokens: 597196800.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T08:49:38 | step: 73000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.6839362767059356e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.31 | consumed tokens: 598016000.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T08:49:56 | step: 73100 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.6830358769511804e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 2.66 | consumed tokens: 598835200.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T08:50:14 | step: 73200 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.6821340220049024e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.88 | consumed tokens: 599654400.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T08:50:32 | step: 73300 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.681231075664982e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.97 | consumed tokens: 600473600.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T08:50:50 | step: 73400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.680326674133539e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.11 | consumed tokens: 601292800.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T08:51:08 | step: 73500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.679421181208454e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.3 | consumed tokens: 602112000.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T08:51:26 | step: 73600 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.678514596889727e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.25 | consumed tokens: 602931200.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T08:51:44 | step: 73700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.6776069211773574e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.44 | consumed tokens: 603750400.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T08:52:02 | step: 73800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.676697790273465e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.05 | consumed tokens: 604569600.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T08:52:20 | step: 73900 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.675787567975931e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.06 | consumed tokens: 605388800.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T08:52:38 | step: 74000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.6748762542847544e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.22 | consumed tokens: 606208000.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T08:52:56 | step: 74100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.673963849199936e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.44 | consumed tokens: 607027200.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T08:53:14 | step: 74200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.6730499889235944e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.97 | consumed tokens: 607846400.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T08:53:32 | step: 74300 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.672135037253611e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.62 | consumed tokens: 608665600.0 | grad norm avg: 0.9 | grad norm last: 0.79 | 
2026-01-01T08:53:50 | step: 74400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.671218994189985e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.11 | consumed tokens: 609484800.0 | grad norm avg: 0.89 | grad norm last: 1.11 | 
2026-01-01T08:54:08 | step: 74500 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.670301859732717e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.08 | consumed tokens: 610304000.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T08:54:26 | step: 74600 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.6693832700839266e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.98 | consumed tokens: 611123200.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T08:54:45 | step: 74700 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.668463589041494e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.39 | consumed tokens: 611942400.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T08:55:03 | step: 74800 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.667542816605419e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.44 | consumed tokens: 612761600.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T08:55:20 | step: 74900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.666620588977821e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.45 | consumed tokens: 613580800.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T08:55:38 | step: 75000 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.665697269956581e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.75 | consumed tokens: 614400000.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T08:55:58 | step: 75100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.664772859541699e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.58 | consumed tokens: 615219200.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T08:56:16 | step: 75200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.663847357733175e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.16 | consumed tokens: 616038400.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T08:56:34 | step: 75300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.662920400733128e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.23 | consumed tokens: 616857600.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T08:56:52 | step: 75400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.66199271613732e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.44 | consumed tokens: 617676800.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T08:57:10 | step: 75500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.6610635763499886e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.72 | consumed tokens: 618496000.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T08:57:28 | step: 75600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.6601329813711345e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.53 | consumed tokens: 619315200.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T08:57:46 | step: 75700 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.659201658796519e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 4.09 | consumed tokens: 620134400.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T08:58:05 | step: 75800 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.658268881030381e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.06 | consumed tokens: 620953600.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T08:58:23 | step: 75900 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.6573350118706e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.78 | consumed tokens: 621772800.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T08:58:41 | step: 76000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.656400051317178e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.23 | consumed tokens: 622592000.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T08:58:58 | step: 76100 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.655463635572232e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.56 | consumed tokens: 623411200.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T08:59:17 | step: 76200 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.654526128433645e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.52 | consumed tokens: 624230400.0 | grad norm avg: 0.9 | grad norm last: 1.0 | 
2026-01-01T08:59:35 | step: 76300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.653587529901415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.12 | consumed tokens: 625049600.0 | grad norm avg: 0.88 | grad norm last: 0.95 | 
2026-01-01T08:59:53 | step: 76400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.652647839975543e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.77 | consumed tokens: 625868800.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T09:00:11 | step: 76500 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.651706694858149e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.16 | consumed tokens: 626688000.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T09:00:29 | step: 76600 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.6507648221449926e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.94 | consumed tokens: 627507200.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T09:00:47 | step: 76700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.649821494240314e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.52 | consumed tokens: 628326400.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T09:01:05 | step: 76800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.648877074941993e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.19 | consumed tokens: 629145600.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T09:01:23 | step: 76900 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.647931200452149e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.44 | consumed tokens: 629964800.0 | grad norm avg: 0.91 | grad norm last: 0.98 | 
2026-01-01T09:01:41 | step: 77000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.646984234568663e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.69 | consumed tokens: 630784000.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T09:01:59 | step: 77100 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.6460365410894156e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.42 | consumed tokens: 631603200.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T09:02:17 | step: 77200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.6450870286207646e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.12 | consumed tokens: 632422400.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T09:02:35 | step: 77300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.644136788556352e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.88 | consumed tokens: 633241600.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T09:02:53 | step: 77400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.643185457098298e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.88 | consumed tokens: 634060800.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T09:03:11 | step: 77500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.6422326704487205e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.64 | consumed tokens: 634880000.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T09:03:29 | step: 77600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.641278792405501e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.91 | consumed tokens: 635699200.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T09:03:47 | step: 77700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.640323459170759e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.25 | consumed tokens: 636518400.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T09:04:05 | step: 77800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.639367398340255e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.19 | consumed tokens: 637337600.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T09:04:23 | step: 77900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.6384098823182285e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.44 | consumed tokens: 638156800.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T09:04:41 | step: 78000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.63745127490256e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.11 | consumed tokens: 638976000.0 | grad norm avg: 0.9 | grad norm last: 0.97 | 
2026-01-01T09:04:59 | step: 78100 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.636491576093249e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.67 | consumed tokens: 639795200.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T09:05:17 | step: 78200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.635530785890296e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.25 | consumed tokens: 640614400.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T09:05:35 | step: 78300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.634568904293701e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.61 | consumed tokens: 641433600.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T09:05:54 | step: 78400 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 4.633605567505583e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.39 | consumed tokens: 642252800.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T09:06:12 | step: 78500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.632641139323823e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.08 | consumed tokens: 643072000.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T09:06:30 | step: 78600 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.631675619748421e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 4.38 | consumed tokens: 643891200.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T09:06:48 | step: 78700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.630708644981496e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.84 | consumed tokens: 644710400.0 | grad norm avg: 0.9 | grad norm last: 0.98 | 
2026-01-01T09:07:06 | step: 78800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.6297409426188096e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.12 | consumed tokens: 645529600.0 | grad norm avg: 0.9 | grad norm last: 0.81 | 
2026-01-01T09:07:24 | step: 78900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.6287717850646004e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.81 | consumed tokens: 646348800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T09:07:42 | step: 79000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.627801536116749e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.25 | consumed tokens: 647168000.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T09:08:00 | step: 79100 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.6268301957752556e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.7 | consumed tokens: 647987200.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T09:08:18 | step: 79200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.625857400242239e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.06 | consumed tokens: 648806400.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T09:08:36 | step: 79300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.6248838771134615e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.48 | consumed tokens: 649625600.0 | grad norm avg: 0.89 | grad norm last: 0.8 | 
2026-01-01T09:08:54 | step: 79400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.623908898793161e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.75 | consumed tokens: 650444800.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T09:09:12 | step: 79500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.622932829079218e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.89 | consumed tokens: 651264000.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T09:09:30 | step: 79600 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.6219556679716334e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 4.16 | consumed tokens: 652083200.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T09:09:48 | step: 79700 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 4.6209774154704064e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.36 | consumed tokens: 652902400.0 | grad norm avg: 0.9 | grad norm last: 1.02 | 
2026-01-01T09:10:06 | step: 79800 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.6199977077776566e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.05 | consumed tokens: 653721600.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T09:10:25 | step: 79900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.6190172724891454e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.3 | consumed tokens: 654540800.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T09:10:43 | step: 80000 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.6180353820091113e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.72 | consumed tokens: 655360000.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T09:11:02 | step: 80100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.617052400135435e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.14 | consumed tokens: 656179200.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T09:11:20 | step: 80200 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.616067963070236e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.22 | consumed tokens: 656998400.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-01T09:11:38 | step: 80300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.615082798409276e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.64 | consumed tokens: 657817600.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T09:11:56 | step: 80400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.6140961785567924e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.66 | consumed tokens: 658636800.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T09:12:14 | step: 80500 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.613108467310667e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.81 | consumed tokens: 659456000.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T09:12:32 | step: 80600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.6121196646708995e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.97 | consumed tokens: 660275200.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T09:12:50 | step: 80700 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.61112977063749e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.91 | consumed tokens: 661094400.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T09:13:08 | step: 80800 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.610138785210438e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.86 | consumed tokens: 661913600.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T09:13:26 | step: 80900 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.6091463445918635e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.39 | consumed tokens: 662732800.0 | grad norm avg: 0.89 | grad norm last: 0.78 | 
2026-01-01T09:13:44 | step: 81000 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 4.6081531763775274e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.22 | consumed tokens: 663552000.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T09:14:03 | step: 81100 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.6071585529716685e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.08 | consumed tokens: 664371200.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T09:14:21 | step: 81200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.6061628381721675e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.03 | consumed tokens: 665190400.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T09:14:39 | step: 81300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.6051660319790244e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.61 | consumed tokens: 666009600.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T09:14:57 | step: 81400 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.6041677705943584e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.61 | consumed tokens: 666828800.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T09:15:15 | step: 81500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.603168781613931e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.59 | consumed tokens: 667648000.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T09:15:33 | step: 81600 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.602168337441981e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.33 | consumed tokens: 668467200.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T09:15:51 | step: 81700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.6011668018763885e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.83 | consumed tokens: 669286400.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T09:16:09 | step: 81800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.600164174917154e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.0 | consumed tokens: 670105600.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T09:16:27 | step: 81900 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.5991604565642774e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.42 | consumed tokens: 670924800.0 | grad norm avg: 0.89 | grad norm last: 0.99 | 
2026-01-01T09:16:45 | step: 82000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.598155646817759e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.83 | consumed tokens: 671744000.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T09:17:03 | step: 82100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.597149381879717e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.72 | consumed tokens: 672563200.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T09:17:21 | step: 82200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.596142389345914e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.5 | consumed tokens: 673382400.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T09:17:39 | step: 82300 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.595133941620588e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.34 | consumed tokens: 674201600.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T09:17:57 | step: 82400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.5941244025016204e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.97 | consumed tokens: 675020800.0 | grad norm avg: 0.9 | grad norm last: 1.0 | 
2026-01-01T09:18:15 | step: 82500 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.59311377198901e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.58 | consumed tokens: 675840000.0 | grad norm avg: 0.9 | grad norm last: 0.8 | 
2026-01-01T09:18:33 | step: 82600 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.5921016862848774e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.33 | consumed tokens: 676659200.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T09:18:51 | step: 82700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.591088872984983e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.69 | consumed tokens: 677478400.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T09:19:09 | step: 82800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.5900749682914466e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.67 | consumed tokens: 678297600.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T09:19:27 | step: 82900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.589059608406387e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.36 | consumed tokens: 679116800.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T09:19:45 | step: 83000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.588043157127686e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.75 | consumed tokens: 679936000.0 | grad norm avg: 0.9 | grad norm last: 1.04 | 
2026-01-01T09:20:03 | step: 83100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.587025614455342e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.44 | consumed tokens: 680755200.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T09:20:21 | step: 83200 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.5860069803893566e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.39 | consumed tokens: 681574400.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T09:20:39 | step: 83300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.584987254929729e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.56 | consumed tokens: 682393600.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T09:20:57 | step: 83400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.583966074278578e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.39 | consumed tokens: 683212800.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T09:21:15 | step: 83500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.582944166031666e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.7 | consumed tokens: 684032000.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T09:21:34 | step: 83600 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.581920802593231e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.52 | consumed tokens: 684851200.0 | grad norm avg: 0.9 | grad norm last: 0.81 | 
2026-01-01T09:21:52 | step: 83700 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.580896711559035e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.78 | consumed tokens: 685670400.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T09:22:10 | step: 83800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.579871165333316e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.84 | consumed tokens: 686489600.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T09:22:28 | step: 83900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.5788445277139544e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.25 | consumed tokens: 687308800.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T09:22:46 | step: 84000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.577816798700951e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.0 | consumed tokens: 688128000.0 | grad norm avg: 0.9 | grad norm last: 1.03 | 
2026-01-01T09:23:04 | step: 84100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.576787614496425e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.09 | consumed tokens: 688947200.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T09:23:22 | step: 84200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.575757702696137e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.86 | consumed tokens: 689766400.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T09:23:40 | step: 84300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.5747263357043266e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.14 | consumed tokens: 690585600.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T09:23:58 | step: 84400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.573694241116755e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.33 | consumed tokens: 691404800.0 | grad norm avg: 0.89 | grad norm last: 0.78 | 
2026-01-01T09:24:16 | step: 84500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.57266069133766e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.98 | consumed tokens: 692224000.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T09:24:34 | step: 84600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.571626050164923e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.39 | consumed tokens: 693043200.0 | grad norm avg: 0.9 | grad norm last: 0.98 | 
2026-01-01T09:24:52 | step: 84700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.570590317598544e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.72 | consumed tokens: 693862400.0 | grad norm avg: 0.9 | grad norm last: 0.99 | 
2026-01-01T09:25:10 | step: 84800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.569553493638523e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.69 | consumed tokens: 694681600.0 | grad norm avg: 0.9 | grad norm last: 0.79 | 
2026-01-01T09:25:28 | step: 84900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.5685155782848597e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.48 | consumed tokens: 695500800.0 | grad norm avg: 0.91 | grad norm last: 0.8 | 
2026-01-01T09:25:47 | step: 85000 | train samples/s: 95.1 | train mfu (16-bit): -1.0 | lr mean: 4.5674762077396736e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 4.06 | consumed tokens: 696320000.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T09:26:06 | step: 85100 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.566436109598726e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.47 | consumed tokens: 697139200.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T09:26:24 | step: 85200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.5653949200641364e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.94 | consumed tokens: 697958400.0 | grad norm avg: 0.9 | grad norm last: 0.8 | 
2026-01-01T09:26:42 | step: 85300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.564352275338024e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.22 | consumed tokens: 698777600.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T09:27:00 | step: 85400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.563308539218269e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.89 | consumed tokens: 699596800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T09:27:18 | step: 85500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.5622637117048725e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.75 | consumed tokens: 700416000.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T09:27:37 | step: 85600 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.561217792797834e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.61 | consumed tokens: 701235200.0 | grad norm avg: 0.9 | grad norm last: 0.78 | 
2026-01-01T09:27:55 | step: 85700 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.560170782497153e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.97 | consumed tokens: 702054400.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T09:28:13 | step: 85800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.5591226808028296e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.11 | consumed tokens: 702873600.0 | grad norm avg: 0.89 | grad norm last: 1.09 | 
2026-01-01T09:28:31 | step: 85900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.558073487714864e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.2 | consumed tokens: 703692800.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T09:28:49 | step: 86000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.557023203233257e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.0 | consumed tokens: 704512000.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T09:29:07 | step: 86100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.555971463560127e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.2 | consumed tokens: 705331200.0 | grad norm avg: 0.91 | grad norm last: 0.96 | 
2026-01-01T09:29:25 | step: 86200 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 4.554918996291235e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.19 | consumed tokens: 706150400.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T09:29:44 | step: 86300 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.5538650738308206e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.16 | consumed tokens: 706969600.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T09:30:02 | step: 86400 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.552810059976764e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.3 | consumed tokens: 707788800.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T09:30:20 | step: 86500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.551753954729065e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.64 | consumed tokens: 708608000.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T09:30:38 | step: 86600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.550697121885605e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.42 | consumed tokens: 709427200.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-01T09:30:56 | step: 86700 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.549638833850622e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.09 | consumed tokens: 710246400.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T09:31:14 | step: 86800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.548579454421997e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.06 | consumed tokens: 711065600.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T09:31:32 | step: 86900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.547518619801849e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.62 | consumed tokens: 711884800.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T09:31:50 | step: 87000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.54645705758594e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.41 | consumed tokens: 712704000.0 | grad norm avg: 0.89 | grad norm last: 0.77 | 
2026-01-01T09:32:08 | step: 87100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.545394403976388e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.97 | consumed tokens: 713523200.0 | grad norm avg: 0.9 | grad norm last: 1.03 | 
2026-01-01T09:32:26 | step: 87200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.5443306589731947e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.5 | consumed tokens: 714342400.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T09:32:44 | step: 87300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.543265458778478e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.0 | consumed tokens: 715161600.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T09:33:02 | step: 87400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.542199530988e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.34 | consumed tokens: 715980800.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T09:33:20 | step: 87500 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.5411321480059996e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.09 | consumed tokens: 716800000.0 | grad norm avg: 0.9 | grad norm last: 1.15 | 
2026-01-01T09:33:38 | step: 87600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.540063673630357e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.2 | consumed tokens: 717619200.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T09:33:56 | step: 87700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.5389944716589525e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.58 | consumed tokens: 718438400.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T09:34:15 | step: 87800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.5379238144960254e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.72 | consumed tokens: 719257600.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T09:34:33 | step: 87900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.536852065939456e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.8 | consumed tokens: 720076800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T09:34:51 | step: 88000 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.535779225989245e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.12 | consumed tokens: 720896000.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T09:35:09 | step: 88100 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.5347052946453914e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.97 | consumed tokens: 721715200.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T09:35:27 | step: 88200 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.533630271907896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.72 | consumed tokens: 722534400.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T09:35:45 | step: 88300 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.532554157776758e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.81 | consumed tokens: 723353600.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T09:36:03 | step: 88400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.531476952251978e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.25 | consumed tokens: 724172800.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T09:36:21 | step: 88500 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.530398655333556e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.52 | consumed tokens: 724992000.0 | grad norm avg: 0.9 | grad norm last: 0.8 | 
2026-01-01T09:36:39 | step: 88600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.5293189032236114e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.33 | consumed tokens: 725811200.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T09:36:57 | step: 88700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.528238423517905e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.77 | consumed tokens: 726630400.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T09:37:16 | step: 88800 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 4.527156852418557e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.8 | consumed tokens: 727449600.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T09:37:34 | step: 88900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.5260738261276856e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.53 | consumed tokens: 728268800.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T09:37:52 | step: 89000 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.524990072241053e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.09 | consumed tokens: 729088000.0 | grad norm avg: 0.9 | grad norm last: 1.0 | 
2026-01-01T09:38:10 | step: 89100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.5239048631628975e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.61 | consumed tokens: 729907200.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T09:38:28 | step: 89200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.5228189264889807e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.94 | consumed tokens: 730726400.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T09:38:46 | step: 89300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.521731534623541e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.72 | consumed tokens: 731545600.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T09:39:04 | step: 89400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.52064341516234e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.27 | consumed tokens: 732364800.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T09:39:22 | step: 89500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.519553840509616e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.53 | consumed tokens: 733184000.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T09:39:40 | step: 89600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.51846317446325e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.11 | consumed tokens: 734003200.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T09:39:59 | step: 89700 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.517371780821122e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.09 | consumed tokens: 734822400.0 | grad norm avg: 0.92 | grad norm last: 0.96 | 
2026-01-01T09:40:17 | step: 89800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.516278931987472e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.2 | consumed tokens: 735641600.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T09:40:35 | step: 89900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.5151849917601794e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 2.47 | consumed tokens: 736460800.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T09:40:53 | step: 90000 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.514089960139245e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.22 | consumed tokens: 737280000.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T09:41:12 | step: 90100 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 4.512993837124668e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.84 | consumed tokens: 738099200.0 | grad norm avg: 0.91 | grad norm last: 0.99 | 
2026-01-01T09:41:30 | step: 90200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.511896622716449e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.41 | consumed tokens: 738918400.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T09:41:48 | step: 90300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.510798680712469e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.64 | consumed tokens: 739737600.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T09:42:07 | step: 90400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.509699283516966e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.61 | consumed tokens: 740556800.0 | grad norm avg: 0.89 | grad norm last: 0.77 | 
2026-01-01T09:42:25 | step: 90500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.5085987949278206e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.72 | consumed tokens: 741376000.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-01T09:42:43 | step: 90600 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.507497214945033e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.95 | consumed tokens: 742195200.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T09:43:01 | step: 90700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.506394543568604e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.73 | consumed tokens: 743014400.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T09:43:19 | step: 90800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.505290780798532e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.58 | consumed tokens: 743833600.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T09:43:37 | step: 90900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.504185926634818e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.95 | consumed tokens: 744652800.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T09:43:55 | step: 91000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.5030799810774624e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.95 | consumed tokens: 745472000.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T09:44:13 | step: 91100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.501972580328584e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.75 | consumed tokens: 746291200.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T09:44:31 | step: 91200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.5008644519839436e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.34 | consumed tokens: 747110400.0 | grad norm avg: 0.91 | grad norm last: 0.79 | 
2026-01-01T09:44:49 | step: 91300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.499755232245661e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.36 | consumed tokens: 747929600.0 | grad norm avg: 0.9 | grad norm last: 0.81 | 
2026-01-01T09:45:07 | step: 91400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.498644921113737e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.16 | consumed tokens: 748748800.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T09:45:25 | step: 91500 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.4975335185881704e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 4.22 | consumed tokens: 749568000.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T09:45:43 | step: 91600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.496421024668962e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.14 | consumed tokens: 750387200.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T09:46:01 | step: 91700 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.495307439356111e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.94 | consumed tokens: 751206400.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T09:46:20 | step: 91800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.494192762649618e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.88 | consumed tokens: 752025600.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T09:46:38 | step: 91900 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.493076994549483e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.39 | consumed tokens: 752844800.0 | grad norm avg: 0.89 | grad norm last: 0.8 | 
2026-01-01T09:46:56 | step: 92000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.491960135055706e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.73 | consumed tokens: 753664000.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T09:47:14 | step: 92100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.4908421841682866e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.58 | consumed tokens: 754483200.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T09:47:32 | step: 92200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.489723141887225e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.55 | consumed tokens: 755302400.0 | grad norm avg: 0.89 | grad norm last: 0.98 | 
2026-01-01T09:47:50 | step: 92300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.488602644414641e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.48 | consumed tokens: 756121600.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T09:48:08 | step: 92400 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.487481419346295e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.34 | consumed tokens: 756940800.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T09:48:26 | step: 92500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.4863591028843075e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.45 | consumed tokens: 757760000.0 | grad norm avg: 0.89 | grad norm last: 1.0 | 
2026-01-01T09:48:44 | step: 92600 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.4852356950286776e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.47 | consumed tokens: 758579200.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T09:49:02 | step: 92700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.4841111957794055e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.56 | consumed tokens: 759398400.0 | grad norm avg: 0.9 | grad norm last: 1.06 | 
2026-01-01T09:49:21 | step: 92800 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.4829856051364914e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.92 | consumed tokens: 760217600.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T09:49:39 | step: 92900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.481858923099935e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.5 | consumed tokens: 761036800.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T09:49:57 | step: 93000 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.4807311496697366e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.66 | consumed tokens: 761856000.0 | grad norm avg: 0.9 | grad norm last: 0.75 | 
2026-01-01T09:50:15 | step: 93100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.479602284845896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.53 | consumed tokens: 762675200.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T09:50:33 | step: 93200 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.4784723286284134e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.34 | consumed tokens: 763494400.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T09:50:51 | step: 93300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.477341644815169e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.77 | consumed tokens: 764313600.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T09:51:09 | step: 93400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.476209505810402e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.34 | consumed tokens: 765132800.0 | grad norm avg: 0.91 | grad norm last: 1.04 | 
2026-01-01T09:51:27 | step: 93500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.475076275411993e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.28 | consumed tokens: 765952000.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T09:51:45 | step: 93600 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.473941953619942e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.17 | consumed tokens: 766771200.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T09:52:03 | step: 93700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.472806540434249e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.94 | consumed tokens: 767590400.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T09:52:21 | step: 93800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.471670035854913e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.67 | consumed tokens: 768409600.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T09:52:39 | step: 93900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.4705328036798164e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.5 | consumed tokens: 769228800.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T09:52:58 | step: 94000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.469394116313197e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.47 | consumed tokens: 770048000.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T09:53:16 | step: 94100 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 4.468254337552935e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.92 | consumed tokens: 770867200.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T09:53:34 | step: 94200 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.4671138311969116e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.45 | consumed tokens: 771686400.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T09:53:52 | step: 94300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.4659718696493655e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.64 | consumed tokens: 772505600.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T09:54:10 | step: 94400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.464829180506058e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 2.34 | consumed tokens: 773324800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T09:54:28 | step: 94500 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.463685036171228e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.25 | consumed tokens: 774144000.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T09:54:46 | step: 94600 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.462540164240636e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.42 | consumed tokens: 774963200.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T09:55:04 | step: 94700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.461393837118521e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.19 | consumed tokens: 775782400.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T09:55:22 | step: 94800 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.460246782400645e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.28 | consumed tokens: 776601600.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T09:55:40 | step: 94900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.459098636289127e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.73 | consumed tokens: 777420800.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T09:55:59 | step: 95000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.457949398783967e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.81 | consumed tokens: 778240000.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T09:56:18 | step: 95100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.456798706087284e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.02 | consumed tokens: 779059200.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T09:56:36 | step: 95200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.455647285794839e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.66 | consumed tokens: 779878400.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T09:56:54 | step: 95300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.4544947741087526e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.91 | consumed tokens: 780697600.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T09:57:12 | step: 95400 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.453341171029024e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.56 | consumed tokens: 781516800.0 | grad norm avg: 0.89 | grad norm last: 1.0 | 
2026-01-01T09:57:30 | step: 95500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.452186476555653e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.48 | consumed tokens: 782336000.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T09:57:49 | step: 95600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.4510310544865206e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.33 | consumed tokens: 783155200.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T09:58:07 | step: 95700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.4498741772258654e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.8 | consumed tokens: 783974400.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T09:58:25 | step: 95800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.448716208571568e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.12 | consumed tokens: 784793600.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T09:58:43 | step: 95900 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.447557148523629e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.17 | consumed tokens: 785612800.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T09:59:01 | step: 96000 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.446397360879928e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.72 | consumed tokens: 786432000.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T09:59:19 | step: 96100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.445236118044704e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.05 | consumed tokens: 787251200.0 | grad norm avg: 0.89 | grad norm last: 1.03 | 
2026-01-01T09:59:37 | step: 96200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.444074147613719e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.58 | consumed tokens: 788070400.0 | grad norm avg: 0.9 | grad norm last: 0.79 | 
2026-01-01T09:59:55 | step: 96300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.442911085789092e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.2 | consumed tokens: 788889600.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T10:00:13 | step: 96400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.441746568772942e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.62 | consumed tokens: 789708800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T10:00:31 | step: 96500 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.4405813241610304e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.2 | consumed tokens: 790528000.0 | grad norm avg: 0.9 | grad norm last: 0.97 | 
2026-01-01T10:00:49 | step: 96600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.439414988155477e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.66 | consumed tokens: 791347200.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T10:01:07 | step: 96700 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 4.438247560756281e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.44 | consumed tokens: 792166400.0 | grad norm avg: 0.9 | grad norm last: 1.0 | 
2026-01-01T10:01:25 | step: 96800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.437079041963443e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.5 | consumed tokens: 792985600.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T10:01:43 | step: 96900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.435909431776963e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.42 | consumed tokens: 793804800.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T10:02:01 | step: 97000 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.434738730196841e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.84 | consumed tokens: 794624000.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T10:02:19 | step: 97100 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.4335673010209575e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.84 | consumed tokens: 795443200.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T10:02:37 | step: 97200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.432394416653551e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.67 | consumed tokens: 796262400.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T10:02:55 | step: 97300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.4312208046903834e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.06 | consumed tokens: 797081600.0 | grad norm avg: 0.91 | grad norm last: 1.01 | 
2026-01-01T10:03:13 | step: 97400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.430045737535693e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.42 | consumed tokens: 797900800.0 | grad norm avg: 0.9 | grad norm last: 0.8 | 
2026-01-01T10:03:31 | step: 97500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.428869942785241e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.06 | consumed tokens: 798720000.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T10:03:49 | step: 97600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.4276930566411465e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.25 | consumed tokens: 799539200.0 | grad norm avg: 0.89 | grad norm last: 0.97 | 
2026-01-01T10:04:07 | step: 97700 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.42651507910341e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.53 | consumed tokens: 800358400.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T10:04:25 | step: 97800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.425336010172032e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.97 | consumed tokens: 801177600.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T10:04:44 | step: 97900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.424155849847011e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.36 | consumed tokens: 801996800.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T10:05:02 | step: 98000 | train samples/s: 95.2 | train mfu (16-bit): -1.0 | lr mean: 4.4229745981283486e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.62 | consumed tokens: 802816000.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T10:05:20 | step: 98100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.421792255016044e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.75 | consumed tokens: 803635200.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T10:05:38 | step: 98200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.4206091843079776e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.34 | consumed tokens: 804454400.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T10:05:56 | step: 98300 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.4194246584083885e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.41 | consumed tokens: 805273600.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T10:06:14 | step: 98400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.418239404913038e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.36 | consumed tokens: 806092800.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T10:06:32 | step: 98500 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.4170530600240454e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.17 | consumed tokens: 806912000.0 | grad norm avg: 0.9 | grad norm last: 0.8 | 
2026-01-01T10:06:50 | step: 98600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.41586525994353e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.14 | consumed tokens: 807731200.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T10:07:08 | step: 98700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.414676732267253e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.53 | consumed tokens: 808550400.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T10:07:26 | step: 98800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.413487476995215e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.48 | consumed tokens: 809369600.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T10:07:44 | step: 98900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.412296766531654e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 4.19 | consumed tokens: 810188800.0 | grad norm avg: 0.91 | grad norm last: 0.81 | 
2026-01-01T10:08:02 | step: 99000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.4111049646744505e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.89 | consumed tokens: 811008000.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T10:08:21 | step: 99100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.409912435221486e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.31 | consumed tokens: 811827200.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T10:08:39 | step: 99200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.408718450576998e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.36 | consumed tokens: 812646400.0 | grad norm avg: 0.89 | grad norm last: 0.99 | 
2026-01-01T10:08:57 | step: 99300 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.4075237383367494e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.55 | consumed tokens: 813465600.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T10:09:15 | step: 99400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.406327934702858e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.17 | consumed tokens: 814284800.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T10:09:33 | step: 99500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.405131039675325e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.34 | consumed tokens: 815104000.0 | grad norm avg: 0.89 | grad norm last: 1.01 | 
2026-01-01T10:09:51 | step: 99600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.40393305325415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.08 | consumed tokens: 815923200.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T10:10:09 | step: 99700 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.4027339754393324e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.67 | consumed tokens: 816742400.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T10:10:27 | step: 99800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.4015341700287536e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.98 | consumed tokens: 817561600.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T10:10:45 | step: 99900 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.400332909426652e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.5 | consumed tokens: 818380800.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T10:11:03 | step: 100000 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.399130921228789e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.09 | consumed tokens: 819200000.0 | grad norm avg: 0.88 | grad norm last: 0.96 | 
2026-01-01T10:11:23 | step: 100100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.3979278416372836e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.73 | consumed tokens: 820019200.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T10:11:41 | step: 100200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.396723670652136e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.52 | consumed tokens: 820838400.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T10:11:59 | step: 100300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.395518408273347e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.75 | consumed tokens: 821657600.0 | grad norm avg: 0.91 | grad norm last: 0.8 | 
2026-01-01T10:12:17 | step: 100400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.394312418298796e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.66 | consumed tokens: 822476800.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T10:12:35 | step: 100500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.393104973132722e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.5 | consumed tokens: 823296000.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T10:12:53 | step: 100600 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 4.391896800370887e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.66 | consumed tokens: 824115200.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T10:13:11 | step: 100700 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.390687172417529e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.12 | consumed tokens: 824934400.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T10:13:30 | step: 100800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.3894768168684095e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.23 | consumed tokens: 825753600.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T10:13:48 | step: 100900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.388265369925648e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.59 | consumed tokens: 826572800.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T10:14:06 | step: 101000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.387053195387125e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.53 | consumed tokens: 827392000.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T10:14:24 | step: 101100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.385839565657079e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.34 | consumed tokens: 828211200.0 | grad norm avg: 0.9 | grad norm last: 0.81 | 
2026-01-01T10:14:42 | step: 101200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.384625208331272e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.09 | consumed tokens: 829030400.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T10:15:00 | step: 101300 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.383409395813942e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.08 | consumed tokens: 829849600.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T10:15:18 | step: 101400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.3821928557008505e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.34 | consumed tokens: 830668800.0 | grad norm avg: 0.91 | grad norm last: 0.82 | 
2026-01-01T10:15:36 | step: 101500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.380975224194117e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.77 | consumed tokens: 831488000.0 | grad norm avg: 0.89 | grad norm last: 1.05 | 
2026-01-01T10:15:54 | step: 101600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.379756865091622e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.8 | consumed tokens: 832307200.0 | grad norm avg: 0.9 | grad norm last: 0.99 | 
2026-01-01T10:16:12 | step: 101700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.378537050797604e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.27 | consumed tokens: 833126400.0 | grad norm avg: 0.9 | grad norm last: 0.78 | 
2026-01-01T10:16:30 | step: 101800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.377316508907825e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.11 | consumed tokens: 833945600.0 | grad norm avg: 0.88 | grad norm last: 1.05 | 
2026-01-01T10:16:49 | step: 101900 | train samples/s: 95.2 | train mfu (16-bit): -1.0 | lr mean: 4.3760945118265226e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.17 | consumed tokens: 834764800.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T10:17:07 | step: 102000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.374871787149459e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.66 | consumed tokens: 835584000.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T10:17:25 | step: 102100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.3736479710787535e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.88 | consumed tokens: 836403200.0 | grad norm avg: 0.91 | grad norm last: 0.99 | 
2026-01-01T10:17:43 | step: 102200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.3724234274122864e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.62 | consumed tokens: 837222400.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T10:18:01 | step: 102300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.3711974285542965e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.12 | consumed tokens: 838041600.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T10:18:19 | step: 102400 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.369970702100545e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.22 | consumed tokens: 838860800.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T10:18:37 | step: 102500 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.368742884253152e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.22 | consumed tokens: 839680000.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T10:18:55 | step: 102600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.367513975012116e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.25 | consumed tokens: 840499200.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T10:19:13 | step: 102700 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.3662839743774384e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.25 | consumed tokens: 841318400.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T10:19:31 | step: 102800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.365053246146999e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.92 | consumed tokens: 842137600.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T10:19:50 | step: 102900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.363821062725037e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.33 | consumed tokens: 842956800.0 | grad norm avg: 0.88 | grad norm last: 1.08 | 
2026-01-01T10:20:08 | step: 103000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.362588151707314e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.59 | consumed tokens: 843776000.0 | grad norm avg: 0.89 | grad norm last: 0.98 | 
2026-01-01T10:20:26 | step: 103100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.3613541492959484e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.06 | consumed tokens: 844595200.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T10:20:44 | step: 103200 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.360119055490941e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.19 | consumed tokens: 845414400.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T10:21:02 | step: 103300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.358883234090172e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.36 | consumed tokens: 846233600.0 | grad norm avg: 0.9 | grad norm last: 0.81 | 
2026-01-01T10:21:20 | step: 103400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.35764595749788e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.44 | consumed tokens: 847052800.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T10:21:38 | step: 103500 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.3564079533098266e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.47 | consumed tokens: 847872000.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T10:21:56 | step: 103600 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.355168857728131e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.77 | consumed tokens: 848691200.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T10:22:14 | step: 103700 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.353929034550674e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.56 | consumed tokens: 849510400.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T10:22:32 | step: 103800 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.3526877561816946e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.12 | consumed tokens: 850329600.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T10:22:51 | step: 103900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.3514457502169535e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.73 | consumed tokens: 851148800.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T10:23:09 | step: 104000 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.35020265285857e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.92 | consumed tokens: 851968000.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T10:23:27 | step: 104100 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.348958464106545e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.89 | consumed tokens: 852787200.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T10:23:45 | step: 104200 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.3477131839608774e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.06 | consumed tokens: 853606400.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T10:24:03 | step: 104300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.3464671762194484e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.72 | consumed tokens: 854425600.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T10:24:21 | step: 104400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.3452200770843774e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 4.16 | consumed tokens: 855244800.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T10:24:40 | step: 104500 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 4.343971886555664e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.73 | consumed tokens: 856064000.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T10:24:58 | step: 104600 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.342722604633309e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.53 | consumed tokens: 856883200.0 | grad norm avg: 0.9 | grad norm last: 1.07 | 
2026-01-01T10:25:16 | step: 104700 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.3414722313173115e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.78 | consumed tokens: 857702400.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T10:25:34 | step: 104800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.340221130405553e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.89 | consumed tokens: 858521600.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T10:25:52 | step: 104900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.338968938100152e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.78 | consumed tokens: 859340800.0 | grad norm avg: 0.89 | grad norm last: 1.0 | 
2026-01-01T10:26:10 | step: 105000 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.3377156544011086e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.59 | consumed tokens: 860160000.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T10:26:30 | step: 105100 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.336461643106304e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.72 | consumed tokens: 860979200.0 | grad norm avg: 0.91 | grad norm last: 1.02 | 
2026-01-01T10:26:48 | step: 105200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.335206176619977e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.25 | consumed tokens: 861798400.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T10:27:06 | step: 105300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.333949982537888e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.02 | consumed tokens: 862617600.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T10:27:24 | step: 105400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.332692697062157e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.91 | consumed tokens: 863436800.0 | grad norm avg: 0.89 | grad norm last: 0.79 | 
2026-01-01T10:27:42 | step: 105500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.331434683990665e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.27 | consumed tokens: 864256000.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T10:28:00 | step: 105600 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.3301752157276496e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.2 | consumed tokens: 865075200.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T10:28:18 | step: 105700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.328915019868873e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.08 | consumed tokens: 865894400.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T10:28:37 | step: 105800 | train samples/s: 94.8 | train mfu (16-bit): -1.0 | lr mean: 4.3276537326164544e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.53 | consumed tokens: 866713600.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T10:28:55 | step: 105900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.326391717768274e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.27 | consumed tokens: 867532800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T10:29:13 | step: 106000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.325128247728571e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.39 | consumed tokens: 868352000.0 | grad norm avg: 0.9 | grad norm last: 0.98 | 
2026-01-01T10:29:31 | step: 106100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.323864050093107e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.36 | consumed tokens: 869171200.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T10:29:49 | step: 106200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.3225987610640004e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.75 | consumed tokens: 869990400.0 | grad norm avg: 0.9 | grad norm last: 0.76 | 
2026-01-01T10:30:07 | step: 106300 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.3213327444391325e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.38 | consumed tokens: 870809600.0 | grad norm avg: 0.9 | grad norm last: 1.01 | 
2026-01-01T10:30:25 | step: 106400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.320065272622742e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.34 | consumed tokens: 871628800.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T10:30:43 | step: 106500 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.3187970732105896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 4.09 | consumed tokens: 872448000.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T10:31:01 | step: 106600 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.317528146202676e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.28 | consumed tokens: 873267200.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T10:31:19 | step: 106700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.3162577640032396e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.7 | consumed tokens: 874086400.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T10:31:37 | step: 106800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.314986654208042e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.72 | consumed tokens: 874905600.0 | grad norm avg: 0.88 | grad norm last: 0.95 | 
2026-01-01T10:31:56 | step: 106900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.313714453019202e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.69 | consumed tokens: 875724800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T10:32:14 | step: 107000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.3124411604367197e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.36 | consumed tokens: 876544000.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T10:32:32 | step: 107100 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.311167140258476e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.55 | consumed tokens: 877363200.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T10:32:50 | step: 107200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.30989166488871e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.08 | consumed tokens: 878182400.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T10:33:08 | step: 107300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.308615825721063e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.39 | consumed tokens: 879001600.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T10:33:26 | step: 107400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.307338531361893e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.5 | consumed tokens: 879820800.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T10:33:44 | step: 107500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.3060605094069615e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.34 | consumed tokens: 880640000.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T10:34:02 | step: 107600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.304781396058388e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.83 | consumed tokens: 881459200.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T10:34:20 | step: 107700 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.3035011913161725e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.05 | consumed tokens: 882278400.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T10:34:38 | step: 107800 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.302219895180315e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.41 | consumed tokens: 883097600.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T10:34:56 | step: 107900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.3009378714486957e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.38 | consumed tokens: 883916800.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T10:35:14 | step: 108000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.2996547563234344e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.14 | consumed tokens: 884736000.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T10:35:32 | step: 108100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.298370913602412e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.14 | consumed tokens: 885555200.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T10:35:50 | step: 108200 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.297085615689866e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.38 | consumed tokens: 886374400.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T10:36:08 | step: 108300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.295799590181559e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.67 | consumed tokens: 887193600.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T10:36:26 | step: 108400 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.294512837077491e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.14 | consumed tokens: 888012800.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T10:36:44 | step: 108500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.2932246287819e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.64 | consumed tokens: 888832000.0 | grad norm avg: 0.89 | grad norm last: 0.82 | 
2026-01-01T10:37:02 | step: 108600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.291935692890547e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.12 | consumed tokens: 889651200.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T10:37:20 | step: 108700 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.2906456656055525e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.02 | consumed tokens: 890470400.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T10:37:38 | step: 108800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.2893549107247964e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.03 | consumed tokens: 891289600.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T10:37:56 | step: 108900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.288063064450398e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.02 | consumed tokens: 892108800.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T10:38:14 | step: 109000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.286770126782358e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.05 | consumed tokens: 892928000.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T10:38:32 | step: 109100 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.285476097720675e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.64 | consumed tokens: 893747200.0 | grad norm avg: 0.89 | grad norm last: 0.8 | 
2026-01-01T10:38:50 | step: 109200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.284181341063231e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.53 | consumed tokens: 894566400.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T10:39:08 | step: 109300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.282885493012145e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.17 | consumed tokens: 895385600.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T10:39:26 | step: 109400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.281588917365298e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.48 | consumed tokens: 896204800.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T10:39:44 | step: 109500 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.2802908865269274e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.11 | consumed tokens: 897024000.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T10:40:02 | step: 109600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.2789921280927956e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.42 | consumed tokens: 897843200.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T10:40:20 | step: 109700 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 4.2776926420629025e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 4.03 | consumed tokens: 898662400.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T10:40:38 | step: 109800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.2763917008414865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.33 | consumed tokens: 899481600.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T10:40:56 | step: 109900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.275090032024309e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.09 | consumed tokens: 900300800.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T10:41:14 | step: 110000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.27378763561137e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.69 | consumed tokens: 901120000.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T10:41:34 | step: 110100 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.2724837840069085e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.23 | consumed tokens: 901939200.0 | grad norm avg: 0.89 | grad norm last: 0.82 | 
2026-01-01T10:41:52 | step: 110200 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.271179568604566e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.72 | consumed tokens: 902758400.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T10:42:10 | step: 110300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.269873898010701e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.59 | consumed tokens: 903577600.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T10:42:28 | step: 110400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.268567499821074e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.09 | consumed tokens: 904396800.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T10:42:46 | step: 110500 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.2672600102378055e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.88 | consumed tokens: 905216000.0 | grad norm avg: 0.89 | grad norm last: 0.77 | 
2026-01-01T10:43:04 | step: 110600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.2659514292608947e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.16 | consumed tokens: 906035200.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T10:43:22 | step: 110700 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.2646421206882223e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.97 | consumed tokens: 906854400.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T10:43:40 | step: 110800 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.263331720721908e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.25 | consumed tokens: 907673600.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T10:43:58 | step: 110900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.2620202293619514e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.38 | consumed tokens: 908492800.0 | grad norm avg: 0.91 | grad norm last: 0.84 | 
2026-01-01T10:44:16 | step: 111000 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.2607080104062334e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 4.66 | consumed tokens: 909312000.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T10:44:34 | step: 111100 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.259394700056873e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.84 | consumed tokens: 910131200.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T10:44:52 | step: 111200 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.258080662111752e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.97 | consumed tokens: 910950400.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T10:45:10 | step: 111300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.2567651689751074e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.59 | consumed tokens: 911769600.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T10:45:28 | step: 111400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.255449312040582e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.27 | consumed tokens: 912588800.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T10:45:46 | step: 111500 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.2541319999145344e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.03 | consumed tokens: 913408000.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T10:46:04 | step: 111600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.252813960192725e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.41 | consumed tokens: 914227200.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T10:46:22 | step: 111700 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.2514948290772736e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.61 | consumed tokens: 915046400.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T10:46:40 | step: 111800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.250174970366061e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.14 | consumed tokens: 915865600.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T10:46:58 | step: 111900 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.248854020261206e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.41 | consumed tokens: 916684800.0 | grad norm avg: 0.91 | grad norm last: 0.98 | 
2026-01-01T10:47:16 | step: 112000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.247532342560589e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.33 | consumed tokens: 917504000.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T10:47:34 | step: 112100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.24620920966845e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.7 | consumed tokens: 918323200.0 | grad norm avg: 0.9 | grad norm last: 0.8 | 
2026-01-01T10:47:52 | step: 112200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.2448853491805494e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.84 | consumed tokens: 919142400.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T10:48:10 | step: 112300 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.243560761096887e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.48 | consumed tokens: 919961600.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T10:48:28 | step: 112400 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.242235081619583e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.61 | consumed tokens: 920780800.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T10:48:46 | step: 112500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.240908310748637e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.11 | consumed tokens: 921600000.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T10:49:04 | step: 112600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.239580812281929e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.73 | consumed tokens: 922419200.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T10:49:22 | step: 112700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.238252222421579e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.58 | consumed tokens: 923238400.0 | grad norm avg: 0.89 | grad norm last: 0.82 | 
2026-01-01T10:49:40 | step: 112800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.236922541167587e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.75 | consumed tokens: 924057600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T10:49:58 | step: 112900 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.2355921323178336e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.3 | consumed tokens: 924876800.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T10:50:16 | step: 113000 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.234260632074438e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.48 | consumed tokens: 925696000.0 | grad norm avg: 0.89 | grad norm last: 0.8 | 
2026-01-01T10:50:34 | step: 113100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.232928404235281e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.95 | consumed tokens: 926515200.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T10:50:52 | step: 113200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.231595085002482e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.45 | consumed tokens: 927334400.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T10:51:10 | step: 113300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.230260674376041e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.94 | consumed tokens: 928153600.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T10:51:28 | step: 113400 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.228925536153838e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.39 | consumed tokens: 928972800.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T10:51:46 | step: 113500 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.227589306537993e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.06 | consumed tokens: 929792000.0 | grad norm avg: 0.91 | grad norm last: 0.81 | 
2026-01-01T10:52:04 | step: 113600 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.226252349326387e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.89 | consumed tokens: 930611200.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T10:52:22 | step: 113700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.224914300721139e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.62 | consumed tokens: 931430400.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T10:52:40 | step: 113800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.223575160722248e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.8 | consumed tokens: 932249600.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T10:52:58 | step: 113900 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.2222352931275964e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.69 | consumed tokens: 933068800.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T10:53:16 | step: 114000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.2208943341393024e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.98 | consumed tokens: 933888000.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-01T10:53:34 | step: 114100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.219552647555247e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.16 | consumed tokens: 934707200.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T10:53:52 | step: 114200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.2182098695775494e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.95 | consumed tokens: 935526400.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T10:54:10 | step: 114300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.21686600020621e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.09 | consumed tokens: 936345600.0 | grad norm avg: 0.89 | grad norm last: 0.97 | 
2026-01-01T10:54:28 | step: 114400 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.2155214032391086e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.44 | consumed tokens: 937164800.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T10:54:46 | step: 114500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.214176078676246e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.66 | consumed tokens: 937984000.0 | grad norm avg: 0.9 | grad norm last: 1.0 | 
2026-01-01T10:55:04 | step: 114600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.212829298921861e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.16 | consumed tokens: 938803200.0 | grad norm avg: 0.89 | grad norm last: 1.04 | 
2026-01-01T10:55:22 | step: 114700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.211482155369595e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.09 | consumed tokens: 939622400.0 | grad norm avg: 0.9 | grad norm last: 1.02 | 
2026-01-01T10:55:41 | step: 114800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.210133556625806e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.92 | consumed tokens: 940441600.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T10:55:59 | step: 114900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.2087842302862555e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.2 | consumed tokens: 941260800.0 | grad norm avg: 0.91 | grad norm last: 0.81 | 
2026-01-01T10:56:17 | step: 115000 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.207434176350944e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.38 | consumed tokens: 942080000.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T10:56:36 | step: 115100 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.206082667224109e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.05 | consumed tokens: 942899200.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T10:56:54 | step: 115200 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.204730794299394e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.92 | consumed tokens: 943718400.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T10:57:12 | step: 115300 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.2033778299810365e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.73 | consumed tokens: 944537600.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T10:57:30 | step: 115400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.202023774269037e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.61 | consumed tokens: 945356800.0 | grad norm avg: 0.91 | grad norm last: 0.83 | 
2026-01-01T10:57:48 | step: 115500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.200668627163395e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 4.12 | consumed tokens: 946176000.0 | grad norm avg: 0.89 | grad norm last: 0.82 | 
2026-01-01T10:58:06 | step: 115600 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.199312752461992e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.27 | consumed tokens: 946995200.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T10:58:24 | step: 115700 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.197956150164828e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.34 | consumed tokens: 947814400.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T10:58:42 | step: 115800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.196598456474021e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.03 | consumed tokens: 948633600.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T10:59:00 | step: 115900 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.195239671389572e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.84 | consumed tokens: 949452800.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T10:59:18 | step: 116000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.193880158709362e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.75 | consumed tokens: 950272000.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T10:59:37 | step: 116100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.19251955463551e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 4.03 | consumed tokens: 951091200.0 | grad norm avg: 0.89 | grad norm last: 0.98 | 
2026-01-01T10:59:55 | step: 116200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.191158222965896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.11 | consumed tokens: 951910400.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T11:00:13 | step: 116300 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.18979579990264e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.19 | consumed tokens: 952729600.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T11:00:31 | step: 116400 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.188432649243623e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.2 | consumed tokens: 953548800.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T11:00:49 | step: 116500 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.1870684071909636e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.09 | consumed tokens: 954368000.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T11:01:07 | step: 116600 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.185703437542543e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.55 | consumed tokens: 955187200.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T11:01:25 | step: 116700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.18433737650048e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.44 | consumed tokens: 956006400.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-01T11:01:43 | step: 116800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.1829705878626555e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.34 | consumed tokens: 956825600.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T11:02:01 | step: 116900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.181602707831189e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.58 | consumed tokens: 957644800.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T11:02:19 | step: 117000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.1802337364060804e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.19 | consumed tokens: 958464000.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T11:02:37 | step: 117100 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.1788640373852104e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.16 | consumed tokens: 959283200.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T11:02:55 | step: 117200 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.177493246970698e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.66 | consumed tokens: 960102400.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T11:03:13 | step: 117300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.176121728960425e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.83 | consumed tokens: 960921600.0 | grad norm avg: 0.89 | grad norm last: 1.01 | 
2026-01-01T11:03:31 | step: 117400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.17474948335439e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.39 | consumed tokens: 961740800.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T11:03:49 | step: 117500 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.1733761463547125e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.0 | consumed tokens: 962560000.0 | grad norm avg: 0.89 | grad norm last: 1.02 | 
2026-01-01T11:04:07 | step: 117600 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.172001717961393e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.02 | consumed tokens: 963379200.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T11:04:25 | step: 117700 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.1706265619723126e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.83 | consumed tokens: 964198400.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T11:04:43 | step: 117800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.16925031458959e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.62 | consumed tokens: 965017600.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T11:05:01 | step: 117900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.1678733396111056e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.52 | consumed tokens: 965836800.0 | grad norm avg: 0.9 | grad norm last: 0.99 | 
2026-01-01T11:05:19 | step: 118000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.166495273238979e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.83 | consumed tokens: 966656000.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T11:05:37 | step: 118100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.1651164792710915e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.03 | consumed tokens: 967475200.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T11:05:55 | step: 118200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.1637365939095616e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.89 | consumed tokens: 968294400.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T11:06:13 | step: 118300 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.16235598095227e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.77 | consumed tokens: 969113600.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T11:06:31 | step: 118400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.1609746403992176e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.5 | consumed tokens: 969932800.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T11:06:49 | step: 118500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.159591844654642e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.64 | consumed tokens: 970752000.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T11:07:07 | step: 118600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.158208685112186e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.61 | consumed tokens: 971571200.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-01T11:07:25 | step: 118700 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.1568244341760874e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.42 | consumed tokens: 972390400.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T11:07:43 | step: 118800 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.155439091846347e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.3 | consumed tokens: 973209600.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T11:08:01 | step: 118900 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.154053021920845e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.39 | consumed tokens: 974028800.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T11:08:19 | step: 119000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.152665860601701e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 5.0 | consumed tokens: 974848000.0 | grad norm avg: 0.9 | grad norm last: 0.97 | 
2026-01-01T11:08:37 | step: 119100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.1512779716867954e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.91 | consumed tokens: 975667200.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T11:08:55 | step: 119200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.149888991378248e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.05 | consumed tokens: 976486400.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T11:09:13 | step: 119300 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.148499283473939e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.7 | consumed tokens: 977305600.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T11:09:31 | step: 119400 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.147108847973868e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.27 | consumed tokens: 978124800.0 | grad norm avg: 0.9 | grad norm last: 0.77 | 
2026-01-01T11:09:49 | step: 119500 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.145717321080156e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.84 | consumed tokens: 978944000.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T11:10:07 | step: 119600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.144324702792801e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.66 | consumed tokens: 979763200.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T11:10:25 | step: 119700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.142931356909685e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 4.28 | consumed tokens: 980582400.0 | grad norm avg: 0.91 | grad norm last: 0.77 | 
2026-01-01T11:10:43 | step: 119800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.141537283430807e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.78 | consumed tokens: 981401600.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T11:11:01 | step: 119900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.1401421185582876e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 4.03 | consumed tokens: 982220800.0 | grad norm avg: 0.9 | grad norm last: 0.8 | 
2026-01-01T11:11:19 | step: 120000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.138745862292126e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.91 | consumed tokens: 983040000.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T11:11:39 | step: 120100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.137349242228083e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.3 | consumed tokens: 983859200.0 | grad norm avg: 0.89 | grad norm last: 0.76 | 
2026-01-01T11:11:57 | step: 120200 | train samples/s: 92.9 | train mfu (16-bit): -1.0 | lr mean: 4.135951166972518e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.86 | consumed tokens: 984678400.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T11:12:16 | step: 120300 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.134552364121191e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.5 | consumed tokens: 985497600.0 | grad norm avg: 0.89 | grad norm last: 1.02 | 
2026-01-01T11:12:34 | step: 120400 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.133152833674103e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.92 | consumed tokens: 986316800.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T11:12:52 | step: 120500 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.1317525756312534e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.48 | consumed tokens: 987136000.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T11:13:10 | step: 120600 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.130350862396881e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.48 | consumed tokens: 987955200.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T11:13:28 | step: 120700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.128948785364628e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 4.09 | consumed tokens: 988774400.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T11:13:47 | step: 120800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.1275456169387326e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.28 | consumed tokens: 989593600.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T11:14:05 | step: 120900 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.126141357119195e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.91 | consumed tokens: 990412800.0 | grad norm avg: 0.89 | grad norm last: 1.05 | 
2026-01-01T11:14:23 | step: 121000 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 4.1247363697038963e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.94 | consumed tokens: 991232000.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T11:14:41 | step: 121100 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.123330654692836e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.36 | consumed tokens: 992051200.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T11:14:59 | step: 121200 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.121923848288134e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 4.06 | consumed tokens: 992870400.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T11:15:18 | step: 121300 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 4.12051631428767e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.53 | consumed tokens: 993689600.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T11:15:36 | step: 121400 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.119107688893564e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.81 | consumed tokens: 994508800.0 | grad norm avg: 0.91 | grad norm last: 0.79 | 
2026-01-01T11:15:54 | step: 121500 | train samples/s: 95.0 | train mfu (16-bit): -1.0 | lr mean: 4.117698335903697e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.86 | consumed tokens: 995328000.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T11:16:13 | step: 121600 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.116287891520187e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.64 | consumed tokens: 996147200.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T11:16:31 | step: 121700 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 4.1148767195409164e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.34 | consumed tokens: 996966400.0 | grad norm avg: 0.9 | grad norm last: 1.07 | 
2026-01-01T11:16:49 | step: 121800 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 4.113464819965884e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.25 | consumed tokens: 997785600.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T11:17:07 | step: 121900 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.11205182899721e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.61 | consumed tokens: 998604800.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T11:17:26 | step: 122000 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.110638110432774e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.97 | consumed tokens: 999424000.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T11:17:44 | step: 122100 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.109223300474696e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.05 | consumed tokens: 1000243200.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T11:18:02 | step: 122200 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.1078077629208565e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.75 | consumed tokens: 1001062400.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T11:18:20 | step: 122300 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.106391497771256e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.45 | consumed tokens: 1001881600.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T11:18:38 | step: 122400 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.104974141228013e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.28 | consumed tokens: 1002700800.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T11:18:57 | step: 122500 | train samples/s: 94.9 | train mfu (16-bit): -1.0 | lr mean: 4.103555693291128e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 4.31 | consumed tokens: 1003520000.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T11:19:15 | step: 122600 | train samples/s: 94.2 | train mfu (16-bit): -1.0 | lr mean: 4.102136881556362e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.55 | consumed tokens: 1004339200.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T11:19:34 | step: 122700 | train samples/s: 94.8 | train mfu (16-bit): -1.0 | lr mean: 4.100716614630073e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.95 | consumed tokens: 1005158400.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T11:19:52 | step: 122800 | train samples/s: 93.7 | train mfu (16-bit): -1.0 | lr mean: 4.099295983905904e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.42 | consumed tokens: 1005977600.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T11:20:11 | step: 122900 | train samples/s: 94.6 | train mfu (16-bit): -1.0 | lr mean: 4.0978742617880926e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.52 | consumed tokens: 1006796800.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T11:20:29 | step: 123000 | train samples/s: 94.8 | train mfu (16-bit): -1.0 | lr mean: 4.096451448276639e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.73 | consumed tokens: 1007616000.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T11:20:49 | step: 123100 | train samples/s: 90.0 | train mfu (16-bit): -1.0 | lr mean: 4.095028270967305e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.39 | consumed tokens: 1008435200.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T11:21:08 | step: 123200 | train samples/s: 87.6 | train mfu (16-bit): -1.0 | lr mean: 4.093604002264328e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.44 | consumed tokens: 1009254400.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T11:21:27 | step: 123300 | train samples/s: 94.4 | train mfu (16-bit): -1.0 | lr mean: 4.09217864216771e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.78 | consumed tokens: 1010073600.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T11:21:45 | step: 123400 | train samples/s: 94.9 | train mfu (16-bit): -1.0 | lr mean: 4.09075255447533e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.44 | consumed tokens: 1010892800.0 | grad norm avg: 0.89 | grad norm last: 0.77 | 
2026-01-01T11:22:04 | step: 123500 | train samples/s: 94.8 | train mfu (16-bit): -1.0 | lr mean: 4.0893257391871884e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.92 | consumed tokens: 1011712000.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T11:22:22 | step: 123600 | train samples/s: 94.9 | train mfu (16-bit): -1.0 | lr mean: 4.087897832505405e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.39 | consumed tokens: 1012531200.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T11:22:40 | step: 123700 | train samples/s: 95.0 | train mfu (16-bit): -1.0 | lr mean: 4.08646919822786e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 4.06 | consumed tokens: 1013350400.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T11:22:59 | step: 123800 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.085039472556673e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.48 | consumed tokens: 1014169600.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T11:23:17 | step: 123900 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.0836090192897245e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.09 | consumed tokens: 1014988800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T11:23:35 | step: 124000 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 4.0821778384270146e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.84 | consumed tokens: 1015808000.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T11:23:54 | step: 124100 | train samples/s: 94.3 | train mfu (16-bit): -1.0 | lr mean: 4.0807455661706626e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.59 | consumed tokens: 1016627200.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T11:24:12 | step: 124200 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.079312566318549e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.08 | consumed tokens: 1017446400.0 | grad norm avg: 0.89 | grad norm last: 0.99 | 
2026-01-01T11:24:30 | step: 124300 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 4.0778788388706744e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.19 | consumed tokens: 1018265600.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T11:24:49 | step: 124400 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.0764440200291574e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.58 | consumed tokens: 1019084800.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T11:25:07 | step: 124500 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.075008473591879e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.2 | consumed tokens: 1019904000.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T11:25:26 | step: 124600 | train samples/s: 87.6 | train mfu (16-bit): -1.0 | lr mean: 4.0735718357609585e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.41 | consumed tokens: 1020723200.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T11:25:47 | step: 124700 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.072134834132157e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.48 | consumed tokens: 1021542400.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T11:26:06 | step: 124800 | train samples/s: 93.1 | train mfu (16-bit): -1.0 | lr mean: 4.070696377311833e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.23 | consumed tokens: 1022361600.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T11:26:24 | step: 124900 | train samples/s: 95.1 | train mfu (16-bit): -1.0 | lr mean: 4.0692575566936284e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.91 | consumed tokens: 1023180800.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T11:26:42 | step: 125000 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.0678176446817815e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.11 | consumed tokens: 1024000000.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T11:27:02 | step: 125100 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 4.0663766412762925e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.62 | consumed tokens: 1024819200.0 | grad norm avg: 0.88 | grad norm last: 0.95 | 
2026-01-01T11:27:20 | step: 125200 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.064935274072923e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.66 | consumed tokens: 1025638400.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T11:27:39 | step: 125300 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.063492815475911e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.0 | consumed tokens: 1026457600.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T11:27:57 | step: 125400 | train samples/s: 94.4 | train mfu (16-bit): -1.0 | lr mean: 4.062049265485257e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.73 | consumed tokens: 1027276800.0 | grad norm avg: 0.91 | grad norm last: 0.82 | 
2026-01-01T11:28:15 | step: 125500 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 4.0606049878988415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.23 | consumed tokens: 1028096000.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T11:28:34 | step: 125600 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.059159982716665e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.14 | consumed tokens: 1028915200.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T11:28:52 | step: 125700 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.0577142499387264e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.05 | consumed tokens: 1029734400.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T11:29:10 | step: 125800 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.056267425767146e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.11 | consumed tokens: 1030553600.0 | grad norm avg: 0.88 | grad norm last: 0.97 | 
2026-01-01T11:29:28 | step: 125900 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.054819873999804e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.02 | consumed tokens: 1031372800.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T11:29:46 | step: 126000 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.053371594636701e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.25 | consumed tokens: 1032192000.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T11:30:05 | step: 126100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.051922223879956e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 4.03 | consumed tokens: 1033011200.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T11:30:23 | step: 126200 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 4.050472125527449e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.39 | consumed tokens: 1033830400.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T11:30:41 | step: 126300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.0490209357813e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.77 | consumed tokens: 1034649600.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T11:30:59 | step: 126400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.0475693822372705e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.38 | consumed tokens: 1035468800.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T11:31:17 | step: 126500 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 4.046116373501718e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.98 | consumed tokens: 1036288000.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T11:31:35 | step: 126600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.044663000968285e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.05 | consumed tokens: 1037107200.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T11:31:54 | step: 126700 | train samples/s: 94.9 | train mfu (16-bit): -1.0 | lr mean: 4.0432085370412096e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.47 | consumed tokens: 1037926400.0 | grad norm avg: 0.9 | grad norm last: 0.8 | 
2026-01-01T11:32:12 | step: 126800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.041753345518373e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.39 | consumed tokens: 1038745600.0 | grad norm avg: 0.9 | grad norm last: 0.81 | 
2026-01-01T11:32:30 | step: 126900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.040297426399775e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.11 | consumed tokens: 1039564800.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T11:32:48 | step: 127000 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.0388404158875346e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.73 | consumed tokens: 1040384000.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T11:33:06 | step: 127100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.037382677779533e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.27 | consumed tokens: 1041203200.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T11:33:24 | step: 127200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.03592421207577e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.94 | consumed tokens: 1042022400.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T11:33:42 | step: 127300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.034464654978365e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.83 | consumed tokens: 1042841600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T11:34:00 | step: 127400 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 4.033004370285198e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.5 | consumed tokens: 1043660800.0 | grad norm avg: 0.88 | grad norm last: 0.95 | 
2026-01-01T11:34:19 | step: 127500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.03154335799627e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.72 | consumed tokens: 1044480000.0 | grad norm avg: 0.9 | grad norm last: 1.07 | 
2026-01-01T11:34:37 | step: 127600 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.0300812543137e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.3 | consumed tokens: 1045299200.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T11:34:55 | step: 127700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.028618786833249e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.42 | consumed tokens: 1046118400.0 | grad norm avg: 0.89 | grad norm last: 1.02 | 
2026-01-01T11:35:13 | step: 127800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 4.027154864161275e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.44 | consumed tokens: 1046937600.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T11:35:31 | step: 127900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.025690577691421e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.08 | consumed tokens: 1047756800.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T11:35:49 | step: 128000 | train samples/s: 94.7 | train mfu (16-bit): -1.0 | lr mean: 4.0242251998279244e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.3 | consumed tokens: 1048576000.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T11:36:07 | step: 128100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.0227590943686664e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.62 | consumed tokens: 1049395200.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T11:36:25 | step: 128200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.021292261313647e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.41 | consumed tokens: 1050214400.0 | grad norm avg: 0.9 | grad norm last: 0.81 | 
2026-01-01T11:36:44 | step: 128300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.0198243368649855e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.81 | consumed tokens: 1051033600.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T11:37:02 | step: 128400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.0183556848205626e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.84 | consumed tokens: 1051852800.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T11:37:20 | step: 128500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.016886305180378e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.09 | consumed tokens: 1052672000.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T11:37:38 | step: 128600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.0154161979444325e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.14 | consumed tokens: 1053491200.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T11:37:56 | step: 128700 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.0139449993148446e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.73 | consumed tokens: 1054310400.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T11:38:14 | step: 128800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.012473073089495e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 4.22 | consumed tokens: 1055129600.0 | grad norm avg: 0.89 | grad norm last: 0.82 | 
2026-01-01T11:38:32 | step: 128900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.0110004192683846e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.11 | consumed tokens: 1055948800.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T11:38:50 | step: 129000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.009526674053632e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.98 | consumed tokens: 1056768000.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T11:39:08 | step: 129100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.0080522012431175e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.59 | consumed tokens: 1057587200.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T11:39:26 | step: 129200 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.006577000836842e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.31 | consumed tokens: 1058406400.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T11:39:45 | step: 129300 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 4.0051010728348047e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.8 | consumed tokens: 1059225600.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T11:40:03 | step: 129400 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.0036240534391254e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.53 | consumed tokens: 1060044800.0 | grad norm avg: 0.9 | grad norm last: 0.99 | 
2026-01-01T11:40:21 | step: 129500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 4.0021466702455655e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.94 | consumed tokens: 1060864000.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T11:40:39 | step: 129600 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 4.000667831860483e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.16 | consumed tokens: 1061683200.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T11:40:57 | step: 129700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.999188629677519e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.69 | consumed tokens: 1062502400.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T11:41:15 | step: 129800 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.9977083361009136e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.42 | consumed tokens: 1063321600.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T11:41:33 | step: 129900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.996227678726427e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.28 | consumed tokens: 1064140800.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T11:41:51 | step: 130000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.994745566160418e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.83 | consumed tokens: 1064960000.0 | grad norm avg: 0.89 | grad norm last: 0.98 | 
2026-01-01T11:42:11 | step: 130100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.993263089796528e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.75 | consumed tokens: 1065779200.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T11:42:29 | step: 130200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.991779522038996e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.05 | consumed tokens: 1066598400.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T11:42:47 | step: 130300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.9902955904835835e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.12 | consumed tokens: 1067417600.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T11:43:05 | step: 130400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.988810203736648e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.98 | consumed tokens: 1068236800.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T11:43:23 | step: 130500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.987324453191832e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.05 | consumed tokens: 1069056000.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T11:43:41 | step: 130600 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 3.985837611253373e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.25 | consumed tokens: 1069875200.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T11:43:59 | step: 130700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.984350405517034e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.17 | consumed tokens: 1070694400.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T11:44:17 | step: 130800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.982862108387053e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.05 | consumed tokens: 1071513600.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T11:44:35 | step: 130900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.98137271986343e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.83 | consumed tokens: 1072332800.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T11:44:53 | step: 131000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.9798829675419256e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.03 | consumed tokens: 1073152000.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T11:45:11 | step: 131100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.9783921238267794e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.03 | consumed tokens: 1073971200.0 | grad norm avg: 0.9 | grad norm last: 0.79 | 
2026-01-01T11:45:29 | step: 131200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.976900552515872e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.83 | consumed tokens: 1074790400.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T11:45:48 | step: 131300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.975408253609203e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.06 | consumed tokens: 1075609600.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T11:46:06 | step: 131400 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.9739152271067724e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.89 | consumed tokens: 1076428800.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T11:46:24 | step: 131500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.9724211092107e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.77 | consumed tokens: 1077248000.0 | grad norm avg: 0.88 | grad norm last: 0.79 | 
2026-01-01T11:46:42 | step: 131600 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.970926263718866e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.11 | consumed tokens: 1078067200.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T11:47:00 | step: 131700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.9694306906312704e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.03 | consumed tokens: 1078886400.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T11:47:18 | step: 131800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.9679343899479136e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.14 | consumed tokens: 1079705600.0 | grad norm avg: 0.89 | grad norm last: 0.98 | 
2026-01-01T11:47:36 | step: 131900 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 3.9664369978709146e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 4.12 | consumed tokens: 1080524800.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T11:47:54 | step: 132000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.964939241996035e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.38 | consumed tokens: 1081344000.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T11:48:12 | step: 132100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.963440394727513e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.5 | consumed tokens: 1082163200.0 | grad norm avg: 0.89 | grad norm last: 1.0 | 
2026-01-01T11:48:30 | step: 132200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.96194081986323e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.81 | consumed tokens: 1082982400.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T11:48:48 | step: 132300 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.9604405174031854e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.53 | consumed tokens: 1083801600.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T11:49:06 | step: 132400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.9589391235494986e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.36 | consumed tokens: 1084620800.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T11:49:24 | step: 132500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.957437365897931e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.56 | consumed tokens: 1085440000.0 | grad norm avg: 0.89 | grad norm last: 0.98 | 
2026-01-01T11:49:43 | step: 132600 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.9559345168527216e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.31 | consumed tokens: 1086259200.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T11:50:01 | step: 132700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.9544309402117506e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.09 | consumed tokens: 1087078400.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T11:50:19 | step: 132800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.952926635975018e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.02 | consumed tokens: 1087897600.0 | grad norm avg: 0.89 | grad norm last: 0.79 | 
2026-01-01T11:50:37 | step: 132900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.9514212403446436e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.23 | consumed tokens: 1088716800.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T11:50:55 | step: 133000 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.949915480916388e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.81 | consumed tokens: 1089536000.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T11:51:13 | step: 133100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.948408630094491e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.19 | consumed tokens: 1090355200.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T11:51:31 | step: 133200 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 3.946901051676832e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.34 | consumed tokens: 1091174400.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T11:51:49 | step: 133300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.945392745663412e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.77 | consumed tokens: 1091993600.0 | grad norm avg: 0.89 | grad norm last: 0.77 | 
2026-01-01T11:52:07 | step: 133400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.94388371205423e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.55 | consumed tokens: 1092812800.0 | grad norm avg: 0.89 | grad norm last: 0.79 | 
2026-01-01T11:52:25 | step: 133500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.9423735870514065e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.62 | consumed tokens: 1093632000.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T11:52:43 | step: 133600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.940862734452821e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.88 | consumed tokens: 1094451200.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T11:53:01 | step: 133700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.9393515180563554e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 4.06 | consumed tokens: 1095270400.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T11:53:20 | step: 133800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.9378392102662474e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.59 | consumed tokens: 1096089600.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T11:53:38 | step: 133900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.936326174880378e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.22 | consumed tokens: 1096908800.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T11:53:56 | step: 134000 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.9348120481008664e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.56 | consumed tokens: 1097728000.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T11:54:14 | step: 134100 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.933297557523474e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.31 | consumed tokens: 1098547200.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T11:54:32 | step: 134200 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.93178197555244e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.75 | consumed tokens: 1099366400.0 | grad norm avg: 0.88 | grad norm last: 1.0 | 
2026-01-01T11:54:50 | step: 134300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.9302660297835246e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.45 | consumed tokens: 1100185600.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T11:55:08 | step: 134400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.928748992620967e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.89 | consumed tokens: 1101004800.0 | grad norm avg: 0.9 | grad norm last: 1.22 | 
2026-01-01T11:55:26 | step: 134500 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 3.927231227862649e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.3 | consumed tokens: 1101824000.0 | grad norm avg: 0.9 | grad norm last: 1.02 | 
2026-01-01T11:55:44 | step: 134600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.9257127355085686e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.42 | consumed tokens: 1102643200.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T11:56:02 | step: 134700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.9241931517608464e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.16 | consumed tokens: 1103462400.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T11:56:20 | step: 134800 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.9226732042152435e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.28 | consumed tokens: 1104281600.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T11:56:38 | step: 134900 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.9211521652759984e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.05 | consumed tokens: 1105100800.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T11:56:56 | step: 135000 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.9196307625388727e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.95 | consumed tokens: 1105920000.0 | grad norm avg: 0.9 | grad norm last: 1.0 | 
2026-01-01T11:57:16 | step: 135100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.918108268408105e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.14 | consumed tokens: 1106739200.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T11:57:34 | step: 135200 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.9165850466815755e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.88 | consumed tokens: 1107558400.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T11:57:52 | step: 135300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.915061097359285e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.42 | consumed tokens: 1108377600.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T11:58:10 | step: 135400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.913536056643352e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.08 | consumed tokens: 1109196800.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T11:58:28 | step: 135500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.9120106521295384e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.7 | consumed tokens: 1110016000.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T11:58:46 | step: 135600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.9104845200199634e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.03 | consumed tokens: 1110835200.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T11:59:04 | step: 135700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.908957296516746e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.03 | consumed tokens: 1111654400.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T11:59:23 | step: 135800 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 3.907429345417768e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.45 | consumed tokens: 1112473600.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T11:59:41 | step: 135900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.905900666723028e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.88 | consumed tokens: 1113292800.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T11:59:59 | step: 136000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 3.9043712604325265e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.73 | consumed tokens: 1114112000.0 | grad norm avg: 0.9 | grad norm last: 1.05 | 
2026-01-01T12:00:16 | step: 136100 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 3.902841126546264e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.39 | consumed tokens: 1114931200.0 | grad norm avg: 0.89 | grad norm last: 0.78 | 
2026-01-01T12:00:35 | step: 136200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.9013102650642395e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.75 | consumed tokens: 1115750400.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T12:00:53 | step: 136300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.899778675986454e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.67 | consumed tokens: 1116569600.0 | grad norm avg: 0.9 | grad norm last: 0.77 | 
2026-01-01T12:01:11 | step: 136400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.898245995515026e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.58 | consumed tokens: 1117388800.0 | grad norm avg: 0.9 | grad norm last: 0.78 | 
2026-01-01T12:01:29 | step: 136500 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.896712951245718e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.25 | consumed tokens: 1118208000.0 | grad norm avg: 0.92 | grad norm last: 0.82 | 
2026-01-01T12:01:47 | step: 136600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.895178815582767e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.98 | consumed tokens: 1119027200.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T12:02:05 | step: 136700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.893644316121936e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 4.03 | consumed tokens: 1119846400.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T12:02:23 | step: 136800 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.8921087252674624e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.58 | consumed tokens: 1120665600.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T12:02:41 | step: 136900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.8905724068172276e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.91 | consumed tokens: 1121484800.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T12:02:59 | step: 137000 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.8890353607712314e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.89 | consumed tokens: 1122304000.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T12:03:17 | step: 137100 | train samples/s: 95.3 | train mfu (16-bit): -1.0 | lr mean: 3.887497587129474e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.25 | consumed tokens: 1123123200.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T12:03:35 | step: 137200 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.8859590858919546e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.06 | consumed tokens: 1123942400.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T12:03:53 | step: 137300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.884419857058674e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.03 | consumed tokens: 1124761600.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T12:04:11 | step: 137400 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.8828795368317515e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.66 | consumed tokens: 1125580800.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T12:04:29 | step: 137500 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.881338852806948e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.83 | consumed tokens: 1126400000.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T12:04:47 | step: 137600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.8797974411863834e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.41 | consumed tokens: 1127219200.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T12:05:05 | step: 137700 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.8782549381721765e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.02 | consumed tokens: 1128038400.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T12:05:23 | step: 137800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.876711707562208e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.5 | consumed tokens: 1128857600.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T12:05:41 | step: 137900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.875168113154359e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.42 | consumed tokens: 1129676800.0 | grad norm avg: 0.89 | grad norm last: 1.02 | 
2026-01-01T12:05:59 | step: 138000 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.873623427352868e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 4.34 | consumed tokens: 1130496000.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T12:06:17 | step: 138100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.8720780139556155e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.69 | consumed tokens: 1131315200.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T12:06:36 | step: 138200 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.8705318729626015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.22 | consumed tokens: 1132134400.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T12:06:54 | step: 138300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.868985368171707e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.78 | consumed tokens: 1132953600.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T12:07:12 | step: 138400 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 3.86743777198717e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.66 | consumed tokens: 1133772800.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T12:07:30 | step: 138500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.865889084408991e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.95 | consumed tokens: 1134592000.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T12:07:48 | step: 138600 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.8643400330329314e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.36 | consumed tokens: 1135411200.0 | grad norm avg: 0.91 | grad norm last: 0.84 | 
2026-01-01T12:08:06 | step: 138700 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.86279025406111e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.31 | consumed tokens: 1136230400.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T12:08:24 | step: 138800 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.861239747493528e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.02 | consumed tokens: 1137049600.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T12:08:42 | step: 138900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.859688513330184e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.75 | consumed tokens: 1137868800.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T12:09:00 | step: 139000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.8581365515710786e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.48 | consumed tokens: 1138688000.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T12:09:18 | step: 139100 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 3.856583498418331e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.55 | consumed tokens: 1139507200.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T12:09:36 | step: 139200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.855030081467703e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.05 | consumed tokens: 1140326400.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T12:09:54 | step: 139300 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.8534759369213134e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.08 | consumed tokens: 1141145600.0 | grad norm avg: 0.89 | grad norm last: 0.99 | 
2026-01-01T12:10:12 | step: 139400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.851920700981282e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.95 | consumed tokens: 1141964800.0 | grad norm avg: 0.9 | grad norm last: 0.81 | 
2026-01-01T12:10:30 | step: 139500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.850365101243369e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.78 | consumed tokens: 1142784000.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T12:10:48 | step: 139600 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.848808410111815e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.05 | consumed tokens: 1143603200.0 | grad norm avg: 0.9 | grad norm last: 0.8 | 
2026-01-01T12:11:07 | step: 139700 | train samples/s: 95.1 | train mfu (16-bit): -1.0 | lr mean: 3.8472513551823795e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.95 | consumed tokens: 1144422400.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T12:11:25 | step: 139800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.845693208859302e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.86 | consumed tokens: 1145241600.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T12:11:43 | step: 139900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.844134698738344e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.59 | consumed tokens: 1146060800.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T12:12:01 | step: 140000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.842575097223744e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.91 | consumed tokens: 1146880000.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T12:12:20 | step: 140100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.841014768113382e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.06 | consumed tokens: 1147699200.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T12:12:38 | step: 140200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.83945407520514e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.69 | consumed tokens: 1148518400.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T12:12:56 | step: 140300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.8378922909032553e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.38 | consumed tokens: 1149337600.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T12:13:14 | step: 140400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.83633014280349e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.55 | consumed tokens: 1150156800.0 | grad norm avg: 0.91 | grad norm last: 1.03 | 
2026-01-01T12:13:32 | step: 140500 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.834766903310083e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.84 | consumed tokens: 1150976000.0 | grad norm avg: 0.91 | grad norm last: 0.98 | 
2026-01-01T12:13:50 | step: 140600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.833202936220914e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.23 | consumed tokens: 1151795200.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T12:14:08 | step: 140700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.831638605333865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.67 | consumed tokens: 1152614400.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T12:14:26 | step: 140800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.830073183053173e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.12 | consumed tokens: 1153433600.0 | grad norm avg: 0.89 | grad norm last: 1.01 | 
2026-01-01T12:14:44 | step: 140900 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.82850703317672e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.89 | consumed tokens: 1154252800.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T12:15:03 | step: 141000 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 3.8269405195023865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 4.03 | consumed tokens: 1155072000.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T12:15:21 | step: 141100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.8253729144344106e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.77 | consumed tokens: 1155891200.0 | grad norm avg: 0.9 | grad norm last: 0.81 | 
2026-01-01T12:15:39 | step: 141200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.8238045817706734e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.48 | consumed tokens: 1156710400.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T12:15:57 | step: 141300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.8222358853090554e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.33 | consumed tokens: 1157529600.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T12:16:15 | step: 141400 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.8206660974537954e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.66 | consumed tokens: 1158348800.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T12:16:33 | step: 141500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.819095582002774e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.81 | consumed tokens: 1159168000.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T12:16:51 | step: 141600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.817524702753872e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.86 | consumed tokens: 1159987200.0 | grad norm avg: 0.9 | grad norm last: 0.98 | 
2026-01-01T12:17:09 | step: 141700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.8159527321113274e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.16 | consumed tokens: 1160806400.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T12:17:27 | step: 141800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.814380397670902e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.81 | consumed tokens: 1161625600.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T12:17:45 | step: 141900 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.812806971836835e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.69 | consumed tokens: 1162444800.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T12:18:03 | step: 142000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.811233182204887e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.81 | consumed tokens: 1163264000.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T12:18:21 | step: 142100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.809658301179297e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.28 | consumed tokens: 1164083200.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T12:18:39 | step: 142200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.8080830563558266e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.05 | consumed tokens: 1164902400.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T12:18:57 | step: 142300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.8065070839365944e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.2 | consumed tokens: 1165721600.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T12:19:15 | step: 142400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.80493002012372e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.94 | consumed tokens: 1166540800.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T12:19:33 | step: 142500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.803352592512965e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.77 | consumed tokens: 1167360000.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T12:19:51 | step: 142600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.801774437306449e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.33 | consumed tokens: 1168179200.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T12:20:09 | step: 142700 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.80019519070629e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.58 | consumed tokens: 1168998400.0 | grad norm avg: 0.91 | grad norm last: 0.82 | 
2026-01-01T12:20:27 | step: 142800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.798615580308251e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.8 | consumed tokens: 1169817600.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T12:20:45 | step: 142900 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.7970352423144504e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.17 | consumed tokens: 1170636800.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T12:21:03 | step: 143000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.7954541767248884e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.95 | consumed tokens: 1171456000.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T12:21:21 | step: 143100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.793872383539565e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.84 | consumed tokens: 1172275200.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T12:21:39 | step: 143200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.79228986275848e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.78 | consumed tokens: 1173094400.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T12:21:57 | step: 143300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.790706614381634e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.02 | consumed tokens: 1173913600.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T12:22:15 | step: 143400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.789122638409026e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.59 | consumed tokens: 1174732800.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T12:22:33 | step: 143500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.787537934840657e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 4.03 | consumed tokens: 1175552000.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T12:22:52 | step: 143600 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 3.785952867474407e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.77 | consumed tokens: 1176371200.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T12:23:10 | step: 143700 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.784366708714515e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.27 | consumed tokens: 1177190400.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T12:23:28 | step: 143800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.7827798223588616e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.2 | consumed tokens: 1178009600.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T12:23:46 | step: 143900 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.7811925722053275e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.17 | consumed tokens: 1178828800.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T12:24:04 | step: 144000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.779604230658151e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 4.09 | consumed tokens: 1179648000.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T12:24:22 | step: 144100 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.778015525313094e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.33 | consumed tokens: 1180467200.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T12:24:40 | step: 144200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.776426092372276e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.48 | consumed tokens: 1181286400.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T12:24:58 | step: 144300 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.774835931835696e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.14 | consumed tokens: 1182105600.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T12:25:16 | step: 144400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.773244679905474e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.27 | consumed tokens: 1182924800.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T12:25:34 | step: 144500 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.7716530641773716e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.3 | consumed tokens: 1183744000.0 | grad norm avg: 0.91 | grad norm last: 0.8 | 
2026-01-01T12:25:52 | step: 144600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.7700607208535075e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.25 | consumed tokens: 1184563200.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T12:26:10 | step: 144700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.768468013731763e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.98 | consumed tokens: 1185382400.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T12:26:28 | step: 144800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.766874215216376e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 4.22 | consumed tokens: 1186201600.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T12:26:47 | step: 144900 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 3.7652796891052276e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.14 | consumed tokens: 1187020800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T12:27:05 | step: 145000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.7636847991961986e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.91 | consumed tokens: 1187840000.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T12:27:24 | step: 145100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.7620888178935274e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.22 | consumed tokens: 1188659200.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T12:27:42 | step: 145200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.7604924727929756e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.84 | consumed tokens: 1189478400.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T12:28:00 | step: 145300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.7588954000966623e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.89 | consumed tokens: 1190297600.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T12:28:18 | step: 145400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.757297236006707e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.67 | consumed tokens: 1191116800.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T12:28:36 | step: 145500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.755698708118871e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 4.59 | consumed tokens: 1191936000.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T12:28:54 | step: 145600 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.754099452635273e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.0 | consumed tokens: 1192755200.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T12:29:12 | step: 145700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.752499833353795e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.02 | consumed tokens: 1193574400.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T12:29:30 | step: 145800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.750899122678675e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.5 | consumed tokens: 1194393600.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T12:29:48 | step: 145900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.749297684407793e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.52 | consumed tokens: 1195212800.0 | grad norm avg: 0.9 | grad norm last: 0.8 | 
2026-01-01T12:30:07 | step: 146000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.7476958823390305e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.81 | consumed tokens: 1196032000.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T12:30:25 | step: 146100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.7460933526745066e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.73 | consumed tokens: 1196851200.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T12:30:43 | step: 146200 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 3.7444897316163406e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.53 | consumed tokens: 1197670400.0 | grad norm avg: 0.9 | grad norm last: 0.78 | 
2026-01-01T12:31:01 | step: 146300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.742885746760294e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.0 | consumed tokens: 1198489600.0 | grad norm avg: 0.91 | grad norm last: 0.96 | 
2026-01-01T12:31:19 | step: 146400 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.741281034308486e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.84 | consumed tokens: 1199308800.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T12:31:37 | step: 146500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.739675958058797e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.34 | consumed tokens: 1200128000.0 | grad norm avg: 0.91 | grad norm last: 0.85 | 
2026-01-01T12:31:55 | step: 146600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.738069790415466e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.83 | consumed tokens: 1200947200.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T12:32:13 | step: 146700 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.7364628951763734e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.64 | consumed tokens: 1201766400.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T12:32:31 | step: 146800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.7348556361394e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.2 | consumed tokens: 1202585600.0 | grad norm avg: 0.91 | grad norm last: 0.99 | 
2026-01-01T12:32:49 | step: 146900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.733247649506666e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.23 | consumed tokens: 1203404800.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T12:33:07 | step: 147000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 3.73163893527817e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.25 | consumed tokens: 1204224000.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T12:33:25 | step: 147100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.7300294934539124e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.8 | consumed tokens: 1205043200.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T12:33:43 | step: 147200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.7284193240338936e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.89 | consumed tokens: 1205862400.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T12:34:01 | step: 147300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.7268084270181134e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.22 | consumed tokens: 1206681600.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T12:34:19 | step: 147400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.7251971662044525e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.56 | consumed tokens: 1207500800.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T12:34:37 | step: 147500 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.72358517779503e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.95 | consumed tokens: 1208320000.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T12:34:56 | step: 147600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.721972097991966e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.28 | consumed tokens: 1209139200.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T12:35:14 | step: 147700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.7203586543910205e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.5 | consumed tokens: 1209958400.0 | grad norm avg: 0.91 | grad norm last: 1.07 | 
2026-01-01T12:35:32 | step: 147800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.7187448469921947e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.55 | consumed tokens: 1210777600.0 | grad norm avg: 0.9 | grad norm last: 1.01 | 
2026-01-01T12:35:50 | step: 147900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.7171299481997266e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.5 | consumed tokens: 1211596800.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T12:36:08 | step: 148000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.715514321811497e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.0 | consumed tokens: 1212416000.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T12:36:26 | step: 148100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.713898331625387e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.17 | consumed tokens: 1213235200.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T12:36:44 | step: 148200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.7122816138435155e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.02 | consumed tokens: 1214054400.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T12:37:02 | step: 148300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.7106641684658825e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.45 | consumed tokens: 1214873600.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T12:37:20 | step: 148400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.709045995492488e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.38 | consumed tokens: 1215692800.0 | grad norm avg: 0.89 | grad norm last: 0.8 | 
2026-01-01T12:37:38 | step: 148500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.707427458721213e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.22 | consumed tokens: 1216512000.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T12:37:56 | step: 148600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.705807830556296e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.69 | consumed tokens: 1217331200.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T12:38:14 | step: 148700 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 3.704187838593498e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.0 | consumed tokens: 1218150400.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T12:38:32 | step: 148800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.7025671190349385e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.81 | consumed tokens: 1218969600.0 | grad norm avg: 0.9 | grad norm last: 0.97 | 
2026-01-01T12:38:50 | step: 148900 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 3.700945671880618e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.41 | consumed tokens: 1219788800.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T12:39:08 | step: 149000 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.6993234971305355e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.81 | consumed tokens: 1220608000.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T12:39:26 | step: 149100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.6977009585825726e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.48 | consumed tokens: 1221427200.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T12:39:44 | step: 149200 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.696077692438848e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.27 | consumed tokens: 1222246400.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T12:40:02 | step: 149300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.6944536986993626e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.22 | consumed tokens: 1223065600.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T12:40:20 | step: 149400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.6928289773641154e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.8 | consumed tokens: 1223884800.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T12:40:38 | step: 149500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.691203528433107e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.61 | consumed tokens: 1224704000.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T12:40:56 | step: 149600 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.6895777157042176e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.84 | consumed tokens: 1225523200.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T12:41:14 | step: 149700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.687951175379567e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.25 | consumed tokens: 1226342400.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T12:41:32 | step: 149800 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.686323907459155e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.33 | consumed tokens: 1227161600.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T12:41:50 | step: 149900 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.684695911942981e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.02 | consumed tokens: 1227980800.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T12:42:08 | step: 150000 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.683067188831046e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.84 | consumed tokens: 1228800000.0 | grad norm avg: 0.9 | grad norm last: 1.03 | 
2026-01-01T12:42:28 | step: 150100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.6814381019212306e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.16 | consumed tokens: 1229619200.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T12:42:46 | step: 150200 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 3.6798082874156535e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.05 | consumed tokens: 1230438400.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T12:43:04 | step: 150300 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.678177745314315e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.17 | consumed tokens: 1231257600.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T12:43:22 | step: 150400 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.676546475617215e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.98 | consumed tokens: 1232076800.0 | grad norm avg: 0.9 | grad norm last: 1.01 | 
2026-01-01T12:43:40 | step: 150500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.6749148421222344e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.45 | consumed tokens: 1232896000.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T12:43:58 | step: 150600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.6732824810314924e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.78 | consumed tokens: 1233715200.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T12:44:16 | step: 150700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.671649392344989e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.47 | consumed tokens: 1234534400.0 | grad norm avg: 0.9 | grad norm last: 1.1 | 
2026-01-01T12:44:34 | step: 150800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.670015576062724e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.14 | consumed tokens: 1235353600.0 | grad norm avg: 0.9 | grad norm last: 0.98 | 
2026-01-01T12:44:52 | step: 150900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.6683813959825784e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.3 | consumed tokens: 1236172800.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T12:45:10 | step: 151000 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.666746124508791e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.53 | consumed tokens: 1236992000.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T12:45:29 | step: 151100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.665110853035003e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.69 | consumed tokens: 1237811200.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-01T12:45:47 | step: 151200 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.663474490167573e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.8 | consumed tokens: 1238630400.0 | grad norm avg: 0.91 | grad norm last: 0.84 | 
2026-01-01T12:46:05 | step: 151300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.661837399704382e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.14 | consumed tokens: 1239449600.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T12:46:23 | step: 151400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.66019994544331e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.45 | consumed tokens: 1240268800.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T12:46:41 | step: 151500 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 3.6585617635864764e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.22 | consumed tokens: 1241088000.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T12:46:59 | step: 151600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.6569228541338816e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.31 | consumed tokens: 1241907200.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T12:47:17 | step: 151700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.655283580883406e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.52 | consumed tokens: 1242726400.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T12:47:35 | step: 151800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.653643580037169e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.3 | consumed tokens: 1243545600.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T12:47:53 | step: 151900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.652002851595171e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.42 | consumed tokens: 1244364800.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T12:48:11 | step: 152000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.650361395557411e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.5 | consumed tokens: 1245184000.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T12:48:29 | step: 152100 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.6487195757217705e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.23 | consumed tokens: 1246003200.0 | grad norm avg: 0.89 | grad norm last: 0.79 | 
2026-01-01T12:48:48 | step: 152200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.6470770282903686e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.59 | consumed tokens: 1246822400.0 | grad norm avg: 0.89 | grad norm last: 0.98 | 
2026-01-01T12:49:06 | step: 152300 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.645433753263205e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.88 | consumed tokens: 1247641600.0 | grad norm avg: 0.9 | grad norm last: 1.1 | 
2026-01-01T12:49:24 | step: 152400 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.643790114438161e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.41 | consumed tokens: 1248460800.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T12:49:42 | step: 152500 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.642145384219475e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.2 | consumed tokens: 1249280000.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T12:50:00 | step: 152600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.640500290202908e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.34 | consumed tokens: 1250099200.0 | grad norm avg: 0.91 | grad norm last: 0.82 | 
2026-01-01T12:50:18 | step: 152700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.6388548323884606e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.73 | consumed tokens: 1250918400.0 | grad norm avg: 0.89 | grad norm last: 0.82 | 
2026-01-01T12:50:36 | step: 152800 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 3.637208283180371e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.27 | consumed tokens: 1251737600.0 | grad norm avg: 0.91 | grad norm last: 0.98 | 
2026-01-01T12:50:54 | step: 152900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.6355613701744005e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.38 | consumed tokens: 1252556800.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T12:51:13 | step: 153000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.633913729572669e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.55 | consumed tokens: 1253376000.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T12:51:31 | step: 153100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.632265725173056e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.81 | consumed tokens: 1254195200.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T12:51:49 | step: 153200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.630616993177682e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.64 | consumed tokens: 1255014400.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T12:52:07 | step: 153300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.628967533586547e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.12 | consumed tokens: 1255833600.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T12:52:25 | step: 153400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.62731734639965e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.98 | consumed tokens: 1256652800.0 | grad norm avg: 0.88 | grad norm last: 0.79 | 
2026-01-01T12:52:43 | step: 153500 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.6256667954148725e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.16 | consumed tokens: 1257472000.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T12:53:01 | step: 153600 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.6240155168343335e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.94 | consumed tokens: 1258291200.0 | grad norm avg: 0.89 | grad norm last: 0.8 | 
2026-01-01T12:53:19 | step: 153700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.622363510658033e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.81 | consumed tokens: 1259110400.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T12:53:37 | step: 153800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.620711140683852e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.8 | consumed tokens: 1259929600.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T12:53:55 | step: 153900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.61905804311391e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.28 | consumed tokens: 1260748800.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T12:54:13 | step: 154000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.617404217948206e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.45 | consumed tokens: 1261568000.0 | grad norm avg: 0.89 | grad norm last: 0.97 | 
2026-01-01T12:54:32 | step: 154100 | train samples/s: 95.0 | train mfu (16-bit): -1.0 | lr mean: 3.615750028984621e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.77 | consumed tokens: 1262387200.0 | grad norm avg: 0.9 | grad norm last: 0.76 | 
2026-01-01T12:54:50 | step: 154200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.6140947486273944e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.56 | consumed tokens: 1263206400.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T12:55:08 | step: 154300 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.612439468270168e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.8 | consumed tokens: 1264025600.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T12:55:26 | step: 154400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.610783096519299e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.73 | consumed tokens: 1264844800.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T12:55:44 | step: 154500 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.609126360970549e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.25 | consumed tokens: 1265664000.0 | grad norm avg: 0.9 | grad norm last: 0.75 | 
2026-01-01T12:56:02 | step: 154600 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.607468897826038e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 4.09 | consumed tokens: 1266483200.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T12:56:20 | step: 154700 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 3.6058110708836466e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.94 | consumed tokens: 1267302400.0 | grad norm avg: 0.9 | grad norm last: 0.98 | 
2026-01-01T12:56:39 | step: 154800 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.6041525163454935e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.09 | consumed tokens: 1268121600.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T12:56:57 | step: 154900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.602493234211579e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.52 | consumed tokens: 1268940800.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T12:57:15 | step: 155000 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.600833588279784e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.58 | consumed tokens: 1269760000.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T12:57:34 | step: 155100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.599173214752227e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.59 | consumed tokens: 1270579200.0 | grad norm avg: 0.92 | grad norm last: 0.83 | 
2026-01-01T12:57:52 | step: 155200 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.597512113628909e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.52 | consumed tokens: 1271398400.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T12:58:10 | step: 155300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.59585064870771e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.7 | consumed tokens: 1272217600.0 | grad norm avg: 0.9 | grad norm last: 0.81 | 
2026-01-01T12:58:29 | step: 155400 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 3.59418845619075e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.81 | consumed tokens: 1273036800.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T12:58:47 | step: 155500 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.5925255360780284e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.03 | consumed tokens: 1273856000.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T12:59:05 | step: 155600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.590862252167426e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.5 | consumed tokens: 1274675200.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T12:59:23 | step: 155700 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.589198240661062e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.06 | consumed tokens: 1275494400.0 | grad norm avg: 0.9 | grad norm last: 0.8 | 
2026-01-01T12:59:41 | step: 155800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.587533501558937e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.08 | consumed tokens: 1276313600.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T12:59:59 | step: 155900 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.585868398658931e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.44 | consumed tokens: 1277132800.0 | grad norm avg: 0.89 | grad norm last: 0.98 | 
2026-01-01T13:00:17 | step: 156000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.584202568163164e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.36 | consumed tokens: 1277952000.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T13:00:35 | step: 156100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.582536373869516e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.31 | consumed tokens: 1278771200.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T13:00:53 | step: 156200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.5808694519801065e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.0 | consumed tokens: 1279590400.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T13:01:11 | step: 156300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.579201802494936e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.23 | consumed tokens: 1280409600.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T13:01:29 | step: 156400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.577533789211884e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.59 | consumed tokens: 1281228800.0 | grad norm avg: 0.9 | grad norm last: 0.81 | 
2026-01-01T13:01:47 | step: 156500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.575865048333071e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.23 | consumed tokens: 1282048000.0 | grad norm avg: 0.89 | grad norm last: 1.0 | 
2026-01-01T13:02:05 | step: 156600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.574195579858497e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.27 | consumed tokens: 1282867200.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T13:02:24 | step: 156700 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 3.572525747586042e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.84 | consumed tokens: 1283686400.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T13:02:42 | step: 156800 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 3.570855187717825e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.66 | consumed tokens: 1284505600.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T13:03:00 | step: 156900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.569184264051728e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.48 | consumed tokens: 1285324800.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T13:03:18 | step: 157000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.567512612789869e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.61 | consumed tokens: 1286144000.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T13:03:36 | step: 157100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.565840233932249e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.02 | consumed tokens: 1286963200.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T13:03:54 | step: 157200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.5641674912767485e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.91 | consumed tokens: 1287782400.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T13:04:12 | step: 157300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.562494021025486e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.09 | consumed tokens: 1288601600.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T13:04:30 | step: 157400 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.5608201869763434e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.14 | consumed tokens: 1289420800.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T13:04:48 | step: 157500 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.559145625331439e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.66 | consumed tokens: 1290240000.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T13:05:07 | step: 157600 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.5574703360907733e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.88 | consumed tokens: 1291059200.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T13:05:25 | step: 157700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.555794683052227e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.98 | consumed tokens: 1291878400.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T13:05:43 | step: 157800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.554118302417919e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.53 | consumed tokens: 1292697600.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T13:06:01 | step: 157900 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.5524415579857305e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.86 | consumed tokens: 1293516800.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T13:06:19 | step: 158000 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 3.5507640859577805e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.41 | consumed tokens: 1294336000.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T13:06:37 | step: 158100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.549085886334069e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.3 | consumed tokens: 1295155200.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T13:06:55 | step: 158200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.547407322912477e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.19 | consumed tokens: 1295974400.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T13:07:13 | step: 158300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.545728395693004e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.02 | consumed tokens: 1296793600.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T13:07:31 | step: 158400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.544048377079889e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.16 | consumed tokens: 1297612800.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T13:07:49 | step: 158500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.542368358466774e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.72 | consumed tokens: 1298432000.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T13:08:07 | step: 158600 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.540687248460017e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.17 | consumed tokens: 1299251200.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T13:08:26 | step: 158700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.5390057746553794e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.41 | consumed tokens: 1300070400.0 | grad norm avg: 0.91 | grad norm last: 0.84 | 
2026-01-01T13:08:44 | step: 158800 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.537323937052861e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.86 | consumed tokens: 1300889600.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T13:09:02 | step: 158900 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.535641371854581e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.0 | consumed tokens: 1301708800.0 | grad norm avg: 0.9 | grad norm last: 1.06 | 
2026-01-01T13:09:20 | step: 159000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.5339580790605396e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.22 | consumed tokens: 1302528000.0 | grad norm avg: 0.9 | grad norm last: 0.99 | 
2026-01-01T13:09:38 | step: 159100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.5322744224686176e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.83 | consumed tokens: 1303347200.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T13:09:56 | step: 159200 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.530590038280934e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.52 | consumed tokens: 1304166400.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T13:10:14 | step: 159300 | train samples/s: 95.0 | train mfu (16-bit): -1.0 | lr mean: 3.52890529029537e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.95 | consumed tokens: 1304985600.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T13:10:32 | step: 159400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.527219814714044e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.16 | consumed tokens: 1305804800.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T13:10:50 | step: 159500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.525533975334838e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.22 | consumed tokens: 1306624000.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T13:11:08 | step: 159600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.52384740835987e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.53 | consumed tokens: 1307443200.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T13:11:27 | step: 159700 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.522160477587022e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.03 | consumed tokens: 1308262400.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T13:11:45 | step: 159800 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 3.520472819218412e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.14 | consumed tokens: 1309081600.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T13:12:03 | step: 159900 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 3.518784433254041e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.33 | consumed tokens: 1309900800.0 | grad norm avg: 0.91 | grad norm last: 0.77 | 
2026-01-01T13:12:21 | step: 160000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.517095683491789e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.95 | consumed tokens: 1310720000.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T13:12:41 | step: 160100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.515406569931656e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.41 | consumed tokens: 1311539200.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T13:12:59 | step: 160200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.513716728775762e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.77 | consumed tokens: 1312358400.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T13:13:17 | step: 160300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.5120261600241065e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.41 | consumed tokens: 1313177600.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T13:13:35 | step: 160400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.51033522747457e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.66 | consumed tokens: 1313996800.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T13:13:53 | step: 160500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.5086435673292726e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.38 | consumed tokens: 1314816000.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T13:14:11 | step: 160600 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 3.506951543386094e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 4.09 | consumed tokens: 1315635200.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T13:14:29 | step: 160700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.5052587918471545e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.31 | consumed tokens: 1316454400.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T13:14:47 | step: 160800 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.503565676510334e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.03 | consumed tokens: 1317273600.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T13:15:05 | step: 160900 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.501872197375633e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.61 | consumed tokens: 1318092800.0 | grad norm avg: 0.91 | grad norm last: 0.85 | 
2026-01-01T13:15:23 | step: 161000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.5001776268472895e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.19 | consumed tokens: 1318912000.0 | grad norm avg: 0.91 | grad norm last: 0.84 | 
2026-01-01T13:15:41 | step: 161100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.498483056318946e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.48 | consumed tokens: 1319731200.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T13:15:59 | step: 161200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.4967877581948414e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.64 | consumed tokens: 1320550400.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T13:16:17 | step: 161300 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.495091732474975e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.08 | consumed tokens: 1321369600.0 | grad norm avg: 0.91 | grad norm last: 0.83 | 
2026-01-01T13:16:35 | step: 161400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.4933953429572284e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.95 | consumed tokens: 1322188800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T13:16:54 | step: 161500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.49169822584372e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.48 | consumed tokens: 1323008000.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T13:17:12 | step: 161600 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.490000744932331e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.53 | consumed tokens: 1323827200.0 | grad norm avg: 0.9 | grad norm last: 1.0 | 
2026-01-01T13:17:30 | step: 161700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.488302536425181e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.62 | consumed tokens: 1324646400.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T13:17:48 | step: 161800 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 3.4866039641201496e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.23 | consumed tokens: 1325465600.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T13:18:06 | step: 161900 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.484905028017238e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.58 | consumed tokens: 1326284800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T13:18:24 | step: 162000 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.483205000520684e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.34 | consumed tokens: 1327104000.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T13:18:42 | step: 162100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.48150497302413e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.8 | consumed tokens: 1327923200.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T13:19:00 | step: 162200 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 3.4798042179318145e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.25 | consumed tokens: 1328742400.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T13:19:18 | step: 162300 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.478102735243738e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.89 | consumed tokens: 1329561600.0 | grad norm avg: 0.91 | grad norm last: 0.98 | 
2026-01-01T13:19:36 | step: 162400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.47640088875778e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.7 | consumed tokens: 1330380800.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T13:19:55 | step: 162500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.474698678473942e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.95 | consumed tokens: 1331200000.0 | grad norm avg: 0.91 | grad norm last: 0.83 | 
2026-01-01T13:20:13 | step: 162600 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.4729957405943424e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.44 | consumed tokens: 1332019200.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T13:20:31 | step: 162700 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.471292438916862e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.16 | consumed tokens: 1332838400.0 | grad norm avg: 0.92 | grad norm last: 0.77 | 
2026-01-01T13:20:49 | step: 162800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.46958840964362e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.06 | consumed tokens: 1333657600.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T13:21:07 | step: 162900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.467884016572498e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.7 | consumed tokens: 1334476800.0 | grad norm avg: 0.93 | grad norm last: 0.81 | 
2026-01-01T13:21:25 | step: 163000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.466178895905614e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.64 | consumed tokens: 1335296000.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T13:21:43 | step: 163100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.464473411440849e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.56 | consumed tokens: 1336115200.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T13:22:01 | step: 163200 | train samples/s: 95.3 | train mfu (16-bit): -1.0 | lr mean: 3.462767199380323e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.92 | consumed tokens: 1336934400.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T13:22:19 | step: 163300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.4610606235219166e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.8 | consumed tokens: 1337753600.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T13:22:38 | step: 163400 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.4593533200677484e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.59 | consumed tokens: 1338572800.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T13:22:56 | step: 163500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.4576456528156996e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.92 | consumed tokens: 1339392000.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T13:23:14 | step: 163600 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.45593762176577e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.17 | consumed tokens: 1340211200.0 | grad norm avg: 0.91 | grad norm last: 1.01 | 
2026-01-01T13:23:32 | step: 163700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.454228863120079e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.95 | consumed tokens: 1341030400.0 | grad norm avg: 0.91 | grad norm last: 0.96 | 
2026-01-01T13:23:50 | step: 163800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.4525197406765074e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.72 | consumed tokens: 1341849600.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T13:24:08 | step: 163900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.450809890637174e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.16 | consumed tokens: 1342668800.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T13:24:26 | step: 164000 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.4490996767999604e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.31 | consumed tokens: 1343488000.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T13:24:44 | step: 164100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.447389099164866e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.19 | consumed tokens: 1344307200.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T13:25:02 | step: 164200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.44567779393401e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.28 | consumed tokens: 1345126400.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T13:25:20 | step: 164300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.4439657611073926e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.38 | consumed tokens: 1345945600.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T13:25:38 | step: 164400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.4422533644828945e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.98 | consumed tokens: 1346764800.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T13:25:56 | step: 164500 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 3.440540604060516e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.92 | consumed tokens: 1347584000.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T13:26:14 | step: 164600 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.4388271160423756e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.41 | consumed tokens: 1348403200.0 | grad norm avg: 0.91 | grad norm last: 0.82 | 
2026-01-01T13:26:33 | step: 164700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.4371132642263547e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.56 | consumed tokens: 1349222400.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T13:26:51 | step: 164800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.435399048612453e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.19 | consumed tokens: 1350041600.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T13:27:09 | step: 164900 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.43368410540279e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.75 | consumed tokens: 1350860800.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T13:27:27 | step: 165000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.431968798395246e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 4.0 | consumed tokens: 1351680000.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T13:27:46 | step: 165100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.430252763791941e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.23 | consumed tokens: 1352499200.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T13:28:04 | step: 165200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.428536365390755e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.36 | consumed tokens: 1353318400.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T13:28:22 | step: 165300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.4268196031916887e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.33 | consumed tokens: 1354137600.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T13:28:40 | step: 165400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.4251021133968607e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.59 | consumed tokens: 1354956800.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T13:28:58 | step: 165500 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.423384259804152e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.22 | consumed tokens: 1355776000.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T13:29:16 | step: 165600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.421665678615682e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.06 | consumed tokens: 1356595200.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T13:29:34 | step: 165700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.419946733629331e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.53 | consumed tokens: 1357414400.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T13:29:53 | step: 165800 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 3.4182274248450994e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.33 | consumed tokens: 1358233600.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T13:30:11 | step: 165900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.4165073884651065e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.34 | consumed tokens: 1359052800.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T13:30:29 | step: 166000 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.414786988287233e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.47 | consumed tokens: 1359872000.0 | grad norm avg: 0.91 | grad norm last: 0.82 | 
2026-01-01T13:30:47 | step: 166100 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.413065860513598e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.66 | consumed tokens: 1360691200.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T13:31:05 | step: 166200 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.411344368942082e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.94 | consumed tokens: 1361510400.0 | grad norm avg: 0.91 | grad norm last: 0.81 | 
2026-01-01T13:31:23 | step: 166300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.4096225135726854e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.56 | consumed tokens: 1362329600.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T13:31:41 | step: 166400 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.4078999306075275e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.7 | consumed tokens: 1363148800.0 | grad norm avg: 0.9 | grad norm last: 0.8 | 
2026-01-01T13:31:59 | step: 166500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.406176983844489e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 4.5 | consumed tokens: 1363968000.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T13:32:17 | step: 166600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.4044536732835695e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.98 | consumed tokens: 1364787200.0 | grad norm avg: 0.91 | grad norm last: 0.84 | 
2026-01-01T13:32:35 | step: 166700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.402729635126889e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.41 | consumed tokens: 1365606400.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T13:32:53 | step: 166800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.401005233172327e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.05 | consumed tokens: 1366425600.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T13:33:11 | step: 166900 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.399280467419885e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.69 | consumed tokens: 1367244800.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T13:33:30 | step: 167000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.3975549740716815e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.06 | consumed tokens: 1368064000.0 | grad norm avg: 0.91 | grad norm last: 0.81 | 
2026-01-01T13:33:48 | step: 167100 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 3.395829116925597e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.42 | consumed tokens: 1368883200.0 | grad norm avg: 0.91 | grad norm last: 0.82 | 
2026-01-01T13:34:06 | step: 167200 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.3941025321837515e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.55 | consumed tokens: 1369702400.0 | grad norm avg: 0.91 | grad norm last: 0.78 | 
2026-01-01T13:34:24 | step: 167300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.392375947441906e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 4.25 | consumed tokens: 1370521600.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T13:34:42 | step: 167400 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.3906486351042986e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.84 | consumed tokens: 1371340800.0 | grad norm avg: 0.9 | grad norm last: 0.81 | 
2026-01-01T13:35:00 | step: 167500 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.38892059517093e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.7 | consumed tokens: 1372160000.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-01T13:35:18 | step: 167600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.387192191439681e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 4.03 | consumed tokens: 1372979200.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T13:35:36 | step: 167700 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.385463423910551e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.09 | consumed tokens: 1373798400.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-01T13:35:54 | step: 167800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.38373429258354e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.98 | consumed tokens: 1374617600.0 | grad norm avg: 0.9 | grad norm last: 1.0 | 
2026-01-01T13:36:12 | step: 167900 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.382004433660768e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.92 | consumed tokens: 1375436800.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T13:36:31 | step: 168000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.380274210940115e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.45 | consumed tokens: 1376256000.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T13:36:49 | step: 168100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.378543260623701e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.94 | consumed tokens: 1377075200.0 | grad norm avg: 0.91 | grad norm last: 0.81 | 
2026-01-01T13:37:07 | step: 168200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.376812310307287e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.75 | consumed tokens: 1377894400.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T13:37:25 | step: 168300 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.37508026859723e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.38 | consumed tokens: 1378713600.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T13:37:43 | step: 168400 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 3.373348226887174e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.64 | consumed tokens: 1379532800.0 | grad norm avg: 0.9 | grad norm last: 0.97 | 
2026-01-01T13:38:01 | step: 168500 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.371615457581356e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.64 | consumed tokens: 1380352000.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T13:38:20 | step: 168600 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.369882324477658e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.3 | consumed tokens: 1381171200.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T13:38:38 | step: 168700 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.3681488275760785e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.42 | consumed tokens: 1381990400.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T13:38:56 | step: 168800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.366414603078738e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.98 | consumed tokens: 1382809600.0 | grad norm avg: 0.91 | grad norm last: 0.96 | 
2026-01-01T13:39:14 | step: 168900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.3646800147835165e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.53 | consumed tokens: 1383628800.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T13:39:32 | step: 169000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.3629450626904145e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.36 | consumed tokens: 1384448000.0 | grad norm avg: 0.91 | grad norm last: 0.96 | 
2026-01-01T13:39:50 | step: 169100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.361209746799432e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.42 | consumed tokens: 1385267200.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T13:40:08 | step: 169200 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.3594737033126876e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.14 | consumed tokens: 1386086400.0 | grad norm avg: 0.9 | grad norm last: 1.01 | 
2026-01-01T13:40:26 | step: 169300 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.357737296028063e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.05 | consumed tokens: 1386905600.0 | grad norm avg: 0.91 | grad norm last: 1.06 | 
2026-01-01T13:40:44 | step: 169400 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.3560001611476764e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.78 | consumed tokens: 1387724800.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T13:41:02 | step: 169500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.35426302626729e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.89 | consumed tokens: 1388544000.0 | grad norm avg: 0.91 | grad norm last: 1.02 | 
2026-01-01T13:41:20 | step: 169600 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.3525251637911424e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.19 | consumed tokens: 1389363200.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T13:41:39 | step: 169700 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 3.350786937517114e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.48 | consumed tokens: 1390182400.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T13:41:57 | step: 169800 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.349047983647324e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.78 | consumed tokens: 1391001600.0 | grad norm avg: 0.9 | grad norm last: 1.07 | 
2026-01-01T13:42:15 | step: 169900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.3473086659796536e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.5 | consumed tokens: 1391820800.0 | grad norm avg: 0.9 | grad norm last: 0.97 | 
2026-01-01T13:42:33 | step: 170000 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.3455689845141023e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.34 | consumed tokens: 1392640000.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T13:42:52 | step: 170100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.3438289392506704e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.12 | consumed tokens: 1393459200.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T13:43:10 | step: 170200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.342088166391477e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.42 | consumed tokens: 1394278400.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T13:43:29 | step: 170300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.340347029734403e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.02 | consumed tokens: 1395097600.0 | grad norm avg: 0.9 | grad norm last: 1.02 | 
2026-01-01T13:43:47 | step: 170400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.338605529279448e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.66 | consumed tokens: 1395916800.0 | grad norm avg: 0.9 | grad norm last: 1.01 | 
2026-01-01T13:44:05 | step: 170500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.3368636650266126e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.11 | consumed tokens: 1396736000.0 | grad norm avg: 0.9 | grad norm last: 0.97 | 
2026-01-01T13:44:23 | step: 170600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.3351210731780156e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.31 | consumed tokens: 1397555200.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T13:44:41 | step: 170700 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.333378117531538e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.47 | consumed tokens: 1398374400.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T13:44:59 | step: 170800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.3316347980871797e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.08 | consumed tokens: 1399193600.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T13:45:17 | step: 170900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.3298911148449406e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.58 | consumed tokens: 1400012800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T13:45:35 | step: 171000 | train samples/s: 95.6 | train mfu (16-bit): -1.0 | lr mean: 3.32814670400694e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.92 | consumed tokens: 1400832000.0 | grad norm avg: 0.9 | grad norm last: 0.81 | 
2026-01-01T13:45:53 | step: 171100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.326401929371059e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.09 | consumed tokens: 1401651200.0 | grad norm avg: 0.91 | grad norm last: 1.14 | 
2026-01-01T13:46:11 | step: 171200 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.324656790937297e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.39 | consumed tokens: 1402470400.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T13:46:29 | step: 171300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.3229112887056544e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.33 | consumed tokens: 1403289600.0 | grad norm avg: 0.91 | grad norm last: 0.8 | 
2026-01-01T13:46:47 | step: 171400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.3211650588782504e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.05 | consumed tokens: 1404108800.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-01T13:47:05 | step: 171500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.319418465252966e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.61 | consumed tokens: 1404928000.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T13:47:24 | step: 171600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.3176715078298e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.84 | consumed tokens: 1405747200.0 | grad norm avg: 0.9 | grad norm last: 1.0 | 
2026-01-01T13:47:42 | step: 171700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.315924186608754e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.66 | consumed tokens: 1406566400.0 | grad norm avg: 0.91 | grad norm last: 0.99 | 
2026-01-01T13:48:00 | step: 171800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.314176501589827e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.5 | consumed tokens: 1407385600.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T13:48:17 | step: 171900 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 3.312428088975139e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.61 | consumed tokens: 1408204800.0 | grad norm avg: 0.91 | grad norm last: 0.85 | 
2026-01-01T13:48:35 | step: 172000 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 3.31067931256257e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.0 | consumed tokens: 1409024000.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T13:48:53 | step: 172100 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 3.30893017235212e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.97 | consumed tokens: 1409843200.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T13:49:11 | step: 172200 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.307180304545909e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.81 | consumed tokens: 1410662400.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T13:49:30 | step: 172300 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 3.305430436739698e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.22 | consumed tokens: 1411481600.0 | grad norm avg: 0.91 | grad norm last: 0.85 | 
2026-01-01T13:49:48 | step: 172400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.3036798413377255e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.28 | consumed tokens: 1412300800.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-01T13:50:06 | step: 172500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.301928882137872e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.44 | consumed tokens: 1413120000.0 | grad norm avg: 0.91 | grad norm last: 0.99 | 
2026-01-01T13:50:24 | step: 172600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.300177559140138e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.77 | consumed tokens: 1413939200.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T13:50:42 | step: 172700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.298425508546643e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.69 | consumed tokens: 1414758400.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-01T13:51:00 | step: 172800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.2966734579531476e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.31 | consumed tokens: 1415577600.0 | grad norm avg: 0.9 | grad norm last: 0.81 | 
2026-01-01T13:51:18 | step: 172900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.294920679763891e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 4.09 | consumed tokens: 1416396800.0 | grad norm avg: 0.91 | grad norm last: 0.83 | 
2026-01-01T13:51:36 | step: 173000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.293167537776753e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.19 | consumed tokens: 1417216000.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T13:51:54 | step: 173100 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.291414031991735e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.94 | consumed tokens: 1418035200.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T13:52:12 | step: 173200 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.2896597986109555e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.38 | consumed tokens: 1418854400.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T13:52:30 | step: 173300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.287905565230176e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.05 | consumed tokens: 1419673600.0 | grad norm avg: 0.9 | grad norm last: 0.98 | 
2026-01-01T13:52:48 | step: 173400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.286150604253635e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.8 | consumed tokens: 1420492800.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T13:53:06 | step: 173500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.284395279479213e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.11 | consumed tokens: 1421312000.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T13:53:24 | step: 173600 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 3.2826395909069106e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.42 | consumed tokens: 1422131200.0 | grad norm avg: 0.9 | grad norm last: 0.81 | 
2026-01-01T13:53:42 | step: 173700 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 3.2808835385367274e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.55 | consumed tokens: 1422950400.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T13:54:00 | step: 173800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.279126758570783e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.22 | consumed tokens: 1423769600.0 | grad norm avg: 0.91 | grad norm last: 0.85 | 
2026-01-01T13:54:18 | step: 173900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.277369978604838e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.33 | consumed tokens: 1424588800.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T13:54:36 | step: 174000 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.275612471043132e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.8 | consumed tokens: 1425408000.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T13:54:54 | step: 174100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.2738545996835455e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.53 | consumed tokens: 1426227200.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T13:55:12 | step: 174200 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.272096364526078e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.97 | consumed tokens: 1427046400.0 | grad norm avg: 0.91 | grad norm last: 0.96 | 
2026-01-01T13:55:30 | step: 174300 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.27033776557073e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.92 | consumed tokens: 1427865600.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T13:55:48 | step: 174400 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.2685784390196204e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.19 | consumed tokens: 1428684800.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T13:56:06 | step: 174500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.26681874867063e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.98 | consumed tokens: 1429504000.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T13:56:24 | step: 174600 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.26505905832164e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.89 | consumed tokens: 1430323200.0 | grad norm avg: 0.92 | grad norm last: 0.96 | 
2026-01-01T13:56:42 | step: 174700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.263298640376888e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 4.03 | consumed tokens: 1431142400.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T13:57:00 | step: 174800 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 3.261537858634256e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.47 | consumed tokens: 1431961600.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T13:57:19 | step: 174900 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 3.259776713093743e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.95 | consumed tokens: 1432780800.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T13:57:37 | step: 175000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.258014839957468e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.58 | consumed tokens: 1433600000.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-01T13:57:56 | step: 175100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.256252966821194e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.06 | consumed tokens: 1434419200.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T13:58:14 | step: 175200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.254490366089158e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.39 | consumed tokens: 1435238400.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-01T13:58:32 | step: 175300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.252727765357122e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.14 | consumed tokens: 1436057600.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T13:58:50 | step: 175400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.2509644370293245e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.39 | consumed tokens: 1436876800.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T13:59:09 | step: 175500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.2492007449036464e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.41 | consumed tokens: 1437696000.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T13:59:27 | step: 175600 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.2474366889800876e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.64 | consumed tokens: 1438515200.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T13:59:45 | step: 175700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.245672269258648e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.95 | consumed tokens: 1439334400.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T14:00:03 | step: 175800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.243907121941447e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.09 | consumed tokens: 1440153600.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T14:00:21 | step: 175900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.2421419746242464e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.38 | consumed tokens: 1440972800.0 | grad norm avg: 0.91 | grad norm last: 0.85 | 
2026-01-01T14:00:39 | step: 176000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.240376099711284e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.25 | consumed tokens: 1441792000.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T14:00:57 | step: 176100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.238610224798322e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.22 | consumed tokens: 1442611200.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T14:01:15 | step: 176200 | train samples/s: 95.4 | train mfu (16-bit): -1.0 | lr mean: 3.236843622289598e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.44 | consumed tokens: 1443430400.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T14:01:33 | step: 176300 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.2350766559829935e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.0 | consumed tokens: 1444249600.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T14:01:52 | step: 176400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.2333093258785084e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.83 | consumed tokens: 1445068800.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-01T14:02:10 | step: 176500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.2315416319761425e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.34 | consumed tokens: 1445888000.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T14:02:28 | step: 176600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.229773574275896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.19 | consumed tokens: 1446707200.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T14:02:46 | step: 176700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.228004788979888e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.11 | consumed tokens: 1447526400.0 | grad norm avg: 0.91 | grad norm last: 0.82 | 
2026-01-01T14:03:04 | step: 176800 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.22623600368388e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.7 | consumed tokens: 1448345600.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T14:03:22 | step: 176900 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 3.2244664907921106e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.31 | consumed tokens: 1449164800.0 | grad norm avg: 0.91 | grad norm last: 0.85 | 
2026-01-01T14:03:40 | step: 177000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.222696977900341e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.17 | consumed tokens: 1449984000.0 | grad norm avg: 0.91 | grad norm last: 0.84 | 
2026-01-01T14:03:58 | step: 177100 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.22092673741281e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 4.09 | consumed tokens: 1450803200.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-01T14:04:16 | step: 177200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 3.2191564969252795e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.55 | consumed tokens: 1451622400.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T14:04:34 | step: 177300 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 3.217385528841987e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.06 | consumed tokens: 1452441600.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T14:04:52 | step: 177400 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.215614196960814e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.77 | consumed tokens: 1453260800.0 | grad norm avg: 0.9 | grad norm last: 1.33 | 
2026-01-01T14:05:11 | step: 177500 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 3.2138425012817606e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.73 | consumed tokens: 1454080000.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T14:05:29 | step: 177600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.212070441804826e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.92 | consumed tokens: 1454899200.0 | grad norm avg: 0.91 | grad norm last: 0.78 | 
2026-01-01T14:05:47 | step: 177700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.210298018530011e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.92 | consumed tokens: 1455718400.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T14:06:05 | step: 177800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.2085252314573154e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.39 | consumed tokens: 1456537600.0 | grad norm avg: 0.91 | grad norm last: 1.02 | 
2026-01-01T14:06:23 | step: 177900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.206751716788858e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.12 | consumed tokens: 1457356800.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T14:06:41 | step: 178000 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 3.204978202120401e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.67 | consumed tokens: 1458176000.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T14:06:59 | step: 178100 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.203204323654063e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.95 | consumed tokens: 1458995200.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T14:07:17 | step: 178200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.201429717591964e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.12 | consumed tokens: 1459814400.0 | grad norm avg: 0.91 | grad norm last: 0.81 | 
2026-01-01T14:07:35 | step: 178300 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.1996551115298644e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.62 | consumed tokens: 1460633600.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T14:07:53 | step: 178400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.1978797778720036e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.09 | consumed tokens: 1461452800.0 | grad norm avg: 0.91 | grad norm last: 0.99 | 
2026-01-01T14:08:11 | step: 178500 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.196104444214143e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.3 | consumed tokens: 1462272000.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T14:08:29 | step: 178600 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.194328382960521e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.23 | consumed tokens: 1463091200.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T14:08:47 | step: 178700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.1925523217068985e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.92 | consumed tokens: 1463910400.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T14:09:06 | step: 178800 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 3.190775532857515e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.0 | consumed tokens: 1464729600.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T14:09:24 | step: 178900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.1889983802102506e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.55 | consumed tokens: 1465548800.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-01T14:09:42 | step: 179000 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.187221227562986e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.14 | consumed tokens: 1466368000.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-01T14:10:00 | step: 179100 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.1854433473199606e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.06 | consumed tokens: 1467187200.0 | grad norm avg: 0.9 | grad norm last: 0.97 | 
2026-01-01T14:10:18 | step: 179200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.183665103279054e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.89 | consumed tokens: 1468006400.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T14:10:36 | step: 179300 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 3.181886495440267e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.97 | consumed tokens: 1468825600.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T14:10:54 | step: 179400 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.180107523803599e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.8 | consumed tokens: 1469644800.0 | grad norm avg: 0.92 | grad norm last: 1.0 | 
2026-01-01T14:11:12 | step: 179500 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.178328552166931e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.52 | consumed tokens: 1470464000.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T14:11:30 | step: 179600 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 3.176548852934502e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.22 | consumed tokens: 1471283200.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T14:11:48 | step: 179700 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.174768789904192e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.88 | consumed tokens: 1472102400.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T14:12:06 | step: 179800 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.1729883630760014e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.12 | consumed tokens: 1472921600.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T14:12:24 | step: 179900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.17120757244993e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.97 | consumed tokens: 1473740800.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T14:12:42 | step: 180000 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 3.169426418025978e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.62 | consumed tokens: 1474560000.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T14:13:02 | step: 180100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 3.167644899804145e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.98 | consumed tokens: 1475379200.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T14:13:20 | step: 180200 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 3.1658630177844316e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.03 | consumed tokens: 1476198400.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T14:13:38 | step: 180300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 3.1640807719668373e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.03 | consumed tokens: 1477017600.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-01T14:13:55 | step: 180400 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 3.1622981623513624e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.44 | consumed tokens: 1477836800.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T14:14:13 | step: 180500 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 3.160515188938007e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.09 | consumed tokens: 1478656000.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T14:14:31 | step: 180600 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 3.1587318517267704e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.17 | consumed tokens: 1479475200.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T14:14:49 | step: 180700 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 3.156948514515534e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.17 | consumed tokens: 1480294400.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T14:15:07 | step: 180800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.155164449708536e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.58 | consumed tokens: 1481113600.0 | grad norm avg: 0.9 | grad norm last: 0.77 | 
2026-01-01T14:15:25 | step: 180900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.153380021103658e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.12 | consumed tokens: 1481932800.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T14:15:43 | step: 181000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 3.1515952287008986e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.06 | consumed tokens: 1482752000.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T14:16:01 | step: 181100 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 3.149810072500259e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.64 | consumed tokens: 1483571200.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T14:16:19 | step: 181200 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 3.148024552501738e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.56 | consumed tokens: 1484390400.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T14:16:37 | step: 181300 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 3.1462390325032175e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 4.31 | consumed tokens: 1485209600.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T14:16:55 | step: 181400 | train samples/s: 95.8 | train mfu (16-bit): -1.0 | lr mean: 3.1444527849089354e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.05 | consumed tokens: 1486028800.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T14:17:13 | step: 181500 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.142666173516773e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.73 | consumed tokens: 1486848000.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T14:17:31 | step: 181600 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 3.140879198326729e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.03 | consumed tokens: 1487667200.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T14:17:49 | step: 181700 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 3.139092223136686e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.59 | consumed tokens: 1488486400.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-01T14:18:07 | step: 181800 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 3.137304520350881e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.39 | consumed tokens: 1489305600.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T14:18:24 | step: 181900 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.135516817565076e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.98 | consumed tokens: 1490124800.0 | grad norm avg: 0.9 | grad norm last: 0.98 | 
2026-01-01T14:18:42 | step: 182000 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.13372838718351e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.06 | consumed tokens: 1490944000.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T14:19:00 | step: 182100 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 3.1319399568019435e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.58 | consumed tokens: 1491763200.0 | grad norm avg: 0.92 | grad norm last: 0.86 | 
2026-01-01T14:19:18 | step: 182200 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 3.130150798824616e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.22 | consumed tokens: 1492582400.0 | grad norm avg: 0.91 | grad norm last: 1.02 | 
2026-01-01T14:19:36 | step: 182300 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 3.128361640847288e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 4.25 | consumed tokens: 1493401600.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T14:19:54 | step: 182400 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 3.1265721190720797e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.14 | consumed tokens: 1494220800.0 | grad norm avg: 0.91 | grad norm last: 0.96 | 
2026-01-01T14:20:12 | step: 182500 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 3.12478186970111e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.05 | consumed tokens: 1495040000.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T14:20:30 | step: 182600 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 3.12299162033014e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.45 | consumed tokens: 1495859200.0 | grad norm avg: 0.93 | grad norm last: 0.84 | 
2026-01-01T14:20:48 | step: 182700 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 3.1212010071612895e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.66 | consumed tokens: 1496678400.0 | grad norm avg: 0.92 | grad norm last: 1.01 | 
2026-01-01T14:21:06 | step: 182800 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 3.119410030194558e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.45 | consumed tokens: 1497497600.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T14:21:24 | step: 182900 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 3.117618689429946e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.94 | consumed tokens: 1498316800.0 | grad norm avg: 0.92 | grad norm last: 0.85 | 
2026-01-01T14:21:41 | step: 183000 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 3.1158269848674536e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.48 | consumed tokens: 1499136000.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T14:21:59 | step: 183100 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.114035280304961e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.94 | consumed tokens: 1499955200.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T14:22:17 | step: 183200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.112242848146707e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.92 | consumed tokens: 1500774400.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T14:22:35 | step: 183300 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 3.110450052190572e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.48 | consumed tokens: 1501593600.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T14:22:53 | step: 183400 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 3.108657256234437e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.41 | consumed tokens: 1502412800.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T14:23:11 | step: 183500 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 3.106863732682541e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.72 | consumed tokens: 1503232000.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T14:23:29 | step: 183600 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 3.105070209130645e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.0 | consumed tokens: 1504051200.0 | grad norm avg: 0.91 | grad norm last: 0.85 | 
2026-01-01T14:23:47 | step: 183700 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 3.103275957982987e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.88 | consumed tokens: 1504870400.0 | grad norm avg: 0.91 | grad norm last: 0.84 | 
2026-01-01T14:24:05 | step: 183800 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 3.1014817068353295e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.89 | consumed tokens: 1505689600.0 | grad norm avg: 0.91 | grad norm last: 1.01 | 
2026-01-01T14:24:23 | step: 183900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.099687091889791e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.0 | consumed tokens: 1506508800.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T14:24:41 | step: 184000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.097892113146372e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.44 | consumed tokens: 1507328000.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T14:24:59 | step: 184100 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 3.0960967706050724e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.78 | consumed tokens: 1508147200.0 | grad norm avg: 0.9 | grad norm last: 0.78 | 
2026-01-01T14:25:17 | step: 184200 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 3.0943014280637726e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.53 | consumed tokens: 1508966400.0 | grad norm avg: 0.91 | grad norm last: 0.98 | 
2026-01-01T14:25:34 | step: 184300 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.0925053579267114e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.25 | consumed tokens: 1509785600.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T14:25:53 | step: 184400 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.0907089239917696e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.61 | consumed tokens: 1510604800.0 | grad norm avg: 0.93 | grad norm last: 1.01 | 
2026-01-01T14:26:11 | step: 184500 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.088912490056828e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.38 | consumed tokens: 1511424000.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T14:26:28 | step: 184600 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 3.087115692324005e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.47 | consumed tokens: 1512243200.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T14:26:46 | step: 184700 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 3.085318166995421e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.84 | consumed tokens: 1513062400.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T14:27:04 | step: 184800 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 3.083520641666837e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.88 | consumed tokens: 1513881600.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T14:27:22 | step: 184900 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 3.081722752540372e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.19 | consumed tokens: 1514700800.0 | grad norm avg: 0.91 | grad norm last: 0.83 | 
2026-01-01T14:27:40 | step: 185000 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.079924499616027e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.92 | consumed tokens: 1515520000.0 | grad norm avg: 0.91 | grad norm last: 0.99 | 
2026-01-01T14:27:59 | step: 185100 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 3.0781262466916814e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.12 | consumed tokens: 1516339200.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T14:28:17 | step: 185200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.0763272661715746e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.69 | consumed tokens: 1517158400.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T14:28:35 | step: 185300 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 3.074528285651468e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.86 | consumed tokens: 1517977600.0 | grad norm avg: 0.92 | grad norm last: 1.01 | 
2026-01-01T14:28:53 | step: 185400 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 3.0727285775355995e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.03 | consumed tokens: 1518796800.0 | grad norm avg: 0.91 | grad norm last: 0.81 | 
2026-01-01T14:29:11 | step: 185500 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.070928869419731e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.38 | consumed tokens: 1519616000.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T14:29:30 | step: 185600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 3.069128797505982e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.77 | consumed tokens: 1520435200.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-01T14:29:47 | step: 185700 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 3.0673283617943525e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.05 | consumed tokens: 1521254400.0 | grad norm avg: 0.92 | grad norm last: 0.85 | 
2026-01-01T14:30:05 | step: 185800 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 3.065527926082723e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.25 | consumed tokens: 1522073600.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T14:30:23 | step: 185900 | train samples/s: 98.8 | train mfu (16-bit): -1.0 | lr mean: 3.063726762775332e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.08 | consumed tokens: 1522892800.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-01T14:30:41 | step: 186000 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 3.0619255994679406e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.33 | consumed tokens: 1523712000.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T14:30:59 | step: 186100 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 3.060123708564788e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.7 | consumed tokens: 1524531200.0 | grad norm avg: 0.91 | grad norm last: 0.96 | 
2026-01-01T14:31:17 | step: 186200 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.0583218176616356e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.97 | consumed tokens: 1525350400.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T14:31:35 | step: 186300 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.0565195629606023e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 4.09 | consumed tokens: 1526169600.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T14:31:53 | step: 186400 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 3.054717308259569e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.98 | consumed tokens: 1526988800.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T14:32:11 | step: 186500 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 3.0529143259627745e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.56 | consumed tokens: 1527808000.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-01T14:32:29 | step: 186600 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 3.0511111617670394e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.19 | consumed tokens: 1528627200.0 | grad norm avg: 0.92 | grad norm last: 0.98 | 
2026-01-01T14:32:47 | step: 186700 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.049307815672364e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.48 | consumed tokens: 1529446400.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T14:33:05 | step: 186800 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 3.047504105779808e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.83 | consumed tokens: 1530265600.0 | grad norm avg: 0.92 | grad norm last: 0.84 | 
2026-01-01T14:33:23 | step: 186900 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.0457000320893712e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.92 | consumed tokens: 1531084800.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T14:33:41 | step: 187000 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 3.0438955946010537e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.22 | consumed tokens: 1531904000.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T14:33:58 | step: 187100 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 3.042090975213796e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.56 | consumed tokens: 1532723200.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T14:34:16 | step: 187200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.0402861739275977e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.81 | consumed tokens: 1533542400.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T14:34:34 | step: 187300 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 3.0384808269445784e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.97 | consumed tokens: 1534361600.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-01T14:34:52 | step: 187400 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.0366752980626188e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.67 | consumed tokens: 1535180800.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-01T14:35:10 | step: 187500 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 3.034869587281719e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.88 | consumed tokens: 1536000000.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-01T14:35:28 | step: 187600 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 3.033063512702938e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.0 | consumed tokens: 1536819200.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-01T14:35:46 | step: 187700 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 3.0312570743262768e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.14 | consumed tokens: 1537638400.0 | grad norm avg: 0.91 | grad norm last: 0.84 | 
2026-01-01T14:36:04 | step: 187800 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.029450454050675e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.42 | consumed tokens: 1538457600.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T14:36:22 | step: 187900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 3.0276434699771926e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 4.06 | consumed tokens: 1539276800.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T14:36:40 | step: 188000 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.0258361221058294e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.75 | consumed tokens: 1540096000.0 | grad norm avg: 0.91 | grad norm last: 0.99 | 
2026-01-01T14:36:58 | step: 188100 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 3.024028592335526e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.42 | consumed tokens: 1540915200.0 | grad norm avg: 0.92 | grad norm last: 0.79 | 
2026-01-01T14:37:16 | step: 188200 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 3.022220880666282e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.23 | consumed tokens: 1541734400.0 | grad norm avg: 0.92 | grad norm last: 0.96 | 
2026-01-01T14:37:34 | step: 188300 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 3.020412623300217e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.06 | consumed tokens: 1542553600.0 | grad norm avg: 0.91 | grad norm last: 0.84 | 
2026-01-01T14:37:52 | step: 188400 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 3.018604365934152e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.05 | consumed tokens: 1543372800.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-01T14:38:09 | step: 188500 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.016795562871266e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.8 | consumed tokens: 1544192000.0 | grad norm avg: 0.91 | grad norm last: 0.96 | 
2026-01-01T14:38:27 | step: 188600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.01498675980838e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.66 | consumed tokens: 1545011200.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-01T14:38:45 | step: 188700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.013177411048673e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.03 | consumed tokens: 1545830400.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-01T14:39:03 | step: 188800 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 3.0113678803900257e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.58 | consumed tokens: 1546649600.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-01T14:39:21 | step: 188900 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 3.009558167832438e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.45 | consumed tokens: 1547468800.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T14:39:39 | step: 189000 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 3.0077480914769694e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.86 | consumed tokens: 1548288000.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T14:39:57 | step: 189100 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 3.0059376513236202e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.27 | consumed tokens: 1549107200.0 | grad norm avg: 0.93 | grad norm last: 1.0 | 
2026-01-01T14:40:15 | step: 189200 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 3.0041270292713307e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.5 | consumed tokens: 1549926400.0 | grad norm avg: 0.92 | grad norm last: 0.86 | 
2026-01-01T14:40:33 | step: 189300 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 3.0023162253201008e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.59 | consumed tokens: 1550745600.0 | grad norm avg: 0.93 | grad norm last: 0.83 | 
2026-01-01T14:40:51 | step: 189400 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.0005050575709902e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.62 | consumed tokens: 1551564800.0 | grad norm avg: 0.92 | grad norm last: 0.83 | 
2026-01-01T14:41:09 | step: 189500 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 2.998693526023999e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.27 | consumed tokens: 1552384000.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T14:41:27 | step: 189600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.9968818125780672e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 4.12 | consumed tokens: 1553203200.0 | grad norm avg: 0.92 | grad norm last: 0.81 | 
2026-01-01T14:41:45 | step: 189700 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.9950697353342548e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.0 | consumed tokens: 1554022400.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T14:42:03 | step: 189800 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.993257476191502e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.91 | consumed tokens: 1554841600.0 | grad norm avg: 0.91 | grad norm last: 0.84 | 
2026-01-01T14:42:21 | step: 189900 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.991445035149809e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.75 | consumed tokens: 1555660800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T14:42:39 | step: 190000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.9896322303102352e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.34 | consumed tokens: 1556480000.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T14:42:58 | step: 190100 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 2.987819243571721e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.31 | consumed tokens: 1557299200.0 | grad norm avg: 0.92 | grad norm last: 0.98 | 
2026-01-01T14:43:16 | step: 190200 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 2.986005893035326e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 4.09 | consumed tokens: 1558118400.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-01T14:43:34 | step: 190300 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.9841921787010506e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.02 | consumed tokens: 1558937600.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T14:43:52 | step: 190400 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.982378464366775e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.77 | consumed tokens: 1559756800.0 | grad norm avg: 0.91 | grad norm last: 1.0 | 
2026-01-01T14:44:10 | step: 190500 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.9805642043356784e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.14 | consumed tokens: 1560576000.0 | grad norm avg: 0.92 | grad norm last: 0.86 | 
2026-01-01T14:44:28 | step: 190600 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.9787499443045817e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.5 | consumed tokens: 1561395200.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T14:44:46 | step: 190700 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 2.976935138576664e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 1.9 | consumed tokens: 1562214400.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T14:45:04 | step: 190800 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.9751203328487463e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.39 | consumed tokens: 1563033600.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T14:45:22 | step: 190900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.973305163322948e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.78 | consumed tokens: 1563852800.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T14:45:40 | step: 191000 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.971489811898209e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.06 | consumed tokens: 1564672000.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-01T14:45:58 | step: 191100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.9696740966755897e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.72 | consumed tokens: 1565491200.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-01T14:46:16 | step: 191200 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.96785819955403e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 4.03 | consumed tokens: 1566310400.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T14:46:34 | step: 191300 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 2.9660419386345893e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.23 | consumed tokens: 1567129600.0 | grad norm avg: 0.92 | grad norm last: 0.96 | 
2026-01-01T14:46:51 | step: 191400 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.9642254958162084e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.33 | consumed tokens: 1567948800.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T14:47:09 | step: 191500 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.9624088710988872e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.95 | consumed tokens: 1568768000.0 | grad norm avg: 0.92 | grad norm last: 0.99 | 
2026-01-01T14:47:27 | step: 191600 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.9605918825836852e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.97 | consumed tokens: 1569587200.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T14:47:45 | step: 191700 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.958774712169543e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.03 | consumed tokens: 1570406400.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-01T14:48:03 | step: 191800 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.95695717795752e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.23 | consumed tokens: 1571225600.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-01T14:48:21 | step: 191900 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.9551394618465565e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.09 | consumed tokens: 1572044800.0 | grad norm avg: 0.91 | grad norm last: 0.98 | 
2026-01-01T14:48:39 | step: 192000 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.9533215638366528e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.08 | consumed tokens: 1572864000.0 | grad norm avg: 0.92 | grad norm last: 0.94 | 
2026-01-01T14:48:57 | step: 192100 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.9515033020288683e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.81 | consumed tokens: 1573683200.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T14:49:15 | step: 192200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.9496848583221436e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.86 | consumed tokens: 1574502400.0 | grad norm avg: 0.92 | grad norm last: 0.94 | 
2026-01-01T14:49:33 | step: 192300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.9478662327164784e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 4.19 | consumed tokens: 1575321600.0 | grad norm avg: 0.92 | grad norm last: 0.78 | 
2026-01-01T14:49:51 | step: 192400 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.9460472433129326e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.17 | consumed tokens: 1576140800.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T14:50:09 | step: 192500 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 2.9442280720104463e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 4.19 | consumed tokens: 1576960000.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-01T14:50:27 | step: 192600 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.9424087188090198e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.06 | consumed tokens: 1577779200.0 | grad norm avg: 0.93 | grad norm last: 0.87 | 
2026-01-01T14:50:45 | step: 192700 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.9405890018097125e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.91 | consumed tokens: 1578598400.0 | grad norm avg: 0.91 | grad norm last: 0.82 | 
2026-01-01T14:51:03 | step: 192800 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.938769102911465e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.27 | consumed tokens: 1579417600.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T14:51:21 | step: 192900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.936949022114277e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 4.03 | consumed tokens: 1580236800.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T14:51:39 | step: 193000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.9351285775192082e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.05 | consumed tokens: 1581056000.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T14:51:56 | step: 193100 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.9333081329241395e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.19 | consumed tokens: 1581875200.0 | grad norm avg: 0.9 | grad norm last: 0.98 | 
2026-01-01T14:52:15 | step: 193200 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.9314871426322497e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.09 | consumed tokens: 1582694400.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T14:52:33 | step: 193300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.92966615234036e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.8 | consumed tokens: 1583513600.0 | grad norm avg: 0.91 | grad norm last: 1.0 | 
2026-01-01T14:52:51 | step: 193400 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.9278447982505895e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.05 | consumed tokens: 1584332800.0 | grad norm avg: 0.92 | grad norm last: 0.86 | 
2026-01-01T14:53:09 | step: 193500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.9260232622618787e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.19 | consumed tokens: 1585152000.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-01T14:53:27 | step: 193600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.9242015443742275e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.8 | consumed tokens: 1585971200.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-01T14:53:44 | step: 193700 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 2.9223794626886956e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.7 | consumed tokens: 1586790400.0 | grad norm avg: 0.91 | grad norm last: 0.85 | 
2026-01-01T14:54:02 | step: 193800 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.9205571991042234e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.16 | consumed tokens: 1587609600.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T14:54:20 | step: 193900 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.9187347536208108e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.41 | consumed tokens: 1588428800.0 | grad norm avg: 0.92 | grad norm last: 0.85 | 
2026-01-01T14:54:38 | step: 194000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.916912126238458e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.16 | consumed tokens: 1589248000.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T14:54:56 | step: 194100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.9150891350582242e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.8 | consumed tokens: 1590067200.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T14:55:14 | step: 194200 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.9132659619790502e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 4.09 | consumed tokens: 1590886400.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T14:55:32 | step: 194300 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.9114426070009358e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.3 | consumed tokens: 1591705600.0 | grad norm avg: 0.94 | grad norm last: 0.86 | 
2026-01-01T14:55:50 | step: 194400 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.909619070123881e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.48 | consumed tokens: 1592524800.0 | grad norm avg: 0.92 | grad norm last: 1.08 | 
2026-01-01T14:56:08 | step: 194500 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.9077951694489457e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.34 | consumed tokens: 1593344000.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-01T14:56:26 | step: 194600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.90597108687507e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.58 | consumed tokens: 1594163200.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-01T14:56:44 | step: 194700 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.9041468224022537e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.94 | consumed tokens: 1594982400.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-01T14:57:02 | step: 194800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.9023223760304973e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.28 | consumed tokens: 1595801600.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-01T14:57:20 | step: 194900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.9004977477598004e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.16 | consumed tokens: 1596620800.0 | grad norm avg: 0.91 | grad norm last: 0.96 | 
2026-01-01T14:57:38 | step: 195000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.898672755691223e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.39 | consumed tokens: 1597440000.0 | grad norm avg: 0.91 | grad norm last: 0.85 | 
2026-01-01T14:57:58 | step: 195100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.896847581723705e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.97 | consumed tokens: 1598259200.0 | grad norm avg: 0.92 | grad norm last: 0.85 | 
2026-01-01T14:58:16 | step: 195200 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 2.8950222258572467e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.3 | consumed tokens: 1599078400.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-01T14:58:34 | step: 195300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.893196688091848e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.2 | consumed tokens: 1599897600.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-01T14:58:51 | step: 195400 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.891370968427509e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.88 | consumed tokens: 1600716800.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T14:59:09 | step: 195500 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.8895448849652894e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.27 | consumed tokens: 1601536000.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-01T14:59:27 | step: 195600 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.8877188015030697e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.81 | consumed tokens: 1602355200.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-01T14:59:45 | step: 195700 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.8858923542429693e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.59 | consumed tokens: 1603174400.0 | grad norm avg: 0.92 | grad norm last: 0.86 | 
2026-01-01T15:00:03 | step: 195800 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.8840657250839286e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.55 | consumed tokens: 1603993600.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-01T15:00:21 | step: 195900 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.8822389140259475e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.3 | consumed tokens: 1604812800.0 | grad norm avg: 0.92 | grad norm last: 0.96 | 
2026-01-01T15:00:39 | step: 196000 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.8804117391700856e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.69 | consumed tokens: 1605632000.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T15:00:57 | step: 196100 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.8785845643142238e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.44 | consumed tokens: 1606451200.0 | grad norm avg: 0.92 | grad norm last: 0.96 | 
2026-01-01T15:01:15 | step: 196200 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.8767570256604813e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.92 | consumed tokens: 1607270400.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T15:01:33 | step: 196300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.8749294870067388e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.67 | consumed tokens: 1608089600.0 | grad norm avg: 0.92 | grad norm last: 1.01 | 
2026-01-01T15:01:51 | step: 196400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.8731015845551156e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.05 | consumed tokens: 1608908800.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-01T15:02:09 | step: 196500 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.871273500204552e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.44 | consumed tokens: 1609728000.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T15:02:27 | step: 196600 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 2.869445233955048e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.16 | consumed tokens: 1610547200.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T15:02:45 | step: 196700 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.8676167858066037e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.78 | consumed tokens: 1611366400.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T15:03:03 | step: 196800 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.865788155759219e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.11 | consumed tokens: 1612185600.0 | grad norm avg: 0.92 | grad norm last: 0.86 | 
2026-01-01T15:03:21 | step: 196900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.8639591619139537e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.05 | consumed tokens: 1613004800.0 | grad norm avg: 0.93 | grad norm last: 1.01 | 
2026-01-01T15:03:39 | step: 197000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.8621301680686884e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.95 | consumed tokens: 1613824000.0 | grad norm avg: 0.92 | grad norm last: 0.98 | 
2026-01-01T15:03:57 | step: 197100 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.8603008104255423e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.81 | consumed tokens: 1614643200.0 | grad norm avg: 0.92 | grad norm last: 0.96 | 
2026-01-01T15:04:15 | step: 197200 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.8584714527823962e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.97 | consumed tokens: 1615462400.0 | grad norm avg: 0.93 | grad norm last: 0.82 | 
2026-01-01T15:04:33 | step: 197300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.8566417313413695e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.44 | consumed tokens: 1616281600.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T15:04:51 | step: 197400 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.8548118280014023e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.83 | consumed tokens: 1617100800.0 | grad norm avg: 0.91 | grad norm last: 0.85 | 
2026-01-01T15:05:09 | step: 197500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 2.8529819246614352e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.67 | consumed tokens: 1617920000.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T15:05:27 | step: 197600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.8511516575235873e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.17 | consumed tokens: 1618739200.0 | grad norm avg: 0.92 | grad norm last: 0.94 | 
2026-01-01T15:05:45 | step: 197700 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.849321208486799e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.06 | consumed tokens: 1619558400.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-01T15:06:03 | step: 197800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.8474905775510706e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.47 | consumed tokens: 1620377600.0 | grad norm avg: 0.9 | grad norm last: 0.98 | 
2026-01-01T15:06:21 | step: 197900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.8456597647164017e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.7 | consumed tokens: 1621196800.0 | grad norm avg: 0.93 | grad norm last: 0.86 | 
2026-01-01T15:06:39 | step: 198000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.8438287699827924e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.66 | consumed tokens: 1622016000.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T15:06:57 | step: 198100 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.8419975933502428e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.8 | consumed tokens: 1622835200.0 | grad norm avg: 0.92 | grad norm last: 1.0 | 
2026-01-01T15:07:14 | step: 198200 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.840166234818753e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.8 | consumed tokens: 1623654400.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T15:07:32 | step: 198300 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.8383346943883225e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.88 | consumed tokens: 1624473600.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-01T15:07:51 | step: 198400 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.836502972058952e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.38 | consumed tokens: 1625292800.0 | grad norm avg: 0.91 | grad norm last: 1.04 | 
2026-01-01T15:08:08 | step: 198500 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.8346710678306408e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.72 | consumed tokens: 1626112000.0 | grad norm avg: 0.9 | grad norm last: 0.78 | 
2026-01-01T15:08:26 | step: 198600 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.832838799804449e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.67 | consumed tokens: 1626931200.0 | grad norm avg: 0.91 | grad norm last: 0.99 | 
2026-01-01T15:08:44 | step: 198700 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.8310065317782573e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.02 | consumed tokens: 1627750400.0 | grad norm avg: 0.92 | grad norm last: 0.96 | 
2026-01-01T15:09:02 | step: 198800 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.8291740818531252e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.64 | consumed tokens: 1628569600.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-01T15:09:20 | step: 198900 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.8273414500290528e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.55 | consumed tokens: 1629388800.0 | grad norm avg: 0.93 | grad norm last: 1.0 | 
2026-01-01T15:09:38 | step: 199000 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.82550863630604e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.92 | consumed tokens: 1630208000.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T15:09:56 | step: 199100 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.8236756406840868e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.58 | consumed tokens: 1631027200.0 | grad norm avg: 0.91 | grad norm last: 0.82 | 
2026-01-01T15:10:14 | step: 199200 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.8218424631631933e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.02 | consumed tokens: 1631846400.0 | grad norm avg: 0.93 | grad norm last: 0.87 | 
2026-01-01T15:10:32 | step: 199300 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.8200091037433594e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.61 | consumed tokens: 1632665600.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T15:10:50 | step: 199400 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.8181755624245852e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.78 | consumed tokens: 1633484800.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-01T15:11:08 | step: 199500 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 2.816342021105811e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.67 | consumed tokens: 1634304000.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-01T15:11:26 | step: 199600 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.814508115989156e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.5 | consumed tokens: 1635123200.0 | grad norm avg: 0.92 | grad norm last: 1.01 | 
2026-01-01T15:11:44 | step: 199700 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.8126740289735608e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.23 | consumed tokens: 1635942400.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T15:12:02 | step: 199800 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.810839760059025e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 4.62 | consumed tokens: 1636761600.0 | grad norm avg: 0.91 | grad norm last: 0.84 | 
2026-01-01T15:12:20 | step: 199900 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.8090054911444895e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.14 | consumed tokens: 1637580800.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-01T15:12:38 | step: 200000 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 2.807170858432073e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.0 | consumed tokens: 1638400000.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-01T15:12:57 | step: 200100 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 2.8053362257196568e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.25 | consumed tokens: 1639219200.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T15:13:15 | step: 200200 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.8035012292093597e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.36 | consumed tokens: 1640038400.0 | grad norm avg: 0.93 | grad norm last: 1.0 | 
2026-01-01T15:13:33 | step: 200300 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.8016662326990627e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.22 | consumed tokens: 1640857600.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T15:13:51 | step: 200400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.7998310542898253e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.44 | consumed tokens: 1641676800.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-01T15:14:09 | step: 200500 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.7979956939816475e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.64 | consumed tokens: 1642496000.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T15:14:27 | step: 200600 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 2.7961601517745294e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.17 | consumed tokens: 1643315200.0 | grad norm avg: 0.9 | grad norm last: 1.03 | 
2026-01-01T15:14:44 | step: 200700 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.794324427668471e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.91 | consumed tokens: 1644134400.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T15:15:02 | step: 200800 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.7924887035624124e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.02 | consumed tokens: 1644953600.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T15:15:20 | step: 200900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.7906526156584732e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.3 | consumed tokens: 1645772800.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-01T15:15:39 | step: 201000 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 2.788816527754534e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.38 | consumed tokens: 1646592000.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-01T15:15:57 | step: 201100 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.786980076052714e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.81 | consumed tokens: 1647411200.0 | grad norm avg: 0.92 | grad norm last: 0.85 | 
2026-01-01T15:16:15 | step: 201200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.7851436243508942e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.86 | consumed tokens: 1648230400.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T15:16:32 | step: 201300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.783306990750134e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.39 | consumed tokens: 1649049600.0 | grad norm avg: 0.91 | grad norm last: 1.02 | 
2026-01-01T15:16:50 | step: 201400 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.7814701752504334e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.28 | consumed tokens: 1649868800.0 | grad norm avg: 0.92 | grad norm last: 0.94 | 
2026-01-01T15:17:08 | step: 201500 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.7796333597507328e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.28 | consumed tokens: 1650688000.0 | grad norm avg: 0.91 | grad norm last: 0.99 | 
2026-01-01T15:17:26 | step: 201600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.7777961804531515e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.12 | consumed tokens: 1651507200.0 | grad norm avg: 0.92 | grad norm last: 1.12 | 
2026-01-01T15:17:44 | step: 201700 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.77595900115557e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.08 | consumed tokens: 1652326400.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-01T15:18:02 | step: 201800 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 2.774121458060108e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.33 | consumed tokens: 1653145600.0 | grad norm avg: 0.91 | grad norm last: 1.01 | 
2026-01-01T15:18:20 | step: 201900 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.772283914964646e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.62 | consumed tokens: 1653964800.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-01T15:18:38 | step: 202000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.770446371869184e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.66 | consumed tokens: 1654784000.0 | grad norm avg: 0.91 | grad norm last: 0.83 | 
2026-01-01T15:18:56 | step: 202100 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.7686084649758413e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.36 | consumed tokens: 1655603200.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T15:19:14 | step: 202200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.7667705580824986e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.69 | consumed tokens: 1656422400.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-01T15:19:32 | step: 202300 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.764932287391275e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.61 | consumed tokens: 1657241600.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-01T15:19:50 | step: 202400 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 2.7630940167000517e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.95 | consumed tokens: 1658060800.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-01T15:20:08 | step: 202500 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.7612557460088283e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.64 | consumed tokens: 1658880000.0 | grad norm avg: 0.92 | grad norm last: 0.83 | 
2026-01-01T15:20:26 | step: 202600 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.759417111519724e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.39 | consumed tokens: 1659699200.0 | grad norm avg: 0.93 | grad norm last: 0.83 | 
2026-01-01T15:20:44 | step: 202700 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.75757847703062e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.27 | consumed tokens: 1660518400.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T15:21:02 | step: 202800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.7557396606425755e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.75 | consumed tokens: 1661337600.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T15:21:20 | step: 202900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.7539006623555906e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.06 | consumed tokens: 1662156800.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-01T15:21:38 | step: 203000 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.7520614821696654e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.75 | consumed tokens: 1662976000.0 | grad norm avg: 0.92 | grad norm last: 0.96 | 
2026-01-01T15:21:56 | step: 203100 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.7502223019837402e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.78 | consumed tokens: 1663795200.0 | grad norm avg: 0.94 | grad norm last: 0.94 | 
2026-01-01T15:22:14 | step: 203200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.7483827579999343e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.97 | consumed tokens: 1664614400.0 | grad norm avg: 0.91 | grad norm last: 0.96 | 
2026-01-01T15:22:32 | step: 203300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.7465433959150687e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.92 | consumed tokens: 1665433600.0 | grad norm avg: 0.91 | grad norm last: 1.0 | 
2026-01-01T15:22:50 | step: 203400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.7447036700323224e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.89 | consumed tokens: 1666252800.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-01T15:23:08 | step: 203500 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.742863944149576e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.06 | consumed tokens: 1667072000.0 | grad norm avg: 0.93 | grad norm last: 1.01 | 
2026-01-01T15:23:26 | step: 203600 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.7410240363678895e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.28 | consumed tokens: 1667891200.0 | grad norm avg: 0.91 | grad norm last: 1.01 | 
2026-01-01T15:23:44 | step: 203700 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.7391839466872625e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.91 | consumed tokens: 1668710400.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T15:24:02 | step: 203800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.737343675107695e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.83 | consumed tokens: 1669529600.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-01T15:24:20 | step: 203900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.7355034035281278e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.44 | consumed tokens: 1670348800.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T15:24:38 | step: 204000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.73366295004962e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.11 | consumed tokens: 1671168000.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-01T15:24:56 | step: 204100 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.7318224965711124e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.47 | consumed tokens: 1671987200.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-01T15:25:14 | step: 204200 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 2.729981679294724e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.14 | consumed tokens: 1672806400.0 | grad norm avg: 0.92 | grad norm last: 0.85 | 
2026-01-01T15:25:32 | step: 204300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.7281408620183356e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.53 | consumed tokens: 1673625600.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-01T15:25:50 | step: 204400 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.7263000447419472e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.2 | consumed tokens: 1674444800.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T15:26:07 | step: 204500 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.724458863667678e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.47 | consumed tokens: 1675264000.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T15:26:25 | step: 204600 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.722617682593409e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.66 | consumed tokens: 1676083200.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-01T15:26:43 | step: 204700 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.72077650151914e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.5 | consumed tokens: 1676902400.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-01T15:27:01 | step: 204800 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 2.71893495664699e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.7 | consumed tokens: 1677721600.0 | grad norm avg: 0.91 | grad norm last: 1.01 | 
2026-01-01T15:27:19 | step: 204900 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.7170934117748402e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.23 | consumed tokens: 1678540800.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-01T15:27:37 | step: 205000 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.7152518669026904e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.58 | consumed tokens: 1679360000.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T15:27:57 | step: 205100 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.7134101401316002e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.31 | consumed tokens: 1680179200.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-01T15:28:15 | step: 205200 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.7115682314615697e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.53 | consumed tokens: 1680998400.0 | grad norm avg: 0.92 | grad norm last: 0.86 | 
2026-01-01T15:28:33 | step: 205300 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 2.7097261408925988e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.5 | consumed tokens: 1681817600.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-01T15:28:50 | step: 205400 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 2.707884050323628e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.22 | consumed tokens: 1682636800.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-01T15:29:08 | step: 205500 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.7060417778557166e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.58 | consumed tokens: 1683456000.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-01T15:29:26 | step: 205600 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.7041995053878054e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.91 | consumed tokens: 1684275200.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T15:29:44 | step: 205700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.7023570510209538e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.14 | consumed tokens: 1685094400.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-01T15:30:02 | step: 205800 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.700514414755162e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.52 | consumed tokens: 1685913600.0 | grad norm avg: 0.91 | grad norm last: 0.81 | 
2026-01-01T15:30:20 | step: 205900 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 2.69867177848937e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.97 | consumed tokens: 1686732800.0 | grad norm avg: 0.92 | grad norm last: 0.8 | 
2026-01-01T15:30:38 | step: 206000 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.6968289603246376e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.11 | consumed tokens: 1687552000.0 | grad norm avg: 0.93 | grad norm last: 0.82 | 
2026-01-01T15:30:56 | step: 206100 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.6949861421599053e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 4.03 | consumed tokens: 1688371200.0 | grad norm avg: 0.92 | grad norm last: 0.99 | 
2026-01-01T15:31:14 | step: 206200 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.6931431420962326e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.61 | consumed tokens: 1689190400.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-01T15:31:32 | step: 206300 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.69130014203256e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.67 | consumed tokens: 1690009600.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-01T15:31:50 | step: 206400 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.689456960069947e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.97 | consumed tokens: 1690828800.0 | grad norm avg: 0.93 | grad norm last: 0.82 | 
2026-01-01T15:32:08 | step: 206500 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 2.6876135962083936e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.3 | consumed tokens: 1691648000.0 | grad norm avg: 0.92 | grad norm last: 1.05 | 
2026-01-01T15:32:26 | step: 206600 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.6857702323468402e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.45 | consumed tokens: 1692467200.0 | grad norm avg: 0.93 | grad norm last: 0.97 | 
2026-01-01T15:32:44 | step: 206700 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.6839266865863465e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.31 | consumed tokens: 1693286400.0 | grad norm avg: 0.93 | grad norm last: 0.86 | 
2026-01-01T15:33:02 | step: 206800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.6820831408258528e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.84 | consumed tokens: 1694105600.0 | grad norm avg: 0.93 | grad norm last: 0.99 | 
2026-01-01T15:33:20 | step: 206900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.6802394131664187e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.8 | consumed tokens: 1694924800.0 | grad norm avg: 0.93 | grad norm last: 0.88 | 
2026-01-01T15:33:38 | step: 207000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.6783955036080442e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.92 | consumed tokens: 1695744000.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-01T15:33:55 | step: 207100 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 2.67655177594861e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.88 | consumed tokens: 1696563200.0 | grad norm avg: 0.92 | grad norm last: 0.99 | 
2026-01-01T15:34:13 | step: 207200 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.6747076844912954e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.44 | consumed tokens: 1697382400.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-01T15:34:31 | step: 207300 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.6728635930339806e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.83 | consumed tokens: 1698201600.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-01T15:34:49 | step: 207400 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.6710195015766658e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.02 | consumed tokens: 1699020800.0 | grad norm avg: 0.92 | grad norm last: 0.84 | 
2026-01-01T15:35:07 | step: 207500 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.6691752282204106e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.0 | consumed tokens: 1699840000.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-01T15:35:25 | step: 207600 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 2.667330772965215e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.73 | consumed tokens: 1700659200.0 | grad norm avg: 0.92 | grad norm last: 0.85 | 
2026-01-01T15:35:43 | step: 207700 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 2.6654863177100196e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.0 | consumed tokens: 1701478400.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-01T15:36:01 | step: 207800 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 2.663641862454824e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.78 | consumed tokens: 1702297600.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T15:36:19 | step: 207900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.6617972253006883e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.42 | consumed tokens: 1703116800.0 | grad norm avg: 0.92 | grad norm last: 1.02 | 
2026-01-01T15:36:37 | step: 208000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.659952406247612e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.95 | consumed tokens: 1703936000.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T15:36:55 | step: 208100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.6581077690934762e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.69 | consumed tokens: 1704755200.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-01T15:37:13 | step: 208200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.6562627681414597e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.47 | consumed tokens: 1705574400.0 | grad norm avg: 0.92 | grad norm last: 0.83 | 
2026-01-01T15:37:31 | step: 208300 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.654417767189443e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.78 | consumed tokens: 1706393600.0 | grad norm avg: 0.92 | grad norm last: 0.96 | 
2026-01-01T15:37:49 | step: 208400 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.6525727662374265e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.2 | consumed tokens: 1707212800.0 | grad norm avg: 0.92 | grad norm last: 1.01 | 
2026-01-01T15:38:07 | step: 208500 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.6507275833864696e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.06 | consumed tokens: 1708032000.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-01T15:38:25 | step: 208600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.6488824005355127e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.88 | consumed tokens: 1708851200.0 | grad norm avg: 0.92 | grad norm last: 0.98 | 
2026-01-01T15:38:43 | step: 208700 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.6470372176845558e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.08 | consumed tokens: 1709670400.0 | grad norm avg: 0.92 | grad norm last: 1.01 | 
2026-01-01T15:39:01 | step: 208800 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 2.6451918529346585e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.09 | consumed tokens: 1710489600.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-01T15:39:19 | step: 208900 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.643346306285821e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.34 | consumed tokens: 1711308800.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-01T15:39:37 | step: 209000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.6415007596369833e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.45 | consumed tokens: 1712128000.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T15:39:55 | step: 209100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.6396552129881456e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 4.12 | consumed tokens: 1712947200.0 | grad norm avg: 0.92 | grad norm last: 0.81 | 
2026-01-01T15:40:13 | step: 209200 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.6378094844403677e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.42 | consumed tokens: 1713766400.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-01T15:40:31 | step: 209300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.6359637558925897e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.84 | consumed tokens: 1714585600.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-01T15:40:49 | step: 209400 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.6341178454458714e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.0 | consumed tokens: 1715404800.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T15:41:07 | step: 209500 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 2.632271934999153e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.67 | consumed tokens: 1716224000.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-01T15:41:25 | step: 209600 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.6304260245524347e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.45 | consumed tokens: 1717043200.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T15:41:43 | step: 209700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.628579932206776e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.12 | consumed tokens: 1717862400.0 | grad norm avg: 0.92 | grad norm last: 1.0 | 
2026-01-01T15:42:01 | step: 209800 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.6267338398611173e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.0 | consumed tokens: 1718681600.0 | grad norm avg: 0.92 | grad norm last: 1.0 | 
2026-01-01T15:42:19 | step: 209900 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.6248877475154586e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.8 | consumed tokens: 1719500800.0 | grad norm avg: 0.91 | grad norm last: 1.0 | 
2026-01-01T15:42:36 | step: 210000 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 2.6230414732708596e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.48 | consumed tokens: 1720320000.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T15:42:56 | step: 210100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.6211951990262605e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.59 | consumed tokens: 1721139200.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T15:43:14 | step: 210200 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.619348742882721e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.52 | consumed tokens: 1721958400.0 | grad norm avg: 0.93 | grad norm last: 0.88 | 
2026-01-01T15:43:32 | step: 210300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.6175022867391817e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.42 | consumed tokens: 1722777600.0 | grad norm avg: 0.93 | grad norm last: 1.07 | 
2026-01-01T15:43:50 | step: 210400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.6156558305956423e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.61 | consumed tokens: 1723596800.0 | grad norm avg: 0.93 | grad norm last: 0.97 | 
2026-01-01T15:44:08 | step: 210500 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.6138091925531626e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.5 | consumed tokens: 1724416000.0 | grad norm avg: 0.93 | grad norm last: 1.03 | 
2026-01-01T15:44:26 | step: 210600 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 2.6119625545106828e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.11 | consumed tokens: 1725235200.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-01T15:44:44 | step: 210700 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 2.610115916468203e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.89 | consumed tokens: 1726054400.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-01T15:45:02 | step: 210800 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.6082692784257233e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.81 | consumed tokens: 1726873600.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-01T15:45:20 | step: 210900 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.6064224584843032e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.52 | consumed tokens: 1727692800.0 | grad norm avg: 0.93 | grad norm last: 0.87 | 
2026-01-01T15:45:38 | step: 211000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 2.6045754566439427e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.77 | consumed tokens: 1728512000.0 | grad norm avg: 0.93 | grad norm last: 0.99 | 
2026-01-01T15:45:56 | step: 211100 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.6027286367025226e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.12 | consumed tokens: 1729331200.0 | grad norm avg: 0.93 | grad norm last: 0.82 | 
2026-01-01T15:46:14 | step: 211200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.6008816348621622e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.05 | consumed tokens: 1730150400.0 | grad norm avg: 0.93 | grad norm last: 0.88 | 
2026-01-01T15:46:32 | step: 211300 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.5990346330218017e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.31 | consumed tokens: 1730969600.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-01T15:46:50 | step: 211400 | train samples/s: 95.5 | train mfu (16-bit): -1.0 | lr mean: 2.597187449282501e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.88 | consumed tokens: 1731788800.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-01T15:47:08 | step: 211500 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.5953404474421404e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.33 | consumed tokens: 1732608000.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-01T15:47:26 | step: 211600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.5934932637028396e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.69 | consumed tokens: 1733427200.0 | grad norm avg: 0.92 | grad norm last: 0.85 | 
2026-01-01T15:47:44 | step: 211700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.5916460799635388e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.19 | consumed tokens: 1734246400.0 | grad norm avg: 0.93 | grad norm last: 0.86 | 
2026-01-01T15:48:02 | step: 211800 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.5897987143252976e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.77 | consumed tokens: 1735065600.0 | grad norm avg: 0.92 | grad norm last: 0.96 | 
2026-01-01T15:48:20 | step: 211900 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 2.5879513486870565e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.52 | consumed tokens: 1735884800.0 | grad norm avg: 0.93 | grad norm last: 0.99 | 
2026-01-01T15:48:38 | step: 212000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.5861039830488153e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.47 | consumed tokens: 1736704000.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-01T15:48:56 | step: 212100 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.584256617410574e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.47 | consumed tokens: 1737523200.0 | grad norm avg: 0.93 | grad norm last: 0.86 | 
2026-01-01T15:49:14 | step: 212200 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.5824090698733926e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.14 | consumed tokens: 1738342400.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-01T15:49:32 | step: 212300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.5805617042351514e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.33 | consumed tokens: 1739161600.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T15:49:50 | step: 212400 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.5787139747990295e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.16 | consumed tokens: 1739980800.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-01T15:50:07 | step: 212500 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.576866427261848e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.5 | consumed tokens: 1740800000.0 | grad norm avg: 0.92 | grad norm last: 0.94 | 
2026-01-01T15:50:26 | step: 212600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.5750188797246665e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.28 | consumed tokens: 1741619200.0 | grad norm avg: 0.92 | grad norm last: 0.96 | 
2026-01-01T15:50:44 | step: 212700 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.5731711502885446e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.61 | consumed tokens: 1742438400.0 | grad norm avg: 0.92 | grad norm last: 0.96 | 
2026-01-01T15:51:02 | step: 212800 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.5713234208524227e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.47 | consumed tokens: 1743257600.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-01T15:51:20 | step: 212900 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.569475691416301e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.52 | consumed tokens: 1744076800.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-01T15:51:37 | step: 213000 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 2.567627961980179e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.52 | consumed tokens: 1744896000.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-01T15:51:55 | step: 213100 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.5657800506451167e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.84 | consumed tokens: 1745715200.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-01T15:52:13 | step: 213200 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.5639321393100545e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.53 | consumed tokens: 1746534400.0 | grad norm avg: 0.93 | grad norm last: 0.98 | 
2026-01-01T15:52:31 | step: 213300 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.5620844098739326e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.14 | consumed tokens: 1747353600.0 | grad norm avg: 0.94 | grad norm last: 1.03 | 
2026-01-01T15:52:49 | step: 213400 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.5602364985388704e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.56 | consumed tokens: 1748172800.0 | grad norm avg: 0.93 | grad norm last: 0.88 | 
2026-01-01T15:53:07 | step: 213500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.5583884053048678e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.44 | consumed tokens: 1748992000.0 | grad norm avg: 0.92 | grad norm last: 0.96 | 
2026-01-01T15:53:25 | step: 213600 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.5565404939698055e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.98 | consumed tokens: 1749811200.0 | grad norm avg: 0.93 | grad norm last: 0.84 | 
2026-01-01T15:53:43 | step: 213700 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.554692400735803e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.91 | consumed tokens: 1750630400.0 | grad norm avg: 0.93 | grad norm last: 0.85 | 
2026-01-01T15:54:01 | step: 213800 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.5528444894007407e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.55 | consumed tokens: 1751449600.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-01T15:54:19 | step: 213900 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.550996396166738e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.12 | consumed tokens: 1752268800.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-01T15:54:37 | step: 214000 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.5491483029327355e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.45 | consumed tokens: 1753088000.0 | grad norm avg: 0.92 | grad norm last: 0.85 | 
2026-01-01T15:54:55 | step: 214100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 2.547300209698733e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.14 | consumed tokens: 1753907200.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-01T15:55:13 | step: 214200 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.54545193456579e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.88 | consumed tokens: 1754726400.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-01T15:55:31 | step: 214300 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.5436038413317874e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.8 | consumed tokens: 1755545600.0 | grad norm avg: 0.93 | grad norm last: 1.01 | 
2026-01-01T15:55:49 | step: 214400 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.5417555661988445e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.95 | consumed tokens: 1756364800.0 | grad norm avg: 0.92 | grad norm last: 1.0 | 
2026-01-01T15:56:07 | step: 214500 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.539907472964842e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 4.12 | consumed tokens: 1757184000.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-01T15:56:25 | step: 214600 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.538059197831899e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.14 | consumed tokens: 1758003200.0 | grad norm avg: 0.93 | grad norm last: 0.86 | 
2026-01-01T15:56:43 | step: 214700 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.536210922698956e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.53 | consumed tokens: 1758822400.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-01T15:57:01 | step: 214800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.534362647566013e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.12 | consumed tokens: 1759641600.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-01T15:57:19 | step: 214900 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.53251437243307e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.41 | consumed tokens: 1760460800.0 | grad norm avg: 0.92 | grad norm last: 1.1 | 
2026-01-01T15:57:37 | step: 215000 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.530666097300127e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.33 | consumed tokens: 1761280000.0 | grad norm avg: 0.94 | grad norm last: 0.89 | 
2026-01-01T15:57:56 | step: 215100 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.528817640268244e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.56 | consumed tokens: 1762099200.0 | grad norm avg: 0.92 | grad norm last: 1.03 | 
2026-01-01T15:58:14 | step: 215200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.526969365135301e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.23 | consumed tokens: 1762918400.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-01T15:58:33 | step: 215300 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.525121090002358e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.44 | consumed tokens: 1763737600.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T15:58:50 | step: 215400 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.5232726329704747e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.36 | consumed tokens: 1764556800.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-01T15:59:08 | step: 215500 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.5214243578375317e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.77 | consumed tokens: 1765376000.0 | grad norm avg: 0.93 | grad norm last: 0.98 | 
2026-01-01T15:59:26 | step: 215600 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.5195759008056484e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.39 | consumed tokens: 1766195200.0 | grad norm avg: 0.94 | grad norm last: 0.95 | 
2026-01-01T15:59:44 | step: 215700 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.517727443773765e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.09 | consumed tokens: 1767014400.0 | grad norm avg: 0.94 | grad norm last: 0.92 | 
2026-01-01T16:00:02 | step: 215800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.5158791686408222e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.0 | consumed tokens: 1767833600.0 | grad norm avg: 0.93 | grad norm last: 0.97 | 
2026-01-01T16:00:20 | step: 215900 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.514030711608939e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.84 | consumed tokens: 1768652800.0 | grad norm avg: 0.93 | grad norm last: 1.0 | 
2026-01-01T16:00:38 | step: 216000 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 2.5121822545770556e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.22 | consumed tokens: 1769472000.0 | grad norm avg: 0.93 | grad norm last: 1.0 | 
2026-01-01T16:00:56 | step: 216100 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.5103337975451723e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.92 | consumed tokens: 1770291200.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-01T16:01:14 | step: 216200 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.508485340513289e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.33 | consumed tokens: 1771110400.0 | grad norm avg: 0.94 | grad norm last: 0.98 | 
2026-01-01T16:01:32 | step: 216300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.506637065380346e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.17 | consumed tokens: 1771929600.0 | grad norm avg: 0.93 | grad norm last: 1.09 | 
2026-01-01T16:01:50 | step: 216400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.5047886083484627e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.66 | consumed tokens: 1772748800.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T16:02:08 | step: 216500 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.5029401513165794e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.5 | consumed tokens: 1773568000.0 | grad norm avg: 0.94 | grad norm last: 0.85 | 
2026-01-01T16:02:26 | step: 216600 | train samples/s: 96.6 | train mfu (16-bit): -1.0 | lr mean: 2.501091694284696e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 4.34 | consumed tokens: 1774387200.0 | grad norm avg: 0.92 | grad norm last: 0.84 | 
2026-01-01T16:02:44 | step: 216700 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.499243237252813e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.81 | consumed tokens: 1775206400.0 | grad norm avg: 0.93 | grad norm last: 1.05 | 
2026-01-01T16:03:02 | step: 216800 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.4973947802209295e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.88 | consumed tokens: 1776025600.0 | grad norm avg: 0.93 | grad norm last: 1.06 | 
2026-01-01T16:03:20 | step: 216900 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.4955463231890462e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.91 | consumed tokens: 1776844800.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T16:03:38 | step: 217000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.4936980480561033e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.45 | consumed tokens: 1777664000.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-01T16:03:56 | step: 217100 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.49184959102422e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.27 | consumed tokens: 1778483200.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-01T16:04:14 | step: 217200 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.4900011339923367e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.95 | consumed tokens: 1779302400.0 | grad norm avg: 0.92 | grad norm last: 0.94 | 
2026-01-01T16:04:32 | step: 217300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.4881526769604534e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.92 | consumed tokens: 1780121600.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-01T16:04:50 | step: 217400 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.4863044018275104e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.69 | consumed tokens: 1780940800.0 | grad norm avg: 0.93 | grad norm last: 0.87 | 
2026-01-01T16:05:08 | step: 217500 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.484455944795627e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.73 | consumed tokens: 1781760000.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-01T16:05:26 | step: 217600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.482607487763744e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.12 | consumed tokens: 1782579200.0 | grad norm avg: 0.93 | grad norm last: 1.11 | 
2026-01-01T16:05:44 | step: 217700 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 2.480759212630801e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.16 | consumed tokens: 1783398400.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-01T16:06:02 | step: 217800 | train samples/s: 98.8 | train mfu (16-bit): -1.0 | lr mean: 2.4789107555989176e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.27 | consumed tokens: 1784217600.0 | grad norm avg: 0.92 | grad norm last: 0.94 | 
2026-01-01T16:06:20 | step: 217900 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.4770624804659747e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 4.31 | consumed tokens: 1785036800.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-01T16:06:38 | step: 218000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.4752142053330317e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.8 | consumed tokens: 1785856000.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T16:06:56 | step: 218100 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.4733657483011484e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.23 | consumed tokens: 1786675200.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-01T16:07:14 | step: 218200 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.4715174731682055e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.41 | consumed tokens: 1787494400.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-01T16:07:32 | step: 218300 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.4696691980352625e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.45 | consumed tokens: 1788313600.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-01T16:07:49 | step: 218400 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 2.4678209229023196e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.17 | consumed tokens: 1789132800.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-01T16:08:07 | step: 218500 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.465972829668317e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.88 | consumed tokens: 1789952000.0 | grad norm avg: 0.94 | grad norm last: 0.89 | 
2026-01-01T16:08:25 | step: 218600 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.464124554535374e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.39 | consumed tokens: 1790771200.0 | grad norm avg: 0.92 | grad norm last: 0.86 | 
2026-01-01T16:08:43 | step: 218700 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.462276279402431e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.23 | consumed tokens: 1791590400.0 | grad norm avg: 0.93 | grad norm last: 0.86 | 
2026-01-01T16:09:01 | step: 218800 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.4604281861684285e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.92 | consumed tokens: 1792409600.0 | grad norm avg: 0.94 | grad norm last: 0.9 | 
2026-01-01T16:09:19 | step: 218900 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.4585799110354856e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.27 | consumed tokens: 1793228800.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-01T16:09:37 | step: 219000 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 2.456731817801483e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.39 | consumed tokens: 1794048000.0 | grad norm avg: 0.94 | grad norm last: 1.01 | 
2026-01-01T16:09:55 | step: 219100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.4548837245674804e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 4.0 | consumed tokens: 1794867200.0 | grad norm avg: 0.92 | grad norm last: 0.96 | 
2026-01-01T16:10:13 | step: 219200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.4530356313334778e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.45 | consumed tokens: 1795686400.0 | grad norm avg: 0.93 | grad norm last: 0.87 | 
2026-01-01T16:10:31 | step: 219300 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.4511875380994752e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.92 | consumed tokens: 1796505600.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-01T16:10:49 | step: 219400 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.449339626764413e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.89 | consumed tokens: 1797324800.0 | grad norm avg: 0.94 | grad norm last: 1.01 | 
2026-01-01T16:11:07 | step: 219500 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 2.4474915335304104e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.16 | consumed tokens: 1798144000.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-01T16:11:25 | step: 219600 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.445643622195348e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.98 | consumed tokens: 1798963200.0 | grad norm avg: 0.93 | grad norm last: 1.01 | 
2026-01-01T16:11:43 | step: 219700 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.443795710860286e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.47 | consumed tokens: 1799782400.0 | grad norm avg: 0.94 | grad norm last: 0.82 | 
2026-01-01T16:12:01 | step: 219800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.4419477995252237e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.8 | consumed tokens: 1800601600.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-01T16:12:19 | step: 219900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.4400998881901614e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.5 | consumed tokens: 1801420800.0 | grad norm avg: 0.94 | grad norm last: 0.91 | 
2026-01-01T16:12:37 | step: 220000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.4382519768550992e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.44 | consumed tokens: 1802240000.0 | grad norm avg: 0.92 | grad norm last: 0.99 | 
2026-01-01T16:12:56 | step: 220100 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.4364042474189773e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.44 | consumed tokens: 1803059200.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T16:13:14 | step: 220200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.4345565179828554e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.11 | consumed tokens: 1803878400.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-01T16:13:32 | step: 220300 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.4327087885467336e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.64 | consumed tokens: 1804697600.0 | grad norm avg: 0.94 | grad norm last: 0.94 | 
2026-01-01T16:13:50 | step: 220400 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.4308610591106117e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.23 | consumed tokens: 1805516800.0 | grad norm avg: 0.94 | grad norm last: 0.92 | 
2026-01-01T16:14:08 | step: 220500 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 2.4290133296744898e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.0 | consumed tokens: 1806336000.0 | grad norm avg: 0.94 | grad norm last: 0.92 | 
2026-01-01T16:14:26 | step: 220600 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.4271657821373083e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.86 | consumed tokens: 1807155200.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-01T16:14:44 | step: 220700 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.4253182346001267e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.23 | consumed tokens: 1807974400.0 | grad norm avg: 0.94 | grad norm last: 0.99 | 
2026-01-01T16:15:02 | step: 220800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.4234706870629452e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.48 | consumed tokens: 1808793600.0 | grad norm avg: 0.92 | grad norm last: 0.84 | 
2026-01-01T16:15:20 | step: 220900 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.4216231395257637e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.88 | consumed tokens: 1809612800.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-01T16:15:38 | step: 221000 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.4197757738875225e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.84 | consumed tokens: 1810432000.0 | grad norm avg: 0.93 | grad norm last: 0.97 | 
2026-01-01T16:15:56 | step: 221100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 2.4179284082492813e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.56 | consumed tokens: 1811251200.0 | grad norm avg: 0.95 | grad norm last: 0.95 | 
2026-01-01T16:16:14 | step: 221200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.4160810426110402e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.25 | consumed tokens: 1812070400.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-01T16:16:32 | step: 221300 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.414233676972799e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.09 | consumed tokens: 1812889600.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-01T16:16:50 | step: 221400 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.4123864932334982e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.61 | consumed tokens: 1813708800.0 | grad norm avg: 0.94 | grad norm last: 0.9 | 
2026-01-01T16:17:08 | step: 221500 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.410539127595257e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.44 | consumed tokens: 1814528000.0 | grad norm avg: 0.93 | grad norm last: 1.02 | 
2026-01-01T16:17:26 | step: 221600 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.4086921257548966e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.97 | consumed tokens: 1815347200.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-01T16:17:44 | step: 221700 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.4068449420155957e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.92 | consumed tokens: 1816166400.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-01T16:18:02 | step: 221800 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 2.4049979401752353e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.28 | consumed tokens: 1816985600.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-01T16:18:20 | step: 221900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.4031509383348748e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.81 | consumed tokens: 1817804800.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-01T16:18:38 | step: 222000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.4013039364945143e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.02 | consumed tokens: 1818624000.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-01T16:18:56 | step: 222100 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.3994571165530942e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.34 | consumed tokens: 1819443200.0 | grad norm avg: 0.93 | grad norm last: 0.87 | 
2026-01-01T16:19:14 | step: 222200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.397610296611674e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.09 | consumed tokens: 1820262400.0 | grad norm avg: 0.93 | grad norm last: 0.87 | 
2026-01-01T16:19:31 | step: 222300 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.395763476670254e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.89 | consumed tokens: 1821081600.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-01T16:19:49 | step: 222400 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 2.3939168386277743e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 4.25 | consumed tokens: 1821900800.0 | grad norm avg: 0.94 | grad norm last: 0.92 | 
2026-01-01T16:20:07 | step: 222500 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.392070018686354e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.11 | consumed tokens: 1822720000.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-01T16:20:25 | step: 222600 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.3902235625428148e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.31 | consumed tokens: 1823539200.0 | grad norm avg: 0.93 | grad norm last: 0.98 | 
2026-01-01T16:20:43 | step: 222700 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.388376924500335e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.0 | consumed tokens: 1824358400.0 | grad norm avg: 0.93 | grad norm last: 0.88 | 
2026-01-01T16:21:01 | step: 222800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.3865304683567956e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.0 | consumed tokens: 1825177600.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-01T16:21:19 | step: 222900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.3846840122132562e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.31 | consumed tokens: 1825996800.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-01T16:21:37 | step: 223000 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.382837737968657e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.8 | consumed tokens: 1826816000.0 | grad norm avg: 0.93 | grad norm last: 0.87 | 
2026-01-01T16:21:55 | step: 223100 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.380991463724058e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.19 | consumed tokens: 1827635200.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-01T16:22:13 | step: 223200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.379145189479459e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.81 | consumed tokens: 1828454400.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-01T16:22:31 | step: 223300 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 2.3772990971338004e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.42 | consumed tokens: 1829273600.0 | grad norm avg: 0.94 | grad norm last: 0.88 | 
2026-01-01T16:22:49 | step: 223400 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.3754530047881417e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.33 | consumed tokens: 1830092800.0 | grad norm avg: 0.94 | grad norm last: 0.98 | 
2026-01-01T16:23:07 | step: 223500 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.3736070943414234e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.58 | consumed tokens: 1830912000.0 | grad norm avg: 0.93 | grad norm last: 1.01 | 
2026-01-01T16:23:25 | step: 223600 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.371761183894705e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.12 | consumed tokens: 1831731200.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-01T16:23:43 | step: 223700 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.3699152734479867e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.06 | consumed tokens: 1832550400.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-01T16:24:00 | step: 223800 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 2.3680693630012684e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.66 | consumed tokens: 1833369600.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-01T16:24:18 | step: 223900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.3662238163524307e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 4.16 | consumed tokens: 1834188800.0 | grad norm avg: 0.94 | grad norm last: 0.9 | 
2026-01-01T16:24:36 | step: 224000 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.3643780878046528e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.2 | consumed tokens: 1835008000.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-01T16:24:54 | step: 224100 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.362532541155815e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.97 | consumed tokens: 1835827200.0 | grad norm avg: 0.94 | grad norm last: 0.94 | 
2026-01-01T16:25:12 | step: 224200 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.3606869945069775e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.03 | consumed tokens: 1836646400.0 | grad norm avg: 0.93 | grad norm last: 1.01 | 
2026-01-01T16:25:30 | step: 224300 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.3588416297570802e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.64 | consumed tokens: 1837465600.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-01T16:25:48 | step: 224400 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.356996265007183e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.52 | consumed tokens: 1838284800.0 | grad norm avg: 0.94 | grad norm last: 0.99 | 
2026-01-01T16:26:06 | step: 224500 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 2.355151082156226e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.25 | consumed tokens: 1839104000.0 | grad norm avg: 0.93 | grad norm last: 0.85 | 
2026-01-01T16:26:24 | step: 224600 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.353305899305269e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.89 | consumed tokens: 1839923200.0 | grad norm avg: 0.93 | grad norm last: 0.8 | 
2026-01-01T16:26:42 | step: 224700 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 2.3514607164543122e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.67 | consumed tokens: 1840742400.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-01T16:27:00 | step: 224800 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 2.3496157155022956e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.41 | consumed tokens: 1841561600.0 | grad norm avg: 0.93 | grad norm last: 0.99 | 
2026-01-01T16:27:18 | step: 224900 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.3477708964492194e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.66 | consumed tokens: 1842380800.0 | grad norm avg: 0.94 | grad norm last: 0.91 | 
2026-01-01T16:27:36 | step: 225000 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.3459260773961432e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.5 | consumed tokens: 1843200000.0 | grad norm avg: 0.94 | grad norm last: 0.9 | 
2026-01-01T16:27:55 | step: 225100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.344081258343067e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.77 | consumed tokens: 1844019200.0 | grad norm avg: 0.94 | grad norm last: 1.03 | 
2026-01-01T16:28:13 | step: 225200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.342236621188931e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.19 | consumed tokens: 1844838400.0 | grad norm avg: 0.94 | grad norm last: 0.91 | 
2026-01-01T16:28:31 | step: 225300 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.3403919840347953e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.95 | consumed tokens: 1845657600.0 | grad norm avg: 0.93 | grad norm last: 0.87 | 
2026-01-01T16:28:49 | step: 225400 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.3385475287795998e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.81 | consumed tokens: 1846476800.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-01T16:29:07 | step: 225500 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.3367030735244043e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.44 | consumed tokens: 1847296000.0 | grad norm avg: 0.94 | grad norm last: 0.95 | 
2026-01-01T16:29:25 | step: 225600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.3348588001681492e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.44 | consumed tokens: 1848115200.0 | grad norm avg: 0.94 | grad norm last: 1.01 | 
2026-01-01T16:29:43 | step: 225700 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.333014526811894e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.19 | consumed tokens: 1848934400.0 | grad norm avg: 0.93 | grad norm last: 0.84 | 
2026-01-01T16:30:01 | step: 225800 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 2.3311704353545792e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 4.03 | consumed tokens: 1849753600.0 | grad norm avg: 0.94 | grad norm last: 0.91 | 
2026-01-01T16:30:19 | step: 225900 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 2.3293263438972645e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.02 | consumed tokens: 1850572800.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-01T16:30:37 | step: 226000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.32748243433889e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.53 | consumed tokens: 1851392000.0 | grad norm avg: 0.94 | grad norm last: 0.99 | 
2026-01-01T16:30:55 | step: 226100 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.325638706679456e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.89 | consumed tokens: 1852211200.0 | grad norm avg: 0.95 | grad norm last: 0.91 | 
2026-01-01T16:31:13 | step: 226200 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.3237947971210815e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.94 | consumed tokens: 1853030400.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-01T16:31:31 | step: 226300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.3219512513605878e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.17 | consumed tokens: 1853849600.0 | grad norm avg: 0.93 | grad norm last: 0.98 | 
2026-01-01T16:31:49 | step: 226400 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.320107705600094e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.45 | consumed tokens: 1854668800.0 | grad norm avg: 0.94 | grad norm last: 0.97 | 
2026-01-01T16:32:07 | step: 226500 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 2.3182641598396003e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.8 | consumed tokens: 1855488000.0 | grad norm avg: 0.94 | grad norm last: 0.95 | 
2026-01-01T16:32:25 | step: 226600 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.3164209778769873e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.2 | consumed tokens: 1856307200.0 | grad norm avg: 0.94 | grad norm last: 0.92 | 
2026-01-01T16:32:43 | step: 226700 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.314577614015434e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.19 | consumed tokens: 1857126400.0 | grad norm avg: 0.94 | grad norm last: 0.87 | 
2026-01-01T16:33:01 | step: 226800 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.312734432052821e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.41 | consumed tokens: 1857945600.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-01T16:33:18 | step: 226900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.3108914319891483e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.36 | consumed tokens: 1858764800.0 | grad norm avg: 0.94 | grad norm last: 1.05 | 
2026-01-01T16:33:36 | step: 227000 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.309048613824416e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.08 | consumed tokens: 1859584000.0 | grad norm avg: 0.94 | grad norm last: 0.91 | 
2026-01-01T16:33:54 | step: 227100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.3072057956596836e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.25 | consumed tokens: 1860403200.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-01T16:34:12 | step: 227200 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.3053629774949513e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.09 | consumed tokens: 1861222400.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-01T16:34:30 | step: 227300 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.3035203412291594e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.89 | consumed tokens: 1862041600.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-01T16:34:48 | step: 227400 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.3016778868623078e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.42 | consumed tokens: 1862860800.0 | grad norm avg: 0.94 | grad norm last: 0.91 | 
2026-01-01T16:35:06 | step: 227500 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.2998354324954562e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.25 | consumed tokens: 1863680000.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-01T16:35:24 | step: 227600 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.297993160027545e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.27 | consumed tokens: 1864499200.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-01T16:35:42 | step: 227700 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.296151069458574e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.61 | consumed tokens: 1865318400.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-01T16:36:00 | step: 227800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.294308978889603e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.66 | consumed tokens: 1866137600.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-01T16:36:18 | step: 227900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.2924670702195726e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.89 | consumed tokens: 1866956800.0 | grad norm avg: 0.94 | grad norm last: 0.95 | 
2026-01-01T16:36:36 | step: 228000 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.290625161549542e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.73 | consumed tokens: 1867776000.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-01T16:36:54 | step: 228100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.288783434778452e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.72 | consumed tokens: 1868595200.0 | grad norm avg: 0.94 | grad norm last: 0.9 | 
2026-01-01T16:37:12 | step: 228200 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.286941889906302e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 4.09 | consumed tokens: 1869414400.0 | grad norm avg: 0.92 | grad norm last: 0.86 | 
2026-01-01T16:37:30 | step: 228300 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 2.2851003450341523e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.03 | consumed tokens: 1870233600.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-01T16:37:48 | step: 228400 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 2.2832589820609428e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.12 | consumed tokens: 1871052800.0 | grad norm avg: 0.94 | grad norm last: 1.01 | 
2026-01-01T16:38:06 | step: 228500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.2814178009866737e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.81 | consumed tokens: 1871872000.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-01T16:38:24 | step: 228600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.2795766199124046e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.61 | consumed tokens: 1872691200.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-01T16:38:42 | step: 228700 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.2777356207370758e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.88 | consumed tokens: 1873510400.0 | grad norm avg: 0.94 | grad norm last: 0.95 | 
2026-01-01T16:39:00 | step: 228800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.2758948034606874e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.84 | consumed tokens: 1874329600.0 | grad norm avg: 0.94 | grad norm last: 0.92 | 
2026-01-01T16:39:18 | step: 228900 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.2740541680832393e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.84 | consumed tokens: 1875148800.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-01T16:39:36 | step: 229000 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.2722135327057913e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.58 | consumed tokens: 1875968000.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-01T16:39:54 | step: 229100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.2703728973283432e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.45 | consumed tokens: 1876787200.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-01T16:40:12 | step: 229200 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.268532625748776e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.75 | consumed tokens: 1877606400.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-01T16:40:30 | step: 229300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 2.2666923541692086e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.0 | consumed tokens: 1878425600.0 | grad norm avg: 0.94 | grad norm last: 0.99 | 
2026-01-01T16:40:48 | step: 229400 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.2648522644885816e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.59 | consumed tokens: 1879244800.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-01T16:41:06 | step: 229500 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 2.263012356706895e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.05 | consumed tokens: 1880064000.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-01T16:41:24 | step: 229600 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.2611724489252083e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.06 | consumed tokens: 1880883200.0 | grad norm avg: 0.94 | grad norm last: 1.0 | 
2026-01-01T16:41:42 | step: 229700 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.259332723042462e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.53 | consumed tokens: 1881702400.0 | grad norm avg: 0.95 | grad norm last: 0.98 | 
2026-01-01T16:42:00 | step: 229800 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 2.257493179058656e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.39 | consumed tokens: 1882521600.0 | grad norm avg: 0.94 | grad norm last: 1.05 | 
2026-01-01T16:42:18 | step: 229900 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.2556536350748502e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.72 | consumed tokens: 1883340800.0 | grad norm avg: 0.94 | grad norm last: 1.01 | 
2026-01-01T16:42:36 | step: 230000 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 2.2538142729899846e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.98 | consumed tokens: 1884160000.0 | grad norm avg: 0.94 | grad norm last: 0.97 | 
2026-01-01T16:42:55 | step: 230100 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 2.2519750928040594e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.14 | consumed tokens: 1884979200.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-01T16:43:13 | step: 230200 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.2501360945170745e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.56 | consumed tokens: 1885798400.0 | grad norm avg: 0.94 | grad norm last: 0.98 | 
2026-01-01T16:43:31 | step: 230300 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.24829727812903e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.11 | consumed tokens: 1886617600.0 | grad norm avg: 0.93 | grad norm last: 0.98 | 
2026-01-01T16:43:49 | step: 230400 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.2464584617409855e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.67 | consumed tokens: 1887436800.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-01T16:44:07 | step: 230500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.2446198272518814e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.61 | consumed tokens: 1888256000.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-01T16:44:25 | step: 230600 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.2427813746617176e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.94 | consumed tokens: 1889075200.0 | grad norm avg: 0.94 | grad norm last: 0.88 | 
2026-01-01T16:44:42 | step: 230700 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.240943103970494e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.09 | consumed tokens: 1889894400.0 | grad norm avg: 0.93 | grad norm last: 1.0 | 
2026-01-01T16:45:00 | step: 230800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.2391048332792707e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.39 | consumed tokens: 1890713600.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-01T16:45:18 | step: 230900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.2372667444869876e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.2 | consumed tokens: 1891532800.0 | grad norm avg: 0.94 | grad norm last: 0.92 | 
2026-01-01T16:45:37 | step: 231000 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.235428837593645e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.11 | consumed tokens: 1892352000.0 | grad norm avg: 0.94 | grad norm last: 0.88 | 
2026-01-01T16:45:55 | step: 231100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.2335911125992425e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.61 | consumed tokens: 1893171200.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-01T16:46:13 | step: 231200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.2317535695037805e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.38 | consumed tokens: 1893990400.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-01T16:46:30 | step: 231300 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.2299160264083184e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.78 | consumed tokens: 1894809600.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-01T16:46:48 | step: 231400 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.2280786652117968e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.53 | consumed tokens: 1895628800.0 | grad norm avg: 0.92 | grad norm last: 1.0 | 
2026-01-01T16:47:06 | step: 231500 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.2262414859142154e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.44 | consumed tokens: 1896448000.0 | grad norm avg: 0.94 | grad norm last: 0.8 | 
2026-01-01T16:47:24 | step: 231600 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.2244044885155745e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.78 | consumed tokens: 1897267200.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-01T16:47:42 | step: 231700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.222567673015874e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.16 | consumed tokens: 1898086400.0 | grad norm avg: 0.92 | grad norm last: 0.98 | 
2026-01-01T16:48:00 | step: 231800 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.2207308575161733e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 4.06 | consumed tokens: 1898905600.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-01T16:48:18 | step: 231900 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.2188944058143534e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.73 | consumed tokens: 1899724800.0 | grad norm avg: 0.93 | grad norm last: 1.02 | 
2026-01-01T16:48:36 | step: 232000 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.2170579541125335e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.41 | consumed tokens: 1900544000.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-01T16:48:54 | step: 232100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.215221684309654e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.89 | consumed tokens: 1901363200.0 | grad norm avg: 0.95 | grad norm last: 0.91 | 
2026-01-01T16:49:12 | step: 232200 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.2133855964057148e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.36 | consumed tokens: 1902182400.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-01T16:49:30 | step: 232300 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 2.211549690400716e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.61 | consumed tokens: 1903001600.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-01T16:49:48 | step: 232400 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.2097139662946574e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.22 | consumed tokens: 1903820800.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-01T16:50:06 | step: 232500 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.2078784240875393e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.25 | consumed tokens: 1904640000.0 | grad norm avg: 0.93 | grad norm last: 1.0 | 
2026-01-01T16:50:24 | step: 232600 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.2060428818804212e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.53 | consumed tokens: 1905459200.0 | grad norm avg: 0.94 | grad norm last: 0.94 | 
2026-01-01T16:50:42 | step: 232700 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.2042077034711838e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.34 | consumed tokens: 1906278400.0 | grad norm avg: 0.93 | grad norm last: 1.02 | 
2026-01-01T16:51:00 | step: 232800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.2023725250619464e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.19 | consumed tokens: 1907097600.0 | grad norm avg: 0.93 | grad norm last: 0.97 | 
2026-01-01T16:51:18 | step: 232900 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.2005375285516493e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.39 | consumed tokens: 1907916800.0 | grad norm avg: 0.94 | grad norm last: 0.92 | 
2026-01-01T16:51:36 | step: 233000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.1987027139402926e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.22 | consumed tokens: 1908736000.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-01T16:51:54 | step: 233100 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.1968680812278762e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.25 | consumed tokens: 1909555200.0 | grad norm avg: 0.95 | grad norm last: 0.98 | 
2026-01-01T16:52:12 | step: 233200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.1950336304144002e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.16 | consumed tokens: 1910374400.0 | grad norm avg: 0.94 | grad norm last: 0.91 | 
2026-01-01T16:52:30 | step: 233300 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.1931993614998646e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.44 | consumed tokens: 1911193600.0 | grad norm avg: 0.94 | grad norm last: 0.86 | 
2026-01-01T16:52:48 | step: 233400 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.1913652744842693e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.16 | consumed tokens: 1912012800.0 | grad norm avg: 0.95 | grad norm last: 0.95 | 
2026-01-01T16:53:06 | step: 233500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.1895313693676144e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.69 | consumed tokens: 1912832000.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-01T16:53:24 | step: 233600 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 2.1876974642509595e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.94 | consumed tokens: 1913651200.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-01T16:53:42 | step: 233700 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.1858639229321852e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.72 | consumed tokens: 1914470400.0 | grad norm avg: 0.93 | grad norm last: 0.84 | 
2026-01-01T16:54:00 | step: 233800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.1840305635123514e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.81 | consumed tokens: 1915289600.0 | grad norm avg: 0.94 | grad norm last: 0.89 | 
2026-01-01T16:54:18 | step: 233900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.1821972040925175e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.61 | consumed tokens: 1916108800.0 | grad norm avg: 0.95 | grad norm last: 0.95 | 
2026-01-01T16:54:36 | step: 234000 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.1803642084705643e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.47 | consumed tokens: 1916928000.0 | grad norm avg: 0.94 | grad norm last: 0.92 | 
2026-01-01T16:54:54 | step: 234100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 2.1785312128486112e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.83 | consumed tokens: 1917747200.0 | grad norm avg: 0.94 | grad norm last: 0.87 | 
2026-01-01T16:55:12 | step: 234200 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.1766985810245387e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.06 | consumed tokens: 1918566400.0 | grad norm avg: 0.95 | grad norm last: 0.92 | 
2026-01-01T16:55:30 | step: 234300 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 2.1748659492004663e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.75 | consumed tokens: 1919385600.0 | grad norm avg: 0.94 | grad norm last: 0.97 | 
2026-01-01T16:55:48 | step: 234400 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.1730336811742745e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 4.41 | consumed tokens: 1920204800.0 | grad norm avg: 0.93 | grad norm last: 0.88 | 
2026-01-01T16:56:06 | step: 234500 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.1712014131480828e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.78 | consumed tokens: 1921024000.0 | grad norm avg: 0.94 | grad norm last: 0.95 | 
2026-01-01T16:56:24 | step: 234600 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.1693695089197718e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.72 | consumed tokens: 1921843200.0 | grad norm avg: 0.94 | grad norm last: 1.03 | 
2026-01-01T16:56:42 | step: 234700 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.1675376046914607e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.75 | consumed tokens: 1922662400.0 | grad norm avg: 0.94 | grad norm last: 0.94 | 
2026-01-01T16:57:00 | step: 234800 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.16570588236209e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.2 | consumed tokens: 1923481600.0 | grad norm avg: 0.94 | grad norm last: 0.87 | 
2026-01-01T16:57:18 | step: 234900 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 2.1638745238306e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.77 | consumed tokens: 1924300800.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-01T16:57:36 | step: 235000 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 2.16204316529911e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.53 | consumed tokens: 1925120000.0 | grad norm avg: 0.94 | grad norm last: 0.9 | 
2026-01-01T16:57:55 | step: 235100 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.160212170565501e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.06 | consumed tokens: 1925939200.0 | grad norm avg: 0.95 | grad norm last: 0.91 | 
2026-01-01T16:58:13 | step: 235200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.1583811758318916e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.73 | consumed tokens: 1926758400.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-01T16:58:31 | step: 235300 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.156550544896163e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.14 | consumed tokens: 1927577600.0 | grad norm avg: 0.94 | grad norm last: 0.94 | 
2026-01-01T16:58:49 | step: 235400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.154720095859375e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.58 | consumed tokens: 1928396800.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-01T16:59:07 | step: 235500 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.1528896468225867e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.39 | consumed tokens: 1929216000.0 | grad norm avg: 0.94 | grad norm last: 1.02 | 
2026-01-01T16:59:24 | step: 235600 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.1510595615836792e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.67 | consumed tokens: 1930035200.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-01T16:59:42 | step: 235700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.149229658243712e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.44 | consumed tokens: 1930854400.0 | grad norm avg: 0.94 | grad norm last: 0.91 | 
2026-01-01T17:00:00 | step: 235800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.1473999368026853e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.06 | consumed tokens: 1931673600.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-01T17:00:18 | step: 235900 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.1455702153616585e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.12 | consumed tokens: 1932492800.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-01T17:00:36 | step: 236000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.1437408577185124e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.14 | consumed tokens: 1933312000.0 | grad norm avg: 0.94 | grad norm last: 0.97 | 
2026-01-01T17:00:54 | step: 236100 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.1419116819743067e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.94 | consumed tokens: 1934131200.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-01T17:01:12 | step: 236200 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 2.1400828700279817e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.08 | consumed tokens: 1934950400.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-01T17:01:30 | step: 236300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.1382540580816567e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.23 | consumed tokens: 1935769600.0 | grad norm avg: 0.94 | grad norm last: 0.98 | 
2026-01-01T17:01:48 | step: 236400 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.136425428034272e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.5 | consumed tokens: 1936588800.0 | grad norm avg: 0.93 | grad norm last: 0.84 | 
2026-01-01T17:02:06 | step: 236500 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.134597161784768e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.48 | consumed tokens: 1937408000.0 | grad norm avg: 0.94 | grad norm last: 1.0 | 
2026-01-01T17:02:24 | step: 236600 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.132768895535264e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.47 | consumed tokens: 1938227200.0 | grad norm avg: 0.94 | grad norm last: 0.97 | 
2026-01-01T17:02:42 | step: 236700 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.130940993083641e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.36 | consumed tokens: 1939046400.0 | grad norm avg: 0.94 | grad norm last: 0.98 | 
2026-01-01T17:03:00 | step: 236800 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.129113272530958e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.48 | consumed tokens: 1939865600.0 | grad norm avg: 0.95 | grad norm last: 1.03 | 
2026-01-01T17:03:18 | step: 236900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.1272857338772155e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.7 | consumed tokens: 1940684800.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-01T17:03:36 | step: 237000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.1254583771224134e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.3 | consumed tokens: 1941504000.0 | grad norm avg: 0.94 | grad norm last: 0.99 | 
2026-01-01T17:03:54 | step: 237100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.1236312022665516e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.44 | consumed tokens: 1942323200.0 | grad norm avg: 0.94 | grad norm last: 0.89 | 
2026-01-01T17:04:12 | step: 237200 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.12180420930963e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.02 | consumed tokens: 1943142400.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-01T17:04:30 | step: 237300 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.119977398251649e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.31 | consumed tokens: 1943961600.0 | grad norm avg: 0.95 | grad norm last: 0.85 | 
2026-01-01T17:04:48 | step: 237400 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.1181509509915486e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.83 | consumed tokens: 1944780800.0 | grad norm avg: 0.95 | grad norm last: 1.04 | 
2026-01-01T17:05:06 | step: 237500 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 2.1163246856303886e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.05 | consumed tokens: 1945600000.0 | grad norm avg: 0.95 | grad norm last: 0.91 | 
2026-01-01T17:05:24 | step: 237600 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.114498602168169e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.91 | consumed tokens: 1946419200.0 | grad norm avg: 0.94 | grad norm last: 1.03 | 
2026-01-01T17:05:42 | step: 237700 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.1126727006048895e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.59 | consumed tokens: 1947238400.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-01T17:06:00 | step: 237800 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.1108469809405506e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.41 | consumed tokens: 1948057600.0 | grad norm avg: 0.94 | grad norm last: 0.97 | 
2026-01-01T17:06:18 | step: 237900 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 2.1090216250740923e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.56 | consumed tokens: 1948876800.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-01T17:06:35 | step: 238000 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 2.107196269207634e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.91 | consumed tokens: 1949696000.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-01T17:06:53 | step: 238100 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.1053712771390565e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.69 | consumed tokens: 1950515200.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-01T17:07:11 | step: 238200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.1035464669694193e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.59 | consumed tokens: 1951334400.0 | grad norm avg: 0.95 | grad norm last: 0.91 | 
2026-01-01T17:07:29 | step: 238300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.1017218386987224e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.61 | consumed tokens: 1952153600.0 | grad norm avg: 0.94 | grad norm last: 0.9 | 
2026-01-01T17:07:47 | step: 238400 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.0998975742259063e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.2 | consumed tokens: 1952972800.0 | grad norm avg: 0.94 | grad norm last: 0.86 | 
2026-01-01T17:08:05 | step: 238500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 2.09807330975309e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.97 | consumed tokens: 1953792000.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-01T17:08:23 | step: 238600 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.0962494090781547e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.11 | consumed tokens: 1954611200.0 | grad norm avg: 0.94 | grad norm last: 0.97 | 
2026-01-01T17:08:41 | step: 238700 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.0944256903021596e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.66 | consumed tokens: 1955430400.0 | grad norm avg: 0.95 | grad norm last: 1.03 | 
2026-01-01T17:08:59 | step: 238800 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 2.0926023353240453e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.69 | consumed tokens: 1956249600.0 | grad norm avg: 0.94 | grad norm last: 0.74 | 
2026-01-01T17:09:17 | step: 238900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.090778980345931e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.02 | consumed tokens: 1957068800.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-01T17:09:35 | step: 239000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.0889559891656972e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.39 | consumed tokens: 1957888000.0 | grad norm avg: 0.93 | grad norm last: 0.81 | 
2026-01-01T17:09:53 | step: 239100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.087133179884404e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.56 | consumed tokens: 1958707200.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-01T17:10:11 | step: 239200 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.085310552502051e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.91 | consumed tokens: 1959526400.0 | grad norm avg: 0.94 | grad norm last: 0.9 | 
2026-01-01T17:10:29 | step: 239300 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.0834882889175788e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.38 | consumed tokens: 1960345600.0 | grad norm avg: 0.94 | grad norm last: 0.9 | 
2026-01-01T17:10:47 | step: 239400 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.081666207232047e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.27 | consumed tokens: 1961164800.0 | grad norm avg: 0.94 | grad norm last: 0.94 | 
2026-01-01T17:11:05 | step: 239500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.0798443074454553e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 4.06 | consumed tokens: 1961984000.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-01T17:11:23 | step: 239600 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.078022589557804e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.86 | consumed tokens: 1962803200.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-01T17:11:41 | step: 239700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.0762012354680337e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.22 | consumed tokens: 1963622400.0 | grad norm avg: 0.95 | grad norm last: 1.32 | 
2026-01-01T17:11:59 | step: 239800 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.0743798813782632e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.64 | consumed tokens: 1964441600.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-01T17:12:17 | step: 239900 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.072559072985314e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.59 | consumed tokens: 1965260800.0 | grad norm avg: 0.93 | grad norm last: 0.87 | 
2026-01-01T17:12:35 | step: 240000 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.0707382645923644e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.14 | consumed tokens: 1966080000.0 | grad norm avg: 0.94 | grad norm last: 1.01 | 
2026-01-01T17:12:54 | step: 240100 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.0689178199972957e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.62 | consumed tokens: 1966899200.0 | grad norm avg: 0.93 | grad norm last: 0.85 | 
2026-01-01T17:13:12 | step: 240200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.0670975573011674e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.27 | consumed tokens: 1967718400.0 | grad norm avg: 0.95 | grad norm last: 0.89 | 
2026-01-01T17:13:30 | step: 240300 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.0652774765039794e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.45 | consumed tokens: 1968537600.0 | grad norm avg: 0.95 | grad norm last: 0.88 | 
2026-01-01T17:13:48 | step: 240400 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.063457759504672e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.0 | consumed tokens: 1969356800.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-01T17:14:06 | step: 240500 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.0616382244043052e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.41 | consumed tokens: 1970176000.0 | grad norm avg: 0.94 | grad norm last: 0.91 | 
2026-01-01T17:14:24 | step: 240600 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.059819053101819e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.17 | consumed tokens: 1970995200.0 | grad norm avg: 0.94 | grad norm last: 1.01 | 
2026-01-01T17:14:42 | step: 240700 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.0579998817993328e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.14 | consumed tokens: 1971814400.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-01T17:15:00 | step: 240800 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.0561810742947273e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.8 | consumed tokens: 1972633600.0 | grad norm avg: 1.0 | grad norm last: 0.91 | 
2026-01-01T17:15:18 | step: 240900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.0543626305880025e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.45 | consumed tokens: 1973452800.0 | grad norm avg: 1.14 | grad norm last: 0.9 | 
2026-01-01T17:15:36 | step: 241000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.0525441868812777e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.83 | consumed tokens: 1974272000.0 | grad norm avg: 0.96 | grad norm last: 0.99 | 
2026-01-01T17:15:54 | step: 241100 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.0507261069724336e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.25 | consumed tokens: 1975091200.0 | grad norm avg: 0.98 | grad norm last: 0.92 | 
2026-01-01T17:16:12 | step: 241200 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.0489083908614703e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.53 | consumed tokens: 1975910400.0 | grad norm avg: 0.95 | grad norm last: 0.93 | 
2026-01-01T17:16:30 | step: 241300 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.0470908566494472e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.59 | consumed tokens: 1976729600.0 | grad norm avg: 0.95 | grad norm last: 0.94 | 
2026-01-01T17:16:48 | step: 241400 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 2.0452735043363646e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.45 | consumed tokens: 1977548800.0 | grad norm avg: 0.95 | grad norm last: 0.83 | 
2026-01-01T17:17:06 | step: 241500 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.0434563339222223e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.28 | consumed tokens: 1978368000.0 | grad norm avg: 0.94 | grad norm last: 0.92 | 
2026-01-01T17:17:24 | step: 241600 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.0416395273059607e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.88 | consumed tokens: 1979187200.0 | grad norm avg: 0.96 | grad norm last: 0.94 | 
2026-01-01T17:17:42 | step: 241700 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.0398230844875798e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.3 | consumed tokens: 1980006400.0 | grad norm avg: 0.95 | grad norm last: 0.89 | 
2026-01-01T17:18:00 | step: 241800 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.038006641669199e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.0 | consumed tokens: 1980825600.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-01T17:18:18 | step: 241900 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.036190744547639e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.17 | consumed tokens: 1981644800.0 | grad norm avg: 0.94 | grad norm last: 0.97 | 
2026-01-01T17:18:35 | step: 242000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.0343748474260792e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.98 | consumed tokens: 1982464000.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-01T17:18:53 | step: 242100 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.0325593141024e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.92 | consumed tokens: 1983283200.0 | grad norm avg: 0.94 | grad norm last: 0.9 | 
2026-01-01T17:19:11 | step: 242200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.0307439626776613e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.44 | consumed tokens: 1984102400.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-01T17:19:29 | step: 242300 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.0289289750508033e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.7 | consumed tokens: 1984921600.0 | grad norm avg: 0.93 | grad norm last: 0.99 | 
2026-01-01T17:19:47 | step: 242400 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 2.0271141693228856e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.39 | consumed tokens: 1985740800.0 | grad norm avg: 0.95 | grad norm last: 0.89 | 
2026-01-01T17:20:05 | step: 242500 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 2.0252997273928486e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.62 | consumed tokens: 1986560000.0 | grad norm avg: 0.94 | grad norm last: 0.99 | 
2026-01-01T17:20:23 | step: 242600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 2.023485467361752e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.88 | consumed tokens: 1987379200.0 | grad norm avg: 0.96 | grad norm last: 0.97 | 
2026-01-01T17:20:41 | step: 242700 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 2.021671571128536e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.72 | consumed tokens: 1988198400.0 | grad norm avg: 0.94 | grad norm last: 0.87 | 
2026-01-01T17:20:59 | step: 242800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.0198578567942604e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.95 | consumed tokens: 1989017600.0 | grad norm avg: 0.95 | grad norm last: 1.09 | 
2026-01-01T17:21:17 | step: 242900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.0180443243589252e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.28 | consumed tokens: 1989836800.0 | grad norm avg: 0.94 | grad norm last: 1.04 | 
2026-01-01T17:21:35 | step: 243000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.0162311557214707e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 4.12 | consumed tokens: 1990656000.0 | grad norm avg: 0.94 | grad norm last: 0.9 | 
2026-01-01T17:21:53 | step: 243100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.0144181689829566e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.02 | consumed tokens: 1991475200.0 | grad norm avg: 0.94 | grad norm last: 1.01 | 
2026-01-01T17:22:11 | step: 243200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 2.012605546042323e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.66 | consumed tokens: 1992294400.0 | grad norm avg: 0.95 | grad norm last: 0.93 | 
2026-01-01T17:22:29 | step: 243300 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 2.01079310500063e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.83 | consumed tokens: 1993113600.0 | grad norm avg: 0.95 | grad norm last: 0.89 | 
2026-01-01T17:22:47 | step: 243400 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 2.0089810277568176e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.22 | consumed tokens: 1993932800.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-01T17:23:05 | step: 243500 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 2.0071691324119456e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.0 | consumed tokens: 1994752000.0 | grad norm avg: 0.95 | grad norm last: 0.95 | 
2026-01-01T17:23:23 | step: 243600 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.0053576008649543e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.38 | consumed tokens: 1995571200.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-01T17:23:41 | step: 243700 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 2.0035462512169033e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 4.03 | consumed tokens: 1996390400.0 | grad norm avg: 0.95 | grad norm last: 0.98 | 
2026-01-01T17:23:59 | step: 243800 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 2.001735265366733e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.66 | consumed tokens: 1997209600.0 | grad norm avg: 0.95 | grad norm last: 0.98 | 
2026-01-01T17:24:17 | step: 243900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.9999244614155032e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.16 | consumed tokens: 1998028800.0 | grad norm avg: 0.95 | grad norm last: 0.91 | 
2026-01-01T17:24:35 | step: 244000 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.998114021262154e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.5 | consumed tokens: 1998848000.0 | grad norm avg: 0.95 | grad norm last: 1.05 | 
2026-01-01T17:24:53 | step: 244100 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.996303763007745e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.84 | consumed tokens: 1999667200.0 | grad norm avg: 0.94 | grad norm last: 0.98 | 
2026-01-01T17:25:11 | step: 244200 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.994493868551217e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.92 | consumed tokens: 2000486400.0 | grad norm avg: 0.95 | grad norm last: 0.97 | 
2026-01-01T17:25:29 | step: 244300 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 1.9926841559936292e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.86 | consumed tokens: 2001305600.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-01T17:25:47 | step: 244400 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 1.9908748072339222e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.09 | consumed tokens: 2002124800.0 | grad norm avg: 0.94 | grad norm last: 0.87 | 
2026-01-01T17:26:05 | step: 244500 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.9890658222720958e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.72 | consumed tokens: 2002944000.0 | grad norm avg: 0.95 | grad norm last: 0.94 | 
2026-01-01T17:26:23 | step: 244600 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.9872570192092098e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.38 | consumed tokens: 2003763200.0 | grad norm avg: 0.95 | grad norm last: 0.96 | 
2026-01-01T17:26:41 | step: 244700 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.9854483980452642e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.77 | consumed tokens: 2004582400.0 | grad norm avg: 0.95 | grad norm last: 0.97 | 
2026-01-01T17:26:59 | step: 244800 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.9836401406791992e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.38 | consumed tokens: 2005401600.0 | grad norm avg: 0.95 | grad norm last: 0.92 | 
2026-01-01T17:27:17 | step: 244900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.981832247111015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.56 | consumed tokens: 2006220800.0 | grad norm avg: 0.95 | grad norm last: 0.9 | 
2026-01-01T17:27:35 | step: 245000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.980024535441771e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.88 | consumed tokens: 2007040000.0 | grad norm avg: 0.95 | grad norm last: 0.99 | 
2026-01-01T17:27:54 | step: 245100 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.978217187570408e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.12 | consumed tokens: 2007859200.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-01T17:28:12 | step: 245200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.9764100215979852e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.7 | consumed tokens: 2008678400.0 | grad norm avg: 0.94 | grad norm last: 1.01 | 
2026-01-01T17:28:31 | step: 245300 | train samples/s: 95.9 | train mfu (16-bit): -1.0 | lr mean: 1.974603219423443e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.12 | consumed tokens: 2009497600.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-01T17:28:49 | step: 245400 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.9727967810467817e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.47 | consumed tokens: 2010316800.0 | grad norm avg: 0.94 | grad norm last: 0.98 | 
2026-01-01T17:29:07 | step: 245500 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.9709905245690607e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.48 | consumed tokens: 2011136000.0 | grad norm avg: 0.94 | grad norm last: 0.9 | 
2026-01-01T17:29:25 | step: 245600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.96918444999028e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.12 | consumed tokens: 2011955200.0 | grad norm avg: 0.94 | grad norm last: 0.87 | 
2026-01-01T17:29:43 | step: 245700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.9673789211083204e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.11 | consumed tokens: 2012774400.0 | grad norm avg: 0.95 | grad norm last: 1.0 | 
2026-01-01T17:30:01 | step: 245800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.965573574125301e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.91 | consumed tokens: 2013593600.0 | grad norm avg: 0.94 | grad norm last: 1.01 | 
2026-01-01T17:30:18 | step: 245900 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.9637684090412222e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.25 | consumed tokens: 2014412800.0 | grad norm avg: 0.95 | grad norm last: 1.0 | 
2026-01-01T17:30:37 | step: 246000 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.961963607755024e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.88 | consumed tokens: 2015232000.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-01T17:30:54 | step: 246100 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.9601591702667065e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.36 | consumed tokens: 2016051200.0 | grad norm avg: 0.95 | grad norm last: 0.95 | 
2026-01-01T17:31:12 | step: 246200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.9583550965762697e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.59 | consumed tokens: 2016870400.0 | grad norm avg: 0.94 | grad norm last: 0.9 | 
2026-01-01T17:31:30 | step: 246300 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.9565512047847733e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.28 | consumed tokens: 2017689600.0 | grad norm avg: 0.95 | grad norm last: 1.02 | 
2026-01-01T17:31:48 | step: 246400 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 1.9547474948922172e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.36 | consumed tokens: 2018508800.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-01T17:32:06 | step: 246500 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.9529443306964822e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.64 | consumed tokens: 2019328000.0 | grad norm avg: 0.95 | grad norm last: 1.04 | 
2026-01-01T17:32:24 | step: 246600 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 1.9511413483996876e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.94 | consumed tokens: 2020147200.0 | grad norm avg: 0.96 | grad norm last: 0.92 | 
2026-01-01T17:32:42 | step: 246700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.9493385480018333e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.83 | consumed tokens: 2020966400.0 | grad norm avg: 0.95 | grad norm last: 0.96 | 
2026-01-01T17:33:01 | step: 246800 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.9475362933008e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.89 | consumed tokens: 2021785600.0 | grad norm avg: 0.94 | grad norm last: 0.99 | 
2026-01-01T17:33:18 | step: 246900 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.945734220498707e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.25 | consumed tokens: 2022604800.0 | grad norm avg: 0.95 | grad norm last: 0.96 | 
2026-01-01T17:33:36 | step: 247000 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.943932511494495e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.19 | consumed tokens: 2023424000.0 | grad norm avg: 0.95 | grad norm last: 0.98 | 
2026-01-01T17:33:54 | step: 247100 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.942130984389223e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.14 | consumed tokens: 2024243200.0 | grad norm avg: 0.95 | grad norm last: 0.87 | 
2026-01-01T17:34:12 | step: 247200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.940329821081832e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.83 | consumed tokens: 2025062400.0 | grad norm avg: 0.96 | grad norm last: 0.99 | 
2026-01-01T17:34:30 | step: 247300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.9385290215723217e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.2 | consumed tokens: 2025881600.0 | grad norm avg: 0.94 | grad norm last: 0.89 | 
2026-01-01T17:34:48 | step: 247400 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.9367284039617516e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.47 | consumed tokens: 2026700800.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-01T17:35:06 | step: 247500 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.9349281501490623e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.23 | consumed tokens: 2027520000.0 | grad norm avg: 0.95 | grad norm last: 0.95 | 
2026-01-01T17:35:24 | step: 247600 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.9331282601342537e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.36 | consumed tokens: 2028339200.0 | grad norm avg: 0.94 | grad norm last: 0.9 | 
2026-01-01T17:35:42 | step: 247700 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.9313287339173257e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.17 | consumed tokens: 2029158400.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-01T17:36:00 | step: 247800 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.9295293895993382e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.11 | consumed tokens: 2029977600.0 | grad norm avg: 0.95 | grad norm last: 0.92 | 
2026-01-01T17:36:18 | step: 247900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.9277304090792313e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.78 | consumed tokens: 2030796800.0 | grad norm avg: 0.95 | grad norm last: 1.02 | 
2026-01-01T17:36:36 | step: 248000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.9259317923570052e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.3 | consumed tokens: 2031616000.0 | grad norm avg: 0.95 | grad norm last: 0.95 | 
2026-01-01T17:36:54 | step: 248100 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.9241333575337194e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.97 | consumed tokens: 2032435200.0 | grad norm avg: 0.95 | grad norm last: 0.91 | 
2026-01-01T17:37:12 | step: 248200 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.9223354684072547e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.94 | consumed tokens: 2033254400.0 | grad norm avg: 0.95 | grad norm last: 0.89 | 
2026-01-01T17:37:30 | step: 248300 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.9205377611797303e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 4.16 | consumed tokens: 2034073600.0 | grad norm avg: 0.95 | grad norm last: 0.91 | 
2026-01-01T17:37:48 | step: 248400 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.9187402358511463e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.03 | consumed tokens: 2034892800.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-01T17:38:06 | step: 248500 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.9169432562193833e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.34 | consumed tokens: 2035712000.0 | grad norm avg: 0.94 | grad norm last: 0.86 | 
2026-01-01T17:38:24 | step: 248600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.9151464584865607e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.05 | consumed tokens: 2036531200.0 | grad norm avg: 0.96 | grad norm last: 0.97 | 
2026-01-01T17:38:42 | step: 248700 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.913350024551619e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.2 | consumed tokens: 2037350400.0 | grad norm avg: 0.94 | grad norm last: 1.0 | 
2026-01-01T17:39:00 | step: 248800 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.9115539544145577e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.94 | consumed tokens: 2038169600.0 | grad norm avg: 0.94 | grad norm last: 1.03 | 
2026-01-01T17:39:18 | step: 248900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.909758066176437e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.61 | consumed tokens: 2038988800.0 | grad norm avg: 0.94 | grad norm last: 0.98 | 
2026-01-01T17:39:36 | step: 249000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.907962723635137e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.62 | consumed tokens: 2039808000.0 | grad norm avg: 0.95 | grad norm last: 0.96 | 
2026-01-01T17:39:54 | step: 249100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.9061675629927777e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.41 | consumed tokens: 2040627200.0 | grad norm avg: 0.96 | grad norm last: 0.96 | 
2026-01-01T17:40:12 | step: 249200 | train samples/s: 95.7 | train mfu (16-bit): -1.0 | lr mean: 1.904372766148299e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.06 | consumed tokens: 2041446400.0 | grad norm avg: 0.95 | grad norm last: 0.99 | 
2026-01-01T17:40:30 | step: 249300 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.902578333101701e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.09 | consumed tokens: 2042265600.0 | grad norm avg: 0.95 | grad norm last: 0.96 | 
2026-01-01T17:40:48 | step: 249400 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.9007840819540434e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.17 | consumed tokens: 2043084800.0 | grad norm avg: 0.95 | grad norm last: 1.04 | 
2026-01-01T17:41:06 | step: 249500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.8989903765032068e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.66 | consumed tokens: 2043904000.0 | grad norm avg: 0.95 | grad norm last: 0.95 | 
2026-01-01T17:41:24 | step: 249600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.8971968529513106e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.05 | consumed tokens: 2044723200.0 | grad norm avg: 0.95 | grad norm last: 0.84 | 
2026-01-01T17:41:42 | step: 249700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.895403693197295e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.22 | consumed tokens: 2045542400.0 | grad norm avg: 0.94 | grad norm last: 0.99 | 
2026-01-01T17:42:00 | step: 249800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.8936108972411603e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.7 | consumed tokens: 2046361600.0 | grad norm avg: 0.96 | grad norm last: 0.95 | 
2026-01-01T17:42:18 | step: 249900 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.891818283183966e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.91 | consumed tokens: 2047180800.0 | grad norm avg: 0.95 | grad norm last: 0.86 | 
2026-01-01T17:42:36 | step: 250000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.8900262148235925e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.89 | consumed tokens: 2048000000.0 | grad norm avg: 0.96 | grad norm last: 0.93 | 
2026-01-01T17:42:56 | step: 250100 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.8882343283621594e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.28 | consumed tokens: 2048819200.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-01T17:43:14 | step: 250200 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.886442805698607e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.52 | consumed tokens: 2049638400.0 | grad norm avg: 0.96 | grad norm last: 0.84 | 
2026-01-01T17:43:32 | step: 250300 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.8846516468329355e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.42 | consumed tokens: 2050457600.0 | grad norm avg: 0.95 | grad norm last: 0.88 | 
2026-01-01T17:43:50 | step: 250400 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.8828608517651446e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.45 | consumed tokens: 2051276800.0 | grad norm avg: 0.95 | grad norm last: 0.89 | 
2026-01-01T17:44:08 | step: 250500 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.8810704204952344e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.3 | consumed tokens: 2052096000.0 | grad norm avg: 0.94 | grad norm last: 0.9 | 
2026-01-01T17:44:26 | step: 250600 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.879280353023205e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.0 | consumed tokens: 2052915200.0 | grad norm avg: 0.94 | grad norm last: 0.97 | 
2026-01-01T17:44:44 | step: 250700 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.8774904674501158e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.81 | consumed tokens: 2053734400.0 | grad norm avg: 0.95 | grad norm last: 0.98 | 
2026-01-01T17:45:02 | step: 250800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.8757011275738478e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.05 | consumed tokens: 2054553600.0 | grad norm avg: 0.95 | grad norm last: 0.91 | 
2026-01-01T17:45:20 | step: 250900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.87391196959652e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.56 | consumed tokens: 2055372800.0 | grad norm avg: 0.95 | grad norm last: 1.01 | 
2026-01-01T17:45:38 | step: 251000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.872123175417073e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 4.28 | consumed tokens: 2056192000.0 | grad norm avg: 0.94 | grad norm last: 1.02 | 
2026-01-01T17:45:56 | step: 251100 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 1.8703347450355068e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.91 | consumed tokens: 2057011200.0 | grad norm avg: 0.96 | grad norm last: 0.87 | 
2026-01-01T17:46:13 | step: 251200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.8685466784518212e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.84 | consumed tokens: 2057830400.0 | grad norm avg: 0.95 | grad norm last: 0.93 | 
2026-01-01T17:46:31 | step: 251300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.8667589756660163e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.86 | consumed tokens: 2058649600.0 | grad norm avg: 0.97 | grad norm last: 0.85 | 
2026-01-01T17:46:49 | step: 251400 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.8649716366780922e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.62 | consumed tokens: 2059468800.0 | grad norm avg: 0.95 | grad norm last: 0.94 | 
2026-01-01T17:47:07 | step: 251500 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.8631846614880487e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.28 | consumed tokens: 2060288000.0 | grad norm avg: 0.96 | grad norm last: 0.95 | 
2026-01-01T17:47:25 | step: 251600 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.861398050095886e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.25 | consumed tokens: 2061107200.0 | grad norm avg: 0.95 | grad norm last: 0.84 | 
2026-01-01T17:47:43 | step: 251700 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 1.8596116206026636e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.86 | consumed tokens: 2061926400.0 | grad norm avg: 0.95 | grad norm last: 0.87 | 
2026-01-01T17:48:01 | step: 251800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.8578257368062623e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.42 | consumed tokens: 2062745600.0 | grad norm avg: 0.94 | grad norm last: 0.97 | 
2026-01-01T17:48:19 | step: 251900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.8560400349088013e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.38 | consumed tokens: 2063564800.0 | grad norm avg: 0.96 | grad norm last: 0.9 | 
2026-01-01T17:48:37 | step: 252000 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.8542548787081614e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.69 | consumed tokens: 2064384000.0 | grad norm avg: 0.94 | grad norm last: 1.03 | 
2026-01-01T17:48:56 | step: 252100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.852469904406462e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 4.16 | consumed tokens: 2065203200.0 | grad norm avg: 0.96 | grad norm last: 0.92 | 
2026-01-01T17:49:13 | step: 252200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.850685293902643e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.95 | consumed tokens: 2066022400.0 | grad norm avg: 0.95 | grad norm last: 0.89 | 
2026-01-01T17:49:31 | step: 252300 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.8489012290956452e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.58 | consumed tokens: 2066841600.0 | grad norm avg: 0.96 | grad norm last: 0.94 | 
2026-01-01T17:49:49 | step: 252400 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.8471173461875878e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.67 | consumed tokens: 2067660800.0 | grad norm avg: 0.96 | grad norm last: 1.0 | 
2026-01-01T17:50:07 | step: 252500 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.845333827077411e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.08 | consumed tokens: 2068480000.0 | grad norm avg: 0.95 | grad norm last: 0.95 | 
2026-01-01T17:50:25 | step: 252600 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.843550671765115e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.28 | consumed tokens: 2069299200.0 | grad norm avg: 0.95 | grad norm last: 0.99 | 
2026-01-01T17:50:43 | step: 252700 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.8417680621496402e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.03 | consumed tokens: 2070118400.0 | grad norm avg: 0.95 | grad norm last: 0.96 | 
2026-01-01T17:51:01 | step: 252800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.8399856344331056e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.86 | consumed tokens: 2070937600.0 | grad norm avg: 0.95 | grad norm last: 0.98 | 
2026-01-01T17:51:19 | step: 252900 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 1.8382035705144517e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.94 | consumed tokens: 2071756800.0 | grad norm avg: 0.95 | grad norm last: 1.04 | 
2026-01-01T17:51:37 | step: 253000 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 1.8364218703936785e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.75 | consumed tokens: 2072576000.0 | grad norm avg: 0.95 | grad norm last: 0.93 | 
2026-01-01T17:51:55 | step: 253100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 1.834640534070786e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.25 | consumed tokens: 2073395200.0 | grad norm avg: 0.95 | grad norm last: 0.97 | 
2026-01-01T17:52:13 | step: 253200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.8328597434447147e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.73 | consumed tokens: 2074214400.0 | grad norm avg: 0.95 | grad norm last: 0.99 | 
2026-01-01T17:52:31 | step: 253300 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 1.8310791347175837e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.38 | consumed tokens: 2075033600.0 | grad norm avg: 0.95 | grad norm last: 0.99 | 
2026-01-01T17:52:49 | step: 253400 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.8292988897883333e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.77 | consumed tokens: 2075852800.0 | grad norm avg: 0.95 | grad norm last: 0.92 | 
2026-01-01T17:53:07 | step: 253500 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 1.8275190086569637e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.27 | consumed tokens: 2076672000.0 | grad norm avg: 0.96 | grad norm last: 1.01 | 
2026-01-01T17:53:25 | step: 253600 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 1.825739673222415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.11 | consumed tokens: 2077491200.0 | grad norm avg: 0.95 | grad norm last: 1.0 | 
2026-01-01T17:53:43 | step: 253700 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.823960519686807e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.2 | consumed tokens: 2078310400.0 | grad norm avg: 0.96 | grad norm last: 0.97 | 
2026-01-01T17:54:01 | step: 253800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.8221817299490795e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.84 | consumed tokens: 2079129600.0 | grad norm avg: 0.95 | grad norm last: 1.02 | 
2026-01-01T17:54:19 | step: 253900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.820403485908173e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.52 | consumed tokens: 2079948800.0 | grad norm avg: 0.96 | grad norm last: 1.01 | 
2026-01-01T17:54:37 | step: 254000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.818625423766207e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.05 | consumed tokens: 2080768000.0 | grad norm avg: 0.94 | grad norm last: 0.95 | 
2026-01-01T17:54:55 | step: 254100 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.816847907321062e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.42 | consumed tokens: 2081587200.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-01T17:55:13 | step: 254200 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 1.8150705727748573e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.11 | consumed tokens: 2082406400.0 | grad norm avg: 0.95 | grad norm last: 1.05 | 
2026-01-01T17:55:31 | step: 254300 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.8132937839254737e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.52 | consumed tokens: 2083225600.0 | grad norm avg: 0.96 | grad norm last: 0.91 | 
2026-01-01T17:55:49 | step: 254400 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 1.8115173588739708e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.61 | consumed tokens: 2084044800.0 | grad norm avg: 0.94 | grad norm last: 1.08 | 
2026-01-01T17:56:07 | step: 254500 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.8097412976203486e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.52 | consumed tokens: 2084864000.0 | grad norm avg: 0.95 | grad norm last: 1.04 | 
2026-01-01T17:56:25 | step: 254600 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.807965600164607e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.8 | consumed tokens: 2085683200.0 | grad norm avg: 0.95 | grad norm last: 1.03 | 
2026-01-01T17:56:43 | step: 254700 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 1.8061902665067464e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.8 | consumed tokens: 2086502400.0 | grad norm avg: 0.95 | grad norm last: 0.95 | 
2026-01-01T17:57:01 | step: 254800 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.8044152966467664e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.14 | consumed tokens: 2087321600.0 | grad norm avg: 0.96 | grad norm last: 0.98 | 
2026-01-01T17:57:19 | step: 254900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.802640690584667e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.09 | consumed tokens: 2088140800.0 | grad norm avg: 0.95 | grad norm last: 0.95 | 
2026-01-01T17:57:37 | step: 255000 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.8008664483204484e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.69 | consumed tokens: 2088960000.0 | grad norm avg: 0.95 | grad norm last: 0.94 | 
2026-01-01T17:57:56 | step: 255100 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 1.799092751753051e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 4.03 | consumed tokens: 2089779200.0 | grad norm avg: 0.94 | grad norm last: 0.9 | 
2026-01-01T17:58:14 | step: 255200 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.7973192370845936e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.05 | consumed tokens: 2090598400.0 | grad norm avg: 0.95 | grad norm last: 0.93 | 
2026-01-01T17:58:32 | step: 255300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.7955462681129575e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.91 | consumed tokens: 2091417600.0 | grad norm avg: 0.95 | grad norm last: 0.97 | 
2026-01-01T17:58:50 | step: 255400 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.793773662939202e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.73 | consumed tokens: 2092236800.0 | grad norm avg: 0.95 | grad norm last: 1.04 | 
2026-01-01T17:59:08 | step: 255500 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.7920014215633273e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.62 | consumed tokens: 2093056000.0 | grad norm avg: 0.96 | grad norm last: 1.08 | 
2026-01-01T17:59:26 | step: 255600 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.7902295439853333e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.11 | consumed tokens: 2093875200.0 | grad norm avg: 0.94 | grad norm last: 1.05 | 
2026-01-01T17:59:44 | step: 255700 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 1.78845803020522e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 4.12 | consumed tokens: 2094694400.0 | grad norm avg: 0.96 | grad norm last: 0.97 | 
2026-01-01T18:00:02 | step: 255800 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.7866868802229874e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.12 | consumed tokens: 2095513600.0 | grad norm avg: 0.95 | grad norm last: 0.98 | 
2026-01-01T18:00:20 | step: 255900 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 1.784916275937576e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.95 | consumed tokens: 2096332800.0 | grad norm avg: 0.96 | grad norm last: 0.93 | 
2026-01-01T18:00:38 | step: 256000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.783146035450045e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.95 | consumed tokens: 2097152000.0 | grad norm avg: 0.95 | grad norm last: 0.87 | 
2026-01-01T18:00:56 | step: 256100 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.7813759768614545e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.03 | consumed tokens: 2097971200.0 | grad norm avg: 0.95 | grad norm last: 1.0 | 
2026-01-01T18:01:14 | step: 256200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.779606463969685e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.53 | consumed tokens: 2098790400.0 | grad norm avg: 0.95 | grad norm last: 0.91 | 
2026-01-01T18:01:32 | step: 256300 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.7778374967747368e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.38 | consumed tokens: 2099609600.0 | grad norm avg: 0.95 | grad norm last: 0.95 | 
2026-01-01T18:01:50 | step: 256400 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.7760687114787288e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.75 | consumed tokens: 2100428800.0 | grad norm avg: 0.96 | grad norm last: 0.91 | 
2026-01-01T18:02:08 | step: 256500 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.774300471879542e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.75 | consumed tokens: 2101248000.0 | grad norm avg: 0.96 | grad norm last: 0.96 | 
2026-01-01T18:02:26 | step: 256600 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.7725324141792953e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.05 | consumed tokens: 2102067200.0 | grad norm avg: 0.95 | grad norm last: 0.97 | 
2026-01-01T18:02:44 | step: 256700 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.7707649021758698e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.59 | consumed tokens: 2102886400.0 | grad norm avg: 0.94 | grad norm last: 0.89 | 
2026-01-01T18:03:02 | step: 256800 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.768997753970325e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.73 | consumed tokens: 2103705600.0 | grad norm avg: 0.95 | grad norm last: 0.81 | 
2026-01-01T18:03:20 | step: 256900 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.7672311514616013e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 4.0 | consumed tokens: 2104524800.0 | grad norm avg: 0.95 | grad norm last: 0.9 | 
2026-01-01T18:03:38 | step: 257000 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 1.765464730851818e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.17 | consumed tokens: 2105344000.0 | grad norm avg: 0.94 | grad norm last: 1.01 | 
2026-01-01T18:03:56 | step: 257100 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.7636988559388556e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.33 | consumed tokens: 2106163200.0 | grad norm avg: 0.94 | grad norm last: 0.88 | 
2026-01-01T18:04:14 | step: 257200 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.761933344823774e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.84 | consumed tokens: 2106982400.0 | grad norm avg: 0.95 | grad norm last: 0.93 | 
2026-01-01T18:04:32 | step: 257300 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.7601683794055134e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.94 | consumed tokens: 2107801600.0 | grad norm avg: 0.95 | grad norm last: 0.95 | 
2026-01-01T18:04:50 | step: 257400 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.7584035958861932e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.64 | consumed tokens: 2108620800.0 | grad norm avg: 0.96 | grad norm last: 0.89 | 
2026-01-01T18:05:08 | step: 257500 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.756639358063694e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.66 | consumed tokens: 2109440000.0 | grad norm avg: 0.94 | grad norm last: 1.0 | 
2026-01-01T18:05:26 | step: 257600 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.7548754840390757e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.78 | consumed tokens: 2110259200.0 | grad norm avg: 0.96 | grad norm last: 0.96 | 
2026-01-01T18:05:44 | step: 257700 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 1.753111973812338e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.41 | consumed tokens: 2111078400.0 | grad norm avg: 0.95 | grad norm last: 1.0 | 
2026-01-01T18:06:02 | step: 257800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.7513490092824213e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.75 | consumed tokens: 2111897600.0 | grad norm avg: 0.95 | grad norm last: 0.98 | 
2026-01-01T18:06:19 | step: 257900 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.749586226651445e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.83 | consumed tokens: 2112716800.0 | grad norm avg: 0.95 | grad norm last: 0.95 | 
2026-01-01T18:06:37 | step: 258000 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.7478239897172898e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.78 | consumed tokens: 2113536000.0 | grad norm avg: 0.95 | grad norm last: 0.87 | 
2026-01-01T18:06:55 | step: 258100 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.7460622984799556e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.83 | consumed tokens: 2114355200.0 | grad norm avg: 0.96 | grad norm last: 0.93 | 
2026-01-01T18:07:13 | step: 258200 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 1.744300789141562e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.42 | consumed tokens: 2115174400.0 | grad norm avg: 0.95 | grad norm last: 0.95 | 
2026-01-01T18:07:31 | step: 258300 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.742539825499989e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.36 | consumed tokens: 2115993600.0 | grad norm avg: 0.96 | grad norm last: 0.99 | 
2026-01-01T18:07:49 | step: 258400 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.740779225656297e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.66 | consumed tokens: 2116812800.0 | grad norm avg: 0.95 | grad norm last: 1.03 | 
2026-01-01T18:08:07 | step: 258500 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 1.739019171509426e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.19 | consumed tokens: 2117632000.0 | grad norm avg: 0.96 | grad norm last: 0.92 | 
2026-01-01T18:08:25 | step: 258600 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 1.7372592992614955e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.28 | consumed tokens: 2118451200.0 | grad norm avg: 0.95 | grad norm last: 0.86 | 
2026-01-01T18:08:43 | step: 258700 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.735499972710386e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.3 | consumed tokens: 2119270400.0 | grad norm avg: 0.95 | grad norm last: 0.93 | 
2026-01-01T18:09:01 | step: 258800 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.7337411918560974e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.55 | consumed tokens: 2120089600.0 | grad norm avg: 0.94 | grad norm last: 0.99 | 
2026-01-01T18:09:19 | step: 258900 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 1.7319825929007493e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.5 | consumed tokens: 2120908800.0 | grad norm avg: 0.95 | grad norm last: 0.95 | 
2026-01-01T18:09:37 | step: 259000 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.7302245396422222e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.81 | consumed tokens: 2121728000.0 | grad norm avg: 0.96 | grad norm last: 1.02 | 
2026-01-01T18:09:55 | step: 259100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.7284670320805162e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.17 | consumed tokens: 2122547200.0 | grad norm avg: 0.94 | grad norm last: 0.91 | 
2026-01-01T18:10:13 | step: 259200 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.7267097064177506e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.41 | consumed tokens: 2123366400.0 | grad norm avg: 0.95 | grad norm last: 0.9 | 
2026-01-01T18:10:31 | step: 259300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.724952926451806e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.0 | consumed tokens: 2124185600.0 | grad norm avg: 0.95 | grad norm last: 0.91 | 
2026-01-01T18:10:49 | step: 259400 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.7231966921826825e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.86 | consumed tokens: 2125004800.0 | grad norm avg: 0.96 | grad norm last: 0.93 | 
2026-01-01T18:11:07 | step: 259500 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 1.7214406398124993e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 4.44 | consumed tokens: 2125824000.0 | grad norm avg: 0.95 | grad norm last: 0.9 | 
2026-01-01T18:11:25 | step: 259600 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.7196851331391372e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.38 | consumed tokens: 2126643200.0 | grad norm avg: 0.95 | grad norm last: 0.89 | 
2026-01-01T18:11:43 | step: 259700 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.717930172162596e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.08 | consumed tokens: 2127462400.0 | grad norm avg: 0.97 | grad norm last: 0.9 | 
2026-01-01T18:12:01 | step: 259800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.7161755749839358e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.3 | consumed tokens: 2128281600.0 | grad norm avg: 0.95 | grad norm last: 0.92 | 
2026-01-01T18:12:19 | step: 259900 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.7144213416031562e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.02 | consumed tokens: 2129100800.0 | grad norm avg: 0.95 | grad norm last: 0.97 | 
2026-01-01T18:12:37 | step: 260000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.7126674720202573e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.97 | consumed tokens: 2129920000.0 | grad norm avg: 0.96 | grad norm last: 1.01 | 
2026-01-01T18:12:56 | step: 260100 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.7109141481341794e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 4.06 | consumed tokens: 2130739200.0 | grad norm avg: 0.95 | grad norm last: 1.0 | 
2026-01-01T18:13:14 | step: 260200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.7091611880459823e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.22 | consumed tokens: 2131558400.0 | grad norm avg: 0.96 | grad norm last: 1.0 | 
2026-01-01T18:13:32 | step: 260300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.7074087736546062e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.36 | consumed tokens: 2132377600.0 | grad norm avg: 0.95 | grad norm last: 0.96 | 
2026-01-01T18:13:50 | step: 260400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.7056567230611108e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.72 | consumed tokens: 2133196800.0 | grad norm avg: 0.96 | grad norm last: 0.96 | 
2026-01-01T18:14:08 | step: 260500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.703905036265496e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.44 | consumed tokens: 2134016000.0 | grad norm avg: 0.96 | grad norm last: 0.96 | 
2026-01-01T18:14:26 | step: 260600 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 1.7021538951667026e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.78 | consumed tokens: 2134835200.0 | grad norm avg: 0.95 | grad norm last: 0.92 | 
2026-01-01T18:14:44 | step: 260700 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 1.7004031178657897e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.25 | consumed tokens: 2135654400.0 | grad norm avg: 0.96 | grad norm last: 0.94 | 
2026-01-01T18:15:02 | step: 260800 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 1.698652886261698e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.22 | consumed tokens: 2136473600.0 | grad norm avg: 0.96 | grad norm last: 1.06 | 
2026-01-01T18:15:20 | step: 260900 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.6969030184554867e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.59 | consumed tokens: 2137292800.0 | grad norm avg: 0.96 | grad norm last: 0.88 | 
2026-01-01T18:15:38 | step: 261000 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.6951536963460967e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.59 | consumed tokens: 2138112000.0 | grad norm avg: 0.95 | grad norm last: 1.1 | 
2026-01-01T18:15:56 | step: 261100 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.6934047380345874e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.27 | consumed tokens: 2138931200.0 | grad norm avg: 0.96 | grad norm last: 1.04 | 
2026-01-01T18:16:14 | step: 261200 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.6916561435209587e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.84 | consumed tokens: 2139750400.0 | grad norm avg: 0.95 | grad norm last: 0.94 | 
2026-01-01T18:16:32 | step: 261300 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 1.689908094704151e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.11 | consumed tokens: 2140569600.0 | grad norm avg: 0.95 | grad norm last: 1.0 | 
2026-01-01T18:16:50 | step: 261400 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 1.6881604096852243e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.17 | consumed tokens: 2141388800.0 | grad norm avg: 0.96 | grad norm last: 0.91 | 
2026-01-01T18:17:07 | step: 261500 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.6864132703631185e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.64 | consumed tokens: 2142208000.0 | grad norm avg: 0.95 | grad norm last: 0.98 | 
2026-01-01T18:17:25 | step: 261600 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.6846664948388934e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.0 | consumed tokens: 2143027200.0 | grad norm avg: 0.96 | grad norm last: 0.91 | 
2026-01-01T18:17:43 | step: 261700 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.6829202650114894e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.73 | consumed tokens: 2143846400.0 | grad norm avg: 0.95 | grad norm last: 0.93 | 
2026-01-01T18:18:01 | step: 261800 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.681174398981966e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.89 | consumed tokens: 2144665600.0 | grad norm avg: 0.95 | grad norm last: 1.05 | 
2026-01-01T18:18:19 | step: 261900 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 1.6794288967503235e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.75 | consumed tokens: 2145484800.0 | grad norm avg: 0.95 | grad norm last: 0.87 | 
2026-01-01T18:18:37 | step: 262000 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 1.677683940215502e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.3 | consumed tokens: 2146304000.0 | grad norm avg: 0.96 | grad norm last: 1.03 | 
2026-01-01T18:18:55 | step: 262100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.6759395293775015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.14 | consumed tokens: 2147123200.0 | grad norm avg: 0.96 | grad norm last: 1.0 | 
2026-01-01T18:19:13 | step: 262200 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 1.6741954823373817e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.59 | consumed tokens: 2147942400.0 | grad norm avg: 0.95 | grad norm last: 1.02 | 
2026-01-01T18:19:31 | step: 262300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.6724517990951426e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.05 | consumed tokens: 2148761600.0 | grad norm avg: 0.95 | grad norm last: 0.92 | 
2026-01-01T18:19:49 | step: 262400 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.670708843448665e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.08 | consumed tokens: 2149580800.0 | grad norm avg: 0.96 | grad norm last: 0.97 | 
2026-01-01T18:20:07 | step: 262500 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.6689660697011277e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.59 | consumed tokens: 2150400000.0 | grad norm avg: 0.96 | grad norm last: 1.11 | 
2026-01-01T18:20:25 | step: 262600 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.6672238416504115e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.64 | consumed tokens: 2151219200.0 | grad norm avg: 0.95 | grad norm last: 0.99 | 
2026-01-01T18:20:43 | step: 262700 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.6654821592965163e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.86 | consumed tokens: 2152038400.0 | grad norm avg: 0.95 | grad norm last: 0.99 | 
2026-01-01T18:21:01 | step: 262800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.663740840740502e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.14 | consumed tokens: 2152857600.0 | grad norm avg: 0.96 | grad norm last: 0.99 | 
2026-01-01T18:21:19 | step: 262900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.661999885982368e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.27 | consumed tokens: 2153676800.0 | grad norm avg: 0.96 | grad norm last: 0.98 | 
2026-01-01T18:21:37 | step: 263000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.6602594769210555e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.42 | consumed tokens: 2154496000.0 | grad norm avg: 0.96 | grad norm last: 0.83 | 
2026-01-01T18:21:55 | step: 263100 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.658519613556564e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.5 | consumed tokens: 2155315200.0 | grad norm avg: 0.95 | grad norm last: 0.99 | 
2026-01-01T18:22:13 | step: 263200 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 1.656780113989953e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.67 | consumed tokens: 2156134400.0 | grad norm avg: 0.96 | grad norm last: 0.91 | 
2026-01-01T18:22:31 | step: 263300 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.655041160120163e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.42 | consumed tokens: 2156953600.0 | grad norm avg: 0.96 | grad norm last: 0.9 | 
2026-01-01T18:22:49 | step: 263400 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.653302570048254e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.84 | consumed tokens: 2157772800.0 | grad norm avg: 0.96 | grad norm last: 1.04 | 
2026-01-01T18:23:07 | step: 263500 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.651564525673166e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.67 | consumed tokens: 2158592000.0 | grad norm avg: 0.96 | grad norm last: 0.94 | 
2026-01-01T18:23:25 | step: 263600 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 1.649827026994899e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.88 | consumed tokens: 2159411200.0 | grad norm avg: 0.96 | grad norm last: 0.99 | 
2026-01-01T18:23:43 | step: 263700 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 1.6480898921145126e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.97 | consumed tokens: 2160230400.0 | grad norm avg: 0.95 | grad norm last: 0.98 | 
2026-01-01T18:24:01 | step: 263800 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.646353121032007e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.45 | consumed tokens: 2161049600.0 | grad norm avg: 0.95 | grad norm last: 0.95 | 
2026-01-01T18:24:19 | step: 263900 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.6446168956463225e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.42 | consumed tokens: 2161868800.0 | grad norm avg: 0.95 | grad norm last: 0.95 | 
2026-01-01T18:24:37 | step: 264000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.642881215957459e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.64 | consumed tokens: 2162688000.0 | grad norm avg: 0.96 | grad norm last: 0.9 | 
2026-01-01T18:24:55 | step: 264100 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.6411459000664763e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.83 | consumed tokens: 2163507200.0 | grad norm avg: 0.95 | grad norm last: 0.88 | 
2026-01-01T18:25:13 | step: 264200 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.6394111298723146e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.59 | consumed tokens: 2164326400.0 | grad norm avg: 0.95 | grad norm last: 0.98 | 
2026-01-01T18:25:30 | step: 264300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.637676905374974e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.89 | consumed tokens: 2165145600.0 | grad norm avg: 0.96 | grad norm last: 0.99 | 
2026-01-01T18:25:48 | step: 264400 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 1.635943044675514e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.23 | consumed tokens: 2165964800.0 | grad norm avg: 0.96 | grad norm last: 0.98 | 
2026-01-01T18:26:06 | step: 264500 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 1.6342097296728753e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.3 | consumed tokens: 2166784000.0 | grad norm avg: 0.96 | grad norm last: 0.92 | 
2026-01-01T18:26:24 | step: 264600 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 1.632476778468117e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.09 | consumed tokens: 2167603200.0 | grad norm avg: 0.96 | grad norm last: 0.93 | 
2026-01-01T18:26:42 | step: 264700 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 1.63074437296018e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.14 | consumed tokens: 2168422400.0 | grad norm avg: 0.96 | grad norm last: 0.85 | 
2026-01-01T18:27:00 | step: 264800 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.629012513149064e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.94 | consumed tokens: 2169241600.0 | grad norm avg: 0.95 | grad norm last: 1.05 | 
2026-01-01T18:27:18 | step: 264900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.6272810171358287e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.98 | consumed tokens: 2170060800.0 | grad norm avg: 0.95 | grad norm last: 1.03 | 
2026-01-01T18:27:36 | step: 265000 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.6255500668194145e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.67 | consumed tokens: 2170880000.0 | grad norm avg: 0.95 | grad norm last: 0.94 | 
2026-01-01T18:27:55 | step: 265100 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.623819480300881e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.08 | consumed tokens: 2171699200.0 | grad norm avg: 0.97 | grad norm last: 1.05 | 
2026-01-01T18:28:13 | step: 265200 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.6220894394791685e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.44 | consumed tokens: 2172518400.0 | grad norm avg: 0.95 | grad norm last: 0.89 | 
2026-01-01T18:28:31 | step: 265300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.620359944354277e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.77 | consumed tokens: 2173337600.0 | grad norm avg: 0.96 | grad norm last: 0.94 | 
2026-01-01T18:28:49 | step: 265400 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.6186309949262068e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.25 | consumed tokens: 2174156800.0 | grad norm avg: 0.96 | grad norm last: 0.95 | 
2026-01-01T18:29:07 | step: 265500 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.616902409296017e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.27 | consumed tokens: 2174976000.0 | grad norm avg: 0.96 | grad norm last: 0.98 | 
2026-01-01T18:29:25 | step: 265600 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.6151741874637082e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.89 | consumed tokens: 2175795200.0 | grad norm avg: 0.96 | grad norm last: 1.01 | 
2026-01-01T18:29:43 | step: 265700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.6134466932271607e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.17 | consumed tokens: 2176614400.0 | grad norm avg: 0.96 | grad norm last: 1.02 | 
2026-01-01T18:30:01 | step: 265800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.611719562788494e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.59 | consumed tokens: 2177433600.0 | grad norm avg: 0.96 | grad norm last: 0.93 | 
2026-01-01T18:30:19 | step: 265900 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.6099929780466482e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.42 | consumed tokens: 2178252800.0 | grad norm avg: 0.96 | grad norm last: 1.11 | 
2026-01-01T18:30:37 | step: 266000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.6082667571026832e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.33 | consumed tokens: 2179072000.0 | grad norm avg: 0.97 | grad norm last: 0.94 | 
2026-01-01T18:30:55 | step: 266100 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 1.6065410818555392e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.66 | consumed tokens: 2179891200.0 | grad norm avg: 0.96 | grad norm last: 0.92 | 
2026-01-01T18:31:13 | step: 266200 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 1.6048159523052163e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.42 | consumed tokens: 2180710400.0 | grad norm avg: 0.96 | grad norm last: 0.92 | 
2026-01-01T18:31:31 | step: 266300 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.6030913684517145e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.5 | consumed tokens: 2181529600.0 | grad norm avg: 0.95 | grad norm last: 1.0 | 
2026-01-01T18:31:49 | step: 266400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.6013671483960934e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.27 | consumed tokens: 2182348800.0 | grad norm avg: 0.95 | grad norm last: 1.0 | 
2026-01-01T18:32:07 | step: 266500 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.5996434740372933e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.09 | consumed tokens: 2183168000.0 | grad norm avg: 0.96 | grad norm last: 1.09 | 
2026-01-01T18:32:25 | step: 266600 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.5979203453753144e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.72 | consumed tokens: 2183987200.0 | grad norm avg: 0.96 | grad norm last: 0.98 | 
2026-01-01T18:32:43 | step: 266700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.596197580511216e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.2 | consumed tokens: 2184806400.0 | grad norm avg: 0.96 | grad norm last: 0.95 | 
2026-01-01T18:33:01 | step: 266800 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.5944755432428792e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.72 | consumed tokens: 2185625600.0 | grad norm avg: 0.96 | grad norm last: 0.99 | 
2026-01-01T18:33:19 | step: 266900 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.592753869772423e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.77 | consumed tokens: 2186444800.0 | grad norm avg: 0.96 | grad norm last: 0.97 | 
2026-01-01T18:33:37 | step: 267000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.5910325600998476e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.47 | consumed tokens: 2187264000.0 | grad norm avg: 0.97 | grad norm last: 0.95 | 
2026-01-01T18:33:55 | step: 267100 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.5893119780230336e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.72 | consumed tokens: 2188083200.0 | grad norm avg: 0.96 | grad norm last: 0.95 | 
2026-01-01T18:34:13 | step: 267200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.5875917597441003e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.06 | consumed tokens: 2188902400.0 | grad norm avg: 0.96 | grad norm last: 1.0 | 
2026-01-01T18:34:31 | step: 267300 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 1.585872087161988e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 4.09 | consumed tokens: 2189721600.0 | grad norm avg: 0.97 | grad norm last: 0.89 | 
2026-01-01T18:34:49 | step: 267400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.5841527783777565e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.14 | consumed tokens: 2190540800.0 | grad norm avg: 0.96 | grad norm last: 0.99 | 
2026-01-01T18:35:07 | step: 267500 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 1.5824341971892864e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.33 | consumed tokens: 2191360000.0 | grad norm avg: 0.96 | grad norm last: 0.93 | 
2026-01-01T18:35:25 | step: 267600 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.580715979798697e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.62 | consumed tokens: 2192179200.0 | grad norm avg: 0.96 | grad norm last: 0.97 | 
2026-01-01T18:35:43 | step: 267700 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.5789983081049286e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.62 | consumed tokens: 2192998400.0 | grad norm avg: 0.97 | grad norm last: 0.97 | 
2026-01-01T18:36:01 | step: 267800 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.5772811821079813e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.52 | consumed tokens: 2193817600.0 | grad norm avg: 0.95 | grad norm last: 0.93 | 
2026-01-01T18:36:19 | step: 267900 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 1.5755644199089147e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.25 | consumed tokens: 2194636800.0 | grad norm avg: 0.95 | grad norm last: 0.92 | 
2026-01-01T18:36:36 | step: 268000 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 1.5738483853056096e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.95 | consumed tokens: 2195456000.0 | grad norm avg: 0.95 | grad norm last: 1.01 | 
2026-01-01T18:36:54 | step: 268100 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.572132714500185e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.22 | consumed tokens: 2196275200.0 | grad norm avg: 0.95 | grad norm last: 0.97 | 
2026-01-01T18:37:12 | step: 268200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.5704175893915817e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.77 | consumed tokens: 2197094400.0 | grad norm avg: 0.96 | grad norm last: 1.02 | 
2026-01-01T18:37:30 | step: 268300 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 1.568702828080859e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.09 | consumed tokens: 2197913600.0 | grad norm avg: 0.96 | grad norm last: 1.03 | 
2026-01-01T18:37:48 | step: 268400 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 1.5669887943658978e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.34 | consumed tokens: 2198732800.0 | grad norm avg: 0.96 | grad norm last: 0.97 | 
2026-01-01T18:38:06 | step: 268500 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 1.5652751244488172e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.25 | consumed tokens: 2199552000.0 | grad norm avg: 0.97 | grad norm last: 0.9 | 
2026-01-01T18:38:24 | step: 268600 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 1.563562182127498e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.52 | consumed tokens: 2200371200.0 | grad norm avg: 0.97 | grad norm last: 1.0 | 
2026-01-01T18:38:42 | step: 268700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 1.5618496036040597e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.03 | consumed tokens: 2201190400.0 | grad norm avg: 0.97 | grad norm last: 0.95 | 
2026-01-01T18:39:00 | step: 268800 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.560137388878502e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.25 | consumed tokens: 2202009600.0 | grad norm avg: 0.96 | grad norm last: 0.95 | 
2026-01-01T18:39:18 | step: 268900 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 1.5584259017487057e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 4.03 | consumed tokens: 2202828800.0 | grad norm avg: 0.96 | grad norm last: 1.0 | 
2026-01-01T18:39:36 | step: 269000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.5567149603157304e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.52 | consumed tokens: 2203648000.0 | grad norm avg: 0.97 | grad norm last: 0.92 | 
2026-01-01T18:39:54 | step: 269100 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 1.555004382680636e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.45 | consumed tokens: 2204467200.0 | grad norm avg: 0.95 | grad norm last: 0.97 | 
2026-01-01T18:40:11 | step: 269200 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 1.5532943507423624e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.92 | consumed tokens: 2205286400.0 | grad norm avg: 0.95 | grad norm last: 0.95 | 
2026-01-01T18:40:29 | step: 269300 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.55158486450091e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.62 | consumed tokens: 2206105600.0 | grad norm avg: 0.96 | grad norm last: 1.04 | 
2026-01-01T18:40:47 | step: 269400 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.5498759239562787e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.77 | consumed tokens: 2206924800.0 | grad norm avg: 0.96 | grad norm last: 0.98 | 
2026-01-01T18:41:05 | step: 269500 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.5481675291084684e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.53 | consumed tokens: 2207744000.0 | grad norm avg: 0.96 | grad norm last: 0.91 | 
2026-01-01T18:41:23 | step: 269600 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.5464596799574792e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.44 | consumed tokens: 2208563200.0 | grad norm avg: 0.96 | grad norm last: 1.0 | 
2026-01-01T18:41:41 | step: 269700 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.5447521946043707e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.72 | consumed tokens: 2209382400.0 | grad norm avg: 0.96 | grad norm last: 0.93 | 
2026-01-01T18:41:59 | step: 269800 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 1.5430454368470237e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.84 | consumed tokens: 2210201600.0 | grad norm avg: 0.96 | grad norm last: 0.89 | 
2026-01-01T18:42:17 | step: 269900 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.5413390428875573e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.38 | consumed tokens: 2211020800.0 | grad norm avg: 0.96 | grad norm last: 0.98 | 
2026-01-01T18:42:35 | step: 270000 | train samples/s: 96.0 | train mfu (16-bit): -1.0 | lr mean: 1.5396333765238523e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.36 | consumed tokens: 2211840000.0 | grad norm avg: 0.97 | grad norm last: 0.97 | 
2026-01-01T18:42:55 | step: 270100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.537928073958028e-05 | peak memory rank 0 (MB): 4524.28 | train loss avg: 3.18 | train loss last: 2.75 | consumed tokens: 2212659200.0 | grad norm avg: 0.97 | grad norm last: 0.97 | 
2026-01-01T18:43:13 | step: 270200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.536223317089025e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.5 | consumed tokens: 2213478400.0 | grad norm avg: 0.97 | grad norm last: 0.91 | 
2026-01-01T18:43:30 | step: 270300 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.5345191059168428e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.5 | consumed tokens: 2214297600.0 | grad norm avg: 0.96 | grad norm last: 1.08 | 
2026-01-01T18:43:48 | step: 270400 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.5328154404414818e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 4.0 | consumed tokens: 2215116800.0 | grad norm avg: 0.96 | grad norm last: 0.97 | 
2026-01-01T18:44:06 | step: 270500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.5311121387640014e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.41 | consumed tokens: 2215936000.0 | grad norm avg: 0.95 | grad norm last: 0.88 | 
2026-01-01T18:44:24 | step: 270600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.5294095646822825e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.2 | consumed tokens: 2216755200.0 | grad norm avg: 0.95 | grad norm last: 1.02 | 
2026-01-01T18:44:42 | step: 270700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.5277075362973846e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.12 | consumed tokens: 2217574400.0 | grad norm avg: 0.96 | grad norm last: 0.99 | 
2026-01-01T18:45:00 | step: 270800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.5260058717103675e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.94 | consumed tokens: 2218393600.0 | grad norm avg: 0.96 | grad norm last: 0.9 | 
2026-01-01T18:45:18 | step: 270900 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.5243049347191118e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.36 | consumed tokens: 2219212800.0 | grad norm avg: 0.96 | grad norm last: 0.88 | 
2026-01-01T18:45:36 | step: 271000 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.522604452475207e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.66 | consumed tokens: 2220032000.0 | grad norm avg: 0.97 | grad norm last: 1.02 | 
2026-01-01T18:45:54 | step: 271100 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.5209045159281231e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.31 | consumed tokens: 2220851200.0 | grad norm avg: 0.97 | grad norm last: 0.96 | 
2026-01-01T18:46:12 | step: 271200 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.5192050341283903e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.75 | consumed tokens: 2221670400.0 | grad norm avg: 0.96 | grad norm last: 0.96 | 
2026-01-01T18:46:30 | step: 271300 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.5175061889749486e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.62 | consumed tokens: 2222489600.0 | grad norm avg: 0.96 | grad norm last: 1.0 | 
2026-01-01T18:46:49 | step: 271400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.515807889518328e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.95 | consumed tokens: 2223308800.0 | grad norm avg: 0.96 | grad norm last: 0.99 | 
2026-01-01T18:47:06 | step: 271500 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.5141100448090583e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.45 | consumed tokens: 2224128000.0 | grad norm avg: 0.96 | grad norm last: 1.02 | 
2026-01-01T18:47:24 | step: 271600 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 1.5124128367460798e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.33 | consumed tokens: 2224947200.0 | grad norm avg: 0.96 | grad norm last: 0.98 | 
2026-01-01T18:47:42 | step: 271700 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.5107160834304523e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.98 | consumed tokens: 2225766400.0 | grad norm avg: 0.96 | grad norm last: 0.99 | 
2026-01-01T18:48:00 | step: 271800 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.509019966761116e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.09 | consumed tokens: 2226585600.0 | grad norm avg: 0.96 | grad norm last: 0.98 | 
2026-01-01T18:48:18 | step: 271900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.5073243048391305e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.34 | consumed tokens: 2227404800.0 | grad norm avg: 0.97 | grad norm last: 0.97 | 
2026-01-01T18:48:36 | step: 272000 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.5056291886139661e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.72 | consumed tokens: 2228224000.0 | grad norm avg: 0.97 | grad norm last: 1.02 | 
2026-01-01T18:48:54 | step: 272100 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 1.503934709035093e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.77 | consumed tokens: 2229043200.0 | grad norm avg: 0.97 | grad norm last: 0.9 | 
2026-01-01T18:49:12 | step: 272200 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.5022406842035707e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.28 | consumed tokens: 2229862400.0 | grad norm avg: 0.96 | grad norm last: 0.92 | 
2026-01-01T18:49:30 | step: 272300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.5005472960183397e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.05 | consumed tokens: 2230681600.0 | grad norm avg: 0.96 | grad norm last: 1.03 | 
2026-01-01T18:49:48 | step: 272400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.4988543625804596e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.42 | consumed tokens: 2231500800.0 | grad norm avg: 0.95 | grad norm last: 0.89 | 
2026-01-01T18:50:06 | step: 272500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.4971620657888707e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.95 | consumed tokens: 2232320000.0 | grad norm avg: 0.96 | grad norm last: 0.91 | 
2026-01-01T18:50:24 | step: 272600 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.4954702237446327e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.62 | consumed tokens: 2233139200.0 | grad norm avg: 0.96 | grad norm last: 0.9 | 
2026-01-01T18:50:42 | step: 272700 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.493779018346686e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.72 | consumed tokens: 2233958400.0 | grad norm avg: 0.97 | grad norm last: 0.99 | 
2026-01-01T18:51:00 | step: 272800 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.4920883586455602e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.19 | consumed tokens: 2234777600.0 | grad norm avg: 0.96 | grad norm last: 0.95 | 
2026-01-01T18:51:18 | step: 272900 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.4903982446412556e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.84 | consumed tokens: 2235596800.0 | grad norm avg: 0.96 | grad norm last: 1.03 | 
2026-01-01T18:51:36 | step: 273000 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 1.488708676333772e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.31 | consumed tokens: 2236416000.0 | grad norm avg: 0.96 | grad norm last: 1.07 | 
2026-01-01T18:51:54 | step: 273100 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.4870196537231095e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.41 | consumed tokens: 2237235200.0 | grad norm avg: 0.96 | grad norm last: 1.02 | 
2026-01-01T18:52:12 | step: 273200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.485331176809268e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.31 | consumed tokens: 2238054400.0 | grad norm avg: 0.96 | grad norm last: 0.88 | 
2026-01-01T18:52:30 | step: 273300 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.4836432455922477e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.3 | consumed tokens: 2238873600.0 | grad norm avg: 0.96 | grad norm last: 1.0 | 
2026-01-01T18:52:48 | step: 273400 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 1.4819559510215186e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.72 | consumed tokens: 2239692800.0 | grad norm avg: 0.97 | grad norm last: 1.03 | 
2026-01-01T18:53:06 | step: 273500 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.4802691111981403e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.58 | consumed tokens: 2240512000.0 | grad norm avg: 0.96 | grad norm last: 0.97 | 
2026-01-01T18:53:24 | step: 273600 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.4785829080210533e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.78 | consumed tokens: 2241331200.0 | grad norm avg: 0.96 | grad norm last: 1.07 | 
2026-01-01T18:53:42 | step: 273700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.4768972505407874e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.3 | consumed tokens: 2242150400.0 | grad norm avg: 0.96 | grad norm last: 1.01 | 
2026-01-01T18:54:00 | step: 273800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.4752121387573425e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.52 | consumed tokens: 2242969600.0 | grad norm avg: 0.96 | grad norm last: 0.86 | 
2026-01-01T18:54:18 | step: 273900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 1.4735275726707187e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.88 | consumed tokens: 2243788800.0 | grad norm avg: 0.97 | grad norm last: 0.97 | 
2026-01-01T18:54:36 | step: 274000 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.4718435522809159e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.5 | consumed tokens: 2244608000.0 | grad norm avg: 0.96 | grad norm last: 0.89 | 
2026-01-01T18:54:54 | step: 274100 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.4701601685374044e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.06 | consumed tokens: 2245427200.0 | grad norm avg: 0.96 | grad norm last: 1.01 | 
2026-01-01T18:55:12 | step: 274200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.468477330490714e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.77 | consumed tokens: 2246246400.0 | grad norm avg: 0.96 | grad norm last: 0.96 | 
2026-01-01T18:55:30 | step: 274300 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.4667950381408446e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.25 | consumed tokens: 2247065600.0 | grad norm avg: 0.97 | grad norm last: 0.95 | 
2026-01-01T18:55:48 | step: 274400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.4651132914877962e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.69 | consumed tokens: 2247884800.0 | grad norm avg: 0.97 | grad norm last: 0.9 | 
2026-01-01T18:56:06 | step: 274500 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.4634321814810392e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.59 | consumed tokens: 2248704000.0 | grad norm avg: 0.96 | grad norm last: 1.09 | 
2026-01-01T18:56:24 | step: 274600 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.4617516171711031e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.61 | consumed tokens: 2249523200.0 | grad norm avg: 0.96 | grad norm last: 0.9 | 
2026-01-01T18:56:42 | step: 274700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.4600715985579882e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.52 | consumed tokens: 2250342400.0 | grad norm avg: 0.95 | grad norm last: 0.99 | 
2026-01-01T18:57:00 | step: 274800 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.4583921256416943e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.09 | consumed tokens: 2251161600.0 | grad norm avg: 0.97 | grad norm last: 0.93 | 
2026-01-01T18:57:18 | step: 274900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.4567132893716916e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.75 | consumed tokens: 2251980800.0 | grad norm avg: 0.96 | grad norm last: 1.0 | 
2026-01-01T18:57:36 | step: 275000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.45503499879851e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.97 | consumed tokens: 2252800000.0 | grad norm avg: 0.96 | grad norm last: 0.98 | 
2026-01-01T18:57:55 | step: 275100 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.4533572539221495e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.67 | consumed tokens: 2253619200.0 | grad norm avg: 0.96 | grad norm last: 0.88 | 
2026-01-01T18:58:14 | step: 275200 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 1.4516801456920803e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.25 | consumed tokens: 2254438400.0 | grad norm avg: 0.97 | grad norm last: 0.96 | 
2026-01-01T18:58:32 | step: 275300 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.450003583158832e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.64 | consumed tokens: 2255257600.0 | grad norm avg: 0.95 | grad norm last: 1.04 | 
2026-01-01T18:58:50 | step: 275400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.4483275663224049e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.11 | consumed tokens: 2256076800.0 | grad norm avg: 0.97 | grad norm last: 0.88 | 
2026-01-01T18:59:08 | step: 275500 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.446652186132269e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.97 | consumed tokens: 2256896000.0 | grad norm avg: 0.98 | grad norm last: 0.98 | 
2026-01-01T18:59:26 | step: 275600 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.4449773516389541e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.48 | consumed tokens: 2257715200.0 | grad norm avg: 0.97 | grad norm last: 0.95 | 
2026-01-01T18:59:43 | step: 275700 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.4433030628424603e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.95 | consumed tokens: 2258534400.0 | grad norm avg: 0.96 | grad norm last: 0.89 | 
2026-01-01T19:00:01 | step: 275800 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 1.4416294106922578e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.42 | consumed tokens: 2259353600.0 | grad norm avg: 0.98 | grad norm last: 1.02 | 
2026-01-01T19:00:19 | step: 275900 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 1.4399563042388763e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.62 | consumed tokens: 2260172800.0 | grad norm avg: 0.96 | grad norm last: 0.93 | 
2026-01-01T19:00:37 | step: 276000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.4382837434823159e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.7 | consumed tokens: 2260992000.0 | grad norm avg: 0.97 | grad norm last: 1.03 | 
2026-01-01T19:00:55 | step: 276100 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.4366118193720467e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.28 | consumed tokens: 2261811200.0 | grad norm avg: 0.96 | grad norm last: 0.9 | 
2026-01-01T19:01:13 | step: 276200 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.4349405319080688e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.02 | consumed tokens: 2262630400.0 | grad norm avg: 0.97 | grad norm last: 0.94 | 
2026-01-01T19:01:31 | step: 276300 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.4332696991914418e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.25 | consumed tokens: 2263449600.0 | grad norm avg: 0.96 | grad norm last: 1.0 | 
2026-01-01T19:01:49 | step: 276400 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.4315995940705761e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.3 | consumed tokens: 2264268800.0 | grad norm avg: 0.97 | grad norm last: 1.0 | 
2026-01-01T19:02:07 | step: 276500 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.4299299436970614e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.52 | consumed tokens: 2265088000.0 | grad norm avg: 0.97 | grad norm last: 0.99 | 
2026-01-01T19:02:25 | step: 276600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.4282609299698379e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.8 | consumed tokens: 2265907200.0 | grad norm avg: 0.97 | grad norm last: 0.92 | 
2026-01-01T19:02:43 | step: 276700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.4265925528889056e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.97 | consumed tokens: 2266726400.0 | grad norm avg: 0.96 | grad norm last: 0.91 | 
2026-01-01T19:03:01 | step: 276800 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.4249247215047944e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.98 | consumed tokens: 2267545600.0 | grad norm avg: 0.97 | grad norm last: 1.01 | 
2026-01-01T19:03:19 | step: 276900 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.4232575267669745e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.89 | consumed tokens: 2268364800.0 | grad norm avg: 0.96 | grad norm last: 0.91 | 
2026-01-01T19:03:37 | step: 277000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.4215908777259756e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.58 | consumed tokens: 2269184000.0 | grad norm avg: 0.97 | grad norm last: 0.89 | 
2026-01-01T19:03:55 | step: 277100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.4199247743817978e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.69 | consumed tokens: 2270003200.0 | grad norm avg: 0.97 | grad norm last: 0.93 | 
2026-01-01T19:04:13 | step: 277200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.4182593076839112e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.28 | consumed tokens: 2270822400.0 | grad norm avg: 0.96 | grad norm last: 0.91 | 
2026-01-01T19:04:31 | step: 277300 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.4165944776323158e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.84 | consumed tokens: 2271641600.0 | grad norm avg: 0.96 | grad norm last: 0.96 | 
2026-01-01T19:04:49 | step: 277400 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.4149301932775415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.17 | consumed tokens: 2272460800.0 | grad norm avg: 0.96 | grad norm last: 1.04 | 
2026-01-01T19:05:07 | step: 277500 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.4132665455690585e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.56 | consumed tokens: 2273280000.0 | grad norm avg: 0.97 | grad norm last: 0.99 | 
2026-01-01T19:05:25 | step: 277600 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.4116034435573965e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.86 | consumed tokens: 2274099200.0 | grad norm avg: 0.96 | grad norm last: 0.9 | 
2026-01-01T19:05:43 | step: 277700 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.4099409781920258e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.75 | consumed tokens: 2274918400.0 | grad norm avg: 0.97 | grad norm last: 1.02 | 
2026-01-01T19:06:02 | step: 277800 | train samples/s: 96.4 | train mfu (16-bit): -1.0 | lr mean: 1.4082790585234761e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.89 | consumed tokens: 2275737600.0 | grad norm avg: 0.95 | grad norm last: 0.93 | 
2026-01-01T19:06:20 | step: 277900 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.4066177755012177e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.59 | consumed tokens: 2276556800.0 | grad norm avg: 0.97 | grad norm last: 1.0 | 
2026-01-01T19:06:38 | step: 278000 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.4049571291252505e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.39 | consumed tokens: 2277376000.0 | grad norm avg: 0.96 | grad norm last: 0.92 | 
2026-01-01T19:06:56 | step: 278100 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.4032970284461044e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.81 | consumed tokens: 2278195200.0 | grad norm avg: 0.96 | grad norm last: 0.91 | 
2026-01-01T19:07:14 | step: 278200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.4016375644132495e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.0 | consumed tokens: 2279014400.0 | grad norm avg: 0.98 | grad norm last: 1.02 | 
2026-01-01T19:07:32 | step: 278300 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.3999786460772157e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.02 | consumed tokens: 2279833600.0 | grad norm avg: 0.97 | grad norm last: 0.9 | 
2026-01-01T19:07:50 | step: 278400 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.3983204553369433e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.92 | consumed tokens: 2280652800.0 | grad norm avg: 0.96 | grad norm last: 0.98 | 
2026-01-01T19:08:08 | step: 278500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.3966627193440218e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.94 | consumed tokens: 2281472000.0 | grad norm avg: 0.97 | grad norm last: 1.0 | 
2026-01-01T19:08:26 | step: 278600 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.3950057109468617e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.95 | consumed tokens: 2282291200.0 | grad norm avg: 0.97 | grad norm last: 0.98 | 
2026-01-01T19:08:44 | step: 278700 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.3933492482465226e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.5 | consumed tokens: 2283110400.0 | grad norm avg: 0.96 | grad norm last: 0.9 | 
2026-01-01T19:09:02 | step: 278800 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.3916934221924748e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.36 | consumed tokens: 2283929600.0 | grad norm avg: 0.96 | grad norm last: 1.0 | 
2026-01-01T19:09:20 | step: 278900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.3900381418352481e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.55 | consumed tokens: 2284748800.0 | grad norm avg: 0.97 | grad norm last: 1.05 | 
2026-01-01T19:09:38 | step: 279000 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.3883834981243126e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.27 | consumed tokens: 2285568000.0 | grad norm avg: 0.96 | grad norm last: 0.88 | 
2026-01-01T19:09:56 | step: 279100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.3867294910596684e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.88 | consumed tokens: 2286387200.0 | grad norm avg: 0.97 | grad norm last: 0.93 | 
2026-01-01T19:10:14 | step: 279200 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 1.3850761206413154e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.62 | consumed tokens: 2287206400.0 | grad norm avg: 0.97 | grad norm last: 0.92 | 
2026-01-01T19:10:32 | step: 279300 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.3834232959197834e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.44 | consumed tokens: 2288025600.0 | grad norm avg: 0.97 | grad norm last: 0.97 | 
2026-01-01T19:10:50 | step: 279400 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 1.3817711078445427e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.0 | consumed tokens: 2288844800.0 | grad norm avg: 0.97 | grad norm last: 0.92 | 
2026-01-01T19:11:08 | step: 279500 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.3801195564155933e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.36 | consumed tokens: 2289664000.0 | grad norm avg: 0.97 | grad norm last: 1.03 | 
2026-01-01T19:11:26 | step: 279600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.3784685506834649e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.86 | consumed tokens: 2290483200.0 | grad norm avg: 0.97 | grad norm last: 0.91 | 
2026-01-01T19:11:44 | step: 279700 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.3768182725470979e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.11 | consumed tokens: 2291302400.0 | grad norm avg: 0.96 | grad norm last: 0.97 | 
2026-01-01T19:12:02 | step: 279800 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.375168540107552e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.11 | consumed tokens: 2292121600.0 | grad norm avg: 0.96 | grad norm last: 0.96 | 
2026-01-01T19:12:20 | step: 279900 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.3735194443142973e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.75 | consumed tokens: 2292940800.0 | grad norm avg: 0.97 | grad norm last: 0.95 | 
2026-01-01T19:12:38 | step: 280000 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 1.3718709851673339e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.5 | consumed tokens: 2293760000.0 | grad norm avg: 0.97 | grad norm last: 1.0 | 
2026-01-01T19:12:57 | step: 280100 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.3702230717171915e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.2 | consumed tokens: 2294579200.0 | grad norm avg: 0.96 | grad norm last: 0.9 | 
2026-01-01T19:13:15 | step: 280200 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.3685757949133404e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.08 | consumed tokens: 2295398400.0 | grad norm avg: 0.95 | grad norm last: 0.98 | 
2026-01-01T19:13:33 | step: 280300 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.3669292457052507e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.31 | consumed tokens: 2296217600.0 | grad norm avg: 0.97 | grad norm last: 0.96 | 
2026-01-01T19:13:51 | step: 280400 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.365283242193982e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.27 | consumed tokens: 2297036800.0 | grad norm avg: 0.97 | grad norm last: 0.97 | 
2026-01-01T19:14:09 | step: 280500 | train samples/s: 96.5 | train mfu (16-bit): -1.0 | lr mean: 1.3636377843795344e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.58 | consumed tokens: 2297856000.0 | grad norm avg: 0.97 | grad norm last: 0.92 | 
2026-01-01T19:14:27 | step: 280600 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.3619930541608483e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.5 | consumed tokens: 2298675200.0 | grad norm avg: 0.97 | grad norm last: 0.95 | 
2026-01-01T19:14:45 | step: 280700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.3603489605884533e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.61 | consumed tokens: 2299494400.0 | grad norm avg: 0.96 | grad norm last: 1.02 | 
2026-01-01T19:15:03 | step: 280800 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.3587054127128795e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.69 | consumed tokens: 2300313600.0 | grad norm avg: 0.96 | grad norm last: 0.94 | 
2026-01-01T19:15:21 | step: 280900 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.357062592433067e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.02 | consumed tokens: 2301132800.0 | grad norm avg: 0.97 | grad norm last: 0.95 | 
2026-01-01T19:15:39 | step: 281000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.3554203178500757e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.88 | consumed tokens: 2301952000.0 | grad norm avg: 0.97 | grad norm last: 0.92 | 
2026-01-01T19:15:57 | step: 281100 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.3537786799133755e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.56 | consumed tokens: 2302771200.0 | grad norm avg: 0.97 | grad norm last: 1.0 | 
2026-01-01T19:16:15 | step: 281200 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 1.3521376786229666e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.11 | consumed tokens: 2303590400.0 | grad norm avg: 0.96 | grad norm last: 1.04 | 
2026-01-01T19:16:33 | step: 281300 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.350497313978849e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.97 | consumed tokens: 2304409600.0 | grad norm avg: 0.96 | grad norm last: 0.96 | 
2026-01-01T19:16:51 | step: 281400 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.3488575859810226e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 4.09 | consumed tokens: 2305228800.0 | grad norm avg: 0.97 | grad norm last: 1.05 | 
2026-01-01T19:17:09 | step: 281500 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.3472184946294874e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.06 | consumed tokens: 2306048000.0 | grad norm avg: 0.97 | grad norm last: 0.99 | 
2026-01-01T19:17:27 | step: 281600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.3455800399242435e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.34 | consumed tokens: 2306867200.0 | grad norm avg: 0.96 | grad norm last: 1.01 | 
2026-01-01T19:17:45 | step: 281700 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.3439422218652908e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.75 | consumed tokens: 2307686400.0 | grad norm avg: 0.97 | grad norm last: 1.03 | 
2026-01-01T19:18:03 | step: 281800 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 1.3423049495031592e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.86 | consumed tokens: 2308505600.0 | grad norm avg: 0.96 | grad norm last: 0.99 | 
2026-01-01T19:18:21 | step: 281900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.340668404736789e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.33 | consumed tokens: 2309324800.0 | grad norm avg: 0.97 | grad norm last: 1.06 | 
2026-01-01T19:18:39 | step: 282000 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.33903249661671e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.69 | consumed tokens: 2310144000.0 | grad norm avg: 0.96 | grad norm last: 0.9 | 
2026-01-01T19:18:57 | step: 282100 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.3373972251429223e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.66 | consumed tokens: 2310963200.0 | grad norm avg: 0.97 | grad norm last: 1.0 | 
2026-01-01T19:19:15 | step: 282200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.3357625903154258e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.91 | consumed tokens: 2311782400.0 | grad norm avg: 0.95 | grad norm last: 0.92 | 
2026-01-01T19:19:33 | step: 282300 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 1.3341285011847503e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.19 | consumed tokens: 2312601600.0 | grad norm avg: 0.95 | grad norm last: 0.95 | 
2026-01-01T19:19:51 | step: 282400 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 1.3324951396498363e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.64 | consumed tokens: 2313420800.0 | grad norm avg: 0.97 | grad norm last: 0.9 | 
2026-01-01T19:20:09 | step: 282500 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.3308624147612136e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.14 | consumed tokens: 2314240000.0 | grad norm avg: 0.97 | grad norm last: 1.02 | 
2026-01-01T19:20:27 | step: 282600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.329230326518882e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.33 | consumed tokens: 2315059200.0 | grad norm avg: 0.97 | grad norm last: 0.98 | 
2026-01-01T19:20:45 | step: 282700 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.3275988749228418e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.86 | consumed tokens: 2315878400.0 | grad norm avg: 0.98 | grad norm last: 0.98 | 
2026-01-01T19:21:03 | step: 282800 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.3259680599730927e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.5 | consumed tokens: 2316697600.0 | grad norm avg: 0.96 | grad norm last: 0.98 | 
2026-01-01T19:21:21 | step: 282900 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.3243379726191051e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.77 | consumed tokens: 2317516800.0 | grad norm avg: 0.98 | grad norm last: 0.95 | 
2026-01-01T19:21:39 | step: 283000 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 1.3227084309619386e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.59 | consumed tokens: 2318336000.0 | grad norm avg: 0.97 | grad norm last: 0.99 | 
2026-01-01T19:21:57 | step: 283100 | train samples/s: 96.3 | train mfu (16-bit): -1.0 | lr mean: 1.3210795259510633e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.06 | consumed tokens: 2319155200.0 | grad norm avg: 0.96 | grad norm last: 0.98 | 
2026-01-01T19:22:15 | step: 283200 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.3194513485359494e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.97 | consumed tokens: 2319974400.0 | grad norm avg: 0.97 | grad norm last: 0.89 | 
2026-01-01T19:22:33 | step: 283300 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.3178237168176565e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.23 | consumed tokens: 2320793600.0 | grad norm avg: 0.96 | grad norm last: 0.98 | 
2026-01-01T19:22:51 | step: 283400 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.3161968126951251e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.7 | consumed tokens: 2321612800.0 | grad norm avg: 0.97 | grad norm last: 0.98 | 
2026-01-01T19:23:09 | step: 283500 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.314570545218885e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.2 | consumed tokens: 2322432000.0 | grad norm avg: 0.98 | grad norm last: 0.93 | 
2026-01-01T19:23:27 | step: 283600 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 1.312944914388936e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.98 | consumed tokens: 2323251200.0 | grad norm avg: 0.98 | grad norm last: 0.97 | 
2026-01-01T19:23:45 | step: 283700 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.3113200111547485e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.64 | consumed tokens: 2324070400.0 | grad norm avg: 0.96 | grad norm last: 1.01 | 
2026-01-01T19:24:03 | step: 283800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 1.309695653617382e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.48 | consumed tokens: 2324889600.0 | grad norm avg: 0.97 | grad norm last: 1.01 | 
2026-01-01T19:24:21 | step: 283900 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 1.308072023675777e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.75 | consumed tokens: 2325708800.0 | grad norm avg: 0.97 | grad norm last: 1.0 | 
2026-01-01T19:24:39 | step: 284000 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 1.306448939430993e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.95 | consumed tokens: 2326528000.0 | grad norm avg: 0.97 | grad norm last: 1.01 | 
2026-01-01T19:24:57 | step: 284100 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.3048265827819705e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.62 | consumed tokens: 2327347200.0 | grad norm avg: 0.97 | grad norm last: 0.94 | 
2026-01-01T19:25:15 | step: 284200 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.3032049537287094e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.45 | consumed tokens: 2328166400.0 | grad norm avg: 0.97 | grad norm last: 0.9 | 
2026-01-01T19:25:33 | step: 284300 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.3015838703722693e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.62 | consumed tokens: 2328985600.0 | grad norm avg: 0.96 | grad norm last: 0.88 | 
2026-01-01T19:25:51 | step: 284400 | train samples/s: 96.1 | train mfu (16-bit): -1.0 | lr mean: 1.2999635146115907e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.94 | consumed tokens: 2329804800.0 | grad norm avg: 0.97 | grad norm last: 0.93 | 
2026-01-01T19:26:09 | step: 284500 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.2983437954972032e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.62 | consumed tokens: 2330624000.0 | grad norm avg: 0.97 | grad norm last: 0.95 | 
2026-01-01T19:26:27 | step: 284600 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 1.296724713029107e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.42 | consumed tokens: 2331443200.0 | grad norm avg: 0.97 | grad norm last: 0.95 | 
2026-01-01T19:26:45 | step: 284700 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 1.2951062672073022e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.97 | consumed tokens: 2332262400.0 | grad norm avg: 0.99 | grad norm last: 1.0 | 
2026-01-01T19:27:03 | step: 284800 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 1.2934885489812586e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.56 | consumed tokens: 2333081600.0 | grad norm avg: 0.98 | grad norm last: 0.98 | 
2026-01-01T19:27:21 | step: 284900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.2918714674015064e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.28 | consumed tokens: 2333900800.0 | grad norm avg: 0.96 | grad norm last: 0.96 | 
