==========================================
Experiment 3: Fine-tuning GPT-2 on 5 languages
Job ID: 2149236
Node: jn116
Start time: Thu Jan  1 05:08:06 AM CET 2026
==========================================
Thu Jan  1 05:08:09 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.28.03              Driver Version: 560.28.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA L40                     On  |   00000000:25:00.0 Off |                  Off |
| N/A   31C    P8             35W /  300W |       1MiB /  49140MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Rank 0 received experiment_id: 2026-01-01__05-08-20_a91e58afaade00f6
Instantiated <class 'int'>: settings -> training_target -> num_target_tokens
Instantiated <class 'int'>: settings -> training_target -> num_target_steps -> config -> global_num_tokens
Instantiated <class 'int'>: settings -> training_target -> num_target_steps
Instantiated <class 'modalities.models.huggingface.huggingface_model.HuggingFacePretrainedModel'>: model_raw

Wrapped layer classes: [<class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>]

Instantiated <class 'torch.distributed.fsdp.fully_sharded_data_parallel.FullyShardedDataParallel'>: wrapped_model
=> optimizer groups:
all (148 modules with 124,439,808 parameters): weight_decay = 0.01
=> all (148 modules with 124,439,808 parameters)
Instantiated <class 'torch.optim.adamw.AdamW'>: optimizer
Instantiated <class 'int'>: lr_scheduler -> config -> total_steps -> config -> global_num_tokens
Instantiated <class 'int'>: lr_scheduler -> config -> total_steps
Instantiated <class 'torch.optim.lr_scheduler.OneCycleLR'>: lr_scheduler
Instantiated <class 'modalities.checkpointing.stateful.app_state.AppState'>: app_state
Instantiated <class 'modalities.loss_functions.CLMCrossEntropyLoss'>: loss_fn
Instantiated <class 'modalities.dataloader.dataset.PackedMemMapDatasetContinuous'>: train_dataset
Instantiated <class 'modalities.dataloader.samplers.ResumableDistributedSampler'>: train_dataloader -> config -> batch_sampler -> config -> sampler
Instantiated <class 'torch.utils.data.sampler.BatchSampler'>: train_dataloader -> config -> batch_sampler
Instantiated <class 'modalities.models.gpt2.collator.GPT2LLMCollateFn'>: collate_fn
Instantiated <class 'modalities.dataloader.dataloader.LLMDataLoader'>: train_dataloader
Instantiated <class 'int'>: progress_subscriber -> config -> num_target_steps -> config -> global_num_tokens
Instantiated <class 'int'>: progress_subscriber -> config -> num_target_steps
Instantiated <class 'modalities.logging_broker.subscriber_impl.progress_subscriber.RichProgressSubscriber'>: progress_subscriber
Instantiated <class 'modalities.logging_broker.subscriber_impl.results_subscriber.WandBEvaluationResultSubscriber'>: evaluation_subscriber
Instantiated <class 'modalities.checkpointing.checkpoint_saving_strategies.SaveKMostRecentCheckpointsStrategy'>: checkpoint_saving -> config -> checkpoint_saving_strategy
Instantiated <class 'modalities.checkpointing.fsdp.fsdp_checkpoint_saving.FSDP1CheckpointSaving'>: checkpoint_saving -> config -> checkpoint_saving_execution
Instantiated <class 'modalities.checkpointing.checkpoint_saving.CheckpointSaving'>: checkpoint_saving
Instantiated <class 'modalities.training.gradient_clipping.fsdp_gradient_clipper.FSDP1GradientClipper'>: gradient_clipper
Model initialized at 2026-01-01 05:08:23.962660.



======================== Training Report ========================
Training target: 
	num_target_tokens: 5713174528
	num_target_steps: 697409 
Intervals: 
	training_log_interval_in_steps: 100
	checkpointing_interval_in_steps: 5000
	evaluation_interval_in_steps: 1000
Step profile: 
	gradient_accumulation_steps: 4
	local_train_micro_batch_size: 4
	sequence_length: 512
	dp_degree: 1
CUDA environment settings: 
	local_rank: 0
	world_size: 1
	global_rank: 0
Consistency enforcement: 
	enforce_tokens_per_step_consistency: True
	enforce_last_step_logged: False
	enforce_last_step_evaluated: False
	enforce_last_step_checkpointed: False
Training progress: 
	global_num_seen_tokens: 0
	num_seen_steps: 0
	num_seen_samples: 0
	last_step: -1
Warnings: 
	[38;5;214mNumber of tokens in the dataset (5713177600) does not match the number of target tokens (5713174528). Missing 0.00% of tokens in the dataset.
	Last step will not be logged. Since remaining_steps (697409) is not a multiple of training_log_interval_in_steps (100).
	Last step will not be evaluated. Since remaining_steps (697409) is not a multiple of evaluation_interval_in_steps (1000).
	Last step will not be checkpointed. Since remaining_steps (697409) is not a multiple of checkpointing_interval_in_steps (5000). [0m 
====================================================================



Start model training at 2026-01-01 05:08:23.963035.
2026-01-01T05:08:46 | step: 100 | train samples/s: 77.8 | train mfu (16-bit): -1.0 | lr mean: 5.0228313739353325e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.32 | train loss last: 4.19 | consumed tokens: 819200.0 | grad norm avg: 3.0 | grad norm last: 2.67 | 
2026-01-01T05:09:07 | step: 200 | train samples/s: 82.8 | train mfu (16-bit): -1.0 | lr mean: 5.0912785809487104e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.27 | train loss last: 4.31 | consumed tokens: 1638400.0 | grad norm avg: 2.68 | grad norm last: 2.56 | 
2026-01-01T05:09:28 | step: 300 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 5.205202796787489e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.21 | train loss last: 3.56 | consumed tokens: 2457600.0 | grad norm avg: 2.63 | grad norm last: 2.7 | 
2026-01-01T05:09:48 | step: 400 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 5.3643730097974185e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.18 | train loss last: 4.06 | consumed tokens: 3276800.0 | grad norm avg: 2.58 | grad norm last: 2.59 | 
2026-01-01T05:10:09 | step: 500 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 5.568465894612018e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.13 | train loss last: 4.0 | consumed tokens: 4096000.0 | grad norm avg: 2.53 | grad norm last: 2.54 | 
2026-01-01T05:10:29 | step: 600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 5.817067631141981e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.15 | train loss last: 4.19 | consumed tokens: 4915200.0 | grad norm avg: 2.52 | grad norm last: 2.61 | 
2026-01-01T05:10:50 | step: 700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 6.109673449827824e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.11 | train loss last: 3.77 | consumed tokens: 5734400.0 | grad norm avg: 2.49 | grad norm last: 2.56 | 
2026-01-01T05:11:10 | step: 800 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 6.445689905376639e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.11 | train loss last: 4.22 | consumed tokens: 6553600.0 | grad norm avg: 2.51 | grad norm last: 2.37 | 
2026-01-01T05:11:31 | step: 900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 6.824434422014747e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.08 | train loss last: 3.77 | consumed tokens: 7372800.0 | grad norm avg: 2.46 | grad norm last: 2.38 | 
2026-01-01T05:11:51 | step: 1000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 7.245138931466499e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.11 | train loss last: 4.34 | consumed tokens: 8192000.0 | grad norm avg: 2.41 | grad norm last: 2.39 | 
2026-01-01T05:12:12 | step: 1100 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 7.706949872954283e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.07 | train loss last: 4.25 | consumed tokens: 9011200.0 | grad norm avg: 2.42 | grad norm last: 2.35 | 
2026-01-01T05:12:32 | step: 1200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 8.208928193198517e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.08 | train loss last: 3.55 | consumed tokens: 9830400.0 | grad norm avg: 2.37 | grad norm last: 2.26 | 
2026-01-01T05:12:53 | step: 1300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 8.75005753186997e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.05 | train loss last: 3.88 | consumed tokens: 10649600.0 | grad norm avg: 2.39 | grad norm last: 2.37 | 
2026-01-01T05:13:13 | step: 1400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 9.329239219368901e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.04 | train loss last: 4.78 | consumed tokens: 11468800.0 | grad norm avg: 2.34 | grad norm last: 2.32 | 
2026-01-01T05:13:34 | step: 1500 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 9.945296369551215e-06 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.01 | train loss last: 4.34 | consumed tokens: 12288000.0 | grad norm avg: 2.28 | grad norm last: 2.15 | 
2026-01-01T05:13:54 | step: 1600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 1.0596980246191379e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.08 | train loss last: 4.5 | consumed tokens: 13107200.0 | grad norm avg: 2.31 | grad norm last: 2.2 | 
2026-01-01T05:14:15 | step: 1700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 1.1282967534498312e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.02 | train loss last: 4.19 | consumed tokens: 13926400.0 | grad norm avg: 2.27 | grad norm last: 2.25 | 
2026-01-01T05:14:35 | step: 1800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 1.20018657980836e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.03 | train loss last: 4.0 | consumed tokens: 14745600.0 | grad norm avg: 2.26 | grad norm last: 2.31 | 
2026-01-01T05:14:56 | step: 1900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 1.2752217116940301e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 4.01 | train loss last: 3.55 | consumed tokens: 15564800.0 | grad norm avg: 2.21 | grad norm last: 2.15 | 
2026-01-01T05:15:16 | step: 2000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 1.3532498087442946e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.99 | train loss last: 3.78 | consumed tokens: 16384000.0 | grad norm avg: 2.16 | grad norm last: 2.36 | 
2026-01-01T05:15:37 | step: 2100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 1.4341125279315747e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.99 | train loss last: 4.19 | consumed tokens: 17203200.0 | grad norm avg: 2.13 | grad norm last: 1.99 | 
2026-01-01T05:15:57 | step: 2200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 1.5176457964116707e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.98 | train loss last: 4.31 | consumed tokens: 18022400.0 | grad norm avg: 2.09 | grad norm last: 2.03 | 
2026-01-01T05:16:18 | step: 2300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 1.603679993422702e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.99 | train loss last: 4.09 | consumed tokens: 18841600.0 | grad norm avg: 2.1 | grad norm last: 1.88 | 
2026-01-01T05:16:38 | step: 2400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 1.692040495981928e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.99 | train loss last: 3.89 | consumed tokens: 19660800.0 | grad norm avg: 2.07 | grad norm last: 2.04 | 
2026-01-01T05:16:58 | step: 2500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 1.78254831553204e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.96 | train loss last: 3.86 | consumed tokens: 20480000.0 | grad norm avg: 2.0 | grad norm last: 1.96 | 
2026-01-01T05:17:19 | step: 2600 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 1.8750193703453988e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.93 | train loss last: 4.25 | consumed tokens: 21299200.0 | grad norm avg: 1.96 | grad norm last: 2.0 | 
2026-01-01T05:17:39 | step: 2700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 1.9692661226144992e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.93 | train loss last: 4.25 | consumed tokens: 22118400.0 | grad norm avg: 1.95 | grad norm last: 2.21 | 
2026-01-01T05:18:00 | step: 2800 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 2.065097214654088e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.96 | train loss last: 3.5 | consumed tokens: 22937600.0 | grad norm avg: 1.9 | grad norm last: 1.87 | 
2026-01-01T05:18:21 | step: 2900 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.1623183783958666e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.92 | train loss last: 4.12 | consumed tokens: 23756800.0 | grad norm avg: 1.87 | grad norm last: 1.74 | 
2026-01-01T05:18:41 | step: 3000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.2607322534895502e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.89 | train loss last: 4.16 | consumed tokens: 24576000.0 | grad norm avg: 1.86 | grad norm last: 1.86 | 
2026-01-01T05:19:02 | step: 3100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.3601391148986295e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.87 | train loss last: 4.16 | consumed tokens: 25395200.0 | grad norm avg: 1.81 | grad norm last: 1.98 | 
2026-01-01T05:19:22 | step: 3200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.460337054799311e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.92 | train loss last: 3.77 | consumed tokens: 26214400.0 | grad norm avg: 1.77 | grad norm last: 1.85 | 
2026-01-01T05:19:43 | step: 3300 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 2.5611228920752183e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.88 | train loss last: 4.22 | consumed tokens: 27033600.0 | grad norm avg: 1.71 | grad norm last: 1.61 | 
2026-01-01T05:20:03 | step: 3400 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 2.6622919904184528e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.85 | train loss last: 3.36 | consumed tokens: 27852800.0 | grad norm avg: 1.69 | grad norm last: 1.62 | 
2026-01-01T05:20:24 | step: 3500 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.7636391678242944e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.87 | train loss last: 4.19 | consumed tokens: 28672000.0 | grad norm avg: 1.68 | grad norm last: 1.54 | 
2026-01-01T05:20:44 | step: 3600 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 2.8649586965912022e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.87 | train loss last: 4.12 | consumed tokens: 29491200.0 | grad norm avg: 1.62 | grad norm last: 1.47 | 
2026-01-01T05:21:05 | step: 3700 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.966044849017635e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.85 | train loss last: 3.36 | consumed tokens: 30310400.0 | grad norm avg: 1.57 | grad norm last: 1.57 | 
2026-01-01T05:21:25 | step: 3800 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 3.066692443098873e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.84 | train loss last: 3.83 | consumed tokens: 31129600.0 | grad norm avg: 1.55 | grad norm last: 1.51 | 
2026-01-01T05:21:46 | step: 3900 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.1666975701227784e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.81 | train loss last: 4.19 | consumed tokens: 31948800.0 | grad norm avg: 1.52 | grad norm last: 1.44 | 
2026-01-01T05:22:06 | step: 4000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.265856867074035e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.81 | train loss last: 3.81 | consumed tokens: 32768000.0 | grad norm avg: 1.5 | grad norm last: 1.53 | 
2026-01-01T05:22:27 | step: 4100 | train samples/s: 82.9 | train mfu (16-bit): -1.0 | lr mean: 3.363969153724611e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.83 | train loss last: 4.31 | consumed tokens: 33587200.0 | grad norm avg: 1.47 | grad norm last: 1.35 | 
2026-01-01T05:22:48 | step: 4200 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.460835796431638e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.81 | train loss last: 4.12 | consumed tokens: 34406400.0 | grad norm avg: 1.46 | grad norm last: 1.52 | 
2026-01-01T05:23:08 | step: 4300 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.556259616743773e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.8 | train loss last: 4.03 | consumed tokens: 35225600.0 | grad norm avg: 1.43 | grad norm last: 1.37 | 
2026-01-01T05:23:29 | step: 4400 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 3.650047074188478e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.78 | train loss last: 4.0 | consumed tokens: 36044800.0 | grad norm avg: 1.42 | grad norm last: 1.48 | 
2026-01-01T05:23:49 | step: 4500 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.742008266272023e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.8 | train loss last: 3.77 | consumed tokens: 36864000.0 | grad norm avg: 1.39 | grad norm last: 1.38 | 
2026-01-01T05:24:10 | step: 4600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.831955837085843e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.78 | train loss last: 3.75 | consumed tokens: 37683200.0 | grad norm avg: 1.37 | grad norm last: 1.35 | 
2026-01-01T05:24:30 | step: 4700 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 3.919707887689583e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.8 | train loss last: 4.06 | consumed tokens: 38502400.0 | grad norm avg: 1.34 | grad norm last: 1.24 | 
2026-01-01T05:24:51 | step: 4800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.0050861571216956e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.75 | train loss last: 3.77 | consumed tokens: 39321600.0 | grad norm avg: 1.32 | grad norm last: 1.29 | 
2026-01-01T05:25:11 | step: 4900 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.0879171137930825e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.79 | train loss last: 4.94 | consumed tokens: 40140800.0 | grad norm avg: 1.29 | grad norm last: 1.25 | 
2026-01-01T05:25:32 | step: 5000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.168033046880737e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.76 | train loss last: 3.66 | consumed tokens: 40960000.0 | grad norm avg: 1.28 | grad norm last: 1.3 | 
2026-01-01T05:25:54 | step: 5100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.245270974934101e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.73 | train loss last: 3.86 | consumed tokens: 41779200.0 | grad norm avg: 1.27 | grad norm last: 1.28 | 
2026-01-01T05:26:15 | step: 5200 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.31947446486447e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.75 | train loss last: 4.12 | consumed tokens: 42598400.0 | grad norm avg: 1.24 | grad norm last: 1.28 | 
2026-01-01T05:26:35 | step: 5300 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.39049290434923e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.73 | train loss last: 3.64 | consumed tokens: 43417600.0 | grad norm avg: 1.24 | grad norm last: 1.23 | 
2026-01-01T05:26:56 | step: 5400 | train samples/s: 82.8 | train mfu (16-bit): -1.0 | lr mean: 4.45818186562974e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.76 | train loss last: 3.44 | consumed tokens: 44236800.0 | grad norm avg: 1.22 | grad norm last: 1.27 | 
2026-01-01T05:27:16 | step: 5500 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.522404196904972e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.73 | train loss last: 4.31 | consumed tokens: 45056000.0 | grad norm avg: 1.2 | grad norm last: 1.15 | 
2026-01-01T05:27:37 | step: 5600 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.583029658533633e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.71 | train loss last: 4.12 | consumed tokens: 45875200.0 | grad norm avg: 1.17 | grad norm last: 1.13 | 
2026-01-01T05:27:58 | step: 5700 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.639934923034161e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.75 | train loss last: 3.95 | consumed tokens: 46694400.0 | grad norm avg: 1.17 | grad norm last: 1.14 | 
2026-01-01T05:28:18 | step: 5800 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.693004666478373e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.72 | train loss last: 3.28 | consumed tokens: 47513600.0 | grad norm avg: 1.14 | grad norm last: 1.12 | 
2026-01-01T05:28:39 | step: 5900 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.742131568491459e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.7 | train loss last: 3.86 | consumed tokens: 48332800.0 | grad norm avg: 1.12 | grad norm last: 1.03 | 
2026-01-01T05:28:59 | step: 6000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.787215220858343e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.71 | train loss last: 3.88 | consumed tokens: 49152000.0 | grad norm avg: 1.13 | grad norm last: 1.08 | 
2026-01-01T05:29:20 | step: 6100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.828164674108848e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.71 | train loss last: 3.91 | consumed tokens: 49971200.0 | grad norm avg: 1.1 | grad norm last: 1.14 | 
2026-01-01T05:29:40 | step: 6200 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.864896254730411e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.72 | train loss last: 3.69 | consumed tokens: 50790400.0 | grad norm avg: 1.08 | grad norm last: 1.03 | 
2026-01-01T05:30:01 | step: 6300 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.897336111753248e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.69 | train loss last: 3.33 | consumed tokens: 51609600.0 | grad norm avg: 1.07 | grad norm last: 1.03 | 
2026-01-01T05:30:21 | step: 6400 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.925418033963069e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.67 | train loss last: 3.78 | consumed tokens: 52428800.0 | grad norm avg: 1.06 | grad norm last: 1.04 | 
2026-01-01T05:30:42 | step: 6500 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.949085268890485e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.67 | train loss last: 3.39 | consumed tokens: 53248000.0 | grad norm avg: 1.05 | grad norm last: 1.02 | 
2026-01-01T05:31:02 | step: 6600 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.968289431417361e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.67 | train loss last: 3.48 | consumed tokens: 54067200.0 | grad norm avg: 1.04 | grad norm last: 0.96 | 
2026-01-01T05:31:23 | step: 6700 | train samples/s: 82.8 | train mfu (16-bit): -1.0 | lr mean: 4.9829915951704606e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.66 | train loss last: 3.95 | consumed tokens: 54886400.0 | grad norm avg: 1.03 | grad norm last: 1.05 | 
2026-01-01T05:31:44 | step: 6800 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.993161928723566e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.66 | train loss last: 3.55 | consumed tokens: 55705600.0 | grad norm avg: 1.02 | grad norm last: 1.09 | 
2026-01-01T05:32:04 | step: 6900 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.998780059395358e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.68 | train loss last: 3.11 | consumed tokens: 56524800.0 | grad norm avg: 1.01 | grad norm last: 1.01 | 
2026-01-01T05:32:25 | step: 7000 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.999999873689376e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.65 | train loss last: 4.03 | consumed tokens: 57344000.0 | grad norm avg: 0.99 | grad norm last: 0.99 | 
2026-01-01T05:32:46 | step: 7100 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.999999509891495e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.67 | train loss last: 4.03 | consumed tokens: 58163200.0 | grad norm avg: 1.01 | grad norm last: 0.99 | 
2026-01-01T05:33:06 | step: 7200 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.999998782295734e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.66 | train loss last: 3.8 | consumed tokens: 58982400.0 | grad norm avg: 1.0 | grad norm last: 1.0 | 
2026-01-01T05:33:27 | step: 7300 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.999997327104211e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.64 | train loss last: 3.61 | consumed tokens: 59801600.0 | grad norm avg: 0.98 | grad norm last: 0.92 | 
2026-01-01T05:33:47 | step: 7400 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9999951443169266e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.64 | train loss last: 3.0 | consumed tokens: 60620800.0 | grad norm avg: 0.97 | grad norm last: 1.02 | 
2026-01-01T05:34:08 | step: 7500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9999929615296423e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.67 | train loss last: 3.67 | consumed tokens: 61440000.0 | grad norm avg: 0.97 | grad norm last: 1.03 | 
2026-01-01T05:34:28 | step: 7600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.999989687348716e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.62 | train loss last: 4.28 | consumed tokens: 62259200.0 | grad norm avg: 0.97 | grad norm last: 0.96 | 
2026-01-01T05:34:49 | step: 7700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9999864131677896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.66 | train loss last: 3.39 | consumed tokens: 63078400.0 | grad norm avg: 0.95 | grad norm last: 0.9 | 
2026-01-01T05:35:09 | step: 7800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.999982411391102e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.62 | train loss last: 3.69 | consumed tokens: 63897600.0 | grad norm avg: 0.95 | grad norm last: 0.95 | 
2026-01-01T05:35:30 | step: 7900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9999776820186526e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.62 | train loss last: 3.47 | consumed tokens: 64716800.0 | grad norm avg: 0.95 | grad norm last: 1.03 | 
2026-01-01T05:35:50 | step: 8000 | train samples/s: 82.9 | train mfu (16-bit): -1.0 | lr mean: 4.9999725888483226e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.64 | train loss last: 3.42 | consumed tokens: 65536000.0 | grad norm avg: 0.96 | grad norm last: 0.98 | 
2026-01-01T05:36:11 | step: 8100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.999967131880112e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.58 | train loss last: 3.55 | consumed tokens: 66355200.0 | grad norm avg: 0.94 | grad norm last: 0.94 | 
2026-01-01T05:36:31 | step: 8200 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.99996094731614e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.61 | train loss last: 3.3 | consumed tokens: 67174400.0 | grad norm avg: 0.94 | grad norm last: 0.91 | 
2026-01-01T05:36:52 | step: 8300 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.999954398954287e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.63 | train loss last: 3.44 | consumed tokens: 67993600.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-01T05:37:12 | step: 8400 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.999947486794554e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.62 | train loss last: 3.69 | consumed tokens: 68812800.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-01T05:37:33 | step: 8500 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.999939847039059e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.62 | train loss last: 4.22 | consumed tokens: 69632000.0 | grad norm avg: 0.92 | grad norm last: 0.98 | 
2026-01-01T05:37:54 | step: 8600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9999314796878025e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.61 | train loss last: 3.36 | consumed tokens: 70451200.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T05:38:14 | step: 8700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.9999227485386655e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.62 | train loss last: 3.66 | consumed tokens: 71270400.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-01T05:38:35 | step: 8800 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.999913653591648e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.61 | train loss last: 3.67 | consumed tokens: 72089600.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-01T05:38:55 | step: 8900 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.9999038310488686e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.62 | train loss last: 3.73 | consumed tokens: 72908800.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T05:39:16 | step: 9000 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.999893644708209e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.6 | train loss last: 4.06 | consumed tokens: 73728000.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T05:39:36 | step: 9100 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.999883094569668e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.59 | train loss last: 3.08 | consumed tokens: 74547200.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T05:39:57 | step: 9200 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.999871816835366e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.58 | train loss last: 3.77 | consumed tokens: 75366400.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T05:40:18 | step: 9300 | train samples/s: 82.5 | train mfu (16-bit): -1.0 | lr mean: 4.9998601753031835e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.59 | train loss last: 3.7 | consumed tokens: 76185600.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T05:40:39 | step: 9400 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.9998478061752394e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.59 | train loss last: 4.28 | consumed tokens: 77004800.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T05:40:59 | step: 9500 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.9998350732494146e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.61 | train loss last: 3.67 | consumed tokens: 77824000.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T05:41:20 | step: 9600 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.999821612727828e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.57 | train loss last: 3.67 | consumed tokens: 78643200.0 | grad norm avg: 0.89 | grad norm last: 0.98 | 
2026-01-01T05:41:40 | step: 9700 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.9998077884083614e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.56 | train loss last: 3.47 | consumed tokens: 79462400.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T05:42:01 | step: 9800 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.999793236493133e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.6 | train loss last: 3.84 | consumed tokens: 80281600.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T05:42:21 | step: 9900 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.9997786845779046e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.56 | train loss last: 2.98 | consumed tokens: 81100800.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T05:42:42 | step: 10000 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.999763041269034e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.55 | train loss last: 3.22 | consumed tokens: 81920000.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T05:43:04 | step: 10100 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.999747034162283e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.58 | train loss last: 3.55 | consumed tokens: 82739200.0 | grad norm avg: 0.88 | grad norm last: 0.95 | 
2026-01-01T05:43:25 | step: 10200 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 4.999730663257651e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.59 | train loss last: 3.78 | consumed tokens: 83558400.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T05:43:45 | step: 10300 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.9997139285551384e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.57 | train loss last: 3.36 | consumed tokens: 84377600.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T05:44:06 | step: 10400 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.9996964662568644e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.55 | train loss last: 3.67 | consumed tokens: 85196800.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T05:44:27 | step: 10500 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.999678276362829e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.56 | train loss last: 3.38 | consumed tokens: 86016000.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T05:44:47 | step: 10600 | train samples/s: 82.8 | train mfu (16-bit): -1.0 | lr mean: 4.9996600864687935e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.53 | train loss last: 3.47 | consumed tokens: 86835200.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T05:45:08 | step: 10700 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.999640805181116e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.55 | train loss last: 3.7 | consumed tokens: 87654400.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T05:45:29 | step: 10800 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.999621523893438e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.55 | train loss last: 3.5 | consumed tokens: 88473600.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T05:45:49 | step: 10900 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.9996011512121186e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.53 | train loss last: 3.09 | consumed tokens: 89292800.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T05:46:10 | step: 11000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.999580778530799e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.56 | train loss last: 3.81 | consumed tokens: 90112000.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T05:46:30 | step: 11100 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.999559678253718e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.56 | train loss last: 3.2 | consumed tokens: 90931200.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T05:46:51 | step: 11200 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.999538214178756e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.58 | train loss last: 3.55 | consumed tokens: 91750400.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T05:47:11 | step: 11300 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9995160225080326e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.54 | train loss last: 3.64 | consumed tokens: 92569600.0 | grad norm avg: 0.86 | grad norm last: 0.91 | 
2026-01-01T05:47:32 | step: 11400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9994934670394287e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.56 | train loss last: 3.33 | consumed tokens: 93388800.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T05:47:52 | step: 11500 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 4.999470183975063e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.55 | train loss last: 3.09 | consumed tokens: 94208000.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T05:48:13 | step: 11600 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.999446537112817e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.52 | train loss last: 3.73 | consumed tokens: 95027200.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-01T05:48:33 | step: 11700 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9994225264526904e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.55 | train loss last: 3.75 | consumed tokens: 95846400.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T05:48:54 | step: 11800 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.999397788196802e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.53 | train loss last: 3.34 | consumed tokens: 96665600.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T05:49:15 | step: 11900 | train samples/s: 82.5 | train mfu (16-bit): -1.0 | lr mean: 4.9993723223451525e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.55 | train loss last: 3.53 | consumed tokens: 97484800.0 | grad norm avg: 0.85 | grad norm last: 0.88 | 
2026-01-01T05:49:35 | step: 12000 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.999346856493503e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.55 | train loss last: 2.91 | consumed tokens: 98304000.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T05:49:56 | step: 12100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.999320299248211e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.53 | train loss last: 3.8 | consumed tokens: 99123200.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T05:50:16 | step: 12200 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.999293742002919e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.55 | train loss last: 3.53 | consumed tokens: 99942400.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T05:50:37 | step: 12300 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.999266457161866e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.54 | train loss last: 3.03 | consumed tokens: 100761600.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T05:50:58 | step: 12400 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 4.9992384447250515e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.56 | train loss last: 3.45 | consumed tokens: 101580800.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T05:51:18 | step: 12500 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.999210432288237e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.53 | train loss last: 3.58 | consumed tokens: 102400000.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T05:51:39 | step: 12600 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.99918132845778e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.54 | train loss last: 3.61 | consumed tokens: 103219200.0 | grad norm avg: 0.85 | grad norm last: 0.87 | 
2026-01-01T05:51:59 | step: 12700 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9991522246273234e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.51 | train loss last: 3.19 | consumed tokens: 104038400.0 | grad norm avg: 0.85 | grad norm last: 0.85 | 
2026-01-01T05:52:20 | step: 12800 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.999122393201105e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.51 | train loss last: 3.75 | consumed tokens: 104857600.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T05:52:40 | step: 12900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.999091834179126e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.49 | train loss last: 3.22 | consumed tokens: 105676800.0 | grad norm avg: 0.85 | grad norm last: 0.87 | 
2026-01-01T05:53:01 | step: 13000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9990609113592654e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.53 | train loss last: 3.7 | consumed tokens: 106496000.0 | grad norm avg: 0.85 | grad norm last: 0.86 | 
2026-01-01T05:53:21 | step: 13100 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.9990296247415245e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.5 | train loss last: 3.42 | consumed tokens: 107315200.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T05:53:42 | step: 13200 | train samples/s: 82.9 | train mfu (16-bit): -1.0 | lr mean: 4.998997610528022e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.51 | train loss last: 3.38 | consumed tokens: 108134400.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T05:54:03 | step: 13300 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.998965232516639e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.49 | train loss last: 3.5 | consumed tokens: 108953600.0 | grad norm avg: 0.85 | grad norm last: 0.9 | 
2026-01-01T05:54:23 | step: 13400 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.9989321269094944e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.49 | train loss last: 3.52 | consumed tokens: 109772800.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T05:54:44 | step: 13500 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.998898657504469e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.52 | train loss last: 3.14 | consumed tokens: 110592000.0 | grad norm avg: 0.85 | grad norm last: 0.84 | 
2026-01-01T05:55:04 | step: 13600 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.998864824301563e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.52 | train loss last: 3.5 | consumed tokens: 111411200.0 | grad norm avg: 0.85 | grad norm last: 0.83 | 
2026-01-01T05:55:25 | step: 13700 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 4.998830263502896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.52 | train loss last: 3.31 | consumed tokens: 112230400.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T05:55:46 | step: 13800 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.998794975108467e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.48 | train loss last: 3.05 | consumed tokens: 113049600.0 | grad norm avg: 0.85 | grad norm last: 0.81 | 
2026-01-01T05:56:06 | step: 13900 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.998759686714038e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.52 | train loss last: 3.45 | consumed tokens: 113868800.0 | grad norm avg: 0.85 | grad norm last: 0.86 | 
2026-01-01T05:56:27 | step: 14000 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.998723670723848e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.49 | train loss last: 3.58 | consumed tokens: 114688000.0 | grad norm avg: 0.85 | grad norm last: 0.88 | 
2026-01-01T05:56:48 | step: 14100 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 4.9986869271378964e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.48 | train loss last: 3.89 | consumed tokens: 115507200.0 | grad norm avg: 0.85 | grad norm last: 0.84 | 
2026-01-01T05:57:08 | step: 14200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.998649819754064e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.52 | train loss last: 3.09 | consumed tokens: 116326400.0 | grad norm avg: 0.85 | grad norm last: 0.83 | 
2026-01-01T05:57:29 | step: 14300 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.998612348572351e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.51 | train loss last: 3.69 | consumed tokens: 117145600.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T05:57:49 | step: 14400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.9985741497948766e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.5 | train loss last: 3.84 | consumed tokens: 117964800.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T05:58:10 | step: 14500 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 4.998535223421641e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.48 | train loss last: 3.53 | consumed tokens: 118784000.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T05:58:30 | step: 14600 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.998496297048405e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.97 | consumed tokens: 119603200.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T05:58:51 | step: 14700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.9984566430794075e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.52 | train loss last: 3.34 | consumed tokens: 120422400.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T05:59:11 | step: 14800 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.998416261514649e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.48 | train loss last: 3.97 | consumed tokens: 121241600.0 | grad norm avg: 0.85 | grad norm last: 0.79 | 
2026-01-01T05:59:32 | step: 14900 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.9983755161520094e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.5 | train loss last: 3.39 | consumed tokens: 122060800.0 | grad norm avg: 0.83 | grad norm last: 0.81 | 
2026-01-01T05:59:53 | step: 15000 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.998334406991489e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.5 | train loss last: 3.06 | consumed tokens: 122880000.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T06:00:15 | step: 15100 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.998292570235208e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.52 | train loss last: 3.61 | consumed tokens: 123699200.0 | grad norm avg: 0.85 | grad norm last: 0.84 | 
2026-01-01T06:00:35 | step: 15200 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9982503696810454e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 2.98 | consumed tokens: 124518400.0 | grad norm avg: 0.85 | grad norm last: 0.81 | 
2026-01-01T06:00:56 | step: 15300 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.998207441531122e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.49 | train loss last: 3.58 | consumed tokens: 125337600.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T06:01:16 | step: 15400 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.9981641495833173e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.51 | train loss last: 3.73 | consumed tokens: 126156800.0 | grad norm avg: 0.83 | grad norm last: 0.81 | 
2026-01-01T06:01:37 | step: 15500 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.998120493837632e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.48 | train loss last: 3.55 | consumed tokens: 126976000.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T06:01:58 | step: 15600 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.998076110496186e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.49 | train loss last: 3.44 | consumed tokens: 127795200.0 | grad norm avg: 0.85 | grad norm last: 0.85 | 
2026-01-01T06:02:18 | step: 15700 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9980313633568585e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.45 | train loss last: 3.56 | consumed tokens: 128614400.0 | grad norm avg: 0.84 | grad norm last: 0.88 | 
2026-01-01T06:02:39 | step: 15800 | train samples/s: 82.5 | train mfu (16-bit): -1.0 | lr mean: 4.99798588862177e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.46 | train loss last: 3.52 | consumed tokens: 129433600.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T06:03:00 | step: 15900 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.9979400500888005e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.46 | train loss last: 3.42 | consumed tokens: 130252800.0 | grad norm avg: 0.83 | grad norm last: 0.81 | 
2026-01-01T06:03:20 | step: 16000 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.99789348396007e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.23 | consumed tokens: 131072000.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T06:03:41 | step: 16100 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.997846554033458e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.51 | train loss last: 3.67 | consumed tokens: 131891200.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T06:04:01 | step: 16200 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.997799260308966e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.46 | train loss last: 4.12 | consumed tokens: 132710400.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T06:04:22 | step: 16300 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.9977512389887124e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.45 | train loss last: 3.25 | consumed tokens: 133529600.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T06:04:42 | step: 16400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.997702853870578e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.48 | train loss last: 3.23 | consumed tokens: 134348800.0 | grad norm avg: 0.85 | grad norm last: 0.84 | 
2026-01-01T06:05:03 | step: 16500 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.9976537411566824e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.5 | consumed tokens: 135168000.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T06:05:24 | step: 16600 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.997604264644906e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.45 | train loss last: 3.55 | consumed tokens: 135987200.0 | grad norm avg: 0.85 | grad norm last: 0.8 | 
2026-01-01T06:05:44 | step: 16700 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.997554424335249e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.25 | consumed tokens: 136806400.0 | grad norm avg: 0.85 | grad norm last: 0.8 | 
2026-01-01T06:06:05 | step: 16800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.99750385642983e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.33 | consumed tokens: 137625600.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T06:06:25 | step: 16900 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.99745256092865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.45 | train loss last: 3.41 | consumed tokens: 138444800.0 | grad norm avg: 0.84 | grad norm last: 0.91 | 
2026-01-01T06:06:46 | step: 17000 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.99740126542747e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.97 | consumed tokens: 139264000.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T06:07:07 | step: 17100 | train samples/s: 82.7 | train mfu (16-bit): -1.0 | lr mean: 4.997348878532648e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.48 | train loss last: 3.75 | consumed tokens: 140083200.0 | grad norm avg: 0.84 | grad norm last: 0.78 | 
2026-01-01T06:07:27 | step: 17200 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.997296491637826e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.48 | train loss last: 2.98 | consumed tokens: 140902400.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T06:07:48 | step: 17300 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.9972433771472424e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.49 | train loss last: 2.58 | consumed tokens: 141721600.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T06:08:09 | step: 17400 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.9971895350608975e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.46 | train loss last: 2.78 | consumed tokens: 142540800.0 | grad norm avg: 0.84 | grad norm last: 0.77 | 
2026-01-01T06:08:29 | step: 17500 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.997135329176672e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.14 | consumed tokens: 143360000.0 | grad norm avg: 0.84 | grad norm last: 0.78 | 
2026-01-01T06:08:50 | step: 17600 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.9970807594945654e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.46 | train loss last: 3.02 | consumed tokens: 144179200.0 | grad norm avg: 0.84 | grad norm last: 0.87 | 
2026-01-01T06:09:10 | step: 17700 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.9970258260145783e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.48 | train loss last: 4.41 | consumed tokens: 144998400.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T06:09:31 | step: 17800 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.996969801140949e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.38 | consumed tokens: 145817600.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T06:09:51 | step: 17900 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.99691377626732e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.77 | consumed tokens: 146636800.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T06:10:12 | step: 18000 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.996857023797929e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.49 | train loss last: 3.14 | consumed tokens: 147456000.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T06:10:33 | step: 18100 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.996799907530658e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.48 | train loss last: 3.95 | consumed tokens: 148275200.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T06:10:53 | step: 18200 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.996742063667625e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 2.83 | consumed tokens: 149094400.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T06:11:14 | step: 18300 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.996683856006712e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.59 | consumed tokens: 149913600.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T06:11:34 | step: 18400 | train samples/s: 82.7 | train mfu (16-bit): -1.0 | lr mean: 4.996624920750037e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.36 | consumed tokens: 150732800.0 | grad norm avg: 0.84 | grad norm last: 0.9 | 
2026-01-01T06:11:55 | step: 18500 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.996565621695481e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.47 | consumed tokens: 151552000.0 | grad norm avg: 0.83 | grad norm last: 0.79 | 
2026-01-01T06:12:16 | step: 18600 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.996505595045164e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.45 | train loss last: 3.41 | consumed tokens: 152371200.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T06:12:36 | step: 18700 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9964452045969665e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.33 | consumed tokens: 153190400.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T06:12:57 | step: 18800 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.996384450350888e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.48 | train loss last: 3.38 | consumed tokens: 154009600.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T06:13:17 | step: 18900 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.996322968509048e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.45 | train loss last: 3.56 | consumed tokens: 154828800.0 | grad norm avg: 0.84 | grad norm last: 0.89 | 
2026-01-01T06:13:38 | step: 19000 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.996261122869328e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.28 | consumed tokens: 155648000.0 | grad norm avg: 0.84 | grad norm last: 0.87 | 
2026-01-01T06:13:58 | step: 19100 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.9961989134317264e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.47 | consumed tokens: 156467200.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T06:14:19 | step: 19200 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 4.996135976398364e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.39 | consumed tokens: 157286400.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T06:14:40 | step: 19300 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 4.9960723117692396e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.45 | train loss last: 3.64 | consumed tokens: 158105600.0 | grad norm avg: 0.84 | grad norm last: 0.88 | 
2026-01-01T06:15:00 | step: 19400 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.996008283342235e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.46 | train loss last: 3.56 | consumed tokens: 158924800.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T06:15:21 | step: 19500 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.995943891117349e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.46 | train loss last: 3.94 | consumed tokens: 159744000.0 | grad norm avg: 0.83 | grad norm last: 0.78 | 
2026-01-01T06:15:41 | step: 19600 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.995879135094583e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.31 | consumed tokens: 160563200.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T06:16:02 | step: 19700 | train samples/s: 82.6 | train mfu (16-bit): -1.0 | lr mean: 4.995813287678175e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.06 | consumed tokens: 161382400.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T06:16:23 | step: 19800 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.995747440261766e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.31 | consumed tokens: 162201600.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T06:16:43 | step: 19900 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.9956808652495965e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.45 | train loss last: 3.17 | consumed tokens: 163020800.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T06:17:04 | step: 20000 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.995613926439546e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.69 | consumed tokens: 163840000.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T06:17:26 | step: 20100 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 4.995546260033734e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.14 | consumed tokens: 164659200.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T06:17:47 | step: 20200 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.9954782298300415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.72 | consumed tokens: 165478400.0 | grad norm avg: 0.83 | grad norm last: 0.77 | 
2026-01-01T06:18:07 | step: 20300 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.9954094720305875e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.11 | consumed tokens: 166297600.0 | grad norm avg: 0.84 | grad norm last: 0.78 | 
2026-01-01T06:18:28 | step: 20400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.995340350433253e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.56 | consumed tokens: 167116800.0 | grad norm avg: 0.83 | grad norm last: 0.84 | 
2026-01-01T06:18:49 | step: 20500 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 4.995270865038037e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.34 | consumed tokens: 167936000.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T06:19:09 | step: 20600 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 4.9952006520470604e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.25 | consumed tokens: 168755200.0 | grad norm avg: 0.83 | grad norm last: 0.86 | 
2026-01-01T06:19:30 | step: 20700 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.995130075258203e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.47 | train loss last: 3.19 | consumed tokens: 169574400.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T06:19:50 | step: 20800 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.995058770873584e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.53 | consumed tokens: 170393600.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T06:20:11 | step: 20900 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 4.994987102691084e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.69 | consumed tokens: 171212800.0 | grad norm avg: 0.84 | grad norm last: 0.87 | 
2026-01-01T06:20:32 | step: 21000 | train samples/s: 82.9 | train mfu (16-bit): -1.0 | lr mean: 4.994914706912823e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.34 | consumed tokens: 172032000.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T06:20:53 | step: 21100 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 4.994841947336681e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.62 | consumed tokens: 172851200.0 | grad norm avg: 0.83 | grad norm last: 0.79 | 
2026-01-01T06:21:13 | step: 21200 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9947688239626586e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.56 | consumed tokens: 173670400.0 | grad norm avg: 0.83 | grad norm last: 0.89 | 
2026-01-01T06:21:34 | step: 21300 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.994694972992875e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 2.97 | consumed tokens: 174489600.0 | grad norm avg: 0.83 | grad norm last: 0.86 | 
2026-01-01T06:21:54 | step: 21400 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.99462075822521e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.12 | consumed tokens: 175308800.0 | grad norm avg: 0.83 | grad norm last: 0.81 | 
2026-01-01T06:22:15 | step: 21500 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.994545815861784e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.41 | consumed tokens: 176128000.0 | grad norm avg: 0.83 | grad norm last: 0.81 | 
2026-01-01T06:22:35 | step: 21600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.994470509700477e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.31 | consumed tokens: 176947200.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T06:22:56 | step: 21700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.9943948397412896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.62 | consumed tokens: 177766400.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T06:23:16 | step: 21800 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 4.994318442186341e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.48 | consumed tokens: 178585600.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T06:23:37 | step: 21900 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.994241680833511e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.16 | consumed tokens: 179404800.0 | grad norm avg: 0.83 | grad norm last: 0.84 | 
2026-01-01T06:23:58 | step: 22000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.99416419188492e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.25 | consumed tokens: 180224000.0 | grad norm avg: 0.83 | grad norm last: 0.89 | 
2026-01-01T06:24:18 | step: 22100 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.994086339138448e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 2.98 | consumed tokens: 181043200.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T06:24:39 | step: 22200 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 4.994007758796215e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.48 | consumed tokens: 181862400.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T06:25:00 | step: 22300 | train samples/s: 82.9 | train mfu (16-bit): -1.0 | lr mean: 4.993928814656101e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 2.86 | consumed tokens: 182681600.0 | grad norm avg: 0.84 | grad norm last: 0.96 | 
2026-01-01T06:25:20 | step: 22400 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.9938495067181066e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.45 | consumed tokens: 183500800.0 | grad norm avg: 0.82 | grad norm last: 0.84 | 
2026-01-01T06:25:41 | step: 22500 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.9937694711843506e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.2 | consumed tokens: 184320000.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T06:26:01 | step: 22600 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.993689071852714e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.06 | consumed tokens: 185139200.0 | grad norm avg: 0.83 | grad norm last: 0.76 | 
2026-01-01T06:26:22 | step: 22700 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.993607944925316e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.55 | consumed tokens: 185958400.0 | grad norm avg: 0.83 | grad norm last: 0.84 | 
2026-01-01T06:26:43 | step: 22800 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.993526454200037e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.03 | consumed tokens: 186777600.0 | grad norm avg: 0.83 | grad norm last: 0.91 | 
2026-01-01T06:27:03 | step: 22900 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.993444599676877e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.91 | consumed tokens: 187596800.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T06:27:24 | step: 23000 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.993362017557956e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.47 | consumed tokens: 188416000.0 | grad norm avg: 0.82 | grad norm last: 0.8 | 
2026-01-01T06:27:44 | step: 23100 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 4.9932790716411546e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.72 | consumed tokens: 189235200.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T06:28:05 | step: 23200 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9931953981285915e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.27 | consumed tokens: 190054400.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T06:28:25 | step: 23300 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9931113608181477e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.09 | consumed tokens: 190873600.0 | grad norm avg: 0.83 | grad norm last: 0.84 | 
2026-01-01T06:28:46 | step: 23400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.9930265959119424e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.08 | consumed tokens: 191692800.0 | grad norm avg: 0.84 | grad norm last: 0.78 | 
2026-01-01T06:29:07 | step: 23500 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 4.9929414672078565e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.38 | consumed tokens: 192512000.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T06:29:27 | step: 23600 | train samples/s: 82.8 | train mfu (16-bit): -1.0 | lr mean: 4.99285597470589e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.25 | consumed tokens: 193331200.0 | grad norm avg: 0.83 | grad norm last: 0.87 | 
2026-01-01T06:29:48 | step: 23700 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 4.992769754608162e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.34 | consumed tokens: 194150400.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T06:30:09 | step: 23800 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.992683170712553e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.44 | train loss last: 3.52 | consumed tokens: 194969600.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T06:30:29 | step: 23900 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.992595859221183e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 2.84 | consumed tokens: 195788800.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T06:30:50 | step: 24000 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.992508183931932e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.31 | consumed tokens: 196608000.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T06:31:10 | step: 24100 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.9924201448448e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.45 | consumed tokens: 197427200.0 | grad norm avg: 0.83 | grad norm last: 0.84 | 
2026-01-01T06:31:31 | step: 24200 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.992331378161907e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 2.58 | consumed tokens: 198246400.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T06:31:52 | step: 24300 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.992241883883253e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 4.03 | consumed tokens: 199065600.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T06:32:12 | step: 24400 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 4.992152389604598e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.44 | consumed tokens: 199884800.0 | grad norm avg: 0.83 | grad norm last: 0.78 | 
2026-01-01T06:32:33 | step: 24500 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.9920621677301824e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.05 | consumed tokens: 200704000.0 | grad norm avg: 0.83 | grad norm last: 0.88 | 
2026-01-01T06:32:53 | step: 24600 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.991971218260005e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.22 | consumed tokens: 201523200.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T06:33:14 | step: 24700 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.991879904991947e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.62 | consumed tokens: 202342400.0 | grad norm avg: 0.82 | grad norm last: 0.85 | 
2026-01-01T06:33:35 | step: 24800 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.9917882279260084e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.09 | consumed tokens: 203161600.0 | grad norm avg: 0.84 | grad norm last: 0.89 | 
2026-01-01T06:33:55 | step: 24900 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.991695823264308e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.61 | consumed tokens: 203980800.0 | grad norm avg: 0.83 | grad norm last: 0.78 | 
2026-01-01T06:34:16 | step: 25000 | train samples/s: 82.4 | train mfu (16-bit): -1.0 | lr mean: 4.9916030548047274e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.38 | consumed tokens: 204800000.0 | grad norm avg: 0.83 | grad norm last: 0.88 | 
2026-01-01T06:34:38 | step: 25100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.991509558749385e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.83 | consumed tokens: 205619200.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T06:34:59 | step: 25200 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 4.991415698896162e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.02 | consumed tokens: 206438400.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T06:35:20 | step: 25300 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 4.991321111447178e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.44 | consumed tokens: 207257600.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T06:35:40 | step: 25400 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.9912265239981934e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.98 | consumed tokens: 208076800.0 | grad norm avg: 0.83 | grad norm last: 0.81 | 
2026-01-01T06:36:01 | step: 25500 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.991130845155567e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.17 | consumed tokens: 208896000.0 | grad norm avg: 0.83 | grad norm last: 0.85 | 
2026-01-01T06:36:21 | step: 25600 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.99103480251506e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.34 | consumed tokens: 209715200.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T06:36:42 | step: 25700 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 4.990938396076672e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.67 | consumed tokens: 210534400.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T06:37:03 | step: 25800 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.990841625840403e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.06 | consumed tokens: 211353600.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T06:37:23 | step: 25900 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.990744128008373e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.27 | consumed tokens: 212172800.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T06:37:44 | step: 26000 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.9906459025805816e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.43 | train loss last: 3.41 | consumed tokens: 212992000.0 | grad norm avg: 0.83 | grad norm last: 0.78 | 
2026-01-01T06:38:05 | step: 26100 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 4.99054767715279e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 2.94 | consumed tokens: 213811200.0 | grad norm avg: 0.83 | grad norm last: 0.81 | 
2026-01-01T06:38:25 | step: 26200 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.9904483603313565e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.25 | consumed tokens: 214630400.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T06:38:46 | step: 26300 | train samples/s: 82.7 | train mfu (16-bit): -1.0 | lr mean: 4.990349043509923e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.8 | consumed tokens: 215449600.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T06:39:07 | step: 26400 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.990248999092728e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.41 | train loss last: 3.64 | consumed tokens: 216268800.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T06:39:27 | step: 26500 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 4.9901482270797715e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.31 | consumed tokens: 217088000.0 | grad norm avg: 0.82 | grad norm last: 0.83 | 
2026-01-01T06:39:48 | step: 26600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.990047091268934e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.42 | train loss last: 3.34 | consumed tokens: 217907200.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T06:40:08 | step: 26700 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.9899455916602165e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.14 | consumed tokens: 218726400.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T06:40:29 | step: 26800 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.989843364455737e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 2.53 | consumed tokens: 219545600.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T06:40:49 | step: 26900 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.989740773453377e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.67 | consumed tokens: 220364800.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T06:41:10 | step: 27000 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 4.9896378186531365e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.48 | consumed tokens: 221184000.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T06:41:31 | step: 27100 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.9895341362571344e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.38 | consumed tokens: 222003200.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T06:41:51 | step: 27200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.989429726265371e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.11 | consumed tokens: 222822400.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T06:42:12 | step: 27300 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 4.9893249524757266e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.44 | consumed tokens: 223641600.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T06:42:32 | step: 27400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9892198148882017e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.81 | consumed tokens: 224460800.0 | grad norm avg: 0.83 | grad norm last: 0.88 | 
2026-01-01T06:42:53 | step: 27500 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.989114313502796e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.17 | consumed tokens: 225280000.0 | grad norm avg: 0.83 | grad norm last: 0.85 | 
2026-01-01T06:43:14 | step: 27600 | train samples/s: 82.3 | train mfu (16-bit): -1.0 | lr mean: 4.989008084521629e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.59 | consumed tokens: 226099200.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T06:43:34 | step: 27700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.9889011279447004e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 4.25 | consumed tokens: 226918400.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T06:43:55 | step: 27800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.988793807569891e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.52 | consumed tokens: 227737600.0 | grad norm avg: 0.83 | grad norm last: 0.93 | 
2026-01-01T06:44:15 | step: 27900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.988686123397201e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.58 | consumed tokens: 228556800.0 | grad norm avg: 0.84 | grad norm last: 0.92 | 
2026-01-01T06:44:36 | step: 28000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.98857771162875e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.42 | consumed tokens: 229376000.0 | grad norm avg: 0.83 | grad norm last: 0.79 | 
2026-01-01T06:44:56 | step: 28100 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.988468936062418e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 2.97 | consumed tokens: 230195200.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T06:45:17 | step: 28200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.988359796698205e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.28 | consumed tokens: 231014400.0 | grad norm avg: 0.83 | grad norm last: 0.87 | 
2026-01-01T06:45:37 | step: 28300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.988249929738231e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.27 | consumed tokens: 231833600.0 | grad norm avg: 0.84 | grad norm last: 0.79 | 
2026-01-01T06:45:58 | step: 28400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9881393351824954e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.86 | consumed tokens: 232652800.0 | grad norm avg: 0.83 | grad norm last: 0.89 | 
2026-01-01T06:46:18 | step: 28500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.98802874062676e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.12 | consumed tokens: 233472000.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T06:46:39 | step: 28600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.987917054677382e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.55 | consumed tokens: 234291200.0 | grad norm avg: 0.83 | grad norm last: 0.87 | 
2026-01-01T06:46:59 | step: 28700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9878053687280044e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.73 | consumed tokens: 235110400.0 | grad norm avg: 0.83 | grad norm last: 0.76 | 
2026-01-01T06:47:19 | step: 28800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.987692955182865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.84 | consumed tokens: 235929600.0 | grad norm avg: 0.83 | grad norm last: 0.89 | 
2026-01-01T06:47:40 | step: 28900 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 4.987579814041965e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.42 | consumed tokens: 236748800.0 | grad norm avg: 0.83 | grad norm last: 0.81 | 
2026-01-01T06:48:01 | step: 29000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.9874663091031834e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 2.77 | consumed tokens: 237568000.0 | grad norm avg: 0.83 | grad norm last: 0.79 | 
2026-01-01T06:48:21 | step: 29100 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.9873524403665215e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.4 | train loss last: 3.11 | consumed tokens: 238387200.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T06:48:41 | step: 29200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.987238207831979e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.02 | consumed tokens: 239206400.0 | grad norm avg: 0.83 | grad norm last: 0.96 | 
2026-01-01T06:49:02 | step: 29300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.987122883903794e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.5 | consumed tokens: 240025600.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T06:49:22 | step: 29400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.987007559975609e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.28 | consumed tokens: 240844800.0 | grad norm avg: 0.85 | grad norm last: 0.86 | 
2026-01-01T06:49:43 | step: 29500 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.986891508451663e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.5 | consumed tokens: 241664000.0 | grad norm avg: 0.84 | grad norm last: 0.88 | 
2026-01-01T06:50:03 | step: 29600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.986775093129836e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.17 | consumed tokens: 242483200.0 | grad norm avg: 0.85 | grad norm last: 0.9 | 
2026-01-01T06:50:24 | step: 29700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.986657950212248e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.27 | consumed tokens: 243302400.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T06:50:44 | step: 29800 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.9865404434967786e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 2.7 | consumed tokens: 244121600.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T06:51:04 | step: 29900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.986422209185548e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.34 | consumed tokens: 244940800.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T06:51:25 | step: 30000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.986303611076437e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 2.83 | consumed tokens: 245760000.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T06:51:47 | step: 30100 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.986184649169445e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.48 | consumed tokens: 246579200.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T06:52:08 | step: 30200 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 4.986064959666692e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.47 | consumed tokens: 247398400.0 | grad norm avg: 0.84 | grad norm last: 0.88 | 
2026-01-01T06:52:28 | step: 30300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.985944906366058e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 2.98 | consumed tokens: 248217600.0 | grad norm avg: 0.83 | grad norm last: 0.78 | 
2026-01-01T06:52:49 | step: 30400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.985824125469662e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.38 | train loss last: 3.0 | consumed tokens: 249036800.0 | grad norm avg: 0.83 | grad norm last: 0.84 | 
2026-01-01T06:53:09 | step: 30500 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.985702980775386e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.73 | consumed tokens: 249856000.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T06:53:30 | step: 30600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.985581472283229e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 2.55 | consumed tokens: 250675200.0 | grad norm avg: 0.83 | grad norm last: 0.88 | 
2026-01-01T06:53:50 | step: 30700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.985459236195311e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.08 | consumed tokens: 251494400.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T06:54:11 | step: 30800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.985336272511631e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 4.06 | consumed tokens: 252313600.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T06:54:31 | step: 30900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9852133088279516e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.67 | consumed tokens: 253132800.0 | grad norm avg: 0.84 | grad norm last: 0.87 | 
2026-01-01T06:54:52 | step: 31000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9850896175485104e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 2.78 | consumed tokens: 253952000.0 | grad norm avg: 0.83 | grad norm last: 0.87 | 
2026-01-01T06:55:12 | step: 31100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.984965198673308e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.0 | consumed tokens: 254771200.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T06:55:32 | step: 31200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.9848404160002246e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 2.91 | consumed tokens: 255590400.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T06:55:53 | step: 31300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.984715269529261e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.72 | consumed tokens: 256409600.0 | grad norm avg: 0.84 | grad norm last: 0.87 | 
2026-01-01T06:56:13 | step: 31400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.984589395462535e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.33 | consumed tokens: 257228800.0 | grad norm avg: 0.83 | grad norm last: 0.89 | 
2026-01-01T06:56:34 | step: 31500 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 4.984463157597929e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.53 | consumed tokens: 258048000.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T06:56:55 | step: 31600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.984336192137562e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.58 | consumed tokens: 258867200.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T06:57:15 | step: 31700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9842088628793135e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.83 | consumed tokens: 259686400.0 | grad norm avg: 0.84 | grad norm last: 0.89 | 
2026-01-01T06:57:36 | step: 31800 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.9840811698231846e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.28 | consumed tokens: 260505600.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T06:57:56 | step: 31900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.983952749171294e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.39 | train loss last: 3.75 | consumed tokens: 261324800.0 | grad norm avg: 0.83 | grad norm last: 0.94 | 
2026-01-01T06:58:16 | step: 32000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.983823964721523e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.05 | consumed tokens: 262144000.0 | grad norm avg: 0.84 | grad norm last: 0.78 | 
2026-01-01T06:58:37 | step: 32100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.983694452675991e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.48 | consumed tokens: 262963200.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T06:58:57 | step: 32200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9835645768325776e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.28 | consumed tokens: 263782400.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T06:59:18 | step: 32300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.983434337191284e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 2.94 | consumed tokens: 264601600.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T06:59:38 | step: 32400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.9833033699542284e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.34 | consumed tokens: 265420800.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T06:59:59 | step: 32500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.983171675121412e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.0 | consumed tokens: 266240000.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T07:00:19 | step: 32600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.983039980288595e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.38 | consumed tokens: 267059200.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T07:00:40 | step: 32700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.982907194062136e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.03 | consumed tokens: 267878400.0 | grad norm avg: 0.83 | grad norm last: 0.78 | 
2026-01-01T07:01:00 | step: 32800 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 4.982774407835677e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.61 | consumed tokens: 268697600.0 | grad norm avg: 0.83 | grad norm last: 0.86 | 
2026-01-01T07:01:21 | step: 32900 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.982640894013457e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.72 | consumed tokens: 269516800.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T07:01:41 | step: 33000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.982507016393356e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.12 | consumed tokens: 270336000.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T07:02:02 | step: 33100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9823724111774936e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.23 | consumed tokens: 271155200.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T07:02:22 | step: 33200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9822374421637505e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.48 | consumed tokens: 271974400.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T07:02:43 | step: 33300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.982101745554246e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.84 | consumed tokens: 272793600.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T07:03:03 | step: 33400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.981965685146861e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.77 | consumed tokens: 273612800.0 | grad norm avg: 0.84 | grad norm last: 0.79 | 
2026-01-01T07:03:24 | step: 33500 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.981829260941595e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 4.06 | consumed tokens: 274432000.0 | grad norm avg: 0.83 | grad norm last: 0.79 | 
2026-01-01T07:03:44 | step: 33600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9816921091405675e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.66 | consumed tokens: 275251200.0 | grad norm avg: 0.84 | grad norm last: 0.77 | 
2026-01-01T07:04:05 | step: 33700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.9815545935416594e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.69 | consumed tokens: 276070400.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T07:04:25 | step: 33800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.98141635034699e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.3 | consumed tokens: 276889600.0 | grad norm avg: 0.82 | grad norm last: 0.75 | 
2026-01-01T07:04:46 | step: 33900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.98127774335444e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.33 | consumed tokens: 277708800.0 | grad norm avg: 0.83 | grad norm last: 0.85 | 
2026-01-01T07:05:06 | step: 34000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.981138408766128e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 4.16 | consumed tokens: 278528000.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T07:05:27 | step: 34100 | train samples/s: 82.8 | train mfu (16-bit): -1.0 | lr mean: 4.980998710379936e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 4.09 | consumed tokens: 279347200.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T07:05:48 | step: 34200 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.980858648195863e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.09 | consumed tokens: 280166400.0 | grad norm avg: 0.83 | grad norm last: 0.94 | 
2026-01-01T07:06:08 | step: 34300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.980717858416028e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.36 | consumed tokens: 280985600.0 | grad norm avg: 0.83 | grad norm last: 0.85 | 
2026-01-01T07:06:29 | step: 34400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.980576704838313e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.31 | consumed tokens: 281804800.0 | grad norm avg: 0.84 | grad norm last: 0.79 | 
2026-01-01T07:06:49 | step: 34500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.980435187462717e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.28 | consumed tokens: 282624000.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T07:07:09 | step: 34600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.98029294249136e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.48 | consumed tokens: 283443200.0 | grad norm avg: 0.83 | grad norm last: 0.84 | 
2026-01-01T07:07:30 | step: 34700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.980150333722122e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.09 | consumed tokens: 284262400.0 | grad norm avg: 0.83 | grad norm last: 0.85 | 
2026-01-01T07:07:50 | step: 34800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9800069973571226e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.2 | consumed tokens: 285081600.0 | grad norm avg: 0.84 | grad norm last: 0.91 | 
2026-01-01T07:08:11 | step: 34900 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.9798632971942425e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.44 | consumed tokens: 285900800.0 | grad norm avg: 0.84 | grad norm last: 0.79 | 
2026-01-01T07:08:31 | step: 35000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.979718869435601e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.58 | consumed tokens: 286720000.0 | grad norm avg: 0.83 | grad norm last: 0.85 | 
2026-01-01T07:08:54 | step: 35100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.979574077879079e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.23 | consumed tokens: 287539200.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T07:09:14 | step: 35200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.979428922524676e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 2.92 | consumed tokens: 288358400.0 | grad norm avg: 0.84 | grad norm last: 0.79 | 
2026-01-01T07:09:35 | step: 35300 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.9792830395745113e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.66 | consumed tokens: 289177600.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T07:09:55 | step: 35400 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.979136792826466e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.28 | consumed tokens: 289996800.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T07:10:16 | step: 35500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.97898981848266e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.59 | consumed tokens: 290816000.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T07:10:36 | step: 35600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.9788424803409725e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.8 | consumed tokens: 291635200.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T07:10:57 | step: 35700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9786947784014046e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.17 | consumed tokens: 292454400.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T07:11:17 | step: 35800 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.978546348866075e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.2 | consumed tokens: 293273600.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T07:11:38 | step: 35900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9783971917349845e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.3 | consumed tokens: 294092800.0 | grad norm avg: 0.83 | grad norm last: 0.78 | 
2026-01-01T07:11:58 | step: 36000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.978248034603894e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.33 | consumed tokens: 294912000.0 | grad norm avg: 0.83 | grad norm last: 0.87 | 
2026-01-01T07:12:19 | step: 36100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9780981498770416e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.7 | consumed tokens: 295731200.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T07:12:39 | step: 36200 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.977947537554428e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.33 | consumed tokens: 296550400.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T07:13:00 | step: 36300 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.977796561433934e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.52 | consumed tokens: 297369600.0 | grad norm avg: 0.82 | grad norm last: 0.85 | 
2026-01-01T07:13:20 | step: 36400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.9776452215155587e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.31 | consumed tokens: 298188800.0 | grad norm avg: 0.83 | grad norm last: 0.87 | 
2026-01-01T07:13:41 | step: 36500 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.977493154001422e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.55 | consumed tokens: 299008000.0 | grad norm avg: 0.83 | grad norm last: 0.84 | 
2026-01-01T07:14:01 | step: 36600 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.977340722689405e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.37 | train loss last: 3.52 | consumed tokens: 299827200.0 | grad norm avg: 0.84 | grad norm last: 0.77 | 
2026-01-01T07:14:22 | step: 36700 | train samples/s: 82.8 | train mfu (16-bit): -1.0 | lr mean: 4.977187927579507e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 2.92 | consumed tokens: 300646400.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T07:14:43 | step: 36800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.977034404873848e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.03 | consumed tokens: 301465600.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T07:15:03 | step: 36900 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.976880154572427e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.42 | consumed tokens: 302284800.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T07:15:24 | step: 37000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9767259042710066e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.25 | consumed tokens: 303104000.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T07:15:44 | step: 37100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.976570562575944e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.42 | consumed tokens: 303923200.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T07:16:05 | step: 37200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.976415220880881e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.45 | consumed tokens: 304742400.0 | grad norm avg: 0.83 | grad norm last: 0.85 | 
2026-01-01T07:16:25 | step: 37300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.976259151590057e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.16 | consumed tokens: 305561600.0 | grad norm avg: 0.83 | grad norm last: 0.9 | 
2026-01-01T07:16:46 | step: 37400 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.976102718501352e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.55 | consumed tokens: 306380800.0 | grad norm avg: 0.82 | grad norm last: 0.75 | 
2026-01-01T07:17:06 | step: 37500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9759455578168854e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 4.34 | consumed tokens: 307200000.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T07:17:26 | step: 37600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.9757880333345383e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.28 | consumed tokens: 308019200.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T07:17:47 | step: 37700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.97562978125643e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 4.16 | consumed tokens: 308838400.0 | grad norm avg: 0.83 | grad norm last: 0.86 | 
2026-01-01T07:18:07 | step: 37800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.9754711653804407e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.09 | consumed tokens: 309657600.0 | grad norm avg: 0.84 | grad norm last: 0.88 | 
2026-01-01T07:18:28 | step: 37900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.97531182190869e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 2.94 | consumed tokens: 310476800.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T07:18:49 | step: 38000 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 4.9751524784369394e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.66 | consumed tokens: 311296000.0 | grad norm avg: 0.82 | grad norm last: 0.79 | 
2026-01-01T07:19:09 | step: 38100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.974992043571547e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 4.06 | consumed tokens: 312115200.0 | grad norm avg: 0.83 | grad norm last: 0.85 | 
2026-01-01T07:19:29 | step: 38200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.974831608706154e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.34 | consumed tokens: 312934400.0 | grad norm avg: 0.83 | grad norm last: 0.89 | 
2026-01-01T07:19:50 | step: 38300 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.974670446245e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.33 | consumed tokens: 313753600.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T07:20:10 | step: 38400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.974508556188084e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 2.97 | consumed tokens: 314572800.0 | grad norm avg: 0.83 | grad norm last: 0.85 | 
2026-01-01T07:20:31 | step: 38500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.974346302333288e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.52 | consumed tokens: 315392000.0 | grad norm avg: 0.83 | grad norm last: 0.78 | 
2026-01-01T07:20:51 | step: 38600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.974183684680611e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.67 | consumed tokens: 316211200.0 | grad norm avg: 0.83 | grad norm last: 0.76 | 
2026-01-01T07:21:12 | step: 38700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.9740203394321725e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 2.95 | consumed tokens: 317030400.0 | grad norm avg: 0.83 | grad norm last: 0.87 | 
2026-01-01T07:21:32 | step: 38800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9738566303858534e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.61 | consumed tokens: 317849600.0 | grad norm avg: 0.83 | grad norm last: 0.86 | 
2026-01-01T07:21:52 | step: 38900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.9736925575416535e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.44 | consumed tokens: 318668800.0 | grad norm avg: 0.82 | grad norm last: 0.77 | 
2026-01-01T07:22:13 | step: 39000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.973527757101692e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.69 | consumed tokens: 319488000.0 | grad norm avg: 0.83 | grad norm last: 0.85 | 
2026-01-01T07:22:33 | step: 39100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.97336259286385e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.78 | consumed tokens: 320307200.0 | grad norm avg: 0.84 | grad norm last: 0.79 | 
2026-01-01T07:22:54 | step: 39200 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.973196701030247e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.12 | consumed tokens: 321126400.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T07:23:15 | step: 39300 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.973030445398763e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.39 | consumed tokens: 321945600.0 | grad norm avg: 0.82 | grad norm last: 0.87 | 
2026-01-01T07:23:35 | step: 39400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.972863462171517e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 2.84 | consumed tokens: 322764800.0 | grad norm avg: 0.83 | grad norm last: 0.84 | 
2026-01-01T07:23:56 | step: 39500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.972696115146391e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.11 | consumed tokens: 323584000.0 | grad norm avg: 0.83 | grad norm last: 0.84 | 
2026-01-01T07:24:16 | step: 39600 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.972528404323384e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 2.78 | consumed tokens: 324403200.0 | grad norm avg: 0.84 | grad norm last: 1.25 | 
2026-01-01T07:24:37 | step: 39700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.972359965904616e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.19 | consumed tokens: 325222400.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T07:24:57 | step: 39800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.972191163687967e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.89 | consumed tokens: 326041600.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T07:25:17 | step: 39900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.972021997673437e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.31 | consumed tokens: 326860800.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T07:25:38 | step: 40000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.971852104063146e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.36 | train loss last: 3.06 | consumed tokens: 327680000.0 | grad norm avg: 0.83 | grad norm last: 0.87 | 
2026-01-01T07:26:00 | step: 40100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.971681482857093e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.41 | consumed tokens: 328499200.0 | grad norm avg: 0.83 | grad norm last: 0.81 | 
2026-01-01T07:26:20 | step: 40200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.97151049785316e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.19 | consumed tokens: 329318400.0 | grad norm avg: 0.83 | grad norm last: 0.91 | 
2026-01-01T07:26:41 | step: 40300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.971339149051346e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.17 | consumed tokens: 330137600.0 | grad norm avg: 0.84 | grad norm last: 0.87 | 
2026-01-01T07:27:01 | step: 40400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.971167436451651e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 2.81 | consumed tokens: 330956800.0 | grad norm avg: 0.85 | grad norm last: 0.86 | 
2026-01-01T07:27:22 | step: 40500 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.970994996256195e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.58 | consumed tokens: 331776000.0 | grad norm avg: 0.83 | grad norm last: 0.88 | 
2026-01-01T07:27:43 | step: 40600 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.9708218284649774e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 2.83 | consumed tokens: 332595200.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T07:28:03 | step: 40700 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.97064866067376e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.56 | consumed tokens: 333414400.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T07:28:24 | step: 40800 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.9704744014889e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.09 | consumed tokens: 334233600.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T07:28:44 | step: 40900 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.9703001423040405e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 3.16 | consumed tokens: 335052800.0 | grad norm avg: 0.83 | grad norm last: 0.96 | 
2026-01-01T07:29:05 | step: 41000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9701251555234194e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.05 | consumed tokens: 335872000.0 | grad norm avg: 0.83 | grad norm last: 0.87 | 
2026-01-01T07:29:25 | step: 41100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.969949441147037e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 2.81 | consumed tokens: 336691200.0 | grad norm avg: 0.83 | grad norm last: 0.9 | 
2026-01-01T07:29:46 | step: 41200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.969773726770654e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.56 | consumed tokens: 337510400.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T07:30:06 | step: 41300 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.96959692100063e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.03 | consumed tokens: 338329600.0 | grad norm avg: 0.83 | grad norm last: 0.86 | 
2026-01-01T07:30:27 | step: 41400 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.969420115230605e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.03 | consumed tokens: 339148800.0 | grad norm avg: 0.84 | grad norm last: 0.88 | 
2026-01-01T07:30:47 | step: 41500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.969242581864819e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.8 | consumed tokens: 339968000.0 | grad norm avg: 0.83 | grad norm last: 0.81 | 
2026-01-01T07:31:08 | step: 41600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9690643209032714e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.06 | consumed tokens: 340787200.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T07:31:28 | step: 41700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.968885696143843e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.78 | consumed tokens: 341606400.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T07:31:49 | step: 41800 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.968706707586534e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 2.95 | consumed tokens: 342425600.0 | grad norm avg: 0.83 | grad norm last: 0.79 | 
2026-01-01T07:32:09 | step: 41900 | train samples/s: 82.8 | train mfu (16-bit): -1.0 | lr mean: 4.968526991433464e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.45 | consumed tokens: 343244800.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T07:32:30 | step: 42000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.968346911482513e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.34 | train loss last: 2.83 | consumed tokens: 344064000.0 | grad norm avg: 0.83 | grad norm last: 0.92 | 
2026-01-01T07:32:50 | step: 42100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.968166467733681e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.09 | consumed tokens: 344883200.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T07:33:11 | step: 42200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.967985296389088e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.06 | consumed tokens: 345702400.0 | grad norm avg: 0.84 | grad norm last: 0.78 | 
2026-01-01T07:33:31 | step: 42300 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.967803761246614e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.36 | consumed tokens: 346521600.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T07:33:52 | step: 42400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.967621498508379e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.23 | consumed tokens: 347340800.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T07:34:12 | step: 42500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.967438871972263e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.61 | consumed tokens: 348160000.0 | grad norm avg: 0.83 | grad norm last: 0.87 | 
2026-01-01T07:34:33 | step: 42600 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.967255881638266e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.88 | consumed tokens: 348979200.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T07:34:53 | step: 42700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.967072163708508e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.77 | consumed tokens: 349798400.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T07:35:14 | step: 42800 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 4.966888081980869e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 4.0 | consumed tokens: 350617600.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T07:35:34 | step: 42900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.966703272657469e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.81 | consumed tokens: 351436800.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T07:35:55 | step: 43000 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.966518099536188e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.69 | consumed tokens: 352256000.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T07:36:15 | step: 43100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.9663321988191456e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.16 | consumed tokens: 353075200.0 | grad norm avg: 0.84 | grad norm last: 0.77 | 
2026-01-01T07:36:36 | step: 43200 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.9661459343042225e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.66 | consumed tokens: 353894400.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T07:36:57 | step: 43300 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.9659593059914187e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.45 | consumed tokens: 354713600.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T07:37:17 | step: 43400 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.9657719500828534e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.75 | consumed tokens: 355532800.0 | grad norm avg: 0.84 | grad norm last: 0.92 | 
2026-01-01T07:37:38 | step: 43500 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9655842303764075e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.38 | consumed tokens: 356352000.0 | grad norm avg: 0.83 | grad norm last: 0.81 | 
2026-01-01T07:37:58 | step: 43600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.965396146872081e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.61 | consumed tokens: 357171200.0 | grad norm avg: 0.83 | grad norm last: 0.81 | 
2026-01-01T07:38:19 | step: 43700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.965207335771993e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.67 | consumed tokens: 357990400.0 | grad norm avg: 0.83 | grad norm last: 0.81 | 
2026-01-01T07:38:39 | step: 43800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.965018160874024e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 2.59 | consumed tokens: 358809600.0 | grad norm avg: 0.83 | grad norm last: 0.92 | 
2026-01-01T07:39:00 | step: 43900 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.964828258380294e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.33 | train loss last: 3.0 | consumed tokens: 359628800.0 | grad norm avg: 0.85 | grad norm last: 0.86 | 
2026-01-01T07:39:20 | step: 44000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.964637992088683e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 4.16 | consumed tokens: 360448000.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T07:39:41 | step: 44100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.9644469982013106e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.59 | consumed tokens: 361267200.0 | grad norm avg: 0.83 | grad norm last: 0.92 | 
2026-01-01T07:40:01 | step: 44200 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.964256004313938e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.0 | consumed tokens: 362086400.0 | grad norm avg: 0.84 | grad norm last: 0.87 | 
2026-01-01T07:40:22 | step: 44300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.964063919032924e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.34 | consumed tokens: 362905600.0 | grad norm avg: 0.83 | grad norm last: 0.9 | 
2026-01-01T07:40:42 | step: 44400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9638718337519094e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.52 | consumed tokens: 363724800.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T07:41:03 | step: 44500 | train samples/s: 82.9 | train mfu (16-bit): -1.0 | lr mean: 4.963678657077253e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.03 | consumed tokens: 364544000.0 | grad norm avg: 0.83 | grad norm last: 0.84 | 
2026-01-01T07:41:23 | step: 44600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.963485480402596e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.28 | consumed tokens: 365363200.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T07:41:44 | step: 44700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.963291576132178e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.23 | consumed tokens: 366182400.0 | grad norm avg: 0.84 | grad norm last: 0.76 | 
2026-01-01T07:42:04 | step: 44800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.9630973080638796e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.35 | train loss last: 3.05 | consumed tokens: 367001600.0 | grad norm avg: 0.83 | grad norm last: 0.84 | 
2026-01-01T07:42:25 | step: 44900 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.9629023123998195e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.11 | consumed tokens: 367820800.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T07:42:45 | step: 45000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.962706952937879e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.88 | consumed tokens: 368640000.0 | grad norm avg: 0.85 | grad norm last: 0.84 | 
2026-01-01T07:43:07 | step: 45100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.9625108658801764e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.32 | train loss last: 3.52 | consumed tokens: 369459200.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T07:43:28 | step: 45200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.962314778822474e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.3 | consumed tokens: 370278400.0 | grad norm avg: 0.85 | grad norm last: 0.83 | 
2026-01-01T07:43:48 | step: 45300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.96211760037113e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.56 | consumed tokens: 371097600.0 | grad norm avg: 0.84 | grad norm last: 0.78 | 
2026-01-01T07:44:09 | step: 45400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.9619204219197854e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.16 | consumed tokens: 371916800.0 | grad norm avg: 0.83 | grad norm last: 0.79 | 
2026-01-01T07:44:29 | step: 45500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.961722152074799e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.91 | consumed tokens: 372736000.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T07:44:49 | step: 45600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.9615238822298124e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.45 | consumed tokens: 373555200.0 | grad norm avg: 0.83 | grad norm last: 0.73 | 
2026-01-01T07:45:10 | step: 45700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.9613248847890645e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.2 | consumed tokens: 374374400.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T07:45:31 | step: 45800 | train samples/s: 82.8 | train mfu (16-bit): -1.0 | lr mean: 4.961125523550436e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.86 | consumed tokens: 375193600.0 | grad norm avg: 0.83 | grad norm last: 0.76 | 
2026-01-01T07:45:51 | step: 45900 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.960925434716046e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.27 | consumed tokens: 376012800.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T07:46:12 | step: 46000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.960724982083775e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.28 | consumed tokens: 376832000.0 | grad norm avg: 0.84 | grad norm last: 0.77 | 
2026-01-01T07:46:32 | step: 46100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.960523801855743e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.97 | consumed tokens: 377651200.0 | grad norm avg: 0.83 | grad norm last: 0.86 | 
2026-01-01T07:46:53 | step: 46200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.960322621627711e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.25 | consumed tokens: 378470400.0 | grad norm avg: 0.84 | grad norm last: 0.77 | 
2026-01-01T07:47:13 | step: 46300 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9601203500060365e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.22 | consumed tokens: 379289600.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T07:47:34 | step: 46400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.959918078384362e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.75 | consumed tokens: 380108800.0 | grad norm avg: 0.84 | grad norm last: 0.87 | 
2026-01-01T07:47:54 | step: 46500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.959714715369046e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.77 | consumed tokens: 380928000.0 | grad norm avg: 0.83 | grad norm last: 0.79 | 
2026-01-01T07:48:15 | step: 46600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.959511352353729e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.34 | consumed tokens: 381747200.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T07:48:35 | step: 46700 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.9593072617426515e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.86 | consumed tokens: 382566400.0 | grad norm avg: 0.84 | grad norm last: 0.88 | 
2026-01-01T07:48:56 | step: 46800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.959102807333693e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.59 | consumed tokens: 383385600.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T07:49:16 | step: 46900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.958897625328973e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.31 | consumed tokens: 384204800.0 | grad norm avg: 0.83 | grad norm last: 0.86 | 
2026-01-01T07:49:36 | step: 47000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.958692079526372e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.7 | consumed tokens: 385024000.0 | grad norm avg: 0.85 | grad norm last: 0.79 | 
2026-01-01T07:49:57 | step: 47100 | train samples/s: 82.7 | train mfu (16-bit): -1.0 | lr mean: 4.958486169925891e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.27 | consumed tokens: 385843200.0 | grad norm avg: 0.83 | grad norm last: 0.95 | 
2026-01-01T07:50:18 | step: 47200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.958279532729648e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.72 | consumed tokens: 386662400.0 | grad norm avg: 0.83 | grad norm last: 0.9 | 
2026-01-01T07:50:38 | step: 47300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.958072167937644e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.45 | consumed tokens: 387481600.0 | grad norm avg: 0.83 | grad norm last: 0.84 | 
2026-01-01T07:50:59 | step: 47400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9578648031456396e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.16 | consumed tokens: 388300800.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T07:51:19 | step: 47500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.957656710757874e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.19 | consumed tokens: 389120000.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T07:51:40 | step: 47600 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.957447890774347e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.91 | consumed tokens: 389939200.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T07:52:00 | step: 47700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.957238706992939e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.34 | consumed tokens: 390758400.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T07:52:21 | step: 47800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.9570291594136506e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.69 | consumed tokens: 391577600.0 | grad norm avg: 0.83 | grad norm last: 0.84 | 
2026-01-01T07:52:41 | step: 47900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.956818884238601e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.16 | consumed tokens: 392396800.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T07:53:02 | step: 48000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.95660824526567e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.0 | consumed tokens: 393216000.0 | grad norm avg: 0.83 | grad norm last: 0.86 | 
2026-01-01T07:53:22 | step: 48100 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.956397242494859e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.53 | consumed tokens: 394035200.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T07:53:43 | step: 48200 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.956185512128286e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.39 | consumed tokens: 394854400.0 | grad norm avg: 0.83 | grad norm last: 0.87 | 
2026-01-01T07:54:03 | step: 48300 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.9559734179638326e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.31 | consumed tokens: 395673600.0 | grad norm avg: 0.84 | grad norm last: 0.79 | 
2026-01-01T07:54:24 | step: 48400 | train samples/s: 82.8 | train mfu (16-bit): -1.0 | lr mean: 4.955760596203618e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.34 | consumed tokens: 396492800.0 | grad norm avg: 0.84 | grad norm last: 0.92 | 
2026-01-01T07:54:45 | step: 48500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.955547410645522e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.61 | consumed tokens: 397312000.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T07:55:05 | step: 48600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.955333861289546e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.08 | consumed tokens: 398131200.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T07:55:25 | step: 48700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.955119584337808e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 2.86 | consumed tokens: 398950400.0 | grad norm avg: 0.84 | grad norm last: 0.92 | 
2026-01-01T07:55:46 | step: 48800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.95490494358819e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.31 | consumed tokens: 399769600.0 | grad norm avg: 0.84 | grad norm last: 0.9 | 
2026-01-01T07:56:06 | step: 48900 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.95468957524281e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.11 | consumed tokens: 400588800.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T07:56:27 | step: 49000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9544738430995494e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.53 | consumed tokens: 401408000.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T07:56:47 | step: 49100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.954257747158408e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.94 | consumed tokens: 402227200.0 | grad norm avg: 0.83 | grad norm last: 0.89 | 
2026-01-01T07:57:08 | step: 49200 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.9540409236215055e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.55 | consumed tokens: 403046400.0 | grad norm avg: 0.84 | grad norm last: 0.77 | 
2026-01-01T07:57:28 | step: 49300 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.953823736286722e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.86 | consumed tokens: 403865600.0 | grad norm avg: 0.84 | grad norm last: 0.89 | 
2026-01-01T07:57:49 | step: 49400 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.953605821356177e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.72 | consumed tokens: 404684800.0 | grad norm avg: 0.84 | grad norm last: 0.79 | 
2026-01-01T07:58:09 | step: 49500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.953387542627752e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 2.92 | consumed tokens: 405504000.0 | grad norm avg: 0.83 | grad norm last: 0.88 | 
2026-01-01T07:58:29 | step: 49600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.9531689001014456e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.56 | consumed tokens: 406323200.0 | grad norm avg: 0.84 | grad norm last: 0.75 | 
2026-01-01T07:58:50 | step: 49700 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 4.952949529979378e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 4.16 | consumed tokens: 407142400.0 | grad norm avg: 0.84 | grad norm last: 0.87 | 
2026-01-01T07:59:11 | step: 49800 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.9527297960594296e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 4.44 | consumed tokens: 407961600.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T07:59:31 | step: 49900 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.95250933454372e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.05 | consumed tokens: 408780800.0 | grad norm avg: 0.84 | grad norm last: 0.87 | 
2026-01-01T07:59:52 | step: 50000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9522885092301294e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.39 | consumed tokens: 409600000.0 | grad norm avg: 0.85 | grad norm last: 0.75 | 
2026-01-01T08:00:14 | step: 50100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.952067320118658e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.53 | consumed tokens: 410419200.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T08:00:34 | step: 50200 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.9518454034114257e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.3 | consumed tokens: 411238400.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T08:00:55 | step: 50300 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.9516231229063123e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.72 | consumed tokens: 412057600.0 | grad norm avg: 0.84 | grad norm last: 0.87 | 
2026-01-01T08:01:16 | step: 50400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.9514001148054376e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.2 | consumed tokens: 412876800.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T08:01:36 | step: 50500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.951176742906682e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.23 | consumed tokens: 413696000.0 | grad norm avg: 0.85 | grad norm last: 0.84 | 
2026-01-01T08:01:56 | step: 50600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.950953007210046e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.27 | consumed tokens: 414515200.0 | grad norm avg: 0.85 | grad norm last: 0.81 | 
2026-01-01T08:02:17 | step: 50700 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 4.9507285439176485e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.5 | consumed tokens: 415334400.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T08:02:37 | step: 50800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.95050371682737e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.0 | consumed tokens: 416153600.0 | grad norm avg: 0.83 | grad norm last: 0.85 | 
2026-01-01T08:02:58 | step: 50900 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.950278525939211e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.84 | consumed tokens: 416972800.0 | grad norm avg: 0.83 | grad norm last: 0.87 | 
2026-01-01T08:03:19 | step: 51000 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.950052607455291e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 3.56 | consumed tokens: 417792000.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T08:03:39 | step: 51100 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.94982632517349e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.83 | consumed tokens: 418611200.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T08:04:00 | step: 51200 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.949599315295927e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.3 | consumed tokens: 419430400.0 | grad norm avg: 0.83 | grad norm last: 0.87 | 
2026-01-01T08:04:20 | step: 51300 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.949371941620484e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.12 | consumed tokens: 420249600.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T08:04:41 | step: 51400 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9491438403492793e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.23 | consumed tokens: 421068800.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T08:05:01 | step: 51500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.948915375280194e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.64 | consumed tokens: 421888000.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T08:05:22 | step: 51600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.948686546413228e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.94 | consumed tokens: 422707200.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T08:05:42 | step: 51700 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.948457353748381e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.64 | consumed tokens: 423526400.0 | grad norm avg: 0.85 | grad norm last: 0.83 | 
2026-01-01T08:06:03 | step: 51800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.948227433487773e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.39 | consumed tokens: 424345600.0 | grad norm avg: 0.83 | grad norm last: 0.74 | 
2026-01-01T08:06:23 | step: 51900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.947996785631403e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.12 | consumed tokens: 425164800.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T08:06:44 | step: 52000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.947765773977153e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.83 | consumed tokens: 425984000.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T08:07:04 | step: 52100 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.947534398525022e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.2 | consumed tokens: 426803200.0 | grad norm avg: 0.85 | grad norm last: 0.78 | 
2026-01-01T08:07:25 | step: 52200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9473022954771295e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.19 | consumed tokens: 427622400.0 | grad norm avg: 0.84 | grad norm last: 0.78 | 
2026-01-01T08:07:46 | step: 52300 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 4.9470698286313564e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 3.59 | consumed tokens: 428441600.0 | grad norm avg: 0.84 | grad norm last: 0.87 | 
2026-01-01T08:08:06 | step: 52400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.9468369979877025e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.31 | train loss last: 2.73 | consumed tokens: 429260800.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T08:08:27 | step: 52500 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 4.946603439748287e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.2 | consumed tokens: 430080000.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T08:08:47 | step: 52600 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.946369517710991e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.44 | consumed tokens: 430899200.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T08:09:08 | step: 52700 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.9461352318758145e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.48 | consumed tokens: 431718400.0 | grad norm avg: 0.85 | grad norm last: 0.84 | 
2026-01-01T08:09:28 | step: 52800 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.9459002184448764e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.55 | consumed tokens: 432537600.0 | grad norm avg: 0.84 | grad norm last: 0.89 | 
2026-01-01T08:09:49 | step: 52900 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 4.945664477418177e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.16 | consumed tokens: 433356800.0 | grad norm avg: 0.85 | grad norm last: 0.83 | 
2026-01-01T08:10:10 | step: 53000 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.945428736391477e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.81 | consumed tokens: 434176000.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T08:10:30 | step: 53100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.9451919039711356e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.47 | consumed tokens: 434995200.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T08:10:51 | step: 53200 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.944955071550794e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.94 | consumed tokens: 435814400.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T08:11:11 | step: 53300 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.944717511534691e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.55 | consumed tokens: 436633600.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T08:11:32 | step: 53400 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.944479587720707e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.23 | consumed tokens: 437452800.0 | grad norm avg: 0.84 | grad norm last: 0.79 | 
2026-01-01T08:11:52 | step: 53500 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.944240936310962e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.14 | consumed tokens: 438272000.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T08:12:13 | step: 53600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.944001921103336e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.3 | train loss last: 2.94 | consumed tokens: 439091200.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T08:12:34 | step: 53700 | train samples/s: 82.9 | train mfu (16-bit): -1.0 | lr mean: 4.9437621782999486e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.08 | consumed tokens: 439910400.0 | grad norm avg: 0.83 | grad norm last: 0.86 | 
2026-01-01T08:12:54 | step: 53800 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 4.943522435496561e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.81 | consumed tokens: 440729600.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T08:13:15 | step: 53900 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.943281601299532e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.42 | consumed tokens: 441548800.0 | grad norm avg: 0.83 | grad norm last: 0.81 | 
2026-01-01T08:13:35 | step: 54000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.943040767102502e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.11 | consumed tokens: 442368000.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-01T08:13:56 | step: 54100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9427992053097114e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.41 | consumed tokens: 443187200.0 | grad norm avg: 0.82 | grad norm last: 0.86 | 
2026-01-01T08:14:16 | step: 54200 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.942556915921159e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.44 | consumed tokens: 444006400.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T08:14:37 | step: 54300 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.942314262734726e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.25 | consumed tokens: 444825600.0 | grad norm avg: 0.83 | grad norm last: 0.82 | 
2026-01-01T08:14:57 | step: 54400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.9420712457504123e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.25 | consumed tokens: 445644800.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T08:15:18 | step: 54500 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.941827864968218e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.95 | consumed tokens: 446464000.0 | grad norm avg: 0.83 | grad norm last: 0.85 | 
2026-01-01T08:15:39 | step: 54600 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 4.941583756590262e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.55 | consumed tokens: 447283200.0 | grad norm avg: 0.84 | grad norm last: 0.79 | 
2026-01-01T08:15:59 | step: 54700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.941338920616545e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.42 | consumed tokens: 448102400.0 | grad norm avg: 0.84 | grad norm last: 0.79 | 
2026-01-01T08:16:20 | step: 54800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9410940846428275e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.03 | consumed tokens: 448921600.0 | grad norm avg: 0.83 | grad norm last: 0.75 | 
2026-01-01T08:16:40 | step: 54900 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 4.940848521073349e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.31 | consumed tokens: 449740800.0 | grad norm avg: 0.82 | grad norm last: 0.9 | 
2026-01-01T08:17:01 | step: 55000 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 4.940602229908109e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.97 | consumed tokens: 450560000.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T08:17:23 | step: 55100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.940355574944988e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.47 | consumed tokens: 451379200.0 | grad norm avg: 0.84 | grad norm last: 0.78 | 
2026-01-01T08:17:44 | step: 55200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.9401085561839864e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.23 | consumed tokens: 452198400.0 | grad norm avg: 0.84 | grad norm last: 0.94 | 
2026-01-01T08:18:04 | step: 55300 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.9398608098272234e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.95 | consumed tokens: 453017600.0 | grad norm avg: 0.84 | grad norm last: 0.92 | 
2026-01-01T08:18:25 | step: 55400 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.93961269967258e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.25 | consumed tokens: 453836800.0 | grad norm avg: 0.83 | grad norm last: 0.81 | 
2026-01-01T08:18:45 | step: 55500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9393642257200554e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.06 | consumed tokens: 454656000.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T08:19:06 | step: 55600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9391150241717696e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.02 | consumed tokens: 455475200.0 | grad norm avg: 0.85 | grad norm last: 0.88 | 
2026-01-01T08:19:27 | step: 55700 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.938865458825603e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.23 | consumed tokens: 456294400.0 | grad norm avg: 0.85 | grad norm last: 0.85 | 
2026-01-01T08:19:47 | step: 55800 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.938615165883675e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.62 | consumed tokens: 457113600.0 | grad norm avg: 0.84 | grad norm last: 0.89 | 
2026-01-01T08:20:08 | step: 55900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9383645091438666e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 2.92 | consumed tokens: 457932800.0 | grad norm avg: 0.84 | grad norm last: 0.87 | 
2026-01-01T08:20:28 | step: 56000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.938113488606177e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.28 | consumed tokens: 458752000.0 | grad norm avg: 0.84 | grad norm last: 0.95 | 
2026-01-01T08:20:49 | step: 56100 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.9378617404727265e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.23 | consumed tokens: 459571200.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T08:21:09 | step: 56200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.937609628541395e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.34 | consumed tokens: 460390400.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T08:21:30 | step: 56300 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 4.937356789014302e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.39 | consumed tokens: 461209600.0 | grad norm avg: 0.85 | grad norm last: 0.87 | 
2026-01-01T08:21:50 | step: 56400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9371035856893286e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.84 | consumed tokens: 462028800.0 | grad norm avg: 0.84 | grad norm last: 0.78 | 
2026-01-01T08:22:11 | step: 56500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.936850018566474e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.45 | consumed tokens: 462848000.0 | grad norm avg: 0.84 | grad norm last: 0.87 | 
2026-01-01T08:22:31 | step: 56600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9365957238478586e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.06 | consumed tokens: 463667200.0 | grad norm avg: 0.84 | grad norm last: 0.87 | 
2026-01-01T08:22:52 | step: 56700 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.936341065331362e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.22 | consumed tokens: 464486400.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T08:23:12 | step: 56800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.936086043016985e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.75 | consumed tokens: 465305600.0 | grad norm avg: 0.84 | grad norm last: 0.89 | 
2026-01-01T08:23:33 | step: 56900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9358302931068465e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.39 | consumed tokens: 466124800.0 | grad norm avg: 0.85 | grad norm last: 0.85 | 
2026-01-01T08:23:53 | step: 57000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.935574179398827e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.81 | consumed tokens: 466944000.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T08:24:13 | step: 57100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9353173380950466e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.36 | consumed tokens: 467763200.0 | grad norm avg: 0.85 | grad norm last: 0.89 | 
2026-01-01T08:24:34 | step: 57200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.935060132993385e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.36 | consumed tokens: 468582400.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T08:24:54 | step: 57300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.934802564093843e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.44 | consumed tokens: 469401600.0 | grad norm avg: 0.85 | grad norm last: 0.94 | 
2026-01-01T08:25:15 | step: 57400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9345442675985396e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.38 | consumed tokens: 470220800.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T08:25:35 | step: 57500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.9342856073053554e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.12 | consumed tokens: 471040000.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T08:25:56 | step: 57600 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.93402621941641e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.11 | consumed tokens: 471859200.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T08:26:16 | step: 57700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9337664677295834e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.52 | consumed tokens: 472678400.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T08:26:37 | step: 57800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.933506352244876e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.97 | consumed tokens: 473497600.0 | grad norm avg: 0.85 | grad norm last: 0.79 | 
2026-01-01T08:26:57 | step: 57900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.933245509164408e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.06 | consumed tokens: 474316800.0 | grad norm avg: 0.85 | grad norm last: 0.87 | 
2026-01-01T08:27:18 | step: 58000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.932984302286059e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.05 | consumed tokens: 475136000.0 | grad norm avg: 0.84 | grad norm last: 0.88 | 
2026-01-01T08:27:38 | step: 58100 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.932722731609829e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.36 | consumed tokens: 475955200.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T08:27:58 | step: 58200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9324604333378375e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.3 | consumed tokens: 476774400.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T08:28:19 | step: 58300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.9321977712679654e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.44 | consumed tokens: 477593600.0 | grad norm avg: 0.83 | grad norm last: 0.87 | 
2026-01-01T08:28:39 | step: 58400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.931934381602332e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.27 | consumed tokens: 478412800.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T08:29:00 | step: 58500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.931670628138818e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.95 | consumed tokens: 479232000.0 | grad norm avg: 0.84 | grad norm last: 0.94 | 
2026-01-01T08:29:20 | step: 58600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.931406510877423e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.03 | consumed tokens: 480051200.0 | grad norm avg: 0.83 | grad norm last: 0.84 | 
2026-01-01T08:29:41 | step: 58700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.931141666020267e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.77 | consumed tokens: 480870400.0 | grad norm avg: 0.83 | grad norm last: 0.81 | 
2026-01-01T08:30:01 | step: 58800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.93087645736523e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.03 | consumed tokens: 481689600.0 | grad norm avg: 0.84 | grad norm last: 0.79 | 
2026-01-01T08:30:22 | step: 58900 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 4.930610521114431e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.31 | consumed tokens: 482508800.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T08:30:42 | step: 59000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.930344221065752e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.19 | consumed tokens: 483328000.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T08:31:03 | step: 59100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.9300775572191924e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.19 | consumed tokens: 484147200.0 | grad norm avg: 0.85 | grad norm last: 0.9 | 
2026-01-01T08:31:23 | step: 59200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.929810165776871e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.98 | consumed tokens: 484966400.0 | grad norm avg: 0.84 | grad norm last: 0.79 | 
2026-01-01T08:31:44 | step: 59300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.929542410536669e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.36 | consumed tokens: 485785600.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T08:32:04 | step: 59400 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.9292742914985865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.84 | consumed tokens: 486604800.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T08:32:24 | step: 59500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.9290054448647425e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.72 | consumed tokens: 487424000.0 | grad norm avg: 0.85 | grad norm last: 0.8 | 
2026-01-01T08:32:45 | step: 59600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.928736234433018e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.81 | consumed tokens: 488243200.0 | grad norm avg: 0.84 | grad norm last: 0.89 | 
2026-01-01T08:33:05 | step: 59700 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.9284662964055315e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.06 | consumed tokens: 489062400.0 | grad norm avg: 0.85 | grad norm last: 0.84 | 
2026-01-01T08:33:26 | step: 59800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.9281959945801646e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.98 | consumed tokens: 489881600.0 | grad norm avg: 0.85 | grad norm last: 0.85 | 
2026-01-01T08:33:46 | step: 59900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.927925328956917e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.12 | consumed tokens: 490700800.0 | grad norm avg: 0.85 | grad norm last: 0.85 | 
2026-01-01T08:34:07 | step: 60000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.927653935737908e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.09 | consumed tokens: 491520000.0 | grad norm avg: 0.85 | grad norm last: 0.86 | 
2026-01-01T08:34:29 | step: 60100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.927382178721018e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.97 | consumed tokens: 492339200.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T08:34:49 | step: 60200 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 4.927110057906248e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.67 | consumed tokens: 493158400.0 | grad norm avg: 0.84 | grad norm last: 0.88 | 
2026-01-01T08:35:10 | step: 60300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.926837209495716e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 2.98 | consumed tokens: 493977600.0 | grad norm avg: 0.85 | grad norm last: 0.91 | 
2026-01-01T08:35:30 | step: 60400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.926563997287303e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.08 | consumed tokens: 494796800.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T08:35:51 | step: 60500 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.926290057483129e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.29 | train loss last: 3.69 | consumed tokens: 495616000.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T08:36:11 | step: 60600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.9260157538810745e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.11 | consumed tokens: 496435200.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T08:36:32 | step: 60700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.925741086481139e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.59 | consumed tokens: 497254400.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T08:36:52 | step: 60800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.925465691485442e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.34 | consumed tokens: 498073600.0 | grad norm avg: 0.85 | grad norm last: 0.92 | 
2026-01-01T08:37:12 | step: 60900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.925189932691865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.12 | consumed tokens: 498892800.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T08:37:33 | step: 61000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.924913446302526e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.75 | consumed tokens: 499712000.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T08:37:53 | step: 61100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.924636596115306e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.42 | consumed tokens: 500531200.0 | grad norm avg: 0.84 | grad norm last: 0.92 | 
2026-01-01T08:38:14 | step: 61200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.9243593821302056e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.25 | consumed tokens: 501350400.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T08:38:34 | step: 61300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.924081440549344e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 4.03 | consumed tokens: 502169600.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T08:38:55 | step: 61400 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.923803135170601e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.92 | consumed tokens: 502988800.0 | grad norm avg: 0.84 | grad norm last: 0.75 | 
2026-01-01T08:39:15 | step: 61500 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 4.923524465993978e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.39 | consumed tokens: 503808000.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T08:39:36 | step: 61600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9232450692215934e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.55 | consumed tokens: 504627200.0 | grad norm avg: 0.85 | grad norm last: 0.79 | 
2026-01-01T08:39:56 | step: 61700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.922965308651328e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.14 | consumed tokens: 505446400.0 | grad norm avg: 0.85 | grad norm last: 0.8 | 
2026-01-01T08:40:17 | step: 61800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.922685184283182e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.91 | consumed tokens: 506265600.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T08:40:37 | step: 61900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.9224043323192745e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.88 | consumed tokens: 507084800.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T08:40:57 | step: 62000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.9221227527596056e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.42 | consumed tokens: 507904000.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T08:41:18 | step: 62100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.921841173199937e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.8 | consumed tokens: 508723200.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T08:41:38 | step: 62200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.9215588660445064e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.39 | consumed tokens: 509542400.0 | grad norm avg: 0.85 | grad norm last: 0.83 | 
2026-01-01T08:41:59 | step: 62300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.921275831293315e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.22 | consumed tokens: 510361600.0 | grad norm avg: 0.85 | grad norm last: 0.86 | 
2026-01-01T08:42:19 | step: 62400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.920992432744242e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.0 | consumed tokens: 511180800.0 | grad norm avg: 0.84 | grad norm last: 0.88 | 
2026-01-01T08:42:40 | step: 62500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.920708670397289e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.27 | consumed tokens: 512000000.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T08:43:00 | step: 62600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.920424544252455e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.17 | consumed tokens: 512819200.0 | grad norm avg: 0.85 | grad norm last: 0.81 | 
2026-01-01T08:43:21 | step: 62700 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.92013969051186e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.36 | consumed tokens: 513638400.0 | grad norm avg: 0.85 | grad norm last: 0.79 | 
2026-01-01T08:43:41 | step: 62800 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.919854109175503e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.17 | consumed tokens: 514457600.0 | grad norm avg: 0.84 | grad norm last: 0.88 | 
2026-01-01T08:44:02 | step: 62900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.9195685278391466e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.8 | consumed tokens: 515276800.0 | grad norm avg: 0.85 | grad norm last: 0.84 | 
2026-01-01T08:44:22 | step: 63000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9192822189070284e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.8 | consumed tokens: 516096000.0 | grad norm avg: 0.84 | grad norm last: 0.78 | 
2026-01-01T08:44:43 | step: 63100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.918995182379149e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.06 | consumed tokens: 516915200.0 | grad norm avg: 0.85 | grad norm last: 0.9 | 
2026-01-01T08:45:03 | step: 63200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.9187077820533887e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.23 | consumed tokens: 517734400.0 | grad norm avg: 0.83 | grad norm last: 0.88 | 
2026-01-01T08:45:23 | step: 63300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.918420017929748e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.16 | consumed tokens: 518553600.0 | grad norm avg: 0.85 | grad norm last: 0.86 | 
2026-01-01T08:45:44 | step: 63400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.918131890008226e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.56 | consumed tokens: 519372800.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T08:46:04 | step: 63500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.917843034490943e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.03 | consumed tokens: 520192000.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T08:46:25 | step: 63600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.917553815175779e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.08 | consumed tokens: 521011200.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T08:46:45 | step: 63700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.917263868264854e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.22 | consumed tokens: 521830400.0 | grad norm avg: 0.85 | grad norm last: 0.91 | 
2026-01-01T08:47:06 | step: 63800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.916973557556048e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.28 | consumed tokens: 522649600.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T08:47:26 | step: 63900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.916682519251481e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.36 | consumed tokens: 523468800.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T08:47:46 | step: 64000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.9163914809469134e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.69 | consumed tokens: 524288000.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T08:48:07 | step: 64100 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 4.916099351248704e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.3 | consumed tokens: 525107200.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T08:48:28 | step: 64200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.9158072215504944e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.11 | consumed tokens: 525926400.0 | grad norm avg: 0.86 | grad norm last: 0.81 | 
2026-01-01T08:48:48 | step: 64300 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.9155143642565235e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.02 | consumed tokens: 526745600.0 | grad norm avg: 0.84 | grad norm last: 0.89 | 
2026-01-01T08:49:08 | step: 64400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.915221143164672e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.28 | consumed tokens: 527564800.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T08:49:29 | step: 64500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.914927194477059e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.59 | consumed tokens: 528384000.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T08:49:49 | step: 64600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.914632881991565e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.33 | consumed tokens: 529203200.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T08:50:10 | step: 64700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.914338205708191e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 4.03 | consumed tokens: 530022400.0 | grad norm avg: 0.85 | grad norm last: 0.8 | 
2026-01-01T08:50:30 | step: 64800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.914042801829055e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.84 | consumed tokens: 530841600.0 | grad norm avg: 0.85 | grad norm last: 0.81 | 
2026-01-01T08:50:51 | step: 64900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9137470341520384e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.31 | consumed tokens: 531660800.0 | grad norm avg: 0.84 | grad norm last: 0.92 | 
2026-01-01T08:51:11 | step: 65000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.9134505388792604e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.94 | consumed tokens: 532480000.0 | grad norm avg: 0.84 | grad norm last: 0.75 | 
2026-01-01T08:51:33 | step: 65100 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.913153679808602e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.28 | consumed tokens: 533299200.0 | grad norm avg: 0.85 | grad norm last: 0.78 | 
2026-01-01T08:51:54 | step: 65200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9128564569400623e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.89 | consumed tokens: 534118400.0 | grad norm avg: 0.85 | grad norm last: 0.88 | 
2026-01-01T08:52:14 | step: 65300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9125585064757615e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.02 | consumed tokens: 534937600.0 | grad norm avg: 0.85 | grad norm last: 0.79 | 
2026-01-01T08:52:35 | step: 65400 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 4.91226019221358e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.22 | consumed tokens: 535756800.0 | grad norm avg: 0.85 | grad norm last: 0.86 | 
2026-01-01T08:52:55 | step: 65500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.911961514153518e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.28 | consumed tokens: 536576000.0 | grad norm avg: 0.85 | grad norm last: 0.84 | 
2026-01-01T08:53:16 | step: 65600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.911662108497694e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.16 | consumed tokens: 537395200.0 | grad norm avg: 0.84 | grad norm last: 0.9 | 
2026-01-01T08:53:36 | step: 65700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.91136233904399e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.89 | consumed tokens: 538214400.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T08:53:57 | step: 65800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.911061841994524e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.34 | consumed tokens: 539033600.0 | grad norm avg: 0.85 | grad norm last: 0.86 | 
2026-01-01T08:54:17 | step: 65900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.910761344945058e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.58 | consumed tokens: 539852800.0 | grad norm avg: 0.84 | grad norm last: 0.74 | 
2026-01-01T08:54:38 | step: 66000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.91045975650195e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.19 | consumed tokens: 540672000.0 | grad norm avg: 0.85 | grad norm last: 0.89 | 
2026-01-01T08:54:58 | step: 66100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9101581680588424e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.62 | consumed tokens: 541491200.0 | grad norm avg: 0.85 | grad norm last: 0.83 | 
2026-01-01T08:55:19 | step: 66200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.909855852019973e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.39 | consumed tokens: 542310400.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T08:55:39 | step: 66300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9095528083853424e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.27 | consumed tokens: 543129600.0 | grad norm avg: 0.84 | grad norm last: 0.92 | 
2026-01-01T08:55:59 | step: 66400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9092497647507116e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.56 | consumed tokens: 543948800.0 | grad norm avg: 0.85 | grad norm last: 0.92 | 
2026-01-01T08:56:20 | step: 66500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.9089459935203195e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.19 | consumed tokens: 544768000.0 | grad norm avg: 0.85 | grad norm last: 0.84 | 
2026-01-01T08:56:40 | step: 66600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.908641494694166e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.27 | consumed tokens: 545587200.0 | grad norm avg: 0.85 | grad norm last: 0.9 | 
2026-01-01T08:57:01 | step: 66700 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 4.9083366320701316e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.81 | consumed tokens: 546406400.0 | grad norm avg: 0.85 | grad norm last: 0.93 | 
2026-01-01T08:57:22 | step: 66800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.9080314056482166e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.45 | consumed tokens: 547225600.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T08:57:42 | step: 66900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.907725815428421e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.58 | consumed tokens: 548044800.0 | grad norm avg: 0.85 | grad norm last: 0.97 | 
2026-01-01T08:58:02 | step: 67000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.907419497612864e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.09 | consumed tokens: 548864000.0 | grad norm avg: 0.85 | grad norm last: 0.86 | 
2026-01-01T08:58:23 | step: 67100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.907112452201545e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.28 | train loss last: 3.17 | consumed tokens: 549683200.0 | grad norm avg: 0.85 | grad norm last: 0.78 | 
2026-01-01T08:58:43 | step: 67200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.906805406790227e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.95 | consumed tokens: 550502400.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T08:59:04 | step: 67300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.906497633783147e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 4.0 | consumed tokens: 551321600.0 | grad norm avg: 0.85 | grad norm last: 0.83 | 
2026-01-01T08:59:24 | step: 67400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9061891331803054e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.02 | consumed tokens: 552140800.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T08:59:45 | step: 67500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.905880268779583e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.0 | consumed tokens: 552960000.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T09:00:05 | step: 67600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9055710405809805e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.05 | consumed tokens: 553779200.0 | grad norm avg: 0.85 | grad norm last: 0.9 | 
2026-01-01T09:00:26 | step: 67700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.905261448584497e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.38 | consumed tokens: 554598400.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T09:00:46 | step: 67800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.904951128992252e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.09 | consumed tokens: 555417600.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-01T09:01:07 | step: 67900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9046404456021264e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.94 | consumed tokens: 556236800.0 | grad norm avg: 0.85 | grad norm last: 0.83 | 
2026-01-01T09:01:28 | step: 68000 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 4.9043290346162394e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.67 | consumed tokens: 557056000.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T09:01:48 | step: 68100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.9040172598324716e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 2.86 | consumed tokens: 557875200.0 | grad norm avg: 0.85 | grad norm last: 0.85 | 
2026-01-01T09:02:09 | step: 68200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.903705121250823e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.62 | consumed tokens: 558694400.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T09:02:29 | step: 68300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.903392255073413e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.66 | consumed tokens: 559513600.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T09:02:50 | step: 68400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.9030790250981227e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.12 | consumed tokens: 560332800.0 | grad norm avg: 0.85 | grad norm last: 0.94 | 
2026-01-01T09:03:10 | step: 68500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9027650675270706e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.42 | consumed tokens: 561152000.0 | grad norm avg: 0.85 | grad norm last: 0.86 | 
2026-01-01T09:03:30 | step: 68600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.9024511099560186e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.53 | consumed tokens: 561971200.0 | grad norm avg: 0.85 | grad norm last: 0.84 | 
2026-01-01T09:03:51 | step: 68700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.9021360609913245e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.0 | consumed tokens: 562790400.0 | grad norm avg: 0.85 | grad norm last: 0.77 | 
2026-01-01T09:04:11 | step: 68800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.9018210120266303e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.34 | consumed tokens: 563609600.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T09:04:32 | step: 68900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.901505235466175e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.45 | consumed tokens: 564428800.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T09:04:52 | step: 69000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.9011890951078385e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.14 | consumed tokens: 565248000.0 | grad norm avg: 0.85 | grad norm last: 0.89 | 
2026-01-01T09:05:13 | step: 69100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.900872227153741e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.5 | consumed tokens: 566067200.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T09:05:33 | step: 69200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.9005549954017624e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.36 | consumed tokens: 566886400.0 | grad norm avg: 0.85 | grad norm last: 0.86 | 
2026-01-01T09:05:54 | step: 69300 | train samples/s: 82.9 | train mfu (16-bit): -1.0 | lr mean: 4.900237399851903e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.66 | consumed tokens: 567705600.0 | grad norm avg: 0.85 | grad norm last: 0.79 | 
2026-01-01T09:06:15 | step: 69400 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.899919076706283e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.12 | consumed tokens: 568524800.0 | grad norm avg: 0.85 | grad norm last: 0.85 | 
2026-01-01T09:06:35 | step: 69500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.8996003897627816e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.39 | consumed tokens: 569344000.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T09:06:55 | step: 69600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.899280975223519e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.11 | consumed tokens: 570163200.0 | grad norm avg: 0.85 | grad norm last: 0.89 | 
2026-01-01T09:07:16 | step: 69700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.898961560684256e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.88 | consumed tokens: 570982400.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T09:07:36 | step: 69800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.8986410547513515e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.59 | consumed tokens: 571801600.0 | grad norm avg: 0.85 | grad norm last: 0.86 | 
2026-01-01T09:07:57 | step: 69900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.898320548818447e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 4.09 | consumed tokens: 572620800.0 | grad norm avg: 0.85 | grad norm last: 0.79 | 
2026-01-01T09:08:17 | step: 70000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.8979993152897805e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.72 | consumed tokens: 573440000.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T09:08:39 | step: 70100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.8976777179632336e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.14 | consumed tokens: 574259200.0 | grad norm avg: 0.85 | grad norm last: 0.84 | 
2026-01-01T09:09:00 | step: 70200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.897355393040925e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.62 | consumed tokens: 575078400.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T09:09:20 | step: 70300 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.897032704320736e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.06 | consumed tokens: 575897600.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T09:09:41 | step: 70400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.8967096518026665e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.06 | consumed tokens: 576716800.0 | grad norm avg: 0.84 | grad norm last: 0.79 | 
2026-01-01T09:10:01 | step: 70500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.896385871688835e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.91 | consumed tokens: 577536000.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T09:10:22 | step: 70600 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 4.8960617277771235e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.36 | consumed tokens: 578355200.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T09:10:43 | step: 70700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.89573685626965e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.17 | consumed tokens: 579174400.0 | grad norm avg: 0.85 | grad norm last: 0.88 | 
2026-01-01T09:11:03 | step: 70800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.895411620964296e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.84 | consumed tokens: 579993600.0 | grad norm avg: 0.86 | grad norm last: 1.02 | 
2026-01-01T09:11:23 | step: 70900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.8950860218610615e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.25 | consumed tokens: 580812800.0 | grad norm avg: 0.85 | grad norm last: 0.85 | 
2026-01-01T09:11:44 | step: 71000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.894760058959946e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.05 | consumed tokens: 581632000.0 | grad norm avg: 0.85 | grad norm last: 0.84 | 
2026-01-01T09:12:04 | step: 71100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.894433368463069e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.48 | consumed tokens: 582451200.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T09:12:25 | step: 71200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.8941063141683117e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.03 | consumed tokens: 583270400.0 | grad norm avg: 0.85 | grad norm last: 0.83 | 
2026-01-01T09:12:45 | step: 71300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.893778532277793e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.48 | consumed tokens: 584089600.0 | grad norm avg: 0.85 | grad norm last: 0.87 | 
2026-01-01T09:13:06 | step: 71400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.893450386589393e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.27 | train loss last: 3.27 | consumed tokens: 584908800.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T09:13:26 | step: 71500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.8931218771031126e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.52 | consumed tokens: 585728000.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T09:13:47 | step: 71600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.892792640021071e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.72 | consumed tokens: 586547200.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T09:14:07 | step: 71700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.892463039141148e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.44 | consumed tokens: 587366400.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T09:14:28 | step: 71800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.8921327106654644e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.31 | consumed tokens: 588185600.0 | grad norm avg: 0.85 | grad norm last: 0.8 | 
2026-01-01T09:14:48 | step: 71900 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.8918023821897805e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.7 | consumed tokens: 589004800.0 | grad norm avg: 0.85 | grad norm last: 0.89 | 
2026-01-01T09:15:09 | step: 72000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.8914709623204544e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.0 | consumed tokens: 589824000.0 | grad norm avg: 0.86 | grad norm last: 0.81 | 
2026-01-01T09:15:29 | step: 72100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.8911395424511284e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 3.25 | consumed tokens: 590643200.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T09:15:50 | step: 72200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.890807394986041e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.58 | consumed tokens: 591462400.0 | grad norm avg: 0.86 | grad norm last: 0.81 | 
2026-01-01T09:16:10 | step: 72300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.890474883723073e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.31 | consumed tokens: 592281600.0 | grad norm avg: 0.85 | grad norm last: 0.89 | 
2026-01-01T09:16:31 | step: 72400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.890141644864343e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.52 | consumed tokens: 593100800.0 | grad norm avg: 0.85 | grad norm last: 0.76 | 
2026-01-01T09:16:51 | step: 72500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.889808042207733e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.16 | consumed tokens: 593920000.0 | grad norm avg: 0.85 | grad norm last: 0.93 | 
2026-01-01T09:17:12 | step: 72600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.889474075753242e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.89 | consumed tokens: 594739200.0 | grad norm avg: 0.85 | grad norm last: 0.85 | 
2026-01-01T09:17:32 | step: 72700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.8891393817029893e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.8 | consumed tokens: 595558400.0 | grad norm avg: 0.84 | grad norm last: 0.86 | 
2026-01-01T09:17:53 | step: 72800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.888804323854856e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.28 | consumed tokens: 596377600.0 | grad norm avg: 0.85 | grad norm last: 0.96 | 
2026-01-01T09:18:13 | step: 72900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.888468902208842e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.17 | consumed tokens: 597196800.0 | grad norm avg: 0.85 | grad norm last: 0.93 | 
2026-01-01T09:18:33 | step: 73000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.888132752967067e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.56 | consumed tokens: 598016000.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T09:18:54 | step: 73100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.887796239927411e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.56 | consumed tokens: 598835200.0 | grad norm avg: 0.85 | grad norm last: 0.89 | 
2026-01-01T09:19:15 | step: 73200 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 4.8874593630898744e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.97 | consumed tokens: 599654400.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T09:19:35 | step: 73300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.887121758656576e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 2.14 | consumed tokens: 600473600.0 | grad norm avg: 0.85 | grad norm last: 0.81 | 
2026-01-01T09:19:56 | step: 73400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.8867837904253975e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.77 | consumed tokens: 601292800.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T09:20:16 | step: 73500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.886445094598457e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.53 | consumed tokens: 602112000.0 | grad norm avg: 0.85 | grad norm last: 0.85 | 
2026-01-01T09:20:36 | step: 73600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.886106034973636e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.2 | consumed tokens: 602931200.0 | grad norm avg: 0.86 | grad norm last: 0.93 | 
2026-01-01T09:20:57 | step: 73700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.8857666115509346e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.91 | consumed tokens: 603750400.0 | grad norm avg: 0.85 | grad norm last: 0.81 | 
2026-01-01T09:21:17 | step: 73800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.8854264605324715e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.3 | consumed tokens: 604569600.0 | grad norm avg: 0.85 | grad norm last: 0.8 | 
2026-01-01T09:21:38 | step: 73900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.8850863095140085e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.45 | consumed tokens: 605388800.0 | grad norm avg: 0.85 | grad norm last: 0.85 | 
2026-01-01T09:21:58 | step: 74000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.884745067101903e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.2 | consumed tokens: 606208000.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T09:22:19 | step: 74100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.884403824689798e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.88 | consumed tokens: 607027200.0 | grad norm avg: 0.85 | grad norm last: 0.78 | 
2026-01-01T09:22:39 | step: 74200 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.8840618546819314e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.06 | consumed tokens: 607846400.0 | grad norm avg: 0.85 | grad norm last: 0.85 | 
2026-01-01T09:23:00 | step: 74300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.8837191570783034e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.0 | consumed tokens: 608665600.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T09:23:20 | step: 74400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.8833760956767946e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 4.16 | consumed tokens: 609484800.0 | grad norm avg: 0.85 | grad norm last: 0.83 | 
2026-01-01T09:23:41 | step: 74500 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 4.883032670477405e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.0 | consumed tokens: 610304000.0 | grad norm avg: 0.85 | grad norm last: 0.81 | 
2026-01-01T09:24:01 | step: 74600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.882688881480135e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.28 | consumed tokens: 611123200.0 | grad norm avg: 0.85 | grad norm last: 0.83 | 
2026-01-01T09:24:22 | step: 74700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.8823443648871034e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.45 | consumed tokens: 611942400.0 | grad norm avg: 0.86 | grad norm last: 0.95 | 
2026-01-01T09:24:42 | step: 74800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.881999484496191e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.45 | consumed tokens: 612761600.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T09:25:03 | step: 74900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.8816538765095174e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.33 | consumed tokens: 613580800.0 | grad norm avg: 0.86 | grad norm last: 0.78 | 
2026-01-01T09:25:23 | step: 75000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.881308268522844e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.31 | consumed tokens: 614400000.0 | grad norm avg: 0.86 | grad norm last: 0.81 | 
2026-01-01T09:25:45 | step: 75100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.880961569142528e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.48 | consumed tokens: 615219200.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T09:26:06 | step: 75200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.880614869762212e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.03 | consumed tokens: 616038400.0 | grad norm avg: 0.86 | grad norm last: 0.94 | 
2026-01-01T09:26:26 | step: 75300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.880267442786135e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.39 | consumed tokens: 616857600.0 | grad norm avg: 0.85 | grad norm last: 0.83 | 
2026-01-01T09:26:47 | step: 75400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.879919652012177e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.33 | consumed tokens: 617676800.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T09:27:07 | step: 75500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.8795711336424574e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.06 | consumed tokens: 618496000.0 | grad norm avg: 0.84 | grad norm last: 0.85 | 
2026-01-01T09:27:27 | step: 75600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.879222251474857e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.97 | consumed tokens: 619315200.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T09:27:48 | step: 75700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.8788730055093765e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.0 | consumed tokens: 620134400.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T09:28:09 | step: 75800 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 4.878523031948134e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.5 | consumed tokens: 620953600.0 | grad norm avg: 0.85 | grad norm last: 0.85 | 
2026-01-01T09:28:29 | step: 75900 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.8781726945890114e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.25 | consumed tokens: 621772800.0 | grad norm avg: 0.85 | grad norm last: 0.8 | 
2026-01-01T09:28:50 | step: 76000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.877821993432008e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.38 | consumed tokens: 622592000.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T09:29:10 | step: 76100 | train samples/s: 85.3 | train mfu (16-bit): -1.0 | lr mean: 4.877470564679243e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.64 | consumed tokens: 623411200.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T09:29:30 | step: 76200 | train samples/s: 85.2 | train mfu (16-bit): -1.0 | lr mean: 4.877118772128597e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.73 | consumed tokens: 624230400.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-01T09:29:50 | step: 76300 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 4.87676625198219e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.47 | consumed tokens: 625049600.0 | grad norm avg: 0.86 | grad norm last: 0.91 | 
2026-01-01T09:30:11 | step: 76400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.8764137318357825e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.64 | consumed tokens: 625868800.0 | grad norm avg: 0.85 | grad norm last: 0.86 | 
2026-01-01T09:30:31 | step: 76500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.876060120295733e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.95 | consumed tokens: 626688000.0 | grad norm avg: 0.84 | grad norm last: 0.89 | 
2026-01-01T09:30:52 | step: 76600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.875706508755684e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.14 | consumed tokens: 627507200.0 | grad norm avg: 0.85 | grad norm last: 0.83 | 
2026-01-01T09:31:12 | step: 76700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.875352169619873e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.66 | consumed tokens: 628326400.0 | grad norm avg: 0.85 | grad norm last: 0.89 | 
2026-01-01T09:31:33 | step: 76800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.874997466686182e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.77 | consumed tokens: 629145600.0 | grad norm avg: 0.85 | grad norm last: 0.91 | 
2026-01-01T09:31:53 | step: 76900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.874642036156729e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.08 | consumed tokens: 629964800.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T09:32:14 | step: 77000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.874286605627276e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.7 | consumed tokens: 630784000.0 | grad norm avg: 0.85 | grad norm last: 0.84 | 
2026-01-01T09:32:34 | step: 77100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.873930083704181e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.28 | consumed tokens: 631603200.0 | grad norm avg: 0.85 | grad norm last: 0.81 | 
2026-01-01T09:32:55 | step: 77200 | train samples/s: 82.8 | train mfu (16-bit): -1.0 | lr mean: 4.873573561781086e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.19 | consumed tokens: 632422400.0 | grad norm avg: 0.85 | grad norm last: 0.88 | 
2026-01-01T09:33:16 | step: 77300 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.8732163122622296e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.98 | consumed tokens: 633241600.0 | grad norm avg: 0.85 | grad norm last: 0.85 | 
2026-01-01T09:33:36 | step: 77400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.872858335147612e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.55 | consumed tokens: 634060800.0 | grad norm avg: 0.85 | grad norm last: 0.85 | 
2026-01-01T09:33:56 | step: 77500 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 4.872500358032994e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.61 | consumed tokens: 634880000.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T09:34:17 | step: 77600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.872141653322615e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.25 | consumed tokens: 635699200.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T09:34:37 | step: 77700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.871782221016474e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.39 | consumed tokens: 636518400.0 | grad norm avg: 0.85 | grad norm last: 0.87 | 
2026-01-01T09:34:58 | step: 77800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.8714227887103334e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.84 | consumed tokens: 637337600.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T09:35:18 | step: 77900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.871062628808431e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.08 | consumed tokens: 638156800.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T09:35:39 | step: 78000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.870701741310768e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.34 | consumed tokens: 638976000.0 | grad norm avg: 0.85 | grad norm last: 0.96 | 
2026-01-01T09:35:59 | step: 78100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.870340853813104e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.86 | consumed tokens: 639795200.0 | grad norm avg: 0.85 | grad norm last: 0.85 | 
2026-01-01T09:36:20 | step: 78200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.8699792387196794e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.26 | train loss last: 2.95 | consumed tokens: 640614400.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T09:36:40 | step: 78300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.869616896030493e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.12 | consumed tokens: 641433600.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T09:37:01 | step: 78400 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.869254189543426e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.39 | consumed tokens: 642252800.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T09:37:21 | step: 78500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.868891119258478e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.7 | consumed tokens: 643072000.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T09:37:42 | step: 78600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.86852768517565e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.42 | consumed tokens: 643891200.0 | grad norm avg: 0.86 | grad norm last: 0.81 | 
2026-01-01T09:38:02 | step: 78700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.86816352349706e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.61 | consumed tokens: 644710400.0 | grad norm avg: 0.85 | grad norm last: 0.84 | 
2026-01-01T09:38:23 | step: 78800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.8677989980205894e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.39 | consumed tokens: 645529600.0 | grad norm avg: 0.85 | grad norm last: 0.89 | 
2026-01-01T09:38:43 | step: 78900 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 4.8674337449483573e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.86 | consumed tokens: 646348800.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T09:39:03 | step: 79000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.8670681280782446e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.67 | consumed tokens: 647168000.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T09:39:24 | step: 79100 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.866702147410251e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.25 | train loss last: 3.39 | consumed tokens: 647987200.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T09:39:44 | step: 79200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.866335802944377e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.44 | consumed tokens: 648806400.0 | grad norm avg: 0.85 | grad norm last: 0.84 | 
2026-01-01T09:40:05 | step: 79300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.8659687308827415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.48 | consumed tokens: 649625600.0 | grad norm avg: 0.85 | grad norm last: 0.89 | 
2026-01-01T09:40:26 | step: 79400 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.865601295023225e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.22 | consumed tokens: 650444800.0 | grad norm avg: 0.85 | grad norm last: 0.78 | 
2026-01-01T09:40:46 | step: 79500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.8652331315679476e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.16 | consumed tokens: 651264000.0 | grad norm avg: 0.85 | grad norm last: 0.87 | 
2026-01-01T09:41:06 | step: 79600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.864864604314789e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.95 | consumed tokens: 652083200.0 | grad norm avg: 0.85 | grad norm last: 0.91 | 
2026-01-01T09:41:27 | step: 79700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.86449571326375e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.0 | consumed tokens: 652902400.0 | grad norm avg: 0.89 | grad norm last: 0.97 | 
2026-01-01T09:41:48 | step: 79800 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 4.8641260946169496e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.12 | consumed tokens: 653721600.0 | grad norm avg: 0.86 | grad norm last: 0.91 | 
2026-01-01T09:42:08 | step: 79900 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.863756112172268e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 4.16 | consumed tokens: 654540800.0 | grad norm avg: 0.86 | grad norm last: 0.78 | 
2026-01-01T09:42:29 | step: 80000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.8633857659297064e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.31 | consumed tokens: 655360000.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T09:42:51 | step: 80100 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.863014692091383e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 2.97 | consumed tokens: 656179200.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-01T09:43:11 | step: 80200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.862643254455179e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.23 | consumed tokens: 656998400.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T09:43:32 | step: 80300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.862271453021094e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.59 | consumed tokens: 657817600.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T09:43:52 | step: 80400 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.861898923991248e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.83 | consumed tokens: 658636800.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T09:44:13 | step: 80500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.861526031163521e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.55 | consumed tokens: 659456000.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T09:44:33 | step: 80600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.8611527745379135e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.16 | consumed tokens: 660275200.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T09:44:54 | step: 80700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.8607787903165445e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.78 | consumed tokens: 661094400.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T09:45:14 | step: 80800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.860404442297295e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.89 | consumed tokens: 661913600.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T09:45:35 | step: 80900 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.860029730480164e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.38 | consumed tokens: 662732800.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T09:45:55 | step: 81000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.8596542910672724e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.94 | consumed tokens: 663552000.0 | grad norm avg: 0.85 | grad norm last: 0.87 | 
2026-01-01T09:46:16 | step: 81100 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 4.8592784878565e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.41 | consumed tokens: 664371200.0 | grad norm avg: 0.86 | grad norm last: 0.78 | 
2026-01-01T09:46:36 | step: 81200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.8589023208478466e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.5 | consumed tokens: 665190400.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-01T09:46:57 | step: 81300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.858525426243432e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.86 | consumed tokens: 666009600.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T09:47:17 | step: 81400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.8581481678411365e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.2 | consumed tokens: 666828800.0 | grad norm avg: 0.85 | grad norm last: 0.83 | 
2026-01-01T09:47:38 | step: 81500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.8577701818430796e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.33 | consumed tokens: 667648000.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T09:47:58 | step: 81600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.857392195845023e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.16 | consumed tokens: 668467200.0 | grad norm avg: 0.85 | grad norm last: 0.78 | 
2026-01-01T09:48:19 | step: 81700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.8570134822512046e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.98 | consumed tokens: 669286400.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T09:48:39 | step: 81800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.856634041061625e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.98 | consumed tokens: 670105600.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T09:49:00 | step: 81900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.8562542360741645e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.08 | consumed tokens: 670924800.0 | grad norm avg: 0.85 | grad norm last: 0.88 | 
2026-01-01T09:49:20 | step: 82000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.8558740672888234e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.66 | consumed tokens: 671744000.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T09:49:40 | step: 82100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.8554935347056016e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.36 | consumed tokens: 672563200.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T09:50:01 | step: 82200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.8551122745266184e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.25 | consumed tokens: 673382400.0 | grad norm avg: 0.86 | grad norm last: 0.77 | 
2026-01-01T09:50:21 | step: 82300 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.8547306505497545e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.19 | consumed tokens: 674201600.0 | grad norm avg: 0.87 | grad norm last: 0.96 | 
2026-01-01T09:50:42 | step: 82400 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 4.854348298977129e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.08 | consumed tokens: 675020800.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T09:51:03 | step: 82500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.853965583606623e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.97 | consumed tokens: 675840000.0 | grad norm avg: 0.88 | grad norm last: 0.99 | 
2026-01-01T09:51:23 | step: 82600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.8535825044382364e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 4.12 | consumed tokens: 676659200.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T09:51:43 | step: 82700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.853199061471969e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.66 | consumed tokens: 677478400.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T09:52:04 | step: 82800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.85281489090994e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.12 | consumed tokens: 678297600.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T09:52:24 | step: 82900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.8524303565500304e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.97 | consumed tokens: 679116800.0 | grad norm avg: 0.85 | grad norm last: 0.98 | 
2026-01-01T09:52:45 | step: 83000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.8520450945943594e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.66 | consumed tokens: 679936000.0 | grad norm avg: 0.85 | grad norm last: 0.86 | 
2026-01-01T09:53:05 | step: 83100 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.851659468840808e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.2 | consumed tokens: 680755200.0 | grad norm avg: 0.85 | grad norm last: 0.8 | 
2026-01-01T09:53:26 | step: 83200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.851273479289375e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 4.31 | consumed tokens: 681574400.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T09:53:46 | step: 83300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.850887125940062e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.77 | consumed tokens: 682393600.0 | grad norm avg: 0.85 | grad norm last: 0.96 | 
2026-01-01T09:54:07 | step: 83400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.8505000449949875e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.39 | consumed tokens: 683212800.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T09:54:27 | step: 83500 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.850112600252032e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.0 | consumed tokens: 684032000.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T09:54:48 | step: 83600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.8497244279133156e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.77 | consumed tokens: 684851200.0 | grad norm avg: 0.85 | grad norm last: 0.81 | 
2026-01-01T09:55:09 | step: 83700 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 4.849335891776718e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.92 | consumed tokens: 685670400.0 | grad norm avg: 0.86 | grad norm last: 0.91 | 
2026-01-01T09:55:29 | step: 83800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.84894699184224e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.25 | consumed tokens: 686489600.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T09:55:50 | step: 83900 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.848557728109881e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.2 | consumed tokens: 687308800.0 | grad norm avg: 0.86 | grad norm last: 0.77 | 
2026-01-01T09:56:10 | step: 84000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.848167736781761e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.12 | consumed tokens: 688128000.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T09:56:31 | step: 84100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.8477770178578794e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.94 | consumed tokens: 688947200.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T09:56:51 | step: 84200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.847386298933998e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.25 | consumed tokens: 689766400.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T09:57:11 | step: 84300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.846994852414355e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.09 | consumed tokens: 690585600.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T09:57:32 | step: 84400 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.846603042096831e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.09 | consumed tokens: 691404800.0 | grad norm avg: 0.87 | grad norm last: 0.94 | 
2026-01-01T09:57:52 | step: 84500 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.846210504183546e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.88 | consumed tokens: 692224000.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T09:58:13 | step: 84600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.84581760247238e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.42 | consumed tokens: 693043200.0 | grad norm avg: 0.86 | grad norm last: 0.81 | 
2026-01-01T09:58:33 | step: 84700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.845424336963333e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.36 | consumed tokens: 693862400.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-01T09:58:54 | step: 84800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.845030707656406e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.84 | consumed tokens: 694681600.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T09:59:14 | step: 84900 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.844636350753717e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.31 | consumed tokens: 695500800.0 | grad norm avg: 0.85 | grad norm last: 0.94 | 
2026-01-01T09:59:35 | step: 85000 | train samples/s: 82.6 | train mfu (16-bit): -1.0 | lr mean: 4.844241630053148e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.25 | consumed tokens: 696320000.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T09:59:58 | step: 85100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.843846181756817e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.48 | consumed tokens: 697139200.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T10:00:18 | step: 85200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.843450369662605e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.45 | consumed tokens: 697958400.0 | grad norm avg: 0.86 | grad norm last: 0.79 | 
2026-01-01T10:00:39 | step: 85300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.843054193770513e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.25 | consumed tokens: 698777600.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T10:00:59 | step: 85400 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.842657290282659e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.62 | consumed tokens: 699596800.0 | grad norm avg: 0.85 | grad norm last: 0.85 | 
2026-01-01T10:01:20 | step: 85500 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.842260022996925e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.97 | consumed tokens: 700416000.0 | grad norm avg: 0.86 | grad norm last: 0.96 | 
2026-01-01T10:01:40 | step: 85600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.84186239191331e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.27 | consumed tokens: 701235200.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T10:02:01 | step: 85700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.841464397031814e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.31 | consumed tokens: 702054400.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T10:02:21 | step: 85800 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.8410656745545566e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.75 | consumed tokens: 702873600.0 | grad norm avg: 0.86 | grad norm last: 0.79 | 
2026-01-01T10:02:42 | step: 85900 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.8406665882794186e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.73 | consumed tokens: 703692800.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T10:03:02 | step: 86000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.840266774408519e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.12 | consumed tokens: 704512000.0 | grad norm avg: 0.86 | grad norm last: 0.78 | 
2026-01-01T10:03:23 | step: 86100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.839866596739739e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.73 | consumed tokens: 705331200.0 | grad norm avg: 0.85 | grad norm last: 0.81 | 
2026-01-01T10:03:43 | step: 86200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.8394660552730784e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.73 | consumed tokens: 706150400.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T10:04:04 | step: 86300 | train samples/s: 82.9 | train mfu (16-bit): -1.0 | lr mean: 4.839065150008537e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.34 | consumed tokens: 706969600.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T10:04:24 | step: 86400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.838663517148234e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.58 | consumed tokens: 707788800.0 | grad norm avg: 0.85 | grad norm last: 0.91 | 
2026-01-01T10:04:45 | step: 86500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.83826152049005e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.33 | consumed tokens: 708608000.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T10:05:05 | step: 86600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.837858796236105e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.3 | consumed tokens: 709427200.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T10:05:26 | step: 86700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.8374557081842795e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.58 | consumed tokens: 710246400.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T10:05:46 | step: 86800 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.837052256334573e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.77 | consumed tokens: 711065600.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T10:06:07 | step: 86900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.836648440686986e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.33 | consumed tokens: 711884800.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T10:06:27 | step: 87000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.836243897443637e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.09 | consumed tokens: 712704000.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T10:06:47 | step: 87100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.835838990402408e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.73 | consumed tokens: 713523200.0 | grad norm avg: 0.86 | grad norm last: 0.76 | 
2026-01-01T10:07:08 | step: 87200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.835433355765417e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.78 | consumed tokens: 714342400.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T10:07:28 | step: 87300 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.835027357330546e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 2.91 | consumed tokens: 715161600.0 | grad norm avg: 0.85 | grad norm last: 0.87 | 
2026-01-01T10:07:49 | step: 87400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.8346209950977936e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.14 | consumed tokens: 715980800.0 | grad norm avg: 0.86 | grad norm last: 0.94 | 
2026-01-01T10:08:09 | step: 87500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.834214269067161e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.55 | consumed tokens: 716800000.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T10:08:30 | step: 87600 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 4.8338068154407665e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.89 | consumed tokens: 717619200.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T10:08:51 | step: 87700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.8333989980164915e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.95 | consumed tokens: 718438400.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T10:09:11 | step: 87800 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.832990452996455e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.27 | consumed tokens: 719257600.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T10:09:32 | step: 87900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.832581907976419e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.16 | consumed tokens: 720076800.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T10:09:52 | step: 88000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.83217227156274e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.81 | consumed tokens: 720896000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T10:10:12 | step: 88100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.831762635149062e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.23 | consumed tokens: 721715200.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T10:10:33 | step: 88200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.831352271139622e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.17 | consumed tokens: 722534400.0 | grad norm avg: 0.85 | grad norm last: 0.84 | 
2026-01-01T10:10:53 | step: 88300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.830941543332301e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.24 | train loss last: 3.84 | consumed tokens: 723353600.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T10:11:14 | step: 88400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.8305304517271e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.14 | consumed tokens: 724172800.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T10:11:34 | step: 88500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.830118632526137e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.2 | consumed tokens: 724992000.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T10:11:55 | step: 88600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.8297064495272934e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.81 | consumed tokens: 725811200.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T10:12:15 | step: 88700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.829293902730569e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.06 | consumed tokens: 726630400.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T10:12:36 | step: 88800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.8288806283380836e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.17 | consumed tokens: 727449600.0 | grad norm avg: 0.86 | grad norm last: 0.91 | 
2026-01-01T10:12:56 | step: 88900 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 4.828466990147717e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.34 | consumed tokens: 728268800.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T10:13:17 | step: 89000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.82805298815947e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.66 | consumed tokens: 729088000.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T10:13:37 | step: 89100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.827638258575462e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.55 | consumed tokens: 729907200.0 | grad norm avg: 0.86 | grad norm last: 0.94 | 
2026-01-01T10:13:58 | step: 89200 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.8272231651935726e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.0 | consumed tokens: 730726400.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-01T10:14:18 | step: 89300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.826807708013803e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.12 | consumed tokens: 731545600.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T10:14:39 | step: 89400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.8263915232382715e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.38 | consumed tokens: 732364800.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T10:14:59 | step: 89500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.8259749746648595e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.69 | consumed tokens: 733184000.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T10:15:19 | step: 89600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.825558062293567e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.25 | consumed tokens: 734003200.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T10:15:40 | step: 89700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.8251404223265126e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.14 | consumed tokens: 734822400.0 | grad norm avg: 0.86 | grad norm last: 0.79 | 
2026-01-01T10:16:00 | step: 89800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.824722418561578e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.92 | consumed tokens: 735641600.0 | grad norm avg: 0.85 | grad norm last: 0.86 | 
2026-01-01T10:16:21 | step: 89900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.824304050998762e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.16 | consumed tokens: 736460800.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T10:16:41 | step: 90000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.823884955840185e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.05 | consumed tokens: 737280000.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T10:17:03 | step: 90100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.823465860681608e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.45 | consumed tokens: 738099200.0 | grad norm avg: 0.86 | grad norm last: 0.94 | 
2026-01-01T10:17:24 | step: 90200 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 4.823045674129389e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.34 | consumed tokens: 738918400.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T10:17:45 | step: 90300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.82262548757717e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.28 | consumed tokens: 739737600.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T10:18:05 | step: 90400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.8222045734291896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.19 | consumed tokens: 740556800.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T10:18:26 | step: 90500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.8217832954833284e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.05 | consumed tokens: 741376000.0 | grad norm avg: 0.86 | grad norm last: 0.81 | 
2026-01-01T10:18:46 | step: 90600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.821361289941706e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.92 | consumed tokens: 742195200.0 | grad norm avg: 0.85 | grad norm last: 0.83 | 
2026-01-01T10:19:07 | step: 90700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.8209389206022024e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.8 | consumed tokens: 743014400.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T10:19:27 | step: 90800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.8205161874648184e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.23 | consumed tokens: 743833600.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T10:19:47 | step: 90900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.8200930905295536e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.2 | consumed tokens: 744652800.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T10:20:08 | step: 91000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.8196692659985274e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.83 | consumed tokens: 745472000.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T10:20:28 | step: 91100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.8192450776696205e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.22 | consumed tokens: 746291200.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T10:20:49 | step: 91200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.818820525542833e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.31 | consumed tokens: 747110400.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T10:21:09 | step: 91300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.818395245820284e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.2 | consumed tokens: 747929600.0 | grad norm avg: 0.85 | grad norm last: 0.88 | 
2026-01-01T10:21:30 | step: 91400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.817969602299854e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.91 | consumed tokens: 748748800.0 | grad norm avg: 0.86 | grad norm last: 0.94 | 
2026-01-01T10:21:50 | step: 91500 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 4.817543594981544e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.67 | consumed tokens: 749568000.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T10:22:11 | step: 91600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.817116860067472e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.72 | consumed tokens: 750387200.0 | grad norm avg: 0.87 | grad norm last: 0.98 | 
2026-01-01T10:22:31 | step: 91700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.816689761355519e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.17 | consumed tokens: 751206400.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T10:22:52 | step: 91800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.816262298845686e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.11 | consumed tokens: 752025600.0 | grad norm avg: 0.86 | grad norm last: 0.79 | 
2026-01-01T10:23:12 | step: 91900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.815834108740091e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.42 | consumed tokens: 752844800.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T10:23:33 | step: 92000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.815405554836616e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.42 | consumed tokens: 753664000.0 | grad norm avg: 0.87 | grad norm last: 1.1 | 
2026-01-01T10:23:53 | step: 92100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.81497663713526e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.02 | consumed tokens: 754483200.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T10:24:14 | step: 92200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.814546991838142e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.55 | consumed tokens: 755302400.0 | grad norm avg: 0.86 | grad norm last: 0.92 | 
2026-01-01T10:24:34 | step: 92300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.814116982743144e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.94 | consumed tokens: 756121600.0 | grad norm avg: 0.85 | grad norm last: 0.86 | 
2026-01-01T10:24:55 | step: 92400 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.813686609850265e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.39 | consumed tokens: 756940800.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T10:25:15 | step: 92500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.8132558731595054e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.84 | consumed tokens: 757760000.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T10:25:36 | step: 92600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.8128244088729843e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.66 | consumed tokens: 758579200.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T10:25:56 | step: 92700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.8123925807885826e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.94 | consumed tokens: 759398400.0 | grad norm avg: 0.86 | grad norm last: 0.78 | 
2026-01-01T10:26:17 | step: 92800 | train samples/s: 82.9 | train mfu (16-bit): -1.0 | lr mean: 4.8119600251084194e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.38 | consumed tokens: 760217600.0 | grad norm avg: 0.85 | grad norm last: 0.9 | 
2026-01-01T10:26:38 | step: 92900 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.8115271056303754e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.3 | consumed tokens: 761036800.0 | grad norm avg: 0.86 | grad norm last: 0.91 | 
2026-01-01T10:26:58 | step: 93000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.811093822354451e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.86 | consumed tokens: 761856000.0 | grad norm avg: 0.86 | grad norm last: 0.81 | 
2026-01-01T10:27:19 | step: 93100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.8106601752806455e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 4.5 | consumed tokens: 762675200.0 | grad norm avg: 0.86 | grad norm last: 0.76 | 
2026-01-01T10:27:39 | step: 93200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.810225800611079e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 4.38 | consumed tokens: 763494400.0 | grad norm avg: 0.85 | grad norm last: 0.83 | 
2026-01-01T10:28:00 | step: 93300 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.809791062143631e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.16 | consumed tokens: 764313600.0 | grad norm avg: 0.86 | grad norm last: 0.79 | 
2026-01-01T10:28:20 | step: 93400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.809355959878303e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.61 | consumed tokens: 765132800.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T10:28:41 | step: 93500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.8089201300172135e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.02 | consumed tokens: 765952000.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T10:29:01 | step: 93600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.808483936358243e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.17 | consumed tokens: 766771200.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T10:29:21 | step: 93700 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.808047378901392e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.72 | consumed tokens: 767590400.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T10:29:42 | step: 93800 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.80761009384878e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 4.91 | consumed tokens: 768409600.0 | grad norm avg: 0.87 | grad norm last: 0.76 | 
2026-01-01T10:30:02 | step: 93900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.807172444998287e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.94 | consumed tokens: 769228800.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T10:30:23 | step: 94000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.806734432349913e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.12 | consumed tokens: 770048000.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T10:30:44 | step: 94100 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 4.8062956921057776e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.36 | consumed tokens: 770867200.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T10:31:04 | step: 94200 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.805856951861642e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.02 | consumed tokens: 771686400.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T10:31:25 | step: 94300 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.805417120223865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.22 | consumed tokens: 772505600.0 | grad norm avg: 0.85 | grad norm last: 0.83 | 
2026-01-01T10:31:45 | step: 94400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.8049772885860875e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.98 | consumed tokens: 773324800.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T10:32:06 | step: 94500 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.804536729352549e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.7 | consumed tokens: 774144000.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T10:32:26 | step: 94600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.804095806321129e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.81 | consumed tokens: 774963200.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T10:32:47 | step: 94700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.803654519491829e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.89 | consumed tokens: 775782400.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T10:33:07 | step: 94800 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.803212505066767e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.12 | consumed tokens: 776601600.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T10:33:28 | step: 94900 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.802770126843825e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.31 | consumed tokens: 777420800.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T10:33:48 | step: 95000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.802327384823002e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.55 | consumed tokens: 778240000.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T10:34:10 | step: 95100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.8018839152064174e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.25 | consumed tokens: 779059200.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T10:34:31 | step: 95200 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.801440081791952e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.36 | consumed tokens: 779878400.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T10:34:51 | step: 95300 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.8009958845796064e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.88 | consumed tokens: 780697600.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T10:35:12 | step: 95400 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.800550959771499e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.72 | consumed tokens: 781516800.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T10:35:32 | step: 95500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.800105671165511e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.53 | consumed tokens: 782336000.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T10:35:53 | step: 95600 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.799660018761642e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.17 | consumed tokens: 783155200.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T10:36:14 | step: 95700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.799214002559893e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.16 | consumed tokens: 783974400.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T10:36:34 | step: 95800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.798767258762382e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 2.7 | consumed tokens: 784793600.0 | grad norm avg: 0.86 | grad norm last: 0.92 | 
2026-01-01T10:36:54 | step: 95900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.7983201511669904e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.34 | consumed tokens: 785612800.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T10:37:15 | step: 96000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.797872679773718e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.45 | consumed tokens: 786432000.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T10:37:35 | step: 96100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.7974244807846844e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.66 | consumed tokens: 787251200.0 | grad norm avg: 0.86 | grad norm last: 0.81 | 
2026-01-01T10:37:56 | step: 96200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.79697591799777e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.75 | consumed tokens: 788070400.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T10:38:16 | step: 96300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.796526627615094e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.16 | consumed tokens: 788889600.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-01T10:38:37 | step: 96400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.7960773372324184e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.62 | consumed tokens: 789708800.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T10:38:57 | step: 96500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.795627319253981e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.52 | consumed tokens: 790528000.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T10:39:18 | step: 96600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.795176937477663e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.34 | consumed tokens: 791347200.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T10:39:39 | step: 96700 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 4.794725828105584e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 4.0 | consumed tokens: 792166400.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T10:39:59 | step: 96800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.794274354935624e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.33 | consumed tokens: 792985600.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T10:40:19 | step: 96900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.793822517967783e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.55 | consumed tokens: 793804800.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T10:40:40 | step: 97000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.7933703172020614e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.7 | consumed tokens: 794624000.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T10:41:00 | step: 97100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.7929173888405785e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.7 | consumed tokens: 795443200.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T10:41:21 | step: 97200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.792464096681215e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.92 | consumed tokens: 796262400.0 | grad norm avg: 0.86 | grad norm last: 0.93 | 
2026-01-01T10:41:41 | step: 97300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.79201007692609e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.05 | consumed tokens: 797081600.0 | grad norm avg: 0.87 | grad norm last: 0.94 | 
2026-01-01T10:42:02 | step: 97400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.791556057170965e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.97 | consumed tokens: 797900800.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T10:42:22 | step: 97500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.791101309820078e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.98 | consumed tokens: 798720000.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T10:42:43 | step: 97600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.790646198671311e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.0 | consumed tokens: 799539200.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T10:43:03 | step: 97700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.7901903599267825e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.66 | consumed tokens: 800358400.0 | grad norm avg: 0.86 | grad norm last: 0.94 | 
2026-01-01T10:43:23 | step: 97800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.789734157384373e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.31 | consumed tokens: 801177600.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T10:43:44 | step: 97900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.789277591044083e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.33 | consumed tokens: 801996800.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T10:44:05 | step: 98000 | train samples/s: 82.8 | train mfu (16-bit): -1.0 | lr mean: 4.788820297108032e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.06 | consumed tokens: 802816000.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T10:44:25 | step: 98100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.7883630031719804e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.83 | consumed tokens: 803635200.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T10:44:46 | step: 98200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.7879049816401675e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.34 | consumed tokens: 804454400.0 | grad norm avg: 0.87 | grad norm last: 0.94 | 
2026-01-01T10:45:06 | step: 98300 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.787446232512593e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.12 | consumed tokens: 805273600.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T10:45:27 | step: 98400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.786987483385019e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.05 | consumed tokens: 806092800.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T10:45:47 | step: 98500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.786528006661683e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.11 | consumed tokens: 806912000.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T10:46:07 | step: 98600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.786067802342586e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.48 | consumed tokens: 807731200.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T10:46:28 | step: 98700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.785607598023489e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.12 | consumed tokens: 808550400.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T10:46:48 | step: 98800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.7851466661086306e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.86 | consumed tokens: 809369600.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T10:47:09 | step: 98900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.7846853703958914e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.92 | consumed tokens: 810188800.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T10:47:29 | step: 99000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.784223347087391e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.12 | consumed tokens: 811008000.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T10:47:50 | step: 99100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.7837609599810094e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.77 | consumed tokens: 811827200.0 | grad norm avg: 0.86 | grad norm last: 0.91 | 
2026-01-01T10:48:10 | step: 99200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.783298209076747e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.55 | consumed tokens: 812646400.0 | grad norm avg: 0.85 | grad norm last: 0.9 | 
2026-01-01T10:48:31 | step: 99300 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.7828350943746045e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.88 | consumed tokens: 813465600.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T10:48:51 | step: 99400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.7823712520767e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.28 | consumed tokens: 814284800.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T10:49:12 | step: 99500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.7819070459809154e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.72 | consumed tokens: 815104000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T10:49:32 | step: 99600 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.78144247608725e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.14 | consumed tokens: 815923200.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T10:49:53 | step: 99700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.780977178597823e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.81 | consumed tokens: 816742400.0 | grad norm avg: 0.86 | grad norm last: 0.95 | 
2026-01-01T10:50:13 | step: 99800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.780511881108396e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.03 | consumed tokens: 817561600.0 | grad norm avg: 0.85 | grad norm last: 0.85 | 
2026-01-01T10:50:34 | step: 99900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.7800454922253266e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.23 | consumed tokens: 818380800.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T10:50:54 | step: 100000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.7795791033422574e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.94 | consumed tokens: 819200000.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-01T10:51:16 | step: 100100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.779111986863427e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.23 | consumed tokens: 820019200.0 | grad norm avg: 0.85 | grad norm last: 0.86 | 
2026-01-01T10:51:37 | step: 100200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.7786445065867156e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.61 | consumed tokens: 820838400.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T10:51:57 | step: 100300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.7781766625121236e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.38 | consumed tokens: 821657600.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T10:52:18 | step: 100400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.77770809084177e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.48 | consumed tokens: 822476800.0 | grad norm avg: 0.86 | grad norm last: 0.77 | 
2026-01-01T10:52:38 | step: 100500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.777239155373536e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 4.09 | consumed tokens: 823296000.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T10:52:59 | step: 100600 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 4.776769856107421e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.41 | consumed tokens: 824115200.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T10:53:19 | step: 100700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.776300193043426e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.38 | consumed tokens: 824934400.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T10:53:40 | step: 100800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.775829802383669e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.86 | consumed tokens: 825753600.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T10:54:00 | step: 100900 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.775359047926031e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.94 | consumed tokens: 826572800.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T10:54:21 | step: 101000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.774887565872632e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.44 | consumed tokens: 827392000.0 | grad norm avg: 0.86 | grad norm last: 0.95 | 
2026-01-01T10:54:41 | step: 101100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.774416083819233e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.89 | consumed tokens: 828211200.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T10:55:02 | step: 101200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.7739438741700724e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.36 | consumed tokens: 829030400.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T10:55:22 | step: 101300 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.7734709369251505e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.91 | consumed tokens: 829849600.0 | grad norm avg: 0.85 | grad norm last: 0.87 | 
2026-01-01T10:55:43 | step: 101400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.7729979996802285e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 4.09 | consumed tokens: 830668800.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T10:56:03 | step: 101500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.772524334839545e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.58 | consumed tokens: 831488000.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T10:56:24 | step: 101600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.772050306200981e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.88 | consumed tokens: 832307200.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T10:56:44 | step: 101700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.771575549966656e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.22 | train loss last: 3.06 | consumed tokens: 833126400.0 | grad norm avg: 0.86 | grad norm last: 0.78 | 
2026-01-01T10:57:05 | step: 101800 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.7711004299344495e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.3 | consumed tokens: 833945600.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T10:57:25 | step: 101900 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 4.7706249461043626e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.31 | consumed tokens: 834764800.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T10:57:46 | step: 102000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.770149098476395e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.17 | consumed tokens: 835584000.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T10:58:06 | step: 102100 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.769672887050547e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.14 | consumed tokens: 836403200.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T10:58:27 | step: 102200 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.769195948028937e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.19 | consumed tokens: 837222400.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T10:58:47 | step: 102300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.768718281411566e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.45 | consumed tokens: 838041600.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T10:59:08 | step: 102400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.768240614794195e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.16 | consumed tokens: 838860800.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T10:59:28 | step: 102500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.767762220581062e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.91 | consumed tokens: 839680000.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T10:59:49 | step: 102600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.767283462570049e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.22 | consumed tokens: 840499200.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T11:00:09 | step: 102700 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.766804340761155e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.95 | consumed tokens: 841318400.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T11:00:30 | step: 102800 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.7663244913564995e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.66 | consumed tokens: 842137600.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T11:00:50 | step: 102900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.7658442781539634e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.36 | consumed tokens: 842956800.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T11:01:11 | step: 103000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.7653637011535466e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.72 | consumed tokens: 843776000.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T11:01:31 | step: 103100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.764882760355249e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.53 | consumed tokens: 844595200.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T11:01:52 | step: 103200 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 4.76440109196119e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.12 | consumed tokens: 845414400.0 | grad norm avg: 0.87 | grad norm last: 0.99 | 
2026-01-01T11:02:13 | step: 103300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.7639190597692505e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.23 | consumed tokens: 846233600.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T11:02:33 | step: 103400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.7634362999815494e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.72 | consumed tokens: 847052800.0 | grad norm avg: 0.86 | grad norm last: 0.94 | 
2026-01-01T11:02:54 | step: 103500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.762953540193848e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.08 | consumed tokens: 847872000.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T11:03:14 | step: 103600 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.762470052810386e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.89 | consumed tokens: 848691200.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T11:03:35 | step: 103700 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.761985837831162e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.27 | consumed tokens: 849510400.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T11:03:55 | step: 103800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.761501622851938e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.7 | consumed tokens: 850329600.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T11:04:15 | step: 103900 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.761016680276953e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.33 | consumed tokens: 851148800.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T11:04:36 | step: 104000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.7605313739040866e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.59 | consumed tokens: 851968000.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T11:04:57 | step: 104100 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.76004570373334e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.83 | consumed tokens: 852787200.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T11:05:17 | step: 104200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.759559305966832e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.41 | consumed tokens: 853606400.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T11:05:37 | step: 104300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.759072544402443e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.73 | consumed tokens: 854425600.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T11:05:58 | step: 104400 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.758585419040173e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 2.73 | consumed tokens: 855244800.0 | grad norm avg: 0.86 | grad norm last: 0.92 | 
2026-01-01T11:06:19 | step: 104500 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 4.758097566082142e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.23 | train loss last: 3.03 | consumed tokens: 856064000.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T11:06:39 | step: 104600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.757609713124111e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.33 | consumed tokens: 856883200.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T11:07:00 | step: 104700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.757121132570319e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.12 | consumed tokens: 857702400.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T11:07:20 | step: 104800 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.756631824420765e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.19 | consumed tokens: 858521600.0 | grad norm avg: 0.87 | grad norm last: 0.76 | 
2026-01-01T11:07:41 | step: 104900 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.756142516271211e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.58 | consumed tokens: 859340800.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T11:08:01 | step: 105000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.755652480525896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.36 | consumed tokens: 860160000.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T11:08:23 | step: 105100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.755161717184819e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 4.28 | consumed tokens: 860979200.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T11:08:44 | step: 105200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.7546709538437426e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.55 | consumed tokens: 861798400.0 | grad norm avg: 0.86 | grad norm last: 0.95 | 
2026-01-01T11:09:04 | step: 105300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.7541794629069045e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.3 | consumed tokens: 862617600.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T11:09:25 | step: 105400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.753687608172186e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.2 | consumed tokens: 863436800.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T11:09:45 | step: 105500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.753195389639586e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.42 | consumed tokens: 864256000.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T11:10:06 | step: 105600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.752702443511225e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.38 | consumed tokens: 865075200.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T11:10:26 | step: 105700 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.7522091335849836e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.53 | consumed tokens: 865894400.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T11:10:47 | step: 105800 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 4.751715459860861e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.86 | consumed tokens: 866713600.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T11:11:07 | step: 105900 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.751221422338858e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.09 | consumed tokens: 867532800.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T11:11:28 | step: 106000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.750726657221094e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.77 | consumed tokens: 868352000.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T11:11:48 | step: 106100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.7502315283054486e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.33 | consumed tokens: 869171200.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T11:12:09 | step: 106200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.749736035591923e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.53 | consumed tokens: 869990400.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T11:12:29 | step: 106300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.7492398152826354e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.84 | consumed tokens: 870809600.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-01T11:12:50 | step: 106400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.7487432311754674e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.06 | consumed tokens: 871628800.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T11:13:10 | step: 106500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.7482462832704186e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.28 | consumed tokens: 872448000.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T11:13:31 | step: 106600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.747748971567489e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.73 | consumed tokens: 873267200.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T11:13:51 | step: 106700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.7472509322687984e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.55 | consumed tokens: 874086400.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T11:14:12 | step: 106800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.746752529172227e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.62 | consumed tokens: 874905600.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T11:14:32 | step: 106900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.7462537622777745e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.03 | consumed tokens: 875724800.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T11:14:53 | step: 107000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.745754267787561e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.22 | consumed tokens: 876544000.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T11:15:13 | step: 107100 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 4.745254773297347e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.75 | consumed tokens: 877363200.0 | grad norm avg: 0.86 | grad norm last: 0.81 | 
2026-01-01T11:15:34 | step: 107200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.744754551211372e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.41 | consumed tokens: 878182400.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T11:15:54 | step: 107300 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 4.7442536015296355e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.59 | consumed tokens: 879001600.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T11:16:15 | step: 107400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.743752651847899e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.5 | consumed tokens: 879820800.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T11:16:35 | step: 107500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.743250974570401e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.23 | consumed tokens: 880640000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T11:16:56 | step: 107600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.7427489334950224e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.08 | consumed tokens: 881459200.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T11:17:16 | step: 107700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.742246164823882e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.42 | consumed tokens: 882278400.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T11:17:36 | step: 107800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.7417430323548615e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.34 | consumed tokens: 883097600.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T11:17:57 | step: 107900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.74123953608796e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.19 | consumed tokens: 883916800.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T11:18:17 | step: 108000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.740735676023178e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.39 | consumed tokens: 884736000.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T11:18:38 | step: 108100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.740231452160515e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.75 | consumed tokens: 885555200.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T11:18:58 | step: 108200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.7397265007020906e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.66 | consumed tokens: 886374400.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T11:19:19 | step: 108300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.7392211854457855e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.92 | consumed tokens: 887193600.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T11:19:39 | step: 108400 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 4.738715142593719e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.72 | consumed tokens: 888012800.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T11:20:00 | step: 108500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.7382090997416526e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.27 | consumed tokens: 888832000.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T11:20:20 | step: 108600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.737702329293825e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.17 | consumed tokens: 889651200.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T11:20:41 | step: 108700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.737195195048116e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 2.73 | consumed tokens: 890470400.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T11:21:01 | step: 108800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.736687333206646e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.62 | consumed tokens: 891289600.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T11:21:22 | step: 108900 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.7361791075672954e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.86 | consumed tokens: 892108800.0 | grad norm avg: 0.86 | grad norm last: 0.93 | 
2026-01-01T11:21:42 | step: 109000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.735670518130064e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.39 | consumed tokens: 892928000.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T11:22:03 | step: 109100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.735161564894952e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.92 | consumed tokens: 893747200.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T11:22:23 | step: 109200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.734652247861959e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.39 | consumed tokens: 894566400.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T11:22:43 | step: 109300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.734142203233205e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.98 | consumed tokens: 895385600.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T11:23:04 | step: 109400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.73363179480657e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.14 | consumed tokens: 896204800.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T11:23:24 | step: 109500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.7331206587841734e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.05 | consumed tokens: 897024000.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T11:23:45 | step: 109600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.732609522761777e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.77 | consumed tokens: 897843200.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T11:24:06 | step: 109700 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.732097659143619e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.22 | consumed tokens: 898662400.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T11:24:26 | step: 109800 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.731585431727581e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.25 | consumed tokens: 899481600.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T11:24:47 | step: 109900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.731072476715781e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.44 | consumed tokens: 900300800.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T11:25:07 | step: 110000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.730559521703981e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.21 | train loss last: 3.23 | consumed tokens: 901120000.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T11:25:29 | step: 110100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.7300458390964195e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.11 | consumed tokens: 901939200.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T11:25:50 | step: 110200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.7295317926909775e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.84 | consumed tokens: 902758400.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T11:26:10 | step: 110300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.729017018689774e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.09 | consumed tokens: 903577600.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T11:26:31 | step: 110400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.72850188089069e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.44 | consumed tokens: 904396800.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T11:26:51 | step: 110500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.727986379293725e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.45 | consumed tokens: 905216000.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T11:27:11 | step: 110600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.727470513898879e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.17 | consumed tokens: 906035200.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T11:27:32 | step: 110700 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.726953920908272e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.33 | consumed tokens: 906854400.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T11:27:52 | step: 110800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.726437327917665e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.22 | consumed tokens: 907673600.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T11:28:13 | step: 110900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.725920007331297e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.16 | consumed tokens: 908492800.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T11:28:33 | step: 111000 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 4.725401959149167e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.97 | consumed tokens: 909312000.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T11:28:54 | step: 111100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.724883910967037e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.56 | consumed tokens: 910131200.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T11:29:14 | step: 111200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.724365135189146e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.23 | consumed tokens: 910950400.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T11:29:35 | step: 111300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.723845995613374e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.39 | consumed tokens: 911769600.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T11:29:55 | step: 111400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.7233261284418404e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.62 | consumed tokens: 912588800.0 | grad norm avg: 0.86 | grad norm last: 0.78 | 
2026-01-01T11:30:16 | step: 111500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.722805897472426e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.34 | consumed tokens: 913408000.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T11:30:36 | step: 111600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.722285666503012e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.05 | consumed tokens: 914227200.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T11:30:57 | step: 111700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.721764344139956e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.3 | consumed tokens: 915046400.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T11:31:17 | step: 111800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.7212430217769e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.61 | consumed tokens: 915865600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T11:31:38 | step: 111900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.720720971818082e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 4.56 | consumed tokens: 916684800.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T11:31:58 | step: 112000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.720198558061384e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.67 | consumed tokens: 917504000.0 | grad norm avg: 0.87 | grad norm last: 0.96 | 
2026-01-01T11:32:18 | step: 112100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.7196757805068046e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.34 | consumed tokens: 918323200.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T11:32:39 | step: 112200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.719152275356464e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.75 | consumed tokens: 919142400.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T11:33:00 | step: 112300 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 4.7186287702061236e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.81 | consumed tokens: 919961600.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T11:33:20 | step: 112400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.718104537460022e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.84 | consumed tokens: 920780800.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T11:33:41 | step: 112500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.7175795771181583e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.2 | consumed tokens: 921600000.0 | grad norm avg: 0.86 | grad norm last: 0.99 | 
2026-01-01T11:34:01 | step: 112600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.717054616776295e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.02 | consumed tokens: 922419200.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T11:34:22 | step: 112700 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.71652892883867e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.81 | consumed tokens: 923238400.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T11:34:42 | step: 112800 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.716002877103165e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.09 | consumed tokens: 924057600.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T11:35:03 | step: 112900 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.7154764615697786e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.61 | consumed tokens: 924876800.0 | grad norm avg: 0.88 | grad norm last: 0.8 | 
2026-01-01T11:35:23 | step: 113000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.714949318440631e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.88 | consumed tokens: 925696000.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T11:35:43 | step: 113100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.714421811513603e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.31 | consumed tokens: 926515200.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T11:36:04 | step: 113200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.713893940788694e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.92 | consumed tokens: 927334400.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T11:36:24 | step: 113300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.713365706265904e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.27 | consumed tokens: 928153600.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T11:36:45 | step: 113400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.712836744147353e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.36 | consumed tokens: 928972800.0 | grad norm avg: 0.86 | grad norm last: 0.91 | 
2026-01-01T11:37:05 | step: 113500 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.712307418230921e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.41 | consumed tokens: 929792000.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T11:37:26 | step: 113600 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 4.7117777285166085e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.83 | consumed tokens: 930611200.0 | grad norm avg: 0.87 | grad norm last: 0.79 | 
2026-01-01T11:37:46 | step: 113700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.7112473112065345e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.52 | consumed tokens: 931430400.0 | grad norm avg: 0.87 | grad norm last: 0.77 | 
2026-01-01T11:38:07 | step: 113800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.7107168938964605e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.27 | consumed tokens: 932249600.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T11:38:27 | step: 113900 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.710185748990625e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.56 | consumed tokens: 933068800.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T11:38:48 | step: 114000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.709654240286909e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.09 | consumed tokens: 933888000.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T11:39:08 | step: 114100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.7091220039874315e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.5 | consumed tokens: 934707200.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T11:39:29 | step: 114200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.708589767687954e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.69 | consumed tokens: 935526400.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T11:39:49 | step: 114300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.708056803792715e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.05 | consumed tokens: 936345600.0 | grad norm avg: 0.86 | grad norm last: 0.92 | 
2026-01-01T11:40:09 | step: 114400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.707523112301715e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.17 | consumed tokens: 937164800.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T11:40:30 | step: 114500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.7069894208107144e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.55 | consumed tokens: 937984000.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T11:40:51 | step: 114600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.7064550017239526e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.25 | consumed tokens: 938803200.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T11:41:11 | step: 114700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.70592021883931e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.81 | consumed tokens: 939622400.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T11:41:31 | step: 114800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.705385072156787e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.91 | consumed tokens: 940441600.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T11:41:52 | step: 114900 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 4.704849561676383e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.23 | consumed tokens: 941260800.0 | grad norm avg: 0.85 | grad norm last: 0.81 | 
2026-01-01T11:42:13 | step: 115000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.704313323600218e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.0 | consumed tokens: 942080000.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T11:42:35 | step: 115100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.703776721726172e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.86 | consumed tokens: 942899200.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T11:42:55 | step: 115200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.703239756054245e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 4.0 | consumed tokens: 943718400.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T11:43:16 | step: 115300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.702702062786557e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.98 | consumed tokens: 944537600.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T11:43:36 | step: 115400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.7021643695188686e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.38 | consumed tokens: 945356800.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T11:43:57 | step: 115500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.701625948655419e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.91 | consumed tokens: 946176000.0 | grad norm avg: 0.86 | grad norm last: 0.79 | 
2026-01-01T11:44:17 | step: 115600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.701086800196208e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.89 | consumed tokens: 946995200.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T11:44:38 | step: 115700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.700547651736997e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.64 | consumed tokens: 947814400.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T11:44:58 | step: 115800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.7000077756820247e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.88 | consumed tokens: 948633600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T11:45:19 | step: 115900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.6994675358291715e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.48 | consumed tokens: 949452800.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T11:45:39 | step: 116000 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.698926932178438e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.25 | consumed tokens: 950272000.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T11:46:00 | step: 116100 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.6983856009319425e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.7 | consumed tokens: 951091200.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T11:46:21 | step: 116200 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 4.697844269685447e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.58 | consumed tokens: 951910400.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T11:46:41 | step: 116300 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.6973022108431906e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.12 | consumed tokens: 952729600.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T11:47:02 | step: 116400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.6967594244051725e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.89 | consumed tokens: 953548800.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T11:47:22 | step: 116500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.6962166379671544e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.08 | consumed tokens: 954368000.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T11:47:42 | step: 116600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.695673123933375e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.94 | consumed tokens: 955187200.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T11:48:03 | step: 116700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.695129246101715e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.81 | consumed tokens: 956006400.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T11:48:23 | step: 116800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.694585004472174e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.84 | consumed tokens: 956825600.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T11:48:44 | step: 116900 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.694040399044752e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.19 | consumed tokens: 957644800.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T11:49:04 | step: 117000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.693495066021569e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.3 | consumed tokens: 958464000.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T11:49:25 | step: 117100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.692949369200505e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 2.95 | consumed tokens: 959283200.0 | grad norm avg: 0.86 | grad norm last: 0.97 | 
2026-01-01T11:49:45 | step: 117200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.692403308581561e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.75 | consumed tokens: 960102400.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T11:50:06 | step: 117300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.691856520366855e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.42 | consumed tokens: 960921600.0 | grad norm avg: 0.87 | grad norm last: 0.94 | 
2026-01-01T11:50:26 | step: 117400 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.6913093683542684e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.05 | consumed tokens: 961740800.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T11:50:47 | step: 117500 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 4.690761852543801e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.53 | consumed tokens: 962560000.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T11:51:08 | step: 117600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.690213972935453e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.55 | consumed tokens: 963379200.0 | grad norm avg: 0.86 | grad norm last: 0.91 | 
2026-01-01T11:51:28 | step: 117700 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.689665729529224e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.33 | consumed tokens: 964198400.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T11:51:49 | step: 117800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.689116758527234e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.55 | consumed tokens: 965017600.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T11:52:09 | step: 117900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.6885674237273633e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.11 | consumed tokens: 965836800.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T11:52:29 | step: 118000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.688017725129612e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.92 | consumed tokens: 966656000.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T11:52:50 | step: 118100 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.6874676627339795e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.42 | consumed tokens: 967475200.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T11:53:11 | step: 118200 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.686916872742586e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.12 | consumed tokens: 968294400.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T11:53:31 | step: 118300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.6863657189533114e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.66 | consumed tokens: 969113600.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T11:53:52 | step: 118400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.6858142013661563e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.14 | consumed tokens: 969932800.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T11:54:12 | step: 118500 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.68526195618324e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.31 | consumed tokens: 970752000.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T11:54:33 | step: 118600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.684709711000323e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.27 | consumed tokens: 971571200.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T11:54:53 | step: 118700 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.6841567382216454e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.83 | consumed tokens: 972390400.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T11:55:14 | step: 118800 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 4.683603401645087e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.33 | consumed tokens: 973209600.0 | grad norm avg: 0.87 | grad norm last: 0.79 | 
2026-01-01T11:55:34 | step: 118900 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.6830493374727666e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.86 | consumed tokens: 974028800.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T11:55:55 | step: 119000 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.6824952733004466e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.09 | consumed tokens: 974848000.0 | grad norm avg: 0.86 | grad norm last: 0.79 | 
2026-01-01T11:56:16 | step: 119100 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.681940481532365e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.89 | consumed tokens: 975667200.0 | grad norm avg: 0.86 | grad norm last: 0.92 | 
2026-01-01T11:56:36 | step: 119200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.681385325966403e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.58 | consumed tokens: 976486400.0 | grad norm avg: 0.87 | grad norm last: 0.78 | 
2026-01-01T11:56:57 | step: 119300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.68082980660256e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.0 | consumed tokens: 977305600.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T11:57:17 | step: 119400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.6802735596429557e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.05 | consumed tokens: 978124800.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T11:57:38 | step: 119500 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.6797169488854706e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.92 | consumed tokens: 978944000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T11:57:58 | step: 119600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.679159974330105e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.11 | consumed tokens: 979763200.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T11:58:19 | step: 119700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.6786026359768584e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.03 | consumed tokens: 980582400.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T11:58:39 | step: 119800 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.6780445700278506e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.33 | consumed tokens: 981401600.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T11:59:00 | step: 119900 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.677486504078843e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.27 | consumed tokens: 982220800.0 | grad norm avg: 0.87 | grad norm last: 0.97 | 
2026-01-01T11:59:20 | step: 120000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.6769277105340734e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.11 | consumed tokens: 983040000.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T11:59:43 | step: 120100 | train samples/s: 82.9 | train mfu (16-bit): -1.0 | lr mean: 4.676368189393543e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.39 | consumed tokens: 983859200.0 | grad norm avg: 0.86 | grad norm last: 0.81 | 
2026-01-01T12:00:03 | step: 120200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.675808668253012e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.58 | consumed tokens: 984678400.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T12:00:24 | step: 120300 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.67524841951672e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.06 | consumed tokens: 985497600.0 | grad norm avg: 0.87 | grad norm last: 0.78 | 
2026-01-01T12:00:44 | step: 120400 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.674687806982547e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.33 | consumed tokens: 986316800.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-01T12:01:05 | step: 120500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.6741268306504935e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 4.03 | consumed tokens: 987136000.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T12:01:25 | step: 120600 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.673565490520559e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.3 | consumed tokens: 987955200.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T12:01:46 | step: 120700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.6730034227948636e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.58 | consumed tokens: 988774400.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T12:02:06 | step: 120800 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.672440991271287e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.02 | consumed tokens: 989593600.0 | grad norm avg: 0.86 | grad norm last: 0.92 | 
2026-01-01T12:02:27 | step: 120900 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.67187819594983e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.0 | consumed tokens: 990412800.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T12:02:47 | step: 121000 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.671315036830492e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.34 | consumed tokens: 991232000.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T12:03:08 | step: 121100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.670751150115393e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.77 | consumed tokens: 992051200.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T12:03:28 | step: 121200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.670186899602413e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.98 | consumed tokens: 992870400.0 | grad norm avg: 0.86 | grad norm last: 0.81 | 
2026-01-01T12:03:49 | step: 121300 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.6696222852915525e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.16 | consumed tokens: 993689600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T12:04:10 | step: 121400 | train samples/s: 82.7 | train mfu (16-bit): -1.0 | lr mean: 4.669057307182811e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.19 | consumed tokens: 994508800.0 | grad norm avg: 0.85 | grad norm last: 0.88 | 
2026-01-01T12:04:30 | step: 121500 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.6684916014783084e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.03 | consumed tokens: 995328000.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T12:04:51 | step: 121600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.667925895773806e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.28 | consumed tokens: 996147200.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T12:05:11 | step: 121700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.6673594624735415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.2 | consumed tokens: 996966400.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T12:05:32 | step: 121800 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.666792301577516e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.05 | consumed tokens: 997785600.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T12:05:52 | step: 121900 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.66622514068149e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.36 | consumed tokens: 998604800.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T12:06:13 | step: 122000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.665657252189703e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.42 | consumed tokens: 999424000.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T12:06:33 | step: 122100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.6650889999000356e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.3 | consumed tokens: 1000243200.0 | grad norm avg: 0.87 | grad norm last: 1.04 | 
2026-01-01T12:06:54 | step: 122200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.664520383812487e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.77 | consumed tokens: 1001062400.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T12:07:14 | step: 122300 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.663951403927058e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.7 | consumed tokens: 1001881600.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T12:07:35 | step: 122400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.6633816964458674e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.02 | consumed tokens: 1002700800.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T12:07:55 | step: 122500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.662811625166796e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.19 | consumed tokens: 1003520000.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T12:08:16 | step: 122600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.662241190089844e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 4.12 | consumed tokens: 1004339200.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T12:08:36 | step: 122700 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.6616703912150115e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.55 | consumed tokens: 1005158400.0 | grad norm avg: 0.87 | grad norm last: 0.96 | 
2026-01-01T12:08:57 | step: 122800 | train samples/s: 82.6 | train mfu (16-bit): -1.0 | lr mean: 4.661099228542298e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.64 | consumed tokens: 1005977600.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T12:09:18 | step: 122900 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.660527338273823e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.19 | consumed tokens: 1006796800.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T12:09:38 | step: 123000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.659955084207468e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.66 | consumed tokens: 1007616000.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T12:09:59 | step: 123100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.6593824663432315e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 4.0 | consumed tokens: 1008435200.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T12:10:19 | step: 123200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.658809120883234e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.17 | consumed tokens: 1009254400.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T12:10:40 | step: 123300 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.6582354116253555e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.3 | consumed tokens: 1010073600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T12:11:00 | step: 123400 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.657661702367477e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.88 | consumed tokens: 1010892800.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T12:11:21 | step: 123500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.6570869017159566e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.59 | consumed tokens: 1011712000.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T12:11:41 | step: 123600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.656512101064436e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 4.06 | consumed tokens: 1012531200.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T12:12:02 | step: 123700 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.655936936615035e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.88 | consumed tokens: 1013350400.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T12:12:22 | step: 123800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.655361044569872e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.17 | consumed tokens: 1014169600.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T12:12:43 | step: 123900 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.654784788726829e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.67 | consumed tokens: 1014988800.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T12:13:04 | step: 124000 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.654208169085905e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 4.0 | consumed tokens: 1015808000.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T12:13:24 | step: 124100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.6536308218492195e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.81 | consumed tokens: 1016627200.0 | grad norm avg: 0.87 | grad norm last: 0.94 | 
2026-01-01T12:13:45 | step: 124200 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.653053110814653e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.31 | consumed tokens: 1017446400.0 | grad norm avg: 0.87 | grad norm last: 0.78 | 
2026-01-01T12:14:05 | step: 124300 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.6524750359822065e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.39 | consumed tokens: 1018265600.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T12:14:26 | step: 124400 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.651896597351879e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.47 | consumed tokens: 1019084800.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T12:14:46 | step: 124500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.6513177949236706e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.33 | consumed tokens: 1019904000.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T12:15:07 | step: 124600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.650738264899701e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.81 | consumed tokens: 1020723200.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T12:15:27 | step: 124700 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.650158734875731e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.02 | consumed tokens: 1021542400.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T12:15:48 | step: 124800 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 4.649578113458119e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.66 | consumed tokens: 1022361600.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T12:16:08 | step: 124900 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.6489974920405075e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.8 | consumed tokens: 1023180800.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T12:16:29 | step: 125000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.648416506825015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.47 | consumed tokens: 1024000000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T12:16:51 | step: 125100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.647834794013761e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.12 | consumed tokens: 1024819200.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T12:17:12 | step: 125200 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.647252717404626e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.66 | consumed tokens: 1025638400.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T12:17:32 | step: 125300 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.646670276997611e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.0 | consumed tokens: 1026457600.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T12:17:53 | step: 125400 | train samples/s: 82.9 | train mfu (16-bit): -1.0 | lr mean: 4.646087472792715e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.11 | consumed tokens: 1027276800.0 | grad norm avg: 0.86 | grad norm last: 0.93 | 
2026-01-01T12:18:13 | step: 125500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.645503940992057e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.33 | consumed tokens: 1028096000.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T12:18:34 | step: 125600 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.644920045393519e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.16 | consumed tokens: 1028915200.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T12:18:55 | step: 125700 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.6443357859971e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.56 | consumed tokens: 1029734400.0 | grad norm avg: 0.88 | grad norm last: 0.77 | 
2026-01-01T12:19:15 | step: 125800 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.6437511628028005e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.06 | consumed tokens: 1030553600.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T12:19:36 | step: 125900 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.64316617581062e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.38 | consumed tokens: 1031372800.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T12:19:56 | step: 126000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.6425804612226784e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.19 | consumed tokens: 1032192000.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T12:20:17 | step: 126100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.641994382836856e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.84 | consumed tokens: 1033011200.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T12:20:37 | step: 126200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.641407940653153e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.84 | consumed tokens: 1033830400.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T12:20:58 | step: 126300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.640821134671569e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.38 | consumed tokens: 1034649600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T12:21:18 | step: 126400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.6402336010942236e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.56 | consumed tokens: 1035468800.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T12:21:38 | step: 126500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.6396457037189975e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.09 | consumed tokens: 1036288000.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T12:21:59 | step: 126600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.639057442545891e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.3 | consumed tokens: 1037107200.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T12:22:20 | step: 126700 | train samples/s: 82.9 | train mfu (16-bit): -1.0 | lr mean: 4.6384688175749034e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.12 | consumed tokens: 1037926400.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T12:22:40 | step: 126800 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.637879828806035e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.12 | consumed tokens: 1038745600.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T12:23:01 | step: 126900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.6372901124414057e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.89 | consumed tokens: 1039564800.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T12:23:21 | step: 127000 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.6367000322788954e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.55 | consumed tokens: 1040384000.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T12:23:42 | step: 127100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.6361095883185044e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.48 | consumed tokens: 1041203200.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T12:24:02 | step: 127200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.635518780560233e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.34 | consumed tokens: 1042022400.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T12:24:22 | step: 127300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.6349272452061996e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.27 | consumed tokens: 1042841600.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T12:24:43 | step: 127400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.6343357098521665e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.17 | consumed tokens: 1043660800.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T12:25:03 | step: 127500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.633743446902372e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.7 | consumed tokens: 1044480000.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T12:25:24 | step: 127600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.633150820154697e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.33 | consumed tokens: 1045299200.0 | grad norm avg: 0.87 | grad norm last: 0.79 | 
2026-01-01T12:25:44 | step: 127700 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.63255746581126e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 4.03 | consumed tokens: 1046118400.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T12:26:05 | step: 127800 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.6319641114678234e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.83 | consumed tokens: 1046937600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T12:26:25 | step: 127900 | train samples/s: 85.3 | train mfu (16-bit): -1.0 | lr mean: 4.631370029528625e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.33 | consumed tokens: 1047756800.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T12:26:46 | step: 128000 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 4.6307755837915465e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.12 | consumed tokens: 1048576000.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T12:27:06 | step: 128100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.630180774256587e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.03 | consumed tokens: 1049395200.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T12:27:27 | step: 128200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.629585600923747e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.28 | consumed tokens: 1050214400.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T12:27:47 | step: 128300 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 4.628989699995145e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.33 | consumed tokens: 1051033600.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T12:28:07 | step: 128400 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.628393435268663e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.7 | consumed tokens: 1051852800.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T12:28:28 | step: 128500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.6277968067443e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.69 | consumed tokens: 1052672000.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T12:28:48 | step: 128600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.627199814422056e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.89 | consumed tokens: 1053491200.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T12:29:09 | step: 128700 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.626602094504051e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.08 | consumed tokens: 1054310400.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T12:29:29 | step: 128800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.626004374586046e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.73 | consumed tokens: 1055129600.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T12:29:49 | step: 128900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.625405927072279e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.62 | consumed tokens: 1055948800.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T12:30:10 | step: 129000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.624807115760632e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.27 | consumed tokens: 1056768000.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T12:30:30 | step: 129100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.624207940651104e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.61 | consumed tokens: 1057587200.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T12:30:51 | step: 129200 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.6236080379458144e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.36 | consumed tokens: 1058406400.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T12:31:11 | step: 129300 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 4.623007771442644e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.42 | consumed tokens: 1059225600.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T12:31:32 | step: 129400 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 4.622407504939474e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.98 | consumed tokens: 1060044800.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T12:31:52 | step: 129500 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.621806147042662e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.39 | consumed tokens: 1060864000.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T12:32:12 | step: 129600 | train samples/s: 85.2 | train mfu (16-bit): -1.0 | lr mean: 4.6212047891458496e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.41 | consumed tokens: 1061683200.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T12:32:33 | step: 129700 | train samples/s: 85.3 | train mfu (16-bit): -1.0 | lr mean: 4.620603067451157e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.19 | consumed tokens: 1062502400.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T12:32:53 | step: 129800 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.620000618160702e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.58 | consumed tokens: 1063321600.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T12:33:13 | step: 129900 | train samples/s: 85.2 | train mfu (16-bit): -1.0 | lr mean: 4.619397805072367e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.5 | consumed tokens: 1064140800.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T12:33:34 | step: 130000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.6187946281861514e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.94 | consumed tokens: 1064960000.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T12:33:56 | step: 130100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.618191087502055e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.3 | consumed tokens: 1065779200.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T12:34:16 | step: 130200 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.617586819222197e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.97 | consumed tokens: 1066598400.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T12:34:37 | step: 130300 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.616982187144458e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.08 | consumed tokens: 1067417600.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T12:34:57 | step: 130400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.616377191268839e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.97 | consumed tokens: 1068236800.0 | grad norm avg: 0.87 | grad norm last: 0.98 | 
2026-01-01T12:35:18 | step: 130500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.615771831595339e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.86 | consumed tokens: 1069056000.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T12:35:38 | step: 130600 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.615166108123958e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.12 | consumed tokens: 1069875200.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T12:35:59 | step: 130700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.614559657056816e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.09 | consumed tokens: 1070694400.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T12:36:19 | step: 130800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.613953205989674e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.0 | consumed tokens: 1071513600.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T12:36:40 | step: 130900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.61334602732677e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.0 | consumed tokens: 1072332800.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T12:37:00 | step: 131000 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.612738121068105e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.48 | consumed tokens: 1073152000.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T12:37:20 | step: 131100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.61213021480944e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.75 | consumed tokens: 1073971200.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T12:37:41 | step: 131200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.6115215809550136e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.72 | consumed tokens: 1074790400.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T12:38:01 | step: 131300 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.610912947100587e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.33 | consumed tokens: 1075609600.0 | grad norm avg: 0.87 | grad norm last: 0.79 | 
2026-01-01T12:38:22 | step: 131400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.610303585650399e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.81 | consumed tokens: 1076428800.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T12:38:42 | step: 131500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.609693860402331e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.27 | consumed tokens: 1077248000.0 | grad norm avg: 0.88 | grad norm last: 0.95 | 
2026-01-01T12:39:02 | step: 131600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.609083407558501e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.66 | consumed tokens: 1078067200.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T12:39:23 | step: 131700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.608472954714671e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.81 | consumed tokens: 1078886400.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-01T12:39:43 | step: 131800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.6078617742750794e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.0 | consumed tokens: 1079705600.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T12:40:04 | step: 131900 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 4.607250230037607e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.62 | consumed tokens: 1080524800.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T12:40:25 | step: 132000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.6066383220022544e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.38 | consumed tokens: 1081344000.0 | grad norm avg: 0.85 | grad norm last: 0.84 | 
2026-01-01T12:40:45 | step: 132100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.606026050169021e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.97 | consumed tokens: 1082163200.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T12:41:05 | step: 132200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.605413050740026e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.12 | consumed tokens: 1082982400.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T12:41:26 | step: 132300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.60479968751315e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.2 | train loss last: 3.27 | consumed tokens: 1083801600.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T12:41:46 | step: 132400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.604185960488394e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.59 | consumed tokens: 1084620800.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T12:42:07 | step: 132500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.603571869665757e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.19 | consumed tokens: 1085440000.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T12:42:27 | step: 132600 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.602957415045239e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.88 | consumed tokens: 1086259200.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T12:42:47 | step: 132700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.60234223282896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.44 | consumed tokens: 1087078400.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T12:43:08 | step: 132800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.6017270506126806e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.41 | consumed tokens: 1087897600.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T12:43:28 | step: 132900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.60111114080064e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.98 | consumed tokens: 1088716800.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T12:43:49 | step: 133000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.6004948671907187e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.36 | consumed tokens: 1089536000.0 | grad norm avg: 0.87 | grad norm last: 0.79 | 
2026-01-01T12:44:09 | step: 133100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.599877865985036e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.73 | consumed tokens: 1090355200.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T12:44:30 | step: 133200 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 4.599260864779353e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.56 | consumed tokens: 1091174400.0 | grad norm avg: 0.86 | grad norm last: 0.79 | 
2026-01-01T12:44:50 | step: 133300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.598643135977909e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.53 | consumed tokens: 1091993600.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T12:45:11 | step: 133400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.598025043378584e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.94 | consumed tokens: 1092812800.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T12:45:31 | step: 133500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.5974065869813785e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.44 | consumed tokens: 1093632000.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T12:45:52 | step: 133600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.596787766786292e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.95 | consumed tokens: 1094451200.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T12:46:12 | step: 133700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.5961682189954445e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.69 | consumed tokens: 1095270400.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T12:46:32 | step: 133800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.595548671204597e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.73 | consumed tokens: 1096089600.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T12:46:53 | step: 133900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.5949283958179876e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.14 | consumed tokens: 1096908800.0 | grad norm avg: 0.87 | grad norm last: 0.96 | 
2026-01-01T12:47:13 | step: 134000 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.594307756633498e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.23 | consumed tokens: 1097728000.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T12:47:34 | step: 134100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.593686753651127e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.11 | consumed tokens: 1098547200.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T12:47:54 | step: 134200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.593065023072995e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.09 | consumed tokens: 1099366400.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T12:48:14 | step: 134300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.592443292494863e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.39 | consumed tokens: 1100185600.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T12:48:35 | step: 134400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.59182083432097e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.09 | consumed tokens: 1101004800.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T12:48:56 | step: 134500 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.591198012349196e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.5 | consumed tokens: 1101824000.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T12:49:16 | step: 134600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.590574826579541e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.45 | consumed tokens: 1102643200.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T12:49:36 | step: 134700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.589950913214125e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.45 | consumed tokens: 1103462400.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T12:49:57 | step: 134800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.5893269998487085e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.23 | consumed tokens: 1104281600.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T12:50:17 | step: 134900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.588702358887531e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.81 | consumed tokens: 1105100800.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T12:50:38 | step: 135000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.5880773541284725e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.52 | consumed tokens: 1105920000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T12:51:00 | step: 135100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.5874519855715334e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.11 | consumed tokens: 1106739200.0 | grad norm avg: 0.86 | grad norm last: 0.92 | 
2026-01-01T12:51:21 | step: 135200 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.586826253216714e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.09 | consumed tokens: 1107558400.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T12:51:41 | step: 135300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.5861997932661325e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.64 | consumed tokens: 1108377600.0 | grad norm avg: 0.86 | grad norm last: 0.96 | 
2026-01-01T12:52:01 | step: 135400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.585573333315551e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.39 | consumed tokens: 1109196800.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T12:52:22 | step: 135500 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.584946145769209e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.27 | consumed tokens: 1110016000.0 | grad norm avg: 0.87 | grad norm last: 0.96 | 
2026-01-01T12:52:42 | step: 135600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.5843185944249853e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.88 | consumed tokens: 1110835200.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T12:53:03 | step: 135700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.5836903154850006e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.66 | consumed tokens: 1111654400.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T12:53:24 | step: 135800 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 4.583062036545016e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.5 | consumed tokens: 1112473600.0 | grad norm avg: 0.86 | grad norm last: 0.91 | 
2026-01-01T12:53:44 | step: 135900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.58243303000927e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.86 | consumed tokens: 1113292800.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T12:54:05 | step: 136000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.5818040234735236e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.91 | consumed tokens: 1114112000.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T12:54:25 | step: 136100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.581174289342016e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.45 | consumed tokens: 1114931200.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T12:54:46 | step: 136200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.580544191412628e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.08 | consumed tokens: 1115750400.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T12:55:06 | step: 136300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.579913365887478e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.47 | consumed tokens: 1116569600.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T12:55:27 | step: 136400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.579282540362328e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.06 | consumed tokens: 1117388800.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T12:55:47 | step: 136500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.578650987241417e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.84 | consumed tokens: 1118208000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T12:56:08 | step: 136600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.5780190703226253e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.16 | consumed tokens: 1119027200.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T12:56:28 | step: 136700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.577386789605953e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.84 | consumed tokens: 1119846400.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T12:56:49 | step: 136800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.5767541450913996e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.38 | consumed tokens: 1120665600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T12:57:09 | step: 136900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.576120772981085e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.14 | consumed tokens: 1121484800.0 | grad norm avg: 0.86 | grad norm last: 0.95 | 
2026-01-01T12:57:30 | step: 137000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.57548740087077e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.73 | consumed tokens: 1122304000.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T12:57:50 | step: 137100 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 4.574853301164694e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.05 | consumed tokens: 1123123200.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T12:58:11 | step: 137200 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.574218837660737e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.86 | consumed tokens: 1123942400.0 | grad norm avg: 0.85 | grad norm last: 0.88 | 
2026-01-01T12:58:31 | step: 137300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.5735840103589e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.72 | consumed tokens: 1124761600.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T12:58:52 | step: 137400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.5729488192591816e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.38 | consumed tokens: 1125580800.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T12:59:12 | step: 137500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.572312900563702e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.67 | consumed tokens: 1126400000.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T12:59:33 | step: 137600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.5716769818682224e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.23 | consumed tokens: 1127219200.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T12:59:53 | step: 137700 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.571040335576981e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.03 | consumed tokens: 1128038400.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T13:00:14 | step: 137800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.5704033254878595e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.97 | consumed tokens: 1128857600.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T13:00:34 | step: 137900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.569765951600857e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.08 | consumed tokens: 1129676800.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-01T13:00:55 | step: 138000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.569127850118093e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.17 | consumed tokens: 1130496000.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T13:01:15 | step: 138100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.568489748635329e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.38 | consumed tokens: 1131315200.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T13:01:35 | step: 138200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.567850919556804e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 4.06 | consumed tokens: 1132134400.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T13:01:56 | step: 138300 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 4.567211726680398e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.03 | consumed tokens: 1132953600.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T13:02:16 | step: 138400 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 4.566572170006111e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.94 | consumed tokens: 1133772800.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T13:02:37 | step: 138500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.565932249533944e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.19 | consumed tokens: 1134592000.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T13:02:57 | step: 138600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.565291601466015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.53 | consumed tokens: 1135411200.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T13:03:18 | step: 138700 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.564650953398086e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.45 | consumed tokens: 1136230400.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T13:03:38 | step: 138800 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.564009577734396e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.91 | consumed tokens: 1137049600.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T13:03:58 | step: 138900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.563367838272825e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.44 | consumed tokens: 1137868800.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-01T13:04:19 | step: 139000 | train samples/s: 85.2 | train mfu (16-bit): -1.0 | lr mean: 4.562725735013373e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.02 | consumed tokens: 1138688000.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T13:04:39 | step: 139100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.56208290415816e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.56 | consumed tokens: 1139507200.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T13:05:00 | step: 139200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.561440073302947e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.0 | consumed tokens: 1140326400.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T13:05:20 | step: 139300 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.5607965148519725e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.19 | consumed tokens: 1141145600.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T13:05:41 | step: 139400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.560152956400998e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.94 | consumed tokens: 1141964800.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T13:06:01 | step: 139500 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.559508670354262e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.61 | consumed tokens: 1142784000.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T13:06:21 | step: 139600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.5588636567117646e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.17 | consumed tokens: 1143603200.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T13:06:42 | step: 139700 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 4.558218643069267e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.61 | consumed tokens: 1144422400.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T13:07:02 | step: 139800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.557573265628889e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.34 | consumed tokens: 1145241600.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T13:07:23 | step: 139900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.55692716059275e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.78 | consumed tokens: 1146060800.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T13:07:43 | step: 140000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.5562806917587295e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.03 | consumed tokens: 1146880000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T13:08:06 | step: 140100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.5556338591268286e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.12 | consumed tokens: 1147699200.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T13:08:26 | step: 140200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.554986662697047e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.69 | consumed tokens: 1148518400.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T13:08:47 | step: 140300 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.554339102469385e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.84 | consumed tokens: 1149337600.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T13:09:07 | step: 140400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.553690814645961e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.62 | consumed tokens: 1150156800.0 | grad norm avg: 0.86 | grad norm last: 0.94 | 
2026-01-01T13:09:28 | step: 140500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.553042526822537e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.84 | consumed tokens: 1150976000.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T13:09:48 | step: 140600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.552393511403352e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.11 | consumed tokens: 1151795200.0 | grad norm avg: 0.87 | grad norm last: 0.97 | 
2026-01-01T13:10:09 | step: 140700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.551744132186286e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.86 | consumed tokens: 1152614400.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T13:10:29 | step: 140800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.5510943891713396e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.95 | consumed tokens: 1153433600.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T13:10:50 | step: 140900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.5504439185606316e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.34 | consumed tokens: 1154252800.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T13:11:10 | step: 141000 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 4.5497934479499236e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.0 | consumed tokens: 1155072000.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T13:11:31 | step: 141100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.549142249743454e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.08 | consumed tokens: 1155891200.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T13:11:51 | step: 141200 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.548490687739104e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.38 | consumed tokens: 1156710400.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T13:12:11 | step: 141300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.547838761936873e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.77 | consumed tokens: 1157529600.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T13:12:32 | step: 141400 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 4.5471864723367617e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.7 | consumed tokens: 1158348800.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T13:12:54 | step: 141500 | train samples/s: 79.6 | train mfu (16-bit): -1.0 | lr mean: 4.5465338189387694e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.14 | consumed tokens: 1159168000.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T13:13:15 | step: 141600 | train samples/s: 82.0 | train mfu (16-bit): -1.0 | lr mean: 4.545880437945016e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 3.16 | consumed tokens: 1159987200.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T13:13:36 | step: 141700 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 4.545227056951262e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.5 | consumed tokens: 1160806400.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T13:13:56 | step: 141800 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 4.544572948361747e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.84 | consumed tokens: 1161625600.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T13:14:17 | step: 141900 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 4.543918475974351e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.16 | consumed tokens: 1162444800.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T13:14:38 | step: 142000 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 4.5432636397890747e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.11 | consumed tokens: 1163264000.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T13:14:58 | step: 142100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.542608076008037e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.17 | consumed tokens: 1164083200.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T13:15:19 | step: 142200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.541952512226999e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.03 | consumed tokens: 1164902400.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T13:15:39 | step: 142300 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 4.5412962208501995e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.47 | consumed tokens: 1165721600.0 | grad norm avg: 0.88 | grad norm last: 1.05 | 
2026-01-01T13:16:00 | step: 142400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.5406399294734e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.98 | consumed tokens: 1166540800.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T13:16:20 | step: 142500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.5399829105008394e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.12 | consumed tokens: 1167360000.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T13:16:41 | step: 142600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.539325163932517e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.44 | consumed tokens: 1168179200.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T13:17:01 | step: 142700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.538667417364195e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.03 | consumed tokens: 1168998400.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T13:17:22 | step: 142800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.538009306997992e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.88 | consumed tokens: 1169817600.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T13:17:42 | step: 142900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.537350469036028e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.8 | consumed tokens: 1170636800.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T13:18:03 | step: 143000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.5366916310740635e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.17 | consumed tokens: 1171456000.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T13:18:23 | step: 143100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.536032065516338e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.3 | consumed tokens: 1172275200.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T13:18:43 | step: 143200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.535372136160731e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.08 | consumed tokens: 1173094400.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T13:19:04 | step: 143300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.5347114792093635e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.06 | consumed tokens: 1173913600.0 | grad norm avg: 0.86 | grad norm last: 0.97 | 
2026-01-01T13:19:24 | step: 143400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.5340508222579956e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.52 | consumed tokens: 1174732800.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T13:19:45 | step: 143500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.533389801508747e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.7 | consumed tokens: 1175552000.0 | grad norm avg: 0.86 | grad norm last: 0.94 | 
2026-01-01T13:20:05 | step: 143600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.532728053163737e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.22 | consumed tokens: 1176371200.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T13:20:26 | step: 143700 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 4.5320659410208464e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.19 | consumed tokens: 1177190400.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T13:20:46 | step: 143800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.531403465080075e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.17 | consumed tokens: 1178009600.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T13:21:07 | step: 143900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.530740625341423e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.33 | consumed tokens: 1178828800.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T13:21:27 | step: 144000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.53007742180489e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.98 | consumed tokens: 1179648000.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T13:21:47 | step: 144100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.529413490672596e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.36 | consumed tokens: 1180467200.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T13:22:08 | step: 144200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.5287495595403016e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.34 | consumed tokens: 1181286400.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T13:22:28 | step: 144300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.528084900812246e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.5 | consumed tokens: 1182105600.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T13:22:49 | step: 144400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.5274198782863095e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.27 | consumed tokens: 1182924800.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T13:23:09 | step: 144500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.5267544919624925e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.12 | consumed tokens: 1183744000.0 | grad norm avg: 0.86 | grad norm last: 0.92 | 
2026-01-01T13:23:30 | step: 144600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.526088741840795e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.59 | consumed tokens: 1184563200.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T13:23:50 | step: 144700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.5254222641233355e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.55 | consumed tokens: 1185382400.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T13:24:11 | step: 144800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.524755786405876e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.5 | consumed tokens: 1186201600.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T13:24:31 | step: 144900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.5240885810926557e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.77 | consumed tokens: 1187020800.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T13:24:52 | step: 145000 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 4.523421011981554e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.83 | consumed tokens: 1187840000.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T13:25:14 | step: 145100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.522753079072572e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.59 | consumed tokens: 1188659200.0 | grad norm avg: 0.87 | grad norm last: 0.79 | 
2026-01-01T13:25:34 | step: 145200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.5220847823657095e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.09 | consumed tokens: 1189478400.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T13:25:55 | step: 145300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.521416121860966e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.62 | consumed tokens: 1190297600.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T13:26:15 | step: 145400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.520747097558342e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.86 | consumed tokens: 1191116800.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T13:26:36 | step: 145500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.520077345659956e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.7 | consumed tokens: 1191936000.0 | grad norm avg: 0.88 | grad norm last: 0.99 | 
2026-01-01T13:26:56 | step: 145600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.51940722996369e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.06 | consumed tokens: 1192755200.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T13:27:16 | step: 145700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.518736750469543e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.0 | consumed tokens: 1193574400.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T13:27:37 | step: 145800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.518065907177515e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.16 | consumed tokens: 1194393600.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T13:27:57 | step: 145900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.517394700087607e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.23 | consumed tokens: 1195212800.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T13:28:18 | step: 146000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.516723129199818e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.86 | consumed tokens: 1196032000.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T13:28:38 | step: 146100 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.516051194514148e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.69 | consumed tokens: 1196851200.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T13:28:59 | step: 146200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.515378532232717e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.77 | consumed tokens: 1197670400.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T13:29:19 | step: 146300 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 4.514705506153405e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.98 | consumed tokens: 1198489600.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T13:29:40 | step: 146400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.514032116276212e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.89 | consumed tokens: 1199308800.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T13:30:00 | step: 146500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.5133583626011387e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.66 | consumed tokens: 1200128000.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T13:30:21 | step: 146600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.5126842451281846e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.3 | consumed tokens: 1200947200.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T13:30:41 | step: 146700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.51200976385735e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.52 | consumed tokens: 1201766400.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T13:31:01 | step: 146800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.5113345549907535e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.05 | consumed tokens: 1202585600.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T13:31:22 | step: 146900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.510659346124157e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.06 | consumed tokens: 1203404800.0 | grad norm avg: 0.86 | grad norm last: 0.79 | 
2026-01-01T13:31:42 | step: 147000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.5099834096618e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.64 | consumed tokens: 1204224000.0 | grad norm avg: 0.88 | grad norm last: 1.0 | 
2026-01-01T13:32:03 | step: 147100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.509307109401561e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.06 | consumed tokens: 1205043200.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T13:32:23 | step: 147200 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.508630445343442e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.18 | train loss last: 2.33 | consumed tokens: 1205862400.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T13:32:44 | step: 147300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.5079534174874425e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.28 | consumed tokens: 1206681600.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T13:33:04 | step: 147400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.507276025833562e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.88 | consumed tokens: 1207500800.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T13:33:24 | step: 147500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.50659790658392e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.75 | consumed tokens: 1208320000.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T13:33:45 | step: 147600 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 4.505919787334278e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 2.72 | consumed tokens: 1209139200.0 | grad norm avg: 0.87 | grad norm last: 1.02 | 
2026-01-01T13:34:06 | step: 147700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.505240940488875e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.33 | consumed tokens: 1209958400.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T13:34:26 | step: 147800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.504561729845591e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.75 | consumed tokens: 1210777600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T13:34:46 | step: 147900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.503882155404426e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.16 | consumed tokens: 1211596800.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T13:35:07 | step: 148000 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.503202217165381e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.98 | consumed tokens: 1212416000.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T13:35:27 | step: 148100 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.5025219151284546e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.03 | consumed tokens: 1213235200.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T13:35:47 | step: 148200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.501840885495767e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.03 | consumed tokens: 1214054400.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T13:36:08 | step: 148300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.5011598558630794e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.11 | consumed tokens: 1214873600.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T13:36:28 | step: 148400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.5004780986346304e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.61 | consumed tokens: 1215692800.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T13:36:49 | step: 148500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.499795977608301e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.25 | consumed tokens: 1216512000.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T13:37:09 | step: 148600 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.4991134927840903e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.11 | consumed tokens: 1217331200.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T13:37:30 | step: 148700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.498430644161999e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.81 | consumed tokens: 1218150400.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T13:37:50 | step: 148800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.4977474317420274e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.83 | consumed tokens: 1218969600.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T13:38:11 | step: 148900 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.497063491726294e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.52 | consumed tokens: 1219788800.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T13:38:31 | step: 149000 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.496379551710561e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.48 | consumed tokens: 1220608000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T13:38:51 | step: 149100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.495694884099066e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.89 | consumed tokens: 1221427200.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T13:39:12 | step: 149200 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.495009852689691e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.16 | consumed tokens: 1222246400.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T13:39:32 | step: 149300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.494324457482435e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.83 | consumed tokens: 1223065600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T13:39:53 | step: 149400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.493638698477298e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.22 | consumed tokens: 1223884800.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T13:40:13 | step: 149500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.4929525756742805e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.12 | consumed tokens: 1224704000.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T13:40:33 | step: 149600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.492266089073382e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.17 | consumed tokens: 1225523200.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T13:40:54 | step: 149700 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.491578874876723e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.38 | consumed tokens: 1226342400.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T13:41:14 | step: 149800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.490891660680063e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.47 | consumed tokens: 1227161600.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T13:41:35 | step: 149900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.490203718887642e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.17 | consumed tokens: 1227980800.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T13:41:55 | step: 150000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.48951541329734e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.25 | consumed tokens: 1228800000.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T13:42:17 | step: 150100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.488826743909158e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.95 | consumed tokens: 1229619200.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T13:42:38 | step: 150200 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 4.4881377107230946e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 4.06 | consumed tokens: 1230438400.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T13:42:58 | step: 150300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.487448313739151e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.61 | consumed tokens: 1231257600.0 | grad norm avg: 0.87 | grad norm last: 0.99 | 
2026-01-01T13:43:19 | step: 150400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.486758552957326e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.16 | consumed tokens: 1232076800.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T13:43:39 | step: 150500 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.48606806457974e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.8 | consumed tokens: 1232896000.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T13:43:59 | step: 150600 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.4853772124042735e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.34 | consumed tokens: 1233715200.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T13:44:20 | step: 150700 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.484686360228807e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 4.09 | consumed tokens: 1234534400.0 | grad norm avg: 0.86 | grad norm last: 0.79 | 
2026-01-01T13:44:40 | step: 150800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.4839947804575786e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.11 | consumed tokens: 1235353600.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T13:45:01 | step: 150900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.48330283688847e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.08 | consumed tokens: 1236172800.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T13:45:21 | step: 151000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.48261052952148e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.06 | consumed tokens: 1236992000.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T13:45:41 | step: 151100 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.481917494558729e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.27 | consumed tokens: 1237811200.0 | grad norm avg: 0.87 | grad norm last: 0.79 | 
2026-01-01T13:46:02 | step: 151200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.481224459595978e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.22 | consumed tokens: 1238630400.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T13:46:22 | step: 151300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.480530697037466e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.58 | consumed tokens: 1239449600.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T13:46:43 | step: 151400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.4798369344789535e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.95 | consumed tokens: 1240268800.0 | grad norm avg: 0.88 | grad norm last: 0.97 | 
2026-01-01T13:47:03 | step: 151500 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 4.47914244432468e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.23 | consumed tokens: 1241088000.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T13:47:24 | step: 151600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.478447590372525e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.69 | consumed tokens: 1241907200.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T13:47:44 | step: 151700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.47775237262249e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.86 | consumed tokens: 1242726400.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T13:48:05 | step: 151800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.477056791074574e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.17 | consumed tokens: 1243545600.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T13:48:25 | step: 151900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.4763608457287773e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.23 | consumed tokens: 1244364800.0 | grad norm avg: 0.87 | grad norm last: 0.94 | 
2026-01-01T13:48:46 | step: 152000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.475664172787219e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.91 | consumed tokens: 1245184000.0 | grad norm avg: 0.86 | grad norm last: 0.91 | 
2026-01-01T13:49:06 | step: 152100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.474967499845661e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.92 | consumed tokens: 1246003200.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T13:49:26 | step: 152200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.474270099308342e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.2 | consumed tokens: 1246822400.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T13:49:47 | step: 152300 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 4.4735723349731416e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.11 | consumed tokens: 1247641600.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T13:50:07 | step: 152400 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 4.4728745706379414e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.34 | consumed tokens: 1248460800.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T13:50:27 | step: 152500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.47217607870698e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.91 | consumed tokens: 1249280000.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T13:50:48 | step: 152600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.471476859180257e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.19 | train loss last: 3.3 | consumed tokens: 1250099200.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T13:51:08 | step: 152700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.470777639653534e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.92 | consumed tokens: 1250918400.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T13:51:29 | step: 152800 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 4.47007805632893e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.06 | consumed tokens: 1251737600.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T13:51:49 | step: 152900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.469377745408565e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.7 | consumed tokens: 1252556800.0 | grad norm avg: 0.87 | grad norm last: 0.78 | 
2026-01-01T13:52:10 | step: 153000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.4686774344881997e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.84 | consumed tokens: 1253376000.0 | grad norm avg: 0.86 | grad norm last: 0.94 | 
2026-01-01T13:52:30 | step: 153100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.467976395972073e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.55 | consumed tokens: 1254195200.0 | grad norm avg: 0.87 | grad norm last: 0.79 | 
2026-01-01T13:52:51 | step: 153200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.467274993658066e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.25 | consumed tokens: 1255014400.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T13:53:11 | step: 153300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.466573227546178e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.31 | consumed tokens: 1255833600.0 | grad norm avg: 0.86 | grad norm last: 0.81 | 
2026-01-01T13:53:32 | step: 153400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.465871097636409e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 4.03 | consumed tokens: 1256652800.0 | grad norm avg: 0.87 | grad norm last: 0.77 | 
2026-01-01T13:53:52 | step: 153500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.46516860392876e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.05 | consumed tokens: 1257472000.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T13:54:12 | step: 153600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.4644657464232296e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.75 | consumed tokens: 1258291200.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T13:54:33 | step: 153700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.463762161321938e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.3 | consumed tokens: 1259110400.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T13:54:53 | step: 153800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.4630585762206465e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.23 | consumed tokens: 1259929600.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T13:55:14 | step: 153900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.4623542635235935e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.88 | consumed tokens: 1260748800.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T13:55:34 | step: 154000 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.46164958702866e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.42 | consumed tokens: 1261568000.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T13:55:55 | step: 154100 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 4.4609445467358455e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.22 | consumed tokens: 1262387200.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T13:56:15 | step: 154200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.4602391426451504e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.56 | consumed tokens: 1263206400.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T13:56:36 | step: 154300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.4595333747565746e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.92 | consumed tokens: 1264025600.0 | grad norm avg: 0.86 | grad norm last: 0.93 | 
2026-01-01T13:56:56 | step: 154400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.458827243070118e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.41 | consumed tokens: 1264844800.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-01T13:57:17 | step: 154500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.458120747585781e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.28 | consumed tokens: 1265664000.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T13:57:37 | step: 154600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.457413524505682e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.11 | consumed tokens: 1266483200.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T13:57:57 | step: 154700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.4567063014255837e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.98 | consumed tokens: 1267302400.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T13:58:18 | step: 154800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.4559983507497236e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.28 | consumed tokens: 1268121600.0 | grad norm avg: 0.86 | grad norm last: 0.81 | 
2026-01-01T13:58:38 | step: 154900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.455290036275983e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.22 | consumed tokens: 1268940800.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T13:58:59 | step: 155000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.4545813580043614e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.92 | consumed tokens: 1269760000.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T13:59:21 | step: 155100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.453872315934859e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.06 | consumed tokens: 1270579200.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T13:59:41 | step: 155200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.453162910067476e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.92 | consumed tokens: 1271398400.0 | grad norm avg: 0.86 | grad norm last: 0.95 | 
2026-01-01T14:00:02 | step: 155300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.452453140402213e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.77 | consumed tokens: 1272217600.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T14:00:22 | step: 155400 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.4517430069390684e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.81 | consumed tokens: 1273036800.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T14:00:43 | step: 155500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.451032145880163e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.56 | consumed tokens: 1273856000.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T14:01:03 | step: 155600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.450321284821257e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.03 | consumed tokens: 1274675200.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T14:01:24 | step: 155700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.44960969616659e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.97 | consumed tokens: 1275494400.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T14:01:44 | step: 155800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.448897743714042e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.89 | consumed tokens: 1276313600.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T14:02:05 | step: 155900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.4481854274636135e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.09 | consumed tokens: 1277132800.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T14:02:25 | step: 156000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.447472747415304e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.5 | consumed tokens: 1277952000.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T14:02:45 | step: 156100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.446759703569114e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.08 | consumed tokens: 1278771200.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T14:03:06 | step: 156200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.4460462959250435e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.31 | consumed tokens: 1279590400.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T14:03:26 | step: 156300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.445332524483092e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.81 | consumed tokens: 1280409600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T14:03:47 | step: 156400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.444618025445379e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.3 | consumed tokens: 1281228800.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T14:04:07 | step: 156500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.4439035264076665e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.94 | consumed tokens: 1282048000.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T14:04:28 | step: 156600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.443188299774192e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.8 | consumed tokens: 1282867200.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T14:04:49 | step: 156700 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.442472709342837e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.41 | consumed tokens: 1283686400.0 | grad norm avg: 0.87 | grad norm last: 0.97 | 
2026-01-01T14:05:09 | step: 156800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.441756755113602e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.7 | consumed tokens: 1284505600.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T14:05:29 | step: 156900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.441040437086485e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.16 | consumed tokens: 1285324800.0 | grad norm avg: 0.86 | grad norm last: 0.92 | 
2026-01-01T14:05:50 | step: 157000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.440323755261488e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.17 | train loss last: 3.61 | consumed tokens: 1286144000.0 | grad norm avg: 0.87 | grad norm last: 0.96 | 
2026-01-01T14:06:10 | step: 157100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.4396067096386105e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.88 | consumed tokens: 1286963200.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T14:06:31 | step: 157200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.438889300217852e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.0 | consumed tokens: 1287782400.0 | grad norm avg: 0.86 | grad norm last: 0.96 | 
2026-01-01T14:06:51 | step: 157300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.438171526999213e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.45 | consumed tokens: 1288601600.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T14:07:12 | step: 157400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.437453026184812e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.53 | consumed tokens: 1289420800.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T14:07:32 | step: 157500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.4367345253704116e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 4.06 | consumed tokens: 1290240000.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T14:07:52 | step: 157600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.4360152969602495e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.34 | consumed tokens: 1291059200.0 | grad norm avg: 0.87 | grad norm last: 0.96 | 
2026-01-01T14:08:13 | step: 157700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.435295704752207e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.58 | consumed tokens: 1291878400.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T14:08:33 | step: 157800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.4345757487462834e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.61 | consumed tokens: 1292697600.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T14:08:54 | step: 157900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.433855428942479e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 2.86 | consumed tokens: 1293516800.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T14:09:14 | step: 158000 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.433134745340794e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.58 | consumed tokens: 1294336000.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T14:09:35 | step: 158100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.432413697941229e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.7 | consumed tokens: 1295155200.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T14:09:55 | step: 158200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.4316922867437825e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.91 | consumed tokens: 1295974400.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T14:10:16 | step: 158300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.4309705117484555e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.45 | consumed tokens: 1296793600.0 | grad norm avg: 0.85 | grad norm last: 0.9 | 
2026-01-01T14:10:36 | step: 158400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.430248009157367e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.12 | consumed tokens: 1297612800.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T14:10:57 | step: 158500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.4295255065662786e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.55 | consumed tokens: 1298432000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T14:11:17 | step: 158600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.428802276379429e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.25 | consumed tokens: 1299251200.0 | grad norm avg: 0.88 | grad norm last: 0.78 | 
2026-01-01T14:11:37 | step: 158700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.428078682394698e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.62 | consumed tokens: 1300070400.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T14:11:58 | step: 158800 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.427354724612087e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.44 | consumed tokens: 1300889600.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T14:12:18 | step: 158900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.426630403031595e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.25 | consumed tokens: 1301708800.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T14:12:39 | step: 159000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.4259057176532224e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.92 | consumed tokens: 1302528000.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T14:12:59 | step: 159100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.425180668476969e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.12 | consumed tokens: 1303347200.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T14:13:19 | step: 159200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.424455255502835e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.81 | consumed tokens: 1304166400.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T14:13:40 | step: 159300 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 4.42372947873082e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.11 | consumed tokens: 1304985600.0 | grad norm avg: 0.86 | grad norm last: 0.92 | 
2026-01-01T14:14:01 | step: 159400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.423002974363044e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.52 | consumed tokens: 1305804800.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T14:14:21 | step: 159500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.422276469995268e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.58 | consumed tokens: 1306624000.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T14:14:41 | step: 159600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.42154923803173e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.02 | consumed tokens: 1307443200.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T14:15:02 | step: 159700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.4208220060681924e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.0 | consumed tokens: 1308262400.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T14:15:22 | step: 159800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.4200940465088934e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.7 | consumed tokens: 1309081600.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T14:15:43 | step: 159900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.4193657231517136e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.59 | consumed tokens: 1309900800.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T14:16:03 | step: 160000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.418637035996653e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.56 | consumed tokens: 1310720000.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T14:16:26 | step: 160100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.417907985043712e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.2 | consumed tokens: 1311539200.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T14:16:46 | step: 160200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.41717857029289e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.62 | consumed tokens: 1312358400.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T14:17:06 | step: 160300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.4164487917441875e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.56 | consumed tokens: 1313177600.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T14:17:27 | step: 160400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.4157182855997235e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.59 | consumed tokens: 1313996800.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T14:17:47 | step: 160500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.4149877794552594e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.31 | consumed tokens: 1314816000.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T14:18:08 | step: 160600 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 4.414256545715034e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.5 | consumed tokens: 1315635200.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T14:18:28 | step: 160700 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.4135253119748086e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.59 | consumed tokens: 1316454400.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T14:18:49 | step: 160800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.412793350638822e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.22 | consumed tokens: 1317273600.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T14:19:09 | step: 160900 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.412061025504954e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.12 | consumed tokens: 1318092800.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-01T14:19:29 | step: 161000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.4113287003710866e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.69 | consumed tokens: 1318912000.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T14:19:50 | step: 161100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.4105956476414576e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.55 | consumed tokens: 1319731200.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T14:20:10 | step: 161200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.409862231113948e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 1.7 | consumed tokens: 1320550400.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T14:20:31 | step: 161300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.4091284507885575e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.89 | consumed tokens: 1321369600.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T14:20:51 | step: 161400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.408393942867406e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.91 | consumed tokens: 1322188800.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T14:21:12 | step: 161500 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 4.407659434946254e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.95 | consumed tokens: 1323008000.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T14:21:32 | step: 161600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.4069245632272214e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.78 | consumed tokens: 1323827200.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T14:21:52 | step: 161700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.4061889639124274e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.19 | consumed tokens: 1324646400.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T14:22:13 | step: 161800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.4054533645976335e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.12 | consumed tokens: 1325465600.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T14:22:34 | step: 161900 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 4.404717037687078e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.05 | consumed tokens: 1326284800.0 | grad norm avg: 0.87 | grad norm last: 1.05 | 
2026-01-01T14:22:54 | step: 162000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.403980710776523e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.27 | consumed tokens: 1327104000.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T14:23:14 | step: 162100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.403243656270206e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.97 | consumed tokens: 1327923200.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T14:23:35 | step: 162200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.4025062379660085e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.81 | consumed tokens: 1328742400.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T14:23:55 | step: 162300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.40176845586393e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.38 | consumed tokens: 1329561600.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T14:24:16 | step: 162400 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.4010303099639714e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.84 | consumed tokens: 1330380800.0 | grad norm avg: 0.86 | grad norm last: 0.92 | 
2026-01-01T14:24:36 | step: 162500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.400291800266132e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.39 | consumed tokens: 1331200000.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T14:24:56 | step: 162600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.3995529267704114e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.61 | consumed tokens: 1332019200.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T14:25:17 | step: 162700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.3988136894768104e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.05 | consumed tokens: 1332838400.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T14:25:37 | step: 162800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.398073724587448e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.81 | consumed tokens: 1333657600.0 | grad norm avg: 0.88 | grad norm last: 0.96 | 
2026-01-01T14:25:58 | step: 162900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.3973337596980855e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.14 | consumed tokens: 1334476800.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T14:26:18 | step: 163000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.3965930672129616e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.41 | consumed tokens: 1335296000.0 | grad norm avg: 0.86 | grad norm last: 0.85 | 
2026-01-01T14:26:38 | step: 163100 | train samples/s: 85.3 | train mfu (16-bit): -1.0 | lr mean: 4.395852374727838e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.67 | consumed tokens: 1336115200.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T14:26:59 | step: 163200 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 4.3951109546469525e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.47 | consumed tokens: 1336934400.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T14:27:19 | step: 163300 | train samples/s: 85.4 | train mfu (16-bit): -1.0 | lr mean: 4.3943691707681865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.06 | consumed tokens: 1337753600.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T14:27:40 | step: 163400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.3936273868894204e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.34 | consumed tokens: 1338572800.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T14:28:00 | step: 163500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.392884875414893e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.28 | consumed tokens: 1339392000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T14:28:20 | step: 163600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.392142000142485e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.36 | consumed tokens: 1340211200.0 | grad norm avg: 0.87 | grad norm last: 0.94 | 
2026-01-01T14:28:41 | step: 163700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.391398761072196e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.16 | consumed tokens: 1341030400.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T14:29:01 | step: 163800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.3906551582040265e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.31 | consumed tokens: 1341849600.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T14:29:22 | step: 163900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.3899108277400956e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.61 | consumed tokens: 1342668800.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T14:29:42 | step: 164000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.3891664972761646e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.75 | consumed tokens: 1343488000.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T14:30:02 | step: 164100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.388421803014353e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.64 | consumed tokens: 1344307200.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T14:30:23 | step: 164200 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.3876767449546605e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.81 | consumed tokens: 1345126400.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T14:30:43 | step: 164300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.386930959299207e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.42 | consumed tokens: 1345945600.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T14:31:04 | step: 164400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.386185173643753e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.73 | consumed tokens: 1346764800.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T14:31:24 | step: 164500 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 4.385438660392538e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.83 | consumed tokens: 1347584000.0 | grad norm avg: 0.87 | grad norm last: 0.77 | 
2026-01-01T14:31:45 | step: 164600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.384691783343442e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.84 | consumed tokens: 1348403200.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T14:32:05 | step: 164700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.383944542496465e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.89 | consumed tokens: 1349222400.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T14:32:26 | step: 164800 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.3831973016494885e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.98 | consumed tokens: 1350041600.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T14:32:46 | step: 164900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.3824493332067505e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.86 | consumed tokens: 1350860800.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T14:33:06 | step: 165000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.381701000966132e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.69 | consumed tokens: 1351680000.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T14:33:28 | step: 165100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.380952304927632e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.94 | consumed tokens: 1352499200.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T14:33:49 | step: 165200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.380203245091252e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.41 | consumed tokens: 1353318400.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T14:34:09 | step: 165300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.3794534576591104e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.86 | consumed tokens: 1354137600.0 | grad norm avg: 0.87 | grad norm last: 0.94 | 
2026-01-01T14:34:30 | step: 165400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.378703670226969e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.88 | consumed tokens: 1354956800.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T14:34:50 | step: 165500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.3779535189969465e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.84 | consumed tokens: 1355776000.0 | grad norm avg: 0.86 | grad norm last: 0.94 | 
2026-01-01T14:35:11 | step: 165600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.3772030039690435e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.12 | consumed tokens: 1356595200.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T14:35:31 | step: 165700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.376451761345379e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.69 | consumed tokens: 1357414400.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T14:35:52 | step: 165800 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 4.3757005187217146e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.91 | consumed tokens: 1358233600.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T14:36:12 | step: 165900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.374948548502289e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.41 | consumed tokens: 1359052800.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T14:36:32 | step: 166000 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.374196214484982e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.2 | consumed tokens: 1359872000.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T14:36:53 | step: 166100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.3734438804676756e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.3 | consumed tokens: 1360691200.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T14:37:13 | step: 166200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.3726908188546076e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.38 | consumed tokens: 1361510400.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T14:37:34 | step: 166300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.371937393443659e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.14 | consumed tokens: 1362329600.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T14:37:54 | step: 166400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.3711836042348295e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.91 | consumed tokens: 1363148800.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T14:38:14 | step: 166500 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.3704294512281194e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.56 | consumed tokens: 1363968000.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T14:38:35 | step: 166600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.3696749344235286e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.81 | consumed tokens: 1364787200.0 | grad norm avg: 0.87 | grad norm last: 0.94 | 
2026-01-01T14:38:55 | step: 166700 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.368920053821057e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.69 | consumed tokens: 1365606400.0 | grad norm avg: 0.87 | grad norm last: 0.79 | 
2026-01-01T14:39:15 | step: 166800 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.368164809420705e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.98 | consumed tokens: 1366425600.0 | grad norm avg: 0.87 | grad norm last: 0.97 | 
2026-01-01T14:39:36 | step: 166900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.367409201222472e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.28 | consumed tokens: 1367244800.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T14:39:56 | step: 167000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.3666528654284775e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.44 | consumed tokens: 1368064000.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T14:40:17 | step: 167100 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 4.365896529634483e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.89 | consumed tokens: 1368883200.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T14:40:38 | step: 167200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.365139830042608e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.67 | consumed tokens: 1369702400.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T14:40:58 | step: 167300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.3643824028549716e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.84 | consumed tokens: 1370521600.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T14:41:18 | step: 167400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.363624975667335e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.44 | consumed tokens: 1371340800.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T14:41:39 | step: 167500 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.362866820883937e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.08 | consumed tokens: 1372160000.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T14:41:59 | step: 167600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.362108666100539e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.8 | consumed tokens: 1372979200.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T14:42:19 | step: 167700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.36134978372138e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.7 | consumed tokens: 1373798400.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T14:42:40 | step: 167800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.36059053754434e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.89 | consumed tokens: 1374617600.0 | grad norm avg: 0.87 | grad norm last: 0.94 | 
2026-01-01T14:43:00 | step: 167900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.359830927569419e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.27 | consumed tokens: 1375436800.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T14:43:21 | step: 168000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.359070953796618e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.94 | consumed tokens: 1376256000.0 | grad norm avg: 0.87 | grad norm last: 0.96 | 
2026-01-01T14:43:41 | step: 168100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.358310980023816e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.89 | consumed tokens: 1377075200.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T14:44:01 | step: 168200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.3575502786552534e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.97 | consumed tokens: 1377894400.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T14:44:22 | step: 168300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.35678921348881e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.89 | consumed tokens: 1378713600.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T14:44:43 | step: 168400 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 4.356027420726605e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.81 | consumed tokens: 1379532800.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T14:45:03 | step: 168500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.3552656279644e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.31 | consumed tokens: 1380352000.0 | grad norm avg: 0.86 | grad norm last: 0.94 | 
2026-01-01T14:45:23 | step: 168600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.354503471404314e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.08 | consumed tokens: 1381171200.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T14:45:44 | step: 168700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.3537409510463476e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.3 | consumed tokens: 1381990400.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T14:46:04 | step: 168800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.3529780668905005e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.08 | consumed tokens: 1382809600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T14:46:25 | step: 168900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.352214455138892e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.7 | consumed tokens: 1383628800.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T14:46:45 | step: 169000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.3514508433872834e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.22 | consumed tokens: 1384448000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T14:47:06 | step: 169100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.3506865040399134e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.36 | consumed tokens: 1385267200.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T14:47:26 | step: 169200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.3499221646925434e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.95 | consumed tokens: 1386086400.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T14:47:46 | step: 169300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.349157097749412e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.98 | consumed tokens: 1386905600.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T14:48:07 | step: 169400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.348392030806281e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.7 | consumed tokens: 1387724800.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T14:48:27 | step: 169500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.347626236267388e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.12 | consumed tokens: 1388544000.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T14:48:48 | step: 169600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.3468600779306144e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.8 | consumed tokens: 1389363200.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T14:49:08 | step: 169700 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 4.34609355579596e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.81 | consumed tokens: 1390182400.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T14:49:29 | step: 169800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.345327033661306e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.5 | consumed tokens: 1391001600.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T14:49:49 | step: 169900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.34455978393089e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.12 | consumed tokens: 1391820800.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T14:50:10 | step: 170000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.343792170402594e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.8 | consumed tokens: 1392640000.0 | grad norm avg: 0.87 | grad norm last: 0.78 | 
2026-01-01T14:50:32 | step: 170100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.343024193076417e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.3 | consumed tokens: 1393459200.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T14:50:52 | step: 170200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.342255851952359e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.02 | consumed tokens: 1394278400.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T14:51:13 | step: 170300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.3414871470304206e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.8 | consumed tokens: 1395097600.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T14:51:33 | step: 170400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.3407180783106014e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.64 | consumed tokens: 1395916800.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T14:51:53 | step: 170500 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.3399486457929015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.77 | consumed tokens: 1396736000.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T14:52:14 | step: 170600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.33917848567944e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.64 | consumed tokens: 1397555200.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T14:52:34 | step: 170700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.338408325565979e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.98 | consumed tokens: 1398374400.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T14:52:55 | step: 170800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.337637801654637e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.41 | consumed tokens: 1399193600.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T14:53:15 | step: 170900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.336866913945414e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.69 | consumed tokens: 1400012800.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T14:53:36 | step: 171000 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 4.33609529864043e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.14 | consumed tokens: 1400832000.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T14:53:56 | step: 171100 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.335323683335446e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.2 | consumed tokens: 1401651200.0 | grad norm avg: 0.86 | grad norm last: 0.92 | 
2026-01-01T14:54:17 | step: 171200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.3345513404347e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.09 | consumed tokens: 1402470400.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T14:54:37 | step: 171300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.333778997533955e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.31 | consumed tokens: 1403289600.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T14:54:58 | step: 171400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.333005927037448e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.3 | consumed tokens: 1404108800.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T14:55:18 | step: 171500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.332232856540941e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.06 | consumed tokens: 1404928000.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T14:55:39 | step: 171600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.331459058448672e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.22 | consumed tokens: 1405747200.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T14:55:59 | step: 171700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.330684896558523e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.7 | consumed tokens: 1406566400.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T14:56:19 | step: 171800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.329910734668374e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.34 | consumed tokens: 1407385600.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T14:56:40 | step: 171900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.3291358451824635e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.0 | consumed tokens: 1408204800.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T14:57:00 | step: 172000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.328360591898672e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.91 | consumed tokens: 1409024000.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T14:57:21 | step: 172100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.327584974817e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.88 | consumed tokens: 1409843200.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T14:57:41 | step: 172200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.3268093577353284e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.16 | train loss last: 3.08 | consumed tokens: 1410662400.0 | grad norm avg: 0.87 | grad norm last: 0.79 | 
2026-01-01T14:58:02 | step: 172300 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.326033013057895e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.23 | consumed tokens: 1411481600.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T14:58:22 | step: 172400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.325256304582581e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.12 | consumed tokens: 1412300800.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T14:58:43 | step: 172500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.324479232309386e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.67 | consumed tokens: 1413120000.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T14:59:03 | step: 172600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.3237017962383106e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.03 | consumed tokens: 1413939200.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T14:59:24 | step: 172700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.3229239963693544e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.11 | consumed tokens: 1414758400.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T14:59:44 | step: 172800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.3221458327025175e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.45 | consumed tokens: 1415577600.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T15:00:04 | step: 172900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.321366941439919e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.23 | consumed tokens: 1416396800.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T15:00:25 | step: 173000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.320588050177321e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.67 | consumed tokens: 1417216000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T15:00:45 | step: 173100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.319808795116842e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.33 | consumed tokens: 1418035200.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T15:01:06 | step: 173200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.319029176258482e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.61 | consumed tokens: 1418854400.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T15:01:26 | step: 173300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.3182491936022416e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.92 | consumed tokens: 1419673600.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T15:01:47 | step: 173400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.31746848335024e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.14 | consumed tokens: 1420492800.0 | grad norm avg: 0.86 | grad norm last: 0.79 | 
2026-01-01T15:02:07 | step: 173500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.316687773098238e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.25 | consumed tokens: 1421312000.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T15:02:28 | step: 173600 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 4.315906699048355e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.28 | consumed tokens: 1422131200.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T15:02:48 | step: 173700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.315124897402711e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.2 | consumed tokens: 1422950400.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T15:03:09 | step: 173800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.314343095757067e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.03 | consumed tokens: 1423769600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T15:03:29 | step: 173900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.313560566515662e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.41 | consumed tokens: 1424588800.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T15:03:50 | step: 174000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.3127780372742563e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.5 | consumed tokens: 1425408000.0 | grad norm avg: 0.86 | grad norm last: 0.91 | 
2026-01-01T15:04:10 | step: 174100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.3119947804370895e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.38 | consumed tokens: 1426227200.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T15:04:30 | step: 174200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.3112115235999227e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.52 | consumed tokens: 1427046400.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T15:04:51 | step: 174300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.3104275391669944e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.33 | consumed tokens: 1427865600.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T15:05:11 | step: 174400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.309643554734066e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.8 | consumed tokens: 1428684800.0 | grad norm avg: 0.87 | grad norm last: 0.94 | 
2026-01-01T15:05:32 | step: 174500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.3088588427053764e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.42 | consumed tokens: 1429504000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T15:05:52 | step: 174600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.308073766878806e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.17 | consumed tokens: 1430323200.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T15:06:13 | step: 174700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.307288691052236e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.48 | consumed tokens: 1431142400.0 | grad norm avg: 0.86 | grad norm last: 0.92 | 
2026-01-01T15:06:33 | step: 174800 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.306502887629904e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.98 | consumed tokens: 1431961600.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T15:06:53 | step: 174900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.305716720409691e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.66 | consumed tokens: 1432780800.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T15:07:14 | step: 175000 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 4.304930189391598e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.47 | consumed tokens: 1433600000.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T15:07:36 | step: 175100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.304143658373505e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.16 | consumed tokens: 1434419200.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T15:07:57 | step: 175200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.30335639975965e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.58 | consumed tokens: 1435238400.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T15:08:17 | step: 175300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.302568777347915e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.91 | consumed tokens: 1436057600.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T15:08:38 | step: 175400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.301780791138299e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.08 | consumed tokens: 1436876800.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T15:08:58 | step: 175500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.300992441130802e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.97 | consumed tokens: 1437696000.0 | grad norm avg: 0.88 | grad norm last: 0.96 | 
2026-01-01T15:09:19 | step: 175600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.3002037273254246e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.86 | consumed tokens: 1438515200.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T15:09:39 | step: 175700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.2994146497221664e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.03 | consumed tokens: 1439334400.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T15:09:59 | step: 175800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.2986252083210275e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.44 | consumed tokens: 1440153600.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T15:10:20 | step: 175900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.297835403122008e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.64 | consumed tokens: 1440972800.0 | grad norm avg: 0.88 | grad norm last: 1.4 | 
2026-01-01T15:10:40 | step: 176000 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.2970452341251075e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.5 | consumed tokens: 1441792000.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T15:11:01 | step: 176100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.2962547013303265e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.08 | consumed tokens: 1442611200.0 | grad norm avg: 0.87 | grad norm last: 0.96 | 
2026-01-01T15:11:21 | step: 176200 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.295463804737665e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.64 | consumed tokens: 1443430400.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T15:11:42 | step: 176300 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.294672544347122e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 4.38 | consumed tokens: 1444249600.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T15:12:02 | step: 176400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.293880920158699e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.39 | consumed tokens: 1445068800.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T15:12:23 | step: 176500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.293088932172395e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.81 | consumed tokens: 1445888000.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T15:12:43 | step: 176600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.292296580388211e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.14 | consumed tokens: 1446707200.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T15:13:03 | step: 176700 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.2915038648061454e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.83 | consumed tokens: 1447526400.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T15:13:24 | step: 176800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.2907107854261994e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.53 | consumed tokens: 1448345600.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T15:13:44 | step: 176900 | train samples/s: 85.3 | train mfu (16-bit): -1.0 | lr mean: 4.289916978450492e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.83 | consumed tokens: 1449164800.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T15:14:05 | step: 177000 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.2891231714747846e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.19 | consumed tokens: 1449984000.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T15:14:25 | step: 177100 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.2883290007011965e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.67 | consumed tokens: 1450803200.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T15:14:45 | step: 177200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.287534466129728e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.78 | consumed tokens: 1451622400.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T15:15:06 | step: 177300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.286739567760378e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.86 | consumed tokens: 1452441600.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T15:15:26 | step: 177400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.285943941795267e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.53 | consumed tokens: 1453260800.0 | grad norm avg: 0.86 | grad norm last: 0.75 | 
2026-01-01T15:15:47 | step: 177500 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 4.285148315830156e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.28 | consumed tokens: 1454080000.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T15:16:07 | step: 177600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.2843523260671645e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.42 | consumed tokens: 1454899200.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T15:16:28 | step: 177700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.2835556087084115e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.77 | consumed tokens: 1455718400.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T15:16:48 | step: 177800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.2827588913496584e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.97 | consumed tokens: 1456537600.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T15:17:08 | step: 177900 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.2819618101930246e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.72 | consumed tokens: 1457356800.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T15:17:29 | step: 178000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.2811640014406294e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.25 | consumed tokens: 1458176000.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T15:17:49 | step: 178100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.280366192688234e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.58 | consumed tokens: 1458995200.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T15:18:09 | step: 178200 | train samples/s: 85.2 | train mfu (16-bit): -1.0 | lr mean: 4.279568020137958e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.22 | consumed tokens: 1459814400.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T15:18:30 | step: 178300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.278769119991921e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.97 | consumed tokens: 1460633600.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T15:18:50 | step: 178400 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.2779702198458835e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.11 | consumed tokens: 1461452800.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T15:19:11 | step: 178500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.2771709559019655e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.75 | consumed tokens: 1462272000.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T15:19:31 | step: 178600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.276370964362286e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.16 | consumed tokens: 1463091200.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T15:19:51 | step: 178700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.2755709728226066e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.14 | consumed tokens: 1463910400.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T15:20:12 | step: 178800 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 4.274770253687166e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.03 | consumed tokens: 1464729600.0 | grad norm avg: 0.86 | grad norm last: 0.9 | 
2026-01-01T15:20:33 | step: 178900 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.273969534551725e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.98 | consumed tokens: 1465548800.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T15:20:53 | step: 179000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.2731680878205225e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.02 | consumed tokens: 1466368000.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T15:21:13 | step: 179100 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.27236664108932e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.69 | consumed tokens: 1467187200.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T15:21:34 | step: 179200 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.2715644667623565e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.45 | consumed tokens: 1468006400.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T15:21:54 | step: 179300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.270762292435393e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.25 | consumed tokens: 1468825600.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T15:22:14 | step: 179400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.269959754310548e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.84 | consumed tokens: 1469644800.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T15:22:35 | step: 179500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.2691564885899425e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.09 | consumed tokens: 1470464000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T15:22:55 | step: 179600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.2683532228693366e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.36 | consumed tokens: 1471283200.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T15:23:16 | step: 179700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.267549229552969e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.5 | consumed tokens: 1472102400.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T15:23:36 | step: 179800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.266745236236602e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.98 | consumed tokens: 1472921600.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T15:23:56 | step: 179900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.2659405153244734e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.75 | consumed tokens: 1473740800.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T15:24:17 | step: 180000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.265135794412345e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.48 | consumed tokens: 1474560000.0 | grad norm avg: 0.86 | grad norm last: 0.8 | 
2026-01-01T15:24:39 | step: 180100 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 4.2643303459044546e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.08 | consumed tokens: 1475379200.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T15:25:00 | step: 180200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.2635248973965645e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.77 | consumed tokens: 1476198400.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T15:25:20 | step: 180300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.262718721292913e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.73 | consumed tokens: 1477017600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T15:25:40 | step: 180400 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 4.2619125451892614e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.58 | consumed tokens: 1477836800.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T15:26:01 | step: 180500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.2611056414898485e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.8 | consumed tokens: 1478656000.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T15:26:21 | step: 180600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.2602987377904356e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.55 | consumed tokens: 1479475200.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T15:26:42 | step: 180700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.259491106495261e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.98 | consumed tokens: 1480294400.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T15:27:02 | step: 180800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.258683475200087e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.03 | consumed tokens: 1481113600.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T15:27:22 | step: 180900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.257875116309151e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.03 | consumed tokens: 1481932800.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T15:27:43 | step: 181000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.2570663936203346e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.66 | consumed tokens: 1482752000.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T15:28:03 | step: 181100 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.256257670931518e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.41 | consumed tokens: 1483571200.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T15:28:24 | step: 181200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.25544822064694e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.44 | consumed tokens: 1484390400.0 | grad norm avg: 0.88 | grad norm last: 0.96 | 
2026-01-01T15:28:44 | step: 181300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.254638770362362e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 2.48 | consumed tokens: 1485209600.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T15:29:05 | step: 181400 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 4.253828592482023e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.97 | consumed tokens: 1486028800.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T15:29:25 | step: 181500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.2530184146016836e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.55 | consumed tokens: 1486848000.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T15:29:46 | step: 181600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.252207509125583e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.61 | consumed tokens: 1487667200.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T15:30:06 | step: 181700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.251396603649482e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.08 | consumed tokens: 1488486400.0 | grad norm avg: 0.87 | grad norm last: 0.77 | 
2026-01-01T15:30:27 | step: 181800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.25058497057762e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.92 | consumed tokens: 1489305600.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T15:30:47 | step: 181900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.249773337505758e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.17 | consumed tokens: 1490124800.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T15:31:07 | step: 182000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.248960976838134e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.97 | consumed tokens: 1490944000.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T15:31:28 | step: 182100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.2481486161705106e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.36 | consumed tokens: 1491763200.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T15:31:48 | step: 182200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.2473358917050064e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.78 | consumed tokens: 1492582400.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T15:32:09 | step: 182300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.2465224396437407e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.3 | consumed tokens: 1493401600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T15:32:29 | step: 182400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.245708987582475e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.16 | consumed tokens: 1494220800.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T15:32:49 | step: 182500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.244894807925448e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.61 | consumed tokens: 1495040000.0 | grad norm avg: 0.88 | grad norm last: 0.8 | 
2026-01-01T15:33:10 | step: 182600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.244080628268421e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.56 | consumed tokens: 1495859200.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T15:33:31 | step: 182700 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.243265721015632e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.75 | consumed tokens: 1496678400.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T15:33:51 | step: 182800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.2424508137628436e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.81 | consumed tokens: 1497497600.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T15:34:11 | step: 182900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.2416355427121744e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.34 | consumed tokens: 1498316800.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T15:34:32 | step: 183000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.240819544065744e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.58 | consumed tokens: 1499136000.0 | grad norm avg: 0.86 | grad norm last: 0.87 | 
2026-01-01T15:34:52 | step: 183100 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.240003545419313e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.02 | consumed tokens: 1499955200.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T15:35:13 | step: 183200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.239186819177121e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.8 | consumed tokens: 1500774400.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T15:35:33 | step: 183300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.238370092934929e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.73 | consumed tokens: 1501593600.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T15:35:53 | step: 183400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.237553002894856e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.45 | consumed tokens: 1502412800.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T15:36:14 | step: 183500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.236735185259022e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.52 | consumed tokens: 1503232000.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T15:36:34 | step: 183600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.2359173676231876e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.47 | consumed tokens: 1504051200.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T15:36:55 | step: 183700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.235099186189473e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.7 | consumed tokens: 1504870400.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T15:37:15 | step: 183800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.234280277159996e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.98 | consumed tokens: 1505689600.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T15:37:36 | step: 183900 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 4.23346136813052e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.73 | consumed tokens: 1506508800.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T15:37:56 | step: 184000 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 4.232642095303163e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.02 | consumed tokens: 1507328000.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T15:38:17 | step: 184100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.231822458677925e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.8 | consumed tokens: 1508147200.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T15:38:37 | step: 184200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.231002094456926e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.06 | consumed tokens: 1508966400.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T15:38:58 | step: 184300 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.230181730235927e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.77 | consumed tokens: 1509785600.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T15:39:18 | step: 184400 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.229361002217047e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.28 | consumed tokens: 1510604800.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T15:39:38 | step: 184500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.228539910400286e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.95 | consumed tokens: 1511424000.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T15:39:59 | step: 184600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.227718454785645e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.5 | consumed tokens: 1512243200.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T15:40:19 | step: 184700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.226896271575242e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.77 | consumed tokens: 1513062400.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T15:40:40 | step: 184800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.2260740883648396e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.33 | consumed tokens: 1513881600.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T15:41:00 | step: 184900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.225251541356556e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.3 | consumed tokens: 1514700800.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T15:41:21 | step: 185000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.224428630550392e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.27 | consumed tokens: 1515520000.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T15:41:43 | step: 185100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.223605355946347e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.5 | consumed tokens: 1516339200.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T15:42:03 | step: 185200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.2227817175444216e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.33 | consumed tokens: 1517158400.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T15:42:24 | step: 185300 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.221957715344615e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.3 | consumed tokens: 1517977600.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T15:42:45 | step: 185400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.221133349346928e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.98 | consumed tokens: 1518796800.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T15:43:05 | step: 185500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.2203086195513606e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.31 | consumed tokens: 1519616000.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T15:43:25 | step: 185600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.219483525957912e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.66 | consumed tokens: 1520435200.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T15:43:46 | step: 185700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.218658068566583e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.0 | consumed tokens: 1521254400.0 | grad norm avg: 0.87 | grad norm last: 0.96 | 
2026-01-01T15:44:06 | step: 185800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.217832247377373e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.17 | consumed tokens: 1522073600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T15:44:27 | step: 185900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.217006062390283e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.77 | consumed tokens: 1522892800.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T15:44:47 | step: 186000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.2161795136053115e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.05 | consumed tokens: 1523712000.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T15:45:08 | step: 186100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.2153526010224596e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.73 | consumed tokens: 1524531200.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T15:45:28 | step: 186200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.2145256884396076e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.02 | consumed tokens: 1525350400.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T15:45:48 | step: 186300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.213698048260994e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.88 | consumed tokens: 1526169600.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T15:46:09 | step: 186400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.2128700442845e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.19 | consumed tokens: 1526988800.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-01T15:46:29 | step: 186500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.2120416765101254e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.42 | consumed tokens: 1527808000.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T15:46:50 | step: 186600 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.2112133087357506e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.67 | consumed tokens: 1528627200.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T15:47:11 | step: 186700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.2103842133656144e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.53 | consumed tokens: 1529446400.0 | grad norm avg: 0.87 | grad norm last: 0.81 | 
2026-01-01T15:47:31 | step: 186800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.2095547541975975e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.0 | consumed tokens: 1530265600.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T15:47:51 | step: 186900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.2087252950295806e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.94 | consumed tokens: 1531084800.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T15:48:12 | step: 187000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.207895108265802e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.78 | consumed tokens: 1531904000.0 | grad norm avg: 0.87 | grad norm last: 0.94 | 
2026-01-01T15:48:32 | step: 187100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.207064557704143e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.84 | consumed tokens: 1532723200.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T15:48:53 | step: 187200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.206234007142484e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.62 | consumed tokens: 1533542400.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T15:49:13 | step: 187300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.205402728985064e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 3.22 | consumed tokens: 1534361600.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T15:49:33 | step: 187400 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.204571450827643e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.55 | consumed tokens: 1535180800.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T15:49:54 | step: 187500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.2037394450744614e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.25 | consumed tokens: 1536000000.0 | grad norm avg: 0.87 | grad norm last: 0.76 | 
2026-01-01T15:50:14 | step: 187600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.2029074393212795e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.5 | consumed tokens: 1536819200.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T15:50:35 | step: 187700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.202075069770217e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.34 | consumed tokens: 1537638400.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T15:50:55 | step: 187800 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 4.201241972623393e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.88 | consumed tokens: 1538457600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T15:51:16 | step: 187900 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 4.200408875476569e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.25 | consumed tokens: 1539276800.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T15:51:36 | step: 188000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.199575414531864e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.22 | consumed tokens: 1540096000.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T15:51:56 | step: 188100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.198741225991398e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.02 | consumed tokens: 1540915200.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T15:52:17 | step: 188200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.197907037450932e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.47 | consumed tokens: 1541734400.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T15:52:37 | step: 188300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.197072485112585e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.16 | consumed tokens: 1542553600.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T15:52:58 | step: 188400 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.1962375689763576e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.89 | consumed tokens: 1543372800.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T15:53:18 | step: 188500 | train samples/s: 85.2 | train mfu (16-bit): -1.0 | lr mean: 4.195402289042249e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.19 | consumed tokens: 1544192000.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T15:53:38 | step: 188600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.1945666453102604e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.19 | consumed tokens: 1545011200.0 | grad norm avg: 0.86 | grad norm last: 0.82 | 
2026-01-01T15:53:59 | step: 188700 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.193730637780391e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.33 | consumed tokens: 1545830400.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T15:54:19 | step: 188800 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.19289426645264e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.83 | consumed tokens: 1546649600.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T15:54:39 | step: 188900 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.192057531327009e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.5 | consumed tokens: 1547468800.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T15:55:00 | step: 189000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.1912204324034974e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.67 | consumed tokens: 1548288000.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T15:55:20 | step: 189100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.190382969682105e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.92 | consumed tokens: 1549107200.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T15:55:41 | step: 189200 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 4.189545143162832e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.19 | consumed tokens: 1549926400.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T15:56:01 | step: 189300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.188706952845678e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.83 | consumed tokens: 1550745600.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T15:56:22 | step: 189400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.187868398730643e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.64 | consumed tokens: 1551564800.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T15:56:42 | step: 189500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.1870298446156085e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.89 | consumed tokens: 1552384000.0 | grad norm avg: 0.87 | grad norm last: 0.79 | 
2026-01-01T15:57:03 | step: 189600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.1861905629048124e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.09 | consumed tokens: 1553203200.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T15:57:23 | step: 189700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.1853509173961356e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.58 | consumed tokens: 1554022400.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T15:57:44 | step: 189800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.184511271887459e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.72 | consumed tokens: 1554841600.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T15:58:04 | step: 189900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.183670898783021e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.45 | consumed tokens: 1555660800.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T15:58:24 | step: 190000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.1828305256785825e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.09 | consumed tokens: 1556480000.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T15:58:47 | step: 190100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.181989424978383e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.73 | consumed tokens: 1557299200.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T15:59:07 | step: 190200 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.181148324278183e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.25 | consumed tokens: 1558118400.0 | grad norm avg: 0.87 | grad norm last: 0.97 | 
2026-01-01T15:59:27 | step: 190300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.180306495982222e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.83 | consumed tokens: 1558937600.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T15:59:48 | step: 190400 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.179464667686261e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.58 | consumed tokens: 1559756800.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T16:00:08 | step: 190500 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 4.1786224755924195e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.73 | consumed tokens: 1560576000.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T16:00:29 | step: 190600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.177779919700697e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.17 | consumed tokens: 1561395200.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T16:00:49 | step: 190700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.176936636213213e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.52 | consumed tokens: 1562214400.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T16:01:10 | step: 190800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.1760933527257293e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.23 | consumed tokens: 1563033600.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T16:01:30 | step: 190900 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.175249705440365e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.27 | consumed tokens: 1563852800.0 | grad norm avg: 0.88 | grad norm last: 0.95 | 
2026-01-01T16:01:50 | step: 191000 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.1744056943571195e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.83 | consumed tokens: 1564672000.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T16:02:11 | step: 191100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.1735613194759935e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.44 | consumed tokens: 1565491200.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T16:02:31 | step: 191200 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.172716580796987e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.19 | consumed tokens: 1566310400.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T16:02:52 | step: 191300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.1718714783200994e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.98 | consumed tokens: 1567129600.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T16:03:12 | step: 191400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.171026012045331e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.73 | consumed tokens: 1567948800.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T16:03:32 | step: 191500 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.170180545770563e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.17 | consumed tokens: 1568768000.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T16:03:53 | step: 191600 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 4.1693343519000337e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.95 | consumed tokens: 1569587200.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T16:04:13 | step: 191700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.1684877942316234e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.95 | consumed tokens: 1570406400.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T16:04:34 | step: 191800 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 4.1676408727653325e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.95 | consumed tokens: 1571225600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T16:04:54 | step: 191900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.1667939512990415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.12 | consumed tokens: 1572044800.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T16:05:15 | step: 192000 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.165946302236989e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.03 | consumed tokens: 1572864000.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T16:05:35 | step: 192100 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.165098653174937e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.98 | consumed tokens: 1573683200.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T16:05:55 | step: 192200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.164250276517123e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.23 | consumed tokens: 1574502400.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T16:06:16 | step: 192300 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.163401899859309e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.39 | consumed tokens: 1575321600.0 | grad norm avg: 0.87 | grad norm last: 0.94 | 
2026-01-01T16:06:36 | step: 192400 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 4.162553159403615e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.69 | consumed tokens: 1576140800.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T16:06:57 | step: 192500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.161703691352159e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 4.06 | consumed tokens: 1576960000.0 | grad norm avg: 0.87 | grad norm last: 0.94 | 
2026-01-01T16:07:17 | step: 192600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.160854223300703e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.75 | consumed tokens: 1577779200.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T16:07:37 | step: 192700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.160004391451366e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.67 | consumed tokens: 1578598400.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T16:07:58 | step: 192800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.159154195804149e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.97 | consumed tokens: 1579417600.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T16:08:18 | step: 192900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.158303636359051e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.22 | consumed tokens: 1580236800.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T16:08:39 | step: 193000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.157452713116072e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.75 | consumed tokens: 1581056000.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T16:08:59 | step: 193100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.1566014260752127e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.3 | consumed tokens: 1581875200.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T16:09:20 | step: 193200 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 4.1557497752364725e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.28 | consumed tokens: 1582694400.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T16:09:40 | step: 193300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.1548977605998516e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.5 | consumed tokens: 1583513600.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T16:10:01 | step: 193400 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.15404538216535e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.02 | consumed tokens: 1584332800.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T16:10:21 | step: 193500 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 4.1531930037308484e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.48 | consumed tokens: 1585152000.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T16:10:41 | step: 193600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.1523398977005854e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.94 | consumed tokens: 1585971200.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T16:11:02 | step: 193700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.1514867916703224e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.67 | consumed tokens: 1586790400.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T16:11:22 | step: 193800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.150632958044298e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.38 | consumed tokens: 1587609600.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T16:11:43 | step: 193900 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.1497791244182736e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.88 | consumed tokens: 1588428800.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T16:12:03 | step: 194000 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 4.148924563196488e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.39 | consumed tokens: 1589248000.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T16:12:23 | step: 194100 | train samples/s: 85.2 | train mfu (16-bit): -1.0 | lr mean: 4.148070001974702e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.3 | consumed tokens: 1590067200.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T16:12:44 | step: 194200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.147215076955035e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.23 | consumed tokens: 1590886400.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T16:13:04 | step: 194300 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.1463594243396074e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.97 | consumed tokens: 1591705600.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T16:13:24 | step: 194400 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.1455037717241794e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.45 | consumed tokens: 1592524800.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T16:13:45 | step: 194500 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.144647755310871e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.86 | consumed tokens: 1593344000.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T16:14:05 | step: 194600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.143791375099681e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.34 | consumed tokens: 1594163200.0 | grad norm avg: 0.87 | grad norm last: 0.94 | 
2026-01-01T16:14:26 | step: 194700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.142934631090611e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.91 | consumed tokens: 1594982400.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T16:14:46 | step: 194800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.1420775232836604e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.06 | consumed tokens: 1595801600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T16:15:07 | step: 194900 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.1412204154767096e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.97 | consumed tokens: 1596620800.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T16:15:27 | step: 195000 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.1403625800739974e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.97 | consumed tokens: 1597440000.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T16:15:49 | step: 195100 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.1395043808734044e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.61 | consumed tokens: 1598259200.0 | grad norm avg: 0.87 | grad norm last: 0.77 | 
2026-01-01T16:16:10 | step: 195200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.1386461816728115e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.33 | consumed tokens: 1599078400.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T16:16:30 | step: 195300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.137787254876457e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.83 | consumed tokens: 1599897600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T16:16:50 | step: 195400 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.136928328080103e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.8 | consumed tokens: 1600716800.0 | grad norm avg: 0.87 | grad norm last: 0.79 | 
2026-01-01T16:17:11 | step: 195500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.136068673687987e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.7 | consumed tokens: 1601536000.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T16:17:31 | step: 195600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.135209019295871e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.53 | consumed tokens: 1602355200.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T16:17:52 | step: 195700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.134349001105875e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.11 | consumed tokens: 1603174400.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T16:18:12 | step: 195800 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 4.133488255320117e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.81 | consumed tokens: 1603993600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T16:18:33 | step: 195900 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 4.132627509534359e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.44 | consumed tokens: 1604812800.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T16:18:53 | step: 196000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.1317663999507204e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.05 | consumed tokens: 1605632000.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T16:19:13 | step: 196100 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.130904926569201e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.19 | consumed tokens: 1606451200.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T16:19:34 | step: 196200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.130043089389801e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.88 | consumed tokens: 1607270400.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T16:19:54 | step: 196300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.129181252210401e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.15 | train loss last: 2.67 | consumed tokens: 1608089600.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T16:20:15 | step: 196400 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.1283186874352396e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.78 | consumed tokens: 1608908800.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T16:20:35 | step: 196500 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.1274557588621974e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.09 | consumed tokens: 1609728000.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T16:20:55 | step: 196600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.126592830289155e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.22 | consumed tokens: 1610547200.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T16:21:16 | step: 196700 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.125729174120352e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.77 | consumed tokens: 1611366400.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T16:21:36 | step: 196800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.124865517951548e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.94 | consumed tokens: 1612185600.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T16:21:57 | step: 196900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.124001134186983e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.78 | consumed tokens: 1613004800.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T16:22:17 | step: 197000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.123136750422418e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.23 | consumed tokens: 1613824000.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T16:22:38 | step: 197100 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 4.1222720028599724e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.53 | consumed tokens: 1614643200.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T16:22:58 | step: 197200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.121406891499646e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.33 | consumed tokens: 1615462400.0 | grad norm avg: 0.87 | grad norm last: 0.94 | 
2026-01-01T16:23:18 | step: 197300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.120541416341439e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.08 | consumed tokens: 1616281600.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T16:23:39 | step: 197400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.119675577385351e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.73 | consumed tokens: 1617100800.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T16:23:59 | step: 197500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.1188093746313825e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.52 | consumed tokens: 1617920000.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T16:24:20 | step: 197600 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.117942808079533e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.38 | consumed tokens: 1618739200.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T16:24:40 | step: 197700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.117075877729803e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.0 | consumed tokens: 1619558400.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T16:25:00 | step: 197800 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.1162085835821927e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.5 | consumed tokens: 1620377600.0 | grad norm avg: 0.88 | grad norm last: 0.78 | 
2026-01-01T16:25:21 | step: 197900 | train samples/s: 85.2 | train mfu (16-bit): -1.0 | lr mean: 4.115341289434582e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.38 | consumed tokens: 1621196800.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T16:25:41 | step: 198000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.11447326769121e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.7 | consumed tokens: 1622016000.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T16:26:02 | step: 198100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.113605245947838e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.59 | consumed tokens: 1622835200.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T16:26:22 | step: 198200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.112736860406585e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.47 | consumed tokens: 1623654400.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T16:26:42 | step: 198300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.111867747269571e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.0 | consumed tokens: 1624473600.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T16:27:03 | step: 198400 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.1109986341325566e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.0 | consumed tokens: 1625292800.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T16:27:24 | step: 198500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.110129157197662e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.41 | consumed tokens: 1626112000.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T16:27:44 | step: 198600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.109259316464886e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.97 | consumed tokens: 1626931200.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T16:28:04 | step: 198700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.10838911193423e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.77 | consumed tokens: 1627750400.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T16:28:25 | step: 198800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.1075189074035734e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.31 | consumed tokens: 1628569600.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T16:28:45 | step: 198900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.1066479752771556e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.31 | consumed tokens: 1629388800.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T16:29:06 | step: 199000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.105776679352857e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.22 | consumed tokens: 1630208000.0 | grad norm avg: 0.86 | grad norm last: 0.83 | 
2026-01-01T16:29:26 | step: 199100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.104905383428559e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.55 | consumed tokens: 1631027200.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T16:29:47 | step: 199200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.104033359908499e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.27 | consumed tokens: 1631846400.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T16:30:07 | step: 199300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.103161336388439e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.09 | consumed tokens: 1632665600.0 | grad norm avg: 0.87 | grad norm last: 0.96 | 
2026-01-01T16:30:27 | step: 199400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.1022885852726176e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.34 | consumed tokens: 1633484800.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T16:30:48 | step: 199500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.101415834156796e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.06 | consumed tokens: 1634304000.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T16:31:08 | step: 199600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.100542719243094e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 4.12 | consumed tokens: 1635123200.0 | grad norm avg: 0.86 | grad norm last: 0.81 | 
2026-01-01T16:31:29 | step: 199700 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 4.0996692405315116e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.33 | consumed tokens: 1635942400.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T16:31:49 | step: 199800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.098795398022048e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.02 | consumed tokens: 1636761600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T16:32:10 | step: 199900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.097921191714704e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.72 | consumed tokens: 1637580800.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T16:32:30 | step: 200000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.09704698540736e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.73 | consumed tokens: 1638400000.0 | grad norm avg: 0.87 | grad norm last: 0.97 | 
2026-01-01T16:32:52 | step: 200100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.0961720515042543e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.95 | consumed tokens: 1639219200.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T16:33:13 | step: 200200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.095296753803268e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.28 | consumed tokens: 1640038400.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T16:33:33 | step: 200300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.094421456102282e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.25 | consumed tokens: 1640857600.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T16:33:54 | step: 200400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.093545794603415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.8 | consumed tokens: 1641676800.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T16:34:14 | step: 200500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.0926694055087864e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.0 | consumed tokens: 1642496000.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T16:34:35 | step: 200600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.091793016414158e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.2 | consumed tokens: 1643315200.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T16:34:55 | step: 200700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.090916263521649e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.42 | consumed tokens: 1644134400.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T16:35:16 | step: 200800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.090039146831259e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.95 | consumed tokens: 1644953600.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T16:35:36 | step: 200900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.0891616663429886e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.95 | consumed tokens: 1645772800.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T16:35:57 | step: 201000 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 4.0882838220568374e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 4.09 | consumed tokens: 1646592000.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T16:36:17 | step: 201100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.087405977770686e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.12 | consumed tokens: 1647411200.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T16:36:38 | step: 201200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.0865274058887735e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.42 | consumed tokens: 1648230400.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T16:36:58 | step: 201300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.085648834006861e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.7 | consumed tokens: 1649049600.0 | grad norm avg: 0.88 | grad norm last: 0.99 | 
2026-01-01T16:37:19 | step: 201400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.084769534529187e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.12 | consumed tokens: 1649868800.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T16:37:39 | step: 201500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.083890235051513e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.59 | consumed tokens: 1650688000.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T16:38:00 | step: 201600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.083010571775958e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.77 | consumed tokens: 1651507200.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T16:38:20 | step: 201700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.0821305447025225e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.52 | consumed tokens: 1652326400.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T16:38:40 | step: 201800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.081250153831206e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.14 | consumed tokens: 1653145600.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T16:39:01 | step: 201900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.0803693991620094e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.95 | consumed tokens: 1653964800.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T16:39:21 | step: 202000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.079488280694932e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.47 | consumed tokens: 1654784000.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T16:39:42 | step: 202100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.0786067984299734e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.34 | consumed tokens: 1655603200.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T16:40:02 | step: 202200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.077725316165015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.56 | consumed tokens: 1656422400.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T16:40:23 | step: 202300 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 4.0768431063042954e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.06 | consumed tokens: 1657241600.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T16:40:44 | step: 202400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.0759608964435756e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.66 | consumed tokens: 1658060800.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T16:41:04 | step: 202500 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.0750779589870945e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.28 | consumed tokens: 1658880000.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T16:41:25 | step: 202600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.074195021530613e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.88 | consumed tokens: 1659699200.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T16:41:45 | step: 202700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.0733117202762514e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.75 | consumed tokens: 1660518400.0 | grad norm avg: 0.89 | grad norm last: 0.98 | 
2026-01-01T16:42:05 | step: 202800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.072428055224009e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.94 | consumed tokens: 1661337600.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T16:42:26 | step: 202900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.0715440263738856e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.61 | consumed tokens: 1662156800.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T16:42:46 | step: 203000 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.070659997523762e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.09 | consumed tokens: 1662976000.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T16:43:07 | step: 203100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.0697752410778776e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.81 | consumed tokens: 1663795200.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T16:43:27 | step: 203200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.068890120834112e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.72 | consumed tokens: 1664614400.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T16:43:48 | step: 203300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.068005000590347e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.06 | consumed tokens: 1665433600.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T16:44:08 | step: 203400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.0671195165487006e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.95 | consumed tokens: 1666252800.0 | grad norm avg: 0.88 | grad norm last: 0.99 | 
2026-01-01T16:44:29 | step: 203500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.066233668709174e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.2 | consumed tokens: 1667072000.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T16:44:50 | step: 203600 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 4.0653470932738855e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.58 | consumed tokens: 1667891200.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T16:45:10 | step: 203700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.064460517838597e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.42 | consumed tokens: 1668710400.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T16:45:30 | step: 203800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.063573942403309e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.55 | consumed tokens: 1669529600.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T16:45:51 | step: 203900 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.0626866393722594e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.3 | consumed tokens: 1670348800.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T16:46:11 | step: 204000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.061798972543329e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.98 | consumed tokens: 1671168000.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T16:46:32 | step: 204100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.0609113057143986e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.64 | consumed tokens: 1671987200.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T16:46:52 | step: 204200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.060022911289707e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.64 | consumed tokens: 1672806400.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T16:47:13 | step: 204300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.059134516865015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.59 | consumed tokens: 1673625600.0 | grad norm avg: 0.88 | grad norm last: 0.95 | 
2026-01-01T16:47:33 | step: 204400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.0582457586424425e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.23 | consumed tokens: 1674444800.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T16:47:54 | step: 204500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.057356636621989e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.31 | consumed tokens: 1675264000.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T16:48:14 | step: 204600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.0564671508036554e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.62 | consumed tokens: 1676083200.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T16:48:35 | step: 204700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.055577301187441e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.08 | consumed tokens: 1676902400.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T16:48:55 | step: 204800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.0546870877733454e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.08 | consumed tokens: 1677721600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T16:49:16 | step: 204900 | train samples/s: 82.7 | train mfu (16-bit): -1.0 | lr mean: 4.0537965105613694e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.7 | consumed tokens: 1678540800.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T16:49:36 | step: 205000 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 4.052905933349393e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.0 | consumed tokens: 1679360000.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T16:49:59 | step: 205100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.0520149923395365e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.38 | consumed tokens: 1680179200.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T16:50:19 | step: 205200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 4.0511233237339184e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.08 | consumed tokens: 1680998400.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T16:50:40 | step: 205300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.0502316551283e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.33 | consumed tokens: 1681817600.0 | grad norm avg: 0.89 | grad norm last: 0.82 | 
2026-01-01T16:51:00 | step: 205400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.049339622724801e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.25 | consumed tokens: 1682636800.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T16:51:20 | step: 205500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.048447226523422e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.02 | consumed tokens: 1683456000.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T16:51:41 | step: 205600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.0475544665241614e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.39 | consumed tokens: 1684275200.0 | grad norm avg: 0.87 | grad norm last: 0.99 | 
2026-01-01T16:52:01 | step: 205700 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 4.046661706524901e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.16 | consumed tokens: 1685094400.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T16:52:22 | step: 205800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.0457682189298794e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.8 | consumed tokens: 1685913600.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T16:52:42 | step: 205900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.0448747313348576e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.56 | consumed tokens: 1686732800.0 | grad norm avg: 0.87 | grad norm last: 0.96 | 
2026-01-01T16:53:03 | step: 206000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.0439805161440745e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.2 | consumed tokens: 1687552000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T16:53:23 | step: 206100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.0430863009532914e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.11 | consumed tokens: 1688371200.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T16:53:44 | step: 206200 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 4.0421917219646275e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.8 | consumed tokens: 1689190400.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T16:54:04 | step: 206300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.041296779178083e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.16 | consumed tokens: 1690009600.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T16:54:25 | step: 206400 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.040401472593658e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.44 | consumed tokens: 1690828800.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T16:54:45 | step: 206500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.0395061660092324e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.55 | consumed tokens: 1691648000.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T16:55:06 | step: 206600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.038610131829046e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.22 | consumed tokens: 1692467200.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T16:55:26 | step: 206700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 4.037714097648859e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.19 | consumed tokens: 1693286400.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T16:55:46 | step: 206800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.0368176996707916e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.56 | consumed tokens: 1694105600.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T16:56:07 | step: 206900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.035920574096963e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.95 | consumed tokens: 1694924800.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T16:56:27 | step: 207000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.035023448523134e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.23 | consumed tokens: 1695744000.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T16:56:48 | step: 207100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.0341259591514245e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.41 | consumed tokens: 1696563200.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T16:57:08 | step: 207200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.033228469779715e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.06 | consumed tokens: 1697382400.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T16:57:28 | step: 207300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.032330252812244e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.34 | consumed tokens: 1698201600.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T16:57:49 | step: 207400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.0314316720468923e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.02 | consumed tokens: 1699020800.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T16:58:10 | step: 207500 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 4.030533091281541e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.44 | consumed tokens: 1699840000.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T16:58:30 | step: 207600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.029634146718308e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.59 | consumed tokens: 1700659200.0 | grad norm avg: 0.87 | grad norm last: 1.2 | 
2026-01-01T16:58:50 | step: 207700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.028734838357195e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.8 | consumed tokens: 1701478400.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T16:59:11 | step: 207800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.0278351661982015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.53 | consumed tokens: 1702297600.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T16:59:31 | step: 207900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.026935130241327e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.62 | consumed tokens: 1703116800.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T16:59:52 | step: 208000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.026034730486572e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.89 | consumed tokens: 1703936000.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T17:00:12 | step: 208100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.025133966933936e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.17 | consumed tokens: 1704755200.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T17:00:32 | step: 208200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.0242332033813e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.67 | consumed tokens: 1705574400.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T17:00:53 | step: 208300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.0233317122329026e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.42 | consumed tokens: 1706393600.0 | grad norm avg: 0.88 | grad norm last: 0.79 | 
2026-01-01T17:01:13 | step: 208400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.022430221084505e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.66 | consumed tokens: 1707212800.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T17:01:34 | step: 208500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.021528366138227e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.58 | consumed tokens: 1708032000.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T17:01:54 | step: 208600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 4.0206261473940685e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.62 | consumed tokens: 1708851200.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T17:02:14 | step: 208700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.019723564852029e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.11 | consumed tokens: 1709670400.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T17:02:35 | step: 208800 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 4.0188209823099896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.84 | consumed tokens: 1710489600.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T17:02:56 | step: 208900 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 4.017917672172189e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.61 | consumed tokens: 1711308800.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T17:03:16 | step: 209000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.017014362034388e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.19 | consumed tokens: 1712128000.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T17:03:36 | step: 209100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.0161103243008256e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.44 | consumed tokens: 1712947200.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T17:03:57 | step: 209200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.015206286567263e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.69 | consumed tokens: 1713766400.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T17:04:17 | step: 209300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.01430188503582e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.02 | consumed tokens: 1714585600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T17:04:38 | step: 209400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.013397483504377e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.91 | consumed tokens: 1715404800.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T17:04:58 | step: 209500 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.012492354377173e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.09 | consumed tokens: 1716224000.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T17:05:18 | step: 209600 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 4.011586861452088e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.64 | consumed tokens: 1717043200.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T17:05:39 | step: 209700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.0106813685270026e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.33 | consumed tokens: 1717862400.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T17:05:59 | step: 209800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.009775511804037e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.94 | consumed tokens: 1718681600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T17:06:20 | step: 209900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.0088689274853095e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.95 | consumed tokens: 1719500800.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T17:06:40 | step: 210000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.007962343166582e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.69 | consumed tokens: 1720320000.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T17:07:02 | step: 210100 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 4.007055758847855e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.2 | consumed tokens: 1721139200.0 | grad norm avg: 0.88 | grad norm last: 0.8 | 
2026-01-01T17:07:23 | step: 210200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.0061484469333664e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.89 | consumed tokens: 1721958400.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T17:07:43 | step: 210300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 4.005240771220997e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.73 | consumed tokens: 1722777600.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T17:08:04 | step: 210400 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 4.0043330955086276e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.14 | consumed tokens: 1723596800.0 | grad norm avg: 0.86 | grad norm last: 0.86 | 
2026-01-01T17:08:24 | step: 210500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.0034250559983775e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.31 | consumed tokens: 1724416000.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T17:08:45 | step: 210600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 4.002516652690247e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.16 | consumed tokens: 1725235200.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T17:09:05 | step: 210700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 4.001607885584235e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.02 | consumed tokens: 1726054400.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T17:09:25 | step: 210800 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 4.000698754680343e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.69 | consumed tokens: 1726873600.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T17:09:46 | step: 210900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.99978925997857e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.27 | consumed tokens: 1727692800.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T17:10:06 | step: 211000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.9988794014789164e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.31 | consumed tokens: 1728512000.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T17:10:27 | step: 211100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.997969542979263e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.09 | consumed tokens: 1729331200.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T17:10:47 | step: 211200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.9970593206817284e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.23 | consumed tokens: 1730150400.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T17:11:07 | step: 211300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.9961487345863134e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.95 | consumed tokens: 1730969600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T17:11:28 | step: 211400 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 3.9952377846930176e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.97 | consumed tokens: 1731788800.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T17:11:49 | step: 211500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.994326471001841e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 4.19 | consumed tokens: 1732608000.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T17:12:09 | step: 211600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.993414793512784e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.47 | consumed tokens: 1733427200.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T17:12:29 | step: 211700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.992503116023727e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.7 | consumed tokens: 1734246400.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T17:12:50 | step: 211800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.991591074736789e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.55 | consumed tokens: 1735065600.0 | grad norm avg: 0.87 | grad norm last: 0.98 | 
2026-01-01T17:13:10 | step: 211900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.9906783058540896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.11 | consumed tokens: 1735884800.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T17:13:31 | step: 212000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.98976553697139e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.59 | consumed tokens: 1736704000.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T17:13:51 | step: 212100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.98885240429081e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.75 | consumed tokens: 1737523200.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T17:14:12 | step: 212200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.98793927161023e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.81 | consumed tokens: 1738342400.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T17:14:32 | step: 212300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.987025411333889e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.02 | consumed tokens: 1739161600.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T17:14:52 | step: 212400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.986111551057547e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.06 | consumed tokens: 1739980800.0 | grad norm avg: 0.87 | grad norm last: 0.95 | 
2026-01-01T17:15:13 | step: 212500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.9851969631854445e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.23 | consumed tokens: 1740800000.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T17:15:33 | step: 212600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.9842823753133416e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.23 | consumed tokens: 1741619200.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T17:15:54 | step: 212700 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 3.983367423643358e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.0 | consumed tokens: 1742438400.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T17:16:15 | step: 212800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.9824524719733745e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.14 | consumed tokens: 1743257600.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T17:16:35 | step: 212900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.9815367927076295e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.36 | consumed tokens: 1744076800.0 | grad norm avg: 0.87 | grad norm last: 0.77 | 
2026-01-01T17:16:55 | step: 213000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.9806211134418845e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.8 | consumed tokens: 1744896000.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T17:17:16 | step: 213100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.979704706580378e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.06 | consumed tokens: 1745715200.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T17:17:36 | step: 213200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.978788299718872e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.36 | consumed tokens: 1746534400.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T17:17:57 | step: 213300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.9778715290594846e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.98 | consumed tokens: 1747353600.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T17:18:17 | step: 213400 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.976954394602217e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.34 | consumed tokens: 1748172800.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T17:18:38 | step: 213500 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.976037260144949e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.84 | consumed tokens: 1748992000.0 | grad norm avg: 0.88 | grad norm last: 1.02 | 
2026-01-01T17:18:58 | step: 213600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.97511939809192e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.73 | consumed tokens: 1749811200.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T17:19:18 | step: 213700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.9742015360388905e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.11 | consumed tokens: 1750630400.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T17:19:39 | step: 213800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.9732833101879805e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.73 | consumed tokens: 1751449600.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T17:19:59 | step: 213900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.972364356741309e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.83 | consumed tokens: 1752268800.0 | grad norm avg: 0.87 | grad norm last: 0.94 | 
2026-01-01T17:20:20 | step: 214000 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 3.9714457670925185e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.34 | consumed tokens: 1753088000.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T17:20:40 | step: 214100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.9705264498479664e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.77 | consumed tokens: 1753907200.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T17:21:01 | step: 214200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.9696067688055336e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.06 | consumed tokens: 1754726400.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T17:21:21 | step: 214300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.968687087763101e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.81 | consumed tokens: 1755545600.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T17:21:42 | step: 214400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.9677670429227874e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.95 | consumed tokens: 1756364800.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T17:22:02 | step: 214500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.966846634284593e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.0 | consumed tokens: 1757184000.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T17:22:23 | step: 214600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.965925861848518e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.3 | consumed tokens: 1758003200.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T17:22:43 | step: 214700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.9650047256145626e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.94 | consumed tokens: 1758822400.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T17:23:03 | step: 214800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.964083589380607e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.0 | consumed tokens: 1759641600.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T17:23:24 | step: 214900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.96316172555089e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.17 | consumed tokens: 1760460800.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T17:23:44 | step: 215000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.962239861721173e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.92 | consumed tokens: 1761280000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T17:24:06 | step: 215100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.961317634093575e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.58 | consumed tokens: 1762099200.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T17:24:27 | step: 215200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.960395042668097e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.84 | consumed tokens: 1762918400.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T17:24:47 | step: 215300 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 3.959472451242618e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.02 | consumed tokens: 1763737600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T17:25:08 | step: 215400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.9585491322213784e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.23 | consumed tokens: 1764556800.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T17:25:28 | step: 215500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.9576258132001385e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.03 | consumed tokens: 1765376000.0 | grad norm avg: 0.88 | grad norm last: 0.99 | 
2026-01-01T17:25:49 | step: 215600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.956702130381018e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.31 | consumed tokens: 1766195200.0 | grad norm avg: 0.88 | grad norm last: 0.79 | 
2026-01-01T17:26:09 | step: 215700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.9557780837640166e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.73 | consumed tokens: 1767014400.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T17:26:30 | step: 215800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.9548536733491346e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.61 | consumed tokens: 1767833600.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T17:26:50 | step: 215900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.953928899136372e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.98 | consumed tokens: 1768652800.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T17:27:10 | step: 216000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.953004124923609e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.94 | consumed tokens: 1769472000.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T17:27:31 | step: 216100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.952078623115085e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.64 | consumed tokens: 1770291200.0 | grad norm avg: 0.87 | grad norm last: 0.85 | 
2026-01-01T17:27:51 | step: 216200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.951153121306561e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.5 | consumed tokens: 1771110400.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T17:28:12 | step: 216300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.950227255700156e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 4.12 | consumed tokens: 1771929600.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-01T17:28:32 | step: 216400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.9493010262958705e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.25 | consumed tokens: 1772748800.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T17:28:53 | step: 216500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.948374796891585e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.38 | consumed tokens: 1773568000.0 | grad norm avg: 0.88 | grad norm last: 0.8 | 
2026-01-01T17:29:13 | step: 216600 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 3.947447839891538e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.58 | consumed tokens: 1774387200.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T17:29:34 | step: 216700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.946520882891491e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.3 | consumed tokens: 1775206400.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T17:29:54 | step: 216800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.9455935620935634e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.69 | consumed tokens: 1776025600.0 | grad norm avg: 0.88 | grad norm last: 0.96 | 
2026-01-01T17:30:15 | step: 216900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.944665877497755e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.75 | consumed tokens: 1776844800.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T17:30:35 | step: 217000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.943737829104066e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.95 | consumed tokens: 1777664000.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T17:30:56 | step: 217100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.942809780710377e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.78 | consumed tokens: 1778483200.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T17:31:16 | step: 217200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.941881368518807e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.67 | consumed tokens: 1779302400.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T17:31:36 | step: 217300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.940952228731476e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.89 | consumed tokens: 1780121600.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T17:31:57 | step: 217400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.9400230889441445e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.8 | consumed tokens: 1780940800.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T17:32:17 | step: 217500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.939093949156813e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.16 | consumed tokens: 1781760000.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T17:32:38 | step: 217600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.938164081773721e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.34 | consumed tokens: 1782579200.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T17:32:58 | step: 217700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.937233850592747e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.09 | consumed tokens: 1783398400.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T17:33:19 | step: 217800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.936303619411774e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.06 | consumed tokens: 1784217600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T17:33:39 | step: 217900 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 3.93537302443292e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.56 | consumed tokens: 1785036800.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T17:34:00 | step: 218000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.934442065656185e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.75 | consumed tokens: 1785856000.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T17:34:20 | step: 218100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.9335111068794504e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.61 | consumed tokens: 1786675200.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T17:34:41 | step: 218200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.932579420506954e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.09 | consumed tokens: 1787494400.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T17:35:01 | step: 218300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.931647734134458e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.48 | consumed tokens: 1788313600.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T17:35:22 | step: 218400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.930715683964081e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.09 | consumed tokens: 1789132800.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T17:35:42 | step: 218500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.9297832699958235e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 4.41 | consumed tokens: 1789952000.0 | grad norm avg: 0.88 | grad norm last: 0.8 | 
2026-01-01T17:36:02 | step: 218600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.928850492229685e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.05 | consumed tokens: 1790771200.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T17:36:23 | step: 218700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.927917350665666e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.67 | consumed tokens: 1791590400.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T17:36:43 | step: 218800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.926984209101647e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.92 | consumed tokens: 1792409600.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T17:37:04 | step: 218900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.9260507037397474e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.78 | consumed tokens: 1793228800.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T17:37:24 | step: 219000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.925116834579967e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.34 | consumed tokens: 1794048000.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T17:37:45 | step: 219100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.924182601622306e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.55 | consumed tokens: 1794867200.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T17:38:05 | step: 219200 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 3.923248004866764e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.0 | consumed tokens: 1795686400.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T17:38:26 | step: 219300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.922313408111222e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.36 | consumed tokens: 1796505600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T17:38:46 | step: 219400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.921378083759919e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.0 | consumed tokens: 1797324800.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T17:39:07 | step: 219500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.9204427594086155e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.56 | consumed tokens: 1798144000.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T17:39:27 | step: 219600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.919507435057312e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.77 | consumed tokens: 1798963200.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T17:39:48 | step: 219700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.9185713831102476e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.75 | consumed tokens: 1799782400.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T17:40:08 | step: 219800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.917634967365302e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.2 | consumed tokens: 1800601600.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T17:40:28 | step: 219900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.916698551620357e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.56 | consumed tokens: 1801420800.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T17:40:49 | step: 220000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.9157617720775306e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.78 | consumed tokens: 1802240000.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T17:41:11 | step: 220100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.914824628736824e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.97 | consumed tokens: 1803059200.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T17:41:32 | step: 220200 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.913887121598236e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.02 | consumed tokens: 1803878400.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T17:41:52 | step: 220300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.912949614459649e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.69 | consumed tokens: 1804697600.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T17:42:12 | step: 220400 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.9120117435231805e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.44 | consumed tokens: 1805516800.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T17:42:33 | step: 220500 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 3.9110735087888315e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.38 | consumed tokens: 1806336000.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T17:42:54 | step: 220600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.910134910256602e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.86 | consumed tokens: 1807155200.0 | grad norm avg: 0.88 | grad norm last: 0.96 | 
2026-01-01T17:43:14 | step: 220700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.9091959479264915e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.03 | consumed tokens: 1807974400.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T17:43:35 | step: 220800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.9082566217985004e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.14 | consumed tokens: 1808793600.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T17:43:55 | step: 220900 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.907317295670509e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.5 | consumed tokens: 1809612800.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T17:44:15 | step: 221000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.9063776057446375e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.3 | consumed tokens: 1810432000.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T17:44:36 | step: 221100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.905437552020885e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.55 | consumed tokens: 1811251200.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T17:44:56 | step: 221200 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 3.904497134499252e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.08 | consumed tokens: 1812070400.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T17:45:17 | step: 221300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.9035567169776186e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.06 | consumed tokens: 1812889600.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T17:45:37 | step: 221400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.902615935658105e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.86 | consumed tokens: 1813708800.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T17:45:58 | step: 221500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.9016744267428294e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.92 | consumed tokens: 1814528000.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T17:46:18 | step: 221600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.900733281625435e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.16 | consumed tokens: 1815347200.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T17:46:39 | step: 221700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.899791408912279e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.61 | consumed tokens: 1816166400.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T17:46:59 | step: 221800 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 3.898849172401242e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.61 | consumed tokens: 1816985600.0 | grad norm avg: 0.88 | grad norm last: 0.97 | 
2026-01-01T17:47:20 | step: 221900 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.897906935890205e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.88 | consumed tokens: 1817804800.0 | grad norm avg: 0.87 | grad norm last: 0.98 | 
2026-01-01T17:47:41 | step: 222000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.896964335581288e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.28 | consumed tokens: 1818624000.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T17:48:01 | step: 222100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.8960213714744896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.86 | consumed tokens: 1819443200.0 | grad norm avg: 0.88 | grad norm last: 0.95 | 
2026-01-01T17:48:21 | step: 222200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.8950784073676914e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.97 | consumed tokens: 1820262400.0 | grad norm avg: 0.87 | grad norm last: 0.91 | 
2026-01-01T17:48:42 | step: 222300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.894134715665132e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.2 | consumed tokens: 1821081600.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T17:49:02 | step: 222400 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.893191023962572e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.05 | consumed tokens: 1821900800.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T17:49:23 | step: 222500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.892246968462132e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.81 | consumed tokens: 1822720000.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T17:49:43 | step: 222600 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 3.891302549163811e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.7 | consumed tokens: 1823539200.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T17:50:04 | step: 222700 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 3.890357766067609e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.33 | consumed tokens: 1824358400.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T17:50:24 | step: 222800 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 3.8894129829714075e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.06 | consumed tokens: 1825177600.0 | grad norm avg: 0.88 | grad norm last: 0.96 | 
2026-01-01T17:50:45 | step: 222900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.888467836077325e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.44 | consumed tokens: 1825996800.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T17:51:05 | step: 223000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.887522325385362e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.8 | consumed tokens: 1826816000.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T17:51:26 | step: 223100 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 3.886576450895518e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.73 | consumed tokens: 1827635200.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T17:51:47 | step: 223200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.8856302126077935e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.86 | consumed tokens: 1828454400.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T17:52:07 | step: 223300 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.884683974320069e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.55 | consumed tokens: 1829273600.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T17:52:28 | step: 223400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.883737372234464e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.44 | consumed tokens: 1830092800.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T17:52:48 | step: 223500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.882790406350978e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.39 | consumed tokens: 1830912000.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T17:53:08 | step: 223600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.881843076669611e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.59 | consumed tokens: 1831731200.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T17:53:29 | step: 223700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.8808957469882444e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.09 | consumed tokens: 1832550400.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T17:53:49 | step: 223800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.879948053508997e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.95 | consumed tokens: 1833369600.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T17:54:10 | step: 223900 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.878999632433988e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.95 | consumed tokens: 1834188800.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T17:54:30 | step: 224000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.87805157515686e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.89 | consumed tokens: 1835008000.0 | grad norm avg: 0.87 | grad norm last: 0.82 | 
2026-01-01T17:54:51 | step: 224100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.8771027902839705e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.95 | consumed tokens: 1835827200.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T17:55:11 | step: 224200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.876154005411081e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.06 | consumed tokens: 1836646400.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T17:55:32 | step: 224300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.87520449294243e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.62 | consumed tokens: 1837465600.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T17:55:52 | step: 224400 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 3.874254980473779e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.95 | consumed tokens: 1838284800.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T17:56:13 | step: 224500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.873305468005128e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.98 | consumed tokens: 1839104000.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T17:56:33 | step: 224600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.872355227940716e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.14 | train loss last: 3.11 | consumed tokens: 1839923200.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T17:56:54 | step: 224700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.8714049878763035e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.16 | consumed tokens: 1840742400.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T17:57:14 | step: 224800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.8704543840140104e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 1.94 | consumed tokens: 1841561600.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T17:57:35 | step: 224900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.8695034163538367e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.69 | consumed tokens: 1842380800.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T17:57:55 | step: 225000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.868552084895782e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.25 | consumed tokens: 1843200000.0 | grad norm avg: 0.88 | grad norm last: 0.8 | 
2026-01-01T17:58:17 | step: 225100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.867600753437728e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.28 | consumed tokens: 1844019200.0 | grad norm avg: 0.88 | grad norm last: 0.8 | 
2026-01-01T17:58:38 | step: 225200 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 3.8666490581817925e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.97 | consumed tokens: 1844838400.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T17:58:58 | step: 225300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.8656969991279766e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.0 | consumed tokens: 1845657600.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T17:59:19 | step: 225400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.86474457627628e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.7 | consumed tokens: 1846476800.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T17:59:39 | step: 225500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.863791789626703e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.89 | consumed tokens: 1847296000.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T17:59:59 | step: 225600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.8628390029771253e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.19 | consumed tokens: 1848115200.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T18:00:20 | step: 225700 | train samples/s: 82.9 | train mfu (16-bit): -1.0 | lr mean: 3.861885852529667e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.38 | consumed tokens: 1848934400.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T18:00:41 | step: 225800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.8609323382843286e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.17 | consumed tokens: 1849753600.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T18:01:01 | step: 225900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.85997882403899e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.69 | consumed tokens: 1850572800.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-01T18:01:22 | step: 226000 | train samples/s: 85.2 | train mfu (16-bit): -1.0 | lr mean: 3.85902458219789e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.72 | consumed tokens: 1851392000.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T18:01:42 | step: 226100 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 3.8580703403567895e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.5 | consumed tokens: 1852211200.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T18:02:02 | step: 226200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.857115734717809e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.05 | consumed tokens: 1853030400.0 | grad norm avg: 0.88 | grad norm last: 0.8 | 
2026-01-01T18:02:23 | step: 226300 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 3.856160765280947e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.28 | consumed tokens: 1853849600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T18:02:43 | step: 226400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.8552057958440855e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.2 | consumed tokens: 1854668800.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T18:03:03 | step: 226500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.854250462609343e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.95 | consumed tokens: 1855488000.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T18:03:24 | step: 226600 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.85329476557672e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.31 | consumed tokens: 1856307200.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T18:03:44 | step: 226700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.8523387047462165e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.05 | consumed tokens: 1857126400.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T18:04:05 | step: 226800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.851382280117832e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.22 | consumed tokens: 1857945600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T18:04:25 | step: 226900 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.850425855489448e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.55 | consumed tokens: 1858764800.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T18:04:46 | step: 227000 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 3.8494690670631826e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.69 | consumed tokens: 1859584000.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-01T18:05:06 | step: 227100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.848511914839037e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.27 | consumed tokens: 1860403200.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T18:05:26 | step: 227200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.84755439881701e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.73 | consumed tokens: 1861222400.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T18:05:47 | step: 227300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.846596882794984e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.94 | consumed tokens: 1862041600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T18:06:07 | step: 227400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.8456390029750764e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.14 | consumed tokens: 1862860800.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T18:06:28 | step: 227500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.8446807593572885e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.92 | consumed tokens: 1863680000.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T18:06:48 | step: 227600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.84372215194162e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.06 | consumed tokens: 1864499200.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T18:07:08 | step: 227700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.842763544525951e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.19 | consumed tokens: 1865318400.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T18:07:29 | step: 227800 | train samples/s: 85.3 | train mfu (16-bit): -1.0 | lr mean: 3.841804209514521e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.44 | consumed tokens: 1866137600.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T18:07:49 | step: 227900 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.840845238300972e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.58 | consumed tokens: 1866956800.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T18:08:09 | step: 228000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.839885539491661e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.53 | consumed tokens: 1867776000.0 | grad norm avg: 0.89 | grad norm last: 1.03 | 
2026-01-01T18:08:30 | step: 228100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.8389254768844694e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.22 | consumed tokens: 1868595200.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T18:08:50 | step: 228200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.837965414277278e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.36 | consumed tokens: 1869414400.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T18:09:11 | step: 228300 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 3.837004987872206e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.48 | consumed tokens: 1870233600.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T18:09:31 | step: 228400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.836044197669253e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.06 | consumed tokens: 1871052800.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T18:09:52 | step: 228500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.8350834074663e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.16 | consumed tokens: 1871872000.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T18:10:12 | step: 228600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.8341218896675855e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.36 | consumed tokens: 1872691200.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T18:10:33 | step: 228700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.833160371868871e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.14 | consumed tokens: 1873510400.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T18:10:53 | step: 228800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.832198854070157e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.8 | consumed tokens: 1874329600.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T18:11:14 | step: 228900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.831236608675681e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.0 | consumed tokens: 1875148800.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T18:11:34 | step: 229000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.830274363281205e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.42 | consumed tokens: 1875968000.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T18:11:54 | step: 229100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.829311754088849e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.05 | consumed tokens: 1876787200.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T18:12:15 | step: 229200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.8283487810986117e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.34 | consumed tokens: 1877606400.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T18:12:35 | step: 229300 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 3.827385444310494e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.02 | consumed tokens: 1878425600.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T18:12:55 | step: 229400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.826422107522376e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.3 | consumed tokens: 1879244800.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T18:13:16 | step: 229500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.825458406936377e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.89 | consumed tokens: 1880064000.0 | grad norm avg: 0.88 | grad norm last: 0.96 | 
2026-01-01T18:13:37 | step: 229600 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 3.824494342552498e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.8 | consumed tokens: 1880883200.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T18:13:57 | step: 229700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.823529914370738e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 2.98 | consumed tokens: 1881702400.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T18:14:17 | step: 229800 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.822565486188978e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.45 | consumed tokens: 1882521600.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T18:14:38 | step: 229900 | train samples/s: 85.2 | train mfu (16-bit): -1.0 | lr mean: 3.821600694209337e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.81 | consumed tokens: 1883340800.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T18:14:58 | step: 230000 | train samples/s: 85.2 | train mfu (16-bit): -1.0 | lr mean: 3.820635538431816e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.23 | consumed tokens: 1884160000.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T18:15:20 | step: 230100 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.819670018856414e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.0 | consumed tokens: 1884979200.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T18:15:40 | step: 230200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.8187044992810115e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.19 | consumed tokens: 1885798400.0 | grad norm avg: 0.88 | grad norm last: 0.95 | 
2026-01-01T18:16:01 | step: 230300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.817738615907729e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 4.06 | consumed tokens: 1886617600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T18:16:21 | step: 230400 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.816772368736565e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.78 | consumed tokens: 1887436800.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T18:16:42 | step: 230500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.8158061215654016e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.34 | consumed tokens: 1888256000.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T18:17:02 | step: 230600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.8148391467984766e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.42 | consumed tokens: 1889075200.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T18:17:22 | step: 230700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.8138721720315516e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.19 | consumed tokens: 1889894400.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T18:17:43 | step: 230800 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 3.812904833466746e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.94 | consumed tokens: 1890713600.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T18:18:03 | step: 230900 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 3.81193749490194e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.91 | consumed tokens: 1891532800.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T18:18:24 | step: 231000 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.810969428741373e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.25 | consumed tokens: 1892352000.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T18:18:44 | step: 231100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.810001362580806e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.05 | consumed tokens: 1893171200.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T18:19:05 | step: 231200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.809032932622358e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.77 | consumed tokens: 1893990400.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T18:19:25 | step: 231300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.8080645026639104e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.17 | consumed tokens: 1894809600.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T18:19:45 | step: 231400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.807095708907582e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.86 | consumed tokens: 1895628800.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T18:20:06 | step: 231500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.8061265513533726e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.52 | consumed tokens: 1896448000.0 | grad norm avg: 0.89 | grad norm last: 1.22 | 
2026-01-01T18:20:26 | step: 231600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.805157030001283e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.91 | consumed tokens: 1897267200.0 | grad norm avg: 0.88 | grad norm last: 0.79 | 
2026-01-01T18:20:47 | step: 231700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.804187144851312e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.91 | consumed tokens: 1898086400.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T18:21:07 | step: 231800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.8032172597013414e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.14 | consumed tokens: 1898905600.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T18:21:27 | step: 231900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.80224701075349e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.66 | consumed tokens: 1899724800.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T18:21:48 | step: 232000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.801276398007758e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.5 | consumed tokens: 1900544000.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-01T18:22:08 | step: 232100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.800305785262026e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.69 | consumed tokens: 1901363200.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T18:22:29 | step: 232200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.7993344449205324e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.08 | consumed tokens: 1902182400.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T18:22:49 | step: 232300 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 3.798363104579039e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.33 | consumed tokens: 1903001600.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T18:23:10 | step: 232400 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.7973917642375454e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.67 | consumed tokens: 1903820800.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T18:23:30 | step: 232500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.7964196963002905e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.22 | consumed tokens: 1904640000.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T18:23:51 | step: 232600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.7954476283630356e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.64 | consumed tokens: 1905459200.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T18:24:11 | step: 232700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.7944751966279e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.08 | consumed tokens: 1906278400.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T18:24:31 | step: 232800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.7935027648927644e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.05 | consumed tokens: 1907097600.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T18:24:52 | step: 232900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.7925296055618674e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.11 | consumed tokens: 1907916800.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T18:25:12 | step: 233000 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.79155644623097e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.8 | consumed tokens: 1908736000.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T18:25:33 | step: 233100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.7905829231021926e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.41 | consumed tokens: 1909555200.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T18:25:53 | step: 233200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.789609399973415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.06 | consumed tokens: 1910374400.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T18:26:13 | step: 233300 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.788635149248876e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.44 | consumed tokens: 1911193600.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T18:26:34 | step: 233400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.7876608985243365e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.06 | consumed tokens: 1912012800.0 | grad norm avg: 0.88 | grad norm last: 0.96 | 
2026-01-01T18:26:54 | step: 233500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.7866866477997974e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.12 | consumed tokens: 1912832000.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T18:27:15 | step: 233600 | train samples/s: 82.9 | train mfu (16-bit): -1.0 | lr mean: 3.785711669479497e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.7 | consumed tokens: 1913651200.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T18:27:35 | step: 233700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.784736691159196e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.97 | consumed tokens: 1914470400.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T18:27:56 | step: 233800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.783761349041015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.73 | consumed tokens: 1915289600.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T18:28:16 | step: 233900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.782785643124953e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.0 | consumed tokens: 1916108800.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T18:28:37 | step: 234000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.781809937208891e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.5 | consumed tokens: 1916928000.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T18:28:57 | step: 234100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.780833867494948e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.84 | consumed tokens: 1917747200.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T18:29:17 | step: 234200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.779857433983125e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.75 | consumed tokens: 1918566400.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T18:29:38 | step: 234300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.778880636673421e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.14 | consumed tokens: 1919385600.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T18:29:58 | step: 234400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.7779038393637165e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.2 | consumed tokens: 1920204800.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T18:30:19 | step: 234500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.776926678256132e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.05 | consumed tokens: 1921024000.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T18:30:39 | step: 234600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.775949153350666e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.3 | consumed tokens: 1921843200.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T18:30:59 | step: 234700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.77497126464732e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.58 | consumed tokens: 1922662400.0 | grad norm avg: 0.87 | grad norm last: 0.8 | 
2026-01-01T18:31:20 | step: 234800 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 3.7739933759439737e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.97 | consumed tokens: 1923481600.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T18:31:40 | step: 234900 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 3.773015123442747e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.28 | consumed tokens: 1924300800.0 | grad norm avg: 0.88 | grad norm last: 0.95 | 
2026-01-01T18:32:01 | step: 235000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.772036507143639e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.33 | consumed tokens: 1925120000.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T18:32:23 | step: 235100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.7710578908445314e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.73 | consumed tokens: 1925939200.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T18:32:43 | step: 235200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.770078910747543e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.69 | consumed tokens: 1926758400.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T18:33:04 | step: 235300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.769099566852674e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.19 | consumed tokens: 1927577600.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T18:33:24 | step: 235400 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 3.768119859159924e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.59 | consumed tokens: 1928396800.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T18:33:44 | step: 235500 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 3.767140151467174e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.78 | consumed tokens: 1929216000.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T18:34:05 | step: 235600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.766160079976544e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.84 | consumed tokens: 1930035200.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T18:34:25 | step: 235700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.7651796446880326e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.28 | consumed tokens: 1930854400.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T18:34:46 | step: 235800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.7641992093995214e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.7 | consumed tokens: 1931673600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T18:35:06 | step: 235900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.7632184103131294e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.27 | consumed tokens: 1932492800.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T18:35:27 | step: 236000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.762237247428857e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.56 | consumed tokens: 1933312000.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T18:35:47 | step: 236100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.7612557207467034e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.06 | consumed tokens: 1934131200.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T18:36:08 | step: 236200 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 3.76027419406455e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.95 | consumed tokens: 1934950400.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T18:36:28 | step: 236300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.759292303584516e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.61 | consumed tokens: 1935769600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T18:36:49 | step: 236400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.758310049306601e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.38 | consumed tokens: 1936588800.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T18:37:09 | step: 236500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.7573277950286865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.81 | consumed tokens: 1937408000.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T18:37:30 | step: 236600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.756345176952891e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.11 | consumed tokens: 1938227200.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T18:37:50 | step: 236700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.755362195079215e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.64 | consumed tokens: 1939046400.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T18:38:11 | step: 236800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.754378849407658e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.39 | consumed tokens: 1939865600.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T18:38:31 | step: 236900 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.753395503736101e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.55 | consumed tokens: 1940684800.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T18:38:52 | step: 237000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.7524117942666635e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.05 | consumed tokens: 1941504000.0 | grad norm avg: 0.88 | grad norm last: 0.96 | 
2026-01-01T18:39:12 | step: 237100 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 3.751427720999345e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.27 | consumed tokens: 1942323200.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T18:39:33 | step: 237200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.750443647732027e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.2 | consumed tokens: 1943142400.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T18:39:53 | step: 237300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.749458846868947e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.44 | consumed tokens: 1943961600.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T18:40:13 | step: 237400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.748474409803748e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.78 | consumed tokens: 1944780800.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T18:40:34 | step: 237500 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 3.747489245142788e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.2 | consumed tokens: 1945600000.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T18:40:55 | step: 237600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.746504080481827e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.42 | consumed tokens: 1946419200.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T18:41:15 | step: 237700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.745518552022986e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.84 | consumed tokens: 1947238400.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T18:41:36 | step: 237800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.744532659766264e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.0 | consumed tokens: 1948057600.0 | grad norm avg: 0.88 | grad norm last: 0.8 | 
2026-01-01T18:41:56 | step: 237900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.7435467675095424e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.08 | consumed tokens: 1948876800.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T18:42:16 | step: 238000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.742560147657059e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.0 | consumed tokens: 1949696000.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T18:42:37 | step: 238100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.7415738916024566e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.89 | consumed tokens: 1950515200.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T18:42:57 | step: 238200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.7405869079520926e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.77 | consumed tokens: 1951334400.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T18:43:18 | step: 238300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.7395999243017286e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.97 | consumed tokens: 1952153600.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T18:43:38 | step: 238400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.738612576853484e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.73 | consumed tokens: 1952972800.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T18:43:59 | step: 238500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.7376248656073585e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.97 | consumed tokens: 1953792000.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T18:44:19 | step: 238600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.736637154361233e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.41 | consumed tokens: 1954611200.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T18:44:40 | step: 238700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.735649079317227e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.56 | consumed tokens: 1955430400.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T18:45:00 | step: 238800 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 3.73466064047534e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.03 | consumed tokens: 1956249600.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T18:45:21 | step: 238900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.7336722016334534e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 3.59 | consumed tokens: 1957068800.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T18:45:41 | step: 239000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.732683398993686e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.09 | consumed tokens: 1957888000.0 | grad norm avg: 0.89 | grad norm last: 0.97 | 
2026-01-01T18:46:02 | step: 239100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.7316942325560376e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.94 | consumed tokens: 1958707200.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T18:46:22 | step: 239200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.7307047023205087e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.41 | consumed tokens: 1959526400.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T18:46:43 | step: 239300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.72971517208498e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.77 | consumed tokens: 1960345600.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T18:47:03 | step: 239400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.72872527805157e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.31 | consumed tokens: 1961164800.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T18:47:23 | step: 239500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.72773502022028e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.23 | consumed tokens: 1961984000.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T18:47:44 | step: 239600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.726744762388989e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.28 | consumed tokens: 1962803200.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T18:48:04 | step: 239700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.725754140759818e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.25 | consumed tokens: 1963622400.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T18:48:25 | step: 239800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.7247631553327665e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.14 | consumed tokens: 1964441600.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T18:48:45 | step: 239900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.723772169905715e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.45 | consumed tokens: 1965260800.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T18:49:06 | step: 240000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.722780820680782e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.23 | consumed tokens: 1966080000.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T18:49:28 | step: 240100 | train samples/s: 82.7 | train mfu (16-bit): -1.0 | lr mean: 3.721789107657969e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.25 | consumed tokens: 1966899200.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T18:49:49 | step: 240200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.720797030837275e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.33 | consumed tokens: 1967718400.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T18:50:09 | step: 240300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.719804954016581e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.94 | consumed tokens: 1968537600.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T18:50:30 | step: 240400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.7188125133980066e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.12 | consumed tokens: 1969356800.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T18:50:50 | step: 240500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.717820072779432e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.02 | consumed tokens: 1970176000.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T18:51:11 | step: 240600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.716826904565096e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.45 | consumed tokens: 1970995200.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T18:51:31 | step: 240700 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.71583373635076e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.73 | consumed tokens: 1971814400.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T18:51:52 | step: 240800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.714840568136424e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.8 | consumed tokens: 1972633600.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T18:52:12 | step: 240900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.7138466723263264e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.05 | consumed tokens: 1973452800.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T18:52:33 | step: 241000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.712852776516229e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.11 | consumed tokens: 1974272000.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T18:52:53 | step: 241100 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 3.7118588807061315e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.2 | consumed tokens: 1975091200.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T18:53:14 | step: 241200 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 3.7108642573002726e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.2 | consumed tokens: 1975910400.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T18:53:34 | step: 241300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.709869633894414e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.36 | consumed tokens: 1976729600.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T18:53:55 | step: 241400 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 3.708874646690674e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.42 | consumed tokens: 1977548800.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T18:54:15 | step: 241500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.7078796594869345e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.52 | consumed tokens: 1978368000.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T18:54:36 | step: 241600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.706884308485314e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.33 | consumed tokens: 1979187200.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T18:54:56 | step: 241700 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.705888593685813e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.44 | consumed tokens: 1980006400.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T18:55:17 | step: 241800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.7048925150884315e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.22 | consumed tokens: 1980825600.0 | grad norm avg: 0.89 | grad norm last: 0.82 | 
2026-01-01T18:55:37 | step: 241900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.70389643649105e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.39 | consumed tokens: 1981644800.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T18:55:58 | step: 242000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.7028999940957874e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.83 | consumed tokens: 1982464000.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T18:56:18 | step: 242100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.701903551700525e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.83 | consumed tokens: 1983283200.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T18:56:39 | step: 242200 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.700906381709501e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.34 | consumed tokens: 1984102400.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T18:56:59 | step: 242300 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.699909211718477e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.66 | consumed tokens: 1984921600.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T18:57:20 | step: 242400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.6989120417274535e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.8 | consumed tokens: 1985740800.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T18:57:40 | step: 242500 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 3.697914144140668e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.77 | consumed tokens: 1986560000.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T18:58:01 | step: 242600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.696916246553883e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.95 | consumed tokens: 1987379200.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T18:58:21 | step: 242700 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 3.695918348967098e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.52 | consumed tokens: 1988198400.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T18:58:42 | step: 242800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.694919723784551e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.03 | consumed tokens: 1989017600.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T18:59:02 | step: 242900 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 3.6939210986020043e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.75 | consumed tokens: 1989836800.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T18:59:23 | step: 243000 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 3.692922473419458e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.5 | consumed tokens: 1990656000.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T18:59:43 | step: 243100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.6919231206411496e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.58 | consumed tokens: 1991475200.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T19:00:04 | step: 243200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.6909237678628415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.72 | consumed tokens: 1992294400.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T19:00:24 | step: 243300 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.689924051286653e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.7 | consumed tokens: 1993113600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T19:00:45 | step: 243400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.688924334710464e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.25 | consumed tokens: 1993932800.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T19:01:05 | step: 243500 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.6879242543363944e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.77 | consumed tokens: 1994752000.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T19:01:26 | step: 243600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.686923810164444e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.62 | consumed tokens: 1995571200.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T19:01:46 | step: 243700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.685923365992494e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.86 | consumed tokens: 1996390400.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T19:02:07 | step: 243800 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.684922558022663e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.08 | consumed tokens: 1997209600.0 | grad norm avg: 0.89 | grad norm last: 0.97 | 
2026-01-01T19:02:27 | step: 243900 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.6839213862549514e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.56 | consumed tokens: 1998028800.0 | grad norm avg: 0.89 | grad norm last: 1.0 | 
2026-01-01T19:02:48 | step: 244000 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 3.682919850689359e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.89 | consumed tokens: 1998848000.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T19:03:08 | step: 244100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.6819183151237667e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.66 | consumed tokens: 1999667200.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T19:03:29 | step: 244200 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.6809164157602936e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.31 | consumed tokens: 2000486400.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T19:03:49 | step: 244300 | train samples/s: 83.9 | train mfu (16-bit): -1.0 | lr mean: 3.6799145163968205e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 2.98 | consumed tokens: 2001305600.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T19:04:10 | step: 244400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.678912253235467e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.44 | consumed tokens: 2002124800.0 | grad norm avg: 0.88 | grad norm last: 0.93 | 
2026-01-01T19:04:30 | step: 244500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.677909626276232e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.66 | consumed tokens: 2002944000.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T19:04:51 | step: 244600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.676906635519117e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.2 | consumed tokens: 2003763200.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T19:05:11 | step: 244700 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 3.675903644762002e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.47 | consumed tokens: 2004582400.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T19:05:32 | step: 244800 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.674900290207006e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.39 | consumed tokens: 2005401600.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T19:05:52 | step: 244900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.67389693565201e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.22 | consumed tokens: 2006220800.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T19:06:13 | step: 245000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.6728932172991335e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.3 | consumed tokens: 2007040000.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T19:06:35 | step: 245100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.671889135148376e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.45 | consumed tokens: 2007859200.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T19:06:56 | step: 245200 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 3.670885052997619e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.56 | consumed tokens: 2008678400.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T19:07:16 | step: 245300 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 3.6698802432511e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.03 | consumed tokens: 2009497600.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T19:07:37 | step: 245400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.668875797302462e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.92 | consumed tokens: 2010316800.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T19:07:57 | step: 245500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.667870623758063e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.33 | consumed tokens: 2011136000.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T19:08:18 | step: 245600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.666865450213663e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.03 | consumed tokens: 2011955200.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T19:08:38 | step: 245700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.665859912871383e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.42 | consumed tokens: 2012774400.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T19:08:58 | step: 245800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.664854375529103e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.83 | consumed tokens: 2013593600.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T19:09:19 | step: 245900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.663848474388942e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.17 | consumed tokens: 2014412800.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T19:09:39 | step: 246000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.6628422094509006e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 4.41 | consumed tokens: 2015232000.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T19:10:00 | step: 246100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.661835580714978e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.78 | consumed tokens: 2016051200.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T19:10:20 | step: 246200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.660828951979056e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.45 | consumed tokens: 2016870400.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T19:10:41 | step: 246300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.659821959445253e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.5 | consumed tokens: 2017689600.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T19:11:01 | step: 246400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.65881496691145e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.92 | consumed tokens: 2018508800.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T19:11:22 | step: 246500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.657807610579766e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.05 | consumed tokens: 2019328000.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T19:11:42 | step: 246600 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 3.656799890450202e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.36 | consumed tokens: 2020147200.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T19:12:03 | step: 246700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.6557921703206375e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.22 | consumed tokens: 2020966400.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T19:12:23 | step: 246800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.6547840863931924e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.5 | consumed tokens: 2021785600.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T19:12:44 | step: 246900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.6537756386678666e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.56 | consumed tokens: 2022604800.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T19:13:04 | step: 247000 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.652767190942541e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.48 | consumed tokens: 2023424000.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T19:13:24 | step: 247100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.651758379419334e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.83 | consumed tokens: 2024243200.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T19:13:45 | step: 247200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.650749204098247e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.62 | consumed tokens: 2025062400.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T19:14:05 | step: 247300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.64974002877716e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.41 | consumed tokens: 2025881600.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T19:14:26 | step: 247400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.648730489658192e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.33 | consumed tokens: 2026700800.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T19:14:46 | step: 247500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.647720586741343e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.69 | consumed tokens: 2027520000.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T19:15:07 | step: 247600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.6467106838244945e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.91 | consumed tokens: 2028339200.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T19:15:27 | step: 247700 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.645700417109765e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.95 | consumed tokens: 2029158400.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T19:15:47 | step: 247800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.644689786597155e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.03 | consumed tokens: 2029977600.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-01T19:16:08 | step: 247900 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 3.643679156084545e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.52 | consumed tokens: 2030796800.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T19:16:29 | step: 248000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.642668161774054e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.17 | consumed tokens: 2031616000.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T19:16:49 | step: 248100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.6416571674635634e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.66 | consumed tokens: 2032435200.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T19:17:10 | step: 248200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.640645445557311e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.67 | consumed tokens: 2033254400.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T19:17:30 | step: 248300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.63963408744894e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.97 | consumed tokens: 2034073600.0 | grad norm avg: 0.89 | grad norm last: 0.82 | 
2026-01-01T19:17:50 | step: 248400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.638622001744807e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.34 | consumed tokens: 2034892800.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T19:18:11 | step: 248500 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.637609916040674e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.23 | consumed tokens: 2035712000.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T19:18:31 | step: 248600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.63659746653866e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.13 | train loss last: 3.77 | consumed tokens: 2036531200.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T19:18:52 | step: 248700 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 3.6355850170366466e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.84 | consumed tokens: 2037350400.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T19:19:12 | step: 248800 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.634572203736752e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.17 | consumed tokens: 2038169600.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T19:19:33 | step: 248900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.633559026638977e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.17 | consumed tokens: 2038988800.0 | grad norm avg: 0.89 | grad norm last: 0.8 | 
2026-01-01T19:19:53 | step: 249000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.632545849541202e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.02 | consumed tokens: 2039808000.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T19:20:13 | step: 249100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.6315323086455464e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.72 | consumed tokens: 2040627200.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T19:20:34 | step: 249200 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 3.63051840395201e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.03 | consumed tokens: 2041446400.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T19:20:55 | step: 249300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.6295044992584735e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.73 | consumed tokens: 2042265600.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T19:21:15 | step: 249400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.6284902307670563e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.12 | consumed tokens: 2043084800.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T19:21:35 | step: 249500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.6274755984777585e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.17 | consumed tokens: 2043904000.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T19:21:56 | step: 249600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.6264609661884606e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.2 | consumed tokens: 2044723200.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T19:22:16 | step: 249700 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.625445970101282e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.67 | consumed tokens: 2045542400.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T19:22:37 | step: 249800 | train samples/s: 85.2 | train mfu (16-bit): -1.0 | lr mean: 3.6244309740141034e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.95 | consumed tokens: 2046361600.0 | grad norm avg: 0.88 | grad norm last: 0.99 | 
2026-01-01T19:22:57 | step: 249900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.623415614129044e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.33 | consumed tokens: 2047180800.0 | grad norm avg: 0.88 | grad norm last: 0.92 | 
2026-01-01T19:23:18 | step: 250000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.622399890446104e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.23 | consumed tokens: 2048000000.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T19:23:40 | step: 250100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.6213838029652834e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.98 | consumed tokens: 2048819200.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T19:24:00 | step: 250200 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.620367715484463e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.48 | consumed tokens: 2049638400.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T19:24:21 | step: 250300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.619351628003642e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.47 | consumed tokens: 2050457600.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T19:24:41 | step: 250400 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.61833481292706e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.27 | consumed tokens: 2051276800.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T19:25:02 | step: 250500 | train samples/s: 82.9 | train mfu (16-bit): -1.0 | lr mean: 3.6173183616483584e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.69 | consumed tokens: 2052096000.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T19:25:22 | step: 250600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.6163011827738956e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.31 | consumed tokens: 2052915200.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T19:25:43 | step: 250700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.615284003899433e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.83 | consumed tokens: 2053734400.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T19:26:03 | step: 250800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.614266461227089e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.69 | consumed tokens: 2054553600.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T19:26:24 | step: 250900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.613248554756865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.36 | consumed tokens: 2055372800.0 | grad norm avg: 0.88 | grad norm last: 0.81 | 
2026-01-01T19:26:44 | step: 251000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.6122306482866406e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.55 | consumed tokens: 2056192000.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T19:27:04 | step: 251100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.6112127418164164e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.58 | consumed tokens: 2057011200.0 | grad norm avg: 0.88 | grad norm last: 0.94 | 
2026-01-01T19:27:25 | step: 251200 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 3.610194107750431e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.64 | consumed tokens: 2057830400.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T19:27:45 | step: 251300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.609175473684445e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.44 | consumed tokens: 2058649600.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T19:28:06 | step: 251400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.6081568396184593e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.91 | consumed tokens: 2059468800.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T19:28:26 | step: 251500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.607137477956712e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.09 | consumed tokens: 2060288000.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T19:28:47 | step: 251600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.606118480092846e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.83 | consumed tokens: 2061107200.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T19:29:07 | step: 251700 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.605098754633218e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.39 | consumed tokens: 2061926400.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T19:29:28 | step: 251800 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 3.60407902917359e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.88 | consumed tokens: 2062745600.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T19:29:48 | step: 251900 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.603058939916082e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.39 | consumed tokens: 2063564800.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T19:30:09 | step: 252000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.602038850658573e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.3 | consumed tokens: 2064384000.0 | grad norm avg: 0.89 | grad norm last: 0.82 | 
2026-01-01T19:30:29 | step: 252100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.601018397603184e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.19 | consumed tokens: 2065203200.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T19:30:50 | step: 252200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.599997580749914e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.5 | consumed tokens: 2066022400.0 | grad norm avg: 0.89 | grad norm last: 0.79 | 
2026-01-01T19:31:10 | step: 252300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.598976763896644e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.66 | consumed tokens: 2066841600.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T19:31:30 | step: 252400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.5979555832454935e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.95 | consumed tokens: 2067660800.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T19:31:51 | step: 252500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.596934038796462e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.77 | consumed tokens: 2068480000.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T19:32:11 | step: 252600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.595912494347431e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.05 | consumed tokens: 2069299200.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T19:32:32 | step: 252700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.594890586100519e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.2 | consumed tokens: 2070118400.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T19:32:52 | step: 252800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.5938686778536066e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.33 | consumed tokens: 2070937600.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T19:33:13 | step: 252900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.592846405808814e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.67 | consumed tokens: 2071756800.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T19:33:33 | step: 253000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.5918237699661404e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.09 | consumed tokens: 2072576000.0 | grad norm avg: 0.89 | grad norm last: 0.82 | 
2026-01-01T19:33:54 | step: 253100 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 3.590801134123467e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.38 | consumed tokens: 2073395200.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T19:34:14 | step: 253200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.589778134482913e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.89 | consumed tokens: 2074214400.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T19:34:35 | step: 253300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.5887551348423585e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.88 | consumed tokens: 2075033600.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T19:34:55 | step: 253400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.5877317714039236e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.33 | consumed tokens: 2075852800.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T19:35:15 | step: 253500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.586708044167608e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.52 | consumed tokens: 2076672000.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T19:35:36 | step: 253600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.5856843169312924e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.33 | consumed tokens: 2077491200.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T19:35:56 | step: 253700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.584660225897096e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.28 | consumed tokens: 2078310400.0 | grad norm avg: 0.88 | grad norm last: 0.88 | 
2026-01-01T19:36:17 | step: 253800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.583635771065019e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.25 | consumed tokens: 2079129600.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T19:36:37 | step: 253900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.582611316232942e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.12 | consumed tokens: 2079948800.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T19:36:58 | step: 254000 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 3.581586497602984e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.44 | consumed tokens: 2080768000.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T19:37:18 | step: 254100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.5805616789730266e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.84 | consumed tokens: 2081587200.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T19:37:39 | step: 254200 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.579536496545188e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.58 | consumed tokens: 2082406400.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T19:37:59 | step: 254300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.578510950319469e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.95 | consumed tokens: 2083225600.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T19:38:20 | step: 254400 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 3.57748540409375e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.5 | consumed tokens: 2084044800.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T19:38:40 | step: 254500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.57645949407015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.23 | consumed tokens: 2084864000.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T19:39:01 | step: 254600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.57543358404655e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.59 | consumed tokens: 2085683200.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T19:39:21 | step: 254700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.574406946427189e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.77 | consumed tokens: 2086502400.0 | grad norm avg: 0.89 | grad norm last: 0.8 | 
2026-01-01T19:39:42 | step: 254800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.573380672605708e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.86 | consumed tokens: 2087321600.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T19:40:02 | step: 254900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.572354034986347e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.53 | consumed tokens: 2088140800.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T19:40:23 | step: 255000 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 3.571327033569105e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.72 | consumed tokens: 2088960000.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T19:40:45 | step: 255100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.570299668353982e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.42 | consumed tokens: 2089779200.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T19:41:05 | step: 255200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.5692723031388596e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.11 | consumed tokens: 2090598400.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T19:41:26 | step: 255300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.568244574125856e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.92 | consumed tokens: 2091417600.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T19:41:46 | step: 255400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.567216845112853e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.38 | consumed tokens: 2092236800.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T19:42:07 | step: 255500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.5661887523019686e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.98 | consumed tokens: 2093056000.0 | grad norm avg: 0.89 | grad norm last: 0.97 | 
2026-01-01T19:42:27 | step: 255600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.565160295693204e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.95 | consumed tokens: 2093875200.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T19:42:48 | step: 255700 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 3.564131839084439e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.78 | consumed tokens: 2094694400.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T19:43:08 | step: 255800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.5631030186777934e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.33 | consumed tokens: 2095513600.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T19:43:29 | step: 255900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.562074198271148e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.62 | consumed tokens: 2096332800.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T19:43:49 | step: 256000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.5610450140666217e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.06 | consumed tokens: 2097152000.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T19:44:09 | step: 256100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.5600158298620954e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.44 | consumed tokens: 2097971200.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T19:44:30 | step: 256200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.558985918061808e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.23 | consumed tokens: 2098790400.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-01T19:44:50 | step: 256300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.557956370059401e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.16 | consumed tokens: 2099609600.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T19:45:11 | step: 256400 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.5569260944612324e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.89 | consumed tokens: 2100428800.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T19:45:31 | step: 256500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.555895818863064e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.2 | consumed tokens: 2101248000.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T19:45:52 | step: 256600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.554865543264896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.62 | consumed tokens: 2102067200.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T19:46:12 | step: 256700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.5538349038688466e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.83 | consumed tokens: 2102886400.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T19:46:32 | step: 256800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.552803900674917e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.52 | consumed tokens: 2103705600.0 | grad norm avg: 0.88 | grad norm last: 0.95 | 
2026-01-01T19:46:53 | step: 256900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.551772533683106e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.7 | consumed tokens: 2104524800.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T19:47:14 | step: 257000 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 3.550741166691296e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.66 | consumed tokens: 2105344000.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T19:47:34 | step: 257100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.549709799699485e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.59 | consumed tokens: 2106163200.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T19:47:54 | step: 257200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.548678068909794e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.55 | consumed tokens: 2106982400.0 | grad norm avg: 0.88 | grad norm last: 0.84 | 
2026-01-01T19:48:15 | step: 257300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.547645974322222e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.19 | consumed tokens: 2107801600.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T19:48:35 | step: 257400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.54661387973465e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.33 | consumed tokens: 2108620800.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T19:48:56 | step: 257500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.5455814213491976e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 4.31 | consumed tokens: 2109440000.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T19:49:16 | step: 257600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.544548599165864e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.08 | consumed tokens: 2110259200.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T19:49:37 | step: 257700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.543515776982531e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.41 | consumed tokens: 2111078400.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T19:49:57 | step: 257800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.542482591001317e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.72 | consumed tokens: 2111897600.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T19:50:17 | step: 257900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.541449405020103e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.83 | consumed tokens: 2112716800.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T19:50:38 | step: 258000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.540415855241008e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.77 | consumed tokens: 2113536000.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T19:50:58 | step: 258100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.5393823054619133e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.8 | consumed tokens: 2114355200.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T19:51:19 | step: 258200 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.538348028087057e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.7 | consumed tokens: 2115174400.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T19:51:39 | step: 258300 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 3.537314114510082e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.23 | consumed tokens: 2115993600.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T19:52:00 | step: 258400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.5362798371352255e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.62 | consumed tokens: 2116812800.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T19:52:20 | step: 258500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.5352451959624887e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.67 | consumed tokens: 2117632000.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T19:52:41 | step: 258600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.534210190991871e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.72 | consumed tokens: 2118451200.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T19:53:01 | step: 258700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.5331751860212535e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.89 | consumed tokens: 2119270400.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-01T19:53:21 | step: 258800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.532140181050636e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.11 | consumed tokens: 2120089600.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T19:53:42 | step: 258900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.531104448484257e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.11 | consumed tokens: 2120908800.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T19:54:02 | step: 259000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.5300690797157586e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.47 | consumed tokens: 2121728000.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T19:54:23 | step: 259100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.529032983351499e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.08 | consumed tokens: 2122547200.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T19:54:43 | step: 259200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.527996886987239e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.73 | consumed tokens: 2123366400.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T19:55:04 | step: 259300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.5269607906229794e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.02 | consumed tokens: 2124185600.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T19:55:24 | step: 259400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.525924330460839e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.08 | consumed tokens: 2125004800.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T19:55:44 | step: 259500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.524887506500818e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.52 | consumed tokens: 2125824000.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-01T19:56:05 | step: 259600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.523850682540797e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.19 | consumed tokens: 2126643200.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T19:56:26 | step: 259700 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 3.522813494782895e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.0 | consumed tokens: 2127462400.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T19:56:46 | step: 259800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.521775943227112e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.95 | consumed tokens: 2128281600.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T19:57:06 | step: 259900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.52073839167133e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.02 | consumed tokens: 2129100800.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T19:57:27 | step: 260000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.519700840115547e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.92 | consumed tokens: 2129920000.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T19:57:49 | step: 260100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.518662924761884e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.58 | consumed tokens: 2130739200.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T19:58:09 | step: 260200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.51762464561034e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.27 | consumed tokens: 2131558400.0 | grad norm avg: 0.89 | grad norm last: 0.82 | 
2026-01-01T19:58:30 | step: 260300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.516586002660915e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.33 | consumed tokens: 2132377600.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T19:58:50 | step: 260400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.5155473597114906e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.77 | consumed tokens: 2133196800.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T19:59:11 | step: 260500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.514508716762066e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.67 | consumed tokens: 2134016000.0 | grad norm avg: 0.89 | grad norm last: 0.98 | 
2026-01-01T19:59:31 | step: 260600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.5134697100147605e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.89 | consumed tokens: 2134835200.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T19:59:52 | step: 260700 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.5124303394695744e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.59 | consumed tokens: 2135654400.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T20:00:12 | step: 260800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.511390968924388e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.3 | consumed tokens: 2136473600.0 | grad norm avg: 0.89 | grad norm last: 0.81 | 
2026-01-01T20:00:33 | step: 260900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.5103512345813215e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.62 | consumed tokens: 2137292800.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T20:00:53 | step: 261000 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 3.509311500238255e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.17 | consumed tokens: 2138112000.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T20:01:14 | step: 261100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.508271402097307e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.94 | consumed tokens: 2138931200.0 | grad norm avg: 0.89 | grad norm last: 0.98 | 
2026-01-01T20:01:34 | step: 261200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.507230940158479e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.38 | consumed tokens: 2139750400.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T20:01:55 | step: 261300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.506190478219651e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.45 | consumed tokens: 2140569600.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T20:02:15 | step: 261400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.5051500162808225e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.55 | consumed tokens: 2141388800.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T20:02:36 | step: 261500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.504108826746233e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.91 | consumed tokens: 2142208000.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T20:02:56 | step: 261600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.503068001009524e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.2 | consumed tokens: 2143027200.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T20:03:16 | step: 261700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.5020264476770535e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.36 | consumed tokens: 2143846400.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T20:03:37 | step: 261800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.500984894344583e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.95 | consumed tokens: 2144665600.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T20:03:57 | step: 261900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.499943341012113e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.66 | consumed tokens: 2145484800.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T20:04:18 | step: 262000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.498901423881762e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.03 | consumed tokens: 2146304000.0 | grad norm avg: 0.89 | grad norm last: 0.98 | 
2026-01-01T20:04:38 | step: 262100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.49785914295353e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.42 | consumed tokens: 2147123200.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T20:04:59 | step: 262200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.496816862025298e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.3 | consumed tokens: 2147942400.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T20:05:19 | step: 262300 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 3.495774217299186e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.98 | consumed tokens: 2148761600.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T20:05:40 | step: 262400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.494731572573073e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.75 | consumed tokens: 2149580800.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T20:06:00 | step: 262500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.49368856404908e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.97 | consumed tokens: 2150400000.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T20:06:21 | step: 262600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.492645191727206e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.28 | consumed tokens: 2151219200.0 | grad norm avg: 0.88 | grad norm last: 0.87 | 
2026-01-01T20:06:41 | step: 262700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.491601819405332e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.14 | consumed tokens: 2152038400.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T20:07:02 | step: 262800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.490558447083458e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.7 | consumed tokens: 2152857600.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T20:07:22 | step: 262900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.489514710963704e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.83 | consumed tokens: 2153676800.0 | grad norm avg: 0.89 | grad norm last: 0.8 | 
2026-01-01T20:07:42 | step: 263000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.4884706110460684e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.53 | consumed tokens: 2154496000.0 | grad norm avg: 0.89 | grad norm last: 0.99 | 
2026-01-01T20:08:03 | step: 263100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.487426511128433e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.3 | consumed tokens: 2155315200.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T20:08:23 | step: 263200 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.486382047412917e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.86 | consumed tokens: 2156134400.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T20:08:44 | step: 263300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.48533721989952e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.0 | consumed tokens: 2156953600.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T20:09:04 | step: 263400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.484292756184004e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.91 | consumed tokens: 2157772800.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T20:09:25 | step: 263500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.483247564872727e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.84 | consumed tokens: 2158592000.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-01T20:09:45 | step: 263600 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 3.4822023735614493e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.75 | consumed tokens: 2159411200.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T20:10:06 | step: 263700 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.481156818452291e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.5 | consumed tokens: 2160230400.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T20:10:26 | step: 263800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.480111263343133e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.02 | consumed tokens: 2161049600.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T20:10:47 | step: 263900 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.479065344436094e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.92 | consumed tokens: 2161868800.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T20:11:07 | step: 264000 | train samples/s: 85.2 | train mfu (16-bit): -1.0 | lr mean: 3.478019425529055e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.56 | consumed tokens: 2162688000.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T20:11:28 | step: 264100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.476973142824136e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.78 | consumed tokens: 2163507200.0 | grad norm avg: 0.9 | grad norm last: 0.8 | 
2026-01-01T20:11:48 | step: 264200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.475926860119216e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.64 | consumed tokens: 2164326400.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T20:12:08 | step: 264300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.474880213616416e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.89 | consumed tokens: 2165145600.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T20:12:29 | step: 264400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.473833203315735e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.33 | consumed tokens: 2165964800.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T20:12:49 | step: 264500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.472786193015054e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.88 | consumed tokens: 2166784000.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T20:13:10 | step: 264600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.471739182714373e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.89 | consumed tokens: 2167603200.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T20:13:30 | step: 264700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.4706914448179305e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.16 | consumed tokens: 2168422400.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T20:13:51 | step: 264800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.469644070719369e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.5 | consumed tokens: 2169241600.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T20:14:11 | step: 264900 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 3.4685959690250456e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.75 | consumed tokens: 2170060800.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T20:14:32 | step: 265000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.467548231128603e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.62 | consumed tokens: 2170880000.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T20:14:54 | step: 265100 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.4664997656363994e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.27 | consumed tokens: 2171699200.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T20:15:14 | step: 265200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.4654513001441956e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.64 | consumed tokens: 2172518400.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T20:15:35 | step: 265300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.464402834651992e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.78 | consumed tokens: 2173337600.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T20:15:55 | step: 265400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.463354005361907e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 4.62 | consumed tokens: 2174156800.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T20:16:15 | step: 265500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.462304812273942e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.48 | consumed tokens: 2174976000.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T20:16:36 | step: 265600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.461255619185977e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.31 | consumed tokens: 2175795200.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T20:16:56 | step: 265700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.4602064260980114e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.89 | consumed tokens: 2176614400.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T20:17:17 | step: 265800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.459156505414285e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.0 | consumed tokens: 2177433600.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T20:17:37 | step: 265900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.458106948528439e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.23 | consumed tokens: 2178252800.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T20:17:58 | step: 266000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.4570566640468314e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.14 | consumed tokens: 2179072000.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T20:18:18 | step: 266100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.456006379565224e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.67 | consumed tokens: 2179891200.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T20:18:39 | step: 266200 | train samples/s: 82.9 | train mfu (16-bit): -1.0 | lr mean: 3.454956095083617e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.97 | consumed tokens: 2180710400.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T20:18:59 | step: 266300 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.4539054468041286e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.91 | consumed tokens: 2181529600.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T20:19:20 | step: 266400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.4528547985246405e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.16 | consumed tokens: 2182348800.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T20:19:40 | step: 266500 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.451803786447272e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.42 | consumed tokens: 2183168000.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T20:20:00 | step: 266600 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.450752410572022e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.86 | consumed tokens: 2183987200.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T20:20:21 | step: 266700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.449701034696773e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.91 | consumed tokens: 2184806400.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T20:20:41 | step: 266800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.4486492950236425e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.94 | consumed tokens: 2185625600.0 | grad norm avg: 0.9 | grad norm last: 0.81 | 
2026-01-01T20:21:02 | step: 266900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.447597555350512e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.52 | consumed tokens: 2186444800.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T20:21:22 | step: 267000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.446545815677382e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.67 | consumed tokens: 2187264000.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T20:21:43 | step: 267100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.4454933484084904e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.08 | consumed tokens: 2188083200.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T20:22:03 | step: 267200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.4444412449374795e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.55 | consumed tokens: 2188902400.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T20:22:23 | step: 267300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.443388413870707e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.42 | consumed tokens: 2189721600.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T20:22:44 | step: 267400 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.442335582803935e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.14 | consumed tokens: 2190540800.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T20:23:04 | step: 267500 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 3.4412827517371625e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.44 | consumed tokens: 2191360000.0 | grad norm avg: 0.9 | grad norm last: 0.97 | 
2026-01-01T20:23:25 | step: 267600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.4402295568725094e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.59 | consumed tokens: 2192179200.0 | grad norm avg: 0.89 | grad norm last: 0.8 | 
2026-01-01T20:23:45 | step: 267700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.4391763620078564e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.98 | consumed tokens: 2192998400.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T20:24:06 | step: 267800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.4381228033453226e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.3 | consumed tokens: 2193817600.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T20:24:26 | step: 267900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.437068880884908e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.22 | consumed tokens: 2194636800.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T20:24:47 | step: 268000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.436014958424494e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.66 | consumed tokens: 2195456000.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T20:25:07 | step: 268100 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 3.434961035964079e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.97 | consumed tokens: 2196275200.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T20:25:27 | step: 268200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.433906385907903e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.42 | consumed tokens: 2197094400.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T20:25:48 | step: 268300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.432852099649608e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.94 | consumed tokens: 2197913600.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T20:26:08 | step: 268400 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.431797449593432e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.08 | consumed tokens: 2198732800.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T20:26:28 | step: 268500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.4307424357393757e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.86 | consumed tokens: 2199552000.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T20:26:49 | step: 268600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.429687421885319e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.3 | consumed tokens: 2200371200.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T20:27:09 | step: 268700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.428632044233382e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.3 | consumed tokens: 2201190400.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T20:27:30 | step: 268800 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 3.4275766665814444e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.92 | consumed tokens: 2202009600.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T20:27:51 | step: 268900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.4265209251316264e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.03 | consumed tokens: 2202828800.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T20:28:11 | step: 269000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.4254651836818084e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.86 | consumed tokens: 2203648000.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T20:28:31 | step: 269100 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.42440907843411e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 1.87 | consumed tokens: 2204467200.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T20:28:52 | step: 269200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.42335260938853e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.83 | consumed tokens: 2205286400.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T20:29:12 | step: 269300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.4222965041408315e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.81 | consumed tokens: 2206105600.0 | grad norm avg: 0.89 | grad norm last: 0.98 | 
2026-01-01T20:29:33 | step: 269400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.4212396712973714e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.73 | consumed tokens: 2206924800.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T20:29:53 | step: 269500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.420182838453911e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.08 | consumed tokens: 2207744000.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T20:30:13 | step: 269600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.419126005610451e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.81 | consumed tokens: 2208563200.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T20:30:34 | step: 269700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.41806880896911e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.75 | consumed tokens: 2209382400.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T20:30:54 | step: 269800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.417011248529889e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.33 | consumed tokens: 2210201600.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T20:31:15 | step: 269900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.415953688090667e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.61 | consumed tokens: 2211020800.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T20:31:35 | step: 270000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.4148961276514456e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.3 | consumed tokens: 2211840000.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T20:31:58 | step: 270100 | train samples/s: 82.8 | train mfu (16-bit): -1.0 | lr mean: 3.413838203414343e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.89 | consumed tokens: 2212659200.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T20:32:18 | step: 270200 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 3.41277991537936e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.44 | consumed tokens: 2213478400.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T20:32:39 | step: 270300 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.4117216273443773e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.05 | consumed tokens: 2214297600.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T20:32:59 | step: 270400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.4106629755115137e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.94 | consumed tokens: 2215116800.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T20:33:20 | step: 270500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.40960432367865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.48 | consumed tokens: 2215936000.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T20:33:40 | step: 270600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.4085453080479056e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.22 | consumed tokens: 2216755200.0 | grad norm avg: 0.89 | grad norm last: 0.82 | 
2026-01-01T20:34:01 | step: 270700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.407486292417161e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.78 | consumed tokens: 2217574400.0 | grad norm avg: 0.89 | grad norm last: 0.99 | 
2026-01-01T20:34:21 | step: 270800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.406427276786417e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.38 | consumed tokens: 2218393600.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T20:34:42 | step: 270900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.405367533559911e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.55 | consumed tokens: 2219212800.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T20:35:02 | step: 271000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.404308154131286e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.55 | consumed tokens: 2220032000.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T20:35:23 | step: 271100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.403248047106899e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.03 | consumed tokens: 2220851200.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T20:35:43 | step: 271200 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.4021883038803935e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.8 | consumed tokens: 2221670400.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T20:36:04 | step: 271300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.401127833058126e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.98 | consumed tokens: 2222489600.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T20:36:24 | step: 271400 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 3.40006772603374e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.89 | consumed tokens: 2223308800.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T20:36:45 | step: 271500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.399006891413592e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.53 | consumed tokens: 2224128000.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T20:37:05 | step: 271600 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 3.3979464205913246e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.42 | consumed tokens: 2224947200.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T20:37:26 | step: 271700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.396885222173296e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.09 | consumed tokens: 2225766400.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T20:37:46 | step: 271800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.395824023755267e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.19 | consumed tokens: 2226585600.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T20:38:07 | step: 271900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.3947628253372386e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.62 | consumed tokens: 2227404800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T20:38:27 | step: 272000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.393701263121329e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.69 | consumed tokens: 2228224000.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T20:38:48 | step: 272100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.39263970090542e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.66 | consumed tokens: 2229043200.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T20:39:08 | step: 272200 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 3.39157777489163e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.7 | consumed tokens: 2229862400.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T20:39:29 | step: 272300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.39051584887784e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.47 | consumed tokens: 2230681600.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T20:39:49 | step: 272400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.389453559066169e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.78 | consumed tokens: 2231500800.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T20:40:10 | step: 272500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.388391269254498e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.97 | consumed tokens: 2232320000.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T20:40:30 | step: 272600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.387328615644947e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.48 | consumed tokens: 2233139200.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T20:40:51 | step: 272700 | train samples/s: 82.9 | train mfu (16-bit): -1.0 | lr mean: 3.3862655982375145e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.19 | consumed tokens: 2233958400.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T20:41:11 | step: 272800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.385202580830082e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.59 | consumed tokens: 2234777600.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T20:41:32 | step: 272900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.38413956342265e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.59 | consumed tokens: 2235596800.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T20:41:52 | step: 273000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.383076182217337e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.12 | train loss last: 2.47 | consumed tokens: 2236416000.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T20:42:13 | step: 273100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.382012801012024e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.78 | consumed tokens: 2237235200.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T20:42:33 | step: 273200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.380949056008831e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.36 | consumed tokens: 2238054400.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T20:42:53 | step: 273300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.379885311005637e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.02 | consumed tokens: 2238873600.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T20:43:14 | step: 273400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.378821202204563e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.27 | consumed tokens: 2239692800.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T20:43:34 | step: 273500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.377756729605608e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.81 | consumed tokens: 2240512000.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T20:43:55 | step: 273600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.3766926208045334e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.02 | consumed tokens: 2241331200.0 | grad norm avg: 0.9 | grad norm last: 0.79 | 
2026-01-01T20:44:15 | step: 273700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.3756277844076976e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.5 | consumed tokens: 2242150400.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T20:44:36 | step: 273800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.374562948010862e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.02 | consumed tokens: 2242969600.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T20:44:56 | step: 273900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.373498111614026e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.95 | consumed tokens: 2243788800.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T20:45:17 | step: 274000 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 3.37243291141931e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.69 | consumed tokens: 2244608000.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T20:45:37 | step: 274100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 3.371367711224593e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.36 | consumed tokens: 2245427200.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T20:45:58 | step: 274200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.370302147231996e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.69 | consumed tokens: 2246246400.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T20:46:18 | step: 274300 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.369236583239399e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.11 | consumed tokens: 2247065600.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T20:46:39 | step: 274400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.368170655448921e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.38 | consumed tokens: 2247884800.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T20:46:59 | step: 274500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.3671043638605624e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.25 | consumed tokens: 2248704000.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T20:47:20 | step: 274600 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 3.3660384360700846e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.53 | consumed tokens: 2249523200.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T20:47:40 | step: 274700 | train samples/s: 84.0 | train mfu (16-bit): -1.0 | lr mean: 3.364971780683845e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.44 | consumed tokens: 2250342400.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T20:48:01 | step: 274800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.363905489095487e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.73 | consumed tokens: 2251161600.0 | grad norm avg: 0.89 | grad norm last: 1.05 | 
2026-01-01T20:48:21 | step: 274900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.362838469911367e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.5 | consumed tokens: 2251980800.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T20:48:42 | step: 275000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.361771450727247e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.92 | consumed tokens: 2252800000.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T20:49:04 | step: 275100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.360704431543127e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.08 | consumed tokens: 2253619200.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T20:49:24 | step: 275200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.359637048561126e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.31 | consumed tokens: 2254438400.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T20:49:45 | step: 275300 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 3.358569665579125e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.61 | consumed tokens: 2255257600.0 | grad norm avg: 0.89 | grad norm last: 0.91 | 
2026-01-01T20:50:06 | step: 275400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.357501918799244e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.16 | consumed tokens: 2256076800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T20:50:26 | step: 275500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.3564341720193624e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.81 | consumed tokens: 2256896000.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T20:50:46 | step: 275600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.355366425239481e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.0 | consumed tokens: 2257715200.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T20:51:07 | step: 275700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.354297950863838e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.11 | consumed tokens: 2258534400.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T20:51:27 | step: 275800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.353229840286076e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.36 | consumed tokens: 2259353600.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T20:51:48 | step: 275900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.352161365910433e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.06 | consumed tokens: 2260172800.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T20:52:08 | step: 276000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.35109252773691e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.81 | consumed tokens: 2260992000.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T20:52:29 | step: 276100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.350023689563386e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.0 | consumed tokens: 2261811200.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T20:52:49 | step: 276200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.348954487591982e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.34 | consumed tokens: 2262630400.0 | grad norm avg: 0.89 | grad norm last: 0.83 | 
2026-01-01T20:53:10 | step: 276300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.3478852856205776e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.34 | consumed tokens: 2263449600.0 | grad norm avg: 0.9 | grad norm last: 0.8 | 
2026-01-01T20:53:30 | step: 276400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.3468160836491734e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.23 | consumed tokens: 2264268800.0 | grad norm avg: 0.91 | grad norm last: 0.84 | 
2026-01-01T20:53:50 | step: 276500 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.345746154082008e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.02 | consumed tokens: 2265088000.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T20:54:11 | step: 276600 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 3.344676588312723e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.81 | consumed tokens: 2265907200.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T20:54:32 | step: 276700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.343606658745557e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.66 | consumed tokens: 2266726400.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T20:54:52 | step: 276800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.342536365380511e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 2.92 | consumed tokens: 2267545600.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T20:55:12 | step: 276900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.341466072015464e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.45 | consumed tokens: 2268364800.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T20:55:33 | step: 277000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.340395778650418e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.53 | consumed tokens: 2269184000.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T20:55:53 | step: 277100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.339325121487491e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.31 | consumed tokens: 2270003200.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T20:56:14 | step: 277200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.338254464324564e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.94 | consumed tokens: 2270822400.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T20:56:34 | step: 277300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.337183443363756e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.86 | consumed tokens: 2271641600.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T20:56:55 | step: 277400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.336112422402948e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.27 | consumed tokens: 2272460800.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T20:57:15 | step: 277500 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.3350410376442596e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.64 | consumed tokens: 2273280000.0 | grad norm avg: 0.89 | grad norm last: 0.95 | 
2026-01-01T20:57:35 | step: 277600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.3339692890876904e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.48 | consumed tokens: 2274099200.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T20:57:56 | step: 277700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.332897904329002e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.16 | consumed tokens: 2274918400.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T20:58:16 | step: 277800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.331825791974552e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.55 | consumed tokens: 2275737600.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T20:58:37 | step: 277900 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 3.330754043417983e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.5 | consumed tokens: 2276556800.0 | grad norm avg: 0.89 | grad norm last: 0.99 | 
2026-01-01T20:58:57 | step: 278000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.329681931063533e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.61 | consumed tokens: 2277376000.0 | grad norm avg: 0.89 | grad norm last: 0.96 | 
2026-01-01T20:59:18 | step: 278100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.328609454911202e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.36 | consumed tokens: 2278195200.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T20:59:38 | step: 278200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.3275369787588716e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.98 | consumed tokens: 2279014400.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T20:59:59 | step: 278300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.32646413880866e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.17 | consumed tokens: 2279833600.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T21:00:19 | step: 278400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.325391298858449e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.78 | consumed tokens: 2280652800.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T21:00:39 | step: 278500 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 3.3243184589082375e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.66 | consumed tokens: 2281472000.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T21:01:00 | step: 278600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.3232452551601455e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.56 | consumed tokens: 2282291200.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T21:01:20 | step: 278700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.322171687614173e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.05 | consumed tokens: 2283110400.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T21:01:41 | step: 278800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.3210981200682e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.02 | consumed tokens: 2283929600.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T21:02:01 | step: 278900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.320024552522227e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.34 | consumed tokens: 2284748800.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T21:02:21 | step: 279000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.318950621178374e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.75 | consumed tokens: 2285568000.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T21:02:42 | step: 279100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.31787668983452e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.22 | consumed tokens: 2286387200.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T21:03:03 | step: 279200 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 3.316802394692786e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.56 | consumed tokens: 2287206400.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T21:03:23 | step: 279300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.315728099551052e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.03 | consumed tokens: 2288025600.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T21:03:43 | step: 279400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.314653440611437e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.45 | consumed tokens: 2288844800.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T21:04:04 | step: 279500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.313578781671822e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.53 | consumed tokens: 2289664000.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T21:04:24 | step: 279600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.3125037589343265e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.89 | consumed tokens: 2290483200.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T21:04:45 | step: 279700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.311428736196831e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.7 | consumed tokens: 2291302400.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T21:05:05 | step: 279800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.3103533496614546e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.78 | consumed tokens: 2292121600.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T21:05:25 | step: 279900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.309277963126078e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.81 | consumed tokens: 2292940800.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T21:05:46 | step: 280000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.308202576590702e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.91 | consumed tokens: 2293760000.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T21:06:08 | step: 280100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.307126826257445e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.38 | consumed tokens: 2294579200.0 | grad norm avg: 0.9 | grad norm last: 0.97 | 
2026-01-01T21:06:28 | step: 280200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.306050712126307e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.47 | consumed tokens: 2295398400.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T21:06:49 | step: 280300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.30497496179305e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.38 | consumed tokens: 2296217600.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T21:07:09 | step: 280400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.303898483864032e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.75 | consumed tokens: 2297036800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T21:07:30 | step: 280500 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 3.302822369732894e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.56 | consumed tokens: 2297856000.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T21:07:50 | step: 280600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.301745528005995e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.66 | consumed tokens: 2298675200.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T21:08:11 | step: 280700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.3006690500769764e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.23 | consumed tokens: 2299494400.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T21:08:31 | step: 280800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.299592208350077e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.09 | consumed tokens: 2300313600.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T21:08:51 | step: 280900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.2985150028252974e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.58 | consumed tokens: 2301132800.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T21:09:12 | step: 281000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.2974377973005176e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.78 | consumed tokens: 2301952000.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T21:09:32 | step: 281100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.296360227977857e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.0 | consumed tokens: 2302771200.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T21:09:53 | step: 281200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.2952826586551964e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.31 | consumed tokens: 2303590400.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T21:10:13 | step: 281300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.294205089332536e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.98 | consumed tokens: 2304409600.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T21:10:34 | step: 281400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.2931271562119946e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.42 | consumed tokens: 2305228800.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T21:10:54 | step: 281500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.292049223091453e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.14 | consumed tokens: 2306048000.0 | grad norm avg: 0.9 | grad norm last: 0.99 | 
2026-01-01T21:11:14 | step: 281600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.290970926173031e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.91 | consumed tokens: 2306867200.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T21:11:35 | step: 281700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.2898926292546093e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.92 | consumed tokens: 2307686400.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T21:11:55 | step: 281800 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 3.2888139685383067e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.53 | consumed tokens: 2308505600.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T21:12:16 | step: 281900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.287735307822004e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.75 | consumed tokens: 2309324800.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T21:12:36 | step: 282000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.286656647105701e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.92 | consumed tokens: 2310144000.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T21:12:57 | step: 282100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.285577622591518e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.84 | consumed tokens: 2310963200.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T21:13:17 | step: 282200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.284498234279454e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.09 | consumed tokens: 2311782400.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T21:13:38 | step: 282300 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.2834188459673896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.41 | consumed tokens: 2312601600.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T21:13:58 | step: 282400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.2823394576553255e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.95 | consumed tokens: 2313420800.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T21:14:18 | step: 282500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.281259705545381e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.73 | consumed tokens: 2314240000.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T21:14:39 | step: 282600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.280179953435436e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.98 | consumed tokens: 2315059200.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T21:14:59 | step: 282700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.279100201325491e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.95 | consumed tokens: 2315878400.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T21:15:20 | step: 282800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.278019721619785e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.88 | consumed tokens: 2316697600.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T21:15:40 | step: 282900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.276939605711959e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.27 | consumed tokens: 2317516800.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T21:16:00 | step: 283000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.275859126006253e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.83 | consumed tokens: 2318336000.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T21:16:21 | step: 283100 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 3.274778646300547e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.55 | consumed tokens: 2319155200.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T21:16:41 | step: 283200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.27369780279696e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.69 | consumed tokens: 2319974400.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T21:17:02 | step: 283300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.272616595495492e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.91 | consumed tokens: 2320793600.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T21:17:22 | step: 283400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.271535751991905e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.73 | consumed tokens: 2321612800.0 | grad norm avg: 0.9 | grad norm last: 0.97 | 
2026-01-01T21:17:43 | step: 283500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.2704545446904376e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.53 | consumed tokens: 2322432000.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T21:18:03 | step: 283600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.269372973591089e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.95 | consumed tokens: 2323251200.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T21:18:23 | step: 283700 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.268291402491741e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.59 | consumed tokens: 2324070400.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T21:18:44 | step: 283800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.267209467594512e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.16 | consumed tokens: 2324889600.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T21:19:04 | step: 283900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.266127532697283e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.2 | consumed tokens: 2325708800.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T21:19:25 | step: 284000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.2650455978000537e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.78 | consumed tokens: 2326528000.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T21:19:45 | step: 284100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.263963299104944e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.92 | consumed tokens: 2327347200.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T21:20:06 | step: 284200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.262881000409834e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.45 | consumed tokens: 2328166400.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T21:20:26 | step: 284300 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.261798701714724e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.06 | consumed tokens: 2328985600.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T21:20:47 | step: 284400 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 3.260715675423853e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.55 | consumed tokens: 2329804800.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T21:21:07 | step: 284500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.2596330129308626e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.95 | consumed tokens: 2330624000.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T21:21:27 | step: 284600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.2585499866399914e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.98 | consumed tokens: 2331443200.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T21:21:48 | step: 284700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.25746696034912e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.05 | consumed tokens: 2332262400.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T21:22:08 | step: 284800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.256383570260368e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 4.34 | consumed tokens: 2333081600.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T21:22:29 | step: 284900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.2553001801716164e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.33 | consumed tokens: 2333900800.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-01T21:22:49 | step: 285000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.254216426284984e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.59 | consumed tokens: 2334720000.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T21:23:11 | step: 285100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.253132672398351e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.95 | consumed tokens: 2335539200.0 | grad norm avg: 0.9 | grad norm last: 1.0 | 
2026-01-01T21:23:32 | step: 285200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.252048554713838e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.36 | consumed tokens: 2336358400.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T21:23:52 | step: 285300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.2509644370293245e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.72 | consumed tokens: 2337177600.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T21:24:12 | step: 285400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.249880319344811e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.08 | consumed tokens: 2337996800.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T21:24:33 | step: 285500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.248795837862417e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.95 | consumed tokens: 2338816000.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T21:24:53 | step: 285600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.247711356380023e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.83 | consumed tokens: 2339635200.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T21:25:14 | step: 285700 | train samples/s: 83.7 | train mfu (16-bit): -1.0 | lr mean: 3.246626511099748e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.58 | consumed tokens: 2340454400.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T21:25:34 | step: 285800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.2455416658194736e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.44 | consumed tokens: 2341273600.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T21:25:55 | step: 285900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.244456820539199e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.05 | consumed tokens: 2342092800.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T21:26:15 | step: 286000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.2433716114610434e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.92 | consumed tokens: 2342912000.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T21:26:35 | step: 286100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.242286402382888e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.78 | consumed tokens: 2343731200.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T21:26:56 | step: 286200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.241200829506852e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.3 | consumed tokens: 2344550400.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T21:27:16 | step: 286300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.2401152566308156e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.11 | consumed tokens: 2345369600.0 | grad norm avg: 0.9 | grad norm last: 0.98 | 
2026-01-01T21:27:37 | step: 286400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.239029319956899e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.95 | consumed tokens: 2346188800.0 | grad norm avg: 0.9 | grad norm last: 0.97 | 
2026-01-01T21:27:57 | step: 286500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.237943383282982e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.22 | consumed tokens: 2347008000.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T21:28:17 | step: 286600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.236857446609065e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.41 | consumed tokens: 2347827200.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T21:28:38 | step: 286700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.2357711461372674e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.11 | consumed tokens: 2348646400.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T21:28:58 | step: 286800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.23468484566547e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.12 | consumed tokens: 2349465600.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T21:29:19 | step: 286900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.2335981813957915e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.66 | consumed tokens: 2350284800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T21:29:39 | step: 287000 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 3.232511517126113e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.27 | consumed tokens: 2351104000.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T21:30:00 | step: 287100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.231424489058554e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 4.12 | consumed tokens: 2351923200.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T21:30:20 | step: 287200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.230337460990995e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 3.06 | consumed tokens: 2352742400.0 | grad norm avg: 0.91 | grad norm last: 0.99 | 
2026-01-01T21:30:41 | step: 287300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.229250432923436e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.5 | consumed tokens: 2353561600.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T21:31:01 | step: 287400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.2281630410579965e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.88 | consumed tokens: 2354380800.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T21:31:22 | step: 287500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.227075649192557e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.7 | consumed tokens: 2355200000.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T21:31:42 | step: 287600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.225988257327117e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.08 | consumed tokens: 2356019200.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T21:32:03 | step: 287700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.2249005016637966e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.36 | consumed tokens: 2356838400.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T21:32:23 | step: 287800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.2238123822025955e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.34 | consumed tokens: 2357657600.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T21:32:44 | step: 287900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.2227242627413943e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.31 | consumed tokens: 2358476800.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T21:33:04 | step: 288000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.221636143280193e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.05 | consumed tokens: 2359296000.0 | grad norm avg: 0.91 | grad norm last: 1.0 | 
2026-01-01T21:33:25 | step: 288100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.2205476600211114e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.94 | consumed tokens: 2360115200.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T21:33:45 | step: 288200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.2194591767620295e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.66 | consumed tokens: 2360934400.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T21:34:06 | step: 288300 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 3.218370693502948e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.58 | consumed tokens: 2361753600.0 | grad norm avg: 0.89 | grad norm last: 0.93 | 
2026-01-01T21:34:26 | step: 288400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.217281846445985e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.59 | consumed tokens: 2362572800.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T21:34:47 | step: 288500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.2161929993890226e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.28 | consumed tokens: 2363392000.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T21:35:07 | step: 288600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.215103788534179e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.34 | consumed tokens: 2364211200.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T21:35:27 | step: 288700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.214014577679336e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.92 | consumed tokens: 2365030400.0 | grad norm avg: 0.9 | grad norm last: 0.99 | 
2026-01-01T21:35:48 | step: 288800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.212925366824493e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.11 | consumed tokens: 2365849600.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T21:36:08 | step: 288900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.211835792171769e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.77 | consumed tokens: 2366668800.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T21:36:29 | step: 289000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.210745853721164e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.23 | consumed tokens: 2367488000.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T21:36:49 | step: 289100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.20965627906844e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.14 | consumed tokens: 2368307200.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T21:37:09 | step: 289200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.2085663406178355e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.88 | consumed tokens: 2369126400.0 | grad norm avg: 0.89 | grad norm last: 0.88 | 
2026-01-01T21:37:30 | step: 289300 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.20747603836935e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.92 | consumed tokens: 2369945600.0 | grad norm avg: 0.9 | grad norm last: 0.97 | 
2026-01-01T21:37:50 | step: 289400 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.206385736120865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.05 | consumed tokens: 2370764800.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-01T21:38:11 | step: 289500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.2052954338723794e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.8 | consumed tokens: 2371584000.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T21:38:31 | step: 289600 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 3.204204767826013e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.0 | consumed tokens: 2372403200.0 | grad norm avg: 0.91 | grad norm last: 0.84 | 
2026-01-01T21:38:52 | step: 289700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.203114101779647e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.59 | consumed tokens: 2373222400.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T21:39:12 | step: 289800 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.202023435733281e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.55 | consumed tokens: 2374041600.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T21:39:33 | step: 289900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.200932405889034e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.61 | consumed tokens: 2374860800.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T21:39:53 | step: 290000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.1998413760447875e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.16 | consumed tokens: 2375680000.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T21:40:15 | step: 290100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.19874998240266e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.98 | consumed tokens: 2376499200.0 | grad norm avg: 0.9 | grad norm last: 1.04 | 
2026-01-01T21:40:36 | step: 290200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.1976585887605324e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.25 | consumed tokens: 2377318400.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T21:40:56 | step: 290300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.196566831320524e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.47 | consumed tokens: 2378137600.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T21:41:16 | step: 290400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.195475073880516e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.83 | consumed tokens: 2378956800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T21:41:37 | step: 290500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.194383316440508e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.86 | consumed tokens: 2379776000.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T21:41:57 | step: 290600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.1932915590004995e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.77 | consumed tokens: 2380595200.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T21:42:18 | step: 290700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.19219907396473e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.33 | consumed tokens: 2381414400.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T21:42:38 | step: 290800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.191106952726841e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.52 | consumed tokens: 2382233600.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T21:42:59 | step: 290900 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 3.190014467691071e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.86 | consumed tokens: 2383052800.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T21:43:19 | step: 291000 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.188921982655302e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.78 | consumed tokens: 2383872000.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T21:43:39 | step: 291100 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.1878291338216513e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.89 | consumed tokens: 2384691200.0 | grad norm avg: 0.9 | grad norm last: 0.98 | 
2026-01-01T21:44:00 | step: 291200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.186736284988001e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.94 | consumed tokens: 2385510400.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T21:44:20 | step: 291300 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.1856434361543506e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.06 | consumed tokens: 2386329600.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T21:44:40 | step: 291400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.1845502235228196e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.95 | consumed tokens: 2387148800.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T21:45:01 | step: 291500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.1834570108912885e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 4.09 | consumed tokens: 2387968000.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T21:45:21 | step: 291600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.182363434461877e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.08 | consumed tokens: 2388787200.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T21:45:42 | step: 291700 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.181269858032465e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.78 | consumed tokens: 2389606400.0 | grad norm avg: 0.9 | grad norm last: 0.98 | 
2026-01-01T21:46:02 | step: 291800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.180176281603053e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.33 | consumed tokens: 2390425600.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T21:46:22 | step: 291900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.179082341375761e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.41 | consumed tokens: 2391244800.0 | grad norm avg: 0.9 | grad norm last: 1.01 | 
2026-01-01T21:46:43 | step: 292000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.177988401148468e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.77 | consumed tokens: 2392064000.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T21:47:03 | step: 292100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.176894460921176e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.34 | consumed tokens: 2392883200.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T21:47:24 | step: 292200 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 3.1758001568960026e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.45 | consumed tokens: 2393702400.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T21:47:44 | step: 292300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.1747058528708294e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.27 | consumed tokens: 2394521600.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T21:48:05 | step: 292400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.1736111850477755e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.2 | consumed tokens: 2395340800.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T21:48:25 | step: 292500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.1725165172247216e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.88 | consumed tokens: 2396160000.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T21:48:46 | step: 292600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.171421849401668e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.22 | consumed tokens: 2396979200.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T21:49:06 | step: 292700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.170326817780733e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.61 | consumed tokens: 2397798400.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T21:49:26 | step: 292800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.1692317861597985e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.09 | consumed tokens: 2398617600.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T21:49:47 | step: 292900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.168136390740983e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.61 | consumed tokens: 2399436800.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T21:50:07 | step: 293000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.167040995322168e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.33 | consumed tokens: 2400256000.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T21:50:28 | step: 293100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.1659455999033526e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.22 | consumed tokens: 2401075200.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T21:50:48 | step: 293200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.1648498406866565e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.67 | consumed tokens: 2401894400.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T21:51:08 | step: 293300 | train samples/s: 85.3 | train mfu (16-bit): -1.0 | lr mean: 3.1637540814699605e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.8 | consumed tokens: 2402713600.0 | grad norm avg: 0.9 | grad norm last: 0.97 | 
2026-01-01T21:51:29 | step: 293400 | train samples/s: 85.2 | train mfu (16-bit): -1.0 | lr mean: 3.1626583222532645e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.47 | consumed tokens: 2403532800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T21:51:49 | step: 293500 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 3.161562199238688e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.72 | consumed tokens: 2404352000.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T21:52:10 | step: 293600 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.160466076224111e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.77 | consumed tokens: 2405171200.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T21:52:30 | step: 293700 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 3.1593695894116536e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.2 | consumed tokens: 2405990400.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T21:52:50 | step: 293800 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.158273102599196e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.06 | consumed tokens: 2406809600.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T21:53:11 | step: 293900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.157176615786739e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.78 | consumed tokens: 2407628800.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T21:53:31 | step: 294000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.1560797651764005e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.22 | consumed tokens: 2408448000.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T21:53:52 | step: 294100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.1549829145660624e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.81 | consumed tokens: 2409267200.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T21:54:12 | step: 294200 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.153886063955724e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.92 | consumed tokens: 2410086400.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T21:54:32 | step: 294300 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.1527888495475054e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.88 | consumed tokens: 2410905600.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T21:54:53 | step: 294400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.1516916351392865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.73 | consumed tokens: 2411724800.0 | grad norm avg: 0.9 | grad norm last: 0.83 | 
2026-01-01T21:55:13 | step: 294500 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.150594056933187e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 3.17 | consumed tokens: 2412544000.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T21:55:33 | step: 294600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.1494964787270874e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.5 | consumed tokens: 2413363200.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T21:55:54 | step: 294700 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.148398900520988e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 4.09 | consumed tokens: 2414182400.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T21:56:14 | step: 294800 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 3.1473009585170075e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.55 | consumed tokens: 2415001600.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T21:56:35 | step: 294900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.146203016513027e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.05 | consumed tokens: 2415820800.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T21:56:55 | step: 295000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.145105074509047e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.52 | consumed tokens: 2416640000.0 | grad norm avg: 0.91 | grad norm last: 0.85 | 
2026-01-01T21:57:17 | step: 295100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.144006768707186e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.58 | consumed tokens: 2417459200.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T21:57:38 | step: 295200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.142908462905325e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.11 | train loss last: 3.2 | consumed tokens: 2418278400.0 | grad norm avg: 0.9 | grad norm last: 0.81 | 
2026-01-01T21:57:58 | step: 295300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.141810157103464e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.8 | consumed tokens: 2419097600.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T21:58:19 | step: 295400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.140711487503722e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.75 | consumed tokens: 2419916800.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T21:58:39 | step: 295500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.1396128179039806e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.66 | consumed tokens: 2420736000.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T21:58:59 | step: 295600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.138513784506358e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.25 | consumed tokens: 2421555200.0 | grad norm avg: 0.89 | grad norm last: 0.9 | 
2026-01-01T21:59:20 | step: 295700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.137414751108736e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.42 | consumed tokens: 2422374400.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T21:59:40 | step: 295800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.1363157177111134e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.16 | consumed tokens: 2423193600.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T22:00:01 | step: 295900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.13521632051561e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.3 | consumed tokens: 2424012800.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-01T22:00:21 | step: 296000 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.134116923320107e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.39 | consumed tokens: 2424832000.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T22:00:42 | step: 296100 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 3.133017526124604e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.92 | consumed tokens: 2425651200.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T22:01:02 | step: 296200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.13191776513122e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.66 | consumed tokens: 2426470400.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T22:01:23 | step: 296300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.1308180041378364e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.64 | consumed tokens: 2427289600.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T22:01:43 | step: 296400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.1297182431444526e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.48 | consumed tokens: 2428108800.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T22:02:03 | step: 296500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.128618118353188e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.67 | consumed tokens: 2428928000.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T22:02:24 | step: 296600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.1275179935619235e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.27 | consumed tokens: 2429747200.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T22:02:44 | step: 296700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.126417504972778e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.11 | consumed tokens: 2430566400.0 | grad norm avg: 0.9 | grad norm last: 0.97 | 
2026-01-01T22:03:05 | step: 296800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.125317380181514e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.66 | consumed tokens: 2431385600.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T22:03:25 | step: 296900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.124216527794488e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.89 | consumed tokens: 2432204800.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T22:03:46 | step: 297000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.1231160392053425e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.11 | consumed tokens: 2433024000.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T22:04:06 | step: 297100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.1220151868183166e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.48 | consumed tokens: 2433843200.0 | grad norm avg: 0.91 | grad norm last: 0.84 | 
2026-01-01T22:04:26 | step: 297200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.1209143344312906e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.27 | consumed tokens: 2434662400.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T22:04:47 | step: 297300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.119813118246384e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.11 | consumed tokens: 2435481600.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T22:05:07 | step: 297400 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 3.118711902061477e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.25 | consumed tokens: 2436300800.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T22:05:28 | step: 297500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.1176106858765706e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.34 | consumed tokens: 2437120000.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T22:05:48 | step: 297600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.116509105893783e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.45 | consumed tokens: 2437939200.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T22:06:09 | step: 297700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.115407525910996e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.53 | consumed tokens: 2438758400.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T22:06:29 | step: 297800 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.1143059459282085e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.77 | consumed tokens: 2439577600.0 | grad norm avg: 0.89 | grad norm last: 0.94 | 
2026-01-01T22:06:49 | step: 297900 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.1132040021475405e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.64 | consumed tokens: 2440396800.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T22:07:10 | step: 298000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.1121020583668724e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.03 | consumed tokens: 2441216000.0 | grad norm avg: 0.92 | grad norm last: 0.98 | 
2026-01-01T22:07:30 | step: 298100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.1109997507883236e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.69 | consumed tokens: 2442035200.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-01T22:07:51 | step: 298200 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.1098978070076555e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.52 | consumed tokens: 2442854400.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T22:08:11 | step: 298300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.108795135631226e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.56 | consumed tokens: 2443673600.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T22:08:31 | step: 298400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.107692828052677e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.02 | consumed tokens: 2444492800.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T22:08:52 | step: 298500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.106590156676248e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.99 | train loss last: 3.03 | consumed tokens: 2445312000.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T22:09:12 | step: 298600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.105487485299818e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.19 | consumed tokens: 2446131200.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T22:09:33 | step: 298700 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 3.104384813923389e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.44 | consumed tokens: 2446950400.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T22:09:53 | step: 298800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.1032817787490785e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.7 | consumed tokens: 2447769600.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T22:10:14 | step: 298900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.102178743574768e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.94 | consumed tokens: 2448588800.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T22:10:34 | step: 299000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.1010753446025774e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.88 | consumed tokens: 2449408000.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T22:10:55 | step: 299100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.0999719456303865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.53 | consumed tokens: 2450227200.0 | grad norm avg: 0.9 | grad norm last: 0.97 | 
2026-01-01T22:11:15 | step: 299200 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 3.0988685466581956e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.8 | consumed tokens: 2451046400.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T22:11:35 | step: 299300 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.0977651476860046e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.22 | consumed tokens: 2451865600.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T22:11:56 | step: 299400 | train samples/s: 85.2 | train mfu (16-bit): -1.0 | lr mean: 3.096661384915933e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.94 | consumed tokens: 2452684800.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T22:12:16 | step: 299500 | train samples/s: 85.2 | train mfu (16-bit): -1.0 | lr mean: 3.095557258347981e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.36 | consumed tokens: 2453504000.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T22:12:36 | step: 299600 | train samples/s: 85.2 | train mfu (16-bit): -1.0 | lr mean: 3.094453495577909e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.06 | consumed tokens: 2454323200.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T22:12:57 | step: 299700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.093349369009957e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.28 | consumed tokens: 2455142400.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T22:13:17 | step: 299800 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 3.0922452424420044e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.75 | consumed tokens: 2455961600.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T22:13:37 | step: 299900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.091140752076171e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.1 | train loss last: 3.27 | consumed tokens: 2456780800.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T22:13:58 | step: 300000 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 3.090036261710338e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.67 | consumed tokens: 2457600000.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T22:14:20 | step: 300100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.088931771344505e-05 | peak memory rank 0 (MB): 4524.28 | train loss avg: 3.08 | train loss last: 3.28 | consumed tokens: 2458419200.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-01T22:14:41 | step: 300200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.087827280978672e-05 | peak memory rank 0 (MB): 4524.28 | train loss avg: 3.05 | train loss last: 3.64 | consumed tokens: 2459238400.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T22:15:01 | step: 300300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.0867224268149585e-05 | peak memory rank 0 (MB): 4524.28 | train loss avg: 3.04 | train loss last: 2.91 | consumed tokens: 2460057600.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T22:15:22 | step: 300400 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.085617208853364e-05 | peak memory rank 0 (MB): 4524.28 | train loss avg: 3.05 | train loss last: 3.11 | consumed tokens: 2460876800.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T22:15:42 | step: 300500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.08451235468965e-05 | peak memory rank 0 (MB): 4524.28 | train loss avg: 3.07 | train loss last: 3.02 | consumed tokens: 2461696000.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T22:16:02 | step: 300600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.083407136728056e-05 | peak memory rank 0 (MB): 4524.28 | train loss avg: 3.06 | train loss last: 2.81 | consumed tokens: 2462515200.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T22:16:23 | step: 300700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.082301918766461e-05 | peak memory rank 0 (MB): 4524.28 | train loss avg: 3.05 | train loss last: 2.8 | consumed tokens: 2463334400.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-01T22:16:43 | step: 300800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.081196337006986e-05 | peak memory rank 0 (MB): 4524.28 | train loss avg: 3.02 | train loss last: 2.94 | consumed tokens: 2464153600.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T22:17:04 | step: 300900 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 3.080090755247511e-05 | peak memory rank 0 (MB): 4524.28 | train loss avg: 3.06 | train loss last: 3.42 | consumed tokens: 2464972800.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T22:17:24 | step: 301000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.078985173488036e-05 | peak memory rank 0 (MB): 4524.28 | train loss avg: 3.06 | train loss last: 3.2 | consumed tokens: 2465792000.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T22:17:44 | step: 301100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.0778795917285606e-05 | peak memory rank 0 (MB): 4524.28 | train loss avg: 3.02 | train loss last: 2.73 | consumed tokens: 2466611200.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T22:18:05 | step: 301200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.076773646171205e-05 | peak memory rank 0 (MB): 4524.28 | train loss avg: 3.05 | train loss last: 2.89 | consumed tokens: 2467430400.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-01T22:18:26 | step: 301300 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 3.075667700613849e-05 | peak memory rank 0 (MB): 4524.28 | train loss avg: 3.07 | train loss last: 3.31 | consumed tokens: 2468249600.0 | grad norm avg: 0.91 | grad norm last: 0.98 | 
2026-01-01T22:18:46 | step: 301400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.074561391258612e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.69 | consumed tokens: 2469068800.0 | grad norm avg: 0.9 | grad norm last: 0.97 | 
2026-01-01T22:19:06 | step: 301500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.073455081903376e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.88 | consumed tokens: 2469888000.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T22:19:27 | step: 301600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.072348772548139e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.98 | consumed tokens: 2470707200.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T22:19:47 | step: 301700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.0712424631929025e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.19 | consumed tokens: 2471526400.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T22:20:08 | step: 301800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.070135790039785e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.73 | consumed tokens: 2472345600.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T22:20:28 | step: 301900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.069029116886668e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.72 | consumed tokens: 2473164800.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T22:20:48 | step: 302000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.06792207993567e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.77 | consumed tokens: 2473984000.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T22:21:09 | step: 302100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.066815042984672e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.52 | consumed tokens: 2474803200.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T22:21:29 | step: 302200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.065708006033674e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.03 | consumed tokens: 2475622400.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T22:21:50 | step: 302300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.064600969082676e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.05 | consumed tokens: 2476441600.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T22:22:10 | step: 302400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.063493568333797e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 4.31 | consumed tokens: 2477260800.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T22:22:31 | step: 302500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.0623861675849184e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.05 | consumed tokens: 2478080000.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T22:22:51 | step: 302600 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 3.06127876683604e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.12 | consumed tokens: 2478899200.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T22:23:12 | step: 302700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.06017100228928e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.2 | consumed tokens: 2479718400.0 | grad norm avg: 0.92 | grad norm last: 0.94 | 
2026-01-01T22:23:32 | step: 302800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.059063237742521e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.0 | consumed tokens: 2480537600.0 | grad norm avg: 0.91 | grad norm last: 0.83 | 
2026-01-01T22:23:53 | step: 302900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.0579554731957614e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.3 | consumed tokens: 2481356800.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T22:24:13 | step: 303000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.056847344851121e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.84 | consumed tokens: 2482176000.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T22:24:33 | step: 303100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.055739216506481e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.91 | consumed tokens: 2482995200.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T22:24:54 | step: 303200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.054631088161841e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.47 | consumed tokens: 2483814400.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T22:25:14 | step: 303300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.05352259601932e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.88 | consumed tokens: 2484633600.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T22:25:35 | step: 303400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 3.0524141038767993e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.45 | consumed tokens: 2485452800.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T22:25:55 | step: 303500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.0513056117342785e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.11 | consumed tokens: 2486272000.0 | grad norm avg: 0.91 | grad norm last: 0.85 | 
2026-01-01T22:26:15 | step: 303600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.0501969376928173e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.69 | consumed tokens: 2487091200.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T22:26:36 | step: 303700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.049088263651356e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.95 | consumed tokens: 2487910400.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T22:26:56 | step: 303800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.0479792258120142e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 2.73 | consumed tokens: 2488729600.0 | grad norm avg: 0.91 | grad norm last: 0.96 | 
2026-01-01T22:27:17 | step: 303900 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 3.0468701879726723e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.44 | consumed tokens: 2489548800.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T22:27:38 | step: 304000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.0457611501333304e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.09 | consumed tokens: 2490368000.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T22:27:58 | step: 304100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.044651930395048e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.23 | consumed tokens: 2491187200.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-01T22:28:18 | step: 304200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.0435425287578255e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.33 | consumed tokens: 2492006400.0 | grad norm avg: 0.91 | grad norm last: 0.98 | 
2026-01-01T22:28:39 | step: 304300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.0424329452216625e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.44 | consumed tokens: 2492825600.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-01T22:28:59 | step: 304400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.0413233616854995e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.08 | consumed tokens: 2493644800.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T22:29:20 | step: 304500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.0402137781493366e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.52 | consumed tokens: 2494464000.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T22:29:40 | step: 304600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.0391040127142332e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.41 | consumed tokens: 2495283200.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-01T22:30:01 | step: 304700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.0379940653801896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.11 | consumed tokens: 2496102400.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T22:30:21 | step: 304800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.0368839361472055e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.25 | consumed tokens: 2496921600.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-01T22:30:42 | step: 304900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.0357738069142215e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.8 | consumed tokens: 2497740800.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T22:31:02 | step: 305000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.0346636776812375e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.19 | consumed tokens: 2498560000.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T22:31:24 | step: 305100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.0335531846503727e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.55 | consumed tokens: 2499379200.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T22:31:45 | step: 305200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.032442691619508e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.59 | consumed tokens: 2500198400.0 | grad norm avg: 0.91 | grad norm last: 0.85 | 
2026-01-01T22:32:05 | step: 305300 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 3.0313321985886432e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.78 | consumed tokens: 2501017600.0 | grad norm avg: 0.91 | grad norm last: 0.96 | 
2026-01-01T22:32:26 | step: 305400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.030221523658838e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.88 | consumed tokens: 2501836800.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T22:32:46 | step: 305500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.0291106668300927e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.72 | consumed tokens: 2502656000.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-01T22:33:07 | step: 305600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.0279998100013472e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.56 | consumed tokens: 2503475200.0 | grad norm avg: 0.91 | grad norm last: 0.99 | 
2026-01-01T22:33:27 | step: 305700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.0268887712736614e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.45 | consumed tokens: 2504294400.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T22:33:48 | step: 305800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.0257775506470352e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.25 | consumed tokens: 2505113600.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-01T22:34:08 | step: 305900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.024666330020409e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.38 | consumed tokens: 2505932800.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T22:34:28 | step: 306000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 3.023555109393783e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.34 | consumed tokens: 2506752000.0 | grad norm avg: 0.91 | grad norm last: 0.98 | 
2026-01-01T22:34:49 | step: 306100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.022443524969276e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.5 | consumed tokens: 2507571200.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T22:35:09 | step: 306200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.0213321224437095e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.62 | consumed tokens: 2508390400.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T22:35:30 | step: 306300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.0202203561202623e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.45 | consumed tokens: 2509209600.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-01T22:35:50 | step: 306400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.019108589796815e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.94 | consumed tokens: 2510028800.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-01T22:36:11 | step: 306500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.017996823473368e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.23 | consumed tokens: 2510848000.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T22:36:31 | step: 306600 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 3.01688469335204e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.08 | consumed tokens: 2511667200.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T22:36:52 | step: 306700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.0157727451296523e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.61 | consumed tokens: 2512486400.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T22:37:12 | step: 306800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.014660433109384e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.61 | consumed tokens: 2513305600.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T22:37:33 | step: 306900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.0135481210891157e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.16 | consumed tokens: 2514124800.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T22:37:53 | step: 307000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.0124358090688474e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.98 | consumed tokens: 2514944000.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T22:38:14 | step: 307100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.0113231332506984e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.33 | consumed tokens: 2515763200.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T22:38:34 | step: 307200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.0102106393314898e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.05 | consumed tokens: 2516582400.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T22:38:55 | step: 307300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.0090979635133408e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.41 | consumed tokens: 2517401600.0 | grad norm avg: 0.9 | grad norm last: 0.95 | 
2026-01-01T22:39:15 | step: 307400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.0079851057962514e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.69 | consumed tokens: 2518220800.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T22:39:36 | step: 307500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 3.0068720661802217e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.97 | consumed tokens: 2519040000.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T22:39:56 | step: 307600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.005759026564192e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.58 | consumed tokens: 2519859200.0 | grad norm avg: 0.9 | grad norm last: 0.8 | 
2026-01-01T22:40:17 | step: 307700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 3.0046459869481623e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.41 | consumed tokens: 2520678400.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T22:40:37 | step: 307800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 3.003532583534252e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.34 | consumed tokens: 2521497600.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T22:40:58 | step: 307900 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 3.002419362019282e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.59 | consumed tokens: 2522316800.0 | grad norm avg: 0.91 | grad norm last: 0.84 | 
2026-01-01T22:41:18 | step: 308000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.001305776706431e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.73 | consumed tokens: 2523136000.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T22:41:39 | step: 308100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 3.0001923732925206e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.28 | consumed tokens: 2523955200.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T22:41:59 | step: 308200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.9990786060807295e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.56 | consumed tokens: 2524774400.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-01T22:42:20 | step: 308300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.9979648388689384e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.14 | consumed tokens: 2525593600.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T22:42:40 | step: 308400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.9968510716571473e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.22 | consumed tokens: 2526412800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T22:43:00 | step: 308500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.9957371225464158e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.17 | consumed tokens: 2527232000.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T22:43:21 | step: 308600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.994622991536744e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.69 | consumed tokens: 2528051200.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T22:43:41 | step: 308700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.993508860527072e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.36 | consumed tokens: 2528870400.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T22:44:02 | step: 308800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.99239454761846e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.17 | consumed tokens: 2529689600.0 | grad norm avg: 0.91 | grad norm last: 1.04 | 
2026-01-01T22:44:22 | step: 308900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.9912800528109074e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.86 | consumed tokens: 2530508800.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T22:44:43 | step: 309000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.9901657399022952e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.97 | consumed tokens: 2531328000.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-01T22:45:03 | step: 309100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.9890510631958023e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.73 | consumed tokens: 2532147200.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-01T22:45:24 | step: 309200 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 2.9879363864893094e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.56 | consumed tokens: 2532966400.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T22:45:44 | step: 309300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.986821527883876e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.09 | consumed tokens: 2533785600.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-01T22:46:05 | step: 309400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.985706669278443e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.2 | consumed tokens: 2534604800.0 | grad norm avg: 0.91 | grad norm last: 0.85 | 
2026-01-01T22:46:25 | step: 309500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.9845918106730096e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.16 | consumed tokens: 2535424000.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T22:46:45 | step: 309600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.9834765882696956e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.94 | consumed tokens: 2536243200.0 | grad norm avg: 0.9 | grad norm last: 1.02 | 
2026-01-01T22:47:06 | step: 309700 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.982361547765322e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.27 | consumed tokens: 2537062400.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T22:47:26 | step: 309800 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 2.9812461434630677e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.06 | consumed tokens: 2537881600.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T22:47:47 | step: 309900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.9801309210597537e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.36 | consumed tokens: 2538700800.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T22:48:07 | step: 310000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.979015334858559e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.08 | consumed tokens: 2539520000.0 | grad norm avg: 0.91 | grad norm last: 1.02 | 
2026-01-01T22:48:29 | step: 310100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.9778997486573644e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.02 | consumed tokens: 2540339200.0 | grad norm avg: 0.91 | grad norm last: 0.96 | 
2026-01-01T22:48:50 | step: 310200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.9767841624561697e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.75 | consumed tokens: 2541158400.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-01T22:49:10 | step: 310300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.9756683943560347e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.23 | consumed tokens: 2541977600.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T22:49:31 | step: 310400 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.9745524443569593e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.16 | consumed tokens: 2542796800.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T22:49:51 | step: 310500 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 2.973436494357884e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.81 | consumed tokens: 2543616000.0 | grad norm avg: 0.9 | grad norm last: 0.94 | 
2026-01-01T22:50:12 | step: 310600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.9723203624598682e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.22 | consumed tokens: 2544435200.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T22:50:32 | step: 310700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.9712042305618525e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.92 | consumed tokens: 2545254400.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-01T22:50:53 | step: 310800 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.9700879167648964e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.47 | consumed tokens: 2546073600.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T22:51:13 | step: 310900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.9689716029679403e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.45 | consumed tokens: 2546892800.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-01T22:51:34 | step: 311000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.9678551072720438e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.09 | consumed tokens: 2547712000.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T22:51:54 | step: 311100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.9667386115761474e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.03 | consumed tokens: 2548531200.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T22:52:14 | step: 311200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.9656219339813106e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.78 | consumed tokens: 2549350400.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-01T22:52:35 | step: 311300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.9645052563864738e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.11 | consumed tokens: 2550169600.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T22:52:55 | step: 311400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.9633883968926966e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.34 | consumed tokens: 2550988800.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T22:53:16 | step: 311500 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.9622715373989195e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.0 | consumed tokens: 2551808000.0 | grad norm avg: 0.92 | grad norm last: 1.03 | 
2026-01-01T22:53:36 | step: 311600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.961154496006202e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.84 | consumed tokens: 2552627200.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T22:53:57 | step: 311700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.960037272714544e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.34 | consumed tokens: 2553446400.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T22:54:17 | step: 311800 | train samples/s: 83.6 | train mfu (16-bit): -1.0 | lr mean: 2.9589200494228862e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.02 | consumed tokens: 2554265600.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T22:54:38 | step: 311900 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.9578028261312284e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.83 | consumed tokens: 2555084800.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T22:54:58 | step: 312000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.95668542094063e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.69 | consumed tokens: 2555904000.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T22:55:19 | step: 312100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.9555678338510916e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.05 | consumed tokens: 2556723200.0 | grad norm avg: 0.9 | grad norm last: 0.99 | 
2026-01-01T22:55:39 | step: 312200 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 2.954450246761553e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.03 | consumed tokens: 2557542400.0 | grad norm avg: 0.91 | grad norm last: 0.98 | 
2026-01-01T22:55:59 | step: 312300 | train samples/s: 85.3 | train mfu (16-bit): -1.0 | lr mean: 2.9533326596720144e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.09 | consumed tokens: 2558361600.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T22:56:20 | step: 312400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.9522148906835355e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.33 | consumed tokens: 2559180800.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T22:56:40 | step: 312500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.9510969397961162e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.39 | consumed tokens: 2560000000.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T22:57:01 | step: 312600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.949978988908697e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.56 | consumed tokens: 2560819200.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T22:57:21 | step: 312700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.9488608561223373e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.27 | consumed tokens: 2561638400.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T22:57:41 | step: 312800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.9477427233359776e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.22 | consumed tokens: 2562457600.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T22:58:02 | step: 312900 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.946624590549618e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.97 | consumed tokens: 2563276800.0 | grad norm avg: 0.9 | grad norm last: 0.97 | 
2026-01-01T22:58:22 | step: 313000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.9455060939653777e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.72 | consumed tokens: 2564096000.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T22:58:43 | step: 313100 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 2.9443877792800777e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.09 | consumed tokens: 2564915200.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-01T22:59:03 | step: 313200 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.9432692826958373e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.67 | consumed tokens: 2565734400.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T22:59:24 | step: 313300 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.9421506042126566e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.56 | consumed tokens: 2566553600.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T22:59:44 | step: 313400 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 2.941031925729476e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.62 | consumed tokens: 2567372800.0 | grad norm avg: 0.91 | grad norm last: 0.96 | 
2026-01-01T23:00:04 | step: 313500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.939913065347355e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.83 | consumed tokens: 2568192000.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-01T23:00:25 | step: 313600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.9387942049652338e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.95 | consumed tokens: 2569011200.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T23:00:45 | step: 313700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.9376753445831127e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.19 | consumed tokens: 2569830400.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T23:01:06 | step: 313800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.936556120403111e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.94 | consumed tokens: 2570649600.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T23:01:26 | step: 313900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.9354370781220496e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.77 | consumed tokens: 2571468800.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T23:01:46 | step: 314000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.9343178539420478e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.0 | consumed tokens: 2572288000.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T23:02:07 | step: 314100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.9331984478631057e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.88 | consumed tokens: 2573107200.0 | grad norm avg: 0.92 | grad norm last: 0.94 | 
2026-01-01T23:02:27 | step: 314200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.9320790417841636e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.86 | consumed tokens: 2573926400.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T23:02:48 | step: 314300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.930959453806281e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.98 | consumed tokens: 2574745600.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T23:03:08 | step: 314400 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 2.9298398658283986e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.05 | consumed tokens: 2575564800.0 | grad norm avg: 0.91 | grad norm last: 1.01 | 
2026-01-01T23:03:29 | step: 314500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.928720277850516e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.19 | consumed tokens: 2576384000.0 | grad norm avg: 0.91 | grad norm last: 0.84 | 
2026-01-01T23:03:49 | step: 314600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.9276005079736933e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.84 | consumed tokens: 2577203200.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T23:04:09 | step: 314700 | train samples/s: 85.3 | train mfu (16-bit): -1.0 | lr mean: 2.92648055619793e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.61 | consumed tokens: 2578022400.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-01T23:04:30 | step: 314800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.925360604422167e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.91 | consumed tokens: 2578841600.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T23:04:50 | step: 314900 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.9242406526464038e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.55 | consumed tokens: 2579660800.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T23:05:11 | step: 315000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.9231205189717002e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.14 | consumed tokens: 2580480000.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T23:05:33 | step: 315100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.9220002033980563e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.81 | consumed tokens: 2581299200.0 | grad norm avg: 0.9 | grad norm last: 0.84 | 
2026-01-01T23:05:53 | step: 315200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.9208798878244124e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.89 | consumed tokens: 2582118400.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T23:06:14 | step: 315300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.9197595722507685e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.55 | consumed tokens: 2582937600.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T23:06:34 | step: 315400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.9186390747781843e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 3.09 | consumed tokens: 2583756800.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T23:06:54 | step: 315500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.9175185773056e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.2 | consumed tokens: 2584576000.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T23:07:15 | step: 315600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.9163978979340754e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.05 | consumed tokens: 2585395200.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-01T23:07:36 | step: 315700 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 2.915277218562551e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.78 | consumed tokens: 2586214400.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T23:07:56 | step: 315800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.914156357292086e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.78 | consumed tokens: 2587033600.0 | grad norm avg: 0.9 | grad norm last: 0.93 | 
2026-01-01T23:08:16 | step: 315900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.913035496021621e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.61 | consumed tokens: 2587852800.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T23:08:37 | step: 316000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.9119144528522156e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.52 | consumed tokens: 2588672000.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T23:08:57 | step: 316100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.9107934096828103e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.23 | consumed tokens: 2589491200.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T23:09:18 | step: 316200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.9096721846144646e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.36 | consumed tokens: 2590310400.0 | grad norm avg: 0.91 | grad norm last: 0.96 | 
2026-01-01T23:09:38 | step: 316300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.908550959546119e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.89 | consumed tokens: 2591129600.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T23:09:59 | step: 316400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.9074297344777733e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.23 | consumed tokens: 2591948800.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T23:10:19 | step: 316500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.9063083275104873e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.17 | consumed tokens: 2592768000.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T23:10:39 | step: 316600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.905186738644261e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.84 | consumed tokens: 2593587200.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T23:11:00 | step: 316700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.9040651497780345e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.97 | consumed tokens: 2594406400.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-01T23:11:20 | step: 316800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.902943560911808e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.16 | consumed tokens: 2595225600.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T23:11:41 | step: 316900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.9018217901466414e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.67 | consumed tokens: 2596044800.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T23:12:02 | step: 317000 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 2.9007000193814747e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.88 | consumed tokens: 2596864000.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T23:12:22 | step: 317100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.8995780667173676e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.0 | consumed tokens: 2597683200.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T23:12:42 | step: 317200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.8984561140532605e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.89 | consumed tokens: 2598502400.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-01T23:13:03 | step: 317300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.897333979490213e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.09 | consumed tokens: 2599321600.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T23:13:23 | step: 317400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.8962118449271657e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.92 | consumed tokens: 2600140800.0 | grad norm avg: 0.91 | grad norm last: 0.85 | 
2026-01-01T23:13:44 | step: 317500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.895089528465178e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.55 | consumed tokens: 2600960000.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T23:14:04 | step: 317600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.89396721200319e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.41 | consumed tokens: 2601779200.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T23:14:25 | step: 317700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.8928448955412023e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.72 | consumed tokens: 2602598400.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T23:14:45 | step: 317800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.891722397180274e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.75 | consumed tokens: 2603417600.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T23:15:05 | step: 317900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.890599898819346e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.98 | consumed tokens: 2604236800.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T23:15:26 | step: 318000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.8894772185594775e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.73 | consumed tokens: 2605056000.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-01T23:15:46 | step: 318100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.888354538299609e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.0 | consumed tokens: 2605875200.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T23:16:07 | step: 318200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.8872316761408e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.67 | consumed tokens: 2606694400.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T23:16:27 | step: 318300 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 2.8861088139819913e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.17 | consumed tokens: 2607513600.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-01T23:16:48 | step: 318400 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 2.884985769924242e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.45 | consumed tokens: 2608332800.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-01T23:17:08 | step: 318500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.883862725866493e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.56 | consumed tokens: 2609152000.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T23:17:29 | step: 318600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.8827396818087436e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.22 | consumed tokens: 2609971200.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-01T23:17:49 | step: 318700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.881616455852054e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.06 | consumed tokens: 2610790400.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T23:18:09 | step: 318800 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 2.8804932298953645e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.41 | consumed tokens: 2611609600.0 | grad norm avg: 0.92 | grad norm last: 0.94 | 
2026-01-01T23:18:30 | step: 318900 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.8793698220397346e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.09 | consumed tokens: 2612428800.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T23:18:50 | step: 319000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.8782464141841047e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.45 | consumed tokens: 2613248000.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T23:19:11 | step: 319100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.8771230063284747e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.5 | consumed tokens: 2614067200.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T23:19:31 | step: 319200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.8759994165739045e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.8 | consumed tokens: 2614886400.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T23:19:51 | step: 319300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.8748756449203938e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.09 | consumed tokens: 2615705600.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T23:20:12 | step: 319400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.8737518732668832e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.72 | consumed tokens: 2616524800.0 | grad norm avg: 0.91 | grad norm last: 1.01 | 
2026-01-01T23:20:32 | step: 319500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.8726281016133726e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.42 | consumed tokens: 2617344000.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T23:20:53 | step: 319600 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 2.8715041480609216e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.08 | consumed tokens: 2618163200.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-01T23:21:13 | step: 319700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.8703801945084706e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 3.77 | consumed tokens: 2618982400.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T23:21:34 | step: 319800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.8692562409560196e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.09 | consumed tokens: 2619801600.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T23:21:54 | step: 319900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.8681321055046283e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.75 | consumed tokens: 2620620800.0 | grad norm avg: 0.92 | grad norm last: 1.05 | 
2026-01-01T23:22:15 | step: 320000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.867007970053237e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 3.52 | consumed tokens: 2621440000.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T23:22:37 | step: 320100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.8658836527029052e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.88 | consumed tokens: 2622259200.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T23:22:57 | step: 320200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.8647593353525735e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.88 | consumed tokens: 2623078400.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T23:23:18 | step: 320300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.8636348361033015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.88 | consumed tokens: 2623897600.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T23:23:38 | step: 320400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.8625103368540294e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.45 | consumed tokens: 2624716800.0 | grad norm avg: 0.91 | grad norm last: 0.98 | 
2026-01-01T23:23:59 | step: 320500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.8613858376047574e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.88 | consumed tokens: 2625536000.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T23:24:19 | step: 320600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.860261156456545e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.56 | consumed tokens: 2626355200.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T23:24:40 | step: 320700 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.8591364753083326e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.95 | consumed tokens: 2627174400.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T23:25:00 | step: 320800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.85801161226118e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.88 | consumed tokens: 2627993600.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T23:25:21 | step: 320900 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 2.856886749214027e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.56 | consumed tokens: 2628812800.0 | grad norm avg: 0.92 | grad norm last: 0.96 | 
2026-01-01T23:25:41 | step: 321000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.8557618861668743e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.73 | consumed tokens: 2629632000.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T23:26:02 | step: 321100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.8546368412207812e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.0 | consumed tokens: 2630451200.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T23:26:22 | step: 321200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.853511796274688e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.17 | consumed tokens: 2631270400.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T23:26:43 | step: 321300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.8523865694296546e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.53 | consumed tokens: 2632089600.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-01T23:27:03 | step: 321400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.851261342584621e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.61 | consumed tokens: 2632908800.0 | grad norm avg: 0.92 | grad norm last: 0.98 | 
2026-01-01T23:27:24 | step: 321500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.8501359338406473e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.05 | consumed tokens: 2633728000.0 | grad norm avg: 0.92 | grad norm last: 0.94 | 
2026-01-01T23:27:44 | step: 321600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.849010706995614e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.34 | consumed tokens: 2634547200.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T23:28:05 | step: 321700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.8478851163526997e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.97 | consumed tokens: 2635366400.0 | grad norm avg: 0.9 | grad norm last: 0.87 | 
2026-01-01T23:28:25 | step: 321800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.846759707608726e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.09 | consumed tokens: 2636185600.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-01T23:28:46 | step: 321900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.8456341169658117e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.05 | consumed tokens: 2637004800.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-01T23:29:06 | step: 322000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.844508344423957e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.94 | consumed tokens: 2637824000.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T23:29:27 | step: 322100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.843382753781043e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.27 | consumed tokens: 2638643200.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T23:29:47 | step: 322200 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 2.842256799340248e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.16 | consumed tokens: 2639462400.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T23:30:08 | step: 322300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.8411310267983936e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.59 | consumed tokens: 2640281600.0 | grad norm avg: 0.91 | grad norm last: 0.85 | 
2026-01-01T23:30:28 | step: 322400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.8400050723575987e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.19 | consumed tokens: 2641100800.0 | grad norm avg: 0.92 | grad norm last: 1.01 | 
2026-01-01T23:30:49 | step: 322500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.8388791179168038e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.78 | consumed tokens: 2641920000.0 | grad norm avg: 0.91 | grad norm last: 0.98 | 
2026-01-01T23:31:09 | step: 322600 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 2.8377529815770686e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.12 | consumed tokens: 2642739200.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-01T23:31:30 | step: 322700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.8366268452373333e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.59 | consumed tokens: 2643558400.0 | grad norm avg: 0.93 | grad norm last: 0.99 | 
2026-01-01T23:31:50 | step: 322800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.8355005269986577e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.66 | consumed tokens: 2644377600.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T23:32:11 | step: 322900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.834374208759982e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.7 | consumed tokens: 2645196800.0 | grad norm avg: 0.91 | grad norm last: 0.96 | 
2026-01-01T23:32:31 | step: 323000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.8332478905213065e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.97 | consumed tokens: 2646016000.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T23:32:52 | step: 323100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.832121572282631e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.92 | consumed tokens: 2646835200.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T23:33:12 | step: 323200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.830995072145015e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.52 | consumed tokens: 2647654400.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T23:33:32 | step: 323300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.8298683901084587e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.16 | consumed tokens: 2648473600.0 | grad norm avg: 0.91 | grad norm last: 0.96 | 
2026-01-01T23:33:53 | step: 323400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.8287418899708427e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.12 | consumed tokens: 2649292800.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T23:34:14 | step: 323500 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 2.827615026035346e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.88 | consumed tokens: 2650112000.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T23:34:34 | step: 323600 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 2.8264883439987898e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.33 | consumed tokens: 2650931200.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T23:34:55 | step: 323700 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.825361480063293e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.06 | consumed tokens: 2651750400.0 | grad norm avg: 0.91 | grad norm last: 1.0 | 
2026-01-01T23:35:15 | step: 323800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.8242346161277965e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.84 | consumed tokens: 2652569600.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T23:35:36 | step: 323900 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.8231075702933595e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.67 | consumed tokens: 2653388800.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T23:35:56 | step: 324000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.8219805244589224e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.56 | consumed tokens: 2654208000.0 | grad norm avg: 0.9 | grad norm last: 0.85 | 
2026-01-01T23:36:16 | step: 324100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.8208534786244854e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.72 | consumed tokens: 2655027200.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T23:36:37 | step: 324200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.819726250891108e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.0 | consumed tokens: 2655846400.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T23:36:57 | step: 324300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.8185990231577307e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.06 | consumed tokens: 2656665600.0 | grad norm avg: 0.92 | grad norm last: 0.84 | 
2026-01-01T23:37:18 | step: 324400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.8174717954243533e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.52 | consumed tokens: 2657484800.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T23:37:38 | step: 324500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.8163443857920356e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.53 | consumed tokens: 2658304000.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T23:37:59 | step: 324600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.815216976159718e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.75 | consumed tokens: 2659123200.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-01T23:38:19 | step: 324700 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.8140895665274e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.2 | consumed tokens: 2659942400.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-01T23:38:40 | step: 324800 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 2.812961974996142e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.5 | consumed tokens: 2660761600.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T23:39:00 | step: 324900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.811834383464884e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.66 | consumed tokens: 2661580800.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T23:39:21 | step: 325000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.8107066100346856e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.42 | consumed tokens: 2662400000.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T23:39:43 | step: 325100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.809578836604487e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.78 | consumed tokens: 2663219200.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T23:40:04 | step: 325200 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 2.8084510631742887e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.83 | consumed tokens: 2664038400.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T23:40:24 | step: 325300 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 2.8073232897440903e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.78 | consumed tokens: 2664857600.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-01T23:40:45 | step: 325400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.8061953344149515e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.34 | consumed tokens: 2665676800.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T23:41:05 | step: 325500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.8050671971868724e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.19 | consumed tokens: 2666496000.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T23:41:26 | step: 325600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.8039392418577336e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.47 | consumed tokens: 2667315200.0 | grad norm avg: 0.93 | grad norm last: 0.85 | 
2026-01-01T23:41:46 | step: 325700 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.8028111046296544e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.73 | consumed tokens: 2668134400.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-01T23:42:07 | step: 325800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.8016829674015753e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.12 | consumed tokens: 2668953600.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-01T23:42:27 | step: 325900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.8005546482745558e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.88 | consumed tokens: 2669772800.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-01T23:42:48 | step: 326000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.7994263291475363e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.8 | consumed tokens: 2670592000.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T23:43:08 | step: 326100 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 2.7982980100205168e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.78 | consumed tokens: 2671411200.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T23:43:29 | step: 326200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.797169508994557e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.41 | consumed tokens: 2672230400.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-01T23:43:49 | step: 326300 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.796041007968597e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.73 | consumed tokens: 2673049600.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T23:44:10 | step: 326400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.7949125069426373e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.97 | consumed tokens: 2673868800.0 | grad norm avg: 0.91 | grad norm last: 1.02 | 
2026-01-01T23:44:30 | step: 326500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.793783824017737e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.91 | consumed tokens: 2674688000.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-01T23:44:51 | step: 326600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.792655141092837e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.28 | consumed tokens: 2675507200.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T23:45:11 | step: 326700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.7915264581679367e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.23 | consumed tokens: 2676326400.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-01T23:45:32 | step: 326800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.790397593344096e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.2 | consumed tokens: 2677145600.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-01T23:45:52 | step: 326900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.7892687285202555e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.17 | consumed tokens: 2677964800.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-01T23:46:12 | step: 327000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.788139863696415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.92 | consumed tokens: 2678784000.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T23:46:33 | step: 327100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.787010816973634e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.25 | consumed tokens: 2679603200.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-01T23:46:53 | step: 327200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.785881770250853e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.55 | consumed tokens: 2680422400.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T23:47:14 | step: 327300 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.7847527235280722e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.47 | consumed tokens: 2681241600.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T23:47:35 | step: 327400 | train samples/s: 82.9 | train mfu (16-bit): -1.0 | lr mean: 2.7836236768052913e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.16 | consumed tokens: 2682060800.0 | grad norm avg: 0.92 | grad norm last: 0.99 | 
2026-01-01T23:47:55 | step: 327500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.78249444818357e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.8 | consumed tokens: 2682880000.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-01T23:48:16 | step: 327600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.7813650376629084e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.11 | consumed tokens: 2683699200.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-01T23:48:36 | step: 327700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.780235809041187e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.58 | consumed tokens: 2684518400.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-01T23:48:57 | step: 327800 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.7791063985205255e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.25 | consumed tokens: 2685337600.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T23:49:17 | step: 327900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.777976987999864e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.94 | consumed tokens: 2686156800.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T23:49:37 | step: 328000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.776847395580262e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.42 | consumed tokens: 2686976000.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-01T23:49:58 | step: 328100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.7757179850596003e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.14 | consumed tokens: 2687795200.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T23:50:18 | step: 328200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.7745883926399983e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.81 | consumed tokens: 2688614400.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T23:50:39 | step: 328300 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.773458618321456e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.59 | consumed tokens: 2689433600.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T23:50:59 | step: 328400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.7723288440029137e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.94 | consumed tokens: 2690252800.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-01T23:51:20 | step: 328500 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.7711990696843714e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.97 | consumed tokens: 2691072000.0 | grad norm avg: 0.92 | grad norm last: 1.1 | 
2026-01-01T23:51:40 | step: 328600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.770069295365829e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.22 | consumed tokens: 2691891200.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-01T23:52:01 | step: 328700 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 2.7689393391483463e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 3.17 | consumed tokens: 2692710400.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-01T23:52:21 | step: 328800 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 2.7678093829308636e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.59 | consumed tokens: 2693529600.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-01T23:52:42 | step: 328900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.766679426713381e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.62 | consumed tokens: 2694348800.0 | grad norm avg: 0.92 | grad norm last: 0.98 | 
2026-01-01T23:53:02 | step: 329000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.7655494704958983e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.73 | consumed tokens: 2695168000.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-01T23:53:23 | step: 329100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.7644193323794752e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.53 | consumed tokens: 2695987200.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-01T23:53:43 | step: 329200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.7632891942630522e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.36 | consumed tokens: 2696806400.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-01T23:54:04 | step: 329300 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 2.7621588742476888e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.81 | consumed tokens: 2697625600.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T23:54:24 | step: 329400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.7610285542323254e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.23 | consumed tokens: 2698444800.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T23:54:44 | step: 329500 | train samples/s: 85.2 | train mfu (16-bit): -1.0 | lr mean: 2.759898234216962e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.97 | consumed tokens: 2699264000.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T23:55:05 | step: 329600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.7587679142015986e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.69 | consumed tokens: 2700083200.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-01T23:55:25 | step: 329700 | train samples/s: 85.2 | train mfu (16-bit): -1.0 | lr mean: 2.7576375941862352e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.84 | consumed tokens: 2700902400.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T23:55:46 | step: 329800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.7565070922719315e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.39 | consumed tokens: 2701721600.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-01T23:56:06 | step: 329900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.7553764084586874e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.31 | consumed tokens: 2702540800.0 | grad norm avg: 0.92 | grad norm last: 0.86 | 
2026-01-01T23:56:26 | step: 330000 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 2.7542459065443836e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.22 | consumed tokens: 2703360000.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T23:56:49 | step: 330100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.7531152227311395e-05 | peak memory rank 0 (MB): 4524.28 | train loss avg: 3.04 | train loss last: 4.0 | consumed tokens: 2704179200.0 | grad norm avg: 0.91 | grad norm last: 0.96 | 
2026-01-01T23:57:09 | step: 330200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.7519845389178954e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.91 | consumed tokens: 2704998400.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-01T23:57:30 | step: 330300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.7508538551046513e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.48 | consumed tokens: 2705817600.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T23:57:50 | step: 330400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.749722989392467e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.72 | consumed tokens: 2706636800.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-01T23:58:11 | step: 330500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.7485921236802824e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.05 | consumed tokens: 2707456000.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-01T23:58:31 | step: 330600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.747461257968098e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.5 | consumed tokens: 2708275200.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-01T23:58:52 | step: 330700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.7463303922559135e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.19 | consumed tokens: 2709094400.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-01T23:59:12 | step: 330800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.7451993446447887e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.84 | consumed tokens: 2709913600.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-01T23:59:32 | step: 330900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.744068297033664e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.86 | consumed tokens: 2710732800.0 | grad norm avg: 0.92 | grad norm last: 0.94 | 
2026-01-01T23:59:53 | step: 331000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.742937249422539e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.14 | consumed tokens: 2711552000.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-02T00:00:13 | step: 331100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.741806019912474e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.17 | consumed tokens: 2712371200.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-02T00:00:34 | step: 331200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.7406747904024087e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.09 | consumed tokens: 2713190400.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-02T00:00:54 | step: 331300 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.7395435608923435e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.17 | consumed tokens: 2714009600.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-02T00:01:15 | step: 331400 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 2.7384123313822784e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.53 | consumed tokens: 2714828800.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-02T00:01:36 | step: 331500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.7372809199732728e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.08 | consumed tokens: 2715648000.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-02T00:01:56 | step: 331600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.7361495085642673e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.86 | consumed tokens: 2716467200.0 | grad norm avg: 0.93 | grad norm last: 1.08 | 
2026-01-02T00:02:17 | step: 331700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.7350180971552618e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.94 | consumed tokens: 2717286400.0 | grad norm avg: 0.92 | grad norm last: 1.01 | 
2026-01-02T00:02:37 | step: 331800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.7338866857462563e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.34 | consumed tokens: 2718105600.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-02T00:02:57 | step: 331900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.7327550924383104e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 2.47 | consumed tokens: 2718924800.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-02T00:03:18 | step: 332000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.7316234991303645e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.16 | consumed tokens: 2719744000.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-02T00:03:38 | step: 332100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.7304919058224186e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.45 | consumed tokens: 2720563200.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T00:03:59 | step: 332200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.7293601306155324e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.25 | consumed tokens: 2721382400.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-02T00:04:19 | step: 332300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.728228355408646e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.67 | consumed tokens: 2722201600.0 | grad norm avg: 0.92 | grad norm last: 1.08 | 
2026-01-02T00:04:40 | step: 332400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.72709658020176e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.73 | consumed tokens: 2723020800.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-02T00:05:00 | step: 332500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.7259648049948737e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.33 | consumed tokens: 2723840000.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-02T00:05:21 | step: 332600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.7248330297879875e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.89 | consumed tokens: 2724659200.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-02T00:05:41 | step: 332700 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 2.723701072682161e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.25 | consumed tokens: 2725478400.0 | grad norm avg: 0.92 | grad norm last: 0.94 | 
2026-01-02T00:06:02 | step: 332800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.7225691155763343e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.73 | consumed tokens: 2726297600.0 | grad norm avg: 0.92 | grad norm last: 0.94 | 
2026-01-02T00:06:22 | step: 332900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.7214371584705077e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.89 | consumed tokens: 2727116800.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-02T00:06:43 | step: 333000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.7203050194657408e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.09 | consumed tokens: 2727936000.0 | grad norm avg: 0.91 | grad norm last: 0.98 | 
2026-01-02T00:07:03 | step: 333100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.7191728804609738e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.2 | consumed tokens: 2728755200.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-02T00:07:23 | step: 333200 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.718040741456207e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.34 | consumed tokens: 2729574400.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-02T00:07:44 | step: 333300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.71690860245144e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.73 | consumed tokens: 2730393600.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-02T00:08:04 | step: 333400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.7157762815477327e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.66 | consumed tokens: 2731212800.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-02T00:08:25 | step: 333500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.7146441425429657e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.8 | consumed tokens: 2732032000.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-02T00:08:45 | step: 333600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.7135118216392584e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.99 | train loss last: 2.81 | consumed tokens: 2732851200.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-02T00:09:06 | step: 333700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.712379500735551e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.73 | consumed tokens: 2733670400.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-02T00:09:26 | step: 333800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.7112469979329035e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.91 | consumed tokens: 2734489600.0 | grad norm avg: 0.92 | grad norm last: 0.86 | 
2026-01-02T00:09:47 | step: 333900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.7101144951302558e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.06 | consumed tokens: 2735308800.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-02T00:10:07 | step: 334000 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 2.708981992327608e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.17 | consumed tokens: 2736128000.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-02T00:10:28 | step: 334100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.7078494895249605e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.62 | consumed tokens: 2736947200.0 | grad norm avg: 0.92 | grad norm last: 0.83 | 
2026-01-02T00:10:48 | step: 334200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.706716986722313e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.3 | consumed tokens: 2737766400.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-02T00:11:09 | step: 334300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.705584302020725e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.64 | consumed tokens: 2738585600.0 | grad norm avg: 0.92 | grad norm last: 0.99 | 
2026-01-02T00:11:29 | step: 334400 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.704451617319137e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.16 | consumed tokens: 2739404800.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-02T00:11:50 | step: 334500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.703318932617549e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.95 | consumed tokens: 2740224000.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-02T00:12:10 | step: 334600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.702186247915961e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.16 | consumed tokens: 2741043200.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-02T00:12:31 | step: 334700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.7010533813154325e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.19 | consumed tokens: 2741862400.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-02T00:12:51 | step: 334800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.6999206966138445e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.2 | consumed tokens: 2742681600.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-02T00:13:12 | step: 334900 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.698787830013316e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.27 | consumed tokens: 2743500800.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-02T00:13:32 | step: 335000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.6976547815138474e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.27 | consumed tokens: 2744320000.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-02T00:13:54 | step: 335100 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.696521914913319e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.8 | consumed tokens: 2745139200.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-02T00:14:15 | step: 335200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.6953888664138503e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.75 | consumed tokens: 2745958400.0 | grad norm avg: 0.92 | grad norm last: 0.85 | 
2026-01-02T00:14:35 | step: 335300 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 2.6942558179143816e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.09 | consumed tokens: 2746777600.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-02T00:14:56 | step: 335400 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.693122769414913e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.02 | consumed tokens: 2747596800.0 | grad norm avg: 0.91 | grad norm last: 0.84 | 
2026-01-02T00:15:16 | step: 335500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.6919897209154442e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.86 | consumed tokens: 2748416000.0 | grad norm avg: 0.93 | grad norm last: 0.97 | 
2026-01-02T00:15:37 | step: 335600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.690856490517035e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.03 | consumed tokens: 2749235200.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-02T00:15:57 | step: 335700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.6897234420175664e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.2 | consumed tokens: 2750054400.0 | grad norm avg: 0.92 | grad norm last: 0.96 | 
2026-01-02T00:16:18 | step: 335800 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.6885902116191573e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.3 | consumed tokens: 2750873600.0 | grad norm avg: 0.92 | grad norm last: 0.85 | 
2026-01-02T00:16:38 | step: 335900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.687456799321808e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.59 | consumed tokens: 2751692800.0 | grad norm avg: 0.92 | grad norm last: 0.96 | 
2026-01-02T00:16:58 | step: 336000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.686323568923399e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.2 | consumed tokens: 2752512000.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-02T00:17:19 | step: 336100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.6851901566260494e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.28 | consumed tokens: 2753331200.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-02T00:17:39 | step: 336200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.6840569262276404e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.91 | consumed tokens: 2754150400.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-02T00:18:00 | step: 336300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.682923513930291e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.77 | consumed tokens: 2754969600.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-02T00:18:20 | step: 336400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.681789919734001e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.39 | consumed tokens: 2755788800.0 | grad norm avg: 0.91 | grad norm last: 0.87 | 
2026-01-02T00:18:41 | step: 336500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.6806565074366517e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.08 | consumed tokens: 2756608000.0 | grad norm avg: 0.92 | grad norm last: 0.94 | 
2026-01-02T00:19:01 | step: 336600 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 2.679522913240362e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.98 | consumed tokens: 2757427200.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-02T00:19:22 | step: 336700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.6783893190440722e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.34 | consumed tokens: 2758246400.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-02T00:19:42 | step: 336800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.6772557248477824e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.36 | consumed tokens: 2759065600.0 | grad norm avg: 0.91 | grad norm last: 0.96 | 
2026-01-02T00:20:03 | step: 336900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.6761221306514926e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.97 | consumed tokens: 2759884800.0 | grad norm avg: 0.92 | grad norm last: 0.96 | 
2026-01-02T00:20:23 | step: 337000 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.674988536455203e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 2.97 | consumed tokens: 2760704000.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-02T00:20:44 | step: 337100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.6738547603599727e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.81 | consumed tokens: 2761523200.0 | grad norm avg: 0.92 | grad norm last: 1.0 | 
2026-01-02T00:21:04 | step: 337200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.6727209842647426e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.64 | consumed tokens: 2762342400.0 | grad norm avg: 0.92 | grad norm last: 0.94 | 
2026-01-02T00:21:25 | step: 337300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.6715872081695125e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.73 | consumed tokens: 2763161600.0 | grad norm avg: 0.92 | grad norm last: 0.84 | 
2026-01-02T00:21:45 | step: 337400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.6704534320742823e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.95 | consumed tokens: 2763980800.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-02T00:22:06 | step: 337500 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 2.6693196559790522e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 4.06 | consumed tokens: 2764800000.0 | grad norm avg: 0.92 | grad norm last: 0.8 | 
2026-01-02T00:22:26 | step: 337600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.6681856979848817e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.92 | consumed tokens: 2765619200.0 | grad norm avg: 0.91 | grad norm last: 0.96 | 
2026-01-02T00:22:46 | step: 337700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.6670517399907112e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.66 | consumed tokens: 2766438400.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-02T00:23:07 | step: 337800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.6659177819965407e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.12 | consumed tokens: 2767257600.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-02T00:23:28 | step: 337900 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 2.6647838240023702e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.98 | consumed tokens: 2768076800.0 | grad norm avg: 0.93 | grad norm last: 0.85 | 
2026-01-02T00:23:48 | step: 338000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.6636498660081998e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.58 | consumed tokens: 2768896000.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-02T00:24:08 | step: 338100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.662515726115089e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.62 | consumed tokens: 2769715200.0 | grad norm avg: 0.93 | grad norm last: 0.88 | 
2026-01-02T00:24:29 | step: 338200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.6613817681209184e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.98 | consumed tokens: 2770534400.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-02T00:24:49 | step: 338300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.6602476282278076e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.75 | consumed tokens: 2771353600.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-02T00:25:10 | step: 338400 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.6591134883346967e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 2.62 | consumed tokens: 2772172800.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-02T00:25:30 | step: 338500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.6579791665426455e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.47 | consumed tokens: 2772992000.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-02T00:25:51 | step: 338600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.6568450266495347e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.14 | consumed tokens: 2773811200.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-02T00:26:11 | step: 338700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.6557107048574835e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.83 | consumed tokens: 2774630400.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-02T00:26:31 | step: 338800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.6545765649643727e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.2 | consumed tokens: 2775449600.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-02T00:26:52 | step: 338900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.6534422431723215e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.67 | consumed tokens: 2776268800.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-02T00:27:12 | step: 339000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.6523079213802703e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.47 | consumed tokens: 2777088000.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-02T00:27:33 | step: 339100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.6511734176892787e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.55 | consumed tokens: 2777907200.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-02T00:27:54 | step: 339200 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 2.6500390958972275e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.98 | consumed tokens: 2778726400.0 | grad norm avg: 0.92 | grad norm last: 0.94 | 
2026-01-02T00:28:14 | step: 339300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.648904592206236e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.44 | consumed tokens: 2779545600.0 | grad norm avg: 0.93 | grad norm last: 0.99 | 
2026-01-02T00:28:34 | step: 339400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.6477702704141848e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.94 | consumed tokens: 2780364800.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-02T00:28:55 | step: 339500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.6466357667231932e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.98 | consumed tokens: 2781184000.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-02T00:29:15 | step: 339600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.6455010811332613e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.98 | consumed tokens: 2782003200.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-02T00:29:36 | step: 339700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.6443665774422698e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.92 | consumed tokens: 2782822400.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T00:29:56 | step: 339800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.6432320737512782e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.34 | consumed tokens: 2783641600.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-02T00:30:17 | step: 339900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.6420973881613463e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.95 | consumed tokens: 2784460800.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-02T00:30:37 | step: 340000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.6409627025714144e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.75 | consumed tokens: 2785280000.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-02T00:30:59 | step: 340100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.6398280169814825e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.88 | consumed tokens: 2786099200.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-02T00:31:20 | step: 340200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.6386933313915506e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.64 | consumed tokens: 2786918400.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-02T00:31:40 | step: 340300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.6375586458016187e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.94 | consumed tokens: 2787737600.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-02T00:32:00 | step: 340400 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 2.6364239602116868e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.36 | consumed tokens: 2788556800.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-02T00:32:21 | step: 340500 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 2.6352890927228145e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.97 | consumed tokens: 2789376000.0 | grad norm avg: 0.92 | grad norm last: 0.94 | 
2026-01-02T00:32:42 | step: 340600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.6341544071328826e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.5 | consumed tokens: 2790195200.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-02T00:33:02 | step: 340700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.6330195396440104e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.94 | consumed tokens: 2791014400.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-02T00:33:23 | step: 340800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.631884672155138e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.03 | consumed tokens: 2791833600.0 | grad norm avg: 0.92 | grad norm last: 0.94 | 
2026-01-02T00:33:43 | step: 340900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.630749804666266e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.77 | consumed tokens: 2792652800.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-02T00:34:03 | step: 341000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.6296147552784532e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.75 | consumed tokens: 2793472000.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-02T00:34:24 | step: 341100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.628479887789581e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.62 | consumed tokens: 2794291200.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-02T00:34:44 | step: 341200 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 2.6273448384017684e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.12 | consumed tokens: 2795110400.0 | grad norm avg: 0.92 | grad norm last: 0.85 | 
2026-01-02T00:35:05 | step: 341300 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.626209970912896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.17 | consumed tokens: 2795929600.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-02T00:35:25 | step: 341400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.6250749215250835e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.28 | consumed tokens: 2796748800.0 | grad norm avg: 0.92 | grad norm last: 1.05 | 
2026-01-02T00:35:45 | step: 341500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.623939872137271e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.23 | consumed tokens: 2797568000.0 | grad norm avg: 0.92 | grad norm last: 0.85 | 
2026-01-02T00:36:06 | step: 341600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.6228048227494583e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.59 | consumed tokens: 2798387200.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-02T00:36:26 | step: 341700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.6216695914627053e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.89 | consumed tokens: 2799206400.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-02T00:36:47 | step: 341800 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 2.6205345420748927e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.66 | consumed tokens: 2800025600.0 | grad norm avg: 0.91 | grad norm last: 0.92 | 
2026-01-02T00:37:07 | step: 341900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.61939949268708e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.89 | consumed tokens: 2800844800.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-02T00:37:28 | step: 342000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.618264261400327e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.89 | consumed tokens: 2801664000.0 | grad norm avg: 0.93 | grad norm last: 0.97 | 
2026-01-02T00:37:48 | step: 342100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.617129030113574e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.41 | consumed tokens: 2802483200.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-02T00:38:09 | step: 342200 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.615993798826821e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.89 | consumed tokens: 2803302400.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-02T00:38:29 | step: 342300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.6148585675400682e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.03 | consumed tokens: 2804121600.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-02T00:38:50 | step: 342400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.6137233362533152e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.0 | consumed tokens: 2804940800.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-02T00:39:10 | step: 342500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.6125881049665622e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.97 | consumed tokens: 2805760000.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-02T00:39:31 | step: 342600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.611452691780869e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.3 | consumed tokens: 2806579200.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-02T00:39:51 | step: 342700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.610317460494116e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.98 | consumed tokens: 2807398400.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-02T00:40:12 | step: 342800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.6091820473084226e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.77 | consumed tokens: 2808217600.0 | grad norm avg: 0.92 | grad norm last: 0.98 | 
2026-01-02T00:40:32 | step: 342900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.6080466341227293e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.92 | consumed tokens: 2809036800.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-02T00:40:53 | step: 343000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.606911220937036e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.92 | consumed tokens: 2809856000.0 | grad norm avg: 0.92 | grad norm last: 0.98 | 
2026-01-02T00:41:13 | step: 343100 | train samples/s: 83.0 | train mfu (16-bit): -1.0 | lr mean: 2.6057758077513427e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.09 | consumed tokens: 2810675200.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-02T00:41:34 | step: 343200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.6046403945656493e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.05 | consumed tokens: 2811494400.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-02T00:41:54 | step: 343300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.603504981379956e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 2.59 | consumed tokens: 2812313600.0 | grad norm avg: 0.92 | grad norm last: 0.96 | 
2026-01-02T00:42:15 | step: 343400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.6023693862953223e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.48 | consumed tokens: 2813132800.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-02T00:42:35 | step: 343500 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.601233973109629e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.59 | consumed tokens: 2813952000.0 | grad norm avg: 0.92 | grad norm last: 0.99 | 
2026-01-02T00:42:56 | step: 343600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.6000983780249953e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.44 | consumed tokens: 2814771200.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-02T00:43:16 | step: 343700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.5989627829403616e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.99 | train loss last: 2.88 | consumed tokens: 2815590400.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T00:43:36 | step: 343800 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.5978273697546683e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.64 | consumed tokens: 2816409600.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-02T00:43:57 | step: 343900 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 2.5966917746700346e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.75 | consumed tokens: 2817228800.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-02T00:44:17 | step: 344000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.595556179585401e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.72 | consumed tokens: 2818048000.0 | grad norm avg: 0.93 | grad norm last: 0.88 | 
2026-01-02T00:44:38 | step: 344100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.594420402601827e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.31 | consumed tokens: 2818867200.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-02T00:44:58 | step: 344200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.5932848075171933e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.61 | consumed tokens: 2819686400.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-02T00:45:19 | step: 344300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.5921492124325596e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.72 | consumed tokens: 2820505600.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-02T00:45:39 | step: 344400 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 2.5910134354489855e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 3.31 | consumed tokens: 2821324800.0 | grad norm avg: 0.93 | grad norm last: 1.0 | 
2026-01-02T00:46:00 | step: 344500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.589877840364352e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.88 | consumed tokens: 2822144000.0 | grad norm avg: 0.93 | grad norm last: 0.85 | 
2026-01-02T00:46:20 | step: 344600 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.588742063380778e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.42 | consumed tokens: 2822963200.0 | grad norm avg: 0.93 | grad norm last: 0.97 | 
2026-01-02T00:46:41 | step: 344700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.5876062863972038e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.84 | consumed tokens: 2823782400.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-02T00:47:01 | step: 344800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.5864705094136298e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 2.73 | consumed tokens: 2824601600.0 | grad norm avg: 0.93 | grad norm last: 0.88 | 
2026-01-02T00:47:22 | step: 344900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.585334914328996e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.03 | consumed tokens: 2825420800.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-02T00:47:42 | step: 345000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.5841989554464817e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 2.48 | consumed tokens: 2826240000.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-02T00:48:04 | step: 345100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.5830631784629077e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.7 | consumed tokens: 2827059200.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-02T00:48:25 | step: 345200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.5819274014793336e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.3 | consumed tokens: 2827878400.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-02T00:48:45 | step: 345300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.5807916244957596e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.94 | consumed tokens: 2828697600.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-02T00:49:06 | step: 345400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.5796556656132452e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.94 | consumed tokens: 2829516800.0 | grad norm avg: 0.93 | grad norm last: 0.98 | 
2026-01-02T00:49:26 | step: 345500 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.5785198886296712e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.45 | consumed tokens: 2830336000.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-02T00:49:47 | step: 345600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.5773839297471568e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.45 | consumed tokens: 2831155200.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-02T00:50:07 | step: 345700 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 2.5762481527635828e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.47 | consumed tokens: 2831974400.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-02T00:50:28 | step: 345800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.5751121938810684e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.39 | consumed tokens: 2832793600.0 | grad norm avg: 0.93 | grad norm last: 0.97 | 
2026-01-02T00:50:48 | step: 345900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.573976234998554e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.83 | consumed tokens: 2833612800.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-02T00:51:09 | step: 346000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.5728402761160396e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 3.55 | consumed tokens: 2834432000.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-02T00:51:29 | step: 346100 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.5717043172335252e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 2.77 | consumed tokens: 2835251200.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-02T00:51:50 | step: 346200 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.5705683583510108e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 3.12 | consumed tokens: 2836070400.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-02T00:52:10 | step: 346300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.5694323994684964e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.27 | consumed tokens: 2836889600.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-02T00:52:31 | step: 346400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.568296440585982e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.16 | consumed tokens: 2837708800.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-02T00:52:51 | step: 346500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.5671602998045273e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 3.06 | consumed tokens: 2838528000.0 | grad norm avg: 0.93 | grad norm last: 0.88 | 
2026-01-02T00:53:12 | step: 346600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.566024340922013e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.0 | consumed tokens: 2839347200.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-02T00:53:32 | step: 346700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.5648882001405582e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.16 | consumed tokens: 2840166400.0 | grad norm avg: 0.92 | grad norm last: 0.86 | 
2026-01-02T00:53:52 | step: 346800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.5637522412580438e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.02 | consumed tokens: 2840985600.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-02T00:54:13 | step: 346900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.562616100476589e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.03 | consumed tokens: 2841804800.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-02T00:54:34 | step: 347000 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 2.5614801415940747e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.78 | consumed tokens: 2842624000.0 | grad norm avg: 0.93 | grad norm last: 0.88 | 
2026-01-02T00:54:54 | step: 347100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.56034400081262e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.99 | train loss last: 3.27 | consumed tokens: 2843443200.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-02T00:55:15 | step: 347200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.5592078600311652e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.03 | consumed tokens: 2844262400.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-02T00:55:35 | step: 347300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.5580717192497104e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.12 | consumed tokens: 2845081600.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-02T00:55:55 | step: 347400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.5569355784682557e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.97 | consumed tokens: 2845900800.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-02T00:56:16 | step: 347500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.555799437686801e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.34 | consumed tokens: 2846720000.0 | grad norm avg: 0.93 | grad norm last: 0.98 | 
2026-01-02T00:56:36 | step: 347600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.5546632969053462e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.11 | consumed tokens: 2847539200.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-02T00:56:57 | step: 347700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.5535271561238915e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.03 | consumed tokens: 2848358400.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-02T00:57:17 | step: 347800 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.5523910153424367e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.0 | consumed tokens: 2849177600.0 | grad norm avg: 0.92 | grad norm last: 0.99 | 
2026-01-02T00:57:38 | step: 347900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.551254874560982e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.02 | consumed tokens: 2849996800.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-02T00:57:58 | step: 348000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.550118551880587e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.8 | consumed tokens: 2850816000.0 | grad norm avg: 0.93 | grad norm last: 1.0 | 
2026-01-02T00:58:18 | step: 348100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.548982411099132e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.83 | consumed tokens: 2851635200.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-02T00:58:39 | step: 348200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.5478462703176774e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.99 | train loss last: 2.67 | consumed tokens: 2852454400.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-02T00:59:00 | step: 348300 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 2.5467099476372823e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.45 | consumed tokens: 2853273600.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T00:59:20 | step: 348400 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.5455738068558276e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.28 | consumed tokens: 2854092800.0 | grad norm avg: 0.94 | grad norm last: 0.92 | 
2026-01-02T00:59:40 | step: 348500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.5444374841754325e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.62 | consumed tokens: 2854912000.0 | grad norm avg: 0.92 | grad norm last: 0.83 | 
2026-01-02T01:00:01 | step: 348600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.5433013433939777e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.78 | consumed tokens: 2855731200.0 | grad norm avg: 0.93 | grad norm last: 0.84 | 
2026-01-02T01:00:21 | step: 348700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.5421650207135826e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.2 | consumed tokens: 2856550400.0 | grad norm avg: 0.93 | grad norm last: 0.98 | 
2026-01-02T01:00:42 | step: 348800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.5410286980331875e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.03 | consumed tokens: 2857369600.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-02T01:01:02 | step: 348900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.5398925572517328e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.84 | consumed tokens: 2858188800.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-02T01:01:23 | step: 349000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.5387562345713377e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.62 | consumed tokens: 2859008000.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-02T01:01:43 | step: 349100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.5376199118909426e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 2.73 | consumed tokens: 2859827200.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-02T01:02:04 | step: 349200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.5364835892105475e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.06 | consumed tokens: 2860646400.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-02T01:02:24 | step: 349300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.5353472665301524e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.14 | consumed tokens: 2861465600.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-02T01:02:44 | step: 349400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.5342109438497573e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.02 | consumed tokens: 2862284800.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T01:03:05 | step: 349500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.5330746211693622e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 2.88 | consumed tokens: 2863104000.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T01:03:25 | step: 349600 | train samples/s: 83.8 | train mfu (16-bit): -1.0 | lr mean: 2.531938298488967e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.95 | consumed tokens: 2863923200.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-02T01:03:46 | step: 349700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.530801975808572e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.3 | consumed tokens: 2864742400.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-02T01:04:06 | step: 349800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.529665653128177e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 3.22 | consumed tokens: 2865561600.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-02T01:04:27 | step: 349900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.528529330447782e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.77 | consumed tokens: 2866380800.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-02T01:04:47 | step: 350000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.5273930077673867e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.92 | consumed tokens: 2867200000.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-02T01:05:09 | step: 350100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.5262566850869916e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.47 | consumed tokens: 2868019200.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-02T01:05:30 | step: 350200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.5251203624065965e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.7 | consumed tokens: 2868838400.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-02T01:05:50 | step: 350300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.5239840397262014e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.73 | consumed tokens: 2869657600.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-02T01:06:11 | step: 350400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.522847535146866e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.39 | consumed tokens: 2870476800.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-02T01:06:31 | step: 350500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.521711212466471e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.17 | consumed tokens: 2871296000.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-02T01:06:52 | step: 350600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.5205748897860758e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 4.06 | consumed tokens: 2872115200.0 | grad norm avg: 0.93 | grad norm last: 0.87 | 
2026-01-02T01:07:12 | step: 350700 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.5194385671056807e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.97 | consumed tokens: 2872934400.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-02T01:07:33 | step: 350800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.5183020625263453e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.19 | consumed tokens: 2873753600.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-02T01:07:53 | step: 350900 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 2.51716573984595e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.11 | consumed tokens: 2874572800.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-02T01:08:14 | step: 351000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.516029417165555e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.53 | consumed tokens: 2875392000.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-02T01:08:34 | step: 351100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.5148929125862196e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.14 | consumed tokens: 2876211200.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-02T01:08:55 | step: 351200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.5137565899058245e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.08 | train loss last: 3.61 | consumed tokens: 2877030400.0 | grad norm avg: 0.93 | grad norm last: 0.87 | 
2026-01-02T01:09:15 | step: 351300 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.512620085326489e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.42 | consumed tokens: 2877849600.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-02T01:09:36 | step: 351400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.511483762646094e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.45 | consumed tokens: 2878668800.0 | grad norm avg: 0.92 | grad norm last: 1.0 | 
2026-01-02T01:09:56 | step: 351500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.510347439965699e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 3.5 | consumed tokens: 2879488000.0 | grad norm avg: 0.93 | grad norm last: 0.98 | 
2026-01-02T01:10:16 | step: 351600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.5092109353863634e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.53 | consumed tokens: 2880307200.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-02T01:10:37 | step: 351700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.5080746127059683e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.67 | consumed tokens: 2881126400.0 | grad norm avg: 0.92 | grad norm last: 0.94 | 
2026-01-02T01:10:57 | step: 351800 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.506938108126633e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.7 | consumed tokens: 2881945600.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-02T01:11:18 | step: 351900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.5058017854462378e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.88 | consumed tokens: 2882764800.0 | grad norm avg: 0.93 | grad norm last: 0.86 | 
2026-01-02T01:11:38 | step: 352000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.5046652808669023e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.98 | consumed tokens: 2883584000.0 | grad norm avg: 0.93 | grad norm last: 0.86 | 
2026-01-02T01:11:59 | step: 352100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.5035289581865072e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.92 | consumed tokens: 2884403200.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-02T01:12:19 | step: 352200 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 2.502392635506112e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.8 | consumed tokens: 2885222400.0 | grad norm avg: 0.93 | grad norm last: 1.0 | 
2026-01-02T01:12:40 | step: 352300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.5012561309267767e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.67 | consumed tokens: 2886041600.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-02T01:13:00 | step: 352400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.5001198082463816e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 2.83 | consumed tokens: 2886860800.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-02T01:13:21 | step: 352500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.498983303667046e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.99 | train loss last: 3.25 | consumed tokens: 2887680000.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-02T01:13:41 | step: 352600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.497846980986651e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.05 | consumed tokens: 2888499200.0 | grad norm avg: 0.93 | grad norm last: 1.04 | 
2026-01-02T01:14:02 | step: 352700 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.4967104764073156e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.75 | consumed tokens: 2889318400.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-02T01:14:22 | step: 352800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.4955741537269205e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.09 | consumed tokens: 2890137600.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-02T01:14:42 | step: 352900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.4944378310465254e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.27 | consumed tokens: 2890956800.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-02T01:15:03 | step: 353000 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.49330132646719e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.48 | consumed tokens: 2891776000.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-02T01:15:23 | step: 353100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.492165003786795e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.99 | train loss last: 3.14 | consumed tokens: 2892595200.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-02T01:15:44 | step: 353200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.4910284992074594e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.95 | consumed tokens: 2893414400.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T01:16:04 | step: 353300 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.4898921765270643e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.62 | consumed tokens: 2894233600.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-02T01:16:25 | step: 353400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.4887558538466692e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.0 | consumed tokens: 2895052800.0 | grad norm avg: 0.94 | grad norm last: 1.03 | 
2026-01-02T01:16:45 | step: 353500 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 2.4876193492673337e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.62 | consumed tokens: 2895872000.0 | grad norm avg: 0.92 | grad norm last: 0.83 | 
2026-01-02T01:17:06 | step: 353600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.4864830265869386e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.3 | consumed tokens: 2896691200.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T01:17:26 | step: 353700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.4853467039065436e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.61 | consumed tokens: 2897510400.0 | grad norm avg: 0.93 | grad norm last: 0.99 | 
2026-01-02T01:17:47 | step: 353800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.484210199327208e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.52 | consumed tokens: 2898329600.0 | grad norm avg: 0.92 | grad norm last: 0.98 | 
2026-01-02T01:18:07 | step: 353900 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.483073876646813e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.99 | train loss last: 2.69 | consumed tokens: 2899148800.0 | grad norm avg: 0.92 | grad norm last: 0.96 | 
2026-01-02T01:18:28 | step: 354000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.481937553966418e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 4.0 | consumed tokens: 2899968000.0 | grad norm avg: 0.93 | grad norm last: 0.86 | 
2026-01-02T01:18:48 | step: 354100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.4808012312860228e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.36 | consumed tokens: 2900787200.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-02T01:19:09 | step: 354200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.4796647267066874e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.75 | consumed tokens: 2901606400.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-02T01:19:29 | step: 354300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.4785284040262923e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.42 | consumed tokens: 2902425600.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-02T01:19:50 | step: 354400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.477392081345897e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.23 | consumed tokens: 2903244800.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-02T01:20:10 | step: 354500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.476255758665502e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.91 | consumed tokens: 2904064000.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T01:20:30 | step: 354600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.475119435985107e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.84 | consumed tokens: 2904883200.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-02T01:20:51 | step: 354700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.473983113304712e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.7 | consumed tokens: 2905702400.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-02T01:21:12 | step: 354800 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 2.4728467906243168e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.77 | consumed tokens: 2906521600.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-02T01:21:32 | step: 354900 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 2.4717104679439217e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.92 | consumed tokens: 2907340800.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-02T01:21:53 | step: 355000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.4705741452635266e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.56 | consumed tokens: 2908160000.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-02T01:22:15 | step: 355100 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.4694378225831315e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.73 | consumed tokens: 2908979200.0 | grad norm avg: 0.93 | grad norm last: 0.88 | 
2026-01-02T01:22:35 | step: 355200 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.4683014999027364e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.7 | consumed tokens: 2909798400.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T01:22:56 | step: 355300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.4671651772223413e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.09 | train loss last: 2.92 | consumed tokens: 2910617600.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-02T01:23:16 | step: 355400 | train samples/s: 84.1 | train mfu (16-bit): -1.0 | lr mean: 2.4660288545419462e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.06 | consumed tokens: 2911436800.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-02T01:23:37 | step: 355500 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.4648927137604915e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.7 | consumed tokens: 2912256000.0 | grad norm avg: 0.92 | grad norm last: 0.99 | 
2026-01-02T01:23:57 | step: 355600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.4637563910800964e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.73 | consumed tokens: 2913075200.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-02T01:24:17 | step: 355700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.4626200683997013e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.86 | consumed tokens: 2913894400.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-02T01:24:38 | step: 355800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.4614839276182465e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.27 | consumed tokens: 2914713600.0 | grad norm avg: 0.93 | grad norm last: 0.97 | 
2026-01-02T01:24:58 | step: 355900 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.4603476049378514e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 3.3 | consumed tokens: 2915532800.0 | grad norm avg: 0.93 | grad norm last: 0.99 | 
2026-01-02T01:25:19 | step: 356000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.4592114641563967e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.53 | consumed tokens: 2916352000.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-02T01:25:40 | step: 356100 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 2.4580751414760016e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.36 | consumed tokens: 2917171200.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-02T01:26:00 | step: 356200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.456939000694547e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.95 | consumed tokens: 2917990400.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-02T01:26:21 | step: 356300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.4558026780141518e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.92 | consumed tokens: 2918809600.0 | grad norm avg: 0.93 | grad norm last: 1.0 | 
2026-01-02T01:26:41 | step: 356400 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.454666537232697e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.33 | consumed tokens: 2919628800.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-02T01:27:02 | step: 356500 | train samples/s: 84.2 | train mfu (16-bit): -1.0 | lr mean: 2.4535303964512423e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.89 | consumed tokens: 2920448000.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-02T01:27:22 | step: 356600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.4523940737708472e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.42 | consumed tokens: 2921267200.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T01:27:43 | step: 356700 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.4512579329893924e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 3.77 | consumed tokens: 2922086400.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T01:28:03 | step: 356800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.4501217922079377e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.33 | consumed tokens: 2922905600.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-02T01:28:23 | step: 356900 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.448985651426483e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.39 | consumed tokens: 2923724800.0 | grad norm avg: 0.92 | grad norm last: 0.84 | 
2026-01-02T01:28:44 | step: 357000 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.4478495106450282e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.8 | consumed tokens: 2924544000.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-02T01:29:04 | step: 357100 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.4467133698635735e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.34 | consumed tokens: 2925363200.0 | grad norm avg: 0.94 | grad norm last: 1.03 | 
2026-01-02T01:29:25 | step: 357200 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.4455772290821187e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.41 | consumed tokens: 2926182400.0 | grad norm avg: 0.93 | grad norm last: 0.86 | 
2026-01-02T01:29:45 | step: 357300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.4444412701996043e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.55 | consumed tokens: 2927001600.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-02T01:30:06 | step: 357400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.4433051294181496e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.7 | consumed tokens: 2927820800.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-02T01:30:27 | step: 357500 | train samples/s: 82.9 | train mfu (16-bit): -1.0 | lr mean: 2.442168988636695e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.83 | consumed tokens: 2928640000.0 | grad norm avg: 0.93 | grad norm last: 0.98 | 
2026-01-02T01:30:47 | step: 357600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.4410330297541805e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.59 | consumed tokens: 2929459200.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T01:31:08 | step: 357700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.4398968889727257e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.14 | consumed tokens: 2930278400.0 | grad norm avg: 0.93 | grad norm last: 0.97 | 
2026-01-02T01:31:28 | step: 357800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.4387609300902113e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.98 | train loss last: 3.16 | consumed tokens: 2931097600.0 | grad norm avg: 0.93 | grad norm last: 0.98 | 
2026-01-02T01:31:48 | step: 357900 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 2.4376247893087566e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.48 | consumed tokens: 2931916800.0 | grad norm avg: 0.94 | grad norm last: 0.89 | 
2026-01-02T01:32:09 | step: 358000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.4364888304262422e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.16 | consumed tokens: 2932736000.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-02T01:32:29 | step: 358100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.4353528715437278e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.89 | consumed tokens: 2933555200.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-02T01:32:50 | step: 358200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.4342169126612134e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.22 | consumed tokens: 2934374400.0 | grad norm avg: 0.92 | grad norm last: 0.99 | 
2026-01-02T01:33:10 | step: 358300 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.433080953778699e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.86 | consumed tokens: 2935193600.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-02T01:33:30 | step: 358400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.4319449948961847e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.23 | consumed tokens: 2936012800.0 | grad norm avg: 0.92 | grad norm last: 1.0 | 
2026-01-02T01:33:51 | step: 358500 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.4308090360136703e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.83 | consumed tokens: 2936832000.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T01:34:11 | step: 358600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.429673077131156e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.98 | consumed tokens: 2937651200.0 | grad norm avg: 0.92 | grad norm last: 1.01 | 
2026-01-02T01:34:32 | step: 358700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.4285371182486415e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.11 | consumed tokens: 2938470400.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-02T01:34:53 | step: 358800 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 2.427401159366127e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 3.06 | consumed tokens: 2939289600.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-02T01:35:13 | step: 358900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.426265382382553e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 1.99 | consumed tokens: 2940108800.0 | grad norm avg: 0.94 | grad norm last: 0.97 | 
2026-01-02T01:35:33 | step: 359000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.4251294235000387e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.52 | consumed tokens: 2940928000.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T01:35:54 | step: 359100 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.4239936465164647e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.8 | consumed tokens: 2941747200.0 | grad norm avg: 0.94 | grad norm last: 0.94 | 
2026-01-02T01:36:14 | step: 359200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.4228578695328906e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.11 | consumed tokens: 2942566400.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-02T01:36:35 | step: 359300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.4217219106503762e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.39 | consumed tokens: 2943385600.0 | grad norm avg: 0.92 | grad norm last: 0.86 | 
2026-01-02T01:36:55 | step: 359400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.4205861336668022e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.06 | consumed tokens: 2944204800.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T01:37:16 | step: 359500 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.419450356683228e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.88 | consumed tokens: 2945024000.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-02T01:37:36 | step: 359600 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.418314579699654e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.12 | consumed tokens: 2945843200.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-02T01:37:56 | step: 359700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.41717880271608e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.98 | consumed tokens: 2946662400.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-02T01:38:17 | step: 359800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.4160432076314464e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.0 | consumed tokens: 2947481600.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-02T01:38:37 | step: 359900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.4149074306478724e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.11 | consumed tokens: 2948300800.0 | grad norm avg: 0.94 | grad norm last: 0.94 | 
2026-01-02T01:38:58 | step: 360000 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.4137716536642984e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.64 | consumed tokens: 2949120000.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-02T01:39:20 | step: 360100 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 2.4126360585796647e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.47 | consumed tokens: 2949939200.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-02T01:39:41 | step: 360200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.411500463495031e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.27 | consumed tokens: 2950758400.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-02T01:40:01 | step: 360300 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.410364686511457e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.39 | consumed tokens: 2951577600.0 | grad norm avg: 0.93 | grad norm last: 0.88 | 
2026-01-02T01:40:21 | step: 360400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.4092290914268233e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.11 | consumed tokens: 2952396800.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-02T01:40:42 | step: 360500 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.4080934963421896e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.36 | consumed tokens: 2953216000.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-02T01:41:02 | step: 360600 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.406957901257556e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.25 | consumed tokens: 2954035200.0 | grad norm avg: 0.93 | grad norm last: 0.97 | 
2026-01-02T01:41:23 | step: 360700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.4058224880718626e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.3 | consumed tokens: 2954854400.0 | grad norm avg: 0.93 | grad norm last: 0.86 | 
2026-01-02T01:41:43 | step: 360800 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.404686892987229e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.89 | consumed tokens: 2955673600.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-02T01:42:04 | step: 360900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.4035512979025953e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.44 | consumed tokens: 2956492800.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-02T01:42:24 | step: 361000 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 2.402415884716902e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.52 | consumed tokens: 2957312000.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-02T01:42:44 | step: 361100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.4012802896322682e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.89 | consumed tokens: 2958131200.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T01:43:05 | step: 361200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.400144876446575e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.48 | consumed tokens: 2958950400.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-02T01:43:25 | step: 361300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.3990094632608816e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.07 | train loss last: 2.89 | consumed tokens: 2959769600.0 | grad norm avg: 0.93 | grad norm last: 0.88 | 
2026-01-02T01:43:46 | step: 361400 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 2.3978740500751883e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.3 | consumed tokens: 2960588800.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-02T01:44:06 | step: 361500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.396738636889495e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.61 | consumed tokens: 2961408000.0 | grad norm avg: 0.93 | grad norm last: 0.98 | 
2026-01-02T01:44:27 | step: 361600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.3956032237038016e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.99 | train loss last: 2.52 | consumed tokens: 2962227200.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-02T01:44:47 | step: 361700 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.3944679924170487e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 2.59 | consumed tokens: 2963046400.0 | grad norm avg: 0.93 | grad norm last: 1.07 | 
2026-01-02T01:45:08 | step: 361800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.3933325792313553e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.11 | consumed tokens: 2963865600.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-02T01:45:28 | step: 361900 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.3921973479446024e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 4.16 | consumed tokens: 2964684800.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-02T01:45:48 | step: 362000 | train samples/s: 85.2 | train mfu (16-bit): -1.0 | lr mean: 2.391061934758909e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.95 | consumed tokens: 2965504000.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-02T01:46:09 | step: 362100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.389926703472156e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 3.14 | consumed tokens: 2966323200.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-02T01:46:29 | step: 362200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.388791472185403e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.95 | consumed tokens: 2967142400.0 | grad norm avg: 0.93 | grad norm last: 1.02 | 
2026-01-02T01:46:50 | step: 362300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.38765624089865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.99 | train loss last: 2.8 | consumed tokens: 2967961600.0 | grad norm avg: 0.93 | grad norm last: 0.88 | 
2026-01-02T01:47:10 | step: 362400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.3865211915108375e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.47 | consumed tokens: 2968780800.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T01:47:30 | step: 362500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.3853859602240846e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.92 | consumed tokens: 2969600000.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-02T01:47:51 | step: 362600 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.3842507289373316e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.78 | consumed tokens: 2970419200.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-02T01:48:12 | step: 362700 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 2.383115679549519e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.44 | consumed tokens: 2971238400.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-02T01:48:32 | step: 362800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.3819806301617064e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.03 | consumed tokens: 2972057600.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-02T01:48:52 | step: 362900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.3808455807738937e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.99 | train loss last: 2.45 | consumed tokens: 2972876800.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-02T01:49:13 | step: 363000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.379710531386081e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.22 | consumed tokens: 2973696000.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-02T01:49:33 | step: 363100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.3785754819982685e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.95 | consumed tokens: 2974515200.0 | grad norm avg: 0.93 | grad norm last: 0.86 | 
2026-01-02T01:49:54 | step: 363200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.377440432610456e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.91 | consumed tokens: 2975334400.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-02T01:50:14 | step: 363300 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.3763055651215836e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.77 | consumed tokens: 2976153600.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-02T01:50:35 | step: 363400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.375170515733771e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.47 | consumed tokens: 2976972800.0 | grad norm avg: 0.93 | grad norm last: 0.87 | 
2026-01-02T01:50:55 | step: 363500 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 2.3740356482448988e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.38 | consumed tokens: 2977792000.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-02T01:51:15 | step: 363600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.3729007807560265e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.64 | consumed tokens: 2978611200.0 | grad norm avg: 0.93 | grad norm last: 0.98 | 
2026-01-02T01:51:36 | step: 363700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.3717659132671542e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.12 | consumed tokens: 2979430400.0 | grad norm avg: 0.93 | grad norm last: 0.88 | 
2026-01-02T01:51:56 | step: 363800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.370631045778282e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.66 | consumed tokens: 2980249600.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-02T01:52:17 | step: 363900 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.36949636018835e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 2.75 | consumed tokens: 2981068800.0 | grad norm avg: 0.92 | grad norm last: 0.88 | 
2026-01-02T01:52:37 | step: 364000 | train samples/s: 83.4 | train mfu (16-bit): -1.0 | lr mean: 2.3683614926994778e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.47 | consumed tokens: 2981888000.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-02T01:52:58 | step: 364100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.367226807109546e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.66 | consumed tokens: 2982707200.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-02T01:53:18 | step: 364200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.3660919396206737e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.97 | consumed tokens: 2983526400.0 | grad norm avg: 0.92 | grad norm last: 0.94 | 
2026-01-02T01:53:39 | step: 364300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.3649572540307418e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.99 | train loss last: 2.67 | consumed tokens: 2984345600.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-02T01:53:59 | step: 364400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.3638227503397502e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.99 | train loss last: 3.19 | consumed tokens: 2985164800.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-02T01:54:19 | step: 364500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.3626880647498183e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.05 | consumed tokens: 2985984000.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-02T01:54:40 | step: 364600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.3615533791598864e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.3 | consumed tokens: 2986803200.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-02T01:55:00 | step: 364700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.360418875468895e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.91 | consumed tokens: 2987622400.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-02T01:55:21 | step: 364800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.3592843717779033e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.98 | train loss last: 2.73 | consumed tokens: 2988441600.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-02T01:55:41 | step: 364900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.3581498680869117e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.48 | consumed tokens: 2989260800.0 | grad norm avg: 0.93 | grad norm last: 0.98 | 
2026-01-02T01:56:01 | step: 365000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.3570153643959202e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.67 | consumed tokens: 2990080000.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-02T01:56:24 | step: 365100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.3558808607049286e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.72 | consumed tokens: 2990899200.0 | grad norm avg: 0.94 | grad norm last: 0.91 | 
2026-01-02T01:56:44 | step: 365200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.354746357013937e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.67 | consumed tokens: 2991718400.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-02T01:57:05 | step: 365300 | train samples/s: 83.1 | train mfu (16-bit): -1.0 | lr mean: 2.353612035221886e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.81 | consumed tokens: 2992537600.0 | grad norm avg: 0.94 | grad norm last: 1.01 | 
2026-01-02T01:57:25 | step: 365400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.3524777134298347e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.25 | consumed tokens: 2993356800.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-02T01:57:46 | step: 365500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.351343209738843e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.86 | consumed tokens: 2994176000.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-02T01:58:06 | step: 365600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.3502090698457323e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.44 | consumed tokens: 2994995200.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T01:58:26 | step: 365700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.349074748053681e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.77 | consumed tokens: 2995814400.0 | grad norm avg: 0.94 | grad norm last: 0.94 | 
2026-01-02T01:58:47 | step: 365800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.34794042626163e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.03 | consumed tokens: 2996633600.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-02T01:59:07 | step: 365900 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.346806286368519e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.12 | consumed tokens: 2997452800.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-02T01:59:28 | step: 366000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.3456721464754082e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.98 | train loss last: 2.83 | consumed tokens: 2998272000.0 | grad norm avg: 0.94 | grad norm last: 0.95 | 
2026-01-02T01:59:48 | step: 366100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.3445380065822974e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.94 | consumed tokens: 2999091200.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-02T02:00:09 | step: 366200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.3434038666891865e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.64 | consumed tokens: 2999910400.0 | grad norm avg: 0.93 | grad norm last: 0.98 | 
2026-01-02T02:00:29 | step: 366300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.3422697267960757e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 3.03 | consumed tokens: 3000729600.0 | grad norm avg: 0.94 | grad norm last: 0.99 | 
2026-01-02T02:00:50 | step: 366400 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.3411357688019052e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.59 | consumed tokens: 3001548800.0 | grad norm avg: 0.93 | grad norm last: 0.86 | 
2026-01-02T02:01:10 | step: 366500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.3400016289087944e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.14 | consumed tokens: 3002368000.0 | grad norm avg: 0.93 | grad norm last: 0.89 | 
2026-01-02T02:01:31 | step: 366600 | train samples/s: 83.5 | train mfu (16-bit): -1.0 | lr mean: 2.338867670914624e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.42 | consumed tokens: 3003187200.0 | grad norm avg: 0.93 | grad norm last: 0.93 | 
2026-01-02T02:01:51 | step: 366700 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.3377337129204534e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.06 | consumed tokens: 3004006400.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-02T02:02:12 | step: 366800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.3365999368252233e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.52 | consumed tokens: 3004825600.0 | grad norm avg: 0.94 | grad norm last: 0.92 | 
2026-01-02T02:02:32 | step: 366900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.3354659788310528e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.16 | consumed tokens: 3005644800.0 | grad norm avg: 0.95 | grad norm last: 0.91 | 
2026-01-02T02:02:52 | step: 367000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.3343322027358226e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.58 | consumed tokens: 3006464000.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-02T02:03:13 | step: 367100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.3331984266405925e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.94 | consumed tokens: 3007283200.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-02T02:03:33 | step: 367200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.3320646505453624e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.8 | consumed tokens: 3008102400.0 | grad norm avg: 0.94 | grad norm last: 0.89 | 
2026-01-02T02:03:54 | step: 367300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.3309308744501323e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.41 | consumed tokens: 3008921600.0 | grad norm avg: 0.94 | grad norm last: 0.91 | 
2026-01-02T02:04:14 | step: 367400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.329797098354902e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.52 | consumed tokens: 3009740800.0 | grad norm avg: 0.93 | grad norm last: 0.97 | 
2026-01-02T02:04:35 | step: 367500 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.3286635041586123e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.48 | consumed tokens: 3010560000.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-02T02:04:55 | step: 367600 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.3275299099623226e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.95 | consumed tokens: 3011379200.0 | grad norm avg: 0.94 | grad norm last: 0.91 | 
2026-01-02T02:05:16 | step: 367700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.3263963157660328e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.2 | consumed tokens: 3012198400.0 | grad norm avg: 0.94 | grad norm last: 0.95 | 
2026-01-02T02:05:36 | step: 367800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.325262721569743e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.92 | consumed tokens: 3013017600.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-02T02:05:57 | step: 367900 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 2.3241291273734532e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.31 | consumed tokens: 3013836800.0 | grad norm avg: 0.94 | grad norm last: 0.97 | 
2026-01-02T02:06:17 | step: 368000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.3229957150761038e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 1.95 | consumed tokens: 3014656000.0 | grad norm avg: 0.94 | grad norm last: 0.88 | 
2026-01-02T02:06:38 | step: 368100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.3218623027787544e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.89 | consumed tokens: 3015475200.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-02T02:06:58 | step: 368200 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.320728890481405e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.91 | consumed tokens: 3016294400.0 | grad norm avg: 0.93 | grad norm last: 0.84 | 
2026-01-02T02:07:19 | step: 368300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.3195954781840555e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.34 | consumed tokens: 3017113600.0 | grad norm avg: 0.93 | grad norm last: 1.02 | 
2026-01-02T02:07:39 | step: 368400 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.318462065886706e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.98 | train loss last: 2.98 | consumed tokens: 3017932800.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-02T02:07:59 | step: 368500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.317328835488297e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.11 | consumed tokens: 3018752000.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T02:08:20 | step: 368600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.316195605089888e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.42 | consumed tokens: 3019571200.0 | grad norm avg: 0.93 | grad norm last: 0.97 | 
2026-01-02T02:08:40 | step: 368700 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.315062374691479e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.14 | consumed tokens: 3020390400.0 | grad norm avg: 0.94 | grad norm last: 0.92 | 
2026-01-02T02:09:01 | step: 368800 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.31392914429307e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.81 | consumed tokens: 3021209600.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-02T02:09:21 | step: 368900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.312796095793601e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 2.67 | consumed tokens: 3022028800.0 | grad norm avg: 0.93 | grad norm last: 0.95 | 
2026-01-02T02:09:42 | step: 369000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.311662865395192e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.73 | consumed tokens: 3022848000.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-02T02:10:02 | step: 369100 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.3105298168957233e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.91 | consumed tokens: 3023667200.0 | grad norm avg: 0.93 | grad norm last: 0.87 | 
2026-01-02T02:10:23 | step: 369200 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 2.3093967683962546e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.22 | consumed tokens: 3024486400.0 | grad norm avg: 0.93 | grad norm last: 0.97 | 
2026-01-02T02:10:43 | step: 369300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.3082639017957263e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.33 | consumed tokens: 3025305600.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-02T02:11:04 | step: 369400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.3071308532962576e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.67 | consumed tokens: 3026124800.0 | grad norm avg: 0.94 | grad norm last: 1.01 | 
2026-01-02T02:11:24 | step: 369500 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.3059979866957292e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 2.88 | consumed tokens: 3026944000.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-02T02:11:45 | step: 369600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.304865120095201e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 2.8 | consumed tokens: 3027763200.0 | grad norm avg: 0.93 | grad norm last: 0.99 | 
2026-01-02T02:12:05 | step: 369700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.303732435393613e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.99 | train loss last: 2.52 | consumed tokens: 3028582400.0 | grad norm avg: 0.94 | grad norm last: 0.91 | 
2026-01-02T02:12:25 | step: 369800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.3025995687930845e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 3.05 | consumed tokens: 3029401600.0 | grad norm avg: 0.94 | grad norm last: 0.92 | 
2026-01-02T02:12:46 | step: 369900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.3014668840914965e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 2.78 | consumed tokens: 3030220800.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T02:13:06 | step: 370000 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.3003341993899085e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.38 | consumed tokens: 3031040000.0 | grad norm avg: 0.93 | grad norm last: 0.98 | 
2026-01-02T02:13:28 | step: 370100 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.2992015146883205e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.92 | consumed tokens: 3031859200.0 | grad norm avg: 0.93 | grad norm last: 0.87 | 
2026-01-02T02:13:49 | step: 370200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.2980688299867325e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 3.42 | consumed tokens: 3032678400.0 | grad norm avg: 0.93 | grad norm last: 0.87 | 
2026-01-02T02:14:09 | step: 370300 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.2969363271840848e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.62 | consumed tokens: 3033497600.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-02T02:14:30 | step: 370400 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.295803824381437e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.66 | consumed tokens: 3034316800.0 | grad norm avg: 0.94 | grad norm last: 0.91 | 
2026-01-02T02:14:50 | step: 370500 | train samples/s: 83.2 | train mfu (16-bit): -1.0 | lr mean: 2.2946713215787895e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.06 | train loss last: 3.44 | consumed tokens: 3035136000.0 | grad norm avg: 0.93 | grad norm last: 1.0 | 
2026-01-02T02:15:11 | step: 370600 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.293538818776142e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.99 | train loss last: 3.66 | consumed tokens: 3035955200.0 | grad norm avg: 0.94 | grad norm last: 0.89 | 
2026-01-02T02:15:31 | step: 370700 | train samples/s: 84.8 | train mfu (16-bit): -1.0 | lr mean: 2.2924064978724346e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.83 | consumed tokens: 3036774400.0 | grad norm avg: 0.94 | grad norm last: 0.95 | 
2026-01-02T02:15:52 | step: 370800 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.2912741769687273e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.72 | consumed tokens: 3037593600.0 | grad norm avg: 0.94 | grad norm last: 0.95 | 
2026-01-02T02:16:12 | step: 370900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.29014185606502e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 3.91 | consumed tokens: 3038412800.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
2026-01-02T02:16:33 | step: 371000 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.2890095351613127e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.44 | consumed tokens: 3039232000.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-02T02:16:53 | step: 371100 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.2878772142576054e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.27 | consumed tokens: 3040051200.0 | grad norm avg: 0.94 | grad norm last: 0.99 | 
2026-01-02T02:17:13 | step: 371200 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.2867450752528384e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.09 | consumed tokens: 3040870400.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-02T02:17:34 | step: 371300 | train samples/s: 85.1 | train mfu (16-bit): -1.0 | lr mean: 2.2856129362480715e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.05 | train loss last: 3.3 | consumed tokens: 3041689600.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T02:17:54 | step: 371400 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.284480979142245e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.84 | consumed tokens: 3042508800.0 | grad norm avg: 0.94 | grad norm last: 0.92 | 
2026-01-02T02:18:15 | step: 371500 | train samples/s: 85.0 | train mfu (16-bit): -1.0 | lr mean: 2.283348840137478e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 2.55 | consumed tokens: 3043328000.0 | grad norm avg: 0.95 | grad norm last: 0.91 | 
2026-01-02T02:18:35 | step: 371600 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.2822168830316514e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.99 | train loss last: 2.97 | consumed tokens: 3044147200.0 | grad norm avg: 0.94 | grad norm last: 0.9 | 
2026-01-02T02:18:55 | step: 371700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.2810849259258248e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 2.83 | consumed tokens: 3044966400.0 | grad norm avg: 0.94 | grad norm last: 0.87 | 
2026-01-02T02:19:16 | step: 371800 | train samples/s: 83.3 | train mfu (16-bit): -1.0 | lr mean: 2.2799529688199982e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.08 | consumed tokens: 3045785600.0 | grad norm avg: 0.93 | grad norm last: 1.02 | 
2026-01-02T02:19:36 | step: 371900 | train samples/s: 84.9 | train mfu (16-bit): -1.0 | lr mean: 2.278821193613112e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.91 | consumed tokens: 3046604800.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-02T02:19:57 | step: 372000 | train samples/s: 84.4 | train mfu (16-bit): -1.0 | lr mean: 2.2776894184062257e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.95 | consumed tokens: 3047424000.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-02T02:20:17 | step: 372100 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.2765576431993395e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.17 | consumed tokens: 3048243200.0 | grad norm avg: 0.96 | grad norm last: 1.0 | 
2026-01-02T02:20:38 | step: 372200 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.2754258679924533e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.39 | consumed tokens: 3049062400.0 | grad norm avg: 0.93 | grad norm last: 1.01 | 
2026-01-02T02:20:58 | step: 372300 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.274294092785567e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.01 | train loss last: 2.58 | consumed tokens: 3049881600.0 | grad norm avg: 0.94 | grad norm last: 0.96 | 
2026-01-02T02:21:19 | step: 372400 | train samples/s: 84.3 | train mfu (16-bit): -1.0 | lr mean: 2.273162499477621e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.59 | consumed tokens: 3050700800.0 | grad norm avg: 0.95 | grad norm last: 0.97 | 
2026-01-02T02:21:39 | step: 372500 | train samples/s: 84.7 | train mfu (16-bit): -1.0 | lr mean: 2.2720309061696753e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 2.77 | consumed tokens: 3051520000.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-02T02:22:00 | step: 372600 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.2708994947606698e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.02 | train loss last: 2.56 | consumed tokens: 3052339200.0 | grad norm avg: 0.93 | grad norm last: 0.96 | 
2026-01-02T02:22:20 | step: 372700 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.269767901452724e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.0 | train loss last: 2.69 | consumed tokens: 3053158400.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-02T02:22:40 | step: 372800 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.2686364900437184e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.04 | train loss last: 3.2 | consumed tokens: 3053977600.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-02T02:23:01 | step: 372900 | train samples/s: 84.5 | train mfu (16-bit): -1.0 | lr mean: 2.267505078634713e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 2.99 | train loss last: 2.86 | consumed tokens: 3054796800.0 | grad norm avg: 0.94 | grad norm last: 0.93 | 
2026-01-02T02:23:21 | step: 373000 | train samples/s: 84.6 | train mfu (16-bit): -1.0 | lr mean: 2.2663738491246477e-05 | peak memory rank 0 (MB): 3893.84 | train loss avg: 3.03 | train loss last: 3.16 | consumed tokens: 3055616000.0 | grad norm avg: 0.93 | grad norm last: 0.91 | 
