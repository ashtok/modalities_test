==========================================
Experiment 3: Fine-tuning GPT-2 on 5 languages
Job ID: 2149928
Node: jnultra01
Start time: Thu Jan  1 05:44:16 PM CET 2026
==========================================
Thu Jan  1 17:44:17 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.28.03              Driver Version: 560.28.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:CB:00.0 Off |                    0 |
| N/A   34C    P0             70W /  700W |       1MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Rank 0 received experiment_id: 2026-01-01__17-44-31_a91e58afaade00f6
Instantiated <class 'int'>: settings -> training_target -> num_target_tokens
Instantiated <class 'int'>: settings -> training_target -> num_target_steps -> config -> global_num_tokens
Instantiated <class 'int'>: settings -> training_target -> num_target_steps
Instantiated <class 'modalities.models.huggingface.huggingface_model.HuggingFacePretrainedModel'>: model_raw

Wrapped layer classes: [<class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>]

Instantiated <class 'torch.distributed.fsdp.fully_sharded_data_parallel.FullyShardedDataParallel'>: wrapped_model
=> optimizer groups:
all (148 modules with 124,439,808 parameters): weight_decay = 0.01
=> all (148 modules with 124,439,808 parameters)
Instantiated <class 'torch.optim.adamw.AdamW'>: optimizer
Instantiated <class 'int'>: lr_scheduler -> config -> total_steps -> config -> global_num_tokens
Instantiated <class 'int'>: lr_scheduler -> config -> total_steps
Instantiated <class 'torch.optim.lr_scheduler.OneCycleLR'>: lr_scheduler
Instantiated <class 'modalities.checkpointing.stateful.app_state.AppState'>: app_state
Instantiated <class 'modalities.loss_functions.CLMCrossEntropyLoss'>: loss_fn
Instantiated <class 'modalities.dataloader.dataset.PackedMemMapDatasetContinuous'>: train_dataset
Instantiated <class 'modalities.dataloader.samplers.ResumableDistributedSampler'>: train_dataloader -> config -> batch_sampler -> config -> sampler
Instantiated <class 'torch.utils.data.sampler.BatchSampler'>: train_dataloader -> config -> batch_sampler
Instantiated <class 'modalities.models.gpt2.collator.GPT2LLMCollateFn'>: collate_fn
Instantiated <class 'modalities.dataloader.dataloader.LLMDataLoader'>: train_dataloader
Instantiated <class 'int'>: progress_subscriber -> config -> num_target_steps -> config -> global_num_tokens
Instantiated <class 'int'>: progress_subscriber -> config -> num_target_steps
Instantiated <class 'modalities.logging_broker.subscriber_impl.progress_subscriber.RichProgressSubscriber'>: progress_subscriber
Instantiated <class 'modalities.logging_broker.subscriber_impl.results_subscriber.WandBEvaluationResultSubscriber'>: evaluation_subscriber
Instantiated <class 'modalities.checkpointing.checkpoint_saving_strategies.SaveKMostRecentCheckpointsStrategy'>: checkpoint_saving -> config -> checkpoint_saving_strategy
Instantiated <class 'modalities.checkpointing.fsdp.fsdp_checkpoint_saving.FSDP1CheckpointSaving'>: checkpoint_saving -> config -> checkpoint_saving_execution
Instantiated <class 'modalities.checkpointing.checkpoint_saving.CheckpointSaving'>: checkpoint_saving
Instantiated <class 'modalities.training.gradient_clipping.fsdp_gradient_clipper.FSDP1GradientClipper'>: gradient_clipper
Model initialized at 2026-01-01 17:44:35.396476.



======================== Training Report ========================
Training target: 
	num_target_tokens: 5713174528
	num_target_steps: 697409 
Intervals: 
	training_log_interval_in_steps: 100
	checkpointing_interval_in_steps: 5000
	evaluation_interval_in_steps: 1000
Step profile: 
	gradient_accumulation_steps: 4
	local_train_micro_batch_size: 4
	sequence_length: 512
	dp_degree: 1
CUDA environment settings: 
	local_rank: 0
	world_size: 1
	global_rank: 0
Consistency enforcement: 
	enforce_tokens_per_step_consistency: True
	enforce_last_step_logged: False
	enforce_last_step_evaluated: False
	enforce_last_step_checkpointed: False
Training progress: 
	global_num_seen_tokens: 0
	num_seen_steps: 0
	num_seen_samples: 0
	last_step: -1
Warnings: 
	[38;5;214mNumber of tokens in the dataset (5713177600) does not match the number of target tokens (5713174528). Missing 0.00% of tokens in the dataset.
	Last step will not be logged. Since remaining_steps (697409) is not a multiple of training_log_interval_in_steps (100).
	Last step will not be evaluated. Since remaining_steps (697409) is not a multiple of evaluation_interval_in_steps (1000).
	Last step will not be checkpointed. Since remaining_steps (697409) is not a multiple of checkpointing_interval_in_steps (5000). [0m 
====================================================================



Start model training at 2026-01-01 17:44:35.396816.
2026-01-01T17:44:52 | step: 100 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 5.0228313739353325e-06 | peak memory rank 0 (MB): 3941.08 | train loss avg: 4.32 | train loss last: 4.25 | consumed tokens: 819200.0 | grad norm avg: 3.02 | grad norm last: 2.78 | 
2026-01-01T17:45:08 | step: 200 | train samples/s: 103.8 | train mfu (16-bit): -1.0 | lr mean: 5.0912785809487104e-06 | peak memory rank 0 (MB): 3941.08 | train loss avg: 4.27 | train loss last: 4.31 | consumed tokens: 1638400.0 | grad norm avg: 2.73 | grad norm last: 2.54 | 
2026-01-01T17:45:24 | step: 300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.205202796787489e-06 | peak memory rank 0 (MB): 3941.08 | train loss avg: 4.21 | train loss last: 3.59 | consumed tokens: 2457600.0 | grad norm avg: 2.67 | grad norm last: 2.86 | 
2026-01-01T17:45:39 | step: 400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.3643730097974185e-06 | peak memory rank 0 (MB): 3941.08 | train loss avg: 4.18 | train loss last: 4.09 | consumed tokens: 3276800.0 | grad norm avg: 2.61 | grad norm last: 2.66 | 
2026-01-01T17:45:55 | step: 500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.568465894612018e-06 | peak memory rank 0 (MB): 3941.08 | train loss avg: 4.13 | train loss last: 4.06 | consumed tokens: 4096000.0 | grad norm avg: 2.6 | grad norm last: 2.78 | 
2026-01-01T17:46:10 | step: 600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.817067631141981e-06 | peak memory rank 0 (MB): 3941.08 | train loss avg: 4.15 | train loss last: 4.22 | consumed tokens: 4915200.0 | grad norm avg: 2.55 | grad norm last: 2.39 | 
2026-01-01T17:46:25 | step: 700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.109673449827824e-06 | peak memory rank 0 (MB): 3941.08 | train loss avg: 4.11 | train loss last: 3.77 | consumed tokens: 5734400.0 | grad norm avg: 2.57 | grad norm last: 2.76 | 
2026-01-01T17:46:41 | step: 800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 6.445689905376639e-06 | peak memory rank 0 (MB): 3941.08 | train loss avg: 4.11 | train loss last: 4.22 | consumed tokens: 6553600.0 | grad norm avg: 2.57 | grad norm last: 2.46 | 
2026-01-01T17:46:56 | step: 900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.824434422014747e-06 | peak memory rank 0 (MB): 3941.08 | train loss avg: 4.08 | train loss last: 3.78 | consumed tokens: 7372800.0 | grad norm avg: 2.51 | grad norm last: 2.4 | 
2026-01-01T17:47:12 | step: 1000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 7.245138931466499e-06 | peak memory rank 0 (MB): 3941.08 | train loss avg: 4.11 | train loss last: 4.34 | consumed tokens: 8192000.0 | grad norm avg: 2.48 | grad norm last: 2.35 | 
2026-01-01T17:47:27 | step: 1100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 7.706949872954283e-06 | peak memory rank 0 (MB): 3941.08 | train loss avg: 4.07 | train loss last: 4.22 | consumed tokens: 9011200.0 | grad norm avg: 2.47 | grad norm last: 2.48 | 
2026-01-01T17:47:43 | step: 1200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.208928193198517e-06 | peak memory rank 0 (MB): 3941.08 | train loss avg: 4.08 | train loss last: 3.55 | consumed tokens: 9830400.0 | grad norm avg: 2.44 | grad norm last: 2.24 | 
2026-01-01T17:47:58 | step: 1300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 8.75005753186997e-06 | peak memory rank 0 (MB): 3941.08 | train loss avg: 4.05 | train loss last: 3.86 | consumed tokens: 10649600.0 | grad norm avg: 2.43 | grad norm last: 2.37 | 
2026-01-01T17:48:13 | step: 1400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 9.329239219368901e-06 | peak memory rank 0 (MB): 3941.08 | train loss avg: 4.04 | train loss last: 4.78 | consumed tokens: 11468800.0 | grad norm avg: 2.41 | grad norm last: 2.39 | 
2026-01-01T17:48:29 | step: 1500 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 9.945296369551215e-06 | peak memory rank 0 (MB): 3941.08 | train loss avg: 4.01 | train loss last: 4.34 | consumed tokens: 12288000.0 | grad norm avg: 2.37 | grad norm last: 2.32 | 
2026-01-01T17:48:44 | step: 1600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0596980246191379e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 4.08 | train loss last: 4.47 | consumed tokens: 13107200.0 | grad norm avg: 2.37 | grad norm last: 2.39 | 
2026-01-01T17:49:00 | step: 1700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.1282967534498312e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 4.02 | train loss last: 4.19 | consumed tokens: 13926400.0 | grad norm avg: 2.36 | grad norm last: 2.33 | 
2026-01-01T17:49:15 | step: 1800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.20018657980836e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 4.03 | train loss last: 4.0 | consumed tokens: 14745600.0 | grad norm avg: 2.33 | grad norm last: 2.41 | 
2026-01-01T17:49:30 | step: 1900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.2752217116940301e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 4.01 | train loss last: 3.55 | consumed tokens: 15564800.0 | grad norm avg: 2.26 | grad norm last: 2.18 | 
2026-01-01T17:49:46 | step: 2000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.3532498087442946e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.99 | train loss last: 3.78 | consumed tokens: 16384000.0 | grad norm avg: 2.23 | grad norm last: 2.29 | 
2026-01-01T17:50:01 | step: 2100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.4341125279315747e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.99 | train loss last: 4.16 | consumed tokens: 17203200.0 | grad norm avg: 2.22 | grad norm last: 2.09 | 
2026-01-01T17:50:16 | step: 2200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.5176457964116707e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.98 | train loss last: 4.31 | consumed tokens: 18022400.0 | grad norm avg: 2.18 | grad norm last: 2.13 | 
2026-01-01T17:50:32 | step: 2300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.603679993422702e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.99 | train loss last: 4.06 | consumed tokens: 18841600.0 | grad norm avg: 2.18 | grad norm last: 1.9 | 
2026-01-01T17:50:47 | step: 2400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.692040495981928e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.99 | train loss last: 3.92 | consumed tokens: 19660800.0 | grad norm avg: 2.13 | grad norm last: 2.05 | 
2026-01-01T17:51:02 | step: 2500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.78254831553204e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.96 | train loss last: 3.88 | consumed tokens: 20480000.0 | grad norm avg: 2.06 | grad norm last: 1.99 | 
2026-01-01T17:51:18 | step: 2600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.8750193703453988e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.93 | train loss last: 4.25 | consumed tokens: 21299200.0 | grad norm avg: 2.02 | grad norm last: 2.06 | 
2026-01-01T17:51:33 | step: 2700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.9692661226144992e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.93 | train loss last: 4.28 | consumed tokens: 22118400.0 | grad norm avg: 2.02 | grad norm last: 2.07 | 
2026-01-01T17:51:49 | step: 2800 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 2.065097214654088e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.96 | train loss last: 3.5 | consumed tokens: 22937600.0 | grad norm avg: 1.98 | grad norm last: 1.87 | 
2026-01-01T17:52:04 | step: 2900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.1623183783958666e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.93 | train loss last: 4.16 | consumed tokens: 23756800.0 | grad norm avg: 1.93 | grad norm last: 1.86 | 
2026-01-01T17:52:19 | step: 3000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.2607322534895502e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.89 | train loss last: 4.19 | consumed tokens: 24576000.0 | grad norm avg: 1.91 | grad norm last: 1.91 | 
2026-01-01T17:52:35 | step: 3100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.3601391148986295e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.87 | train loss last: 4.19 | consumed tokens: 25395200.0 | grad norm avg: 1.86 | grad norm last: 2.13 | 
2026-01-01T17:52:50 | step: 3200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.460337054799311e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.92 | train loss last: 3.75 | consumed tokens: 26214400.0 | grad norm avg: 1.81 | grad norm last: 1.91 | 
2026-01-01T17:53:05 | step: 3300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.5611228920752183e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.88 | train loss last: 4.22 | consumed tokens: 27033600.0 | grad norm avg: 1.77 | grad norm last: 1.63 | 
2026-01-01T17:53:21 | step: 3400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.6622919904184528e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.85 | train loss last: 3.36 | consumed tokens: 27852800.0 | grad norm avg: 1.75 | grad norm last: 1.81 | 
2026-01-01T17:53:36 | step: 3500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 2.7636391678242944e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.87 | train loss last: 4.19 | consumed tokens: 28672000.0 | grad norm avg: 1.75 | grad norm last: 1.58 | 
2026-01-01T17:53:51 | step: 3600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 2.8649586965912022e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.87 | train loss last: 4.12 | consumed tokens: 29491200.0 | grad norm avg: 1.68 | grad norm last: 1.56 | 
2026-01-01T17:54:07 | step: 3700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.966044849017635e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.85 | train loss last: 3.36 | consumed tokens: 30310400.0 | grad norm avg: 1.64 | grad norm last: 1.67 | 
2026-01-01T17:54:22 | step: 3800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.066692443098873e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.84 | train loss last: 3.81 | consumed tokens: 31129600.0 | grad norm avg: 1.63 | grad norm last: 1.56 | 
2026-01-01T17:54:37 | step: 3900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.1666975701227784e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.81 | train loss last: 4.22 | consumed tokens: 31948800.0 | grad norm avg: 1.6 | grad norm last: 1.46 | 
2026-01-01T17:54:53 | step: 4000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.265856867074035e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.81 | train loss last: 3.83 | consumed tokens: 32768000.0 | grad norm avg: 1.57 | grad norm last: 1.66 | 
2026-01-01T17:55:08 | step: 4100 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 3.363969153724611e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.83 | train loss last: 4.31 | consumed tokens: 33587200.0 | grad norm avg: 1.54 | grad norm last: 1.49 | 
2026-01-01T17:55:24 | step: 4200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.460835796431638e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.81 | train loss last: 4.16 | consumed tokens: 34406400.0 | grad norm avg: 1.53 | grad norm last: 1.6 | 
2026-01-01T17:55:39 | step: 4300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.556259616743773e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.81 | train loss last: 4.0 | consumed tokens: 35225600.0 | grad norm avg: 1.49 | grad norm last: 1.38 | 
2026-01-01T17:55:54 | step: 4400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.650047074188478e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.78 | train loss last: 4.03 | consumed tokens: 36044800.0 | grad norm avg: 1.48 | grad norm last: 1.56 | 
2026-01-01T17:56:10 | step: 4500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.742008266272023e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.8 | train loss last: 3.8 | consumed tokens: 36864000.0 | grad norm avg: 1.45 | grad norm last: 1.42 | 
2026-01-01T17:56:25 | step: 4600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.831955837085843e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.78 | train loss last: 3.75 | consumed tokens: 37683200.0 | grad norm avg: 1.41 | grad norm last: 1.37 | 
2026-01-01T17:56:41 | step: 4700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.919707887689583e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.8 | train loss last: 4.09 | consumed tokens: 38502400.0 | grad norm avg: 1.39 | grad norm last: 1.29 | 
2026-01-01T17:56:56 | step: 4800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.0050861571216956e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.75 | train loss last: 3.77 | consumed tokens: 39321600.0 | grad norm avg: 1.36 | grad norm last: 1.36 | 
2026-01-01T17:57:12 | step: 4900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.0879171137930825e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.79 | train loss last: 4.94 | consumed tokens: 40140800.0 | grad norm avg: 1.34 | grad norm last: 1.29 | 
2026-01-01T17:57:27 | step: 5000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.168033046880737e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.76 | train loss last: 3.66 | consumed tokens: 40960000.0 | grad norm avg: 1.33 | grad norm last: 1.33 | 
2026-01-01T17:57:44 | step: 5100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.245270974934101e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.73 | train loss last: 3.88 | consumed tokens: 41779200.0 | grad norm avg: 1.32 | grad norm last: 1.44 | 
2026-01-01T17:57:59 | step: 5200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.31947446486447e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.75 | train loss last: 4.16 | consumed tokens: 42598400.0 | grad norm avg: 1.29 | grad norm last: 1.34 | 
2026-01-01T17:58:15 | step: 5300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.39049290434923e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.72 | train loss last: 3.64 | consumed tokens: 43417600.0 | grad norm avg: 1.28 | grad norm last: 1.28 | 
2026-01-01T17:58:30 | step: 5400 | train samples/s: 103.8 | train mfu (16-bit): -1.0 | lr mean: 4.45818186562974e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.76 | train loss last: 3.42 | consumed tokens: 44236800.0 | grad norm avg: 1.24 | grad norm last: 1.38 | 
2026-01-01T17:58:46 | step: 5500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.522404196904972e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.73 | train loss last: 4.25 | consumed tokens: 45056000.0 | grad norm avg: 1.24 | grad norm last: 1.18 | 
2026-01-01T17:59:01 | step: 5600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.583029658533633e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.71 | train loss last: 4.16 | consumed tokens: 45875200.0 | grad norm avg: 1.2 | grad norm last: 1.18 | 
2026-01-01T17:59:17 | step: 5700 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.639934923034161e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.75 | train loss last: 3.94 | consumed tokens: 46694400.0 | grad norm avg: 1.2 | grad norm last: 1.17 | 
2026-01-01T17:59:32 | step: 5800 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.693004666478373e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.72 | train loss last: 3.3 | consumed tokens: 47513600.0 | grad norm avg: 1.18 | grad norm last: 1.16 | 
2026-01-01T17:59:48 | step: 5900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.742131568491459e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.7 | train loss last: 3.88 | consumed tokens: 48332800.0 | grad norm avg: 1.15 | grad norm last: 1.08 | 
2026-01-01T18:00:03 | step: 6000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.787215220858343e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.71 | train loss last: 3.88 | consumed tokens: 49152000.0 | grad norm avg: 1.15 | grad norm last: 1.07 | 
2026-01-01T18:00:19 | step: 6100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.828164674108848e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.71 | train loss last: 3.92 | consumed tokens: 49971200.0 | grad norm avg: 1.13 | grad norm last: 1.18 | 
2026-01-01T18:00:34 | step: 6200 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.864896254730411e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.72 | train loss last: 3.7 | consumed tokens: 50790400.0 | grad norm avg: 1.1 | grad norm last: 1.05 | 
2026-01-01T18:00:50 | step: 6300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.897336111753248e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.69 | train loss last: 3.33 | consumed tokens: 51609600.0 | grad norm avg: 1.1 | grad norm last: 1.02 | 
2026-01-01T18:01:05 | step: 6400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.925418033963069e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.67 | train loss last: 3.78 | consumed tokens: 52428800.0 | grad norm avg: 1.08 | grad norm last: 1.07 | 
2026-01-01T18:01:21 | step: 6500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.949085268890485e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.67 | train loss last: 3.39 | consumed tokens: 53248000.0 | grad norm avg: 1.07 | grad norm last: 1.07 | 
2026-01-01T18:01:36 | step: 6600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.968289431417361e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.67 | train loss last: 3.5 | consumed tokens: 54067200.0 | grad norm avg: 1.07 | grad norm last: 0.98 | 
2026-01-01T18:01:52 | step: 6700 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.9829915951704606e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.66 | train loss last: 3.94 | consumed tokens: 54886400.0 | grad norm avg: 1.04 | grad norm last: 1.05 | 
2026-01-01T18:02:07 | step: 6800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.993161928723566e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.66 | train loss last: 3.58 | consumed tokens: 55705600.0 | grad norm avg: 1.04 | grad norm last: 1.15 | 
2026-01-01T18:02:23 | step: 6900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.998780059395358e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.68 | train loss last: 3.09 | consumed tokens: 56524800.0 | grad norm avg: 1.03 | grad norm last: 1.04 | 
2026-01-01T18:02:38 | step: 7000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.999999873689376e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.65 | train loss last: 4.03 | consumed tokens: 57344000.0 | grad norm avg: 1.02 | grad norm last: 0.98 | 
2026-01-01T18:02:53 | step: 7100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.999999509891495e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.67 | train loss last: 4.03 | consumed tokens: 58163200.0 | grad norm avg: 1.01 | grad norm last: 0.99 | 
2026-01-01T18:03:09 | step: 7200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.999998782295734e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.66 | train loss last: 3.8 | consumed tokens: 58982400.0 | grad norm avg: 1.01 | grad norm last: 1.03 | 
2026-01-01T18:03:24 | step: 7300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.999997327104211e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.64 | train loss last: 3.61 | consumed tokens: 59801600.0 | grad norm avg: 1.0 | grad norm last: 0.93 | 
2026-01-01T18:03:40 | step: 7400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.9999951443169266e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.63 | train loss last: 3.0 | consumed tokens: 60620800.0 | grad norm avg: 0.99 | grad norm last: 1.01 | 
2026-01-01T18:03:55 | step: 7500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.9999929615296423e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.67 | train loss last: 3.66 | consumed tokens: 61440000.0 | grad norm avg: 0.98 | grad norm last: 1.01 | 
2026-01-01T18:04:11 | step: 7600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.999989687348716e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.62 | train loss last: 4.31 | consumed tokens: 62259200.0 | grad norm avg: 0.97 | grad norm last: 0.98 | 
2026-01-01T18:04:26 | step: 7700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.9999864131677896e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.66 | train loss last: 3.41 | consumed tokens: 63078400.0 | grad norm avg: 0.96 | grad norm last: 0.9 | 
2026-01-01T18:04:42 | step: 7800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.999982411391102e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.62 | train loss last: 3.66 | consumed tokens: 63897600.0 | grad norm avg: 0.96 | grad norm last: 0.94 | 
2026-01-01T18:04:57 | step: 7900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.9999776820186526e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.62 | train loss last: 3.44 | consumed tokens: 64716800.0 | grad norm avg: 0.96 | grad norm last: 0.98 | 
2026-01-01T18:05:13 | step: 8000 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.9999725888483226e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.64 | train loss last: 3.42 | consumed tokens: 65536000.0 | grad norm avg: 0.95 | grad norm last: 0.99 | 
2026-01-01T18:05:28 | step: 8100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.999967131880112e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.58 | train loss last: 3.55 | consumed tokens: 66355200.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-01T18:05:43 | step: 8200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.99996094731614e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.61 | train loss last: 3.28 | consumed tokens: 67174400.0 | grad norm avg: 0.94 | grad norm last: 0.92 | 
2026-01-01T18:05:59 | step: 8300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.999954398954287e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.63 | train loss last: 3.44 | consumed tokens: 67993600.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-01T18:06:14 | step: 8400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.999947486794554e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.62 | train loss last: 3.67 | consumed tokens: 68812800.0 | grad norm avg: 0.92 | grad norm last: 0.87 | 
2026-01-01T18:06:30 | step: 8500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.999939847039059e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.62 | train loss last: 4.22 | consumed tokens: 69632000.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-01T18:06:45 | step: 8600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.9999314796878025e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.61 | train loss last: 3.31 | consumed tokens: 70451200.0 | grad norm avg: 0.91 | grad norm last: 0.89 | 
2026-01-01T18:07:01 | step: 8700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.9999227485386655e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.62 | train loss last: 3.64 | consumed tokens: 71270400.0 | grad norm avg: 0.9 | grad norm last: 0.97 | 
2026-01-01T18:07:16 | step: 8800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.999913653591648e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.61 | train loss last: 3.67 | consumed tokens: 72089600.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-01T18:07:31 | step: 8900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.9999038310488686e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.62 | train loss last: 3.75 | consumed tokens: 72908800.0 | grad norm avg: 0.9 | grad norm last: 0.92 | 
2026-01-01T18:07:47 | step: 9000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.999893644708209e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.6 | train loss last: 4.06 | consumed tokens: 73728000.0 | grad norm avg: 0.9 | grad norm last: 0.88 | 
2026-01-01T18:08:02 | step: 9100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.999883094569668e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.59 | train loss last: 3.05 | consumed tokens: 74547200.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T18:08:18 | step: 9200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.999871816835366e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.58 | train loss last: 3.77 | consumed tokens: 75366400.0 | grad norm avg: 0.89 | grad norm last: 0.92 | 
2026-01-01T18:08:33 | step: 9300 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.9998601753031835e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.58 | train loss last: 3.7 | consumed tokens: 76185600.0 | grad norm avg: 0.88 | grad norm last: 0.82 | 
2026-01-01T18:08:49 | step: 9400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.9998478061752394e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.59 | train loss last: 4.28 | consumed tokens: 77004800.0 | grad norm avg: 0.89 | grad norm last: 0.87 | 
2026-01-01T18:09:04 | step: 9500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.9998350732494146e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.6 | train loss last: 3.66 | consumed tokens: 77824000.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-01T18:09:20 | step: 9600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.999821612727828e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.56 | train loss last: 3.7 | consumed tokens: 78643200.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-01T18:09:35 | step: 9700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.9998077884083614e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.56 | train loss last: 3.5 | consumed tokens: 79462400.0 | grad norm avg: 0.87 | grad norm last: 0.83 | 
2026-01-01T18:09:51 | step: 9800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.999793236493133e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.6 | train loss last: 3.81 | consumed tokens: 80281600.0 | grad norm avg: 0.87 | grad norm last: 0.87 | 
2026-01-01T18:10:06 | step: 9900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.9997786845779046e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.56 | train loss last: 2.98 | consumed tokens: 81100800.0 | grad norm avg: 0.88 | grad norm last: 0.85 | 
2026-01-01T18:10:21 | step: 10000 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.999763041269034e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.55 | train loss last: 3.2 | consumed tokens: 81920000.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-01T18:10:38 | step: 10100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.999747034162283e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.58 | train loss last: 3.5 | consumed tokens: 82739200.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-01T18:10:54 | step: 10200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.999730663257651e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.59 | train loss last: 3.78 | consumed tokens: 83558400.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-01T18:11:09 | step: 10300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.9997139285551384e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.57 | train loss last: 3.38 | consumed tokens: 84377600.0 | grad norm avg: 0.87 | grad norm last: 0.84 | 
2026-01-01T18:11:25 | step: 10400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.9996964662568644e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.55 | train loss last: 3.67 | consumed tokens: 85196800.0 | grad norm avg: 0.85 | grad norm last: 0.85 | 
2026-01-01T18:11:40 | step: 10500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.999678276362829e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.55 | train loss last: 3.36 | consumed tokens: 86016000.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T18:11:56 | step: 10600 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 4.9996600864687935e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.53 | train loss last: 3.47 | consumed tokens: 86835200.0 | grad norm avg: 0.86 | grad norm last: 0.88 | 
2026-01-01T18:12:11 | step: 10700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.999640805181116e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.55 | train loss last: 3.69 | consumed tokens: 87654400.0 | grad norm avg: 0.85 | grad norm last: 0.8 | 
2026-01-01T18:12:27 | step: 10800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.999621523893438e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.55 | train loss last: 3.45 | consumed tokens: 88473600.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-01T18:12:42 | step: 10900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.9996011512121186e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.53 | train loss last: 3.11 | consumed tokens: 89292800.0 | grad norm avg: 0.85 | grad norm last: 0.87 | 
2026-01-01T18:12:57 | step: 11000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.999580778530799e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.55 | train loss last: 3.8 | consumed tokens: 90112000.0 | grad norm avg: 0.85 | grad norm last: 0.79 | 
2026-01-01T18:13:13 | step: 11100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.999559678253718e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.56 | train loss last: 3.22 | consumed tokens: 90931200.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T18:13:28 | step: 11200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.999538214178756e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.57 | train loss last: 3.53 | consumed tokens: 91750400.0 | grad norm avg: 0.85 | grad norm last: 0.83 | 
2026-01-01T18:13:44 | step: 11300 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.9995160225080326e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.54 | train loss last: 3.67 | consumed tokens: 92569600.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-01T18:13:59 | step: 11400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.9994934670394287e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.56 | train loss last: 3.3 | consumed tokens: 93388800.0 | grad norm avg: 0.85 | grad norm last: 0.82 | 
2026-01-01T18:14:15 | step: 11500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.999470183975063e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.54 | train loss last: 3.06 | consumed tokens: 94208000.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-01T18:14:30 | step: 11600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.999446537112817e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.51 | train loss last: 3.73 | consumed tokens: 95027200.0 | grad norm avg: 0.84 | grad norm last: 0.8 | 
2026-01-01T18:14:46 | step: 11700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.9994225264526904e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.55 | train loss last: 3.73 | consumed tokens: 95846400.0 | grad norm avg: 0.84 | grad norm last: 0.81 | 
2026-01-01T18:15:01 | step: 11800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.999397788196802e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.53 | train loss last: 3.31 | consumed tokens: 96665600.0 | grad norm avg: 0.82 | grad norm last: 0.83 | 
2026-01-01T18:15:17 | step: 11900 | train samples/s: 103.7 | train mfu (16-bit): -1.0 | lr mean: 4.9993723223451525e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.54 | train loss last: 3.52 | consumed tokens: 97484800.0 | grad norm avg: 0.82 | grad norm last: 0.8 | 
2026-01-01T18:15:32 | step: 12000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.999346856493503e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.55 | train loss last: 2.92 | consumed tokens: 98304000.0 | grad norm avg: 0.83 | grad norm last: 0.81 | 
2026-01-01T18:15:48 | step: 12100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.999320299248211e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.53 | train loss last: 3.83 | consumed tokens: 99123200.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-01T18:16:03 | step: 12200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.999293742002919e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.55 | train loss last: 3.52 | consumed tokens: 99942400.0 | grad norm avg: 0.82 | grad norm last: 0.82 | 
2026-01-01T18:16:18 | step: 12300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.999266457161866e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.53 | train loss last: 3.05 | consumed tokens: 100761600.0 | grad norm avg: 0.82 | grad norm last: 0.79 | 
2026-01-01T18:16:34 | step: 12400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.9992384447250515e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.55 | train loss last: 3.44 | consumed tokens: 101580800.0 | grad norm avg: 0.82 | grad norm last: 0.81 | 
2026-01-01T18:16:49 | step: 12500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.999210432288237e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.53 | train loss last: 3.53 | consumed tokens: 102400000.0 | grad norm avg: 0.82 | grad norm last: 0.78 | 
2026-01-01T18:17:05 | step: 12600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.99918132845778e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.53 | train loss last: 3.61 | consumed tokens: 103219200.0 | grad norm avg: 0.82 | grad norm last: 0.83 | 
2026-01-01T18:17:20 | step: 12700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.9991522246273234e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.51 | train loss last: 3.16 | consumed tokens: 104038400.0 | grad norm avg: 0.82 | grad norm last: 0.82 | 
2026-01-01T18:17:36 | step: 12800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.999122393201105e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.51 | train loss last: 3.75 | consumed tokens: 104857600.0 | grad norm avg: 0.82 | grad norm last: 0.83 | 
2026-01-01T18:17:51 | step: 12900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.999091834179126e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.49 | train loss last: 3.25 | consumed tokens: 105676800.0 | grad norm avg: 0.82 | grad norm last: 0.89 | 
2026-01-01T18:18:07 | step: 13000 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.9990609113592654e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.52 | train loss last: 3.7 | consumed tokens: 106496000.0 | grad norm avg: 0.82 | grad norm last: 0.88 | 
2026-01-01T18:18:22 | step: 13100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.9990296247415245e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.5 | train loss last: 3.41 | consumed tokens: 107315200.0 | grad norm avg: 0.81 | grad norm last: 0.8 | 
2026-01-01T18:18:38 | step: 13200 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 4.998997610528022e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.5 | train loss last: 3.38 | consumed tokens: 108134400.0 | grad norm avg: 0.81 | grad norm last: 0.8 | 
2026-01-01T18:18:53 | step: 13300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.998965232516639e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.49 | train loss last: 3.47 | consumed tokens: 108953600.0 | grad norm avg: 0.81 | grad norm last: 0.84 | 
2026-01-01T18:19:09 | step: 13400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.9989321269094944e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.48 | train loss last: 3.5 | consumed tokens: 109772800.0 | grad norm avg: 0.82 | grad norm last: 0.79 | 
2026-01-01T18:19:24 | step: 13500 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.998898657504469e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.51 | train loss last: 3.14 | consumed tokens: 110592000.0 | grad norm avg: 0.81 | grad norm last: 0.77 | 
2026-01-01T18:19:40 | step: 13600 | train samples/s: 103.4 | train mfu (16-bit): -1.0 | lr mean: 4.998864824301563e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.52 | train loss last: 3.48 | consumed tokens: 111411200.0 | grad norm avg: 0.8 | grad norm last: 0.76 | 
2026-01-01T18:19:56 | step: 13700 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.998830263502896e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.52 | train loss last: 3.31 | consumed tokens: 112230400.0 | grad norm avg: 0.81 | grad norm last: 0.79 | 
2026-01-01T18:20:11 | step: 13800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.998794975108467e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.48 | train loss last: 3.05 | consumed tokens: 113049600.0 | grad norm avg: 0.81 | grad norm last: 0.79 | 
2026-01-01T18:20:27 | step: 13900 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.998759686714038e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.51 | train loss last: 3.45 | consumed tokens: 113868800.0 | grad norm avg: 0.81 | grad norm last: 0.79 | 
2026-01-01T18:20:43 | step: 14000 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.998723670723848e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.49 | train loss last: 3.59 | consumed tokens: 114688000.0 | grad norm avg: 0.8 | grad norm last: 0.81 | 
2026-01-01T18:20:58 | step: 14100 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.9986869271378964e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.48 | train loss last: 3.91 | consumed tokens: 115507200.0 | grad norm avg: 0.81 | grad norm last: 0.76 | 
2026-01-01T18:21:14 | step: 14200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.998649819754064e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.51 | train loss last: 3.11 | consumed tokens: 116326400.0 | grad norm avg: 0.8 | grad norm last: 0.77 | 
2026-01-01T18:21:29 | step: 14300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.998612348572351e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.51 | train loss last: 3.69 | consumed tokens: 117145600.0 | grad norm avg: 0.81 | grad norm last: 0.75 | 
2026-01-01T18:21:45 | step: 14400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.9985741497948766e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.5 | train loss last: 3.81 | consumed tokens: 117964800.0 | grad norm avg: 0.79 | grad norm last: 0.8 | 
2026-01-01T18:22:00 | step: 14500 | train samples/s: 103.7 | train mfu (16-bit): -1.0 | lr mean: 4.998535223421641e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.48 | train loss last: 3.53 | consumed tokens: 118784000.0 | grad norm avg: 0.8 | grad norm last: 0.78 | 
2026-01-01T18:22:16 | step: 14600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.998496297048405e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.47 | train loss last: 3.97 | consumed tokens: 119603200.0 | grad norm avg: 0.8 | grad norm last: 0.77 | 
2026-01-01T18:22:31 | step: 14700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.9984566430794075e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.52 | train loss last: 3.34 | consumed tokens: 120422400.0 | grad norm avg: 0.8 | grad norm last: 0.8 | 
2026-01-01T18:22:47 | step: 14800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.998416261514649e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.48 | train loss last: 3.97 | consumed tokens: 121241600.0 | grad norm avg: 0.8 | grad norm last: 0.78 | 
2026-01-01T18:23:02 | step: 14900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.9983755161520094e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.5 | train loss last: 3.36 | consumed tokens: 122060800.0 | grad norm avg: 0.79 | grad norm last: 0.78 | 
2026-01-01T18:23:18 | step: 15000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.998334406991489e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.5 | train loss last: 3.05 | consumed tokens: 122880000.0 | grad norm avg: 0.8 | grad norm last: 0.78 | 
2026-01-01T18:23:34 | step: 15100 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.998292570235208e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.51 | train loss last: 3.62 | consumed tokens: 123699200.0 | grad norm avg: 0.81 | grad norm last: 0.8 | 
2026-01-01T18:23:50 | step: 15200 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.9982503696810454e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.47 | train loss last: 3.02 | consumed tokens: 124518400.0 | grad norm avg: 0.8 | grad norm last: 0.79 | 
2026-01-01T18:24:05 | step: 15300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.998207441531122e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.48 | train loss last: 3.58 | consumed tokens: 125337600.0 | grad norm avg: 0.8 | grad norm last: 0.76 | 
2026-01-01T18:24:21 | step: 15400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.9981641495833173e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.51 | train loss last: 3.7 | consumed tokens: 126156800.0 | grad norm avg: 0.8 | grad norm last: 0.8 | 
2026-01-01T18:24:36 | step: 15500 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.998120493837632e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.48 | train loss last: 3.53 | consumed tokens: 126976000.0 | grad norm avg: 0.8 | grad norm last: 0.81 | 
2026-01-01T18:24:52 | step: 15600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.998076110496186e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.49 | train loss last: 3.45 | consumed tokens: 127795200.0 | grad norm avg: 0.8 | grad norm last: 0.8 | 
2026-01-01T18:25:07 | step: 15700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.9980313633568585e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.45 | train loss last: 3.55 | consumed tokens: 128614400.0 | grad norm avg: 0.79 | grad norm last: 1.09 | 
2026-01-01T18:25:23 | step: 15800 | train samples/s: 103.5 | train mfu (16-bit): -1.0 | lr mean: 4.99798588862177e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.45 | train loss last: 3.5 | consumed tokens: 129433600.0 | grad norm avg: 0.8 | grad norm last: 0.81 | 
2026-01-01T18:25:39 | step: 15900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.9979400500888005e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.46 | train loss last: 3.45 | consumed tokens: 130252800.0 | grad norm avg: 0.79 | grad norm last: 0.8 | 
2026-01-01T18:25:54 | step: 16000 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.99789348396007e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.46 | train loss last: 3.25 | consumed tokens: 131072000.0 | grad norm avg: 0.8 | grad norm last: 0.78 | 
2026-01-01T18:26:10 | step: 16100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.997846554033458e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.5 | train loss last: 3.67 | consumed tokens: 131891200.0 | grad norm avg: 0.78 | grad norm last: 0.79 | 
2026-01-01T18:26:25 | step: 16200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.997799260308966e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.46 | train loss last: 4.09 | consumed tokens: 132710400.0 | grad norm avg: 0.79 | grad norm last: 0.77 | 
2026-01-01T18:26:41 | step: 16300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.9977512389887124e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.45 | train loss last: 3.25 | consumed tokens: 133529600.0 | grad norm avg: 0.78 | grad norm last: 0.78 | 
2026-01-01T18:26:56 | step: 16400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.997702853870578e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.48 | train loss last: 3.22 | consumed tokens: 134348800.0 | grad norm avg: 0.8 | grad norm last: 0.82 | 
2026-01-01T18:27:11 | step: 16500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.9976537411566824e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.47 | train loss last: 3.52 | consumed tokens: 135168000.0 | grad norm avg: 0.79 | grad norm last: 0.75 | 
2026-01-01T18:27:27 | step: 16600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.997604264644906e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.45 | train loss last: 3.58 | consumed tokens: 135987200.0 | grad norm avg: 0.79 | grad norm last: 0.77 | 
2026-01-01T18:27:42 | step: 16700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.997554424335249e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.46 | train loss last: 3.25 | consumed tokens: 136806400.0 | grad norm avg: 0.79 | grad norm last: 0.76 | 
2026-01-01T18:27:58 | step: 16800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.99750385642983e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.46 | train loss last: 3.34 | consumed tokens: 137625600.0 | grad norm avg: 0.79 | grad norm last: 0.78 | 
2026-01-01T18:28:13 | step: 16900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.99745256092865e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.45 | train loss last: 3.42 | consumed tokens: 138444800.0 | grad norm avg: 0.78 | grad norm last: 0.86 | 
2026-01-01T18:28:29 | step: 17000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.99740126542747e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.46 | train loss last: 3.97 | consumed tokens: 139264000.0 | grad norm avg: 0.79 | grad norm last: 0.78 | 
2026-01-01T18:28:44 | step: 17100 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.997348878532648e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.48 | train loss last: 3.78 | consumed tokens: 140083200.0 | grad norm avg: 0.78 | grad norm last: 0.77 | 
2026-01-01T18:29:00 | step: 17200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.997296491637826e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.48 | train loss last: 3.0 | consumed tokens: 140902400.0 | grad norm avg: 0.78 | grad norm last: 0.78 | 
2026-01-01T18:29:15 | step: 17300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.9972433771472424e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.49 | train loss last: 2.58 | consumed tokens: 141721600.0 | grad norm avg: 0.78 | grad norm last: 0.75 | 
2026-01-01T18:29:31 | step: 17400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.9971895350608975e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.45 | train loss last: 2.78 | consumed tokens: 142540800.0 | grad norm avg: 0.78 | grad norm last: 0.77 | 
2026-01-01T18:29:46 | step: 17500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.997135329176672e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.47 | train loss last: 3.12 | consumed tokens: 143360000.0 | grad norm avg: 0.79 | grad norm last: 0.74 | 
2026-01-01T18:30:01 | step: 17600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.9970807594945654e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.46 | train loss last: 3.02 | consumed tokens: 144179200.0 | grad norm avg: 0.79 | grad norm last: 0.78 | 
2026-01-01T18:30:17 | step: 17700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.9970258260145783e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.48 | train loss last: 4.41 | consumed tokens: 144998400.0 | grad norm avg: 0.78 | grad norm last: 0.76 | 
2026-01-01T18:30:32 | step: 17800 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.996969801140949e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.42 | train loss last: 3.39 | consumed tokens: 145817600.0 | grad norm avg: 0.78 | grad norm last: 0.8 | 
2026-01-01T18:30:48 | step: 17900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.99691377626732e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.46 | train loss last: 3.73 | consumed tokens: 146636800.0 | grad norm avg: 0.77 | grad norm last: 0.77 | 
2026-01-01T18:31:03 | step: 18000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.996857023797929e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.49 | train loss last: 3.14 | consumed tokens: 147456000.0 | grad norm avg: 0.78 | grad norm last: 0.73 | 
2026-01-01T18:31:19 | step: 18100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.996799907530658e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.48 | train loss last: 3.95 | consumed tokens: 148275200.0 | grad norm avg: 0.78 | grad norm last: 0.8 | 
2026-01-01T18:31:34 | step: 18200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.996742063667625e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.42 | train loss last: 2.81 | consumed tokens: 149094400.0 | grad norm avg: 0.78 | grad norm last: 0.75 | 
2026-01-01T18:31:50 | step: 18300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.996683856006712e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.41 | train loss last: 3.56 | consumed tokens: 149913600.0 | grad norm avg: 0.8 | grad norm last: 0.73 | 
2026-01-01T18:32:05 | step: 18400 | train samples/s: 103.8 | train mfu (16-bit): -1.0 | lr mean: 4.996624920750037e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.43 | train loss last: 3.38 | consumed tokens: 150732800.0 | grad norm avg: 0.79 | grad norm last: 0.8 | 
2026-01-01T18:32:21 | step: 18500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.996565621695481e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.44 | train loss last: 3.48 | consumed tokens: 151552000.0 | grad norm avg: 0.78 | grad norm last: 0.75 | 
2026-01-01T18:32:36 | step: 18600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.996505595045164e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.45 | train loss last: 3.38 | consumed tokens: 152371200.0 | grad norm avg: 0.78 | grad norm last: 0.74 | 
2026-01-01T18:32:52 | step: 18700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.9964452045969665e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.47 | train loss last: 3.33 | consumed tokens: 153190400.0 | grad norm avg: 0.77 | grad norm last: 0.8 | 
2026-01-01T18:33:07 | step: 18800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.996384450350888e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.48 | train loss last: 3.38 | consumed tokens: 154009600.0 | grad norm avg: 0.77 | grad norm last: 0.78 | 
2026-01-01T18:33:22 | step: 18900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.996322968509048e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.45 | train loss last: 3.53 | consumed tokens: 154828800.0 | grad norm avg: 0.78 | grad norm last: 0.8 | 
2026-01-01T18:33:38 | step: 19000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.996261122869328e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.44 | train loss last: 3.25 | consumed tokens: 155648000.0 | grad norm avg: 0.78 | grad norm last: 0.82 | 
2026-01-01T18:33:53 | step: 19100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.9961989134317264e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.44 | train loss last: 3.47 | consumed tokens: 156467200.0 | grad norm avg: 0.78 | grad norm last: 0.73 | 
2026-01-01T18:34:09 | step: 19200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.996135976398364e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.44 | train loss last: 3.41 | consumed tokens: 157286400.0 | grad norm avg: 0.78 | grad norm last: 0.77 | 
2026-01-01T18:34:24 | step: 19300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.9960723117692396e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.44 | train loss last: 3.64 | consumed tokens: 158105600.0 | grad norm avg: 0.78 | grad norm last: 0.81 | 
2026-01-01T18:34:40 | step: 19400 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.996008283342235e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.45 | train loss last: 3.55 | consumed tokens: 158924800.0 | grad norm avg: 0.78 | grad norm last: 0.78 | 
2026-01-01T18:34:55 | step: 19500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.995943891117349e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.45 | train loss last: 3.97 | consumed tokens: 159744000.0 | grad norm avg: 0.78 | grad norm last: 0.77 | 
2026-01-01T18:35:11 | step: 19600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.995879135094583e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.44 | train loss last: 3.28 | consumed tokens: 160563200.0 | grad norm avg: 0.77 | grad norm last: 0.76 | 
2026-01-01T18:35:26 | step: 19700 | train samples/s: 103.7 | train mfu (16-bit): -1.0 | lr mean: 4.995813287678175e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.43 | train loss last: 3.05 | consumed tokens: 161382400.0 | grad norm avg: 0.77 | grad norm last: 0.76 | 
2026-01-01T18:35:42 | step: 19800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.995747440261766e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.43 | train loss last: 3.28 | consumed tokens: 162201600.0 | grad norm avg: 0.78 | grad norm last: 0.72 | 
2026-01-01T18:35:57 | step: 19900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.9956808652495965e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.45 | train loss last: 3.19 | consumed tokens: 163020800.0 | grad norm avg: 0.78 | grad norm last: 0.8 | 
2026-01-01T18:36:13 | step: 20000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.995613926439546e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.41 | train loss last: 3.69 | consumed tokens: 163840000.0 | grad norm avg: 0.77 | grad norm last: 0.75 | 
2026-01-01T18:36:30 | step: 20100 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.995546260033734e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.43 | train loss last: 3.14 | consumed tokens: 164659200.0 | grad norm avg: 0.77 | grad norm last: 0.74 | 
2026-01-01T18:36:45 | step: 20200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.9954782298300415e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.42 | train loss last: 3.73 | consumed tokens: 165478400.0 | grad norm avg: 0.77 | grad norm last: 0.75 | 
2026-01-01T18:37:01 | step: 20300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.9954094720305875e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.41 | train loss last: 3.12 | consumed tokens: 166297600.0 | grad norm avg: 0.78 | grad norm last: 0.74 | 
2026-01-01T18:37:16 | step: 20400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.995340350433253e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.42 | train loss last: 3.56 | consumed tokens: 167116800.0 | grad norm avg: 0.77 | grad norm last: 0.76 | 
2026-01-01T18:37:31 | step: 20500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.995270865038037e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.42 | train loss last: 3.34 | consumed tokens: 167936000.0 | grad norm avg: 0.77 | grad norm last: 0.74 | 
2026-01-01T18:37:47 | step: 20600 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.9952006520470604e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.43 | train loss last: 3.25 | consumed tokens: 168755200.0 | grad norm avg: 0.77 | grad norm last: 0.79 | 
2026-01-01T18:38:02 | step: 20700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.995130075258203e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.46 | train loss last: 3.19 | consumed tokens: 169574400.0 | grad norm avg: 0.77 | grad norm last: 0.75 | 
2026-01-01T18:38:18 | step: 20800 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.995058770873584e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.41 | train loss last: 3.55 | consumed tokens: 170393600.0 | grad norm avg: 0.77 | grad norm last: 0.8 | 
2026-01-01T18:38:34 | step: 20900 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.994987102691084e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.44 | train loss last: 3.67 | consumed tokens: 171212800.0 | grad norm avg: 0.77 | grad norm last: 0.82 | 
2026-01-01T18:38:49 | step: 21000 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.994914706912823e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.43 | train loss last: 3.33 | consumed tokens: 172032000.0 | grad norm avg: 0.77 | grad norm last: 0.74 | 
2026-01-01T18:39:05 | step: 21100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.994841947336681e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.42 | train loss last: 3.64 | consumed tokens: 172851200.0 | grad norm avg: 0.77 | grad norm last: 0.73 | 
2026-01-01T18:39:20 | step: 21200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.9947688239626586e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.44 | train loss last: 3.53 | consumed tokens: 173670400.0 | grad norm avg: 0.77 | grad norm last: 0.78 | 
2026-01-01T18:39:36 | step: 21300 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.994694972992875e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.4 | train loss last: 2.97 | consumed tokens: 174489600.0 | grad norm avg: 0.77 | grad norm last: 0.78 | 
2026-01-01T18:39:51 | step: 21400 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.99462075822521e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.43 | train loss last: 3.12 | consumed tokens: 175308800.0 | grad norm avg: 0.77 | grad norm last: 0.74 | 
2026-01-01T18:40:07 | step: 21500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.994545815861784e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.43 | train loss last: 3.38 | consumed tokens: 176128000.0 | grad norm avg: 0.77 | grad norm last: 0.75 | 
2026-01-01T18:40:22 | step: 21600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.994470509700477e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.43 | train loss last: 3.31 | consumed tokens: 176947200.0 | grad norm avg: 0.77 | grad norm last: 0.75 | 
2026-01-01T18:40:38 | step: 21700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.9943948397412896e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.42 | train loss last: 3.62 | consumed tokens: 177766400.0 | grad norm avg: 0.76 | grad norm last: 0.73 | 
2026-01-01T18:40:53 | step: 21800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.994318442186341e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.41 | train loss last: 3.47 | consumed tokens: 178585600.0 | grad norm avg: 0.77 | grad norm last: 0.77 | 
2026-01-01T18:41:09 | step: 21900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.994241680833511e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.42 | train loss last: 3.14 | consumed tokens: 179404800.0 | grad norm avg: 0.77 | grad norm last: 0.81 | 
2026-01-01T18:41:24 | step: 22000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.99416419188492e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.42 | train loss last: 3.27 | consumed tokens: 180224000.0 | grad norm avg: 0.76 | grad norm last: 0.82 | 
2026-01-01T18:41:40 | step: 22100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.994086339138448e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.39 | train loss last: 2.98 | consumed tokens: 181043200.0 | grad norm avg: 0.77 | grad norm last: 0.78 | 
2026-01-01T18:41:55 | step: 22200 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.994007758796215e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.42 | train loss last: 3.47 | consumed tokens: 181862400.0 | grad norm avg: 0.77 | grad norm last: 0.77 | 
2026-01-01T18:42:11 | step: 22300 | train samples/s: 103.4 | train mfu (16-bit): -1.0 | lr mean: 4.993928814656101e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.42 | train loss last: 2.84 | consumed tokens: 182681600.0 | grad norm avg: 0.77 | grad norm last: 0.86 | 
2026-01-01T18:42:27 | step: 22400 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.9938495067181066e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.41 | train loss last: 3.45 | consumed tokens: 183500800.0 | grad norm avg: 0.76 | grad norm last: 0.75 | 
2026-01-01T18:42:42 | step: 22500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.9937694711843506e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.4 | train loss last: 3.17 | consumed tokens: 184320000.0 | grad norm avg: 0.77 | grad norm last: 0.75 | 
2026-01-01T18:42:57 | step: 22600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.993689071852714e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.4 | train loss last: 3.05 | consumed tokens: 185139200.0 | grad norm avg: 0.77 | grad norm last: 0.7 | 
2026-01-01T18:43:13 | step: 22700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.993607944925316e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.41 | train loss last: 3.56 | consumed tokens: 185958400.0 | grad norm avg: 0.76 | grad norm last: 0.8 | 
2026-01-01T18:43:28 | step: 22800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.993526454200037e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.4 | train loss last: 3.05 | consumed tokens: 186777600.0 | grad norm avg: 0.76 | grad norm last: 0.82 | 
2026-01-01T18:43:44 | step: 22900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.993444599676877e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.43 | train loss last: 3.88 | consumed tokens: 187596800.0 | grad norm avg: 0.76 | grad norm last: 0.76 | 
2026-01-01T18:43:59 | step: 23000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.993362017557956e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.44 | train loss last: 3.44 | consumed tokens: 188416000.0 | grad norm avg: 0.77 | grad norm last: 0.76 | 
2026-01-01T18:44:15 | step: 23100 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.9932790716411546e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.39 | train loss last: 3.72 | consumed tokens: 189235200.0 | grad norm avg: 0.77 | grad norm last: 0.75 | 
2026-01-01T18:44:30 | step: 23200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.9931953981285915e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.39 | train loss last: 3.25 | consumed tokens: 190054400.0 | grad norm avg: 0.77 | grad norm last: 0.76 | 
2026-01-01T18:44:46 | step: 23300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.9931113608181477e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.43 | train loss last: 3.09 | consumed tokens: 190873600.0 | grad norm avg: 0.76 | grad norm last: 0.74 | 
2026-01-01T18:45:01 | step: 23400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.9930265959119424e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.37 | train loss last: 3.06 | consumed tokens: 191692800.0 | grad norm avg: 0.77 | grad norm last: 0.71 | 
2026-01-01T18:45:17 | step: 23500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.9929414672078565e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.42 | train loss last: 3.38 | consumed tokens: 192512000.0 | grad norm avg: 0.77 | grad norm last: 0.75 | 
2026-01-01T18:45:32 | step: 23600 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.99285597470589e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.39 | train loss last: 3.25 | consumed tokens: 193331200.0 | grad norm avg: 0.76 | grad norm last: 0.78 | 
2026-01-01T18:45:48 | step: 23700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.992769754608162e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.39 | train loss last: 3.34 | consumed tokens: 194150400.0 | grad norm avg: 0.76 | grad norm last: 0.77 | 
2026-01-01T18:46:03 | step: 23800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.992683170712553e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.43 | train loss last: 3.53 | consumed tokens: 194969600.0 | grad norm avg: 0.76 | grad norm last: 0.77 | 
2026-01-01T18:46:19 | step: 23900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.992595859221183e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.4 | train loss last: 2.83 | consumed tokens: 195788800.0 | grad norm avg: 0.77 | grad norm last: 0.75 | 
2026-01-01T18:46:34 | step: 24000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.992508183931932e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.39 | train loss last: 3.28 | consumed tokens: 196608000.0 | grad norm avg: 0.76 | grad norm last: 0.75 | 
2026-01-01T18:46:50 | step: 24100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.9924201448448e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.39 | train loss last: 3.45 | consumed tokens: 197427200.0 | grad norm avg: 0.76 | grad norm last: 0.78 | 
2026-01-01T18:47:05 | step: 24200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.992331378161907e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.39 | train loss last: 2.59 | consumed tokens: 198246400.0 | grad norm avg: 0.76 | grad norm last: 0.73 | 
2026-01-01T18:47:20 | step: 24300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.992241883883253e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.39 | train loss last: 4.06 | consumed tokens: 199065600.0 | grad norm avg: 0.76 | grad norm last: 0.81 | 
2026-01-01T18:47:36 | step: 24400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.992152389604598e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.39 | train loss last: 3.44 | consumed tokens: 199884800.0 | grad norm avg: 0.77 | grad norm last: 0.74 | 
2026-01-01T18:47:51 | step: 24500 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.9920621677301824e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.41 | train loss last: 3.02 | consumed tokens: 200704000.0 | grad norm avg: 0.76 | grad norm last: 0.77 | 
2026-01-01T18:48:07 | step: 24600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.991971218260005e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.39 | train loss last: 3.27 | consumed tokens: 201523200.0 | grad norm avg: 0.76 | grad norm last: 0.78 | 
2026-01-01T18:48:22 | step: 24700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.991879904991947e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.4 | train loss last: 3.62 | consumed tokens: 202342400.0 | grad norm avg: 0.75 | grad norm last: 0.77 | 
2026-01-01T18:48:38 | step: 24800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.9917882279260084e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.39 | train loss last: 3.12 | consumed tokens: 203161600.0 | grad norm avg: 0.76 | grad norm last: 0.79 | 
2026-01-01T18:48:53 | step: 24900 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.991695823264308e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.4 | train loss last: 3.62 | consumed tokens: 203980800.0 | grad norm avg: 0.76 | grad norm last: 0.75 | 
2026-01-01T18:49:09 | step: 25000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.9916030548047274e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.37 | train loss last: 3.34 | consumed tokens: 204800000.0 | grad norm avg: 0.76 | grad norm last: 0.78 | 
2026-01-01T18:49:26 | step: 25100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.991509558749385e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.41 | train loss last: 3.8 | consumed tokens: 205619200.0 | grad norm avg: 0.76 | grad norm last: 0.75 | 
2026-01-01T18:49:41 | step: 25200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.991415698896162e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.4 | train loss last: 3.03 | consumed tokens: 206438400.0 | grad norm avg: 0.76 | grad norm last: 0.78 | 
2026-01-01T18:49:57 | step: 25300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.991321111447178e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.39 | train loss last: 3.41 | consumed tokens: 207257600.0 | grad norm avg: 0.76 | grad norm last: 0.74 | 
2026-01-01T18:50:12 | step: 25400 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.9912265239981934e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.4 | train loss last: 3.97 | consumed tokens: 208076800.0 | grad norm avg: 0.76 | grad norm last: 0.73 | 
2026-01-01T18:50:28 | step: 25500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.991130845155567e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.39 | train loss last: 3.14 | consumed tokens: 208896000.0 | grad norm avg: 0.75 | grad norm last: 0.79 | 
2026-01-01T18:50:43 | step: 25600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.99103480251506e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.37 | train loss last: 3.36 | consumed tokens: 209715200.0 | grad norm avg: 0.76 | grad norm last: 0.74 | 
2026-01-01T18:50:58 | step: 25700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.990938396076672e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.37 | train loss last: 3.64 | consumed tokens: 210534400.0 | grad norm avg: 0.76 | grad norm last: 0.76 | 
2026-01-01T18:51:14 | step: 25800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.990841625840403e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.42 | train loss last: 3.05 | consumed tokens: 211353600.0 | grad norm avg: 0.76 | grad norm last: 0.73 | 
2026-01-01T18:51:29 | step: 25900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.990744128008373e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.38 | train loss last: 3.27 | consumed tokens: 212172800.0 | grad norm avg: 0.75 | grad norm last: 0.74 | 
2026-01-01T18:51:45 | step: 26000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.9906459025805816e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.42 | train loss last: 3.41 | consumed tokens: 212992000.0 | grad norm avg: 0.75 | grad norm last: 0.73 | 
2026-01-01T18:52:00 | step: 26100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.99054767715279e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.37 | train loss last: 2.95 | consumed tokens: 213811200.0 | grad norm avg: 0.75 | grad norm last: 0.77 | 
2026-01-01T18:52:16 | step: 26200 | train samples/s: 103.7 | train mfu (16-bit): -1.0 | lr mean: 4.9904483603313565e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.39 | train loss last: 3.27 | consumed tokens: 214630400.0 | grad norm avg: 0.76 | grad norm last: 0.77 | 
2026-01-01T18:52:32 | step: 26300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.990349043509923e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.38 | train loss last: 3.78 | consumed tokens: 215449600.0 | grad norm avg: 0.76 | grad norm last: 0.75 | 
2026-01-01T18:52:47 | step: 26400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.990248999092728e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.4 | train loss last: 3.64 | consumed tokens: 216268800.0 | grad norm avg: 0.75 | grad norm last: 0.7 | 
2026-01-01T18:53:03 | step: 26500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.9901482270797715e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.41 | train loss last: 3.33 | consumed tokens: 217088000.0 | grad norm avg: 0.75 | grad norm last: 0.76 | 
2026-01-01T18:53:18 | step: 26600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.990047091268934e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.41 | train loss last: 3.33 | consumed tokens: 217907200.0 | grad norm avg: 0.76 | grad norm last: 0.72 | 
2026-01-01T18:53:34 | step: 26700 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.9899455916602165e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.37 | train loss last: 3.12 | consumed tokens: 218726400.0 | grad norm avg: 0.76 | grad norm last: 0.74 | 
2026-01-01T18:53:49 | step: 26800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.989843364455737e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.38 | train loss last: 2.53 | consumed tokens: 219545600.0 | grad norm avg: 0.77 | grad norm last: 0.76 | 
2026-01-01T18:54:04 | step: 26900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.989740773453377e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.39 | train loss last: 3.69 | consumed tokens: 220364800.0 | grad norm avg: 0.75 | grad norm last: 0.74 | 
2026-01-01T18:54:20 | step: 27000 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.9896378186531365e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.36 | train loss last: 3.5 | consumed tokens: 221184000.0 | grad norm avg: 0.76 | grad norm last: 0.74 | 
2026-01-01T18:54:35 | step: 27100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.9895341362571344e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.39 | train loss last: 3.34 | consumed tokens: 222003200.0 | grad norm avg: 0.76 | grad norm last: 0.75 | 
2026-01-01T18:54:51 | step: 27200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.989429726265371e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.38 | train loss last: 3.08 | consumed tokens: 222822400.0 | grad norm avg: 0.76 | grad norm last: 0.74 | 
2026-01-01T18:55:06 | step: 27300 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.9893249524757266e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.37 | train loss last: 3.45 | consumed tokens: 223641600.0 | grad norm avg: 0.75 | grad norm last: 0.77 | 
2026-01-01T18:55:22 | step: 27400 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.9892198148882017e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.37 | train loss last: 3.83 | consumed tokens: 224460800.0 | grad norm avg: 0.75 | grad norm last: 0.75 | 
2026-01-01T18:55:38 | step: 27500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.989114313502796e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.19 | consumed tokens: 225280000.0 | grad norm avg: 0.75 | grad norm last: 0.78 | 
2026-01-01T18:55:53 | step: 27600 | train samples/s: 103.4 | train mfu (16-bit): -1.0 | lr mean: 4.989008084521629e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 3.61 | consumed tokens: 226099200.0 | grad norm avg: 0.75 | grad norm last: 0.73 | 
2026-01-01T18:56:09 | step: 27700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.9889011279447004e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.36 | train loss last: 4.25 | consumed tokens: 226918400.0 | grad norm avg: 0.75 | grad norm last: 0.72 | 
2026-01-01T18:56:25 | step: 27800 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.988793807569891e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.52 | consumed tokens: 227737600.0 | grad norm avg: 0.75 | grad norm last: 0.85 | 
2026-01-01T18:56:40 | step: 27900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.988686123397201e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.37 | train loss last: 3.56 | consumed tokens: 228556800.0 | grad norm avg: 0.75 | grad norm last: 0.78 | 
2026-01-01T18:56:56 | step: 28000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.98857771162875e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.37 | train loss last: 3.39 | consumed tokens: 229376000.0 | grad norm avg: 0.76 | grad norm last: 0.76 | 
2026-01-01T18:57:11 | step: 28100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.988468936062418e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.36 | train loss last: 2.97 | consumed tokens: 230195200.0 | grad norm avg: 0.76 | grad norm last: 0.72 | 
2026-01-01T18:57:26 | step: 28200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.988359796698205e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.36 | train loss last: 3.27 | consumed tokens: 231014400.0 | grad norm avg: 0.75 | grad norm last: 0.78 | 
2026-01-01T18:57:42 | step: 28300 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.988249929738231e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.37 | train loss last: 3.25 | consumed tokens: 231833600.0 | grad norm avg: 0.75 | grad norm last: 0.76 | 
2026-01-01T18:57:57 | step: 28400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.9881393351824954e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.39 | train loss last: 3.86 | consumed tokens: 232652800.0 | grad norm avg: 0.76 | grad norm last: 0.8 | 
2026-01-01T18:58:13 | step: 28500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.98802874062676e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.38 | train loss last: 3.12 | consumed tokens: 233472000.0 | grad norm avg: 0.75 | grad norm last: 0.75 | 
2026-01-01T18:58:28 | step: 28600 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.987917054677382e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.37 | train loss last: 3.53 | consumed tokens: 234291200.0 | grad norm avg: 0.75 | grad norm last: 0.8 | 
2026-01-01T18:58:44 | step: 28700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.9878053687280044e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.39 | train loss last: 3.75 | consumed tokens: 235110400.0 | grad norm avg: 0.75 | grad norm last: 0.74 | 
2026-01-01T18:59:00 | step: 28800 | train samples/s: 103.7 | train mfu (16-bit): -1.0 | lr mean: 4.987692955182865e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.37 | train loss last: 3.83 | consumed tokens: 235929600.0 | grad norm avg: 0.75 | grad norm last: 0.76 | 
2026-01-01T18:59:15 | step: 28900 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.987579814041965e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.38 | train loss last: 3.44 | consumed tokens: 236748800.0 | grad norm avg: 0.75 | grad norm last: 0.76 | 
2026-01-01T18:59:31 | step: 29000 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.9874663091031834e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.36 | train loss last: 2.78 | consumed tokens: 237568000.0 | grad norm avg: 0.75 | grad norm last: 0.74 | 
2026-01-01T18:59:46 | step: 29100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.9873524403665215e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.4 | train loss last: 3.11 | consumed tokens: 238387200.0 | grad norm avg: 0.75 | grad norm last: 0.72 | 
2026-01-01T19:00:02 | step: 29200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.987238207831979e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.37 | train loss last: 3.02 | consumed tokens: 239206400.0 | grad norm avg: 0.75 | grad norm last: 0.85 | 
2026-01-01T19:00:17 | step: 29300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.987122883903794e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.32 | train loss last: 3.5 | consumed tokens: 240025600.0 | grad norm avg: 0.75 | grad norm last: 0.76 | 
2026-01-01T19:00:33 | step: 29400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.987007559975609e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.38 | train loss last: 3.28 | consumed tokens: 240844800.0 | grad norm avg: 0.76 | grad norm last: 0.77 | 
2026-01-01T19:00:48 | step: 29500 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.986891508451663e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.48 | consumed tokens: 241664000.0 | grad norm avg: 0.75 | grad norm last: 0.79 | 
2026-01-01T19:01:04 | step: 29600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.986775093129836e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.32 | train loss last: 3.19 | consumed tokens: 242483200.0 | grad norm avg: 0.75 | grad norm last: 0.75 | 
2026-01-01T19:01:19 | step: 29700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.986657950212248e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 3.28 | consumed tokens: 243302400.0 | grad norm avg: 0.75 | grad norm last: 0.75 | 
2026-01-01T19:01:35 | step: 29800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.9865404434967786e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.35 | train loss last: 2.7 | consumed tokens: 244121600.0 | grad norm avg: 0.75 | grad norm last: 0.74 | 
2026-01-01T19:01:50 | step: 29900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.986422209185548e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.38 | train loss last: 3.34 | consumed tokens: 244940800.0 | grad norm avg: 0.75 | grad norm last: 0.73 | 
2026-01-01T19:02:05 | step: 30000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.986303611076437e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.38 | train loss last: 2.81 | consumed tokens: 245760000.0 | grad norm avg: 0.75 | grad norm last: 0.73 | 
2026-01-01T19:02:23 | step: 30100 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 4.986184649169445e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.36 | train loss last: 3.48 | consumed tokens: 246579200.0 | grad norm avg: 0.74 | grad norm last: 0.73 | 
2026-01-01T19:02:38 | step: 30200 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.986064959666692e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 3.45 | consumed tokens: 247398400.0 | grad norm avg: 0.75 | grad norm last: 0.79 | 
2026-01-01T19:02:54 | step: 30300 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.985944906366058e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.35 | train loss last: 2.95 | consumed tokens: 248217600.0 | grad norm avg: 0.75 | grad norm last: 0.74 | 
2026-01-01T19:03:09 | step: 30400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.985824125469662e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.37 | train loss last: 2.97 | consumed tokens: 249036800.0 | grad norm avg: 0.75 | grad norm last: 0.75 | 
2026-01-01T19:03:25 | step: 30500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.985702980775386e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 3.7 | consumed tokens: 249856000.0 | grad norm avg: 0.75 | grad norm last: 0.77 | 
2026-01-01T19:03:40 | step: 30600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.985581472283229e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.35 | train loss last: 2.55 | consumed tokens: 250675200.0 | grad norm avg: 0.76 | grad norm last: 0.77 | 
2026-01-01T19:03:56 | step: 30700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.985459236195311e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.06 | consumed tokens: 251494400.0 | grad norm avg: 0.74 | grad norm last: 0.71 | 
2026-01-01T19:04:11 | step: 30800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.985336272511631e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 4.06 | consumed tokens: 252313600.0 | grad norm avg: 0.75 | grad norm last: 0.74 | 
2026-01-01T19:04:27 | step: 30900 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.9852133088279516e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.35 | train loss last: 3.66 | consumed tokens: 253132800.0 | grad norm avg: 0.75 | grad norm last: 0.8 | 
2026-01-01T19:04:42 | step: 31000 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.9850896175485104e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.38 | train loss last: 2.77 | consumed tokens: 253952000.0 | grad norm avg: 0.75 | grad norm last: 0.8 | 
2026-01-01T19:04:58 | step: 31100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.984965198673308e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 3.0 | consumed tokens: 254771200.0 | grad norm avg: 0.75 | grad norm last: 0.83 | 
2026-01-01T19:05:13 | step: 31200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.9848404160002246e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 2.89 | consumed tokens: 255590400.0 | grad norm avg: 0.75 | grad norm last: 0.75 | 
2026-01-01T19:05:29 | step: 31300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.984715269529261e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.36 | train loss last: 3.73 | consumed tokens: 256409600.0 | grad norm avg: 0.75 | grad norm last: 0.81 | 
2026-01-01T19:05:44 | step: 31400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.984589395462535e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.35 | train loss last: 3.33 | consumed tokens: 257228800.0 | grad norm avg: 0.74 | grad norm last: 0.8 | 
2026-01-01T19:06:00 | step: 31500 | train samples/s: 103.4 | train mfu (16-bit): -1.0 | lr mean: 4.984463157597929e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.35 | train loss last: 3.56 | consumed tokens: 258048000.0 | grad norm avg: 0.74 | grad norm last: 0.76 | 
2026-01-01T19:06:15 | step: 31600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.984336192137562e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.37 | train loss last: 3.56 | consumed tokens: 258867200.0 | grad norm avg: 0.75 | grad norm last: 0.77 | 
2026-01-01T19:06:31 | step: 31700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.9842088628793135e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.35 | train loss last: 3.84 | consumed tokens: 259686400.0 | grad norm avg: 0.77 | grad norm last: 0.78 | 
2026-01-01T19:06:46 | step: 31800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.9840811698231846e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 3.28 | consumed tokens: 260505600.0 | grad norm avg: 0.75 | grad norm last: 0.72 | 
2026-01-01T19:07:02 | step: 31900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.983952749171294e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.39 | train loss last: 3.73 | consumed tokens: 261324800.0 | grad norm avg: 0.74 | grad norm last: 0.85 | 
2026-01-01T19:07:18 | step: 32000 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.983823964721523e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.35 | train loss last: 3.05 | consumed tokens: 262144000.0 | grad norm avg: 0.75 | grad norm last: 0.68 | 
2026-01-01T19:07:33 | step: 32100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.983694452675991e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.48 | consumed tokens: 262963200.0 | grad norm avg: 0.74 | grad norm last: 0.73 | 
2026-01-01T19:07:48 | step: 32200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.9835645768325776e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.37 | train loss last: 3.3 | consumed tokens: 263782400.0 | grad norm avg: 0.75 | grad norm last: 0.74 | 
2026-01-01T19:08:04 | step: 32300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.983434337191284e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.36 | train loss last: 2.92 | consumed tokens: 264601600.0 | grad norm avg: 0.75 | grad norm last: 0.75 | 
2026-01-01T19:08:19 | step: 32400 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.9833033699542284e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.34 | consumed tokens: 265420800.0 | grad norm avg: 0.74 | grad norm last: 0.74 | 
2026-01-01T19:08:35 | step: 32500 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.983171675121412e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.35 | train loss last: 2.98 | consumed tokens: 266240000.0 | grad norm avg: 0.75 | grad norm last: 0.78 | 
2026-01-01T19:08:50 | step: 32600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.983039980288595e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.36 | consumed tokens: 267059200.0 | grad norm avg: 0.75 | grad norm last: 0.72 | 
2026-01-01T19:09:06 | step: 32700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.982907194062136e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.35 | train loss last: 3.05 | consumed tokens: 267878400.0 | grad norm avg: 0.74 | grad norm last: 0.72 | 
2026-01-01T19:09:22 | step: 32800 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.982774407835677e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.37 | train loss last: 3.59 | consumed tokens: 268697600.0 | grad norm avg: 0.74 | grad norm last: 0.77 | 
2026-01-01T19:09:37 | step: 32900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.982640894013457e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.35 | train loss last: 3.7 | consumed tokens: 269516800.0 | grad norm avg: 0.75 | grad norm last: 0.73 | 
2026-01-01T19:09:52 | step: 33000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.982507016393356e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.12 | consumed tokens: 270336000.0 | grad norm avg: 0.74 | grad norm last: 0.74 | 
2026-01-01T19:10:08 | step: 33100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.9823724111774936e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.35 | train loss last: 3.23 | consumed tokens: 271155200.0 | grad norm avg: 0.74 | grad norm last: 0.72 | 
2026-01-01T19:10:23 | step: 33200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.9822374421637505e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 3.47 | consumed tokens: 271974400.0 | grad norm avg: 0.74 | grad norm last: 0.71 | 
2026-01-01T19:10:39 | step: 33300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.982101745554246e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.35 | train loss last: 3.83 | consumed tokens: 272793600.0 | grad norm avg: 0.74 | grad norm last: 0.75 | 
2026-01-01T19:10:54 | step: 33400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.981965685146861e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.75 | consumed tokens: 273612800.0 | grad norm avg: 0.74 | grad norm last: 0.73 | 
2026-01-01T19:11:10 | step: 33500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.981829260941595e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 4.06 | consumed tokens: 274432000.0 | grad norm avg: 0.74 | grad norm last: 0.71 | 
2026-01-01T19:11:25 | step: 33600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.9816921091405675e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 3.66 | consumed tokens: 275251200.0 | grad norm avg: 0.74 | grad norm last: 0.72 | 
2026-01-01T19:11:41 | step: 33700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.9815545935416594e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.35 | train loss last: 3.69 | consumed tokens: 276070400.0 | grad norm avg: 0.74 | grad norm last: 0.83 | 
2026-01-01T19:11:56 | step: 33800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.98141635034699e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.36 | train loss last: 3.31 | consumed tokens: 276889600.0 | grad norm avg: 0.73 | grad norm last: 0.68 | 
2026-01-01T19:12:12 | step: 33900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.98127774335444e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.33 | consumed tokens: 277708800.0 | grad norm avg: 0.74 | grad norm last: 0.79 | 
2026-01-01T19:12:27 | step: 34000 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.981138408766128e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 4.12 | consumed tokens: 278528000.0 | grad norm avg: 0.74 | grad norm last: 0.73 | 
2026-01-01T19:12:43 | step: 34100 | train samples/s: 103.3 | train mfu (16-bit): -1.0 | lr mean: 4.980998710379936e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.36 | train loss last: 4.09 | consumed tokens: 279347200.0 | grad norm avg: 0.74 | grad norm last: 0.73 | 
2026-01-01T19:12:59 | step: 34200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.980858648195863e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 3.09 | consumed tokens: 280166400.0 | grad norm avg: 0.74 | grad norm last: 0.75 | 
2026-01-01T19:13:14 | step: 34300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.980717858416028e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.36 | train loss last: 3.33 | consumed tokens: 280985600.0 | grad norm avg: 0.74 | grad norm last: 0.76 | 
2026-01-01T19:13:29 | step: 34400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.980576704838313e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 3.3 | consumed tokens: 281804800.0 | grad norm avg: 0.74 | grad norm last: 0.72 | 
2026-01-01T19:13:45 | step: 34500 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.980435187462717e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 3.25 | consumed tokens: 282624000.0 | grad norm avg: 0.75 | grad norm last: 0.73 | 
2026-01-01T19:14:00 | step: 34600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.98029294249136e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.32 | train loss last: 3.48 | consumed tokens: 283443200.0 | grad norm avg: 0.74 | grad norm last: 0.72 | 
2026-01-01T19:14:16 | step: 34700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.980150333722122e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.32 | train loss last: 3.11 | consumed tokens: 284262400.0 | grad norm avg: 0.74 | grad norm last: 0.74 | 
2026-01-01T19:14:31 | step: 34800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.9800069973571226e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 3.19 | consumed tokens: 285081600.0 | grad norm avg: 0.74 | grad norm last: 0.78 | 
2026-01-01T19:14:47 | step: 34900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.9798632971942425e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.32 | train loss last: 3.42 | consumed tokens: 285900800.0 | grad norm avg: 0.74 | grad norm last: 0.74 | 
2026-01-01T19:15:02 | step: 35000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.979718869435601e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.56 | consumed tokens: 286720000.0 | grad norm avg: 0.74 | grad norm last: 0.77 | 
2026-01-01T19:15:19 | step: 35100 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.979574077879079e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.32 | train loss last: 3.25 | consumed tokens: 287539200.0 | grad norm avg: 0.74 | grad norm last: 0.73 | 
2026-01-01T19:15:35 | step: 35200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.979428922524676e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 2.94 | consumed tokens: 288358400.0 | grad norm avg: 0.74 | grad norm last: 0.71 | 
2026-01-01T19:15:50 | step: 35300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.9792830395745113e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.35 | train loss last: 3.67 | consumed tokens: 289177600.0 | grad norm avg: 0.74 | grad norm last: 0.73 | 
2026-01-01T19:16:06 | step: 35400 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 4.979136792826466e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.36 | train loss last: 3.27 | consumed tokens: 289996800.0 | grad norm avg: 0.73 | grad norm last: 0.73 | 
2026-01-01T19:16:21 | step: 35500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.97898981848266e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 3.61 | consumed tokens: 290816000.0 | grad norm avg: 0.73 | grad norm last: 0.69 | 
2026-01-01T19:16:38 | step: 35600 | train samples/s: 98.8 | train mfu (16-bit): -1.0 | lr mean: 4.9788424803409725e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.36 | train loss last: 3.8 | consumed tokens: 291635200.0 | grad norm avg: 0.74 | grad norm last: 0.75 | 
2026-01-01T19:16:53 | step: 35700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.9786947784014046e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 3.14 | consumed tokens: 292454400.0 | grad norm avg: 0.74 | grad norm last: 0.71 | 
2026-01-01T19:17:09 | step: 35800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.978546348866075e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.36 | train loss last: 3.2 | consumed tokens: 293273600.0 | grad norm avg: 0.74 | grad norm last: 0.71 | 
2026-01-01T19:17:24 | step: 35900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.9783971917349845e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.28 | consumed tokens: 294092800.0 | grad norm avg: 0.74 | grad norm last: 0.71 | 
2026-01-01T19:17:40 | step: 36000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.978248034603894e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.33 | consumed tokens: 294912000.0 | grad norm avg: 0.74 | grad norm last: 0.76 | 
2026-01-01T19:17:55 | step: 36100 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.9780981498770416e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 3.7 | consumed tokens: 295731200.0 | grad norm avg: 0.74 | grad norm last: 0.7 | 
2026-01-01T19:18:11 | step: 36200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.977947537554428e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 3.33 | consumed tokens: 296550400.0 | grad norm avg: 0.74 | grad norm last: 0.71 | 
2026-01-01T19:18:26 | step: 36300 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.977796561433934e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 3.5 | consumed tokens: 297369600.0 | grad norm avg: 0.73 | grad norm last: 0.74 | 
2026-01-01T19:18:42 | step: 36400 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.9776452215155587e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.35 | train loss last: 3.28 | consumed tokens: 298188800.0 | grad norm avg: 0.75 | grad norm last: 0.74 | 
2026-01-01T19:18:57 | step: 36500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.977493154001422e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.52 | consumed tokens: 299008000.0 | grad norm avg: 0.73 | grad norm last: 0.79 | 
2026-01-01T19:19:13 | step: 36600 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.977340722689405e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.36 | train loss last: 3.52 | consumed tokens: 299827200.0 | grad norm avg: 0.74 | grad norm last: 0.69 | 
2026-01-01T19:19:29 | step: 36700 | train samples/s: 103.0 | train mfu (16-bit): -1.0 | lr mean: 4.977187927579507e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.3 | train loss last: 2.94 | consumed tokens: 300646400.0 | grad norm avg: 0.75 | grad norm last: 0.74 | 
2026-01-01T19:19:44 | step: 36800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.977034404873848e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.02 | consumed tokens: 301465600.0 | grad norm avg: 0.74 | grad norm last: 0.72 | 
2026-01-01T19:20:00 | step: 36900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.976880154572427e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 3.44 | consumed tokens: 302284800.0 | grad norm avg: 0.74 | grad norm last: 0.72 | 
2026-01-01T19:20:15 | step: 37000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.9767259042710066e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 3.25 | consumed tokens: 303104000.0 | grad norm avg: 0.74 | grad norm last: 0.73 | 
2026-01-01T19:20:31 | step: 37100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.976570562575944e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 3.42 | consumed tokens: 303923200.0 | grad norm avg: 0.74 | grad norm last: 0.71 | 
2026-01-01T19:20:46 | step: 37200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.976415220880881e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 3.47 | consumed tokens: 304742400.0 | grad norm avg: 0.73 | grad norm last: 0.76 | 
2026-01-01T19:21:02 | step: 37300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.976259151590057e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.16 | consumed tokens: 305561600.0 | grad norm avg: 0.74 | grad norm last: 0.7 | 
2026-01-01T19:21:17 | step: 37400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.976102718501352e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.35 | train loss last: 3.56 | consumed tokens: 306380800.0 | grad norm avg: 0.73 | grad norm last: 0.7 | 
2026-01-01T19:21:32 | step: 37500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.9759455578168854e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.3 | train loss last: 4.34 | consumed tokens: 307200000.0 | grad norm avg: 0.73 | grad norm last: 0.74 | 
2026-01-01T19:21:48 | step: 37600 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.9757880333345383e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.35 | train loss last: 3.3 | consumed tokens: 308019200.0 | grad norm avg: 0.74 | grad norm last: 0.73 | 
2026-01-01T19:22:04 | step: 37700 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.97562978125643e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 4.16 | consumed tokens: 308838400.0 | grad norm avg: 0.73 | grad norm last: 0.77 | 
2026-01-01T19:22:19 | step: 37800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.9754711653804407e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 3.11 | consumed tokens: 309657600.0 | grad norm avg: 0.74 | grad norm last: 0.77 | 
2026-01-01T19:22:35 | step: 37900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.97531182190869e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 2.92 | consumed tokens: 310476800.0 | grad norm avg: 0.73 | grad norm last: 0.73 | 
2026-01-01T19:22:50 | step: 38000 | train samples/s: 103.5 | train mfu (16-bit): -1.0 | lr mean: 4.9751524784369394e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.66 | consumed tokens: 311296000.0 | grad norm avg: 0.74 | grad norm last: 0.71 | 
2026-01-01T19:23:06 | step: 38100 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.974992043571547e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.32 | train loss last: 4.03 | consumed tokens: 312115200.0 | grad norm avg: 0.73 | grad norm last: 0.74 | 
2026-01-01T19:23:21 | step: 38200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.974831608706154e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 3.34 | consumed tokens: 312934400.0 | grad norm avg: 0.73 | grad norm last: 0.74 | 
2026-01-01T19:23:37 | step: 38300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.974670446245e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.32 | train loss last: 3.31 | consumed tokens: 313753600.0 | grad norm avg: 0.74 | grad norm last: 0.74 | 
2026-01-01T19:23:52 | step: 38400 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.974508556188084e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 2.94 | consumed tokens: 314572800.0 | grad norm avg: 0.73 | grad norm last: 0.74 | 
2026-01-01T19:24:08 | step: 38500 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.974346302333288e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 3.5 | consumed tokens: 315392000.0 | grad norm avg: 0.74 | grad norm last: 0.7 | 
2026-01-01T19:24:24 | step: 38600 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.974183684680611e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.32 | train loss last: 3.67 | consumed tokens: 316211200.0 | grad norm avg: 0.73 | grad norm last: 0.69 | 
2026-01-01T19:24:39 | step: 38700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.9740203394321725e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 2.97 | consumed tokens: 317030400.0 | grad norm avg: 0.73 | grad norm last: 0.72 | 
2026-01-01T19:24:54 | step: 38800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.9738566303858534e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 3.61 | consumed tokens: 317849600.0 | grad norm avg: 0.73 | grad norm last: 0.74 | 
2026-01-01T19:25:10 | step: 38900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.9736925575416535e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.47 | consumed tokens: 318668800.0 | grad norm avg: 0.73 | grad norm last: 0.68 | 
2026-01-01T19:25:25 | step: 39000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.973527757101692e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 2.69 | consumed tokens: 319488000.0 | grad norm avg: 0.73 | grad norm last: 0.73 | 
2026-01-01T19:25:41 | step: 39100 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.97336259286385e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.8 | consumed tokens: 320307200.0 | grad norm avg: 0.74 | grad norm last: 0.71 | 
2026-01-01T19:25:57 | step: 39200 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.973196701030247e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.12 | consumed tokens: 321126400.0 | grad norm avg: 0.74 | grad norm last: 0.74 | 
2026-01-01T19:26:12 | step: 39300 | train samples/s: 103.4 | train mfu (16-bit): -1.0 | lr mean: 4.973030445398763e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.32 | train loss last: 3.38 | consumed tokens: 321945600.0 | grad norm avg: 0.73 | grad norm last: 0.77 | 
2026-01-01T19:26:28 | step: 39400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.972863462171517e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 2.86 | consumed tokens: 322764800.0 | grad norm avg: 0.73 | grad norm last: 0.74 | 
2026-01-01T19:26:43 | step: 39500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.972696115146391e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.09 | consumed tokens: 323584000.0 | grad norm avg: 0.73 | grad norm last: 0.72 | 
2026-01-01T19:26:59 | step: 39600 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.972528404323384e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.32 | train loss last: 2.77 | consumed tokens: 324403200.0 | grad norm avg: 0.74 | grad norm last: 1.55 | 
2026-01-01T19:27:14 | step: 39700 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.972359965904616e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 3.19 | consumed tokens: 325222400.0 | grad norm avg: 0.73 | grad norm last: 0.74 | 
2026-01-01T19:27:30 | step: 39800 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.972191163687967e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.36 | train loss last: 3.89 | consumed tokens: 326041600.0 | grad norm avg: 0.74 | grad norm last: 0.73 | 
2026-01-01T19:27:45 | step: 39900 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.972021997673437e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.32 | train loss last: 3.28 | consumed tokens: 326860800.0 | grad norm avg: 0.73 | grad norm last: 0.73 | 
2026-01-01T19:28:01 | step: 40000 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.971852104063146e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.36 | train loss last: 3.05 | consumed tokens: 327680000.0 | grad norm avg: 0.73 | grad norm last: 0.77 | 
2026-01-01T19:28:18 | step: 40100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.971681482857093e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.41 | consumed tokens: 328499200.0 | grad norm avg: 0.73 | grad norm last: 0.72 | 
2026-01-01T19:28:33 | step: 40200 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.97151049785316e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.16 | consumed tokens: 329318400.0 | grad norm avg: 0.73 | grad norm last: 0.74 | 
2026-01-01T19:28:49 | step: 40300 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.971339149051346e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.3 | train loss last: 3.17 | consumed tokens: 330137600.0 | grad norm avg: 0.73 | grad norm last: 0.73 | 
2026-01-01T19:29:04 | step: 40400 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.971167436451651e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 2.81 | consumed tokens: 330956800.0 | grad norm avg: 0.73 | grad norm last: 0.79 | 
2026-01-01T19:29:20 | step: 40500 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.970994996256195e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 3.53 | consumed tokens: 331776000.0 | grad norm avg: 0.72 | grad norm last: 0.74 | 
2026-01-01T19:29:36 | step: 40600 | train samples/s: 103.5 | train mfu (16-bit): -1.0 | lr mean: 4.9708218284649774e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.32 | train loss last: 2.84 | consumed tokens: 332595200.0 | grad norm avg: 0.73 | grad norm last: 0.7 | 
2026-01-01T19:29:51 | step: 40700 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.97064866067376e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 3.53 | consumed tokens: 333414400.0 | grad norm avg: 0.73 | grad norm last: 0.72 | 
2026-01-01T19:30:07 | step: 40800 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.9704744014889e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.3 | train loss last: 3.09 | consumed tokens: 334233600.0 | grad norm avg: 0.73 | grad norm last: 0.74 | 
2026-01-01T19:30:23 | step: 40900 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.9703001423040405e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 3.16 | consumed tokens: 335052800.0 | grad norm avg: 0.73 | grad norm last: 0.74 | 
2026-01-01T19:30:38 | step: 41000 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.9701251555234194e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.02 | consumed tokens: 335872000.0 | grad norm avg: 0.73 | grad norm last: 0.74 | 
2026-01-01T19:30:54 | step: 41100 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.969949441147037e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 2.81 | consumed tokens: 336691200.0 | grad norm avg: 0.73 | grad norm last: 0.74 | 
2026-01-01T19:31:09 | step: 41200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.969773726770654e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.32 | train loss last: 3.55 | consumed tokens: 337510400.0 | grad norm avg: 0.72 | grad norm last: 0.67 | 
2026-01-01T19:31:25 | step: 41300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.96959692100063e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 3.03 | consumed tokens: 338329600.0 | grad norm avg: 0.73 | grad norm last: 0.73 | 
2026-01-01T19:31:40 | step: 41400 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.969420115230605e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.03 | consumed tokens: 339148800.0 | grad norm avg: 0.73 | grad norm last: 0.75 | 
2026-01-01T19:31:56 | step: 41500 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.969242581864819e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.3 | train loss last: 3.78 | consumed tokens: 339968000.0 | grad norm avg: 0.73 | grad norm last: 0.7 | 
2026-01-01T19:32:11 | step: 41600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.9690643209032714e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.32 | train loss last: 3.06 | consumed tokens: 340787200.0 | grad norm avg: 0.73 | grad norm last: 0.77 | 
2026-01-01T19:32:27 | step: 41700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.968885696143843e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 3.75 | consumed tokens: 341606400.0 | grad norm avg: 0.73 | grad norm last: 0.72 | 
2026-01-01T19:32:42 | step: 41800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.968706707586534e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 2.97 | consumed tokens: 342425600.0 | grad norm avg: 0.73 | grad norm last: 0.75 | 
2026-01-01T19:32:58 | step: 41900 | train samples/s: 103.0 | train mfu (16-bit): -1.0 | lr mean: 4.968526991433464e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 3.47 | consumed tokens: 343244800.0 | grad norm avg: 0.73 | grad norm last: 0.75 | 
2026-01-01T19:33:14 | step: 42000 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.968346911482513e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 2.83 | consumed tokens: 344064000.0 | grad norm avg: 0.73 | grad norm last: 0.76 | 
2026-01-01T19:33:29 | step: 42100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.968166467733681e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.06 | consumed tokens: 344883200.0 | grad norm avg: 0.74 | grad norm last: 0.73 | 
2026-01-01T19:33:44 | step: 42200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.967985296389088e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.06 | consumed tokens: 345702400.0 | grad norm avg: 0.73 | grad norm last: 0.67 | 
2026-01-01T19:34:00 | step: 42300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.967803761246614e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.34 | consumed tokens: 346521600.0 | grad norm avg: 0.73 | grad norm last: 0.7 | 
2026-01-01T19:34:15 | step: 42400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.967621498508379e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.32 | train loss last: 3.27 | consumed tokens: 347340800.0 | grad norm avg: 0.73 | grad norm last: 0.7 | 
2026-01-01T19:34:31 | step: 42500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.967438871972263e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 3.61 | consumed tokens: 348160000.0 | grad norm avg: 0.72 | grad norm last: 0.74 | 
2026-01-01T19:34:46 | step: 42600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.967255881638266e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 2.91 | consumed tokens: 348979200.0 | grad norm avg: 0.73 | grad norm last: 0.7 | 
2026-01-01T19:35:02 | step: 42700 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.967072163708508e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 2.78 | consumed tokens: 349798400.0 | grad norm avg: 0.73 | grad norm last: 0.69 | 
2026-01-01T19:35:18 | step: 42800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.966888081980869e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 4.0 | consumed tokens: 350617600.0 | grad norm avg: 0.73 | grad norm last: 0.72 | 
2026-01-01T19:35:33 | step: 42900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.966703272657469e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 2.8 | consumed tokens: 351436800.0 | grad norm avg: 0.73 | grad norm last: 0.74 | 
2026-01-01T19:35:48 | step: 43000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.966518099536188e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.67 | consumed tokens: 352256000.0 | grad norm avg: 0.73 | grad norm last: 0.72 | 
2026-01-01T19:36:04 | step: 43100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.9663321988191456e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.3 | train loss last: 3.17 | consumed tokens: 353075200.0 | grad norm avg: 0.73 | grad norm last: 0.67 | 
2026-01-01T19:36:20 | step: 43200 | train samples/s: 103.5 | train mfu (16-bit): -1.0 | lr mean: 4.9661459343042225e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.66 | consumed tokens: 353894400.0 | grad norm avg: 0.72 | grad norm last: 0.75 | 
2026-01-01T19:36:35 | step: 43300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.9659593059914187e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 3.45 | consumed tokens: 354713600.0 | grad norm avg: 0.73 | grad norm last: 0.7 | 
2026-01-01T19:36:51 | step: 43400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.9657719500828534e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 2.73 | consumed tokens: 355532800.0 | grad norm avg: 0.73 | grad norm last: 0.81 | 
2026-01-01T19:37:06 | step: 43500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.9655842303764075e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.32 | train loss last: 3.39 | consumed tokens: 356352000.0 | grad norm avg: 0.72 | grad norm last: 0.81 | 
2026-01-01T19:37:22 | step: 43600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.965396146872081e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.3 | train loss last: 2.59 | consumed tokens: 357171200.0 | grad norm avg: 0.72 | grad norm last: 0.71 | 
2026-01-01T19:37:37 | step: 43700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.965207335771993e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.3 | train loss last: 2.64 | consumed tokens: 357990400.0 | grad norm avg: 0.73 | grad norm last: 0.71 | 
2026-01-01T19:37:53 | step: 43800 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.965018160874024e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 2.61 | consumed tokens: 358809600.0 | grad norm avg: 0.73 | grad norm last: 0.77 | 
2026-01-01T19:38:08 | step: 43900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.964828258380294e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.33 | train loss last: 3.0 | consumed tokens: 359628800.0 | grad norm avg: 0.74 | grad norm last: 0.73 | 
2026-01-01T19:38:24 | step: 44000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.964637992088683e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.32 | train loss last: 4.16 | consumed tokens: 360448000.0 | grad norm avg: 0.73 | grad norm last: 0.74 | 
2026-01-01T19:38:39 | step: 44100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.9644469982013106e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.3 | train loss last: 3.59 | consumed tokens: 361267200.0 | grad norm avg: 0.74 | grad norm last: 0.78 | 
2026-01-01T19:38:55 | step: 44200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.964256004313938e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.0 | consumed tokens: 362086400.0 | grad norm avg: 0.72 | grad norm last: 0.75 | 
2026-01-01T19:39:10 | step: 44300 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.964063919032924e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.34 | consumed tokens: 362905600.0 | grad norm avg: 0.73 | grad norm last: 0.79 | 
2026-01-01T19:39:26 | step: 44400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.9638718337519094e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.5 | consumed tokens: 363724800.0 | grad norm avg: 0.73 | grad norm last: 0.72 | 
2026-01-01T19:39:42 | step: 44500 | train samples/s: 103.6 | train mfu (16-bit): -1.0 | lr mean: 4.963678657077253e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.0 | consumed tokens: 364544000.0 | grad norm avg: 0.72 | grad norm last: 0.74 | 
2026-01-01T19:39:57 | step: 44600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.963485480402596e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.27 | consumed tokens: 365363200.0 | grad norm avg: 0.73 | grad norm last: 0.7 | 
2026-01-01T19:40:13 | step: 44700 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.963291576132178e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 3.22 | consumed tokens: 366182400.0 | grad norm avg: 0.72 | grad norm last: 0.67 | 
2026-01-01T19:40:28 | step: 44800 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.9630973080638796e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.34 | train loss last: 3.03 | consumed tokens: 367001600.0 | grad norm avg: 0.72 | grad norm last: 0.73 | 
2026-01-01T19:40:44 | step: 44900 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.9629023123998195e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.08 | consumed tokens: 367820800.0 | grad norm avg: 0.73 | grad norm last: 0.73 | 
2026-01-01T19:40:59 | step: 45000 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.962706952937879e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.88 | consumed tokens: 368640000.0 | grad norm avg: 0.73 | grad norm last: 0.75 | 
2026-01-01T19:41:16 | step: 45100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.9625108658801764e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 3.48 | consumed tokens: 369459200.0 | grad norm avg: 0.72 | grad norm last: 0.72 | 
2026-01-01T19:41:32 | step: 45200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.962314778822474e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.28 | consumed tokens: 370278400.0 | grad norm avg: 0.73 | grad norm last: 0.72 | 
2026-01-01T19:41:47 | step: 45300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.96211760037113e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 3.55 | consumed tokens: 371097600.0 | grad norm avg: 0.72 | grad norm last: 0.69 | 
2026-01-01T19:42:03 | step: 45400 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.9619204219197854e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.3 | train loss last: 3.17 | consumed tokens: 371916800.0 | grad norm avg: 0.72 | grad norm last: 0.75 | 
2026-01-01T19:42:18 | step: 45500 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.961722152074799e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 2.89 | consumed tokens: 372736000.0 | grad norm avg: 0.73 | grad norm last: 0.72 | 
2026-01-01T19:42:34 | step: 45600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.9615238822298124e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.41 | consumed tokens: 373555200.0 | grad norm avg: 0.73 | grad norm last: 0.67 | 
2026-01-01T19:42:49 | step: 45700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.9613248847890645e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.19 | consumed tokens: 374374400.0 | grad norm avg: 0.72 | grad norm last: 0.73 | 
2026-01-01T19:43:05 | step: 45800 | train samples/s: 103.8 | train mfu (16-bit): -1.0 | lr mean: 4.961125523550436e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.3 | train loss last: 2.86 | consumed tokens: 375193600.0 | grad norm avg: 0.72 | grad norm last: 0.69 | 
2026-01-01T19:43:21 | step: 45900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.960925434716046e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.3 | train loss last: 3.25 | consumed tokens: 376012800.0 | grad norm avg: 0.73 | grad norm last: 0.7 | 
2026-01-01T19:43:36 | step: 46000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.960724982083775e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.28 | consumed tokens: 376832000.0 | grad norm avg: 0.73 | grad norm last: 0.7 | 
2026-01-01T19:43:52 | step: 46100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.960523801855743e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 2.97 | consumed tokens: 377651200.0 | grad norm avg: 0.72 | grad norm last: 0.72 | 
2026-01-01T19:44:07 | step: 46200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.960322621627711e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.27 | consumed tokens: 378470400.0 | grad norm avg: 0.73 | grad norm last: 0.71 | 
2026-01-01T19:44:23 | step: 46300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.9601203500060365e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.3 | train loss last: 3.23 | consumed tokens: 379289600.0 | grad norm avg: 0.73 | grad norm last: 0.74 | 
2026-01-01T19:44:38 | step: 46400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.959918078384362e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 2.75 | consumed tokens: 380108800.0 | grad norm avg: 0.72 | grad norm last: 0.74 | 
2026-01-01T19:44:54 | step: 46500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.959714715369046e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 2.78 | consumed tokens: 380928000.0 | grad norm avg: 0.73 | grad norm last: 0.69 | 
2026-01-01T19:45:09 | step: 46600 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.959511352353729e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.34 | consumed tokens: 381747200.0 | grad norm avg: 0.73 | grad norm last: 0.71 | 
2026-01-01T19:45:25 | step: 46700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.9593072617426515e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.3 | train loss last: 3.84 | consumed tokens: 382566400.0 | grad norm avg: 0.73 | grad norm last: 0.75 | 
2026-01-01T19:45:40 | step: 46800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.959102807333693e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.59 | consumed tokens: 383385600.0 | grad norm avg: 0.73 | grad norm last: 0.75 | 
2026-01-01T19:45:56 | step: 46900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.958897625328973e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.3 | consumed tokens: 384204800.0 | grad norm avg: 0.72 | grad norm last: 0.74 | 
2026-01-01T19:46:11 | step: 47000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.958692079526372e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 3.69 | consumed tokens: 385024000.0 | grad norm avg: 0.73 | grad norm last: 0.72 | 
2026-01-01T19:46:27 | step: 47100 | train samples/s: 102.6 | train mfu (16-bit): -1.0 | lr mean: 4.958486169925891e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.3 | train loss last: 3.25 | consumed tokens: 385843200.0 | grad norm avg: 0.72 | grad norm last: 0.74 | 
2026-01-01T19:46:43 | step: 47200 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.958279532729648e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 2.72 | consumed tokens: 386662400.0 | grad norm avg: 0.72 | grad norm last: 0.76 | 
2026-01-01T19:46:58 | step: 47300 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.958072167937644e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.3 | train loss last: 3.45 | consumed tokens: 387481600.0 | grad norm avg: 0.73 | grad norm last: 0.72 | 
2026-01-01T19:47:14 | step: 47400 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.9578648031456396e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.14 | consumed tokens: 388300800.0 | grad norm avg: 0.72 | grad norm last: 0.72 | 
2026-01-01T19:47:29 | step: 47500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.957656710757874e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.19 | consumed tokens: 389120000.0 | grad norm avg: 0.73 | grad norm last: 0.76 | 
2026-01-01T19:47:45 | step: 47600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.957447890774347e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 2.91 | consumed tokens: 389939200.0 | grad norm avg: 0.72 | grad norm last: 0.76 | 
2026-01-01T19:48:00 | step: 47700 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.957238706992939e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.3 | train loss last: 3.38 | consumed tokens: 390758400.0 | grad norm avg: 0.72 | grad norm last: 0.71 | 
2026-01-01T19:48:16 | step: 47800 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.9570291594136506e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.67 | consumed tokens: 391577600.0 | grad norm avg: 0.72 | grad norm last: 0.71 | 
2026-01-01T19:48:31 | step: 47900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.956818884238601e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.14 | consumed tokens: 392396800.0 | grad norm avg: 0.73 | grad norm last: 0.73 | 
2026-01-01T19:48:47 | step: 48000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.95660824526567e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 2.94 | consumed tokens: 393216000.0 | grad norm avg: 0.72 | grad norm last: 0.73 | 
2026-01-01T19:49:02 | step: 48100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.956397242494859e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.52 | consumed tokens: 394035200.0 | grad norm avg: 0.72 | grad norm last: 0.72 | 
2026-01-01T19:49:18 | step: 48200 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.956185512128286e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.39 | consumed tokens: 394854400.0 | grad norm avg: 0.72 | grad norm last: 0.73 | 
2026-01-01T19:49:34 | step: 48300 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.9559734179638326e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.3 | consumed tokens: 395673600.0 | grad norm avg: 0.73 | grad norm last: 0.72 | 
2026-01-01T19:49:49 | step: 48400 | train samples/s: 103.8 | train mfu (16-bit): -1.0 | lr mean: 4.955760596203618e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.3 | consumed tokens: 396492800.0 | grad norm avg: 0.73 | grad norm last: 0.75 | 
2026-01-01T19:50:05 | step: 48500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.955547410645522e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 2.61 | consumed tokens: 397312000.0 | grad norm avg: 0.72 | grad norm last: 0.73 | 
2026-01-01T19:50:20 | step: 48600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.955333861289546e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.08 | consumed tokens: 398131200.0 | grad norm avg: 0.73 | grad norm last: 0.69 | 
2026-01-01T19:50:36 | step: 48700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.955119584337808e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 2.84 | consumed tokens: 398950400.0 | grad norm avg: 0.72 | grad norm last: 0.74 | 
2026-01-01T19:50:51 | step: 48800 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.95490494358819e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.3 | consumed tokens: 399769600.0 | grad norm avg: 0.72 | grad norm last: 0.75 | 
2026-01-01T19:51:07 | step: 48900 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.95468957524281e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.11 | consumed tokens: 400588800.0 | grad norm avg: 0.73 | grad norm last: 0.74 | 
2026-01-01T19:51:22 | step: 49000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.9544738430995494e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.52 | consumed tokens: 401408000.0 | grad norm avg: 0.72 | grad norm last: 0.71 | 
2026-01-01T19:51:38 | step: 49100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.954257747158408e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 2.94 | consumed tokens: 402227200.0 | grad norm avg: 0.73 | grad norm last: 0.72 | 
2026-01-01T19:51:53 | step: 49200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.9540409236215055e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.55 | consumed tokens: 403046400.0 | grad norm avg: 0.72 | grad norm last: 0.69 | 
2026-01-01T19:52:09 | step: 49300 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.953823736286722e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.88 | consumed tokens: 403865600.0 | grad norm avg: 0.73 | grad norm last: 0.75 | 
2026-01-01T19:52:25 | step: 49400 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.953605821356177e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.72 | consumed tokens: 404684800.0 | grad norm avg: 0.72 | grad norm last: 0.71 | 
2026-01-01T19:52:40 | step: 49500 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.953387542627752e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.31 | train loss last: 2.91 | consumed tokens: 405504000.0 | grad norm avg: 0.73 | grad norm last: 0.74 | 
2026-01-01T19:52:56 | step: 49600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.9531689001014456e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.55 | consumed tokens: 406323200.0 | grad norm avg: 0.72 | grad norm last: 0.66 | 
2026-01-01T19:53:11 | step: 49700 | train samples/s: 103.8 | train mfu (16-bit): -1.0 | lr mean: 4.952949529979378e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 4.12 | consumed tokens: 407142400.0 | grad norm avg: 0.72 | grad norm last: 0.77 | 
2026-01-01T19:53:27 | step: 49800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.9527297960594296e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 4.41 | consumed tokens: 407961600.0 | grad norm avg: 0.72 | grad norm last: 0.71 | 
2026-01-01T19:53:43 | step: 49900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.95250933454372e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.05 | consumed tokens: 408780800.0 | grad norm avg: 0.72 | grad norm last: 0.76 | 
2026-01-01T19:53:58 | step: 50000 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.9522885092301294e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.36 | consumed tokens: 409600000.0 | grad norm avg: 0.73 | grad norm last: 0.71 | 
2026-01-01T19:54:15 | step: 50100 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.952067320118658e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.5 | consumed tokens: 410419200.0 | grad norm avg: 0.73 | grad norm last: 0.76 | 
2026-01-01T19:54:31 | step: 50200 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.9518454034114257e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.3 | consumed tokens: 411238400.0 | grad norm avg: 0.72 | grad norm last: 0.7 | 
2026-01-01T19:54:46 | step: 50300 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.9516231229063123e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.73 | consumed tokens: 412057600.0 | grad norm avg: 0.72 | grad norm last: 0.73 | 
2026-01-01T19:55:02 | step: 50400 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.9514001148054376e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.22 | consumed tokens: 412876800.0 | grad norm avg: 0.72 | grad norm last: 0.71 | 
2026-01-01T19:55:17 | step: 50500 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.951176742906682e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.22 | consumed tokens: 413696000.0 | grad norm avg: 0.72 | grad norm last: 0.73 | 
2026-01-01T19:55:33 | step: 50600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.950953007210046e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.25 | consumed tokens: 414515200.0 | grad norm avg: 0.73 | grad norm last: 0.71 | 
2026-01-01T19:55:48 | step: 50700 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.9507285439176485e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.5 | consumed tokens: 415334400.0 | grad norm avg: 0.72 | grad norm last: 0.74 | 
2026-01-01T19:56:04 | step: 50800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.95050371682737e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.3 | train loss last: 2.97 | consumed tokens: 416153600.0 | grad norm avg: 0.72 | grad norm last: 0.75 | 
2026-01-01T19:56:20 | step: 50900 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.950278525939211e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 2.84 | consumed tokens: 416972800.0 | grad norm avg: 0.72 | grad norm last: 0.76 | 
2026-01-01T19:56:35 | step: 51000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.950052607455291e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.3 | train loss last: 3.55 | consumed tokens: 417792000.0 | grad norm avg: 0.72 | grad norm last: 0.73 | 
2026-01-01T19:56:51 | step: 51100 | train samples/s: 103.0 | train mfu (16-bit): -1.0 | lr mean: 4.94982632517349e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 2.8 | consumed tokens: 418611200.0 | grad norm avg: 0.72 | grad norm last: 0.75 | 
2026-01-01T19:57:06 | step: 51200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.949599315295927e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.3 | consumed tokens: 419430400.0 | grad norm avg: 0.72 | grad norm last: 0.73 | 
2026-01-01T19:57:22 | step: 51300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.949371941620484e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.14 | consumed tokens: 420249600.0 | grad norm avg: 0.72 | grad norm last: 0.75 | 
2026-01-01T19:57:37 | step: 51400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.9491438403492793e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.3 | train loss last: 3.22 | consumed tokens: 421068800.0 | grad norm avg: 0.72 | grad norm last: 0.68 | 
2026-01-01T19:57:53 | step: 51500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.948915375280194e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 2.64 | consumed tokens: 421888000.0 | grad norm avg: 0.72 | grad norm last: 0.71 | 
2026-01-01T19:58:08 | step: 51600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.948686546413228e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 2.94 | consumed tokens: 422707200.0 | grad norm avg: 0.72 | grad norm last: 0.7 | 
2026-01-01T19:58:24 | step: 51700 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.948457353748381e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 2.62 | consumed tokens: 423526400.0 | grad norm avg: 0.72 | grad norm last: 0.68 | 
2026-01-01T19:58:39 | step: 51800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.948227433487773e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.38 | consumed tokens: 424345600.0 | grad norm avg: 0.72 | grad norm last: 0.69 | 
2026-01-01T19:58:55 | step: 51900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.947996785631403e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.11 | consumed tokens: 425164800.0 | grad norm avg: 0.71 | grad norm last: 0.68 | 
2026-01-01T19:59:10 | step: 52000 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.947765773977153e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.84 | consumed tokens: 425984000.0 | grad norm avg: 0.72 | grad norm last: 0.7 | 
2026-01-01T19:59:26 | step: 52100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.947534398525022e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.19 | consumed tokens: 426803200.0 | grad norm avg: 0.72 | grad norm last: 0.71 | 
2026-01-01T19:59:42 | step: 52200 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.9473022954771295e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.17 | consumed tokens: 427622400.0 | grad norm avg: 0.72 | grad norm last: 0.68 | 
2026-01-01T19:59:57 | step: 52300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.9470698286313564e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.61 | consumed tokens: 428441600.0 | grad norm avg: 0.72 | grad norm last: 0.74 | 
2026-01-01T20:00:13 | step: 52400 | train samples/s: 103.5 | train mfu (16-bit): -1.0 | lr mean: 4.9468369979877025e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.3 | train loss last: 2.7 | consumed tokens: 429260800.0 | grad norm avg: 0.72 | grad norm last: 0.72 | 
2026-01-01T20:00:28 | step: 52500 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.946603439748287e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.17 | consumed tokens: 430080000.0 | grad norm avg: 0.72 | grad norm last: 0.7 | 
2026-01-01T20:00:44 | step: 52600 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.946369517710991e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.42 | consumed tokens: 430899200.0 | grad norm avg: 0.72 | grad norm last: 1.14 | 
2026-01-01T20:01:00 | step: 52700 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.9461352318758145e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 2.48 | consumed tokens: 431718400.0 | grad norm avg: 0.72 | grad norm last: 0.7 | 
2026-01-01T20:01:15 | step: 52800 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.9459002184448764e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 2.55 | consumed tokens: 432537600.0 | grad norm avg: 0.72 | grad norm last: 0.73 | 
2026-01-01T20:01:31 | step: 52900 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.945664477418177e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.12 | consumed tokens: 433356800.0 | grad norm avg: 0.72 | grad norm last: 0.72 | 
2026-01-01T20:01:46 | step: 53000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.945428736391477e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 2.77 | consumed tokens: 434176000.0 | grad norm avg: 0.73 | grad norm last: 0.72 | 
2026-01-01T20:02:02 | step: 53100 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.9451919039711356e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.44 | consumed tokens: 434995200.0 | grad norm avg: 0.72 | grad norm last: 0.7 | 
2026-01-01T20:02:17 | step: 53200 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.944955071550794e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 2.92 | consumed tokens: 435814400.0 | grad norm avg: 0.72 | grad norm last: 0.71 | 
2026-01-01T20:02:33 | step: 53300 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.944717511534691e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.53 | consumed tokens: 436633600.0 | grad norm avg: 0.72 | grad norm last: 0.72 | 
2026-01-01T20:02:48 | step: 53400 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.944479587720707e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.25 | consumed tokens: 437452800.0 | grad norm avg: 0.72 | grad norm last: 0.69 | 
2026-01-01T20:03:04 | step: 53500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.944240936310962e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.11 | consumed tokens: 438272000.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:03:20 | step: 53600 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.944001921103336e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 2.95 | consumed tokens: 439091200.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-01T20:03:35 | step: 53700 | train samples/s: 102.6 | train mfu (16-bit): -1.0 | lr mean: 4.9437621782999486e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.08 | consumed tokens: 439910400.0 | grad norm avg: 0.72 | grad norm last: 0.73 | 
2026-01-01T20:03:51 | step: 53800 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.943522435496561e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 2.8 | consumed tokens: 440729600.0 | grad norm avg: 0.72 | grad norm last: 0.7 | 
2026-01-01T20:04:07 | step: 53900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.943281601299532e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.41 | consumed tokens: 441548800.0 | grad norm avg: 0.72 | grad norm last: 0.7 | 
2026-01-01T20:04:22 | step: 54000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.943040767102502e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.09 | consumed tokens: 442368000.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:04:38 | step: 54100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.9427992053097114e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.38 | consumed tokens: 443187200.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-01T20:04:53 | step: 54200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.942556915921159e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.39 | consumed tokens: 444006400.0 | grad norm avg: 0.72 | grad norm last: 0.71 | 
2026-01-01T20:05:09 | step: 54300 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.942314262734726e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.25 | consumed tokens: 444825600.0 | grad norm avg: 0.72 | grad norm last: 0.72 | 
2026-01-01T20:05:24 | step: 54400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.9420712457504123e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.25 | consumed tokens: 445644800.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:05:40 | step: 54500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.941827864968218e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 2.94 | consumed tokens: 446464000.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:05:56 | step: 54600 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.941583756590262e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.55 | consumed tokens: 447283200.0 | grad norm avg: 0.72 | grad norm last: 0.71 | 
2026-01-01T20:06:11 | step: 54700 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.941338920616545e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.45 | consumed tokens: 448102400.0 | grad norm avg: 0.72 | grad norm last: 0.69 | 
2026-01-01T20:06:27 | step: 54800 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.9410940846428275e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.05 | consumed tokens: 448921600.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-01T20:06:42 | step: 54900 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.940848521073349e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.28 | consumed tokens: 449740800.0 | grad norm avg: 0.71 | grad norm last: 0.75 | 
2026-01-01T20:06:58 | step: 55000 | train samples/s: 103.7 | train mfu (16-bit): -1.0 | lr mean: 4.940602229908109e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.94 | consumed tokens: 450560000.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-01T20:07:15 | step: 55100 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.940355574944988e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.47 | consumed tokens: 451379200.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-01T20:07:30 | step: 55200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.9401085561839864e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.23 | consumed tokens: 452198400.0 | grad norm avg: 0.71 | grad norm last: 0.76 | 
2026-01-01T20:07:46 | step: 55300 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.9398608098272234e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 2.94 | consumed tokens: 453017600.0 | grad norm avg: 0.72 | grad norm last: 0.73 | 
2026-01-01T20:08:02 | step: 55400 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.93961269967258e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.25 | consumed tokens: 453836800.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-01T20:08:17 | step: 55500 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.9393642257200554e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.08 | consumed tokens: 454656000.0 | grad norm avg: 0.72 | grad norm last: 0.69 | 
2026-01-01T20:08:33 | step: 55600 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.9391150241717696e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 2.97 | consumed tokens: 455475200.0 | grad norm avg: 0.72 | grad norm last: 0.74 | 
2026-01-01T20:08:48 | step: 55700 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.938865458825603e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.23 | consumed tokens: 456294400.0 | grad norm avg: 0.72 | grad norm last: 0.73 | 
2026-01-01T20:09:04 | step: 55800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.938615165883675e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.62 | consumed tokens: 457113600.0 | grad norm avg: 0.72 | grad norm last: 0.74 | 
2026-01-01T20:09:19 | step: 55900 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.9383645091438666e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 2.91 | consumed tokens: 457932800.0 | grad norm avg: 0.72 | grad norm last: 0.73 | 
2026-01-01T20:09:35 | step: 56000 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.938113488606177e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.27 | consumed tokens: 458752000.0 | grad norm avg: 0.72 | grad norm last: 0.79 | 
2026-01-01T20:09:51 | step: 56100 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.9378617404727265e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.23 | consumed tokens: 459571200.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T20:10:06 | step: 56200 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.937609628541395e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.33 | consumed tokens: 460390400.0 | grad norm avg: 0.72 | grad norm last: 0.72 | 
2026-01-01T20:10:22 | step: 56300 | train samples/s: 103.1 | train mfu (16-bit): -1.0 | lr mean: 4.937356789014302e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.38 | consumed tokens: 461209600.0 | grad norm avg: 0.72 | grad norm last: 0.71 | 
2026-01-01T20:10:38 | step: 56400 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.9371035856893286e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.84 | consumed tokens: 462028800.0 | grad norm avg: 0.72 | grad norm last: 0.71 | 
2026-01-01T20:10:53 | step: 56500 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.936850018566474e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.45 | consumed tokens: 462848000.0 | grad norm avg: 0.71 | grad norm last: 0.74 | 
2026-01-01T20:11:09 | step: 56600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.9365957238478586e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.06 | consumed tokens: 463667200.0 | grad norm avg: 0.71 | grad norm last: 0.76 | 
2026-01-01T20:11:24 | step: 56700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.936341065331362e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.22 | consumed tokens: 464486400.0 | grad norm avg: 0.72 | grad norm last: 0.73 | 
2026-01-01T20:11:40 | step: 56800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.936086043016985e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.73 | consumed tokens: 465305600.0 | grad norm avg: 0.72 | grad norm last: 0.73 | 
2026-01-01T20:11:56 | step: 56900 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.9358302931068465e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.38 | consumed tokens: 466124800.0 | grad norm avg: 0.72 | grad norm last: 0.74 | 
2026-01-01T20:12:11 | step: 57000 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.935574179398827e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 2.78 | consumed tokens: 466944000.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T20:12:27 | step: 57100 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.9353173380950466e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.36 | consumed tokens: 467763200.0 | grad norm avg: 0.72 | grad norm last: 0.75 | 
2026-01-01T20:12:42 | step: 57200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.935060132993385e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.34 | consumed tokens: 468582400.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:12:58 | step: 57300 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.934802564093843e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.42 | consumed tokens: 469401600.0 | grad norm avg: 0.72 | grad norm last: 0.72 | 
2026-01-01T20:13:13 | step: 57400 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.9345442675985396e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.34 | consumed tokens: 470220800.0 | grad norm avg: 0.72 | grad norm last: 0.7 | 
2026-01-01T20:13:29 | step: 57500 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.9342856073053554e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.11 | consumed tokens: 471040000.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:13:45 | step: 57600 | train samples/s: 103.0 | train mfu (16-bit): -1.0 | lr mean: 4.93402621941641e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.11 | consumed tokens: 471859200.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T20:14:00 | step: 57700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.9337664677295834e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 2.55 | consumed tokens: 472678400.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:14:16 | step: 57800 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.933506352244876e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 2.98 | consumed tokens: 473497600.0 | grad norm avg: 0.71 | grad norm last: 0.67 | 
2026-01-01T20:14:31 | step: 57900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.933245509164408e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.03 | consumed tokens: 474316800.0 | grad norm avg: 0.72 | grad norm last: 0.72 | 
2026-01-01T20:14:47 | step: 58000 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.932984302286059e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.06 | consumed tokens: 475136000.0 | grad norm avg: 0.71 | grad norm last: 0.75 | 
2026-01-01T20:15:03 | step: 58100 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.932722731609829e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.34 | consumed tokens: 475955200.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T20:15:18 | step: 58200 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.9324604333378375e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.31 | consumed tokens: 476774400.0 | grad norm avg: 0.72 | grad norm last: 0.69 | 
2026-01-01T20:15:34 | step: 58300 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.9321977712679654e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.45 | consumed tokens: 477593600.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:15:49 | step: 58400 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.931934381602332e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.25 | consumed tokens: 478412800.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:16:05 | step: 58500 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.931670628138818e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 2.92 | consumed tokens: 479232000.0 | grad norm avg: 0.71 | grad norm last: 0.76 | 
2026-01-01T20:16:21 | step: 58600 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.931406510877423e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.03 | consumed tokens: 480051200.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:16:36 | step: 58700 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.931141666020267e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.75 | consumed tokens: 480870400.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:16:52 | step: 58800 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.93087645736523e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.02 | consumed tokens: 481689600.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T20:17:08 | step: 58900 | train samples/s: 103.1 | train mfu (16-bit): -1.0 | lr mean: 4.930610521114431e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.31 | consumed tokens: 482508800.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:17:23 | step: 59000 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.930344221065752e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.17 | consumed tokens: 483328000.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:17:39 | step: 59100 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.9300775572191924e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.16 | consumed tokens: 484147200.0 | grad norm avg: 0.71 | grad norm last: 0.74 | 
2026-01-01T20:17:55 | step: 59200 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.929810165776871e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 2.98 | consumed tokens: 484966400.0 | grad norm avg: 0.71 | grad norm last: 0.67 | 
2026-01-01T20:18:10 | step: 59300 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.929542410536669e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.38 | consumed tokens: 485785600.0 | grad norm avg: 0.71 | grad norm last: 0.68 | 
2026-01-01T20:18:26 | step: 59400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.9292742914985865e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 2.84 | consumed tokens: 486604800.0 | grad norm avg: 0.72 | grad norm last: 0.69 | 
2026-01-01T20:18:41 | step: 59500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.9290054448647425e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.7 | consumed tokens: 487424000.0 | grad norm avg: 0.72 | grad norm last: 0.72 | 
2026-01-01T20:18:57 | step: 59600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.928736234433018e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 2.78 | consumed tokens: 488243200.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-01T20:19:12 | step: 59700 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.9284662964055315e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.05 | consumed tokens: 489062400.0 | grad norm avg: 0.72 | grad norm last: 0.72 | 
2026-01-01T20:19:28 | step: 59800 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.9281959945801646e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 2.98 | consumed tokens: 489881600.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:19:44 | step: 59900 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.927925328956917e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.09 | consumed tokens: 490700800.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:19:59 | step: 60000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.927653935737908e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.06 | consumed tokens: 491520000.0 | grad norm avg: 0.72 | grad norm last: 0.69 | 
2026-01-01T20:20:16 | step: 60100 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.927382178721018e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 2.98 | consumed tokens: 492339200.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:20:32 | step: 60200 | train samples/s: 102.7 | train mfu (16-bit): -1.0 | lr mean: 4.927110057906248e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.67 | consumed tokens: 493158400.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:20:48 | step: 60300 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.926837209495716e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 2.95 | consumed tokens: 493977600.0 | grad norm avg: 0.72 | grad norm last: 0.77 | 
2026-01-01T20:21:03 | step: 60400 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.926563997287303e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.08 | consumed tokens: 494796800.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-01T20:21:19 | step: 60500 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.926290057483129e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.29 | train loss last: 3.67 | consumed tokens: 495616000.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-01T20:21:34 | step: 60600 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.9260157538810745e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.08 | consumed tokens: 496435200.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-01T20:21:50 | step: 60700 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.925741086481139e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.59 | consumed tokens: 497254400.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T20:22:06 | step: 60800 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.925465691485442e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.34 | consumed tokens: 498073600.0 | grad norm avg: 0.72 | grad norm last: 0.72 | 
2026-01-01T20:22:21 | step: 60900 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.925189932691865e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.12 | consumed tokens: 498892800.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:22:37 | step: 61000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.924913446302526e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 2.75 | consumed tokens: 499712000.0 | grad norm avg: 0.72 | grad norm last: 0.72 | 
2026-01-01T20:22:52 | step: 61100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.924636596115306e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.42 | consumed tokens: 500531200.0 | grad norm avg: 0.71 | grad norm last: 0.75 | 
2026-01-01T20:23:08 | step: 61200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.9243593821302056e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.25 | consumed tokens: 501350400.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:23:23 | step: 61300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.924081440549344e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 4.03 | consumed tokens: 502169600.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T20:23:38 | step: 61400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.923803135170601e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.86 | consumed tokens: 502988800.0 | grad norm avg: 0.72 | grad norm last: 0.66 | 
2026-01-01T20:23:54 | step: 61500 | train samples/s: 103.4 | train mfu (16-bit): -1.0 | lr mean: 4.923524465993978e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.38 | consumed tokens: 503808000.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:24:10 | step: 61600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.9232450692215934e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.53 | consumed tokens: 504627200.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T20:24:25 | step: 61700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.922965308651328e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.11 | consumed tokens: 505446400.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:24:41 | step: 61800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.922685184283182e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 2.89 | consumed tokens: 506265600.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-01T20:24:56 | step: 61900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.9224043323192745e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 2.89 | consumed tokens: 507084800.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:25:12 | step: 62000 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.9221227527596056e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.42 | consumed tokens: 507904000.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T20:25:27 | step: 62100 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.921841173199937e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.8 | consumed tokens: 508723200.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:25:43 | step: 62200 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.9215588660445064e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.36 | consumed tokens: 509542400.0 | grad norm avg: 0.73 | grad norm last: 0.7 | 
2026-01-01T20:25:58 | step: 62300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.921275831293315e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.2 | consumed tokens: 510361600.0 | grad norm avg: 0.72 | grad norm last: 0.73 | 
2026-01-01T20:26:14 | step: 62400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.920992432744242e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 2.98 | consumed tokens: 511180800.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T20:26:29 | step: 62500 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.920708670397289e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.25 | consumed tokens: 512000000.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-01T20:26:45 | step: 62600 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.920424544252455e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.19 | consumed tokens: 512819200.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-01T20:27:01 | step: 62700 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.92013969051186e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.33 | consumed tokens: 513638400.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:27:16 | step: 62800 | train samples/s: 103.4 | train mfu (16-bit): -1.0 | lr mean: 4.919854109175503e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.28 | train loss last: 3.16 | consumed tokens: 514457600.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-01T20:27:32 | step: 62900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.9195685278391466e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 2.8 | consumed tokens: 515276800.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:27:47 | step: 63000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.9192822189070284e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.78 | consumed tokens: 516096000.0 | grad norm avg: 0.71 | grad norm last: 0.66 | 
2026-01-01T20:28:03 | step: 63100 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.918995182379149e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.03 | consumed tokens: 516915200.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:28:19 | step: 63200 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.9187077820533887e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.23 | consumed tokens: 517734400.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:28:34 | step: 63300 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.918420017929748e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.14 | consumed tokens: 518553600.0 | grad norm avg: 0.72 | grad norm last: 0.71 | 
2026-01-01T20:28:50 | step: 63400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.918131890008226e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.56 | consumed tokens: 519372800.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T20:29:05 | step: 63500 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.917843034490943e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.03 | consumed tokens: 520192000.0 | grad norm avg: 0.72 | grad norm last: 0.71 | 
2026-01-01T20:29:21 | step: 63600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.917553815175779e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.08 | consumed tokens: 521011200.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:29:36 | step: 63700 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.917263868264854e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.2 | consumed tokens: 521830400.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:29:52 | step: 63800 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.916973557556048e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.3 | consumed tokens: 522649600.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T20:30:07 | step: 63900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.916682519251481e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.34 | consumed tokens: 523468800.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T20:30:23 | step: 64000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.9163914809469134e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 2.66 | consumed tokens: 524288000.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-01T20:30:39 | step: 64100 | train samples/s: 103.6 | train mfu (16-bit): -1.0 | lr mean: 4.916099351248704e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.28 | consumed tokens: 525107200.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:30:54 | step: 64200 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.9158072215504944e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.11 | consumed tokens: 525926400.0 | grad norm avg: 0.71 | grad norm last: 0.66 | 
2026-01-01T20:31:10 | step: 64300 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.9155143642565235e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.0 | consumed tokens: 526745600.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:31:26 | step: 64400 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.915221143164672e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 2.28 | consumed tokens: 527564800.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-01T20:31:41 | step: 64500 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.914927194477059e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.58 | consumed tokens: 528384000.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:31:57 | step: 64600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.914632881991565e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.33 | consumed tokens: 529203200.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:32:12 | step: 64700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.914338205708191e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 4.0 | consumed tokens: 530022400.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:32:28 | step: 64800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.914042801829055e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 2.88 | consumed tokens: 530841600.0 | grad norm avg: 0.71 | grad norm last: 0.67 | 
2026-01-01T20:32:43 | step: 64900 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.9137470341520384e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.28 | consumed tokens: 531660800.0 | grad norm avg: 0.71 | grad norm last: 0.75 | 
2026-01-01T20:32:59 | step: 65000 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.9134505388792604e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.94 | consumed tokens: 532480000.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T20:33:16 | step: 65100 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.913153679808602e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.3 | consumed tokens: 533299200.0 | grad norm avg: 0.72 | grad norm last: 0.67 | 
2026-01-01T20:33:31 | step: 65200 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.9128564569400623e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.86 | consumed tokens: 534118400.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:33:47 | step: 65300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.9125585064757615e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.0 | consumed tokens: 534937600.0 | grad norm avg: 0.71 | grad norm last: 0.67 | 
2026-01-01T20:34:03 | step: 65400 | train samples/s: 102.5 | train mfu (16-bit): -1.0 | lr mean: 4.91226019221358e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.2 | consumed tokens: 535756800.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:34:18 | step: 65500 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.911961514153518e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.28 | consumed tokens: 536576000.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:34:34 | step: 65600 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.911662108497694e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.16 | consumed tokens: 537395200.0 | grad norm avg: 0.71 | grad norm last: 0.74 | 
2026-01-01T20:34:50 | step: 65700 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.91136233904399e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.88 | consumed tokens: 538214400.0 | grad norm avg: 0.71 | grad norm last: 0.74 | 
2026-01-01T20:35:05 | step: 65800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.911061841994524e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.3 | consumed tokens: 539033600.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-01T20:35:21 | step: 65900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.910761344945058e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.58 | consumed tokens: 539852800.0 | grad norm avg: 0.71 | grad norm last: 0.67 | 
2026-01-01T20:35:36 | step: 66000 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.91045975650195e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.2 | consumed tokens: 540672000.0 | grad norm avg: 0.71 | grad norm last: 0.75 | 
2026-01-01T20:35:52 | step: 66100 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.9101581680588424e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.64 | consumed tokens: 541491200.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:36:08 | step: 66200 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.909855852019973e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.39 | consumed tokens: 542310400.0 | grad norm avg: 0.71 | grad norm last: 0.68 | 
2026-01-01T20:36:23 | step: 66300 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.9095528083853424e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.25 | consumed tokens: 543129600.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-01T20:36:39 | step: 66400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.9092497647507116e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.56 | consumed tokens: 543948800.0 | grad norm avg: 0.71 | grad norm last: 0.74 | 
2026-01-01T20:36:54 | step: 66500 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.9089459935203195e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.19 | consumed tokens: 544768000.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:37:10 | step: 66600 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.908641494694166e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.27 | consumed tokens: 545587200.0 | grad norm avg: 0.71 | grad norm last: 0.74 | 
2026-01-01T20:37:26 | step: 66700 | train samples/s: 102.2 | train mfu (16-bit): -1.0 | lr mean: 4.9083366320701316e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 2.78 | consumed tokens: 546406400.0 | grad norm avg: 0.71 | grad norm last: 0.75 | 
2026-01-01T20:37:41 | step: 66800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.9080314056482166e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.45 | consumed tokens: 547225600.0 | grad norm avg: 0.71 | grad norm last: 0.68 | 
2026-01-01T20:37:57 | step: 66900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.907725815428421e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.56 | consumed tokens: 548044800.0 | grad norm avg: 0.71 | grad norm last: 0.75 | 
2026-01-01T20:38:13 | step: 67000 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.907419497612864e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.03 | consumed tokens: 548864000.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-01T20:38:28 | step: 67100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.907112452201545e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.16 | consumed tokens: 549683200.0 | grad norm avg: 0.71 | grad norm last: 0.67 | 
2026-01-01T20:38:44 | step: 67200 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.906805406790227e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 2.95 | consumed tokens: 550502400.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:38:59 | step: 67300 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.906497633783147e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 4.0 | consumed tokens: 551321600.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:39:15 | step: 67400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.9061891331803054e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.02 | consumed tokens: 552140800.0 | grad norm avg: 0.72 | grad norm last: 0.7 | 
2026-01-01T20:39:30 | step: 67500 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.905880268779583e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 2.97 | consumed tokens: 552960000.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-01T20:39:46 | step: 67600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.9055710405809805e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.02 | consumed tokens: 553779200.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:40:02 | step: 67700 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.905261448584497e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.36 | consumed tokens: 554598400.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:40:17 | step: 67800 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.904951128992252e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.11 | consumed tokens: 555417600.0 | grad norm avg: 0.72 | grad norm last: 0.75 | 
2026-01-01T20:40:33 | step: 67900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.9046404456021264e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 2.94 | consumed tokens: 556236800.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T20:40:48 | step: 68000 | train samples/s: 103.8 | train mfu (16-bit): -1.0 | lr mean: 4.9043290346162394e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 2.67 | consumed tokens: 557056000.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:41:04 | step: 68100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.9040172598324716e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 2.84 | consumed tokens: 557875200.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T20:41:20 | step: 68200 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.903705121250823e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 2.66 | consumed tokens: 558694400.0 | grad norm avg: 0.71 | grad norm last: 0.68 | 
2026-01-01T20:41:35 | step: 68300 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.903392255073413e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.69 | consumed tokens: 559513600.0 | grad norm avg: 0.71 | grad norm last: 0.74 | 
2026-01-01T20:41:51 | step: 68400 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.9030790250981227e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.08 | consumed tokens: 560332800.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-01T20:42:06 | step: 68500 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.9027650675270706e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.41 | consumed tokens: 561152000.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-01T20:42:22 | step: 68600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.9024511099560186e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.52 | consumed tokens: 561971200.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-01T20:42:37 | step: 68700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.9021360609913245e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 2.97 | consumed tokens: 562790400.0 | grad norm avg: 0.71 | grad norm last: 0.66 | 
2026-01-01T20:42:53 | step: 68800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.9018210120266303e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.34 | consumed tokens: 563609600.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T20:43:09 | step: 68900 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.901505235466175e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.42 | consumed tokens: 564428800.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:43:24 | step: 69000 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.9011890951078385e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.14 | consumed tokens: 565248000.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T20:43:40 | step: 69100 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.900872227153741e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.26 | train loss last: 3.5 | consumed tokens: 566067200.0 | grad norm avg: 0.71 | grad norm last: 0.75 | 
2026-01-01T20:43:55 | step: 69200 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.9005549954017624e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.34 | consumed tokens: 566886400.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T20:44:11 | step: 69300 | train samples/s: 102.9 | train mfu (16-bit): -1.0 | lr mean: 4.900237399851903e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.67 | consumed tokens: 567705600.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T20:44:27 | step: 69400 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.899919076706283e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.12 | consumed tokens: 568524800.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-01T20:44:43 | step: 69500 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.8996003897627816e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.38 | consumed tokens: 569344000.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T20:44:58 | step: 69600 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.899280975223519e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.12 | consumed tokens: 570163200.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-01T20:45:14 | step: 69700 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.898961560684256e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 2.84 | consumed tokens: 570982400.0 | grad norm avg: 0.71 | grad norm last: 0.74 | 
2026-01-01T20:45:29 | step: 69800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.8986410547513515e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 2.58 | consumed tokens: 571801600.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:45:45 | step: 69900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.898320548818447e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 4.09 | consumed tokens: 572620800.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T20:46:01 | step: 70000 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.8979993152897805e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.69 | consumed tokens: 573440000.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:46:18 | step: 70100 | train samples/s: 103.6 | train mfu (16-bit): -1.0 | lr mean: 4.8976777179632336e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.19 | consumed tokens: 574259200.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T20:46:33 | step: 70200 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.897355393040925e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.61 | consumed tokens: 575078400.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-01T20:46:49 | step: 70300 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.897032704320736e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.08 | consumed tokens: 575897600.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:47:05 | step: 70400 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.8967096518026665e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.05 | consumed tokens: 576716800.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T20:47:20 | step: 70500 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.896385871688835e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 2.89 | consumed tokens: 577536000.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:47:36 | step: 70600 | train samples/s: 102.5 | train mfu (16-bit): -1.0 | lr mean: 4.8960617277771235e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.33 | consumed tokens: 578355200.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-01T20:47:52 | step: 70700 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.89573685626965e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.16 | consumed tokens: 579174400.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T20:48:07 | step: 70800 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.895411620964296e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 2.83 | consumed tokens: 579993600.0 | grad norm avg: 0.71 | grad norm last: 0.79 | 
2026-01-01T20:48:23 | step: 70900 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.8950860218610615e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.23 | consumed tokens: 580812800.0 | grad norm avg: 0.71 | grad norm last: 0.74 | 
2026-01-01T20:48:38 | step: 71000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.894760058959946e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.03 | consumed tokens: 581632000.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:48:54 | step: 71100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.894433368463069e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 2.53 | consumed tokens: 582451200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T20:49:10 | step: 71200 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.8941063141683117e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.02 | consumed tokens: 583270400.0 | grad norm avg: 0.7 | grad norm last: 0.65 | 
2026-01-01T20:49:25 | step: 71300 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.893778532277793e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 2.5 | consumed tokens: 584089600.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-01T20:49:41 | step: 71400 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.893450386589393e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.27 | train loss last: 3.28 | consumed tokens: 584908800.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T20:49:56 | step: 71500 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.8931218771031126e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.5 | consumed tokens: 585728000.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T20:50:12 | step: 71600 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.892792640021071e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 2.73 | consumed tokens: 586547200.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T20:50:27 | step: 71700 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.892463039141148e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.45 | consumed tokens: 587366400.0 | grad norm avg: 0.71 | grad norm last: 0.76 | 
2026-01-01T20:50:43 | step: 71800 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.8921327106654644e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.3 | consumed tokens: 588185600.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:50:59 | step: 71900 | train samples/s: 102.9 | train mfu (16-bit): -1.0 | lr mean: 4.8918023821897805e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.69 | consumed tokens: 589004800.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T20:51:14 | step: 72000 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.8914709623204544e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 2.98 | consumed tokens: 589824000.0 | grad norm avg: 0.71 | grad norm last: 0.68 | 
2026-01-01T20:51:30 | step: 72100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.8911395424511284e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 3.22 | consumed tokens: 590643200.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T20:51:45 | step: 72200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.890807394986041e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.59 | consumed tokens: 591462400.0 | grad norm avg: 0.71 | grad norm last: 0.68 | 
2026-01-01T20:52:01 | step: 72300 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.890474883723073e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.28 | consumed tokens: 592281600.0 | grad norm avg: 0.71 | grad norm last: 0.74 | 
2026-01-01T20:52:17 | step: 72400 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.890141644864343e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.52 | consumed tokens: 593100800.0 | grad norm avg: 0.71 | grad norm last: 0.67 | 
2026-01-01T20:52:32 | step: 72500 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.889808042207733e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.16 | consumed tokens: 593920000.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T20:52:48 | step: 72600 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.889474075753242e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 2.88 | consumed tokens: 594739200.0 | grad norm avg: 0.71 | grad norm last: 0.75 | 
2026-01-01T20:53:04 | step: 72700 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.8891393817029893e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 2.78 | consumed tokens: 595558400.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T20:53:19 | step: 72800 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.888804323854856e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.28 | consumed tokens: 596377600.0 | grad norm avg: 0.71 | grad norm last: 0.75 | 
2026-01-01T20:53:35 | step: 72900 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.888468902208842e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.19 | consumed tokens: 597196800.0 | grad norm avg: 0.7 | grad norm last: 0.74 | 
2026-01-01T20:53:50 | step: 73000 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.888132752967067e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.56 | consumed tokens: 598016000.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T20:54:06 | step: 73100 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.887796239927411e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.55 | consumed tokens: 598835200.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T20:54:22 | step: 73200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.8874593630898744e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.94 | consumed tokens: 599654400.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T20:54:38 | step: 73300 | train samples/s: 103.1 | train mfu (16-bit): -1.0 | lr mean: 4.887121758656576e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 2.12 | consumed tokens: 600473600.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T20:54:53 | step: 73400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.8867837904253975e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 2.77 | consumed tokens: 601292800.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T20:55:09 | step: 73500 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.886445094598457e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.52 | consumed tokens: 602112000.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-01T20:55:24 | step: 73600 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.886106034973636e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.2 | consumed tokens: 602931200.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T20:55:40 | step: 73700 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.8857666115509346e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.88 | consumed tokens: 603750400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T20:55:55 | step: 73800 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.8854264605324715e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.31 | consumed tokens: 604569600.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T20:56:11 | step: 73900 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.8850863095140085e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.44 | consumed tokens: 605388800.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:56:27 | step: 74000 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.884745067101903e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.2 | consumed tokens: 606208000.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:56:42 | step: 74100 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.884403824689798e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 2.88 | consumed tokens: 607027200.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T20:56:58 | step: 74200 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.8840618546819314e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.05 | consumed tokens: 607846400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T20:57:13 | step: 74300 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.8837191570783034e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.0 | consumed tokens: 608665600.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T20:57:29 | step: 74400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.8833760956767946e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 4.12 | consumed tokens: 609484800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T20:57:44 | step: 74500 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.883032670477405e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 2.98 | consumed tokens: 610304000.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T20:58:00 | step: 74600 | train samples/s: 103.3 | train mfu (16-bit): -1.0 | lr mean: 4.882688881480135e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.27 | consumed tokens: 611123200.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T20:58:16 | step: 74700 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.8823443648871034e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.45 | consumed tokens: 611942400.0 | grad norm avg: 0.71 | grad norm last: 0.76 | 
2026-01-01T20:58:31 | step: 74800 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.881999484496191e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.42 | consumed tokens: 612761600.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T20:58:47 | step: 74900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.8816538765095174e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.33 | consumed tokens: 613580800.0 | grad norm avg: 0.71 | grad norm last: 0.66 | 
2026-01-01T20:59:02 | step: 75000 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.881308268522844e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.31 | consumed tokens: 614400000.0 | grad norm avg: 0.71 | grad norm last: 0.66 | 
2026-01-01T20:59:19 | step: 75100 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.880961569142528e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.48 | consumed tokens: 615219200.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T20:59:35 | step: 75200 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.880614869762212e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.03 | consumed tokens: 616038400.0 | grad norm avg: 0.7 | grad norm last: 0.75 | 
2026-01-01T20:59:51 | step: 75300 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.880267442786135e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.39 | consumed tokens: 616857600.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:00:06 | step: 75400 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.879919652012177e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.3 | consumed tokens: 617676800.0 | grad norm avg: 0.71 | grad norm last: 0.74 | 
2026-01-01T21:00:22 | step: 75500 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.8795711336424574e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.08 | consumed tokens: 618496000.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:00:37 | step: 75600 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.879222251474857e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 2.94 | consumed tokens: 619315200.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T21:00:53 | step: 75700 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.8788730055093765e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.03 | consumed tokens: 620134400.0 | grad norm avg: 0.71 | grad norm last: 0.67 | 
2026-01-01T21:01:08 | step: 75800 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.878523031948134e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.5 | consumed tokens: 620953600.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:01:24 | step: 75900 | train samples/s: 102.6 | train mfu (16-bit): -1.0 | lr mean: 4.8781726945890114e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.25 | consumed tokens: 621772800.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:01:40 | step: 76000 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.877821993432008e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.36 | consumed tokens: 622592000.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-01T21:01:55 | step: 76100 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.877470564679243e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 2.61 | consumed tokens: 623411200.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:02:11 | step: 76200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.877118772128597e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 2.73 | consumed tokens: 624230400.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-01T21:02:26 | step: 76300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.87676625198219e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.47 | consumed tokens: 625049600.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:02:42 | step: 76400 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.8764137318357825e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.59 | consumed tokens: 625868800.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:02:58 | step: 76500 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.876060120295733e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 2.94 | consumed tokens: 626688000.0 | grad norm avg: 0.7 | grad norm last: 0.74 | 
2026-01-01T21:03:13 | step: 76600 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.875706508755684e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.12 | consumed tokens: 627507200.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T21:03:29 | step: 76700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.875352169619873e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.67 | consumed tokens: 628326400.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:03:44 | step: 76800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.874997466686182e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.77 | consumed tokens: 629145600.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-01T21:04:00 | step: 76900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.874642036156729e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.09 | consumed tokens: 629964800.0 | grad norm avg: 0.71 | grad norm last: 0.76 | 
2026-01-01T21:04:16 | step: 77000 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.874286605627276e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.69 | consumed tokens: 630784000.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:04:31 | step: 77100 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.873930083704181e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.27 | consumed tokens: 631603200.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:04:47 | step: 77200 | train samples/s: 102.9 | train mfu (16-bit): -1.0 | lr mean: 4.873573561781086e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.19 | consumed tokens: 632422400.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T21:05:03 | step: 77300 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.8732163122622296e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 2.97 | consumed tokens: 633241600.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T21:05:18 | step: 77400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.872858335147612e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.53 | consumed tokens: 634060800.0 | grad norm avg: 0.71 | grad norm last: 0.66 | 
2026-01-01T21:05:34 | step: 77500 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.872500358032994e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.59 | consumed tokens: 634880000.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:05:49 | step: 77600 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.872141653322615e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.27 | consumed tokens: 635699200.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T21:06:05 | step: 77700 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.871782221016474e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.39 | consumed tokens: 636518400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:06:21 | step: 77800 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.8714227887103334e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 2.83 | consumed tokens: 637337600.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T21:06:36 | step: 77900 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.871062628808431e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.06 | consumed tokens: 638156800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:06:52 | step: 78000 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.870701741310768e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.34 | consumed tokens: 638976000.0 | grad norm avg: 0.71 | grad norm last: 0.75 | 
2026-01-01T21:07:07 | step: 78100 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.870340853813104e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 2.88 | consumed tokens: 639795200.0 | grad norm avg: 0.7 | grad norm last: 0.74 | 
2026-01-01T21:07:23 | step: 78200 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.8699792387196794e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.25 | train loss last: 2.97 | consumed tokens: 640614400.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T21:07:39 | step: 78300 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.869616896030493e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.11 | consumed tokens: 641433600.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T21:07:54 | step: 78400 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.869254189543426e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.39 | consumed tokens: 642252800.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T21:08:10 | step: 78500 | train samples/s: 103.0 | train mfu (16-bit): -1.0 | lr mean: 4.868891119258478e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 2.69 | consumed tokens: 643072000.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-01T21:08:26 | step: 78600 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.86852768517565e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.42 | consumed tokens: 643891200.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:08:41 | step: 78700 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 4.86816352349706e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.59 | consumed tokens: 644710400.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:08:57 | step: 78800 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.8677989980205894e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.34 | consumed tokens: 645529600.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T21:09:12 | step: 78900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.8674337449483573e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 2.84 | consumed tokens: 646348800.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T21:09:28 | step: 79000 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.8670681280782446e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.62 | consumed tokens: 647168000.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T21:09:43 | step: 79100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.866702147410251e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.39 | consumed tokens: 647987200.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:09:59 | step: 79200 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.866335802944377e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.45 | consumed tokens: 648806400.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T21:10:15 | step: 79300 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.8659687308827415e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.47 | consumed tokens: 649625600.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T21:10:30 | step: 79400 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.865601295023225e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.23 | consumed tokens: 650444800.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T21:10:46 | step: 79500 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.8652331315679476e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.16 | consumed tokens: 651264000.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T21:11:01 | step: 79600 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.864864604314789e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 2.95 | consumed tokens: 652083200.0 | grad norm avg: 0.7 | grad norm last: 0.74 | 
2026-01-01T21:11:17 | step: 79700 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.86449571326375e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 2.98 | consumed tokens: 652902400.0 | grad norm avg: 0.71 | grad norm last: 0.75 | 
2026-01-01T21:11:33 | step: 79800 | train samples/s: 102.6 | train mfu (16-bit): -1.0 | lr mean: 4.8641260946169496e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.12 | consumed tokens: 653721600.0 | grad norm avg: 0.71 | grad norm last: 0.75 | 
2026-01-01T21:11:49 | step: 79900 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.863756112172268e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 4.16 | consumed tokens: 654540800.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T21:12:04 | step: 80000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.8633857659297064e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.33 | consumed tokens: 655360000.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:12:23 | step: 80100 | train samples/s: 94.3 | train mfu (16-bit): -1.0 | lr mean: 4.863014692091383e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 2.98 | consumed tokens: 656179200.0 | grad norm avg: 0.71 | grad norm last: 0.74 | 
2026-01-01T21:12:38 | step: 80200 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.862643254455179e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.23 | consumed tokens: 656998400.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-01T21:12:54 | step: 80300 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.862271453021094e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.56 | consumed tokens: 657817600.0 | grad norm avg: 0.71 | grad norm last: 0.67 | 
2026-01-01T21:13:10 | step: 80400 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.861898923991248e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 2.83 | consumed tokens: 658636800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:13:25 | step: 80500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.861526031163521e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.53 | consumed tokens: 659456000.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T21:13:40 | step: 80600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.8611527745379135e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.12 | consumed tokens: 660275200.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T21:13:56 | step: 80700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.8607787903165445e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.8 | consumed tokens: 661094400.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T21:14:12 | step: 80800 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.860404442297295e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.89 | consumed tokens: 661913600.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-01T21:14:27 | step: 80900 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.860029730480164e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.36 | consumed tokens: 662732800.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:14:43 | step: 81000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.8596542910672724e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.92 | consumed tokens: 663552000.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:14:58 | step: 81100 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 4.8592784878565e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.39 | consumed tokens: 664371200.0 | grad norm avg: 0.71 | grad norm last: 0.65 | 
2026-01-01T21:15:14 | step: 81200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.8589023208478466e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.48 | consumed tokens: 665190400.0 | grad norm avg: 0.71 | grad norm last: 0.74 | 
2026-01-01T21:15:29 | step: 81300 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.858525426243432e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 2.88 | consumed tokens: 666009600.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T21:15:45 | step: 81400 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.8581481678411365e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.2 | consumed tokens: 666828800.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T21:16:01 | step: 81500 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.8577701818430796e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.31 | consumed tokens: 667648000.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:16:16 | step: 81600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.857392195845023e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 3.14 | consumed tokens: 668467200.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T21:16:31 | step: 81700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.8570134822512046e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 2.97 | consumed tokens: 669286400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:16:47 | step: 81800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.856634041061625e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 2.98 | consumed tokens: 670105600.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T21:17:02 | step: 81900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.8562542360741645e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.08 | consumed tokens: 670924800.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:17:18 | step: 82000 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.8558740672888234e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.67 | consumed tokens: 671744000.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T21:17:34 | step: 82100 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.8554935347056016e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.36 | consumed tokens: 672563200.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:17:49 | step: 82200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.8551122745266184e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.23 | consumed tokens: 673382400.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T21:18:05 | step: 82300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.8547306505497545e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.17 | consumed tokens: 674201600.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T21:18:20 | step: 82400 | train samples/s: 103.7 | train mfu (16-bit): -1.0 | lr mean: 4.854348298977129e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.08 | consumed tokens: 675020800.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:18:36 | step: 82500 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.853965583606623e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.95 | consumed tokens: 675840000.0 | grad norm avg: 0.7 | grad norm last: 0.76 | 
2026-01-01T21:18:52 | step: 82600 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.8535825044382364e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 4.09 | consumed tokens: 676659200.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:19:07 | step: 82700 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.853199061471969e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.62 | consumed tokens: 677478400.0 | grad norm avg: 0.71 | grad norm last: 0.67 | 
2026-01-01T21:19:23 | step: 82800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.85281489090994e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.12 | consumed tokens: 678297600.0 | grad norm avg: 0.71 | grad norm last: 0.68 | 
2026-01-01T21:19:38 | step: 82900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.8524303565500304e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.97 | consumed tokens: 679116800.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:19:54 | step: 83000 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.8520450945943594e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.67 | consumed tokens: 679936000.0 | grad norm avg: 0.71 | grad norm last: 0.75 | 
2026-01-01T21:20:10 | step: 83100 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.851659468840808e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.22 | consumed tokens: 680755200.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T21:20:25 | step: 83200 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.851273479289375e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 4.31 | consumed tokens: 681574400.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:20:41 | step: 83300 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.850887125940062e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.75 | consumed tokens: 682393600.0 | grad norm avg: 0.7 | grad norm last: 0.76 | 
2026-01-01T21:20:56 | step: 83400 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.8505000449949875e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 2.39 | consumed tokens: 683212800.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:21:12 | step: 83500 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.850112600252032e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 2.98 | consumed tokens: 684032000.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T21:21:28 | step: 83600 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.8497244279133156e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 2.77 | consumed tokens: 684851200.0 | grad norm avg: 0.7 | grad norm last: 0.65 | 
2026-01-01T21:21:44 | step: 83700 | train samples/s: 103.0 | train mfu (16-bit): -1.0 | lr mean: 4.849335891776718e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 2.91 | consumed tokens: 685670400.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-01T21:21:59 | step: 83800 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.84894699184224e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.23 | consumed tokens: 686489600.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:22:15 | step: 83900 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.848557728109881e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.17 | consumed tokens: 687308800.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T21:22:30 | step: 84000 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.848167736781761e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.09 | consumed tokens: 688128000.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:22:46 | step: 84100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.8477770178578794e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.95 | consumed tokens: 688947200.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:23:01 | step: 84200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.847386298933998e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.2 | consumed tokens: 689766400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:23:17 | step: 84300 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.846994852414355e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.09 | consumed tokens: 690585600.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T21:23:33 | step: 84400 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.846603042096831e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.09 | consumed tokens: 691404800.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T21:23:48 | step: 84500 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.846210504183546e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.89 | consumed tokens: 692224000.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:24:04 | step: 84600 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.84581760247238e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.42 | consumed tokens: 693043200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:24:19 | step: 84700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.845424336963333e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.36 | consumed tokens: 693862400.0 | grad norm avg: 0.7 | grad norm last: 0.75 | 
2026-01-01T21:24:35 | step: 84800 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.845030707656406e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 2.83 | consumed tokens: 694681600.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:24:51 | step: 84900 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.844636350753717e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.31 | consumed tokens: 695500800.0 | grad norm avg: 0.7 | grad norm last: 0.76 | 
2026-01-01T21:25:07 | step: 85000 | train samples/s: 102.3 | train mfu (16-bit): -1.0 | lr mean: 4.844241630053148e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.25 | consumed tokens: 696320000.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:25:24 | step: 85100 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.843846181756817e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.48 | consumed tokens: 697139200.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-01T21:25:39 | step: 85200 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.843450369662605e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.45 | consumed tokens: 697958400.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:25:55 | step: 85300 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.843054193770513e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.2 | consumed tokens: 698777600.0 | grad norm avg: 0.71 | grad norm last: 0.74 | 
2026-01-01T21:26:10 | step: 85400 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.842657290282659e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 2.61 | consumed tokens: 699596800.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:26:26 | step: 85500 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.842260022996925e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.97 | consumed tokens: 700416000.0 | grad norm avg: 0.7 | grad norm last: 0.75 | 
2026-01-01T21:26:42 | step: 85600 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.84186239191331e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.25 | consumed tokens: 701235200.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T21:26:57 | step: 85700 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 4.841464397031814e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.31 | consumed tokens: 702054400.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:27:13 | step: 85800 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.8410656745545566e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 2.73 | consumed tokens: 702873600.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T21:27:29 | step: 85900 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.8406665882794186e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.72 | consumed tokens: 703692800.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:27:44 | step: 86000 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.840266774408519e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.12 | consumed tokens: 704512000.0 | grad norm avg: 0.7 | grad norm last: 0.65 | 
2026-01-01T21:28:00 | step: 86100 | train samples/s: 102.2 | train mfu (16-bit): -1.0 | lr mean: 4.839866596739739e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.7 | consumed tokens: 705331200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:28:16 | step: 86200 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.8394660552730784e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 2.75 | consumed tokens: 706150400.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T21:28:32 | step: 86300 | train samples/s: 103.1 | train mfu (16-bit): -1.0 | lr mean: 4.839065150008537e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.33 | consumed tokens: 706969600.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:28:47 | step: 86400 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.838663517148234e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.58 | consumed tokens: 707788800.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:29:03 | step: 86500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.83826152049005e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.31 | consumed tokens: 708608000.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:29:18 | step: 86600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.837858796236105e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.28 | consumed tokens: 709427200.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-01T21:29:34 | step: 86700 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.8374557081842795e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.56 | consumed tokens: 710246400.0 | grad norm avg: 0.7 | grad norm last: 0.75 | 
2026-01-01T21:29:50 | step: 86800 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 4.837052256334573e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.23 | train loss last: 2.78 | consumed tokens: 711065600.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T21:30:05 | step: 86900 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.836648440686986e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.31 | consumed tokens: 711884800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:30:21 | step: 87000 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.836243897443637e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.09 | consumed tokens: 712704000.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:30:37 | step: 87100 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.835838990402408e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.72 | consumed tokens: 713523200.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T21:30:52 | step: 87200 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.835433355765417e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.78 | consumed tokens: 714342400.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:31:08 | step: 87300 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.835027357330546e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 2.89 | consumed tokens: 715161600.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:31:24 | step: 87400 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.8346209950977936e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.11 | consumed tokens: 715980800.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T21:31:39 | step: 87500 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.834214269067161e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.56 | consumed tokens: 716800000.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T21:31:55 | step: 87600 | train samples/s: 102.9 | train mfu (16-bit): -1.0 | lr mean: 4.8338068154407665e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.88 | consumed tokens: 717619200.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:32:11 | step: 87700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.8333989980164915e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.97 | consumed tokens: 718438400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:32:26 | step: 87800 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.832990452996455e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.28 | consumed tokens: 719257600.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:32:42 | step: 87900 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.832581907976419e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.14 | consumed tokens: 720076800.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-01T21:32:57 | step: 88000 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.83217227156274e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 2.78 | consumed tokens: 720896000.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:33:13 | step: 88100 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.831762635149062e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.22 | consumed tokens: 721715200.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T21:33:29 | step: 88200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.831352271139622e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.19 | consumed tokens: 722534400.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T21:33:44 | step: 88300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.830941543332301e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.24 | train loss last: 3.84 | consumed tokens: 723353600.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:34:00 | step: 88400 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.8305304517271e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.12 | consumed tokens: 724172800.0 | grad norm avg: 0.72 | grad norm last: 0.65 | 
2026-01-01T21:34:15 | step: 88500 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.830118632526137e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.19 | consumed tokens: 724992000.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:34:31 | step: 88600 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.8297064495272934e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.78 | consumed tokens: 725811200.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:34:46 | step: 88700 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.829293902730569e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.05 | consumed tokens: 726630400.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T21:35:02 | step: 88800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.8288806283380836e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.16 | consumed tokens: 727449600.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T21:35:18 | step: 88900 | train samples/s: 103.7 | train mfu (16-bit): -1.0 | lr mean: 4.828466990147717e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.34 | consumed tokens: 728268800.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:35:33 | step: 89000 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.82805298815947e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 2.66 | consumed tokens: 729088000.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:35:49 | step: 89100 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.827638258575462e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.55 | consumed tokens: 729907200.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:36:05 | step: 89200 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.8272231651935726e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.0 | consumed tokens: 730726400.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:36:20 | step: 89300 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.826807708013803e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.12 | consumed tokens: 731545600.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:36:36 | step: 89400 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.8263915232382715e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.34 | consumed tokens: 732364800.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:36:51 | step: 89500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.8259749746648595e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.7 | consumed tokens: 733184000.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:37:07 | step: 89600 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.825558062293567e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.22 | consumed tokens: 734003200.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:37:23 | step: 89700 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.8251404223265126e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.16 | consumed tokens: 734822400.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:37:38 | step: 89800 | train samples/s: 103.7 | train mfu (16-bit): -1.0 | lr mean: 4.824722418561578e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 2.91 | consumed tokens: 735641600.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:37:54 | step: 89900 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.824304050998762e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.12 | consumed tokens: 736460800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:38:10 | step: 90000 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.823884955840185e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.03 | consumed tokens: 737280000.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T21:38:26 | step: 90100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.823465860681608e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.44 | consumed tokens: 738099200.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T21:38:42 | step: 90200 | train samples/s: 103.2 | train mfu (16-bit): -1.0 | lr mean: 4.823045674129389e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.34 | consumed tokens: 738918400.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:38:58 | step: 90300 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 4.82262548757717e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.28 | consumed tokens: 739737600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T21:39:14 | step: 90400 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.8222045734291896e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.16 | consumed tokens: 740556800.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T21:39:29 | step: 90500 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.8217832954833284e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.06 | consumed tokens: 741376000.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:39:45 | step: 90600 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.821361289941706e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 2.94 | consumed tokens: 742195200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T21:40:00 | step: 90700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.8209389206022024e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.78 | consumed tokens: 743014400.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T21:40:16 | step: 90800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.8205161874648184e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.25 | consumed tokens: 743833600.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:40:31 | step: 90900 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.8200930905295536e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.17 | consumed tokens: 744652800.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:40:47 | step: 91000 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.8196692659985274e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.83 | consumed tokens: 745472000.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:41:03 | step: 91100 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.8192450776696205e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.2 | consumed tokens: 746291200.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:41:18 | step: 91200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.818820525542833e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.31 | consumed tokens: 747110400.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:41:34 | step: 91300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.818395245820284e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.19 | consumed tokens: 747929600.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:41:50 | step: 91400 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.817969602299854e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 2.91 | consumed tokens: 748748800.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:42:06 | step: 91500 | train samples/s: 101.9 | train mfu (16-bit): -1.0 | lr mean: 4.817543594981544e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.66 | consumed tokens: 749568000.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T21:42:21 | step: 91600 | train samples/s: 103.7 | train mfu (16-bit): -1.0 | lr mean: 4.817116860067472e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.67 | consumed tokens: 750387200.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T21:42:37 | step: 91700 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.816689761355519e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.17 | consumed tokens: 751206400.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T21:42:52 | step: 91800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.816262298845686e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.12 | consumed tokens: 752025600.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T21:43:08 | step: 91900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.815834108740091e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.41 | consumed tokens: 752844800.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T21:43:24 | step: 92000 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.815405554836616e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.42 | consumed tokens: 753664000.0 | grad norm avg: 0.7 | grad norm last: 1.09 | 
2026-01-01T21:43:39 | step: 92100 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.81497663713526e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.0 | consumed tokens: 754483200.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:43:55 | step: 92200 | train samples/s: 103.7 | train mfu (16-bit): -1.0 | lr mean: 4.814546991838142e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.53 | consumed tokens: 755302400.0 | grad norm avg: 0.7 | grad norm last: 0.75 | 
2026-01-01T21:44:11 | step: 92300 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.814116982743144e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 2.92 | consumed tokens: 756121600.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:44:26 | step: 92400 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.813686609850265e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 2.36 | consumed tokens: 756940800.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T21:44:42 | step: 92500 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.8132558731595054e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.81 | consumed tokens: 757760000.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:44:58 | step: 92600 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.8128244088729843e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.64 | consumed tokens: 758579200.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:45:13 | step: 92700 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.8123925807885826e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 2.94 | consumed tokens: 759398400.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:45:29 | step: 92800 | train samples/s: 102.3 | train mfu (16-bit): -1.0 | lr mean: 4.8119600251084194e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.39 | consumed tokens: 760217600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T21:45:45 | step: 92900 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.8115271056303754e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.3 | consumed tokens: 761036800.0 | grad norm avg: 0.7 | grad norm last: 0.74 | 
2026-01-01T21:46:00 | step: 93000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.811093822354451e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.86 | consumed tokens: 761856000.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:46:16 | step: 93100 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.8106601752806455e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 4.5 | consumed tokens: 762675200.0 | grad norm avg: 0.7 | grad norm last: 0.65 | 
2026-01-01T21:46:32 | step: 93200 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.810225800611079e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 4.34 | consumed tokens: 763494400.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T21:46:47 | step: 93300 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.809791062143631e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.16 | consumed tokens: 764313600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T21:47:03 | step: 93400 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.809355959878303e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.58 | consumed tokens: 765132800.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:47:18 | step: 93500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.8089201300172135e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.0 | consumed tokens: 765952000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T21:47:34 | step: 93600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.808483936358243e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.14 | consumed tokens: 766771200.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T21:47:49 | step: 93700 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.808047378901392e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.7 | consumed tokens: 767590400.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:48:05 | step: 93800 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.80761009384878e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 4.88 | consumed tokens: 768409600.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:48:21 | step: 93900 | train samples/s: 103.8 | train mfu (16-bit): -1.0 | lr mean: 4.807172444998287e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.94 | consumed tokens: 769228800.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:48:37 | step: 94000 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.806734432349913e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.12 | consumed tokens: 770048000.0 | grad norm avg: 0.71 | grad norm last: 0.75 | 
2026-01-01T21:48:52 | step: 94100 | train samples/s: 103.0 | train mfu (16-bit): -1.0 | lr mean: 4.8062956921057776e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.38 | consumed tokens: 770867200.0 | grad norm avg: 0.7 | grad norm last: 0.65 | 
2026-01-01T21:49:08 | step: 94200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.805856951861642e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.0 | consumed tokens: 771686400.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:49:24 | step: 94300 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.805417120223865e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.19 | consumed tokens: 772505600.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T21:49:39 | step: 94400 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.8049772885860875e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.97 | consumed tokens: 773324800.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:49:55 | step: 94500 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.804536729352549e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.72 | consumed tokens: 774144000.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:50:11 | step: 94600 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.804095806321129e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.77 | consumed tokens: 774963200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:50:26 | step: 94700 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.803654519491829e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 2.84 | consumed tokens: 775782400.0 | grad norm avg: 0.7 | grad norm last: 0.74 | 
2026-01-01T21:50:42 | step: 94800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.803212505066767e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.12 | consumed tokens: 776601600.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T21:50:57 | step: 94900 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.802770126843825e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.31 | consumed tokens: 777420800.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T21:51:13 | step: 95000 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.802327384823002e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.53 | consumed tokens: 778240000.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T21:51:30 | step: 95100 | train samples/s: 103.8 | train mfu (16-bit): -1.0 | lr mean: 4.8018839152064174e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.23 | consumed tokens: 779059200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:51:46 | step: 95200 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.801440081791952e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.36 | consumed tokens: 779878400.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:52:01 | step: 95300 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.8009958845796064e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 2.86 | consumed tokens: 780697600.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:52:17 | step: 95400 | train samples/s: 103.1 | train mfu (16-bit): -1.0 | lr mean: 4.800550959771499e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.72 | consumed tokens: 781516800.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:52:33 | step: 95500 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.800105671165511e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.52 | consumed tokens: 782336000.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:52:49 | step: 95600 | train samples/s: 103.5 | train mfu (16-bit): -1.0 | lr mean: 4.799660018761642e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.16 | consumed tokens: 783155200.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T21:53:04 | step: 95700 | train samples/s: 103.8 | train mfu (16-bit): -1.0 | lr mean: 4.799214002559893e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.14 | consumed tokens: 783974400.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T21:53:20 | step: 95800 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.798767258762382e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 2.69 | consumed tokens: 784793600.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-01T21:53:36 | step: 95900 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.7983201511669904e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.33 | consumed tokens: 785612800.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T21:53:51 | step: 96000 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.797872679773718e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.41 | consumed tokens: 786432000.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:54:07 | step: 96100 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.7974244807846844e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.64 | consumed tokens: 787251200.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T21:54:22 | step: 96200 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.79697591799777e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.7 | consumed tokens: 788070400.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T21:54:38 | step: 96300 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.796526627615094e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.17 | consumed tokens: 788889600.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T21:54:54 | step: 96400 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.7960773372324184e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 2.61 | consumed tokens: 789708800.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T21:55:09 | step: 96500 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.795627319253981e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.5 | consumed tokens: 790528000.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:55:25 | step: 96600 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.795176937477663e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.34 | consumed tokens: 791347200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:55:41 | step: 96700 | train samples/s: 102.6 | train mfu (16-bit): -1.0 | lr mean: 4.794725828105584e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 4.0 | consumed tokens: 792166400.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T21:55:57 | step: 96800 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.794274354935624e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.33 | consumed tokens: 792985600.0 | grad norm avg: 0.71 | grad norm last: 0.66 | 
2026-01-01T21:56:12 | step: 96900 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.793822517967783e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.53 | consumed tokens: 793804800.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T21:56:28 | step: 97000 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.7933703172020614e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.67 | consumed tokens: 794624000.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:56:43 | step: 97100 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.7929173888405785e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.67 | consumed tokens: 795443200.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-01T21:56:59 | step: 97200 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.792464096681215e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 2.94 | consumed tokens: 796262400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:57:15 | step: 97300 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 4.79201007692609e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.02 | consumed tokens: 797081600.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:57:30 | step: 97400 | train samples/s: 103.8 | train mfu (16-bit): -1.0 | lr mean: 4.791556057170965e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.95 | consumed tokens: 797900800.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T21:57:46 | step: 97500 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.791101309820078e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.97 | consumed tokens: 798720000.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:58:02 | step: 97600 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.790646198671311e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.02 | consumed tokens: 799539200.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:58:17 | step: 97700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.7901903599267825e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.66 | consumed tokens: 800358400.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:58:33 | step: 97800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.789734157384373e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.3 | consumed tokens: 801177600.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T21:58:48 | step: 97900 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.789277591044083e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.33 | consumed tokens: 801996800.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T21:59:04 | step: 98000 | train samples/s: 101.8 | train mfu (16-bit): -1.0 | lr mean: 4.788820297108032e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.06 | consumed tokens: 802816000.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T21:59:20 | step: 98100 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.7883630031719804e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.8 | consumed tokens: 803635200.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T21:59:36 | step: 98200 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.7879049816401675e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.3 | consumed tokens: 804454400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T21:59:51 | step: 98300 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.787446232512593e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.12 | consumed tokens: 805273600.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T22:00:07 | step: 98400 | train samples/s: 103.8 | train mfu (16-bit): -1.0 | lr mean: 4.786987483385019e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.06 | consumed tokens: 806092800.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T22:00:23 | step: 98500 | train samples/s: 103.6 | train mfu (16-bit): -1.0 | lr mean: 4.786528006661683e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.09 | consumed tokens: 806912000.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T22:00:39 | step: 98600 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.786067802342586e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.47 | consumed tokens: 807731200.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T22:00:54 | step: 98700 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.785607598023489e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.11 | consumed tokens: 808550400.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T22:01:10 | step: 98800 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.7851466661086306e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 2.86 | consumed tokens: 809369600.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-01T22:01:26 | step: 98900 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.7846853703958914e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.92 | consumed tokens: 810188800.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-01T22:01:41 | step: 99000 | train samples/s: 103.5 | train mfu (16-bit): -1.0 | lr mean: 4.784223347087391e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.12 | consumed tokens: 811008000.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T22:01:57 | step: 99100 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.7837609599810094e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 2.78 | consumed tokens: 811827200.0 | grad norm avg: 0.7 | grad norm last: 0.75 | 
2026-01-01T22:02:13 | step: 99200 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.783298209076747e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.56 | consumed tokens: 812646400.0 | grad norm avg: 0.69 | grad norm last: 0.74 | 
2026-01-01T22:02:29 | step: 99300 | train samples/s: 103.2 | train mfu (16-bit): -1.0 | lr mean: 4.7828350943746045e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.88 | consumed tokens: 813465600.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T22:02:44 | step: 99400 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.7823712520767e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.25 | consumed tokens: 814284800.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T22:03:00 | step: 99500 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.7819070459809154e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 2.7 | consumed tokens: 815104000.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T22:03:16 | step: 99600 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.78144247608725e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.14 | consumed tokens: 815923200.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T22:03:31 | step: 99700 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.780977178597823e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 2.8 | consumed tokens: 816742400.0 | grad norm avg: 0.69 | grad norm last: 0.76 | 
2026-01-01T22:03:47 | step: 99800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.780511881108396e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.03 | consumed tokens: 817561600.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T22:04:02 | step: 99900 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.7800454922253266e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.25 | consumed tokens: 818380800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T22:04:18 | step: 100000 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.7795791033422574e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.97 | consumed tokens: 819200000.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:04:35 | step: 100100 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 4.779111986863427e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.23 | consumed tokens: 820019200.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T22:04:51 | step: 100200 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.7786445065867156e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.62 | consumed tokens: 820838400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:05:06 | step: 100300 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.7781766625121236e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.39 | consumed tokens: 821657600.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T22:05:22 | step: 100400 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.77770809084177e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.48 | consumed tokens: 822476800.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T22:05:37 | step: 100500 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.777239155373536e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 4.06 | consumed tokens: 823296000.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T22:05:54 | step: 100600 | train samples/s: 101.9 | train mfu (16-bit): -1.0 | lr mean: 4.776769856107421e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.42 | consumed tokens: 824115200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T22:06:09 | step: 100700 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.776300193043426e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.39 | consumed tokens: 824934400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:06:25 | step: 100800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.775829802383669e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 2.84 | consumed tokens: 825753600.0 | grad norm avg: 0.71 | grad norm last: 0.69 | 
2026-01-01T22:06:40 | step: 100900 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.775359047926031e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.91 | consumed tokens: 826572800.0 | grad norm avg: 0.7 | grad norm last: 0.74 | 
2026-01-01T22:06:56 | step: 101000 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.774887565872632e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.44 | consumed tokens: 827392000.0 | grad norm avg: 0.7 | grad norm last: 0.75 | 
2026-01-01T22:07:12 | step: 101100 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.774416083819233e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 2.91 | consumed tokens: 828211200.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T22:07:27 | step: 101200 | train samples/s: 103.8 | train mfu (16-bit): -1.0 | lr mean: 4.7739438741700724e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.36 | consumed tokens: 829030400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T22:07:43 | step: 101300 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.7734709369251505e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.91 | consumed tokens: 829849600.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T22:07:58 | step: 101400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.7729979996802285e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 4.12 | consumed tokens: 830668800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T22:08:14 | step: 101500 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.772524334839545e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 2.56 | consumed tokens: 831488000.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T22:08:30 | step: 101600 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.772050306200981e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.84 | consumed tokens: 832307200.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T22:08:45 | step: 101700 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.771575549966656e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.21 | train loss last: 3.06 | consumed tokens: 833126400.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T22:09:01 | step: 101800 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.7711004299344495e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.31 | consumed tokens: 833945600.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T22:09:17 | step: 101900 | train samples/s: 103.1 | train mfu (16-bit): -1.0 | lr mean: 4.7706249461043626e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.31 | consumed tokens: 834764800.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T22:09:32 | step: 102000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.770149098476395e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.14 | consumed tokens: 835584000.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T22:09:48 | step: 102100 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.769672887050547e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.16 | consumed tokens: 836403200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:10:04 | step: 102200 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.769195948028937e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.22 | consumed tokens: 837222400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T22:10:19 | step: 102300 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.768718281411566e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.42 | consumed tokens: 838041600.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T22:10:35 | step: 102400 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.768240614794195e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.16 | consumed tokens: 838860800.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T22:10:50 | step: 102500 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.767762220581062e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.89 | consumed tokens: 839680000.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T22:11:06 | step: 102600 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.767283462570049e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.2 | consumed tokens: 840499200.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T22:11:22 | step: 102700 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.766804340761155e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.94 | consumed tokens: 841318400.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T22:11:38 | step: 102800 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 4.7663244913564995e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.64 | consumed tokens: 842137600.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T22:11:53 | step: 102900 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.7658442781539634e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.36 | consumed tokens: 842956800.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T22:12:09 | step: 103000 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.7653637011535466e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.7 | consumed tokens: 843776000.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T22:12:24 | step: 103100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.764882760355249e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.56 | consumed tokens: 844595200.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T22:12:40 | step: 103200 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.76440109196119e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.11 | consumed tokens: 845414400.0 | grad norm avg: 0.69 | grad norm last: 0.75 | 
2026-01-01T22:12:56 | step: 103300 | train samples/s: 101.9 | train mfu (16-bit): -1.0 | lr mean: 4.7639190597692505e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.23 | consumed tokens: 846233600.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T22:13:12 | step: 103400 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.7634362999815494e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.73 | consumed tokens: 847052800.0 | grad norm avg: 0.7 | grad norm last: 0.76 | 
2026-01-01T22:13:27 | step: 103500 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.762953540193848e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.06 | consumed tokens: 847872000.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T22:13:43 | step: 103600 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.762470052810386e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.86 | consumed tokens: 848691200.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T22:13:58 | step: 103700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.761985837831162e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.25 | consumed tokens: 849510400.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T22:14:14 | step: 103800 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.761501622851938e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.73 | consumed tokens: 850329600.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T22:14:30 | step: 103900 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.761016680276953e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.33 | consumed tokens: 851148800.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T22:14:45 | step: 104000 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.7605313739040866e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.61 | consumed tokens: 851968000.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T22:15:01 | step: 104100 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.76004570373334e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.83 | consumed tokens: 852787200.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T22:15:16 | step: 104200 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.759559305966832e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.39 | consumed tokens: 853606400.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T22:15:32 | step: 104300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.759072544402443e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.72 | consumed tokens: 854425600.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T22:15:48 | step: 104400 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.758585419040173e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 2.69 | consumed tokens: 855244800.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T22:16:04 | step: 104500 | train samples/s: 102.5 | train mfu (16-bit): -1.0 | lr mean: 4.758097566082142e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.22 | train loss last: 3.0 | consumed tokens: 856064000.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T22:16:19 | step: 104600 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.757609713124111e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.33 | consumed tokens: 856883200.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T22:16:35 | step: 104700 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.757121132570319e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.14 | consumed tokens: 857702400.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T22:16:50 | step: 104800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.756631824420765e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.17 | consumed tokens: 858521600.0 | grad norm avg: 0.7 | grad norm last: 0.65 | 
2026-01-01T22:17:06 | step: 104900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.756142516271211e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.56 | consumed tokens: 859340800.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T22:17:22 | step: 105000 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.755652480525896e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.39 | consumed tokens: 860160000.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T22:17:39 | step: 105100 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.755161717184819e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 4.25 | consumed tokens: 860979200.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T22:17:54 | step: 105200 | train samples/s: 103.5 | train mfu (16-bit): -1.0 | lr mean: 4.7546709538437426e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.52 | consumed tokens: 861798400.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T22:18:10 | step: 105300 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.7541794629069045e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.31 | consumed tokens: 862617600.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-01T22:18:26 | step: 105400 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.753687608172186e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.16 | consumed tokens: 863436800.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-01T22:18:42 | step: 105500 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.753195389639586e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.39 | consumed tokens: 864256000.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T22:18:58 | step: 105600 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.752702443511225e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.38 | consumed tokens: 865075200.0 | grad norm avg: 0.7 | grad norm last: 0.84 | 
2026-01-01T22:19:13 | step: 105700 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 4.7522091335849836e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.52 | consumed tokens: 865894400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:19:29 | step: 105800 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.751715459860861e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.88 | consumed tokens: 866713600.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T22:19:45 | step: 105900 | train samples/s: 102.9 | train mfu (16-bit): -1.0 | lr mean: 4.751221422338858e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.08 | consumed tokens: 867532800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:20:00 | step: 106000 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.750726657221094e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.77 | consumed tokens: 868352000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T22:20:16 | step: 106100 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.7502315283054486e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.31 | consumed tokens: 869171200.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-01T22:20:32 | step: 106200 | train samples/s: 103.7 | train mfu (16-bit): -1.0 | lr mean: 4.749736035591923e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.52 | consumed tokens: 869990400.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T22:20:48 | step: 106300 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.7492398152826354e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.83 | consumed tokens: 870809600.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T22:21:03 | step: 106400 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.7487432311754674e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.05 | consumed tokens: 871628800.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T22:21:19 | step: 106500 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.7482462832704186e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.28 | consumed tokens: 872448000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T22:21:34 | step: 106600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.747748971567489e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.7 | consumed tokens: 873267200.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T22:21:50 | step: 106700 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.7472509322687984e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.55 | consumed tokens: 874086400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:22:06 | step: 106800 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.746752529172227e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.61 | consumed tokens: 874905600.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T22:22:21 | step: 106900 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.7462537622777745e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.02 | consumed tokens: 875724800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:22:37 | step: 107000 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.745754267787561e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.2 | consumed tokens: 876544000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T22:22:52 | step: 107100 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.745254773297347e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.73 | consumed tokens: 877363200.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T22:23:08 | step: 107200 | train samples/s: 103.1 | train mfu (16-bit): -1.0 | lr mean: 4.744754551211372e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.41 | consumed tokens: 878182400.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T22:23:24 | step: 107300 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.7442536015296355e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.56 | consumed tokens: 879001600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:23:40 | step: 107400 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.743752651847899e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.47 | consumed tokens: 879820800.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T22:23:55 | step: 107500 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.743250974570401e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.23 | consumed tokens: 880640000.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T22:24:11 | step: 107600 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.7427489334950224e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.05 | consumed tokens: 881459200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T22:24:27 | step: 107700 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.742246164823882e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.42 | consumed tokens: 882278400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T22:24:42 | step: 107800 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.7417430323548615e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.33 | consumed tokens: 883097600.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T22:24:58 | step: 107900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.74123953608796e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.17 | consumed tokens: 883916800.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T22:25:13 | step: 108000 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.740735676023178e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.38 | consumed tokens: 884736000.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T22:25:29 | step: 108100 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.740231452160515e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.72 | consumed tokens: 885555200.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T22:25:45 | step: 108200 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.7397265007020906e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.66 | consumed tokens: 886374400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T22:26:00 | step: 108300 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.7392211854457855e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.89 | consumed tokens: 887193600.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T22:26:16 | step: 108400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.738715142593719e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.72 | consumed tokens: 888012800.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T22:26:32 | step: 108500 | train samples/s: 102.6 | train mfu (16-bit): -1.0 | lr mean: 4.7382090997416526e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.27 | consumed tokens: 888832000.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T22:26:48 | step: 108600 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.737702329293825e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.2 | consumed tokens: 889651200.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T22:27:03 | step: 108700 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.737195195048116e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 2.69 | consumed tokens: 890470400.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T22:27:19 | step: 108800 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.736687333206646e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.61 | consumed tokens: 891289600.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T22:27:34 | step: 108900 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.7361791075672954e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.88 | consumed tokens: 892108800.0 | grad norm avg: 0.69 | grad norm last: 0.74 | 
2026-01-01T22:27:50 | step: 109000 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.735670518130064e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.38 | consumed tokens: 892928000.0 | grad norm avg: 0.7 | grad norm last: 0.75 | 
2026-01-01T22:28:06 | step: 109100 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.735161564894952e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.91 | consumed tokens: 893747200.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T22:28:21 | step: 109200 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.734652247861959e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.38 | consumed tokens: 894566400.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T22:28:37 | step: 109300 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.734142203233205e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.94 | consumed tokens: 895385600.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T22:28:53 | step: 109400 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.73363179480657e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.12 | consumed tokens: 896204800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T22:29:08 | step: 109500 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.7331206587841734e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.05 | consumed tokens: 897024000.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T22:29:24 | step: 109600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.732609522761777e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.77 | consumed tokens: 897843200.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T22:29:39 | step: 109700 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.732097659143619e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.2 | consumed tokens: 898662400.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-01T22:29:55 | step: 109800 | train samples/s: 102.3 | train mfu (16-bit): -1.0 | lr mean: 4.731585431727581e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.25 | consumed tokens: 899481600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:30:11 | step: 109900 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.731072476715781e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.44 | consumed tokens: 900300800.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-01T22:30:26 | step: 110000 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.730559521703981e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.2 | train loss last: 3.23 | consumed tokens: 901120000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T22:30:43 | step: 110100 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.7300458390964195e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.11 | consumed tokens: 901939200.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T22:30:59 | step: 110200 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.7295317926909775e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.83 | consumed tokens: 902758400.0 | grad norm avg: 0.7 | grad norm last: 0.76 | 
2026-01-01T22:31:14 | step: 110300 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.729017018689774e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.08 | consumed tokens: 903577600.0 | grad norm avg: 0.69 | grad norm last: 0.75 | 
2026-01-01T22:31:30 | step: 110400 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.72850188089069e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.45 | consumed tokens: 904396800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T22:31:46 | step: 110500 | train samples/s: 103.7 | train mfu (16-bit): -1.0 | lr mean: 4.727986379293725e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.42 | consumed tokens: 905216000.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T22:32:02 | step: 110600 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.727470513898879e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.16 | consumed tokens: 906035200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:32:17 | step: 110700 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.726953920908272e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.33 | consumed tokens: 906854400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T22:32:33 | step: 110800 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.726437327917665e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.2 | consumed tokens: 907673600.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T22:32:48 | step: 110900 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.725920007331297e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.14 | consumed tokens: 908492800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T22:33:04 | step: 111000 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.725401959149167e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.94 | consumed tokens: 909312000.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T22:33:20 | step: 111100 | train samples/s: 102.2 | train mfu (16-bit): -1.0 | lr mean: 4.724883910967037e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.58 | consumed tokens: 910131200.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-01T22:33:36 | step: 111200 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.724365135189146e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.23 | consumed tokens: 910950400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:33:51 | step: 111300 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.723845995613374e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.38 | consumed tokens: 911769600.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T22:34:07 | step: 111400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.7233261284418404e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.64 | consumed tokens: 912588800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:34:22 | step: 111500 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.722805897472426e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.31 | consumed tokens: 913408000.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-01T22:34:39 | step: 111600 | train samples/s: 100.3 | train mfu (16-bit): -1.0 | lr mean: 4.722285666503012e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.03 | consumed tokens: 914227200.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T22:34:54 | step: 111700 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.721764344139956e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.28 | consumed tokens: 915046400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T22:35:10 | step: 111800 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.7212430217769e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.61 | consumed tokens: 915865600.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T22:35:25 | step: 111900 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.720720971818082e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 4.56 | consumed tokens: 916684800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T22:35:41 | step: 112000 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.720198558061384e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.67 | consumed tokens: 917504000.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T22:35:57 | step: 112100 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.7196757805068046e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.33 | consumed tokens: 918323200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T22:36:12 | step: 112200 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.719152275356464e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.75 | consumed tokens: 919142400.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T22:36:28 | step: 112300 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.7186287702061236e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.8 | consumed tokens: 919961600.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T22:36:44 | step: 112400 | train samples/s: 102.5 | train mfu (16-bit): -1.0 | lr mean: 4.718104537460022e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.81 | consumed tokens: 920780800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T22:37:00 | step: 112500 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.7175795771181583e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.19 | consumed tokens: 921600000.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-01T22:37:15 | step: 112600 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.717054616776295e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.02 | consumed tokens: 922419200.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T22:37:31 | step: 112700 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.71652892883867e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.81 | consumed tokens: 923238400.0 | grad norm avg: 0.69 | grad norm last: 0.75 | 
2026-01-01T22:37:47 | step: 112800 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.716002877103165e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.09 | consumed tokens: 924057600.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T22:38:02 | step: 112900 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.7154764615697786e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.61 | consumed tokens: 924876800.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T22:38:18 | step: 113000 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.714949318440631e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.84 | consumed tokens: 925696000.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T22:38:33 | step: 113100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.714421811513603e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.28 | consumed tokens: 926515200.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T22:38:49 | step: 113200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.713893940788694e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.91 | consumed tokens: 927334400.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T22:39:05 | step: 113300 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.713365706265904e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.23 | consumed tokens: 928153600.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T22:39:20 | step: 113400 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.712836744147353e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.33 | consumed tokens: 928972800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:39:36 | step: 113500 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.712307418230921e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.39 | consumed tokens: 929792000.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:39:52 | step: 113600 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.7117777285166085e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.83 | consumed tokens: 930611200.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T22:40:07 | step: 113700 | train samples/s: 102.9 | train mfu (16-bit): -1.0 | lr mean: 4.7112473112065345e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.5 | consumed tokens: 931430400.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T22:40:23 | step: 113800 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.7107168938964605e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.27 | consumed tokens: 932249600.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-01T22:40:39 | step: 113900 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.710185748990625e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.53 | consumed tokens: 933068800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:40:54 | step: 114000 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 4.709654240286909e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.12 | consumed tokens: 933888000.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T22:41:10 | step: 114100 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.7091220039874315e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.45 | consumed tokens: 934707200.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T22:41:26 | step: 114200 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.708589767687954e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.7 | consumed tokens: 935526400.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T22:41:41 | step: 114300 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.708056803792715e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.02 | consumed tokens: 936345600.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T22:41:57 | step: 114400 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.707523112301715e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.16 | consumed tokens: 937164800.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T22:42:13 | step: 114500 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.7069894208107144e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.53 | consumed tokens: 937984000.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T22:42:28 | step: 114600 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.7064550017239526e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.23 | consumed tokens: 938803200.0 | grad norm avg: 0.7 | grad norm last: 0.64 | 
2026-01-01T22:42:44 | step: 114700 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.70592021883931e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.81 | consumed tokens: 939622400.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T22:42:59 | step: 114800 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.705385072156787e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.89 | consumed tokens: 940441600.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-01T22:43:15 | step: 114900 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.704849561676383e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.22 | consumed tokens: 941260800.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T22:43:31 | step: 115000 | train samples/s: 103.2 | train mfu (16-bit): -1.0 | lr mean: 4.704313323600218e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.0 | consumed tokens: 942080000.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-01T22:43:48 | step: 115100 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.703776721726172e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.86 | consumed tokens: 942899200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T22:44:04 | step: 115200 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.703239756054245e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.97 | consumed tokens: 943718400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:44:19 | step: 115300 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.702702062786557e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.0 | consumed tokens: 944537600.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T22:44:35 | step: 115400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.7021643695188686e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.36 | consumed tokens: 945356800.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T22:44:50 | step: 115500 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.701625948655419e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.88 | consumed tokens: 946176000.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-01T22:45:06 | step: 115600 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.701086800196208e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.86 | consumed tokens: 946995200.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-01T22:45:22 | step: 115700 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.700547651736997e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.66 | consumed tokens: 947814400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:45:37 | step: 115800 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.7000077756820247e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.91 | consumed tokens: 948633600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:45:53 | step: 115900 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.6994675358291715e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.48 | consumed tokens: 949452800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:46:09 | step: 116000 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.698926932178438e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.23 | consumed tokens: 950272000.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-01T22:46:24 | step: 116100 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.6983856009319425e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.73 | consumed tokens: 951091200.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T22:46:40 | step: 116200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.697844269685447e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.56 | consumed tokens: 951910400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T22:46:56 | step: 116300 | train samples/s: 102.5 | train mfu (16-bit): -1.0 | lr mean: 4.6973022108431906e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.11 | consumed tokens: 952729600.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T22:47:11 | step: 116400 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.6967594244051725e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.88 | consumed tokens: 953548800.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T22:47:27 | step: 116500 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.6962166379671544e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.05 | consumed tokens: 954368000.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T22:47:43 | step: 116600 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.695673123933375e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.92 | consumed tokens: 955187200.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T22:47:58 | step: 116700 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.695129246101715e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.8 | consumed tokens: 956006400.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-01T22:48:14 | step: 116800 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.694585004472174e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.83 | consumed tokens: 956825600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:48:29 | step: 116900 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.694040399044752e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.19 | consumed tokens: 957644800.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T22:48:45 | step: 117000 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.693495066021569e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.28 | consumed tokens: 958464000.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T22:49:01 | step: 117100 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.692949369200505e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.97 | consumed tokens: 959283200.0 | grad norm avg: 0.69 | grad norm last: 0.75 | 
2026-01-01T22:49:16 | step: 117200 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.692403308581561e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.72 | consumed tokens: 960102400.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T22:49:32 | step: 117300 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.691856520366855e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.42 | consumed tokens: 960921600.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T22:49:47 | step: 117400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.6913093683542684e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.03 | consumed tokens: 961740800.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-01T22:50:03 | step: 117500 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.690761852543801e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.5 | consumed tokens: 962560000.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T22:50:19 | step: 117600 | train samples/s: 102.3 | train mfu (16-bit): -1.0 | lr mean: 4.690213972935453e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.56 | consumed tokens: 963379200.0 | grad norm avg: 0.69 | grad norm last: 0.74 | 
2026-01-01T22:50:35 | step: 117700 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.689665729529224e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.33 | consumed tokens: 964198400.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T22:50:50 | step: 117800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.689116758527234e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.53 | consumed tokens: 965017600.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T22:51:06 | step: 117900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.6885674237273633e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.14 | consumed tokens: 965836800.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-01T22:51:21 | step: 118000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.688017725129612e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.89 | consumed tokens: 966656000.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:51:37 | step: 118100 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.6874676627339795e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.41 | consumed tokens: 967475200.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T22:51:52 | step: 118200 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.686916872742586e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.11 | consumed tokens: 968294400.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T22:52:08 | step: 118300 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.6863657189533114e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.64 | consumed tokens: 969113600.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T22:52:24 | step: 118400 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.6858142013661563e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.12 | consumed tokens: 969932800.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T22:52:39 | step: 118500 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.68526195618324e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.28 | consumed tokens: 970752000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T22:52:55 | step: 118600 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.684709711000323e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.27 | consumed tokens: 971571200.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T22:53:10 | step: 118700 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.6841567382216454e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.8 | consumed tokens: 972390400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:53:26 | step: 118800 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 4.683603401645087e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.33 | consumed tokens: 973209600.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T22:53:42 | step: 118900 | train samples/s: 102.3 | train mfu (16-bit): -1.0 | lr mean: 4.6830493374727666e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.83 | consumed tokens: 974028800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T22:53:58 | step: 119000 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.6824952733004466e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.09 | consumed tokens: 974848000.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-01T22:54:13 | step: 119100 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.681940481532365e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.91 | consumed tokens: 975667200.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-01T22:54:29 | step: 119200 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.681385325966403e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.56 | consumed tokens: 976486400.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T22:54:45 | step: 119300 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.68082980660256e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.98 | consumed tokens: 977305600.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T22:55:00 | step: 119400 | train samples/s: 102.8 | train mfu (16-bit): -1.0 | lr mean: 4.6802735596429557e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.03 | consumed tokens: 978124800.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T22:55:16 | step: 119500 | train samples/s: 102.2 | train mfu (16-bit): -1.0 | lr mean: 4.6797169488854706e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.92 | consumed tokens: 978944000.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-01T22:55:32 | step: 119600 | train samples/s: 103.8 | train mfu (16-bit): -1.0 | lr mean: 4.679159974330105e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.11 | consumed tokens: 979763200.0 | grad norm avg: 0.69 | grad norm last: 0.74 | 
2026-01-01T22:55:48 | step: 119700 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.6786026359768584e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.03 | consumed tokens: 980582400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:56:03 | step: 119800 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.6780445700278506e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.31 | consumed tokens: 981401600.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T22:56:19 | step: 119900 | train samples/s: 102.8 | train mfu (16-bit): -1.0 | lr mean: 4.677486504078843e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.25 | consumed tokens: 982220800.0 | grad norm avg: 0.7 | grad norm last: 0.77 | 
2026-01-01T22:56:35 | step: 120000 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 4.6769277105340734e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.09 | consumed tokens: 983040000.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T22:56:52 | step: 120100 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 4.676368189393543e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.36 | consumed tokens: 983859200.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T22:57:08 | step: 120200 | train samples/s: 102.8 | train mfu (16-bit): -1.0 | lr mean: 4.675808668253012e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.56 | consumed tokens: 984678400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:57:24 | step: 120300 | train samples/s: 103.5 | train mfu (16-bit): -1.0 | lr mean: 4.67524841951672e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.08 | consumed tokens: 985497600.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T22:57:39 | step: 120400 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.674687806982547e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.33 | consumed tokens: 986316800.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T22:57:55 | step: 120500 | train samples/s: 103.7 | train mfu (16-bit): -1.0 | lr mean: 4.6741268306504935e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 4.03 | consumed tokens: 987136000.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T22:58:11 | step: 120600 | train samples/s: 103.6 | train mfu (16-bit): -1.0 | lr mean: 4.673565490520559e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.28 | consumed tokens: 987955200.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-01T22:58:27 | step: 120700 | train samples/s: 103.4 | train mfu (16-bit): -1.0 | lr mean: 4.6730034227948636e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.59 | consumed tokens: 988774400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T22:58:42 | step: 120800 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.672440991271287e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.03 | consumed tokens: 989593600.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T22:58:58 | step: 120900 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.67187819594983e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.98 | consumed tokens: 990412800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T22:59:14 | step: 121000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.671315036830492e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.33 | consumed tokens: 991232000.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T22:59:29 | step: 121100 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.670751150115393e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.7 | consumed tokens: 992051200.0 | grad norm avg: 0.7 | grad norm last: 0.74 | 
2026-01-01T22:59:45 | step: 121200 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.670186899602413e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 2.98 | consumed tokens: 992870400.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T23:00:01 | step: 121300 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.6696222852915525e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.16 | consumed tokens: 993689600.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T23:00:16 | step: 121400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.669057307182811e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.19 | consumed tokens: 994508800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:00:32 | step: 121500 | train samples/s: 103.7 | train mfu (16-bit): -1.0 | lr mean: 4.6684916014783084e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.02 | consumed tokens: 995328000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T23:00:47 | step: 121600 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.667925895773806e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.28 | consumed tokens: 996147200.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-01T23:01:03 | step: 121700 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.6673594624735415e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.22 | consumed tokens: 996966400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:01:20 | step: 121800 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.666792301577516e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.05 | consumed tokens: 997785600.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-01T23:01:36 | step: 121900 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 4.66622514068149e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.34 | consumed tokens: 998604800.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:01:53 | step: 122000 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.665657252189703e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.44 | consumed tokens: 999424000.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:02:09 | step: 122100 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.6650889999000356e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.28 | consumed tokens: 1000243200.0 | grad norm avg: 0.69 | grad norm last: 0.76 | 
2026-01-01T23:02:26 | step: 122200 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 4.664520383812487e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.73 | consumed tokens: 1001062400.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-01T23:02:42 | step: 122300 | train samples/s: 98.8 | train mfu (16-bit): -1.0 | lr mean: 4.663951403927058e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.7 | consumed tokens: 1001881600.0 | grad norm avg: 0.69 | grad norm last: 0.74 | 
2026-01-01T23:02:59 | step: 122400 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 4.6633816964458674e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.02 | consumed tokens: 1002700800.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-01T23:03:15 | step: 122500 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 4.662811625166796e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.19 | consumed tokens: 1003520000.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:03:32 | step: 122600 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 4.662241190089844e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 4.12 | consumed tokens: 1004339200.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T23:03:48 | step: 122700 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 4.6616703912150115e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.52 | consumed tokens: 1005158400.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T23:04:05 | step: 122800 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 4.661099228542298e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.64 | consumed tokens: 1005977600.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T23:04:22 | step: 122900 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.660527338273823e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.17 | consumed tokens: 1006796800.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T23:04:38 | step: 123000 | train samples/s: 98.8 | train mfu (16-bit): -1.0 | lr mean: 4.659955084207468e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.64 | consumed tokens: 1007616000.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T23:04:55 | step: 123100 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.6593824663432315e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.98 | consumed tokens: 1008435200.0 | grad norm avg: 0.7 | grad norm last: 0.65 | 
2026-01-01T23:05:11 | step: 123200 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.658809120883234e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.16 | consumed tokens: 1009254400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:05:28 | step: 123300 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 4.6582354116253555e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.28 | consumed tokens: 1010073600.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T23:05:44 | step: 123400 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 4.657661702367477e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.88 | consumed tokens: 1010892800.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T23:06:01 | step: 123500 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 4.6570869017159566e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.59 | consumed tokens: 1011712000.0 | grad norm avg: 0.7 | grad norm last: 0.75 | 
2026-01-01T23:06:17 | step: 123600 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 4.656512101064436e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 4.03 | consumed tokens: 1012531200.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-01T23:06:33 | step: 123700 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.655936936615035e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.86 | consumed tokens: 1013350400.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T23:06:50 | step: 123800 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.655361044569872e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.16 | consumed tokens: 1014169600.0 | grad norm avg: 0.72 | grad norm last: 0.71 | 
2026-01-01T23:07:07 | step: 123900 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 4.654784788726829e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.67 | consumed tokens: 1014988800.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-01T23:07:23 | step: 124000 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.654208169085905e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 4.0 | consumed tokens: 1015808000.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T23:07:40 | step: 124100 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.6536308218492195e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.81 | consumed tokens: 1016627200.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T23:07:56 | step: 124200 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 4.653053110814653e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.3 | consumed tokens: 1017446400.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T23:08:13 | step: 124300 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.6524750359822065e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.39 | consumed tokens: 1018265600.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T23:08:29 | step: 124400 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 4.651896597351879e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.47 | consumed tokens: 1019084800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:08:46 | step: 124500 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 4.6513177949236706e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.3 | consumed tokens: 1019904000.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T23:09:02 | step: 124600 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 4.650738264899701e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.8 | consumed tokens: 1020723200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:09:19 | step: 124700 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 4.650158734875731e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.02 | consumed tokens: 1021542400.0 | grad norm avg: 0.69 | grad norm last: 0.74 | 
2026-01-01T23:09:35 | step: 124800 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 4.649578113458119e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.64 | consumed tokens: 1022361600.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-01T23:09:52 | step: 124900 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.6489974920405075e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.78 | consumed tokens: 1023180800.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:10:08 | step: 125000 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.648416506825015e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.47 | consumed tokens: 1024000000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:10:26 | step: 125100 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 4.647834794013761e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.09 | consumed tokens: 1024819200.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:10:43 | step: 125200 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 4.647252717404626e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.64 | consumed tokens: 1025638400.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T23:10:59 | step: 125300 | train samples/s: 100.4 | train mfu (16-bit): -1.0 | lr mean: 4.646670276997611e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.97 | consumed tokens: 1026457600.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T23:11:16 | step: 125400 | train samples/s: 96.8 | train mfu (16-bit): -1.0 | lr mean: 4.646087472792715e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.11 | consumed tokens: 1027276800.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T23:11:33 | step: 125500 | train samples/s: 96.2 | train mfu (16-bit): -1.0 | lr mean: 4.645503940992057e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.3 | consumed tokens: 1028096000.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T23:11:49 | step: 125600 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.644920045393519e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.12 | consumed tokens: 1028915200.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:12:06 | step: 125700 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 4.6443357859971e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.55 | consumed tokens: 1029734400.0 | grad norm avg: 0.7 | grad norm last: 0.65 | 
2026-01-01T23:12:22 | step: 125800 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.6437511628028005e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.09 | consumed tokens: 1030553600.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-01T23:12:39 | step: 125900 | train samples/s: 100.4 | train mfu (16-bit): -1.0 | lr mean: 4.64316617581062e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.36 | consumed tokens: 1031372800.0 | grad norm avg: 0.7 | grad norm last: 0.64 | 
2026-01-01T23:12:55 | step: 126000 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.6425804612226784e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.17 | consumed tokens: 1032192000.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T23:13:12 | step: 126100 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.641994382836856e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.81 | consumed tokens: 1033011200.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T23:13:28 | step: 126200 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 4.641407940653153e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.84 | consumed tokens: 1033830400.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T23:13:44 | step: 126300 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 4.640821134671569e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.36 | consumed tokens: 1034649600.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T23:14:01 | step: 126400 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.6402336010942236e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.55 | consumed tokens: 1035468800.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-01T23:14:17 | step: 126500 | train samples/s: 100.1 | train mfu (16-bit): -1.0 | lr mean: 4.6396457037189975e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.06 | consumed tokens: 1036288000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:14:34 | step: 126600 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.639057442545891e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.3 | consumed tokens: 1037107200.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T23:14:50 | step: 126700 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.6384688175749034e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.16 | consumed tokens: 1037926400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:15:07 | step: 126800 | train samples/s: 97.2 | train mfu (16-bit): -1.0 | lr mean: 4.637879828806035e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.14 | consumed tokens: 1038745600.0 | grad norm avg: 0.7 | grad norm last: 0.75 | 
2026-01-01T23:15:23 | step: 126900 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.6372901124414057e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.91 | consumed tokens: 1039564800.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:15:39 | step: 127000 | train samples/s: 100.1 | train mfu (16-bit): -1.0 | lr mean: 4.6367000322788954e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.55 | consumed tokens: 1040384000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:15:56 | step: 127100 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.6361095883185044e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.47 | consumed tokens: 1041203200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T23:16:12 | step: 127200 | train samples/s: 98.8 | train mfu (16-bit): -1.0 | lr mean: 4.635518780560233e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.33 | consumed tokens: 1042022400.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T23:16:29 | step: 127300 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.6349272452061996e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.27 | consumed tokens: 1042841600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:16:45 | step: 127400 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.6343357098521665e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.17 | consumed tokens: 1043660800.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T23:17:02 | step: 127500 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.633743446902372e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.67 | consumed tokens: 1044480000.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T23:17:18 | step: 127600 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.633150820154697e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.33 | consumed tokens: 1045299200.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-01T23:17:34 | step: 127700 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.63255746581126e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 4.0 | consumed tokens: 1046118400.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T23:17:51 | step: 127800 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.6319641114678234e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.83 | consumed tokens: 1046937600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:18:07 | step: 127900 | train samples/s: 98.8 | train mfu (16-bit): -1.0 | lr mean: 4.631370029528625e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.31 | consumed tokens: 1047756800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:18:24 | step: 128000 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.6307755837915465e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.12 | consumed tokens: 1048576000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:18:40 | step: 128100 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 4.630180774256587e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.02 | consumed tokens: 1049395200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:18:57 | step: 128200 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.629585600923747e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.27 | consumed tokens: 1050214400.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T23:19:13 | step: 128300 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.628989699995145e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.34 | consumed tokens: 1051033600.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:19:30 | step: 128400 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.628393435268663e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.69 | consumed tokens: 1051852800.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:19:46 | step: 128500 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 4.6277968067443e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.67 | consumed tokens: 1052672000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T23:20:02 | step: 128600 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.627199814422056e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.88 | consumed tokens: 1053491200.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:20:19 | step: 128700 | train samples/s: 100.2 | train mfu (16-bit): -1.0 | lr mean: 4.626602094504051e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.06 | consumed tokens: 1054310400.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T23:20:35 | step: 128800 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.626004374586046e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.75 | consumed tokens: 1055129600.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-01T23:20:51 | step: 128900 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.625405927072279e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.62 | consumed tokens: 1055948800.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:21:08 | step: 129000 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.624807115760632e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.25 | consumed tokens: 1056768000.0 | grad norm avg: 0.69 | grad norm last: 0.75 | 
2026-01-01T23:21:24 | step: 129100 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 4.624207940651104e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.61 | consumed tokens: 1057587200.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T23:21:41 | step: 129200 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.6236080379458144e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.33 | consumed tokens: 1058406400.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-01T23:21:57 | step: 129300 | train samples/s: 100.3 | train mfu (16-bit): -1.0 | lr mean: 4.623007771442644e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.42 | consumed tokens: 1059225600.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T23:22:14 | step: 129400 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 4.622407504939474e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.97 | consumed tokens: 1060044800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T23:22:30 | step: 129500 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.621806147042662e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.36 | consumed tokens: 1060864000.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-01T23:22:47 | step: 129600 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 4.6212047891458496e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.39 | consumed tokens: 1061683200.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-01T23:23:03 | step: 129700 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 4.620603067451157e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.19 | consumed tokens: 1062502400.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-01T23:23:19 | step: 129800 | train samples/s: 100.4 | train mfu (16-bit): -1.0 | lr mean: 4.620000618160702e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.58 | consumed tokens: 1063321600.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-01T23:23:36 | step: 129900 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.619397805072367e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.47 | consumed tokens: 1064140800.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-01T23:23:52 | step: 130000 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.6187946281861514e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.94 | consumed tokens: 1064960000.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-01T23:24:10 | step: 130100 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.618191087502055e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.31 | consumed tokens: 1065779200.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:24:26 | step: 130200 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.617586819222197e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.95 | consumed tokens: 1066598400.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T23:24:42 | step: 130300 | train samples/s: 100.2 | train mfu (16-bit): -1.0 | lr mean: 4.616982187144458e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.11 | consumed tokens: 1067417600.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T23:24:59 | step: 130400 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 4.616377191268839e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.97 | consumed tokens: 1068236800.0 | grad norm avg: 0.69 | grad norm last: 0.76 | 
2026-01-01T23:25:15 | step: 130500 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.615771831595339e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.84 | consumed tokens: 1069056000.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-01T23:25:32 | step: 130600 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.615166108123958e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.09 | consumed tokens: 1069875200.0 | grad norm avg: 0.71 | grad norm last: 0.76 | 
2026-01-01T23:25:49 | step: 130700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.614559657056816e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.08 | consumed tokens: 1070694400.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T23:26:05 | step: 130800 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.613953205989674e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.02 | consumed tokens: 1071513600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:26:21 | step: 130900 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.61334602732677e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.0 | consumed tokens: 1072332800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:26:38 | step: 131000 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.612738121068105e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.45 | consumed tokens: 1073152000.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-01T23:26:54 | step: 131100 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.61213021480944e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.72 | consumed tokens: 1073971200.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-01T23:27:11 | step: 131200 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.6115215809550136e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.7 | consumed tokens: 1074790400.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T23:27:27 | step: 131300 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.610912947100587e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.3 | consumed tokens: 1075609600.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T23:27:44 | step: 131400 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.610303585650399e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.83 | consumed tokens: 1076428800.0 | grad norm avg: 0.69 | grad norm last: 0.75 | 
2026-01-01T23:28:00 | step: 131500 | train samples/s: 100.5 | train mfu (16-bit): -1.0 | lr mean: 4.609693860402331e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.23 | consumed tokens: 1077248000.0 | grad norm avg: 0.7 | grad norm last: 0.74 | 
2026-01-01T23:28:16 | step: 131600 | train samples/s: 100.5 | train mfu (16-bit): -1.0 | lr mean: 4.609083407558501e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.66 | consumed tokens: 1078067200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T23:28:32 | step: 131700 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.608472954714671e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.77 | consumed tokens: 1078886400.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T23:28:49 | step: 131800 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 4.6078617742750794e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.98 | consumed tokens: 1079705600.0 | grad norm avg: 0.7 | grad norm last: 0.8 | 
2026-01-01T23:29:05 | step: 131900 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.607250230037607e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.62 | consumed tokens: 1080524800.0 | grad norm avg: 0.7 | grad norm last: 0.65 | 
2026-01-01T23:29:22 | step: 132000 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 4.6066383220022544e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.39 | consumed tokens: 1081344000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:29:38 | step: 132100 | train samples/s: 100.5 | train mfu (16-bit): -1.0 | lr mean: 4.606026050169021e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.97 | consumed tokens: 1082163200.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T23:29:55 | step: 132200 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.605413050740026e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.14 | consumed tokens: 1082982400.0 | grad norm avg: 0.69 | grad norm last: 0.81 | 
2026-01-01T23:30:11 | step: 132300 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.60479968751315e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.19 | train loss last: 3.23 | consumed tokens: 1083801600.0 | grad norm avg: 0.7 | grad norm last: 0.77 | 
2026-01-01T23:30:27 | step: 132400 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.604185960488394e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.59 | consumed tokens: 1084620800.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T23:30:44 | step: 132500 | train samples/s: 100.3 | train mfu (16-bit): -1.0 | lr mean: 4.603571869665757e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.2 | consumed tokens: 1085440000.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T23:31:00 | step: 132600 | train samples/s: 100.4 | train mfu (16-bit): -1.0 | lr mean: 4.602957415045239e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.86 | consumed tokens: 1086259200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:31:16 | step: 132700 | train samples/s: 101.0 | train mfu (16-bit): -1.0 | lr mean: 4.60234223282896e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.44 | consumed tokens: 1087078400.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T23:31:32 | step: 132800 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.6017270506126806e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.39 | consumed tokens: 1087897600.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T23:31:49 | step: 132900 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.60111114080064e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.0 | consumed tokens: 1088716800.0 | grad norm avg: 0.69 | grad norm last: 0.77 | 
2026-01-01T23:32:05 | step: 133000 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.6004948671907187e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.38 | consumed tokens: 1089536000.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-01T23:32:22 | step: 133100 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.599877865985036e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.72 | consumed tokens: 1090355200.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-01T23:32:38 | step: 133200 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.599260864779353e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.56 | consumed tokens: 1091174400.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:32:55 | step: 133300 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.598643135977909e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.5 | consumed tokens: 1091993600.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-01T23:33:11 | step: 133400 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 4.598025043378584e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.92 | consumed tokens: 1092812800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T23:33:28 | step: 133500 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 4.5974065869813785e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.41 | consumed tokens: 1093632000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:33:44 | step: 133600 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.596787766786292e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.95 | consumed tokens: 1094451200.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-01T23:34:01 | step: 133700 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.5961682189954445e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.67 | consumed tokens: 1095270400.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:34:17 | step: 133800 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.595548671204597e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.72 | consumed tokens: 1096089600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:34:33 | step: 133900 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.5949283958179876e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.14 | consumed tokens: 1096908800.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T23:34:50 | step: 134000 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.594307756633498e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.2 | consumed tokens: 1097728000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:35:06 | step: 134100 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.593686753651127e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.12 | consumed tokens: 1098547200.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T23:35:23 | step: 134200 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 4.593065023072995e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.09 | consumed tokens: 1099366400.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T23:35:39 | step: 134300 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.592443292494863e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.38 | consumed tokens: 1100185600.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:35:56 | step: 134400 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.59182083432097e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.08 | consumed tokens: 1101004800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:36:12 | step: 134500 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.591198012349196e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.48 | consumed tokens: 1101824000.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T23:36:29 | step: 134600 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.590574826579541e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.45 | consumed tokens: 1102643200.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T23:36:45 | step: 134700 | train samples/s: 98.8 | train mfu (16-bit): -1.0 | lr mean: 4.589950913214125e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.45 | consumed tokens: 1103462400.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T23:37:02 | step: 134800 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 4.5893269998487085e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.23 | consumed tokens: 1104281600.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T23:37:18 | step: 134900 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.588702358887531e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.83 | consumed tokens: 1105100800.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T23:37:35 | step: 135000 | train samples/s: 100.1 | train mfu (16-bit): -1.0 | lr mean: 4.5880773541284725e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.55 | consumed tokens: 1105920000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T23:37:52 | step: 135100 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.5874519855715334e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.11 | consumed tokens: 1106739200.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-01T23:38:09 | step: 135200 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.586826253216714e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.06 | consumed tokens: 1107558400.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-01T23:38:25 | step: 135300 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.5861997932661325e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.62 | consumed tokens: 1108377600.0 | grad norm avg: 0.69 | grad norm last: 0.76 | 
2026-01-01T23:38:41 | step: 135400 | train samples/s: 100.1 | train mfu (16-bit): -1.0 | lr mean: 4.585573333315551e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.34 | consumed tokens: 1109196800.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-01T23:38:58 | step: 135500 | train samples/s: 100.1 | train mfu (16-bit): -1.0 | lr mean: 4.584946145769209e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.27 | consumed tokens: 1110016000.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-01T23:39:14 | step: 135600 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.5843185944249853e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.88 | consumed tokens: 1110835200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T23:39:30 | step: 135700 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 4.5836903154850006e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.64 | consumed tokens: 1111654400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T23:39:47 | step: 135800 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.583062036545016e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.5 | consumed tokens: 1112473600.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T23:40:04 | step: 135900 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 4.58243303000927e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.86 | consumed tokens: 1113292800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:40:20 | step: 136000 | train samples/s: 100.1 | train mfu (16-bit): -1.0 | lr mean: 4.5818040234735236e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.89 | consumed tokens: 1114112000.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T23:40:36 | step: 136100 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.581174289342016e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.47 | consumed tokens: 1114931200.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-01T23:40:53 | step: 136200 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.580544191412628e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.03 | consumed tokens: 1115750400.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-01T23:41:09 | step: 136300 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.579913365887478e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.48 | consumed tokens: 1116569600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:41:26 | step: 136400 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 4.579282540362328e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.05 | consumed tokens: 1117388800.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:41:42 | step: 136500 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 4.578650987241417e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.84 | consumed tokens: 1118208000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T23:41:59 | step: 136600 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 4.5780190703226253e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.14 | consumed tokens: 1119027200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T23:42:15 | step: 136700 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.577386789605953e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.86 | consumed tokens: 1119846400.0 | grad norm avg: 0.7 | grad norm last: 0.74 | 
2026-01-01T23:42:32 | step: 136800 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.5767541450913996e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.38 | consumed tokens: 1120665600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:42:48 | step: 136900 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 4.576120772981085e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.16 | consumed tokens: 1121484800.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-01T23:43:05 | step: 137000 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.57548740087077e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.73 | consumed tokens: 1122304000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T23:43:21 | step: 137100 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.574853301164694e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.08 | consumed tokens: 1123123200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:43:38 | step: 137200 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.574218837660737e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.84 | consumed tokens: 1123942400.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T23:43:54 | step: 137300 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.5735840103589e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.72 | consumed tokens: 1124761600.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T23:44:11 | step: 137400 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.5729488192591816e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.38 | consumed tokens: 1125580800.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-01T23:44:27 | step: 137500 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.572312900563702e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.67 | consumed tokens: 1126400000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:44:43 | step: 137600 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 4.5716769818682224e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.23 | consumed tokens: 1127219200.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T23:45:00 | step: 137700 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.571040335576981e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.03 | consumed tokens: 1128038400.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T23:45:16 | step: 137800 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.5704033254878595e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.94 | consumed tokens: 1128857600.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:45:33 | step: 137900 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.569765951600857e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.05 | consumed tokens: 1129676800.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T23:45:49 | step: 138000 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.569127850118093e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.14 | consumed tokens: 1130496000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:46:06 | step: 138100 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 4.568489748635329e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.38 | consumed tokens: 1131315200.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T23:46:22 | step: 138200 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 4.567850919556804e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 4.06 | consumed tokens: 1132134400.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T23:46:39 | step: 138300 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.567211726680398e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.03 | consumed tokens: 1132953600.0 | grad norm avg: 0.7 | grad norm last: 0.65 | 
2026-01-01T23:46:55 | step: 138400 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.566572170006111e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.95 | consumed tokens: 1133772800.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T23:47:12 | step: 138500 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 4.565932249533944e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.16 | consumed tokens: 1134592000.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:47:28 | step: 138600 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.565291601466015e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.55 | consumed tokens: 1135411200.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:47:44 | step: 138700 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.564650953398086e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.45 | consumed tokens: 1136230400.0 | grad norm avg: 0.72 | grad norm last: 0.7 | 
2026-01-01T23:48:01 | step: 138800 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.564009577734396e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.91 | consumed tokens: 1137049600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:48:17 | step: 138900 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.563367838272825e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.44 | consumed tokens: 1137868800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:48:34 | step: 139000 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.562725735013373e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.02 | consumed tokens: 1138688000.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:48:50 | step: 139100 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.56208290415816e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.52 | consumed tokens: 1139507200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T23:49:06 | step: 139200 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.561440073302947e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.0 | consumed tokens: 1140326400.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T23:49:23 | step: 139300 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 4.5607965148519725e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.17 | consumed tokens: 1141145600.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:49:39 | step: 139400 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.560152956400998e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.94 | consumed tokens: 1141964800.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T23:49:56 | step: 139500 | train samples/s: 100.1 | train mfu (16-bit): -1.0 | lr mean: 4.559508670354262e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.62 | consumed tokens: 1142784000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:50:12 | step: 139600 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 4.5588636567117646e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.2 | consumed tokens: 1143603200.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-01T23:50:29 | step: 139700 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.558218643069267e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.58 | consumed tokens: 1144422400.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T23:50:45 | step: 139800 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.557573265628889e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.33 | consumed tokens: 1145241600.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:51:02 | step: 139900 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.55692716059275e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.78 | consumed tokens: 1146060800.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T23:51:18 | step: 140000 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.5562806917587295e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.02 | consumed tokens: 1146880000.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T23:51:36 | step: 140100 | train samples/s: 100.1 | train mfu (16-bit): -1.0 | lr mean: 4.5556338591268286e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.11 | consumed tokens: 1147699200.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T23:51:52 | step: 140200 | train samples/s: 100.6 | train mfu (16-bit): -1.0 | lr mean: 4.554986662697047e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.64 | consumed tokens: 1148518400.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T23:52:08 | step: 140300 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.554339102469385e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.81 | consumed tokens: 1149337600.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-01T23:52:25 | step: 140400 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 4.553690814645961e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.61 | consumed tokens: 1150156800.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T23:52:41 | step: 140500 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.553042526822537e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.86 | consumed tokens: 1150976000.0 | grad norm avg: 0.69 | grad norm last: 0.76 | 
2026-01-01T23:52:57 | step: 140600 | train samples/s: 100.1 | train mfu (16-bit): -1.0 | lr mean: 4.552393511403352e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.08 | consumed tokens: 1151795200.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-01T23:53:14 | step: 140700 | train samples/s: 100.1 | train mfu (16-bit): -1.0 | lr mean: 4.551744132186286e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.84 | consumed tokens: 1152614400.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:53:30 | step: 140800 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.5510943891713396e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.97 | consumed tokens: 1153433600.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-01T23:53:46 | step: 140900 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 4.5504439185606316e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.34 | consumed tokens: 1154252800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:54:03 | step: 141000 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 4.5497934479499236e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.0 | consumed tokens: 1155072000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T23:54:20 | step: 141100 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.549142249743454e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.05 | consumed tokens: 1155891200.0 | grad norm avg: 0.69 | grad norm last: 0.74 | 
2026-01-01T23:54:36 | step: 141200 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.548490687739104e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.39 | consumed tokens: 1156710400.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:54:52 | step: 141300 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.547838761936873e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.77 | consumed tokens: 1157529600.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T23:55:09 | step: 141400 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.5471864723367617e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.7 | consumed tokens: 1158348800.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T23:55:25 | step: 141500 | train samples/s: 100.3 | train mfu (16-bit): -1.0 | lr mean: 4.5465338189387694e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.09 | consumed tokens: 1159168000.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:55:41 | step: 141600 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.545880437945016e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 3.14 | consumed tokens: 1159987200.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T23:55:58 | step: 141700 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.545227056951262e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.5 | consumed tokens: 1160806400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:56:14 | step: 141800 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.544572948361747e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.83 | consumed tokens: 1161625600.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-01T23:56:30 | step: 141900 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.543918475974351e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.14 | consumed tokens: 1162444800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T23:56:47 | step: 142000 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.5432636397890747e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.11 | consumed tokens: 1163264000.0 | grad norm avg: 0.69 | grad norm last: 0.79 | 
2026-01-01T23:57:03 | step: 142100 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.542608076008037e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.16 | consumed tokens: 1164083200.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:57:20 | step: 142200 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 4.541952512226999e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.03 | consumed tokens: 1164902400.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-01T23:57:36 | step: 142300 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.5412962208501995e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.42 | consumed tokens: 1165721600.0 | grad norm avg: 0.69 | grad norm last: 0.75 | 
2026-01-01T23:57:53 | step: 142400 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 4.5406399294734e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.97 | consumed tokens: 1166540800.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T23:58:09 | step: 142500 | train samples/s: 100.5 | train mfu (16-bit): -1.0 | lr mean: 4.5399829105008394e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.12 | consumed tokens: 1167360000.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:58:25 | step: 142600 | train samples/s: 101.0 | train mfu (16-bit): -1.0 | lr mean: 4.539325163932517e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.44 | consumed tokens: 1168179200.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-01T23:58:41 | step: 142700 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.538667417364195e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.02 | consumed tokens: 1168998400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:58:58 | step: 142800 | train samples/s: 100.2 | train mfu (16-bit): -1.0 | lr mean: 4.538009306997992e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.89 | consumed tokens: 1169817600.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-01T23:59:14 | step: 142900 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.537350469036028e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.73 | consumed tokens: 1170636800.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T23:59:30 | step: 143000 | train samples/s: 100.9 | train mfu (16-bit): -1.0 | lr mean: 4.5366916310740635e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.16 | consumed tokens: 1171456000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T23:59:46 | step: 143100 | train samples/s: 100.6 | train mfu (16-bit): -1.0 | lr mean: 4.536032065516338e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.3 | consumed tokens: 1172275200.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T00:00:03 | step: 143200 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 4.535372136160731e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.05 | consumed tokens: 1173094400.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:00:19 | step: 143300 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.5347114792093635e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.06 | consumed tokens: 1173913600.0 | grad norm avg: 0.69 | grad norm last: 0.74 | 
2026-01-02T00:00:36 | step: 143400 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 4.5340508222579956e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.5 | consumed tokens: 1174732800.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T00:00:52 | step: 143500 | train samples/s: 98.8 | train mfu (16-bit): -1.0 | lr mean: 4.533389801508747e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.69 | consumed tokens: 1175552000.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-02T00:01:09 | step: 143600 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 4.532728053163737e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.22 | consumed tokens: 1176371200.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-02T00:01:25 | step: 143700 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 4.5320659410208464e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.2 | consumed tokens: 1177190400.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:01:42 | step: 143800 | train samples/s: 100.2 | train mfu (16-bit): -1.0 | lr mean: 4.531403465080075e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.2 | consumed tokens: 1178009600.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-02T00:01:58 | step: 143900 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 4.530740625341423e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.3 | consumed tokens: 1178828800.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T00:02:15 | step: 144000 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.53007742180489e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.97 | consumed tokens: 1179648000.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-02T00:02:31 | step: 144100 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.529413490672596e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.34 | consumed tokens: 1180467200.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:02:47 | step: 144200 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 4.5287495595403016e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.34 | consumed tokens: 1181286400.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-02T00:03:04 | step: 144300 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.528084900812246e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.5 | consumed tokens: 1182105600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:03:20 | step: 144400 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.5274198782863095e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.25 | consumed tokens: 1182924800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:03:37 | step: 144500 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 4.5267544919624925e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.14 | consumed tokens: 1183744000.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T00:03:53 | step: 144600 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 4.526088741840795e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.58 | consumed tokens: 1184563200.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:04:10 | step: 144700 | train samples/s: 98.8 | train mfu (16-bit): -1.0 | lr mean: 4.5254222641233355e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.55 | consumed tokens: 1185382400.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T00:04:26 | step: 144800 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.524755786405876e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.45 | consumed tokens: 1186201600.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-02T00:04:43 | step: 144900 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 4.5240885810926557e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.75 | consumed tokens: 1187020800.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:04:59 | step: 145000 | train samples/s: 97.4 | train mfu (16-bit): -1.0 | lr mean: 4.523421011981554e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.81 | consumed tokens: 1187840000.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T00:05:17 | step: 145100 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 4.522753079072572e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.58 | consumed tokens: 1188659200.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T00:05:34 | step: 145200 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.5220847823657095e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.09 | consumed tokens: 1189478400.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T00:05:50 | step: 145300 | train samples/s: 100.6 | train mfu (16-bit): -1.0 | lr mean: 4.521416121860966e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.62 | consumed tokens: 1190297600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:06:06 | step: 145400 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.520747097558342e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.84 | consumed tokens: 1191116800.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:06:23 | step: 145500 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.520077345659956e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.66 | consumed tokens: 1191936000.0 | grad norm avg: 0.7 | grad norm last: 0.74 | 
2026-01-02T00:06:39 | step: 145600 | train samples/s: 100.6 | train mfu (16-bit): -1.0 | lr mean: 4.51940722996369e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.05 | consumed tokens: 1192755200.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-02T00:06:55 | step: 145700 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.518736750469543e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.97 | consumed tokens: 1193574400.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:07:12 | step: 145800 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.518065907177515e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.16 | consumed tokens: 1194393600.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:07:28 | step: 145900 | train samples/s: 100.8 | train mfu (16-bit): -1.0 | lr mean: 4.517394700087607e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.22 | consumed tokens: 1195212800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:07:44 | step: 146000 | train samples/s: 100.2 | train mfu (16-bit): -1.0 | lr mean: 4.516723129199818e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.83 | consumed tokens: 1196032000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:08:01 | step: 146100 | train samples/s: 100.3 | train mfu (16-bit): -1.0 | lr mean: 4.516051194514148e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.69 | consumed tokens: 1196851200.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-02T00:08:17 | step: 146200 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.515378532232717e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.73 | consumed tokens: 1197670400.0 | grad norm avg: 0.7 | grad norm last: 0.65 | 
2026-01-02T00:08:33 | step: 146300 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 4.514705506153405e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.97 | consumed tokens: 1198489600.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:08:50 | step: 146400 | train samples/s: 101.4 | train mfu (16-bit): -1.0 | lr mean: 4.514032116276212e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.88 | consumed tokens: 1199308800.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:09:06 | step: 146500 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.5133583626011387e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.64 | consumed tokens: 1200128000.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T00:09:22 | step: 146600 | train samples/s: 100.8 | train mfu (16-bit): -1.0 | lr mean: 4.5126842451281846e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.3 | consumed tokens: 1200947200.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T00:09:38 | step: 146700 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.51200976385735e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.55 | consumed tokens: 1201766400.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:09:55 | step: 146800 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.5113345549907535e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.03 | consumed tokens: 1202585600.0 | grad norm avg: 0.69 | grad norm last: 0.74 | 
2026-01-02T00:10:11 | step: 146900 | train samples/s: 101.3 | train mfu (16-bit): -1.0 | lr mean: 4.510659346124157e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.06 | consumed tokens: 1203404800.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:10:27 | step: 147000 | train samples/s: 100.7 | train mfu (16-bit): -1.0 | lr mean: 4.5099834096618e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.61 | consumed tokens: 1204224000.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-02T00:10:43 | step: 147100 | train samples/s: 101.0 | train mfu (16-bit): -1.0 | lr mean: 4.509307109401561e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.03 | consumed tokens: 1205043200.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:11:00 | step: 147200 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 4.508630445343442e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.17 | train loss last: 2.3 | consumed tokens: 1205862400.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:11:16 | step: 147300 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.5079534174874425e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.28 | consumed tokens: 1206681600.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:11:32 | step: 147400 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.507276025833562e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.88 | consumed tokens: 1207500800.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:11:49 | step: 147500 | train samples/s: 100.5 | train mfu (16-bit): -1.0 | lr mean: 4.50659790658392e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.75 | consumed tokens: 1208320000.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T00:12:05 | step: 147600 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 4.505919787334278e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 2.72 | consumed tokens: 1209139200.0 | grad norm avg: 0.69 | grad norm last: 0.74 | 
2026-01-02T00:12:21 | step: 147700 | train samples/s: 100.2 | train mfu (16-bit): -1.0 | lr mean: 4.505240940488875e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.31 | consumed tokens: 1209958400.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T00:12:38 | step: 147800 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.504561729845591e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.73 | consumed tokens: 1210777600.0 | grad norm avg: 0.69 | grad norm last: 0.74 | 
2026-01-02T00:12:54 | step: 147900 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.503882155404426e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.11 | consumed tokens: 1211596800.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-02T00:13:11 | step: 148000 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.503202217165381e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.95 | consumed tokens: 1212416000.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T00:13:27 | step: 148100 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.5025219151284546e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.02 | consumed tokens: 1213235200.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:13:43 | step: 148200 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 4.501840885495767e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.02 | consumed tokens: 1214054400.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-02T00:14:00 | step: 148300 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 4.5011598558630794e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.12 | consumed tokens: 1214873600.0 | grad norm avg: 0.69 | grad norm last: 0.76 | 
2026-01-02T00:14:16 | step: 148400 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 4.5004780986346304e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.61 | consumed tokens: 1215692800.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T00:14:33 | step: 148500 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.499795977608301e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.22 | consumed tokens: 1216512000.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:14:49 | step: 148600 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.4991134927840903e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.08 | consumed tokens: 1217331200.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:15:06 | step: 148700 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.498430644161999e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.81 | consumed tokens: 1218150400.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T00:15:22 | step: 148800 | train samples/s: 100.6 | train mfu (16-bit): -1.0 | lr mean: 4.4977474317420274e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.81 | consumed tokens: 1218969600.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T00:15:38 | step: 148900 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 4.497063491726294e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.48 | consumed tokens: 1219788800.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-02T00:15:55 | step: 149000 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.496379551710561e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.45 | consumed tokens: 1220608000.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T00:16:11 | step: 149100 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.495694884099066e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.86 | consumed tokens: 1221427200.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T00:16:28 | step: 149200 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.495009852689691e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.17 | consumed tokens: 1222246400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:16:44 | step: 149300 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.494324457482435e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.77 | consumed tokens: 1223065600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:17:00 | step: 149400 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.493638698477298e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.23 | consumed tokens: 1223884800.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T00:17:17 | step: 149500 | train samples/s: 100.2 | train mfu (16-bit): -1.0 | lr mean: 4.4929525756742805e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.09 | consumed tokens: 1224704000.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T00:17:33 | step: 149600 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.492266089073382e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.14 | consumed tokens: 1225523200.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T00:17:49 | step: 149700 | train samples/s: 100.2 | train mfu (16-bit): -1.0 | lr mean: 4.491578874876723e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.36 | consumed tokens: 1226342400.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T00:18:06 | step: 149800 | train samples/s: 100.2 | train mfu (16-bit): -1.0 | lr mean: 4.490891660680063e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.47 | consumed tokens: 1227161600.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-02T00:18:22 | step: 149900 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.490203718887642e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.19 | consumed tokens: 1227980800.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:18:38 | step: 150000 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.48951541329734e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.23 | consumed tokens: 1228800000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:18:56 | step: 150100 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.488826743909158e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.94 | consumed tokens: 1229619200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:19:13 | step: 150200 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 4.4881377107230946e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 4.06 | consumed tokens: 1230438400.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T00:19:29 | step: 150300 | train samples/s: 101.1 | train mfu (16-bit): -1.0 | lr mean: 4.487448313739151e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.62 | consumed tokens: 1231257600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:19:45 | step: 150400 | train samples/s: 100.4 | train mfu (16-bit): -1.0 | lr mean: 4.486758552957326e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.12 | consumed tokens: 1232076800.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:20:01 | step: 150500 | train samples/s: 100.2 | train mfu (16-bit): -1.0 | lr mean: 4.48606806457974e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.77 | consumed tokens: 1232896000.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T00:20:18 | step: 150600 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.4853772124042735e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.33 | consumed tokens: 1233715200.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-02T00:20:34 | step: 150700 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.484686360228807e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 4.09 | consumed tokens: 1234534400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:20:50 | step: 150800 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.4839947804575786e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.09 | consumed tokens: 1235353600.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T00:21:07 | step: 150900 | train samples/s: 100.3 | train mfu (16-bit): -1.0 | lr mean: 4.48330283688847e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.05 | consumed tokens: 1236172800.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-02T00:21:23 | step: 151000 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.48261052952148e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.06 | consumed tokens: 1236992000.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T00:21:39 | step: 151100 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 4.481917494558729e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.23 | consumed tokens: 1237811200.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:21:56 | step: 151200 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 4.481224459595978e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.23 | consumed tokens: 1238630400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:22:13 | step: 151300 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 4.480530697037466e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.58 | consumed tokens: 1239449600.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:22:29 | step: 151400 | train samples/s: 100.2 | train mfu (16-bit): -1.0 | lr mean: 4.4798369344789535e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.94 | consumed tokens: 1240268800.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:22:45 | step: 151500 | train samples/s: 100.4 | train mfu (16-bit): -1.0 | lr mean: 4.47914244432468e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.22 | consumed tokens: 1241088000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:23:02 | step: 151600 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 4.478447590372525e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.67 | consumed tokens: 1241907200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:23:18 | step: 151700 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.47775237262249e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.86 | consumed tokens: 1242726400.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:23:35 | step: 151800 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.477056791074574e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.2 | consumed tokens: 1243545600.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:23:51 | step: 151900 | train samples/s: 100.8 | train mfu (16-bit): -1.0 | lr mean: 4.4763608457287773e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.22 | consumed tokens: 1244364800.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-02T00:24:07 | step: 152000 | train samples/s: 101.1 | train mfu (16-bit): -1.0 | lr mean: 4.475664172787219e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.92 | consumed tokens: 1245184000.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T00:24:23 | step: 152100 | train samples/s: 100.9 | train mfu (16-bit): -1.0 | lr mean: 4.474967499845661e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.92 | consumed tokens: 1246003200.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:24:39 | step: 152200 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.474270099308342e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.22 | consumed tokens: 1246822400.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:24:56 | step: 152300 | train samples/s: 100.9 | train mfu (16-bit): -1.0 | lr mean: 4.4735723349731416e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.12 | consumed tokens: 1247641600.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T00:25:12 | step: 152400 | train samples/s: 100.7 | train mfu (16-bit): -1.0 | lr mean: 4.4728745706379414e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.34 | consumed tokens: 1248460800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:25:28 | step: 152500 | train samples/s: 100.8 | train mfu (16-bit): -1.0 | lr mean: 4.47217607870698e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.92 | consumed tokens: 1249280000.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T00:25:44 | step: 152600 | train samples/s: 100.5 | train mfu (16-bit): -1.0 | lr mean: 4.471476859180257e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.18 | train loss last: 3.28 | consumed tokens: 1250099200.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-02T00:26:01 | step: 152700 | train samples/s: 100.3 | train mfu (16-bit): -1.0 | lr mean: 4.470777639653534e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.94 | consumed tokens: 1250918400.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:26:17 | step: 152800 | train samples/s: 100.6 | train mfu (16-bit): -1.0 | lr mean: 4.47007805632893e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.06 | consumed tokens: 1251737600.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:26:33 | step: 152900 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 4.469377745408565e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.7 | consumed tokens: 1252556800.0 | grad norm avg: 0.7 | grad norm last: 0.64 | 
2026-01-02T00:26:50 | step: 153000 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.4686774344881997e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.8 | consumed tokens: 1253376000.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:27:06 | step: 153100 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.467976395972073e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.52 | consumed tokens: 1254195200.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:27:23 | step: 153200 | train samples/s: 100.2 | train mfu (16-bit): -1.0 | lr mean: 4.467274993658066e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.25 | consumed tokens: 1255014400.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T00:27:39 | step: 153300 | train samples/s: 100.3 | train mfu (16-bit): -1.0 | lr mean: 4.466573227546178e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.28 | consumed tokens: 1255833600.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:27:55 | step: 153400 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.465871097636409e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.98 | consumed tokens: 1256652800.0 | grad norm avg: 0.69 | grad norm last: 0.63 | 
2026-01-02T00:28:12 | step: 153500 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.46516860392876e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.06 | consumed tokens: 1257472000.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-02T00:28:28 | step: 153600 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 4.4644657464232296e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.77 | consumed tokens: 1258291200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:28:45 | step: 153700 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.463762161321938e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.3 | consumed tokens: 1259110400.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:29:01 | step: 153800 | train samples/s: 100.4 | train mfu (16-bit): -1.0 | lr mean: 4.4630585762206465e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.22 | consumed tokens: 1259929600.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:29:17 | step: 153900 | train samples/s: 100.4 | train mfu (16-bit): -1.0 | lr mean: 4.4623542635235935e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.88 | consumed tokens: 1260748800.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:29:34 | step: 154000 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.46164958702866e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.42 | consumed tokens: 1261568000.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T00:29:50 | step: 154100 | train samples/s: 100.1 | train mfu (16-bit): -1.0 | lr mean: 4.4609445467358455e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.2 | consumed tokens: 1262387200.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:30:07 | step: 154200 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 4.4602391426451504e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.55 | consumed tokens: 1263206400.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-02T00:30:23 | step: 154300 | train samples/s: 100.2 | train mfu (16-bit): -1.0 | lr mean: 4.4595333747565746e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.91 | consumed tokens: 1264025600.0 | grad norm avg: 0.68 | grad norm last: 0.73 | 
2026-01-02T00:30:39 | step: 154400 | train samples/s: 100.5 | train mfu (16-bit): -1.0 | lr mean: 4.458827243070118e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.39 | consumed tokens: 1264844800.0 | grad norm avg: 0.69 | grad norm last: 0.75 | 
2026-01-02T00:30:55 | step: 154500 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.458120747585781e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.28 | consumed tokens: 1265664000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:31:12 | step: 154600 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 4.457413524505682e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.11 | consumed tokens: 1266483200.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:31:29 | step: 154700 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 4.4567063014255837e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 2.97 | consumed tokens: 1267302400.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T00:31:45 | step: 154800 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 4.4559983507497236e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.25 | consumed tokens: 1268121600.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T00:32:02 | step: 154900 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.455290036275983e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.2 | consumed tokens: 1268940800.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T00:32:18 | step: 155000 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 4.4545813580043614e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.92 | consumed tokens: 1269760000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:32:36 | step: 155100 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.453872315934859e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.05 | consumed tokens: 1270579200.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:32:52 | step: 155200 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.453162910067476e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.88 | consumed tokens: 1271398400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:33:09 | step: 155300 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.452453140402213e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.73 | consumed tokens: 1272217600.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:33:25 | step: 155400 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.4517430069390684e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.81 | consumed tokens: 1273036800.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T00:33:42 | step: 155500 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 4.451032145880163e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.55 | consumed tokens: 1273856000.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T00:33:58 | step: 155600 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.450321284821257e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.02 | consumed tokens: 1274675200.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T00:34:15 | step: 155700 | train samples/s: 100.3 | train mfu (16-bit): -1.0 | lr mean: 4.44960969616659e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.98 | consumed tokens: 1275494400.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:34:31 | step: 155800 | train samples/s: 100.1 | train mfu (16-bit): -1.0 | lr mean: 4.448897743714042e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.91 | consumed tokens: 1276313600.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-02T00:34:47 | step: 155900 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.4481854274636135e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.09 | consumed tokens: 1277132800.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T00:35:03 | step: 156000 | train samples/s: 100.5 | train mfu (16-bit): -1.0 | lr mean: 4.447472747415304e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.48 | consumed tokens: 1277952000.0 | grad norm avg: 0.69 | grad norm last: 0.74 | 
2026-01-02T00:35:20 | step: 156100 | train samples/s: 101.4 | train mfu (16-bit): -1.0 | lr mean: 4.446759703569114e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.06 | consumed tokens: 1278771200.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-02T00:35:36 | step: 156200 | train samples/s: 101.3 | train mfu (16-bit): -1.0 | lr mean: 4.4460462959250435e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.3 | consumed tokens: 1279590400.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:35:52 | step: 156300 | train samples/s: 100.3 | train mfu (16-bit): -1.0 | lr mean: 4.445332524483092e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.83 | consumed tokens: 1280409600.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T00:36:09 | step: 156400 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 4.444618025445379e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.3 | consumed tokens: 1281228800.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:36:25 | step: 156500 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 4.4439035264076665e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.91 | consumed tokens: 1282048000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:36:41 | step: 156600 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.443188299774192e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.77 | consumed tokens: 1282867200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T00:36:58 | step: 156700 | train samples/s: 100.8 | train mfu (16-bit): -1.0 | lr mean: 4.442472709342837e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.41 | consumed tokens: 1283686400.0 | grad norm avg: 0.7 | grad norm last: 0.76 | 
2026-01-02T00:37:14 | step: 156800 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 4.441756755113602e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.7 | consumed tokens: 1284505600.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:37:31 | step: 156900 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 4.441040437086485e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.16 | consumed tokens: 1285324800.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:37:47 | step: 157000 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.440323755261488e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.16 | train loss last: 3.59 | consumed tokens: 1286144000.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T00:38:03 | step: 157100 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.4396067096386105e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.89 | consumed tokens: 1286963200.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T00:38:19 | step: 157200 | train samples/s: 100.4 | train mfu (16-bit): -1.0 | lr mean: 4.438889300217852e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.98 | consumed tokens: 1287782400.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-02T00:38:36 | step: 157300 | train samples/s: 100.3 | train mfu (16-bit): -1.0 | lr mean: 4.438171526999213e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.44 | consumed tokens: 1288601600.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:38:52 | step: 157400 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.437453026184812e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.53 | consumed tokens: 1289420800.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T00:39:09 | step: 157500 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.4367345253704116e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 4.06 | consumed tokens: 1290240000.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:39:25 | step: 157600 | train samples/s: 98.8 | train mfu (16-bit): -1.0 | lr mean: 4.4360152969602495e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.34 | consumed tokens: 1291059200.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T00:39:41 | step: 157700 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.435295704752207e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.58 | consumed tokens: 1291878400.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:39:58 | step: 157800 | train samples/s: 100.4 | train mfu (16-bit): -1.0 | lr mean: 4.4345757487462834e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 2.59 | consumed tokens: 1292697600.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:40:14 | step: 157900 | train samples/s: 100.3 | train mfu (16-bit): -1.0 | lr mean: 4.433855428942479e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 2.88 | consumed tokens: 1293516800.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T00:40:30 | step: 158000 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.433134745340794e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.58 | consumed tokens: 1294336000.0 | grad norm avg: 0.68 | grad norm last: 0.66 | 
2026-01-02T00:40:47 | step: 158100 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 4.432413697941229e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.69 | consumed tokens: 1295155200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:41:03 | step: 158200 | train samples/s: 100.1 | train mfu (16-bit): -1.0 | lr mean: 4.4316922867437825e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.91 | consumed tokens: 1295974400.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T00:41:19 | step: 158300 | train samples/s: 100.5 | train mfu (16-bit): -1.0 | lr mean: 4.4309705117484555e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.42 | consumed tokens: 1296793600.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T00:41:36 | step: 158400 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.430248009157367e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.12 | consumed tokens: 1297612800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T00:41:52 | step: 158500 | train samples/s: 100.9 | train mfu (16-bit): -1.0 | lr mean: 4.4295255065662786e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.52 | consumed tokens: 1298432000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:42:08 | step: 158600 | train samples/s: 100.3 | train mfu (16-bit): -1.0 | lr mean: 4.428802276379429e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.27 | consumed tokens: 1299251200.0 | grad norm avg: 0.7 | grad norm last: 0.64 | 
2026-01-02T00:42:25 | step: 158700 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.428078682394698e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.61 | consumed tokens: 1300070400.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:42:41 | step: 158800 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 4.427354724612087e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.41 | consumed tokens: 1300889600.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T00:42:58 | step: 158900 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 4.426630403031595e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.27 | consumed tokens: 1301708800.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:43:14 | step: 159000 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.4259057176532224e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.88 | consumed tokens: 1302528000.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T00:43:31 | step: 159100 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 4.425180668476969e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.14 | consumed tokens: 1303347200.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T00:43:47 | step: 159200 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 4.424455255502835e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.8 | consumed tokens: 1304166400.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:44:04 | step: 159300 | train samples/s: 98.8 | train mfu (16-bit): -1.0 | lr mean: 4.42372947873082e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.12 | consumed tokens: 1304985600.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T00:44:20 | step: 159400 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 4.423002974363044e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.53 | consumed tokens: 1305804800.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:44:37 | step: 159500 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.422276469995268e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.58 | consumed tokens: 1306624000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:44:53 | step: 159600 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.42154923803173e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.0 | consumed tokens: 1307443200.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:45:10 | step: 159700 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.4208220060681924e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.02 | consumed tokens: 1308262400.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T00:45:26 | step: 159800 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.4200940465088934e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.7 | consumed tokens: 1309081600.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T00:45:43 | step: 159900 | train samples/s: 98.8 | train mfu (16-bit): -1.0 | lr mean: 4.4193657231517136e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.59 | consumed tokens: 1309900800.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:45:59 | step: 160000 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 4.418637035996653e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.55 | consumed tokens: 1310720000.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T00:46:17 | step: 160100 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 4.417907985043712e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.2 | consumed tokens: 1311539200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:46:33 | step: 160200 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.41717857029289e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.61 | consumed tokens: 1312358400.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:46:50 | step: 160300 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 4.4164487917441875e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.55 | consumed tokens: 1313177600.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:47:06 | step: 160400 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.4157182855997235e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.58 | consumed tokens: 1313996800.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-02T00:47:23 | step: 160500 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 4.4149877794552594e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.3 | consumed tokens: 1314816000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:47:40 | step: 160600 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 4.414256545715034e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.48 | consumed tokens: 1315635200.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T00:47:56 | step: 160700 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.4135253119748086e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.56 | consumed tokens: 1316454400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:48:13 | step: 160800 | train samples/s: 98.8 | train mfu (16-bit): -1.0 | lr mean: 4.412793350638822e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.19 | consumed tokens: 1317273600.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-02T00:48:29 | step: 160900 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.412061025504954e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.14 | consumed tokens: 1318092800.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T00:48:46 | step: 161000 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 4.4113287003710866e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.66 | consumed tokens: 1318912000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:49:02 | step: 161100 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 4.4105956476414576e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.52 | consumed tokens: 1319731200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:49:19 | step: 161200 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 4.409862231113948e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 1.69 | consumed tokens: 1320550400.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:49:35 | step: 161300 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 4.4091284507885575e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.91 | consumed tokens: 1321369600.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:49:52 | step: 161400 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 4.408393942867406e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.89 | consumed tokens: 1322188800.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-02T00:50:08 | step: 161500 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.407659434946254e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.92 | consumed tokens: 1323008000.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-02T00:50:25 | step: 161600 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.4069245632272214e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.73 | consumed tokens: 1323827200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:50:41 | step: 161700 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 4.4061889639124274e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.17 | consumed tokens: 1324646400.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:50:58 | step: 161800 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 4.4054533645976335e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.11 | consumed tokens: 1325465600.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:51:14 | step: 161900 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 4.404717037687078e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.05 | consumed tokens: 1326284800.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T00:51:31 | step: 162000 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 4.403980710776523e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.27 | consumed tokens: 1327104000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:51:47 | step: 162100 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.403243656270206e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.95 | consumed tokens: 1327923200.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T00:52:04 | step: 162200 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 4.4025062379660085e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.78 | consumed tokens: 1328742400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:52:20 | step: 162300 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 4.40176845586393e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.39 | consumed tokens: 1329561600.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-02T00:52:37 | step: 162400 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 4.4010303099639714e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.81 | consumed tokens: 1330380800.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-02T00:52:53 | step: 162500 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 4.400291800266132e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.39 | consumed tokens: 1331200000.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-02T00:53:10 | step: 162600 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.3995529267704114e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.64 | consumed tokens: 1332019200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T00:53:26 | step: 162700 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.3988136894768104e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.05 | consumed tokens: 1332838400.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T00:53:43 | step: 162800 | train samples/s: 98.8 | train mfu (16-bit): -1.0 | lr mean: 4.398073724587448e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.81 | consumed tokens: 1333657600.0 | grad norm avg: 0.7 | grad norm last: 0.75 | 
2026-01-02T00:53:59 | step: 162900 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 4.3973337596980855e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.09 | consumed tokens: 1334476800.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-02T00:54:16 | step: 163000 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 4.3965930672129616e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.39 | consumed tokens: 1335296000.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T00:54:32 | step: 163100 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.395852374727838e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 2.69 | consumed tokens: 1336115200.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:54:49 | step: 163200 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.3951109546469525e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.47 | consumed tokens: 1336934400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:55:05 | step: 163300 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 4.3943691707681865e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.08 | consumed tokens: 1337753600.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T00:55:22 | step: 163400 | train samples/s: 100.6 | train mfu (16-bit): -1.0 | lr mean: 4.3936273868894204e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.31 | consumed tokens: 1338572800.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:55:38 | step: 163500 | train samples/s: 101.1 | train mfu (16-bit): -1.0 | lr mean: 4.392884875414893e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.3 | consumed tokens: 1339392000.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T00:55:54 | step: 163600 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.392142000142485e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.31 | consumed tokens: 1340211200.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T00:56:10 | step: 163700 | train samples/s: 100.3 | train mfu (16-bit): -1.0 | lr mean: 4.391398761072196e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.17 | consumed tokens: 1341030400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:56:27 | step: 163800 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.3906551582040265e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.31 | consumed tokens: 1341849600.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-02T00:56:43 | step: 163900 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 4.3899108277400956e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.59 | consumed tokens: 1342668800.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:57:00 | step: 164000 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.3891664972761646e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.73 | consumed tokens: 1343488000.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-02T00:57:16 | step: 164100 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.388421803014353e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.61 | consumed tokens: 1344307200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:57:33 | step: 164200 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.3876767449546605e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.8 | consumed tokens: 1345126400.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:57:49 | step: 164300 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.386930959299207e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.39 | consumed tokens: 1345945600.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:58:05 | step: 164400 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.386185173643753e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.73 | consumed tokens: 1346764800.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T00:58:22 | step: 164500 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 4.385438660392538e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.83 | consumed tokens: 1347584000.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-02T00:58:38 | step: 164600 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 4.384691783343442e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.88 | consumed tokens: 1348403200.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-02T00:58:55 | step: 164700 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.383944542496465e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.88 | consumed tokens: 1349222400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T00:59:11 | step: 164800 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.3831973016494885e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.97 | consumed tokens: 1350041600.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T00:59:28 | step: 164900 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.3824493332067505e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.84 | consumed tokens: 1350860800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T00:59:44 | step: 165000 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.381701000966132e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.69 | consumed tokens: 1351680000.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T01:00:02 | step: 165100 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.380952304927632e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 2.92 | consumed tokens: 1352499200.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-02T01:00:18 | step: 165200 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.380203245091252e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.39 | consumed tokens: 1353318400.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-02T01:00:35 | step: 165300 | train samples/s: 100.1 | train mfu (16-bit): -1.0 | lr mean: 4.3794534576591104e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.84 | consumed tokens: 1354137600.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-02T01:00:51 | step: 165400 | train samples/s: 100.6 | train mfu (16-bit): -1.0 | lr mean: 4.378703670226969e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.88 | consumed tokens: 1354956800.0 | grad norm avg: 0.69 | grad norm last: 0.63 | 
2026-01-02T01:01:07 | step: 165500 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.3779535189969465e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.81 | consumed tokens: 1355776000.0 | grad norm avg: 0.69 | grad norm last: 0.75 | 
2026-01-02T01:01:24 | step: 165600 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.3772030039690435e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.12 | consumed tokens: 1356595200.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T01:01:40 | step: 165700 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.376451761345379e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.69 | consumed tokens: 1357414400.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:01:56 | step: 165800 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 4.3757005187217146e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.89 | consumed tokens: 1358233600.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:02:13 | step: 165900 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 4.374948548502289e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.39 | consumed tokens: 1359052800.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T01:02:29 | step: 166000 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.374196214484982e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.19 | consumed tokens: 1359872000.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T01:02:45 | step: 166100 | train samples/s: 100.6 | train mfu (16-bit): -1.0 | lr mean: 4.3734438804676756e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 3.28 | consumed tokens: 1360691200.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T01:03:02 | step: 166200 | train samples/s: 100.3 | train mfu (16-bit): -1.0 | lr mean: 4.3726908188546076e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.39 | consumed tokens: 1361510400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:03:18 | step: 166300 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.371937393443659e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.16 | consumed tokens: 1362329600.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T01:03:34 | step: 166400 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.3711836042348295e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.91 | consumed tokens: 1363148800.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-02T01:03:51 | step: 166500 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.3704294512281194e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.55 | consumed tokens: 1363968000.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-02T01:04:07 | step: 166600 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.3696749344235286e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.81 | consumed tokens: 1364787200.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T01:04:23 | step: 166700 | train samples/s: 100.1 | train mfu (16-bit): -1.0 | lr mean: 4.368920053821057e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.67 | consumed tokens: 1365606400.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T01:04:40 | step: 166800 | train samples/s: 100.2 | train mfu (16-bit): -1.0 | lr mean: 4.368164809420705e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.98 | consumed tokens: 1366425600.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-02T01:04:56 | step: 166900 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.367409201222472e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.28 | consumed tokens: 1367244800.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T01:05:13 | step: 167000 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 4.3666528654284775e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.06 | train loss last: 2.44 | consumed tokens: 1368064000.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T01:05:29 | step: 167100 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.365896529634483e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.91 | consumed tokens: 1368883200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T01:05:46 | step: 167200 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.365139830042608e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.66 | consumed tokens: 1369702400.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T01:06:02 | step: 167300 | train samples/s: 100.1 | train mfu (16-bit): -1.0 | lr mean: 4.3643824028549716e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.84 | consumed tokens: 1370521600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:06:19 | step: 167400 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.363624975667335e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.44 | consumed tokens: 1371340800.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T01:06:35 | step: 167500 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 4.362866820883937e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.05 | consumed tokens: 1372160000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T01:06:52 | step: 167600 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.362108666100539e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.8 | consumed tokens: 1372979200.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:07:08 | step: 167700 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.36134978372138e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.72 | consumed tokens: 1373798400.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T01:07:24 | step: 167800 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.36059053754434e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.88 | consumed tokens: 1374617600.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T01:07:41 | step: 167900 | train samples/s: 100.6 | train mfu (16-bit): -1.0 | lr mean: 4.359830927569419e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.25 | consumed tokens: 1375436800.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:07:57 | step: 168000 | train samples/s: 100.7 | train mfu (16-bit): -1.0 | lr mean: 4.359070953796618e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.95 | consumed tokens: 1376256000.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-02T01:08:13 | step: 168100 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.358310980023816e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.86 | consumed tokens: 1377075200.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T01:08:30 | step: 168200 | train samples/s: 100.2 | train mfu (16-bit): -1.0 | lr mean: 4.3575502786552534e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.98 | consumed tokens: 1377894400.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T01:08:46 | step: 168300 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.35678921348881e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.05 | train loss last: 3.88 | consumed tokens: 1378713600.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:09:02 | step: 168400 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.356027420726605e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.8 | consumed tokens: 1379532800.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T01:09:19 | step: 168500 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 4.3552656279644e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.3 | consumed tokens: 1380352000.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:09:35 | step: 168600 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 4.354503471404314e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.06 | consumed tokens: 1381171200.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T01:09:52 | step: 168700 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.3537409510463476e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.3 | consumed tokens: 1381990400.0 | grad norm avg: 0.71 | grad norm last: 0.68 | 
2026-01-02T01:10:08 | step: 168800 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.3529780668905005e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.06 | consumed tokens: 1382809600.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:10:25 | step: 168900 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.352214455138892e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.7 | consumed tokens: 1383628800.0 | grad norm avg: 0.7 | grad norm last: 0.64 | 
2026-01-02T01:10:41 | step: 169000 | train samples/s: 100.4 | train mfu (16-bit): -1.0 | lr mean: 4.3514508433872834e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.19 | consumed tokens: 1384448000.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T01:10:57 | step: 169100 | train samples/s: 100.8 | train mfu (16-bit): -1.0 | lr mean: 4.3506865040399134e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.34 | consumed tokens: 1385267200.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T01:11:13 | step: 169200 | train samples/s: 100.2 | train mfu (16-bit): -1.0 | lr mean: 4.3499221646925434e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.92 | consumed tokens: 1386086400.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-02T01:11:30 | step: 169300 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.349157097749412e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 2.97 | consumed tokens: 1386905600.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:11:46 | step: 169400 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.348392030806281e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.7 | consumed tokens: 1387724800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:12:02 | step: 169500 | train samples/s: 100.6 | train mfu (16-bit): -1.0 | lr mean: 4.347626236267388e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.12 | consumed tokens: 1388544000.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:12:19 | step: 169600 | train samples/s: 100.7 | train mfu (16-bit): -1.0 | lr mean: 4.3468600779306144e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.8 | consumed tokens: 1389363200.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T01:12:35 | step: 169700 | train samples/s: 100.8 | train mfu (16-bit): -1.0 | lr mean: 4.34609355579596e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.83 | consumed tokens: 1390182400.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:12:51 | step: 169800 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 4.345327033661306e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.48 | consumed tokens: 1391001600.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:13:08 | step: 169900 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.34455978393089e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 3.12 | consumed tokens: 1391820800.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T01:13:24 | step: 170000 | train samples/s: 100.0 | train mfu (16-bit): -1.0 | lr mean: 4.343792170402594e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.8 | consumed tokens: 1392640000.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-02T01:13:42 | step: 170100 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.343024193076417e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.28 | consumed tokens: 1393459200.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:13:58 | step: 170200 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.342255851952359e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.02 | consumed tokens: 1394278400.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:14:15 | step: 170300 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.3414871470304206e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 2.8 | consumed tokens: 1395097600.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-02T01:14:31 | step: 170400 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 4.3407180783106014e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.62 | consumed tokens: 1395916800.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T01:14:48 | step: 170500 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.3399486457929015e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.77 | consumed tokens: 1396736000.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T01:15:04 | step: 170600 | train samples/s: 99.3 | train mfu (16-bit): -1.0 | lr mean: 4.33917848567944e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.62 | consumed tokens: 1397555200.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T01:15:20 | step: 170700 | train samples/s: 100.1 | train mfu (16-bit): -1.0 | lr mean: 4.338408325565979e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.0 | consumed tokens: 1398374400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:15:37 | step: 170800 | train samples/s: 100.7 | train mfu (16-bit): -1.0 | lr mean: 4.337637801654637e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.41 | consumed tokens: 1399193600.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T01:15:53 | step: 170900 | train samples/s: 99.9 | train mfu (16-bit): -1.0 | lr mean: 4.336866913945414e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.69 | consumed tokens: 1400012800.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T01:16:09 | step: 171000 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 4.33609529864043e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.14 | consumed tokens: 1400832000.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:16:26 | step: 171100 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 4.335323683335446e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.19 | consumed tokens: 1401651200.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-02T01:16:42 | step: 171200 | train samples/s: 100.7 | train mfu (16-bit): -1.0 | lr mean: 4.3345513404347e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.08 | consumed tokens: 1402470400.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:16:59 | step: 171300 | train samples/s: 100.6 | train mfu (16-bit): -1.0 | lr mean: 4.333778997533955e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.28 | consumed tokens: 1403289600.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-02T01:17:15 | step: 171400 | train samples/s: 100.4 | train mfu (16-bit): -1.0 | lr mean: 4.333005927037448e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.3 | consumed tokens: 1404108800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T01:17:31 | step: 171500 | train samples/s: 100.2 | train mfu (16-bit): -1.0 | lr mean: 4.332232856540941e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.08 | consumed tokens: 1404928000.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:17:47 | step: 171600 | train samples/s: 100.2 | train mfu (16-bit): -1.0 | lr mean: 4.331459058448672e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.2 | consumed tokens: 1405747200.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T01:18:04 | step: 171700 | train samples/s: 100.6 | train mfu (16-bit): -1.0 | lr mean: 4.330684896558523e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.7 | consumed tokens: 1406566400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T01:18:20 | step: 171800 | train samples/s: 100.8 | train mfu (16-bit): -1.0 | lr mean: 4.329910734668374e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.33 | consumed tokens: 1407385600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:18:36 | step: 171900 | train samples/s: 100.9 | train mfu (16-bit): -1.0 | lr mean: 4.3291358451824635e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.0 | consumed tokens: 1408204800.0 | grad norm avg: 0.69 | grad norm last: 0.77 | 
2026-01-02T01:18:52 | step: 172000 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.328360591898672e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.88 | consumed tokens: 1409024000.0 | grad norm avg: 0.7 | grad norm last: 0.76 | 
2026-01-02T01:19:09 | step: 172100 | train samples/s: 100.7 | train mfu (16-bit): -1.0 | lr mean: 4.327584974817e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 2.89 | consumed tokens: 1409843200.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:19:25 | step: 172200 | train samples/s: 100.5 | train mfu (16-bit): -1.0 | lr mean: 4.3268093577353284e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.15 | train loss last: 3.08 | consumed tokens: 1410662400.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-02T01:19:41 | step: 172300 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.326033013057895e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.2 | consumed tokens: 1411481600.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:19:58 | step: 172400 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 4.325256304582581e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.11 | consumed tokens: 1412300800.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:20:14 | step: 172500 | train samples/s: 99.8 | train mfu (16-bit): -1.0 | lr mean: 4.324479232309386e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.66 | consumed tokens: 1413120000.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-02T01:20:31 | step: 172600 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.3237017962383106e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.03 | consumed tokens: 1413939200.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T01:20:47 | step: 172700 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.3229239963693544e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.09 | consumed tokens: 1414758400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:21:04 | step: 172800 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 4.3221458327025175e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.44 | consumed tokens: 1415577600.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:21:20 | step: 172900 | train samples/s: 99.0 | train mfu (16-bit): -1.0 | lr mean: 4.321366941439919e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.23 | consumed tokens: 1416396800.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:21:36 | step: 173000 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.320588050177321e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.67 | consumed tokens: 1417216000.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:21:53 | step: 173100 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.319808795116842e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.3 | consumed tokens: 1418035200.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T01:22:09 | step: 173200 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.319029176258482e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.61 | consumed tokens: 1418854400.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T01:22:26 | step: 173300 | train samples/s: 99.7 | train mfu (16-bit): -1.0 | lr mean: 4.3182491936022416e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.91 | consumed tokens: 1419673600.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T01:22:42 | step: 173400 | train samples/s: 99.6 | train mfu (16-bit): -1.0 | lr mean: 4.31746848335024e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.11 | consumed tokens: 1420492800.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-02T01:22:58 | step: 173500 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.316687773098238e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.27 | consumed tokens: 1421312000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T01:23:15 | step: 173600 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 4.315906699048355e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.3 | consumed tokens: 1422131200.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T01:23:31 | step: 173700 | train samples/s: 98.8 | train mfu (16-bit): -1.0 | lr mean: 4.315124897402711e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.19 | consumed tokens: 1422950400.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T01:23:48 | step: 173800 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.314343095757067e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.02 | consumed tokens: 1423769600.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T01:24:04 | step: 173900 | train samples/s: 100.4 | train mfu (16-bit): -1.0 | lr mean: 4.313560566515662e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.38 | consumed tokens: 1424588800.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:24:20 | step: 174000 | train samples/s: 100.2 | train mfu (16-bit): -1.0 | lr mean: 4.3127780372742563e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.48 | consumed tokens: 1425408000.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:24:37 | step: 174100 | train samples/s: 100.7 | train mfu (16-bit): -1.0 | lr mean: 4.3119947804370895e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.36 | consumed tokens: 1426227200.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:24:53 | step: 174200 | train samples/s: 100.1 | train mfu (16-bit): -1.0 | lr mean: 4.3112115235999227e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 2.5 | consumed tokens: 1427046400.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-02T01:25:09 | step: 174300 | train samples/s: 100.3 | train mfu (16-bit): -1.0 | lr mean: 4.3104275391669944e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.33 | consumed tokens: 1427865600.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:25:25 | step: 174400 | train samples/s: 100.6 | train mfu (16-bit): -1.0 | lr mean: 4.309643554734066e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.78 | consumed tokens: 1428684800.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-02T01:25:42 | step: 174500 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 4.3088588427053764e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.42 | consumed tokens: 1429504000.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:25:58 | step: 174600 | train samples/s: 100.6 | train mfu (16-bit): -1.0 | lr mean: 4.308073766878806e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.14 | consumed tokens: 1430323200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:26:14 | step: 174700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.307288691052236e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.45 | consumed tokens: 1431142400.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T01:26:29 | step: 174800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.306502887629904e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.97 | consumed tokens: 1431961600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:26:45 | step: 174900 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.305716720409691e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.66 | consumed tokens: 1432780800.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T01:27:01 | step: 175000 | train samples/s: 102.4 | train mfu (16-bit): -1.0 | lr mean: 4.304930189391598e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.42 | consumed tokens: 1433600000.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:27:18 | step: 175100 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.304143658373505e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.12 | consumed tokens: 1434419200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T01:27:33 | step: 175200 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.30335639975965e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.52 | consumed tokens: 1435238400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T01:27:49 | step: 175300 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.302568777347915e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.91 | consumed tokens: 1436057600.0 | grad norm avg: 0.7 | grad norm last: 0.75 | 
2026-01-02T01:28:04 | step: 175400 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.301780791138299e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.03 | consumed tokens: 1436876800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:28:20 | step: 175500 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.300992441130802e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 2.97 | consumed tokens: 1437696000.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-02T01:28:36 | step: 175600 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.3002037273254246e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.84 | consumed tokens: 1438515200.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T01:28:51 | step: 175700 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.2994146497221664e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.0 | consumed tokens: 1439334400.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:29:07 | step: 175800 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.2986252083210275e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.45 | consumed tokens: 1440153600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:29:23 | step: 175900 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.297835403122008e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.64 | consumed tokens: 1440972800.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T01:29:38 | step: 176000 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.2970452341251075e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 3.48 | consumed tokens: 1441792000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:29:54 | step: 176100 | train samples/s: 103.8 | train mfu (16-bit): -1.0 | lr mean: 4.2962547013303265e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.05 | consumed tokens: 1442611200.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-02T01:30:10 | step: 176200 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 4.295463804737665e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.61 | consumed tokens: 1443430400.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T01:30:26 | step: 176300 | train samples/s: 102.2 | train mfu (16-bit): -1.0 | lr mean: 4.294672544347122e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 4.34 | consumed tokens: 1444249600.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T01:30:41 | step: 176400 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.293880920158699e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.34 | consumed tokens: 1445068800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:30:57 | step: 176500 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.293088932172395e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.81 | consumed tokens: 1445888000.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T01:31:12 | step: 176600 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.292296580388211e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.14 | consumed tokens: 1446707200.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T01:31:28 | step: 176700 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.2915038648061454e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 2.83 | consumed tokens: 1447526400.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T01:31:44 | step: 176800 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.2907107854261994e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.52 | consumed tokens: 1448345600.0 | grad norm avg: 0.7 | grad norm last: 0.77 | 
2026-01-02T01:31:59 | step: 176900 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.289916978450492e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.84 | consumed tokens: 1449164800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T01:32:15 | step: 177000 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.2891231714747846e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.19 | consumed tokens: 1449984000.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:32:31 | step: 177100 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.2883290007011965e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.67 | consumed tokens: 1450803200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:32:46 | step: 177200 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.287534466129728e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.75 | consumed tokens: 1451622400.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:33:02 | step: 177300 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.286739567760378e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 2.86 | consumed tokens: 1452441600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:33:18 | step: 177400 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.285943941795267e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 2.52 | consumed tokens: 1453260800.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-02T01:33:33 | step: 177500 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.285148315830156e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 3.27 | consumed tokens: 1454080000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:33:49 | step: 177600 | train samples/s: 103.0 | train mfu (16-bit): -1.0 | lr mean: 4.2843523260671645e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.42 | consumed tokens: 1454899200.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T01:34:05 | step: 177700 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.2835556087084115e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.75 | consumed tokens: 1455718400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:34:20 | step: 177800 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.2827588913496584e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.97 | consumed tokens: 1456537600.0 | grad norm avg: 0.69 | grad norm last: 0.74 | 
2026-01-02T01:34:36 | step: 177900 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.2819618101930246e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.73 | consumed tokens: 1457356800.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-02T01:34:52 | step: 178000 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.2811640014406294e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 3.23 | consumed tokens: 1458176000.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:35:07 | step: 178100 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.280366192688234e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 2.58 | consumed tokens: 1458995200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T01:35:23 | step: 178200 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.279568020137958e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.19 | consumed tokens: 1459814400.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T01:35:38 | step: 178300 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.278769119991921e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 2.97 | consumed tokens: 1460633600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:35:54 | step: 178400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.2779702198458835e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.09 | consumed tokens: 1461452800.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T01:36:10 | step: 178500 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.2771709559019655e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.75 | consumed tokens: 1462272000.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:36:25 | step: 178600 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.276370964362286e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.16 | consumed tokens: 1463091200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:36:41 | step: 178700 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.2755709728226066e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.11 | consumed tokens: 1463910400.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-02T01:36:57 | step: 178800 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.274770253687166e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 3.03 | consumed tokens: 1464729600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:37:12 | step: 178900 | train samples/s: 103.2 | train mfu (16-bit): -1.0 | lr mean: 4.273969534551725e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.0 | consumed tokens: 1465548800.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T01:37:28 | step: 179000 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.2731680878205225e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.02 | consumed tokens: 1466368000.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:37:44 | step: 179100 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.27236664108932e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 3.69 | consumed tokens: 1467187200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:37:59 | step: 179200 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.2715644667623565e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.06 | train loss last: 3.44 | consumed tokens: 1468006400.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:38:15 | step: 179300 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.270762292435393e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.27 | consumed tokens: 1468825600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:38:31 | step: 179400 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.269959754310548e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 2.83 | consumed tokens: 1469644800.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T01:38:46 | step: 179500 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.2691564885899425e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.08 | consumed tokens: 1470464000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T01:39:02 | step: 179600 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.2683532228693366e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.36 | consumed tokens: 1471283200.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:39:17 | step: 179700 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.267549229552969e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.5 | consumed tokens: 1472102400.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T01:39:33 | step: 179800 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.266745236236602e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.06 | train loss last: 2.98 | consumed tokens: 1472921600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:39:49 | step: 179900 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.2659405153244734e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 2.73 | consumed tokens: 1473740800.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:40:04 | step: 180000 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.265135794412345e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.47 | consumed tokens: 1474560000.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T01:40:21 | step: 180100 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.2643303459044546e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.08 | consumed tokens: 1475379200.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T01:40:37 | step: 180200 | train samples/s: 103.5 | train mfu (16-bit): -1.0 | lr mean: 4.2635248973965645e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 3.78 | consumed tokens: 1476198400.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:40:52 | step: 180300 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.262718721292913e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.73 | consumed tokens: 1477017600.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:41:08 | step: 180400 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.2619125451892614e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.59 | consumed tokens: 1477836800.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T01:41:24 | step: 180500 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.2611056414898485e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.77 | consumed tokens: 1478656000.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:41:39 | step: 180600 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.2602987377904356e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.5 | consumed tokens: 1479475200.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T01:41:55 | step: 180700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.259491106495261e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 2.95 | consumed tokens: 1480294400.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-02T01:42:10 | step: 180800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.258683475200087e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.03 | consumed tokens: 1481113600.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-02T01:42:26 | step: 180900 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.257875116309151e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.98 | consumed tokens: 1481932800.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T01:42:42 | step: 181000 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.2570663936203346e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.64 | consumed tokens: 1482752000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:42:57 | step: 181100 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.256257670931518e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.41 | consumed tokens: 1483571200.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-02T01:43:13 | step: 181200 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 4.25544822064694e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.41 | consumed tokens: 1484390400.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T01:43:29 | step: 181300 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.254638770362362e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.45 | consumed tokens: 1485209600.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T01:43:44 | step: 181400 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.253828592482023e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.0 | consumed tokens: 1486028800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T01:44:00 | step: 181500 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.2530184146016836e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.56 | consumed tokens: 1486848000.0 | grad norm avg: 0.69 | grad norm last: 0.64 | 
2026-01-02T01:44:16 | step: 181600 | train samples/s: 102.9 | train mfu (16-bit): -1.0 | lr mean: 4.252207509125583e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.59 | consumed tokens: 1487667200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:44:31 | step: 181700 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.251396603649482e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.02 | consumed tokens: 1488486400.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-02T01:44:47 | step: 181800 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.25058497057762e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.92 | consumed tokens: 1489305600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:45:02 | step: 181900 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.249773337505758e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 2.17 | consumed tokens: 1490124800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T01:45:18 | step: 182000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.248960976838134e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 2.95 | consumed tokens: 1490944000.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-02T01:45:33 | step: 182100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.2481486161705106e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.36 | consumed tokens: 1491763200.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:45:49 | step: 182200 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.2473358917050064e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.77 | consumed tokens: 1492582400.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:46:04 | step: 182300 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.2465224396437407e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.3 | consumed tokens: 1493401600.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-02T01:46:20 | step: 182400 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.245708987582475e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.14 | consumed tokens: 1494220800.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-02T01:46:36 | step: 182500 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.244894807925448e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 2.59 | consumed tokens: 1495040000.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T01:46:51 | step: 182600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.244080628268421e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.55 | consumed tokens: 1495859200.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T01:47:07 | step: 182700 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.243265721015632e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.75 | consumed tokens: 1496678400.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:47:22 | step: 182800 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.2424508137628436e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.83 | consumed tokens: 1497497600.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T01:47:38 | step: 182900 | train samples/s: 102.4 | train mfu (16-bit): -1.0 | lr mean: 4.2416355427121744e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.33 | consumed tokens: 1498316800.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T01:47:54 | step: 183000 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.240819544065744e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.59 | consumed tokens: 1499136000.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T01:48:09 | step: 183100 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.240003545419313e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.0 | consumed tokens: 1499955200.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T01:48:25 | step: 183200 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.239186819177121e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 2.78 | consumed tokens: 1500774400.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T01:48:41 | step: 183300 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.238370092934929e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.72 | consumed tokens: 1501593600.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T01:48:56 | step: 183400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.237553002894856e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.45 | consumed tokens: 1502412800.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-02T01:49:12 | step: 183500 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.236735185259022e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 2.55 | consumed tokens: 1503232000.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-02T01:49:27 | step: 183600 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.2359173676231876e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.47 | consumed tokens: 1504051200.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-02T01:49:43 | step: 183700 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.235099186189473e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.05 | train loss last: 3.69 | consumed tokens: 1504870400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:49:58 | step: 183800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.234280277159996e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.97 | consumed tokens: 1505689600.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:50:14 | step: 183900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.23346136813052e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.77 | consumed tokens: 1506508800.0 | grad norm avg: 0.7 | grad norm last: 0.76 | 
2026-01-02T01:50:29 | step: 184000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.232642095303163e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.98 | consumed tokens: 1507328000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:50:45 | step: 184100 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.231822458677925e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.83 | consumed tokens: 1508147200.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T01:51:01 | step: 184200 | train samples/s: 102.9 | train mfu (16-bit): -1.0 | lr mean: 4.231002094456926e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.05 | consumed tokens: 1508966400.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T01:51:16 | step: 184300 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.230181730235927e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.77 | consumed tokens: 1509785600.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-02T01:51:32 | step: 184400 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.229361002217047e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.3 | consumed tokens: 1510604800.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:51:48 | step: 184500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.228539910400286e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.92 | consumed tokens: 1511424000.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T01:52:03 | step: 184600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.227718454785645e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.47 | consumed tokens: 1512243200.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T01:52:19 | step: 184700 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.226896271575242e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.73 | consumed tokens: 1513062400.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-02T01:52:34 | step: 184800 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.2260740883648396e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.34 | consumed tokens: 1513881600.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T01:52:50 | step: 184900 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.225251541356556e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.27 | consumed tokens: 1514700800.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T01:53:06 | step: 185000 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.224428630550392e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.28 | consumed tokens: 1515520000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:53:22 | step: 185100 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.223605355946347e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.06 | train loss last: 3.47 | consumed tokens: 1516339200.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T01:53:38 | step: 185200 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.2227817175444216e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.34 | consumed tokens: 1517158400.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T01:53:54 | step: 185300 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.221957715344615e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.3 | consumed tokens: 1517977600.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T01:54:09 | step: 185400 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.221133349346928e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.97 | consumed tokens: 1518796800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:54:25 | step: 185500 | train samples/s: 102.2 | train mfu (16-bit): -1.0 | lr mean: 4.2203086195513606e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.27 | consumed tokens: 1519616000.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T01:54:41 | step: 185600 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.219483525957912e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.64 | consumed tokens: 1520435200.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T01:54:57 | step: 185700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.218658068566583e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.0 | consumed tokens: 1521254400.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T01:55:12 | step: 185800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.217832247377373e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.17 | consumed tokens: 1522073600.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T01:55:28 | step: 185900 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.217006062390283e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.78 | consumed tokens: 1522892800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:55:43 | step: 186000 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.2161795136053115e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.02 | consumed tokens: 1523712000.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-02T01:55:59 | step: 186100 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.2153526010224596e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.72 | consumed tokens: 1524531200.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:56:15 | step: 186200 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.2145256884396076e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.04 | train loss last: 3.0 | consumed tokens: 1525350400.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T01:56:30 | step: 186300 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.213698048260994e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.06 | train loss last: 2.86 | consumed tokens: 1526169600.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:56:46 | step: 186400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.2128700442845e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.22 | consumed tokens: 1526988800.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T01:57:01 | step: 186500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.2120416765101254e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.41 | consumed tokens: 1527808000.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T01:57:17 | step: 186600 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.2112133087357506e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.7 | consumed tokens: 1528627200.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-02T01:57:32 | step: 186700 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.2103842133656144e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.52 | consumed tokens: 1529446400.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T01:57:48 | step: 186800 | train samples/s: 102.8 | train mfu (16-bit): -1.0 | lr mean: 4.2095547541975975e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.98 | consumed tokens: 1530265600.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T01:58:04 | step: 186900 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.2087252950295806e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.94 | consumed tokens: 1531084800.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T01:58:19 | step: 187000 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.207895108265802e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.75 | consumed tokens: 1531904000.0 | grad norm avg: 0.69 | grad norm last: 0.74 | 
2026-01-02T01:58:35 | step: 187100 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.207064557704143e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.83 | consumed tokens: 1532723200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T01:58:50 | step: 187200 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.206234007142484e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.04 | train loss last: 2.61 | consumed tokens: 1533542400.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T01:59:06 | step: 187300 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.205402728985064e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 3.22 | consumed tokens: 1534361600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:59:22 | step: 187400 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.204571450827643e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.55 | consumed tokens: 1535180800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T01:59:37 | step: 187500 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.2037394450744614e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.23 | consumed tokens: 1536000000.0 | grad norm avg: 0.7 | grad norm last: 0.65 | 
2026-01-02T01:59:53 | step: 187600 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.2029074393212795e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.47 | consumed tokens: 1536819200.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T02:00:08 | step: 187700 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.202075069770217e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 2.31 | consumed tokens: 1537638400.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-02T02:00:24 | step: 187800 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.201241972623393e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.86 | consumed tokens: 1538457600.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T02:00:40 | step: 187900 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.200408875476569e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.22 | consumed tokens: 1539276800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T02:00:55 | step: 188000 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.199575414531864e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.22 | consumed tokens: 1540096000.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-02T02:01:11 | step: 188100 | train samples/s: 102.5 | train mfu (16-bit): -1.0 | lr mean: 4.198741225991398e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.05 | consumed tokens: 1540915200.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T02:01:27 | step: 188200 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.197907037450932e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.48 | consumed tokens: 1541734400.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T02:01:42 | step: 188300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.197072485112585e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.12 | consumed tokens: 1542553600.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T02:01:58 | step: 188400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.1962375689763576e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 2.89 | consumed tokens: 1543372800.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T02:02:14 | step: 188500 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.195402289042249e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.19 | consumed tokens: 1544192000.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T02:02:29 | step: 188600 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.1945666453102604e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.17 | consumed tokens: 1545011200.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T02:02:45 | step: 188700 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.193730637780391e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.3 | consumed tokens: 1545830400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T02:03:01 | step: 188800 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.19289426645264e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.06 | train loss last: 3.8 | consumed tokens: 1546649600.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T02:03:16 | step: 188900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.192057531327009e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.52 | consumed tokens: 1547468800.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-02T02:03:32 | step: 189000 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.1912204324034974e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.64 | consumed tokens: 1548288000.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T02:03:47 | step: 189100 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.190382969682105e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.89 | consumed tokens: 1549107200.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T02:04:03 | step: 189200 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.189545143162832e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.2 | consumed tokens: 1549926400.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T02:04:19 | step: 189300 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.188706952845678e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.84 | consumed tokens: 1550745600.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T02:04:34 | step: 189400 | train samples/s: 103.2 | train mfu (16-bit): -1.0 | lr mean: 4.187868398730643e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.05 | train loss last: 2.64 | consumed tokens: 1551564800.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T02:04:50 | step: 189500 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.1870298446156085e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 2.88 | consumed tokens: 1552384000.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-02T02:05:06 | step: 189600 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.1861905629048124e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.05 | consumed tokens: 1553203200.0 | grad norm avg: 0.7 | grad norm last: 0.65 | 
2026-01-02T02:05:21 | step: 189700 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.1853509173961356e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 3.58 | consumed tokens: 1554022400.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T02:05:37 | step: 189800 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.184511271887459e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.72 | consumed tokens: 1554841600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T02:05:53 | step: 189900 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.183670898783021e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.42 | consumed tokens: 1555660800.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-02T02:06:08 | step: 190000 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.1828305256785825e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.08 | consumed tokens: 1556480000.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T02:06:25 | step: 190100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.181989424978383e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 3.77 | consumed tokens: 1557299200.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T02:06:41 | step: 190200 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.181148324278183e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.13 | train loss last: 3.25 | consumed tokens: 1558118400.0 | grad norm avg: 0.69 | grad norm last: 0.74 | 
2026-01-02T02:06:56 | step: 190300 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.180306495982222e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.84 | consumed tokens: 1558937600.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-02T02:07:12 | step: 190400 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.179464667686261e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.56 | consumed tokens: 1559756800.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-02T02:07:28 | step: 190500 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.1786224755924195e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.75 | consumed tokens: 1560576000.0 | grad norm avg: 0.7 | grad norm last: 0.64 | 
2026-01-02T02:07:43 | step: 190600 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.177779919700697e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.17 | consumed tokens: 1561395200.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-02T02:07:59 | step: 190700 | train samples/s: 102.7 | train mfu (16-bit): -1.0 | lr mean: 4.176936636213213e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.5 | consumed tokens: 1562214400.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T02:08:15 | step: 190800 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.1760933527257293e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 3.22 | consumed tokens: 1563033600.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-02T02:08:31 | step: 190900 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.175249705440365e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 2.23 | consumed tokens: 1563852800.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T02:08:46 | step: 191000 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.1744056943571195e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.83 | consumed tokens: 1564672000.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T02:09:02 | step: 191100 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.1735613194759935e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 2.41 | consumed tokens: 1565491200.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T02:09:17 | step: 191200 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.172716580796987e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.2 | consumed tokens: 1566310400.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
2026-01-02T02:09:33 | step: 191300 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.1718714783200994e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.06 | train loss last: 3.02 | consumed tokens: 1567129600.0 | grad norm avg: 0.69 | grad norm last: 0.76 | 
2026-01-02T02:09:48 | step: 191400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.171026012045331e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.72 | consumed tokens: 1567948800.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T02:10:04 | step: 191500 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.170180545770563e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.16 | consumed tokens: 1568768000.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T02:10:20 | step: 191600 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.1693343519000337e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.91 | consumed tokens: 1569587200.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-02T02:10:35 | step: 191700 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.1684877942316234e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.94 | consumed tokens: 1570406400.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T02:10:51 | step: 191800 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.1676408727653325e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.94 | consumed tokens: 1571225600.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T02:11:06 | step: 191900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.1667939512990415e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 3.11 | consumed tokens: 1572044800.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T02:11:22 | step: 192000 | train samples/s: 103.7 | train mfu (16-bit): -1.0 | lr mean: 4.165946302236989e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.02 | consumed tokens: 1572864000.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T02:11:38 | step: 192100 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.165098653174937e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.98 | consumed tokens: 1573683200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T02:11:53 | step: 192200 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.164250276517123e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.22 | consumed tokens: 1574502400.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T02:12:09 | step: 192300 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.163401899859309e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.38 | consumed tokens: 1575321600.0 | grad norm avg: 0.7 | grad norm last: 0.76 | 
2026-01-02T02:12:25 | step: 192400 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.162553159403615e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 2.69 | consumed tokens: 1576140800.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-02T02:12:40 | step: 192500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.161703691352159e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 4.06 | consumed tokens: 1576960000.0 | grad norm avg: 0.7 | grad norm last: 0.77 | 
2026-01-02T02:12:56 | step: 192600 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.160854223300703e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.72 | consumed tokens: 1577779200.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T02:13:11 | step: 192700 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.160004391451366e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.05 | train loss last: 2.67 | consumed tokens: 1578598400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T02:13:27 | step: 192800 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.159154195804149e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.97 | consumed tokens: 1579417600.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T02:13:43 | step: 192900 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.158303636359051e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.22 | consumed tokens: 1580236800.0 | grad norm avg: 0.69 | grad norm last: 0.66 | 
2026-01-02T02:13:58 | step: 193000 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.157452713116072e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.06 | train loss last: 2.75 | consumed tokens: 1581056000.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T02:14:14 | step: 193100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.1566014260752127e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.06 | train loss last: 3.28 | consumed tokens: 1581875200.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T02:14:29 | step: 193200 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.1557497752364725e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.06 | train loss last: 3.25 | consumed tokens: 1582694400.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T02:14:45 | step: 193300 | train samples/s: 102.6 | train mfu (16-bit): -1.0 | lr mean: 4.1548977605998516e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.47 | consumed tokens: 1583513600.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T02:15:01 | step: 193400 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.15404538216535e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.97 | consumed tokens: 1584332800.0 | grad norm avg: 0.69 | grad norm last: 0.75 | 
2026-01-02T02:15:16 | step: 193500 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.1531930037308484e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.48 | consumed tokens: 1585152000.0 | grad norm avg: 0.69 | grad norm last: 0.68 | 
2026-01-02T02:15:32 | step: 193600 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.1523398977005854e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 2.92 | consumed tokens: 1585971200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T02:15:48 | step: 193700 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.1514867916703224e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.06 | train loss last: 2.66 | consumed tokens: 1586790400.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T02:16:03 | step: 193800 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.150632958044298e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.33 | consumed tokens: 1587609600.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-02T02:16:19 | step: 193900 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.1497791244182736e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 2.86 | consumed tokens: 1588428800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T02:16:35 | step: 194000 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.148924563196488e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.06 | train loss last: 3.39 | consumed tokens: 1589248000.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T02:16:50 | step: 194100 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.148070001974702e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.27 | consumed tokens: 1590067200.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T02:17:06 | step: 194200 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.147215076955035e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 3.23 | consumed tokens: 1590886400.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-02T02:17:21 | step: 194300 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.1463594243396074e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 2.95 | consumed tokens: 1591705600.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-02T02:17:37 | step: 194400 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.1455037717241794e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.42 | consumed tokens: 1592524800.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-02T02:17:53 | step: 194500 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.144647755310871e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 2.83 | consumed tokens: 1593344000.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T02:18:09 | step: 194600 | train samples/s: 102.3 | train mfu (16-bit): -1.0 | lr mean: 4.143791375099681e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.36 | consumed tokens: 1594163200.0 | grad norm avg: 0.69 | grad norm last: 0.76 | 
2026-01-02T02:18:24 | step: 194700 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 4.142934631090611e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.91 | consumed tokens: 1594982400.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T02:18:40 | step: 194800 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.1420775232836604e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.06 | consumed tokens: 1595801600.0 | grad norm avg: 0.7 | grad norm last: 0.67 | 
2026-01-02T02:18:56 | step: 194900 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.1412204154767096e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.97 | consumed tokens: 1596620800.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-02T02:19:11 | step: 195000 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.1403625800739974e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.95 | consumed tokens: 1597440000.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T02:19:28 | step: 195100 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.1395043808734044e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 3.61 | consumed tokens: 1598259200.0 | grad norm avg: 0.69 | grad norm last: 0.65 | 
2026-01-02T02:19:44 | step: 195200 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.1386461816728115e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.31 | consumed tokens: 1599078400.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-02T02:19:59 | step: 195300 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.137787254876457e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.06 | train loss last: 2.81 | consumed tokens: 1599897600.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-02T02:20:15 | step: 195400 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.136928328080103e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 2.77 | consumed tokens: 1600716800.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-02T02:20:31 | step: 195500 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.136068673687987e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.7 | consumed tokens: 1601536000.0 | grad norm avg: 0.7 | grad norm last: 0.64 | 
2026-01-02T02:20:46 | step: 195600 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.135209019295871e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.12 | train loss last: 2.53 | consumed tokens: 1602355200.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-02T02:21:02 | step: 195700 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.134349001105875e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.11 | train loss last: 3.08 | consumed tokens: 1603174400.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-02T02:21:17 | step: 195800 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.133488255320117e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.08 | train loss last: 2.83 | consumed tokens: 1603993600.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T02:21:33 | step: 195900 | train samples/s: 102.3 | train mfu (16-bit): -1.0 | lr mean: 4.132627509534359e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.41 | consumed tokens: 1604812800.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T02:21:49 | step: 196000 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 4.1317663999507204e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 3.02 | consumed tokens: 1605632000.0 | grad norm avg: 0.7 | grad norm last: 0.74 | 
2026-01-02T02:22:05 | step: 196100 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.130904926569201e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.17 | consumed tokens: 1606451200.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-02T02:22:20 | step: 196200 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.130043089389801e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 2.84 | consumed tokens: 1607270400.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T02:22:36 | step: 196300 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.129181252210401e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.14 | train loss last: 2.67 | consumed tokens: 1608089600.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-02T02:22:52 | step: 196400 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.1283186874352396e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 3.78 | consumed tokens: 1608908800.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T02:23:07 | step: 196500 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 4.1274557588621974e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.09 | train loss last: 3.08 | consumed tokens: 1609728000.0 | grad norm avg: 0.69 | grad norm last: 0.75 | 
2026-01-02T02:23:23 | step: 196600 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.126592830289155e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.1 | train loss last: 3.22 | consumed tokens: 1610547200.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
                      step: 196700 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.125729174120352e-05 | peak memory rank 0 (MB): 3941.08 | train loss avg: 3.07 | train loss last: 2.77 | consumed tokens: 1611366400.0 | grad norm avg: 0.69 | grad norm last: 0.72 | 
