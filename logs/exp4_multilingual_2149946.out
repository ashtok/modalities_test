==========================================
Experiment 4: Fine-tuning GPT-2 on 5 languages with 4 GPUs
Job ID: 2149946
Node: jnfat02
Start time: Thu Jan  1 07:25:51 PM CET 2026
==========================================
Thu Jan  1 19:25:52 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.28.03              Driver Version: 560.28.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA L40S                    On  |   00000000:05:00.0 Off |                    0 |
| N/A   29C    P8             35W /  350W |       1MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA L40S                    On  |   00000000:06:00.0 Off |                    0 |
| N/A   30C    P8             32W /  350W |       1MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA L40S                    On  |   00000000:45:00.0 Off |                    0 |
| N/A   29C    P8             34W /  350W |       1MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA L40S                    On  |   00000000:46:00.0 Off |                    0 |
| N/A   30C    P8             33W /  350W |       1MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Rank 0 received experiment_id: 2026-01-01__19-26-08_a91e58afaade00f6
Rank 1 received experiment_id: 2026-01-01__19-26-08_a91e58afaade00f6
Rank 2 received experiment_id: 2026-01-01__19-26-08_a91e58afaade00f6
Rank 3 received experiment_id: 2026-01-01__19-26-08_a91e58afaade00f6
Instantiated <class 'int'>: settings -> training_target -> num_target_tokens
Instantiated <class 'int'>: settings -> training_target -> num_target_steps -> config -> global_num_tokens
Instantiated <class 'int'>: settings -> training_target -> num_target_steps
Instantiated <class 'modalities.models.huggingface.huggingface_model.HuggingFacePretrainedModel'>: model_raw

Wrapped layer classes: [<class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>]

Instantiated <class 'torch.distributed.fsdp.fully_sharded_data_parallel.FullyShardedDataParallel'>: wrapped_model
=> optimizer groups:
all (148 modules with 31,109,952 parameters): weight_decay = 0.01
=> all (148 modules with 31,109,952 parameters)
Instantiated <class 'torch.optim.adamw.AdamW'>: optimizer
Instantiated <class 'int'>: lr_scheduler -> config -> total_steps -> config -> global_num_tokens
Instantiated <class 'int'>: lr_scheduler -> config -> total_steps
Instantiated <class 'torch.optim.lr_scheduler.OneCycleLR'>: lr_scheduler
Instantiated <class 'modalities.checkpointing.stateful.app_state.AppState'>: app_state
Instantiated <class 'modalities.loss_functions.CLMCrossEntropyLoss'>: loss_fn
Instantiated <class 'modalities.dataloader.dataset.PackedMemMapDatasetContinuous'>: train_dataset
Instantiated <class 'modalities.dataloader.samplers.ResumableDistributedSampler'>: train_dataloader -> config -> batch_sampler -> config -> sampler
Instantiated <class 'torch.utils.data.sampler.BatchSampler'>: train_dataloader -> config -> batch_sampler
Instantiated <class 'modalities.models.gpt2.collator.GPT2LLMCollateFn'>: collate_fn
Instantiated <class 'modalities.dataloader.dataloader.LLMDataLoader'>: train_dataloader
Instantiated <class 'int'>: progress_subscriber -> config -> num_target_steps -> config -> global_num_tokens
Instantiated <class 'int'>: progress_subscriber -> config -> num_target_steps
Instantiated <class 'modalities.logging_broker.subscriber_impl.progress_subscriber.RichProgressSubscriber'>: progress_subscriber
Instantiated <class 'modalities.logging_broker.subscriber_impl.results_subscriber.WandBEvaluationResultSubscriber'>: evaluation_subscriber
Instantiated <class 'modalities.checkpointing.checkpoint_saving_strategies.SaveKMostRecentCheckpointsStrategy'>: checkpoint_saving -> config -> checkpoint_saving_strategy
Instantiated <class 'modalities.checkpointing.fsdp.fsdp_checkpoint_saving.FSDP1CheckpointSaving'>: checkpoint_saving -> config -> checkpoint_saving_execution
Instantiated <class 'modalities.checkpointing.checkpoint_saving.CheckpointSaving'>: checkpoint_saving
Instantiated <class 'modalities.training.gradient_clipping.fsdp_gradient_clipper.FSDP1GradientClipper'>: gradient_clipper
Model initialized at 2026-01-01 19:26:12.213544.



======================== Training Report ========================
Training target: 
	num_target_tokens: 5713166336
	num_target_steps: 174352 
Intervals: 
	training_log_interval_in_steps: 100
	checkpointing_interval_in_steps: 5000
	evaluation_interval_in_steps: 1000
Step profile: 
	gradient_accumulation_steps: 4
	local_train_micro_batch_size: 4
	sequence_length: 512
	dp_degree: 4
CUDA environment settings: 
	local_rank: 0
	world_size: 4
	global_rank: 0
Consistency enforcement: 
	enforce_tokens_per_step_consistency: True
	enforce_last_step_logged: False
	enforce_last_step_evaluated: False
	enforce_last_step_checkpointed: False
Training progress: 
	global_num_seen_tokens: 0
	num_seen_steps: 0
	num_seen_samples: 0
	last_step: -1
Warnings: 
	[38;5;214mNumber of tokens in the dataset (5713177600) does not match the number of target tokens (5713166336). Missing 0.00% of tokens in the dataset.
	Last step will not be logged. Since remaining_steps (174352) is not a multiple of training_log_interval_in_steps (100).
	Last step will not be evaluated. Since remaining_steps (174352) is not a multiple of evaluation_interval_in_steps (1000).
	Last step will not be checkpointed. Since remaining_steps (174352) is not a multiple of checkpointing_interval_in_steps (5000). [0m 
====================================================================



Start model training at 2026-01-01 19:26:12.213815.
2026-01-01T19:26:42 | step: 100 | train samples/s: 244.7 | train mfu (16-bit): -1.0 | lr mean: 5.36468678546953e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 4.29 | train loss last: 4.28 | consumed tokens: 3276800.0 | grad norm avg: 1.8 | grad norm last: 1.68 | 
2026-01-01T19:27:11 | step: 200 | train samples/s: 254.1 | train mfu (16-bit): -1.0 | lr mean: 6.446925453928998e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 4.18 | train loss last: 4.29 | consumed tokens: 6553600.0 | grad norm avg: 1.39 | grad norm last: 1.3 | 
2026-01-01T19:27:39 | step: 300 | train samples/s: 265.0 | train mfu (16-bit): -1.0 | lr mean: 8.21163303044159e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 4.14 | train loss last: 4.04 | consumed tokens: 9830400.0 | grad norm avg: 1.32 | grad norm last: 1.36 | 
2026-01-01T19:28:07 | step: 400 | train samples/s: 268.5 | train mfu (16-bit): -1.0 | lr mean: 1.0601604117255192e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 4.1 | train loss last: 3.94 | consumed tokens: 13107200.0 | grad norm avg: 1.25 | grad norm last: 1.27 | 
2026-01-01T19:28:36 | step: 500 | train samples/s: 264.0 | train mfu (16-bit): -1.0 | lr mean: 1.3539362953451928e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 4.08 | train loss last: 4.22 | consumed tokens: 16384000.0 | grad norm avg: 1.2 | grad norm last: 1.11 | 
2026-01-01T19:29:04 | step: 600 | train samples/s: 279.9 | train mfu (16-bit): -1.0 | lr mean: 1.692967998678796e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 4.06 | train loss last: 3.68 | consumed tokens: 19660800.0 | grad norm avg: 1.14 | grad norm last: 1.09 | 
2026-01-01T19:29:32 | step: 700 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 2.0662650058511645e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 4.02 | train loss last: 3.83 | consumed tokens: 22937600.0 | grad norm avg: 1.06 | grad norm last: 1.02 | 
2026-01-01T19:29:59 | step: 800 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 2.461726217006799e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.98 | train loss last: 3.96 | consumed tokens: 26214400.0 | grad norm avg: 0.98 | grad norm last: 0.94 | 
2026-01-01T19:30:27 | step: 900 | train samples/s: 278.1 | train mfu (16-bit): -1.0 | lr mean: 2.86653248622315e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.95 | train loss last: 3.73 | consumed tokens: 29491200.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-01T19:30:55 | step: 1000 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 3.2675612601451576e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.91 | train loss last: 3.91 | consumed tokens: 32768000.0 | grad norm avg: 0.86 | grad norm last: 0.78 | 
2026-01-01T19:31:23 | step: 1100 | train samples/s: 278.0 | train mfu (16-bit): -1.0 | lr mean: 3.651812221505679e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.9 | train loss last: 3.89 | consumed tokens: 36044800.0 | grad norm avg: 0.81 | grad norm last: 0.8 | 
2026-01-01T19:31:51 | step: 1200 | train samples/s: 274.7 | train mfu (16-bit): -1.0 | lr mean: 4.006829476566054e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.87 | train loss last: 3.95 | consumed tokens: 39321600.0 | grad norm avg: 0.78 | grad norm last: 0.72 | 
2026-01-01T19:32:19 | step: 1300 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 4.321104643167928e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.85 | train loss last: 4.15 | consumed tokens: 42598400.0 | grad norm avg: 0.74 | grad norm last: 0.76 | 
2026-01-01T19:32:47 | step: 1400 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 4.5844499254599214e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.83 | train loss last: 4.06 | consumed tokens: 45875200.0 | grad norm avg: 0.72 | grad norm last: 0.69 | 
2026-01-01T19:33:14 | step: 1500 | train samples/s: 279.5 | train mfu (16-bit): -1.0 | lr mean: 4.788328806171194e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.82 | train loss last: 3.84 | consumed tokens: 49152000.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T19:33:42 | step: 1600 | train samples/s: 277.4 | train mfu (16-bit): -1.0 | lr mean: 4.926131805405021e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.79 | train loss last: 3.86 | consumed tokens: 52428800.0 | grad norm avg: 0.67 | grad norm last: 0.66 | 
2026-01-01T19:34:10 | step: 1700 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 4.9933918489841744e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.77 | train loss last: 3.99 | consumed tokens: 55705600.0 | grad norm avg: 0.66 | grad norm last: 0.66 | 
2026-01-01T19:34:38 | step: 1800 | train samples/s: 275.1 | train mfu (16-bit): -1.0 | lr mean: 4.999998782295734e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.76 | train loss last: 3.85 | consumed tokens: 58982400.0 | grad norm avg: 0.65 | grad norm last: 0.65 | 
2026-01-01T19:35:06 | step: 1900 | train samples/s: 277.8 | train mfu (16-bit): -1.0 | lr mean: 4.999989687348716e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.75 | train loss last: 3.92 | consumed tokens: 62259200.0 | grad norm avg: 0.64 | grad norm last: 0.63 | 
2026-01-01T19:35:34 | step: 2000 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 4.9999725888483226e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.74 | train loss last: 3.65 | consumed tokens: 65536000.0 | grad norm avg: 0.63 | grad norm last: 0.66 | 
2026-01-01T19:36:02 | step: 2100 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 4.999947122996673e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.71 | train loss last: 3.55 | consumed tokens: 68812800.0 | grad norm avg: 0.62 | grad norm last: 0.58 | 
2026-01-01T19:36:29 | step: 2200 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 4.999913289793767e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.72 | train loss last: 3.6 | consumed tokens: 72089600.0 | grad norm avg: 0.61 | grad norm last: 0.63 | 
2026-01-01T19:36:57 | step: 2300 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 4.9998714530374855e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.7 | train loss last: 3.63 | consumed tokens: 75366400.0 | grad norm avg: 0.61 | grad norm last: 0.6 | 
2026-01-01T19:37:25 | step: 2400 | train samples/s: 275.2 | train mfu (16-bit): -1.0 | lr mean: 4.9998212489299476e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.69 | train loss last: 3.86 | consumed tokens: 78643200.0 | grad norm avg: 0.61 | grad norm last: 0.6 | 
2026-01-01T19:37:53 | step: 2500 | train samples/s: 275.0 | train mfu (16-bit): -1.0 | lr mean: 4.9997626774711534e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.67 | train loss last: 3.54 | consumed tokens: 81920000.0 | grad norm avg: 0.6 | grad norm last: 0.61 | 
2026-01-01T19:38:21 | step: 2600 | train samples/s: 280.7 | train mfu (16-bit): -1.0 | lr mean: 4.999695738661103e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.67 | train loss last: 3.5 | consumed tokens: 85196800.0 | grad norm avg: 0.61 | grad norm last: 0.58 | 
2026-01-01T19:38:49 | step: 2700 | train samples/s: 280.2 | train mfu (16-bit): -1.0 | lr mean: 4.999620796297677e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.65 | train loss last: 3.64 | consumed tokens: 88473600.0 | grad norm avg: 0.6 | grad norm last: 0.63 | 
2026-01-01T19:39:17 | step: 2800 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 4.9995374865829945e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.66 | train loss last: 3.95 | consumed tokens: 91750400.0 | grad norm avg: 0.59 | grad norm last: 0.63 | 
2026-01-01T19:39:44 | step: 2900 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 4.999445809517056e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.64 | train loss last: 3.51 | consumed tokens: 95027200.0 | grad norm avg: 0.61 | grad norm last: 0.69 | 
2026-01-01T19:40:12 | step: 3000 | train samples/s: 280.2 | train mfu (16-bit): -1.0 | lr mean: 4.999345765099861e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.65 | train loss last: 3.56 | consumed tokens: 98304000.0 | grad norm avg: 0.6 | grad norm last: 0.58 | 
2026-01-01T19:40:40 | step: 3100 | train samples/s: 275.2 | train mfu (16-bit): -1.0 | lr mean: 4.99923771712929e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.65 | train loss last: 3.93 | consumed tokens: 101580800.0 | grad norm avg: 0.6 | grad norm last: 0.59 | 
2026-01-01T19:41:09 | step: 3200 | train samples/s: 274.7 | train mfu (16-bit): -1.0 | lr mean: 4.999121301807463e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.62 | train loss last: 3.7 | consumed tokens: 104857600.0 | grad norm avg: 0.59 | grad norm last: 0.58 | 
2026-01-01T19:41:36 | step: 3300 | train samples/s: 280.1 | train mfu (16-bit): -1.0 | lr mean: 4.99899651913438e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.61 | train loss last: 3.54 | consumed tokens: 108134400.0 | grad norm avg: 0.59 | grad norm last: 0.6 | 
2026-01-01T19:42:04 | step: 3400 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 4.998863732907921e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.6 | train loss last: 3.85 | consumed tokens: 111411200.0 | grad norm avg: 0.59 | grad norm last: 0.57 | 
2026-01-01T19:42:32 | step: 3500 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 4.998722579330206e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.6 | train loss last: 3.68 | consumed tokens: 114688000.0 | grad norm avg: 0.59 | grad norm last: 0.54 | 
2026-01-01T19:43:00 | step: 3600 | train samples/s: 280.7 | train mfu (16-bit): -1.0 | lr mean: 4.9985730584012344e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.6 | train loss last: 3.45 | consumed tokens: 117964800.0 | grad norm avg: 0.59 | grad norm last: 0.59 | 
2026-01-01T19:43:27 | step: 3700 | train samples/s: 280.7 | train mfu (16-bit): -1.0 | lr mean: 4.998415170121007e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.59 | train loss last: 3.61 | consumed tokens: 121241600.0 | grad norm avg: 0.58 | grad norm last: 0.55 | 
2026-01-01T19:43:55 | step: 3800 | train samples/s: 277.7 | train mfu (16-bit): -1.0 | lr mean: 4.9982489144895226e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.6 | train loss last: 3.68 | consumed tokens: 124518400.0 | grad norm avg: 0.59 | grad norm last: 0.62 | 
2026-01-01T19:44:24 | step: 3900 | train samples/s: 272.7 | train mfu (16-bit): -1.0 | lr mean: 4.998074655304663e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.6 | train loss last: 3.46 | consumed tokens: 127795200.0 | grad norm avg: 0.6 | grad norm last: 0.71 | 
2026-01-01T19:44:51 | step: 4000 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 4.997892028768547e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.56 | train loss last: 3.56 | consumed tokens: 131072000.0 | grad norm avg: 0.59 | grad norm last: 0.59 | 
2026-01-01T19:45:19 | step: 4100 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 4.997701398679055e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.58 | train loss last: 3.52 | consumed tokens: 134348800.0 | grad norm avg: 0.59 | grad norm last: 0.58 | 
2026-01-01T19:45:47 | step: 4200 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 4.9975020374404266e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.56 | train loss last: 3.57 | consumed tokens: 137625600.0 | grad norm avg: 0.59 | grad norm last: 0.56 | 
2026-01-01T19:46:15 | step: 4300 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 4.9972946726484224e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.57 | train loss last: 3.38 | consumed tokens: 140902400.0 | grad norm avg: 0.59 | grad norm last: 0.65 | 
2026-01-01T19:46:42 | step: 4400 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 4.9970793043030426e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.57 | train loss last: 3.41 | consumed tokens: 144179200.0 | grad norm avg: 0.59 | grad norm last: 0.62 | 
2026-01-01T19:47:10 | step: 4500 | train samples/s: 278.0 | train mfu (16-bit): -1.0 | lr mean: 4.996855204808526e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.57 | train loss last: 3.51 | consumed tokens: 147456000.0 | grad norm avg: 0.59 | grad norm last: 0.6 | 
2026-01-01T19:47:39 | step: 4600 | train samples/s: 272.6 | train mfu (16-bit): -1.0 | lr mean: 4.996623101760633e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.54 | train loss last: 3.45 | consumed tokens: 150732800.0 | grad norm avg: 0.59 | grad norm last: 0.67 | 
2026-01-01T19:48:07 | step: 4700 | train samples/s: 279.5 | train mfu (16-bit): -1.0 | lr mean: 4.9963826313614845e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.56 | train loss last: 3.48 | consumed tokens: 154009600.0 | grad norm avg: 0.59 | grad norm last: 0.57 | 
2026-01-01T19:48:34 | step: 4800 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 4.9961337936110795e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.54 | train loss last: 3.48 | consumed tokens: 157286400.0 | grad norm avg: 0.6 | grad norm last: 0.6 | 
2026-01-01T19:49:02 | step: 4900 | train samples/s: 280.7 | train mfu (16-bit): -1.0 | lr mean: 4.995876952307299e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.55 | train loss last: 3.44 | consumed tokens: 160563200.0 | grad norm avg: 0.59 | grad norm last: 0.56 | 
2026-01-01T19:49:30 | step: 5000 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 4.995611743652262e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.53 | train loss last: 3.58 | consumed tokens: 163840000.0 | grad norm avg: 0.61 | grad norm last: 0.59 | 
2026-01-01T19:50:00 | step: 5100 | train samples/s: 276.7 | train mfu (16-bit): -1.0 | lr mean: 4.9953381676459685e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.52 | train loss last: 3.28 | consumed tokens: 167116800.0 | grad norm avg: 0.59 | grad norm last: 0.56 | 
2026-01-01T19:50:28 | step: 5200 | train samples/s: 276.4 | train mfu (16-bit): -1.0 | lr mean: 4.9950565880862996e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.53 | train loss last: 3.61 | consumed tokens: 170393600.0 | grad norm avg: 0.6 | grad norm last: 0.64 | 
2026-01-01T19:50:56 | step: 5300 | train samples/s: 276.5 | train mfu (16-bit): -1.0 | lr mean: 4.9947666411753744e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.53 | train loss last: 3.5 | consumed tokens: 173670400.0 | grad norm avg: 0.6 | grad norm last: 0.63 | 
2026-01-01T19:51:24 | step: 5400 | train samples/s: 277.2 | train mfu (16-bit): -1.0 | lr mean: 4.994468326913193e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.52 | train loss last: 3.55 | consumed tokens: 176947200.0 | grad norm avg: 0.6 | grad norm last: 0.61 | 
2026-01-01T19:51:51 | step: 5500 | train samples/s: 279.2 | train mfu (16-bit): -1.0 | lr mean: 4.994162009097636e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.52 | train loss last: 3.46 | consumed tokens: 180224000.0 | grad norm avg: 0.59 | grad norm last: 0.57 | 
2026-01-01T19:52:19 | step: 5600 | train samples/s: 279.4 | train mfu (16-bit): -1.0 | lr mean: 4.9938469601329416e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.51 | train loss last: 3.54 | consumed tokens: 183500800.0 | grad norm avg: 0.6 | grad norm last: 0.55 | 
2026-01-01T19:52:47 | step: 5700 | train samples/s: 276.9 | train mfu (16-bit): -1.0 | lr mean: 4.9935242714127526e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.5 | train loss last: 3.46 | consumed tokens: 186777600.0 | grad norm avg: 0.61 | grad norm last: 0.56 | 
2026-01-01T19:53:15 | step: 5800 | train samples/s: 279.5 | train mfu (16-bit): -1.0 | lr mean: 4.9931928515434265e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.51 | train loss last: 3.49 | consumed tokens: 190054400.0 | grad norm avg: 0.6 | grad norm last: 0.55 | 
2026-01-01T19:53:43 | step: 5900 | train samples/s: 276.3 | train mfu (16-bit): -1.0 | lr mean: 4.992853428120725e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.5 | train loss last: 3.36 | consumed tokens: 193331200.0 | grad norm avg: 0.61 | grad norm last: 0.57 | 
2026-01-01T19:54:11 | step: 6000 | train samples/s: 277.0 | train mfu (16-bit): -1.0 | lr mean: 4.992505637346767e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.51 | train loss last: 3.48 | consumed tokens: 196608000.0 | grad norm avg: 0.61 | grad norm last: 0.6 | 
2026-01-01T19:54:39 | step: 6100 | train samples/s: 279.9 | train mfu (16-bit): -1.0 | lr mean: 4.9921494792215526e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.49 | train loss last: 3.27 | consumed tokens: 199884800.0 | grad norm avg: 0.6 | grad norm last: 0.57 | 
2026-01-01T19:55:07 | step: 6200 | train samples/s: 277.5 | train mfu (16-bit): -1.0 | lr mean: 4.991785317542963e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.5 | train loss last: 3.54 | consumed tokens: 203161600.0 | grad norm avg: 0.6 | grad norm last: 0.57 | 
2026-01-01T19:55:35 | step: 6300 | train samples/s: 279.6 | train mfu (16-bit): -1.0 | lr mean: 4.9914127885131165e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.5 | train loss last: 3.5 | consumed tokens: 206438400.0 | grad norm avg: 0.6 | grad norm last: 0.61 | 
2026-01-01T19:56:03 | step: 6400 | train samples/s: 276.9 | train mfu (16-bit): -1.0 | lr mean: 4.991031892132014e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.49 | train loss last: 3.6 | consumed tokens: 209715200.0 | grad norm avg: 0.6 | grad norm last: 0.55 | 
2026-01-01T19:56:31 | step: 6500 | train samples/s: 279.7 | train mfu (16-bit): -1.0 | lr mean: 4.990642992197536e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.5 | train loss last: 3.73 | consumed tokens: 212992000.0 | grad norm avg: 0.61 | grad norm last: 0.58 | 
2026-01-01T19:56:59 | step: 6600 | train samples/s: 273.9 | train mfu (16-bit): -1.0 | lr mean: 4.9902457249118015e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.48 | train loss last: 3.71 | consumed tokens: 216268800.0 | grad norm avg: 0.6 | grad norm last: 0.58 | 
2026-01-01T19:57:27 | step: 6700 | train samples/s: 279.5 | train mfu (16-bit): -1.0 | lr mean: 4.9898404540726915e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.49 | train loss last: 3.34 | consumed tokens: 219545600.0 | grad norm avg: 0.61 | grad norm last: 0.61 | 
2026-01-01T19:57:55 | step: 6800 | train samples/s: 279.7 | train mfu (16-bit): -1.0 | lr mean: 4.989426815882325e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.48 | train loss last: 3.39 | consumed tokens: 222822400.0 | grad norm avg: 0.61 | grad norm last: 0.57 | 
2026-01-01T19:58:23 | step: 6900 | train samples/s: 277.4 | train mfu (16-bit): -1.0 | lr mean: 4.9890048103407025e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.45 | train loss last: 3.38 | consumed tokens: 226099200.0 | grad norm avg: 0.6 | grad norm last: 0.64 | 
2026-01-01T19:58:50 | step: 7000 | train samples/s: 279.9 | train mfu (16-bit): -1.0 | lr mean: 4.9885744374478236e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.46 | train loss last: 3.48 | consumed tokens: 229376000.0 | grad norm avg: 0.61 | grad norm last: 0.57 | 
2026-01-01T19:59:18 | step: 7100 | train samples/s: 273.8 | train mfu (16-bit): -1.0 | lr mean: 4.988136061001569e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.47 | train loss last: 3.68 | consumed tokens: 232652800.0 | grad norm avg: 0.62 | grad norm last: 0.55 | 
2026-01-01T19:59:46 | step: 7200 | train samples/s: 273.3 | train mfu (16-bit): -1.0 | lr mean: 4.987689317204058e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.47 | train loss last: 3.38 | consumed tokens: 235929600.0 | grad norm avg: 0.61 | grad norm last: 0.54 | 
2026-01-01T20:00:15 | step: 7300 | train samples/s: 262.2 | train mfu (16-bit): -1.0 | lr mean: 4.987234569853172e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.47 | train loss last: 3.41 | consumed tokens: 239206400.0 | grad norm avg: 0.6 | grad norm last: 0.53 | 
2026-01-01T20:00:43 | step: 7400 | train samples/s: 265.5 | train mfu (16-bit): -1.0 | lr mean: 4.986771455151029e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.44 | train loss last: 3.26 | consumed tokens: 242483200.0 | grad norm avg: 0.61 | grad norm last: 0.58 | 
2026-01-01T20:01:11 | step: 7500 | train samples/s: 273.1 | train mfu (16-bit): -1.0 | lr mean: 4.98629997309763e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.46 | train loss last: 3.29 | consumed tokens: 245760000.0 | grad norm avg: 0.61 | grad norm last: 0.55 | 
2026-01-01T20:01:39 | step: 7600 | train samples/s: 268.6 | train mfu (16-bit): -1.0 | lr mean: 4.985820487490855e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.45 | train loss last: 3.37 | consumed tokens: 249036800.0 | grad norm avg: 0.61 | grad norm last: 0.59 | 
2026-01-01T20:02:08 | step: 7700 | train samples/s: 261.8 | train mfu (16-bit): -1.0 | lr mean: 4.985332634532824e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.44 | train loss last: 3.54 | consumed tokens: 252313600.0 | grad norm avg: 0.61 | grad norm last: 0.61 | 
2026-01-01T20:02:36 | step: 7800 | train samples/s: 266.8 | train mfu (16-bit): -1.0 | lr mean: 4.9848367780214176e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.45 | train loss last: 3.26 | consumed tokens: 255590400.0 | grad norm avg: 0.62 | grad norm last: 0.58 | 
2026-01-01T20:03:05 | step: 7900 | train samples/s: 266.7 | train mfu (16-bit): -1.0 | lr mean: 4.9843325541587546e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.45 | train loss last: 3.45 | consumed tokens: 258867200.0 | grad norm avg: 0.61 | grad norm last: 0.6 | 
2026-01-01T20:03:34 | step: 8000 | train samples/s: 260.3 | train mfu (16-bit): -1.0 | lr mean: 4.9838199629448354e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.45 | train loss last: 3.37 | consumed tokens: 262144000.0 | grad norm avg: 0.61 | grad norm last: 0.66 | 
2026-01-01T20:04:02 | step: 8100 | train samples/s: 269.0 | train mfu (16-bit): -1.0 | lr mean: 4.9832993681775406e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.45 | train loss last: 3.51 | consumed tokens: 265420800.0 | grad norm avg: 0.61 | grad norm last: 0.65 | 
2026-01-01T20:04:30 | step: 8200 | train samples/s: 271.5 | train mfu (16-bit): -1.0 | lr mean: 4.9827704060589895e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.45 | train loss last: 3.32 | consumed tokens: 268697600.0 | grad norm avg: 0.62 | grad norm last: 0.59 | 
2026-01-01T20:04:57 | step: 8300 | train samples/s: 276.9 | train mfu (16-bit): -1.0 | lr mean: 4.982233076589182e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.44 | train loss last: 3.62 | consumed tokens: 271974400.0 | grad norm avg: 0.61 | grad norm last: 0.6 | 
2026-01-01T20:05:26 | step: 8400 | train samples/s: 261.7 | train mfu (16-bit): -1.0 | lr mean: 4.981687743565999e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.43 | train loss last: 3.55 | consumed tokens: 275251200.0 | grad norm avg: 0.61 | grad norm last: 0.58 | 
2026-01-01T20:05:55 | step: 8500 | train samples/s: 266.3 | train mfu (16-bit): -1.0 | lr mean: 4.98113440698944e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.44 | train loss last: 3.62 | consumed tokens: 278528000.0 | grad norm avg: 0.61 | grad norm last: 0.64 | 
2026-01-01T20:06:23 | step: 8600 | train samples/s: 263.7 | train mfu (16-bit): -1.0 | lr mean: 4.9805727030616254e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.44 | train loss last: 3.58 | consumed tokens: 281804800.0 | grad norm avg: 0.61 | grad norm last: 0.61 | 
2026-01-01T20:06:52 | step: 8700 | train samples/s: 264.0 | train mfu (16-bit): -1.0 | lr mean: 4.980002631782554e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.42 | train loss last: 3.53 | consumed tokens: 285081600.0 | grad norm avg: 0.61 | grad norm last: 0.56 | 
2026-01-01T20:07:21 | step: 8800 | train samples/s: 267.0 | train mfu (16-bit): -1.0 | lr mean: 4.9794241931522265e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.43 | train loss last: 3.42 | consumed tokens: 288358400.0 | grad norm avg: 0.61 | grad norm last: 0.67 | 
2026-01-01T20:07:49 | step: 8900 | train samples/s: 266.1 | train mfu (16-bit): -1.0 | lr mean: 4.978838114766404e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.45 | train loss last: 3.57 | consumed tokens: 291635200.0 | grad norm avg: 0.61 | grad norm last: 0.59 | 
2026-01-01T20:08:18 | step: 9000 | train samples/s: 265.6 | train mfu (16-bit): -1.0 | lr mean: 4.9782433052314445e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.43 | train loss last: 3.45 | consumed tokens: 294912000.0 | grad norm avg: 0.6 | grad norm last: 0.61 | 
2026-01-01T20:08:47 | step: 9100 | train samples/s: 262.4 | train mfu (16-bit): -1.0 | lr mean: 4.9776404921431094e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.42 | train loss last: 3.36 | consumed tokens: 298188800.0 | grad norm avg: 0.6 | grad norm last: 0.59 | 
2026-01-01T20:09:15 | step: 9200 | train samples/s: 264.5 | train mfu (16-bit): -1.0 | lr mean: 4.977029675501399e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.43 | train loss last: 3.32 | consumed tokens: 301465600.0 | grad norm avg: 0.61 | grad norm last: 0.63 | 
2026-01-01T20:09:44 | step: 9300 | train samples/s: 261.3 | train mfu (16-bit): -1.0 | lr mean: 4.976410491508432e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.42 | train loss last: 3.5 | consumed tokens: 304742400.0 | grad norm avg: 0.61 | grad norm last: 0.65 | 
2026-01-01T20:10:13 | step: 9400 | train samples/s: 267.3 | train mfu (16-bit): -1.0 | lr mean: 4.9757829401642084e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.43 | train loss last: 3.55 | consumed tokens: 308019200.0 | grad norm avg: 0.6 | grad norm last: 0.62 | 
2026-01-01T20:10:41 | step: 9500 | train samples/s: 266.5 | train mfu (16-bit): -1.0 | lr mean: 4.9751473852666095e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.42 | train loss last: 3.71 | consumed tokens: 311296000.0 | grad norm avg: 0.61 | grad norm last: 0.6 | 
2026-01-01T20:11:10 | step: 9600 | train samples/s: 266.8 | train mfu (16-bit): -1.0 | lr mean: 4.974503826815635e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.42 | train loss last: 3.26 | consumed tokens: 314572800.0 | grad norm avg: 0.61 | grad norm last: 0.61 | 
2026-01-01T20:11:39 | step: 9700 | train samples/s: 263.5 | train mfu (16-bit): -1.0 | lr mean: 4.973851901013404e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.41 | train loss last: 3.5 | consumed tokens: 317849600.0 | grad norm avg: 0.61 | grad norm last: 0.64 | 
2026-01-01T20:12:07 | step: 9800 | train samples/s: 265.6 | train mfu (16-bit): -1.0 | lr mean: 4.973191607859917e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.42 | train loss last: 3.43 | consumed tokens: 321126400.0 | grad norm avg: 0.62 | grad norm last: 0.61 | 
2026-01-01T20:12:36 | step: 9900 | train samples/s: 264.0 | train mfu (16-bit): -1.0 | lr mean: 4.972523311153054e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.42 | train loss last: 3.14 | consumed tokens: 324403200.0 | grad norm avg: 0.61 | grad norm last: 0.84 | 
2026-01-01T20:13:05 | step: 10000 | train samples/s: 259.9 | train mfu (16-bit): -1.0 | lr mean: 4.971846647094935e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.43 | train loss last: 3.47 | consumed tokens: 327680000.0 | grad norm avg: 0.62 | grad norm last: 0.53 | 
2026-01-01T20:13:35 | step: 10100 | train samples/s: 267.2 | train mfu (16-bit): -1.0 | lr mean: 4.9711619794834405e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.4 | train loss last: 3.2 | consumed tokens: 330956800.0 | grad norm avg: 0.61 | grad norm last: 0.61 | 
2026-01-01T20:14:04 | step: 10200 | train samples/s: 266.7 | train mfu (16-bit): -1.0 | lr mean: 4.97046930831857e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.4 | train loss last: 3.4 | consumed tokens: 334233600.0 | grad norm avg: 0.61 | grad norm last: 0.61 | 
2026-01-01T20:14:32 | step: 10300 | train samples/s: 266.3 | train mfu (16-bit): -1.0 | lr mean: 4.969768269802444e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.4 | train loss last: 3.51 | consumed tokens: 337510400.0 | grad norm avg: 0.61 | grad norm last: 0.63 | 
2026-01-01T20:15:01 | step: 10400 | train samples/s: 264.8 | train mfu (16-bit): -1.0 | lr mean: 4.969058863935061e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.4 | train loss last: 3.23 | consumed tokens: 340787200.0 | grad norm avg: 0.62 | grad norm last: 0.71 | 
2026-01-01T20:15:29 | step: 10500 | train samples/s: 264.3 | train mfu (16-bit): -1.0 | lr mean: 4.968341454514302e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.41 | train loss last: 3.16 | consumed tokens: 344064000.0 | grad norm avg: 0.6 | grad norm last: 0.56 | 
2026-01-01T20:15:58 | step: 10600 | train samples/s: 261.1 | train mfu (16-bit): -1.0 | lr mean: 4.967616041540168e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.39 | train loss last: 3.6 | consumed tokens: 347340800.0 | grad norm avg: 0.6 | grad norm last: 0.61 | 
2026-01-01T20:16:27 | step: 10700 | train samples/s: 262.5 | train mfu (16-bit): -1.0 | lr mean: 4.966882261214778e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.39 | train loss last: 3.63 | consumed tokens: 350617600.0 | grad norm avg: 0.61 | grad norm last: 0.57 | 
2026-01-01T20:16:56 | step: 10800 | train samples/s: 264.7 | train mfu (16-bit): -1.0 | lr mean: 4.966140477336012e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.38 | train loss last: 3.46 | consumed tokens: 353894400.0 | grad norm avg: 0.62 | grad norm last: 0.68 | 
2026-01-01T20:17:24 | step: 10900 | train samples/s: 266.5 | train mfu (16-bit): -1.0 | lr mean: 4.9653903261059895e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.39 | train loss last: 3.41 | consumed tokens: 357171200.0 | grad norm avg: 0.61 | grad norm last: 0.61 | 
2026-01-01T20:17:53 | step: 11000 | train samples/s: 266.5 | train mfu (16-bit): -1.0 | lr mean: 4.9646321713225916e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.41 | train loss last: 3.54 | consumed tokens: 360448000.0 | grad norm avg: 0.62 | grad norm last: 0.58 | 
2026-01-01T20:18:22 | step: 11100 | train samples/s: 263.8 | train mfu (16-bit): -1.0 | lr mean: 4.9638656491879374e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.38 | train loss last: 3.72 | consumed tokens: 363724800.0 | grad norm avg: 0.62 | grad norm last: 0.63 | 
2026-01-01T20:18:50 | step: 11200 | train samples/s: 265.1 | train mfu (16-bit): -1.0 | lr mean: 4.9630911234999076e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.4 | train loss last: 3.15 | consumed tokens: 367001600.0 | grad norm avg: 0.61 | grad norm last: 0.62 | 
2026-01-01T20:19:19 | step: 11300 | train samples/s: 259.3 | train mfu (16-bit): -1.0 | lr mean: 4.962308594258502e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.39 | train loss last: 3.38 | consumed tokens: 370278400.0 | grad norm avg: 0.62 | grad norm last: 0.7 | 
2026-01-01T20:19:48 | step: 11400 | train samples/s: 261.4 | train mfu (16-bit): -1.0 | lr mean: 4.9615176976658404e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.38 | train loss last: 3.25 | consumed tokens: 373555200.0 | grad norm avg: 0.62 | grad norm last: 0.68 | 
2026-01-01T20:20:17 | step: 11500 | train samples/s: 266.3 | train mfu (16-bit): -1.0 | lr mean: 4.960718797519803e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.38 | train loss last: 3.52 | consumed tokens: 376832000.0 | grad norm avg: 0.61 | grad norm last: 0.62 | 
2026-01-01T20:20:45 | step: 11600 | train samples/s: 263.7 | train mfu (16-bit): -1.0 | lr mean: 4.9599115300225094e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.37 | train loss last: 3.12 | consumed tokens: 380108800.0 | grad norm avg: 0.62 | grad norm last: 0.64 | 
2026-01-01T20:21:14 | step: 11700 | train samples/s: 264.5 | train mfu (16-bit): -1.0 | lr mean: 4.959096622769721e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.38 | train loss last: 3.43 | consumed tokens: 383385600.0 | grad norm avg: 0.61 | grad norm last: 0.57 | 
2026-01-01T20:21:42 | step: 11800 | train samples/s: 264.9 | train mfu (16-bit): -1.0 | lr mean: 4.958272984367795e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.38 | train loss last: 3.21 | consumed tokens: 386662400.0 | grad norm avg: 0.61 | grad norm last: 0.66 | 
2026-01-01T20:22:11 | step: 11900 | train samples/s: 265.2 | train mfu (16-bit): -1.0 | lr mean: 4.957441706210375e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.38 | train loss last: 3.1 | consumed tokens: 389939200.0 | grad norm avg: 0.61 | grad norm last: 0.61 | 
2026-01-01T20:22:40 | step: 12000 | train samples/s: 262.4 | train mfu (16-bit): -1.0 | lr mean: 4.956602060701698e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.38 | train loss last: 3.27 | consumed tokens: 393216000.0 | grad norm avg: 0.62 | grad norm last: 0.65 | 
2026-01-01T20:23:09 | step: 12100 | train samples/s: 262.2 | train mfu (16-bit): -1.0 | lr mean: 4.955754047841765e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.38 | train loss last: 3.39 | consumed tokens: 396492800.0 | grad norm avg: 0.61 | grad norm last: 0.71 | 
2026-01-01T20:23:37 | step: 12200 | train samples/s: 266.4 | train mfu (16-bit): -1.0 | lr mean: 4.954898395226337e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.37 | train loss last: 3.18 | consumed tokens: 399769600.0 | grad norm avg: 0.62 | grad norm last: 0.59 | 
2026-01-01T20:24:06 | step: 12300 | train samples/s: 265.9 | train mfu (16-bit): -1.0 | lr mean: 4.954034375259653e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.37 | train loss last: 3.5 | consumed tokens: 403046400.0 | grad norm avg: 0.62 | grad norm last: 0.54 | 
2026-01-01T20:24:35 | step: 12400 | train samples/s: 263.0 | train mfu (16-bit): -1.0 | lr mean: 4.953161987941712e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.38 | train loss last: 3.57 | consumed tokens: 406323200.0 | grad norm avg: 0.62 | grad norm last: 0.54 | 
2026-01-01T20:25:03 | step: 12500 | train samples/s: 265.7 | train mfu (16-bit): -1.0 | lr mean: 4.952281597070396e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.38 | train loss last: 3.41 | consumed tokens: 409600000.0 | grad norm avg: 0.61 | grad norm last: 0.54 | 
2026-01-01T20:25:32 | step: 12600 | train samples/s: 267.4 | train mfu (16-bit): -1.0 | lr mean: 4.951393566443585e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.36 | train loss last: 3.26 | consumed tokens: 412876800.0 | grad norm avg: 0.6 | grad norm last: 0.57 | 
2026-01-01T20:26:00 | step: 12700 | train samples/s: 265.5 | train mfu (16-bit): -1.0 | lr mean: 4.950496804667637e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.38 | train loss last: 3.39 | consumed tokens: 416153600.0 | grad norm avg: 0.62 | grad norm last: 0.61 | 
2026-01-01T20:26:29 | step: 12800 | train samples/s: 265.0 | train mfu (16-bit): -1.0 | lr mean: 4.949592403136194e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.37 | train loss last: 3.36 | consumed tokens: 419430400.0 | grad norm avg: 0.61 | grad norm last: 0.6 | 
2026-01-01T20:26:57 | step: 12900 | train samples/s: 265.3 | train mfu (16-bit): -1.0 | lr mean: 4.9486796342534944e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.38 | train loss last: 3.43 | consumed tokens: 422707200.0 | grad norm avg: 0.61 | grad norm last: 0.63 | 
2026-01-01T20:27:26 | step: 13000 | train samples/s: 264.4 | train mfu (16-bit): -1.0 | lr mean: 4.9477588618174195e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.37 | train loss last: 3.45 | consumed tokens: 425984000.0 | grad norm avg: 0.61 | grad norm last: 0.58 | 
2026-01-01T20:27:54 | step: 13100 | train samples/s: 267.5 | train mfu (16-bit): -1.0 | lr mean: 4.946829722030088e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.37 | train loss last: 3.17 | consumed tokens: 429260800.0 | grad norm avg: 0.61 | grad norm last: 0.64 | 
2026-01-01T20:28:23 | step: 13200 | train samples/s: 266.4 | train mfu (16-bit): -1.0 | lr mean: 4.945892942487262e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.36 | train loss last: 3.21 | consumed tokens: 432537600.0 | grad norm avg: 0.61 | grad norm last: 0.67 | 
2026-01-01T20:28:52 | step: 13300 | train samples/s: 260.9 | train mfu (16-bit): -1.0 | lr mean: 4.94494779559318e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.37 | train loss last: 2.98 | consumed tokens: 435814400.0 | grad norm avg: 0.62 | grad norm last: 0.61 | 
2026-01-01T20:29:20 | step: 13400 | train samples/s: 266.5 | train mfu (16-bit): -1.0 | lr mean: 4.943994645145722e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.36 | train loss last: 3.33 | consumed tokens: 439091200.0 | grad norm avg: 0.61 | grad norm last: 0.6 | 
2026-01-01T20:29:49 | step: 13500 | train samples/s: 264.3 | train mfu (16-bit): -1.0 | lr mean: 4.9430331273470074e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.35 | train loss last: 3.32 | consumed tokens: 442368000.0 | grad norm avg: 0.61 | grad norm last: 0.64 | 
2026-01-01T20:30:17 | step: 13600 | train samples/s: 267.5 | train mfu (16-bit): -1.0 | lr mean: 4.942063969792798e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.36 | train loss last: 3.55 | consumed tokens: 445644800.0 | grad norm avg: 0.61 | grad norm last: 0.56 | 
2026-01-01T20:30:46 | step: 13700 | train samples/s: 261.9 | train mfu (16-bit): -1.0 | lr mean: 4.9410864448873326e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.36 | train loss last: 3.38 | consumed tokens: 448921600.0 | grad norm avg: 0.61 | grad norm last: 0.63 | 
2026-01-01T20:31:15 | step: 13800 | train samples/s: 268.7 | train mfu (16-bit): -1.0 | lr mean: 4.9401009164284915e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.35 | train loss last: 3.27 | consumed tokens: 452198400.0 | grad norm avg: 0.6 | grad norm last: 0.66 | 
2026-01-01T20:31:43 | step: 13900 | train samples/s: 267.8 | train mfu (16-bit): -1.0 | lr mean: 4.939107384416275e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.34 | train loss last: 3.15 | consumed tokens: 455475200.0 | grad norm avg: 0.61 | grad norm last: 0.66 | 
2026-01-01T20:32:12 | step: 14000 | train samples/s: 264.5 | train mfu (16-bit): -1.0 | lr mean: 4.938105485052802e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.36 | train loss last: 3.16 | consumed tokens: 458752000.0 | grad norm avg: 0.62 | grad norm last: 0.64 | 
2026-01-01T20:32:41 | step: 14100 | train samples/s: 264.1 | train mfu (16-bit): -1.0 | lr mean: 4.937095945933834e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.36 | train loss last: 3.28 | consumed tokens: 462028800.0 | grad norm avg: 0.6 | grad norm last: 0.56 | 
2026-01-01T20:33:09 | step: 14200 | train samples/s: 265.8 | train mfu (16-bit): -1.0 | lr mean: 4.9360780394636095e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.35 | train loss last: 3.29 | consumed tokens: 465305600.0 | grad norm avg: 0.61 | grad norm last: 0.62 | 
2026-01-01T20:33:38 | step: 14300 | train samples/s: 263.8 | train mfu (16-bit): -1.0 | lr mean: 4.9350521294400096e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.34 | train loss last: 3.28 | consumed tokens: 468582400.0 | grad norm avg: 0.61 | grad norm last: 0.64 | 
2026-01-01T20:34:07 | step: 14400 | train samples/s: 264.7 | train mfu (16-bit): -1.0 | lr mean: 4.934018215863034e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.35 | train loss last: 3.27 | consumed tokens: 471859200.0 | grad norm avg: 0.6 | grad norm last: 0.52 | 
2026-01-01T20:34:35 | step: 14500 | train samples/s: 267.5 | train mfu (16-bit): -1.0 | lr mean: 4.932976298732683e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.34 | train loss last: 3.27 | consumed tokens: 475136000.0 | grad norm avg: 0.61 | grad norm last: 0.61 | 
2026-01-01T20:35:04 | step: 14600 | train samples/s: 266.5 | train mfu (16-bit): -1.0 | lr mean: 4.9319263780489564e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.33 | train loss last: 3.48 | consumed tokens: 478412800.0 | grad norm avg: 0.61 | grad norm last: 0.7 | 
2026-01-01T20:35:33 | step: 14700 | train samples/s: 263.5 | train mfu (16-bit): -1.0 | lr mean: 4.9308680900139734e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.34 | train loss last: 3.02 | consumed tokens: 481689600.0 | grad norm avg: 0.6 | grad norm last: 0.58 | 
2026-01-01T20:36:01 | step: 14800 | train samples/s: 264.0 | train mfu (16-bit): -1.0 | lr mean: 4.9298021622234955e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.35 | train loss last: 3.14 | consumed tokens: 484966400.0 | grad norm avg: 0.6 | grad norm last: 0.63 | 
2026-01-01T20:36:30 | step: 14900 | train samples/s: 269.0 | train mfu (16-bit): -1.0 | lr mean: 4.9287278670817614e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.34 | train loss last: 3.26 | consumed tokens: 488243200.0 | grad norm avg: 0.61 | grad norm last: 0.71 | 
2026-01-01T20:36:58 | step: 15000 | train samples/s: 266.7 | train mfu (16-bit): -1.0 | lr mean: 4.9276455683866516e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.33 | train loss last: 3.16 | consumed tokens: 491520000.0 | grad norm avg: 0.61 | grad norm last: 0.59 | 
2026-01-01T20:37:28 | step: 15100 | train samples/s: 267.2 | train mfu (16-bit): -1.0 | lr mean: 4.926555266138166e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.35 | train loss last: 3.31 | consumed tokens: 494796800.0 | grad norm avg: 0.61 | grad norm last: 0.58 | 
2026-01-01T20:37:57 | step: 15200 | train samples/s: 264.4 | train mfu (16-bit): -1.0 | lr mean: 4.925456960336305e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.34 | train loss last: 3.23 | consumed tokens: 498073600.0 | grad norm avg: 0.61 | grad norm last: 0.64 | 
2026-01-01T20:38:26 | step: 15300 | train samples/s: 265.7 | train mfu (16-bit): -1.0 | lr mean: 4.9243506509810686e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.34 | train loss last: 3.34 | consumed tokens: 501350400.0 | grad norm avg: 0.61 | grad norm last: 0.68 | 
2026-01-01T20:38:55 | step: 15400 | train samples/s: 262.8 | train mfu (16-bit): -1.0 | lr mean: 4.9232363380724564e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.32 | train loss last: 3.3 | consumed tokens: 504627200.0 | grad norm avg: 0.6 | grad norm last: 0.54 | 
2026-01-01T20:39:24 | step: 15500 | train samples/s: 262.7 | train mfu (16-bit): -1.0 | lr mean: 4.9221140216104686e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.34 | train loss last: 3.45 | consumed tokens: 507904000.0 | grad norm avg: 0.61 | grad norm last: 0.68 | 
2026-01-01T20:39:52 | step: 15600 | train samples/s: 265.7 | train mfu (16-bit): -1.0 | lr mean: 4.920983701595105e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.34 | train loss last: 3.42 | consumed tokens: 511180800.0 | grad norm avg: 0.62 | grad norm last: 0.53 | 
2026-01-01T20:40:21 | step: 15700 | train samples/s: 264.5 | train mfu (16-bit): -1.0 | lr mean: 4.919845378026366e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.34 | train loss last: 3.36 | consumed tokens: 514457600.0 | grad norm avg: 0.6 | grad norm last: 0.61 | 
2026-01-01T20:40:49 | step: 15800 | train samples/s: 267.5 | train mfu (16-bit): -1.0 | lr mean: 4.9186990509042516e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.33 | train loss last: 3.32 | consumed tokens: 517734400.0 | grad norm avg: 0.61 | grad norm last: 0.6 | 
2026-01-01T20:41:18 | step: 15900 | train samples/s: 268.0 | train mfu (16-bit): -1.0 | lr mean: 4.9175447202287614e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.34 | train loss last: 3.37 | consumed tokens: 521011200.0 | grad norm avg: 0.61 | grad norm last: 0.63 | 
2026-01-01T20:41:46 | step: 16000 | train samples/s: 267.8 | train mfu (16-bit): -1.0 | lr mean: 4.9163823859998956e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.34 | train loss last: 3.22 | consumed tokens: 524288000.0 | grad norm avg: 0.6 | grad norm last: 0.61 | 
2026-01-01T20:42:15 | step: 16100 | train samples/s: 264.9 | train mfu (16-bit): -1.0 | lr mean: 4.915212048217654e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.34 | train loss last: 3.32 | consumed tokens: 527564800.0 | grad norm avg: 0.6 | grad norm last: 0.58 | 
2026-01-01T20:42:44 | step: 16200 | train samples/s: 263.1 | train mfu (16-bit): -1.0 | lr mean: 4.914033706882037e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.33 | train loss last: 3.24 | consumed tokens: 530841600.0 | grad norm avg: 0.61 | grad norm last: 0.56 | 
2026-01-01T20:43:12 | step: 16300 | train samples/s: 265.5 | train mfu (16-bit): -1.0 | lr mean: 4.9128473619930446e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.32 | train loss last: 3.48 | consumed tokens: 534118400.0 | grad norm avg: 0.62 | grad norm last: 0.67 | 
2026-01-01T20:43:41 | step: 16400 | train samples/s: 263.1 | train mfu (16-bit): -1.0 | lr mean: 4.9116530135506764e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.33 | train loss last: 3.61 | consumed tokens: 537395200.0 | grad norm avg: 0.63 | grad norm last: 0.61 | 
2026-01-01T20:44:10 | step: 16500 | train samples/s: 266.2 | train mfu (16-bit): -1.0 | lr mean: 4.9104506615549326e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.32 | train loss last: 3.45 | consumed tokens: 540672000.0 | grad norm avg: 0.62 | grad norm last: 0.66 | 
2026-01-01T20:44:39 | step: 16600 | train samples/s: 266.1 | train mfu (16-bit): -1.0 | lr mean: 4.909240306005813e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.32 | train loss last: 3.59 | consumed tokens: 543948800.0 | grad norm avg: 0.61 | grad norm last: 0.58 | 
2026-01-01T20:45:08 | step: 16700 | train samples/s: 260.6 | train mfu (16-bit): -1.0 | lr mean: 4.908021946903318e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.32 | train loss last: 3.21 | consumed tokens: 547225600.0 | grad norm avg: 0.61 | grad norm last: 0.58 | 
2026-01-01T20:45:37 | step: 16800 | train samples/s: 262.0 | train mfu (16-bit): -1.0 | lr mean: 4.9067955842474476e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.32 | train loss last: 3.08 | consumed tokens: 550502400.0 | grad norm avg: 0.6 | grad norm last: 0.62 | 
2026-01-01T20:46:05 | step: 16900 | train samples/s: 264.7 | train mfu (16-bit): -1.0 | lr mean: 4.905561581836082e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.33 | train loss last: 3.52 | consumed tokens: 553779200.0 | grad norm avg: 0.62 | grad norm last: 0.63 | 
2026-01-01T20:46:34 | step: 17000 | train samples/s: 266.0 | train mfu (16-bit): -1.0 | lr mean: 4.904319575871341e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.33 | train loss last: 2.96 | consumed tokens: 557056000.0 | grad norm avg: 0.61 | grad norm last: 0.57 | 
2026-01-01T20:47:03 | step: 17100 | train samples/s: 264.8 | train mfu (16-bit): -1.0 | lr mean: 4.9030692025553435e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.33 | train loss last: 3.14 | consumed tokens: 560332800.0 | grad norm avg: 0.62 | grad norm last: 0.59 | 
2026-01-01T20:47:31 | step: 17200 | train samples/s: 267.2 | train mfu (16-bit): -1.0 | lr mean: 4.901811189483851e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.32 | train loss last: 3.06 | consumed tokens: 563609600.0 | grad norm avg: 0.6 | grad norm last: 0.57 | 
2026-01-01T20:48:00 | step: 17300 | train samples/s: 267.0 | train mfu (16-bit): -1.0 | lr mean: 4.900545172858983e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.32 | train loss last: 3.22 | consumed tokens: 566886400.0 | grad norm avg: 0.61 | grad norm last: 0.6 | 
2026-01-01T20:48:29 | step: 17400 | train samples/s: 260.9 | train mfu (16-bit): -1.0 | lr mean: 4.89927115268074e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.33 | train loss last: 3.22 | consumed tokens: 570163200.0 | grad norm avg: 0.61 | grad norm last: 0.6 | 
2026-01-01T20:48:57 | step: 17500 | train samples/s: 269.1 | train mfu (16-bit): -1.0 | lr mean: 4.8979894927470013e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.3 | train loss last: 3.54 | consumed tokens: 573440000.0 | grad norm avg: 0.61 | grad norm last: 0.62 | 
2026-01-01T20:49:25 | step: 17600 | train samples/s: 266.7 | train mfu (16-bit): -1.0 | lr mean: 4.8966994654620066e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.32 | train loss last: 2.92 | consumed tokens: 576716800.0 | grad norm avg: 0.61 | grad norm last: 0.64 | 
2026-01-01T20:49:54 | step: 17700 | train samples/s: 262.8 | train mfu (16-bit): -1.0 | lr mean: 4.895401798421517e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.32 | train loss last: 3.29 | consumed tokens: 579993600.0 | grad norm avg: 0.61 | grad norm last: 0.62 | 
2026-01-01T20:50:23 | step: 17800 | train samples/s: 265.3 | train mfu (16-bit): -1.0 | lr mean: 4.894096127827652e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.32 | train loss last: 3.33 | consumed tokens: 583270400.0 | grad norm avg: 0.63 | grad norm last: 0.63 | 
2026-01-01T20:50:52 | step: 17900 | train samples/s: 265.8 | train mfu (16-bit): -1.0 | lr mean: 4.892782453680411e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.32 | train loss last: 3.23 | consumed tokens: 586547200.0 | grad norm avg: 0.61 | grad norm last: 0.65 | 
2026-01-01T20:51:20 | step: 18000 | train samples/s: 267.1 | train mfu (16-bit): -1.0 | lr mean: 4.8914607759797946e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.31 | train loss last: 3.22 | consumed tokens: 589824000.0 | grad norm avg: 0.61 | grad norm last: 0.63 | 
2026-01-01T20:51:49 | step: 18100 | train samples/s: 263.7 | train mfu (16-bit): -1.0 | lr mean: 4.890131458523683e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.3 | train loss last: 3.29 | consumed tokens: 593100800.0 | grad norm avg: 0.6 | grad norm last: 0.68 | 
2026-01-01T20:52:18 | step: 18200 | train samples/s: 262.3 | train mfu (16-bit): -1.0 | lr mean: 4.888794137514196e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.3 | train loss last: 3.0 | consumed tokens: 596377600.0 | grad norm avg: 0.61 | grad norm last: 0.58 | 
2026-01-01T20:52:46 | step: 18300 | train samples/s: 272.7 | train mfu (16-bit): -1.0 | lr mean: 4.887448812951334e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.31 | train loss last: 3.61 | consumed tokens: 599654400.0 | grad norm avg: 0.61 | grad norm last: 0.55 | 
2026-01-01T20:53:14 | step: 18400 | train samples/s: 266.6 | train mfu (16-bit): -1.0 | lr mean: 4.886095484835096e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.31 | train loss last: 3.27 | consumed tokens: 602931200.0 | grad norm avg: 0.61 | grad norm last: 0.58 | 
2026-01-01T20:53:43 | step: 18500 | train samples/s: 266.5 | train mfu (16-bit): -1.0 | lr mean: 4.884734516963363e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.3 | train loss last: 3.17 | consumed tokens: 606208000.0 | grad norm avg: 0.63 | grad norm last: 0.68 | 
2026-01-01T20:54:11 | step: 18600 | train samples/s: 265.5 | train mfu (16-bit): -1.0 | lr mean: 4.883365545538254e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.29 | train loss last: 3.67 | consumed tokens: 609484800.0 | grad norm avg: 0.61 | grad norm last: 0.56 | 
2026-01-01T20:54:40 | step: 18700 | train samples/s: 265.9 | train mfu (16-bit): -1.0 | lr mean: 4.8819889343576506e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.32 | train loss last: 3.17 | consumed tokens: 612761600.0 | grad norm avg: 0.61 | grad norm last: 0.63 | 
2026-01-01T20:55:08 | step: 18800 | train samples/s: 266.7 | train mfu (16-bit): -1.0 | lr mean: 4.880603955825791e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.3 | train loss last: 3.16 | consumed tokens: 616038400.0 | grad norm avg: 0.62 | grad norm last: 0.58 | 
2026-01-01T20:55:37 | step: 18900 | train samples/s: 260.4 | train mfu (16-bit): -1.0 | lr mean: 4.879211337538436e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.32 | train loss last: 3.32 | consumed tokens: 619315200.0 | grad norm avg: 0.61 | grad norm last: 0.67 | 
2026-01-01T20:56:06 | step: 19000 | train samples/s: 263.4 | train mfu (16-bit): -1.0 | lr mean: 4.8778110794955865e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.3 | train loss last: 3.42 | consumed tokens: 622592000.0 | grad norm avg: 0.62 | grad norm last: 0.63 | 
2026-01-01T20:56:34 | step: 19100 | train samples/s: 269.8 | train mfu (16-bit): -1.0 | lr mean: 4.8764024541014805e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.3 | train loss last: 3.15 | consumed tokens: 625868800.0 | grad norm avg: 0.62 | grad norm last: 0.6 | 
2026-01-01T20:57:02 | step: 19200 | train samples/s: 270.1 | train mfu (16-bit): -1.0 | lr mean: 4.8749865527497604e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.3 | train loss last: 3.33 | consumed tokens: 629145600.0 | grad norm avg: 0.62 | grad norm last: 0.7 | 
2026-01-01T20:57:31 | step: 19300 | train samples/s: 267.3 | train mfu (16-bit): -1.0 | lr mean: 4.873562284046784e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.3 | train loss last: 3.43 | consumed tokens: 632422400.0 | grad norm avg: 0.62 | grad norm last: 0.62 | 
2026-01-01T20:57:59 | step: 19400 | train samples/s: 267.8 | train mfu (16-bit): -1.0 | lr mean: 4.872130375588313e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.29 | train loss last: 3.4 | consumed tokens: 635699200.0 | grad norm avg: 0.62 | grad norm last: 0.64 | 
2026-01-01T20:58:27 | step: 19500 | train samples/s: 266.7 | train mfu (16-bit): -1.0 | lr mean: 4.8706908273743466e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.3 | train loss last: 3.37 | consumed tokens: 638976000.0 | grad norm avg: 0.61 | grad norm last: 0.56 | 
2026-01-01T20:58:56 | step: 19600 | train samples/s: 264.5 | train mfu (16-bit): -1.0 | lr mean: 4.869242911809124e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.31 | train loss last: 3.46 | consumed tokens: 642252800.0 | grad norm avg: 0.62 | grad norm last: 0.6 | 
2026-01-01T20:59:25 | step: 19700 | train samples/s: 262.1 | train mfu (16-bit): -1.0 | lr mean: 4.8677877202862874e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.31 | train loss last: 3.53 | consumed tokens: 645529600.0 | grad norm avg: 0.62 | grad norm last: 0.63 | 
2026-01-01T20:59:54 | step: 19800 | train samples/s: 266.6 | train mfu (16-bit): -1.0 | lr mean: 4.8663241614121944e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.3 | train loss last: 3.21 | consumed tokens: 648806400.0 | grad norm avg: 0.61 | grad norm last: 0.57 | 
2026-01-01T21:00:22 | step: 19900 | train samples/s: 267.6 | train mfu (16-bit): -1.0 | lr mean: 4.864853326580487e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.31 | train loss last: 3.21 | consumed tokens: 652083200.0 | grad norm avg: 0.61 | grad norm last: 0.64 | 
2026-01-01T21:00:50 | step: 20000 | train samples/s: 267.2 | train mfu (16-bit): -1.0 | lr mean: 4.863374124397524e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.29 | train loss last: 3.14 | consumed tokens: 655360000.0 | grad norm avg: 0.62 | grad norm last: 0.64 | 
2026-01-01T21:01:21 | step: 20100 | train samples/s: 264.3 | train mfu (16-bit): -1.0 | lr mean: 4.861887282459065e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.3 | train loss last: 3.12 | consumed tokens: 658636800.0 | grad norm avg: 0.62 | grad norm last: 0.65 | 
2026-01-01T21:01:49 | step: 20200 | train samples/s: 268.4 | train mfu (16-bit): -1.0 | lr mean: 4.860392800765112e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.28 | train loss last: 3.27 | consumed tokens: 661913600.0 | grad norm avg: 0.63 | grad norm last: 0.64 | 
2026-01-01T21:02:18 | step: 20300 | train samples/s: 263.5 | train mfu (16-bit): -1.0 | lr mean: 4.858890315517783e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.29 | train loss last: 3.77 | consumed tokens: 665190400.0 | grad norm avg: 0.62 | grad norm last: 0.62 | 
2026-01-01T21:02:46 | step: 20400 | train samples/s: 262.5 | train mfu (16-bit): -1.0 | lr mean: 4.8573801905149594e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.29 | train loss last: 3.33 | consumed tokens: 668467200.0 | grad norm avg: 0.63 | grad norm last: 0.58 | 
2026-01-01T21:03:15 | step: 20500 | train samples/s: 266.5 | train mfu (16-bit): -1.0 | lr mean: 4.855862425756641e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.3 | train loss last: 3.46 | consumed tokens: 671744000.0 | grad norm avg: 0.62 | grad norm last: 0.61 | 
2026-01-01T21:03:43 | step: 20600 | train samples/s: 266.6 | train mfu (16-bit): -1.0 | lr mean: 4.8543366574449465e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.28 | train loss last: 3.06 | consumed tokens: 675020800.0 | grad norm avg: 0.62 | grad norm last: 0.63 | 
2026-01-01T21:04:11 | step: 20700 | train samples/s: 269.2 | train mfu (16-bit): -1.0 | lr mean: 4.8528028855798766e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.28 | train loss last: 3.04 | consumed tokens: 678297600.0 | grad norm avg: 0.63 | grad norm last: 0.58 | 
2026-01-01T21:04:40 | step: 20800 | train samples/s: 264.5 | train mfu (16-bit): -1.0 | lr mean: 4.851261473959312e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.29 | train loss last: 3.62 | consumed tokens: 681574400.0 | grad norm avg: 0.62 | grad norm last: 0.61 | 
2026-01-01T21:05:09 | step: 20900 | train samples/s: 264.8 | train mfu (16-bit): -1.0 | lr mean: 4.849712422583252e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.28 | train loss last: 3.18 | consumed tokens: 684851200.0 | grad norm avg: 0.61 | grad norm last: 0.59 | 
2026-01-01T21:05:37 | step: 21000 | train samples/s: 264.7 | train mfu (16-bit): -1.0 | lr mean: 4.848155367653817e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.29 | train loss last: 3.41 | consumed tokens: 688128000.0 | grad norm avg: 0.61 | grad norm last: 0.6 | 
2026-01-01T21:06:06 | step: 21100 | train samples/s: 266.4 | train mfu (16-bit): -1.0 | lr mean: 4.846590672968887e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.28 | train loss last: 3.26 | consumed tokens: 691404800.0 | grad norm avg: 0.62 | grad norm last: 0.64 | 
2026-01-01T21:06:34 | step: 21200 | train samples/s: 265.4 | train mfu (16-bit): -1.0 | lr mean: 4.845018338528462e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.27 | train loss last: 3.21 | consumed tokens: 694681600.0 | grad norm avg: 0.62 | grad norm last: 0.55 | 
2026-01-01T21:07:03 | step: 21300 | train samples/s: 267.0 | train mfu (16-bit): -1.0 | lr mean: 4.843438000534661e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.27 | train loss last: 3.52 | consumed tokens: 697958400.0 | grad norm avg: 0.61 | grad norm last: 0.59 | 
2026-01-01T21:07:31 | step: 21400 | train samples/s: 267.0 | train mfu (16-bit): -1.0 | lr mean: 4.8418500227853656e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.27 | train loss last: 3.4 | consumed tokens: 701235200.0 | grad norm avg: 0.62 | grad norm last: 0.58 | 
2026-01-01T21:08:00 | step: 21500 | train samples/s: 266.5 | train mfu (16-bit): -1.0 | lr mean: 4.840254405280575e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.29 | train loss last: 3.15 | consumed tokens: 704512000.0 | grad norm avg: 0.63 | grad norm last: 0.59 | 
2026-01-01T21:08:28 | step: 21600 | train samples/s: 264.7 | train mfu (16-bit): -1.0 | lr mean: 4.838650784222409e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.28 | train loss last: 3.17 | consumed tokens: 707788800.0 | grad norm avg: 0.61 | grad norm last: 0.65 | 
2026-01-01T21:08:57 | step: 21700 | train samples/s: 265.2 | train mfu (16-bit): -1.0 | lr mean: 4.837039523408748e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.27 | train loss last: 3.45 | consumed tokens: 711065600.0 | grad norm avg: 0.62 | grad norm last: 0.58 | 
2026-01-01T21:09:25 | step: 21800 | train samples/s: 269.3 | train mfu (16-bit): -1.0 | lr mean: 4.8354206228395924e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.27 | train loss last: 2.93 | consumed tokens: 714342400.0 | grad norm avg: 0.61 | grad norm last: 0.55 | 
2026-01-01T21:09:54 | step: 21900 | train samples/s: 266.6 | train mfu (16-bit): -1.0 | lr mean: 4.833794082514942e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.27 | train loss last: 3.33 | consumed tokens: 717619200.0 | grad norm avg: 0.61 | grad norm last: 0.64 | 
2026-01-01T21:10:22 | step: 22000 | train samples/s: 263.1 | train mfu (16-bit): -1.0 | lr mean: 4.8321595386369154e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.28 | train loss last: 2.98 | consumed tokens: 720896000.0 | grad norm avg: 0.62 | grad norm last: 0.6 | 
2026-01-01T21:10:51 | step: 22100 | train samples/s: 267.2 | train mfu (16-bit): -1.0 | lr mean: 4.830517355003394e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.29 | train loss last: 3.12 | consumed tokens: 724172800.0 | grad norm avg: 0.62 | grad norm last: 0.65 | 
2026-01-01T21:11:20 | step: 22200 | train samples/s: 257.8 | train mfu (16-bit): -1.0 | lr mean: 4.828867531614378e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.28 | train loss last: 3.43 | consumed tokens: 727449600.0 | grad norm avg: 0.63 | grad norm last: 0.63 | 
2026-01-01T21:11:49 | step: 22300 | train samples/s: 259.2 | train mfu (16-bit): -1.0 | lr mean: 4.827210068469867e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.28 | train loss last: 2.74 | consumed tokens: 730726400.0 | grad norm avg: 0.62 | grad norm last: 0.62 | 
2026-01-01T21:12:17 | step: 22400 | train samples/s: 267.1 | train mfu (16-bit): -1.0 | lr mean: 4.825544965569861e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.26 | train loss last: 3.31 | consumed tokens: 734003200.0 | grad norm avg: 0.62 | grad norm last: 0.65 | 
2026-01-01T21:12:45 | step: 22500 | train samples/s: 267.7 | train mfu (16-bit): -1.0 | lr mean: 4.82387185911648e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.28 | train loss last: 3.23 | consumed tokens: 737280000.0 | grad norm avg: 0.61 | grad norm last: 0.55 | 
2026-01-01T21:13:14 | step: 22600 | train samples/s: 265.8 | train mfu (16-bit): -1.0 | lr mean: 4.822191476705484e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.27 | train loss last: 3.23 | consumed tokens: 740556800.0 | grad norm avg: 0.62 | grad norm last: 0.63 | 
2026-01-01T21:13:42 | step: 22700 | train samples/s: 263.3 | train mfu (16-bit): -1.0 | lr mean: 4.820503090741113e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.28 | train loss last: 3.22 | consumed tokens: 743833600.0 | grad norm avg: 0.61 | grad norm last: 0.69 | 
2026-01-01T21:14:11 | step: 22800 | train samples/s: 264.7 | train mfu (16-bit): -1.0 | lr mean: 4.818807065021247e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.26 | train loss last: 3.48 | consumed tokens: 747110400.0 | grad norm avg: 0.62 | grad norm last: 0.61 | 
2026-01-01T21:14:39 | step: 22900 | train samples/s: 266.5 | train mfu (16-bit): -1.0 | lr mean: 4.8171033995458856e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.27 | train loss last: 3.24 | consumed tokens: 750387200.0 | grad norm avg: 0.62 | grad norm last: 0.62 | 
2026-01-01T21:15:09 | step: 23000 | train samples/s: 252.8 | train mfu (16-bit): -1.0 | lr mean: 4.81539209431503e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.26 | train loss last: 3.02 | consumed tokens: 753664000.0 | grad norm avg: 0.63 | grad norm last: 0.63 | 
2026-01-01T21:15:37 | step: 23100 | train samples/s: 263.6 | train mfu (16-bit): -1.0 | lr mean: 4.813673149328679e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.28 | train loss last: 2.89 | consumed tokens: 756940800.0 | grad norm avg: 0.63 | grad norm last: 0.62 | 
2026-01-01T21:16:06 | step: 23200 | train samples/s: 266.0 | train mfu (16-bit): -1.0 | lr mean: 4.811946564586833e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.27 | train loss last: 3.57 | consumed tokens: 760217600.0 | grad norm avg: 0.62 | grad norm last: 0.58 | 
2026-01-01T21:16:34 | step: 23300 | train samples/s: 267.3 | train mfu (16-bit): -1.0 | lr mean: 4.8102123400894925e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.28 | train loss last: 3.65 | consumed tokens: 763494400.0 | grad norm avg: 0.62 | grad norm last: 0.62 | 
2026-01-01T21:17:02 | step: 23400 | train samples/s: 268.5 | train mfu (16-bit): -1.0 | lr mean: 4.808470112038776e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.27 | train loss last: 3.14 | consumed tokens: 766771200.0 | grad norm avg: 0.62 | grad norm last: 0.64 | 
2026-01-01T21:17:31 | step: 23500 | train samples/s: 263.0 | train mfu (16-bit): -1.0 | lr mean: 4.806720608030446e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.27 | train loss last: 3.05 | consumed tokens: 770048000.0 | grad norm avg: 0.62 | grad norm last: 0.59 | 
2026-01-01T21:17:59 | step: 23600 | train samples/s: 267.9 | train mfu (16-bit): -1.0 | lr mean: 4.8049634642666206e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.26 | train loss last: 3.04 | consumed tokens: 773324800.0 | grad norm avg: 0.62 | grad norm last: 0.58 | 
2026-01-01T21:18:28 | step: 23700 | train samples/s: 262.0 | train mfu (16-bit): -1.0 | lr mean: 4.8031986807473004e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.27 | train loss last: 3.67 | consumed tokens: 776601600.0 | grad norm avg: 0.61 | grad norm last: 0.64 | 
2026-01-01T21:18:57 | step: 23800 | train samples/s: 266.3 | train mfu (16-bit): -1.0 | lr mean: 4.801426257472485e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.27 | train loss last: 3.49 | consumed tokens: 779878400.0 | grad norm avg: 0.61 | grad norm last: 0.61 | 
2026-01-01T21:19:25 | step: 23900 | train samples/s: 263.3 | train mfu (16-bit): -1.0 | lr mean: 4.799646194442175e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.27 | train loss last: 3.36 | consumed tokens: 783155200.0 | grad norm avg: 0.62 | grad norm last: 0.6 | 
2026-01-01T21:19:54 | step: 24000 | train samples/s: 265.1 | train mfu (16-bit): -1.0 | lr mean: 4.7978584916563705e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.28 | train loss last: 3.3 | consumed tokens: 786432000.0 | grad norm avg: 0.62 | grad norm last: 0.6 | 
2026-01-01T21:20:22 | step: 24100 | train samples/s: 266.4 | train mfu (16-bit): -1.0 | lr mean: 4.796063149115071e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.27 | train loss last: 3.33 | consumed tokens: 789708800.0 | grad norm avg: 0.61 | grad norm last: 0.61 | 
2026-01-01T21:20:51 | step: 24200 | train samples/s: 259.8 | train mfu (16-bit): -1.0 | lr mean: 4.794260166818276e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.26 | consumed tokens: 792985600.0 | grad norm avg: 0.63 | grad norm last: 0.66 | 
2026-01-01T21:21:20 | step: 24300 | train samples/s: 262.6 | train mfu (16-bit): -1.0 | lr mean: 4.792449908563867e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.27 | train loss last: 3.22 | consumed tokens: 796262400.0 | grad norm avg: 0.62 | grad norm last: 0.65 | 
2026-01-01T21:21:48 | step: 24400 | train samples/s: 265.8 | train mfu (16-bit): -1.0 | lr mean: 4.790631646756083e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.09 | consumed tokens: 799539200.0 | grad norm avg: 0.63 | grad norm last: 0.56 | 
2026-01-01T21:22:17 | step: 24500 | train samples/s: 266.8 | train mfu (16-bit): -1.0 | lr mean: 4.788806108990684e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.27 | train loss last: 3.2 | consumed tokens: 802816000.0 | grad norm avg: 0.62 | grad norm last: 0.63 | 
2026-01-01T21:22:45 | step: 24600 | train samples/s: 266.6 | train mfu (16-bit): -1.0 | lr mean: 4.7869729314697906e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.19 | consumed tokens: 806092800.0 | grad norm avg: 0.62 | grad norm last: 0.64 | 
2026-01-01T21:23:14 | step: 24700 | train samples/s: 267.2 | train mfu (16-bit): -1.0 | lr mean: 4.785132114193402e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.27 | train loss last: 3.15 | consumed tokens: 809369600.0 | grad norm avg: 0.62 | grad norm last: 0.66 | 
2026-01-01T21:23:42 | step: 24800 | train samples/s: 266.5 | train mfu (16-bit): -1.0 | lr mean: 4.783283657161519e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.26 | train loss last: 3.44 | consumed tokens: 812646400.0 | grad norm avg: 0.62 | grad norm last: 0.6 | 
2026-01-01T21:24:11 | step: 24900 | train samples/s: 264.1 | train mfu (16-bit): -1.0 | lr mean: 4.7814279241720214e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.33 | consumed tokens: 815923200.0 | grad norm avg: 0.62 | grad norm last: 0.64 | 
2026-01-01T21:24:40 | step: 25000 | train samples/s: 261.5 | train mfu (16-bit): -1.0 | lr mean: 4.779564551427029e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.27 | train loss last: 3.19 | consumed tokens: 819200000.0 | grad norm avg: 0.63 | grad norm last: 0.61 | 
2026-01-01T21:25:10 | step: 25100 | train samples/s: 267.9 | train mfu (16-bit): -1.0 | lr mean: 4.777693538926542e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.14 | consumed tokens: 822476800.0 | grad norm avg: 0.61 | grad norm last: 0.61 | 
2026-01-01T21:25:38 | step: 25200 | train samples/s: 266.5 | train mfu (16-bit): -1.0 | lr mean: 4.7758148866705596e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.26 | train loss last: 3.2 | consumed tokens: 825753600.0 | grad norm avg: 0.63 | grad norm last: 0.66 | 
2026-01-01T21:26:06 | step: 25300 | train samples/s: 267.4 | train mfu (16-bit): -1.0 | lr mean: 4.773928958456963e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.26 | train loss last: 3.37 | consumed tokens: 829030400.0 | grad norm avg: 0.63 | grad norm last: 0.63 | 
2026-01-01T21:26:35 | step: 25400 | train samples/s: 267.9 | train mfu (16-bit): -1.0 | lr mean: 4.772035390487872e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.28 | train loss last: 2.98 | consumed tokens: 832307200.0 | grad norm avg: 0.62 | grad norm last: 0.67 | 
2026-01-01T21:27:03 | step: 25500 | train samples/s: 270.1 | train mfu (16-bit): -1.0 | lr mean: 4.770134182763286e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.52 | consumed tokens: 835584000.0 | grad norm avg: 0.64 | grad norm last: 0.75 | 
2026-01-01T21:27:31 | step: 25600 | train samples/s: 265.0 | train mfu (16-bit): -1.0 | lr mean: 4.7682256990810856e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.26 | train loss last: 3.58 | consumed tokens: 838860800.0 | grad norm avg: 0.63 | grad norm last: 0.63 | 
2026-01-01T21:28:00 | step: 25700 | train samples/s: 263.1 | train mfu (16-bit): -1.0 | lr mean: 4.7663095756433904e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.31 | consumed tokens: 842137600.0 | grad norm avg: 0.64 | grad norm last: 0.63 | 
2026-01-01T21:28:29 | step: 25800 | train samples/s: 265.3 | train mfu (16-bit): -1.0 | lr mean: 4.7643858124502e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.25 | consumed tokens: 845414400.0 | grad norm avg: 0.63 | grad norm last: 0.67 | 
2026-01-01T21:28:57 | step: 25900 | train samples/s: 265.6 | train mfu (16-bit): -1.0 | lr mean: 4.762454773299396e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.3 | consumed tokens: 848691200.0 | grad norm avg: 0.63 | grad norm last: 0.64 | 
2026-01-01T21:29:26 | step: 26000 | train samples/s: 266.9 | train mfu (16-bit): -1.0 | lr mean: 4.760516094393097e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.26 | train loss last: 3.55 | consumed tokens: 851968000.0 | grad norm avg: 0.62 | grad norm last: 0.61 | 
2026-01-01T21:29:54 | step: 26100 | train samples/s: 263.9 | train mfu (16-bit): -1.0 | lr mean: 4.7585701395291835e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.26 | train loss last: 3.31 | consumed tokens: 855244800.0 | grad norm avg: 0.62 | grad norm last: 0.63 | 
2026-01-01T21:30:23 | step: 26200 | train samples/s: 264.6 | train mfu (16-bit): -1.0 | lr mean: 4.756616544909775e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.27 | train loss last: 3.43 | consumed tokens: 858521600.0 | grad norm avg: 0.63 | grad norm last: 0.6 | 
2026-01-01T21:30:51 | step: 26300 | train samples/s: 265.9 | train mfu (16-bit): -1.0 | lr mean: 4.754655310534872e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.05 | consumed tokens: 861798400.0 | grad norm avg: 0.63 | grad norm last: 0.56 | 
2026-01-01T21:31:20 | step: 26400 | train samples/s: 264.3 | train mfu (16-bit): -1.0 | lr mean: 4.7526871640002355e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.2 | consumed tokens: 865075200.0 | grad norm avg: 0.64 | grad norm last: 0.66 | 
2026-01-01T21:31:49 | step: 26500 | train samples/s: 264.4 | train mfu (16-bit): -1.0 | lr mean: 4.750711013912223e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.26 | train loss last: 3.21 | consumed tokens: 868352000.0 | grad norm avg: 0.63 | grad norm last: 0.64 | 
2026-01-01T21:32:17 | step: 26600 | train samples/s: 265.6 | train mfu (16-bit): -1.0 | lr mean: 4.748727587866597e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.37 | consumed tokens: 871628800.0 | grad norm avg: 0.62 | grad norm last: 0.62 | 
2026-01-01T21:32:46 | step: 26700 | train samples/s: 264.5 | train mfu (16-bit): -1.0 | lr mean: 4.746736885863356e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.23 | train loss last: 3.3 | consumed tokens: 874905600.0 | grad norm avg: 0.63 | grad norm last: 0.62 | 
2026-01-01T21:33:14 | step: 26800 | train samples/s: 264.9 | train mfu (16-bit): -1.0 | lr mean: 4.744738544104621e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.17 | consumed tokens: 878182400.0 | grad norm avg: 0.63 | grad norm last: 0.57 | 
2026-01-01T21:33:43 | step: 26900 | train samples/s: 260.6 | train mfu (16-bit): -1.0 | lr mean: 4.742732926388271e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.09 | consumed tokens: 881459200.0 | grad norm avg: 0.63 | grad norm last: 0.61 | 
2026-01-01T21:34:12 | step: 27000 | train samples/s: 266.8 | train mfu (16-bit): -1.0 | lr mean: 4.7407196689164266e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 2.93 | consumed tokens: 884736000.0 | grad norm avg: 0.63 | grad norm last: 0.62 | 
2026-01-01T21:34:40 | step: 27100 | train samples/s: 260.6 | train mfu (16-bit): -1.0 | lr mean: 4.738699135486968e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.34 | consumed tokens: 888012800.0 | grad norm avg: 0.62 | grad norm last: 0.62 | 
2026-01-01T21:35:09 | step: 27200 | train samples/s: 267.0 | train mfu (16-bit): -1.0 | lr mean: 4.736671326099895e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.24 | train loss last: 3.39 | consumed tokens: 891289600.0 | grad norm avg: 0.62 | grad norm last: 0.6 | 
2026-01-01T21:35:37 | step: 27300 | train samples/s: 265.0 | train mfu (16-bit): -1.0 | lr mean: 4.734635876957327e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.24 | train loss last: 3.36 | consumed tokens: 894566400.0 | grad norm avg: 0.63 | grad norm last: 0.56 | 
2026-01-01T21:36:06 | step: 27400 | train samples/s: 265.8 | train mfu (16-bit): -1.0 | lr mean: 4.732593151857145e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.24 | train loss last: 3.21 | consumed tokens: 897843200.0 | grad norm avg: 0.63 | grad norm last: 0.71 | 
2026-01-01T21:36:34 | step: 27500 | train samples/s: 266.9 | train mfu (16-bit): -1.0 | lr mean: 4.730543150799349e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.26 | train loss last: 3.28 | consumed tokens: 901120000.0 | grad norm avg: 0.63 | grad norm last: 0.61 | 
2026-01-01T21:37:03 | step: 27600 | train samples/s: 260.4 | train mfu (16-bit): -1.0 | lr mean: 4.7284858737839386e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.39 | consumed tokens: 904396800.0 | grad norm avg: 0.62 | grad norm last: 0.66 | 
2026-01-01T21:37:31 | step: 27700 | train samples/s: 269.1 | train mfu (16-bit): -1.0 | lr mean: 4.726420957013033e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.35 | consumed tokens: 907673600.0 | grad norm avg: 0.64 | grad norm last: 0.65 | 
2026-01-01T21:38:00 | step: 27800 | train samples/s: 264.5 | train mfu (16-bit): -1.0 | lr mean: 4.724348764284514e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.24 | train loss last: 3.18 | consumed tokens: 910950400.0 | grad norm avg: 0.63 | grad norm last: 0.63 | 
2026-01-01T21:38:29 | step: 27900 | train samples/s: 266.1 | train mfu (16-bit): -1.0 | lr mean: 4.7222689318004996e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.04 | consumed tokens: 914227200.0 | grad norm avg: 0.62 | grad norm last: 0.68 | 
2026-01-01T21:38:57 | step: 28000 | train samples/s: 264.2 | train mfu (16-bit): -1.0 | lr mean: 4.720182187156752e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.24 | train loss last: 2.81 | consumed tokens: 917504000.0 | grad norm avg: 0.64 | grad norm last: 0.59 | 
2026-01-01T21:39:26 | step: 28100 | train samples/s: 264.8 | train mfu (16-bit): -1.0 | lr mean: 4.718087802757509e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.24 | train loss last: 3.13 | consumed tokens: 920780800.0 | grad norm avg: 0.63 | grad norm last: 0.57 | 
2026-01-01T21:39:54 | step: 28200 | train samples/s: 266.4 | train mfu (16-bit): -1.0 | lr mean: 4.715986142400652e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.23 | consumed tokens: 924057600.0 | grad norm avg: 0.63 | grad norm last: 0.61 | 
2026-01-01T21:40:23 | step: 28300 | train samples/s: 262.2 | train mfu (16-bit): -1.0 | lr mean: 4.713877206086181e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.24 | train loss last: 3.04 | consumed tokens: 927334400.0 | grad norm avg: 0.63 | grad norm last: 0.67 | 
2026-01-01T21:40:52 | step: 28400 | train samples/s: 267.1 | train mfu (16-bit): -1.0 | lr mean: 4.711760993814096e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.08 | consumed tokens: 930611200.0 | grad norm avg: 0.62 | grad norm last: 0.6 | 
2026-01-01T21:41:20 | step: 28500 | train samples/s: 265.4 | train mfu (16-bit): -1.0 | lr mean: 4.7096375055843964e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.23 | train loss last: 3.45 | consumed tokens: 933888000.0 | grad norm avg: 0.62 | grad norm last: 0.61 | 
2026-01-01T21:41:49 | step: 28600 | train samples/s: 267.2 | train mfu (16-bit): -1.0 | lr mean: 4.707506377599202e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.26 | train loss last: 3.32 | consumed tokens: 937164800.0 | grad norm avg: 0.64 | grad norm last: 0.74 | 
2026-01-01T21:42:17 | step: 28700 | train samples/s: 270.1 | train mfu (16-bit): -1.0 | lr mean: 4.705368337454274e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.24 | train loss last: 3.0 | consumed tokens: 940441600.0 | grad norm avg: 0.64 | grad norm last: 0.65 | 
2026-01-01T21:42:45 | step: 28800 | train samples/s: 267.5 | train mfu (16-bit): -1.0 | lr mean: 4.7032226575538516e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.23 | train loss last: 3.16 | consumed tokens: 943718400.0 | grad norm avg: 0.62 | grad norm last: 0.58 | 
2026-01-01T21:43:13 | step: 28900 | train samples/s: 267.8 | train mfu (16-bit): -1.0 | lr mean: 4.701069701695815e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.23 | train loss last: 3.08 | consumed tokens: 946995200.0 | grad norm avg: 0.63 | grad norm last: 0.61 | 
2026-01-01T21:43:42 | step: 29000 | train samples/s: 262.2 | train mfu (16-bit): -1.0 | lr mean: 4.6989098336780444e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.21 | consumed tokens: 950272000.0 | grad norm avg: 0.62 | grad norm last: 0.65 | 
2026-01-01T21:44:11 | step: 29100 | train samples/s: 265.9 | train mfu (16-bit): -1.0 | lr mean: 4.696742325904779e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.23 | train loss last: 2.97 | consumed tokens: 953548800.0 | grad norm avg: 0.63 | grad norm last: 0.77 | 
2026-01-01T21:44:40 | step: 29200 | train samples/s: 268.7 | train mfu (16-bit): -1.0 | lr mean: 4.6945679059717804e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.23 | train loss last: 3.09 | consumed tokens: 956825600.0 | grad norm avg: 0.63 | grad norm last: 0.57 | 
2026-01-01T21:45:08 | step: 29300 | train samples/s: 268.9 | train mfu (16-bit): -1.0 | lr mean: 4.692385846283287e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.23 | train loss last: 3.05 | consumed tokens: 960102400.0 | grad norm avg: 0.62 | grad norm last: 0.59 | 
2026-01-01T21:45:36 | step: 29400 | train samples/s: 268.8 | train mfu (16-bit): -1.0 | lr mean: 4.69019687443506e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.24 | train loss last: 3.76 | consumed tokens: 963379200.0 | grad norm avg: 0.62 | grad norm last: 0.58 | 
2026-01-01T21:46:05 | step: 29500 | train samples/s: 265.5 | train mfu (16-bit): -1.0 | lr mean: 4.688000262831338e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.23 | train loss last: 3.1 | consumed tokens: 966656000.0 | grad norm avg: 0.62 | grad norm last: 0.61 | 
2026-01-01T21:46:34 | step: 29600 | train samples/s: 265.8 | train mfu (16-bit): -1.0 | lr mean: 4.685796739067882e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.23 | train loss last: 3.24 | consumed tokens: 969932800.0 | grad norm avg: 0.63 | grad norm last: 0.6 | 
2026-01-01T21:47:02 | step: 29700 | train samples/s: 264.6 | train mfu (16-bit): -1.0 | lr mean: 4.683585939346813e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.24 | train loss last: 3.52 | consumed tokens: 973209600.0 | grad norm avg: 0.62 | grad norm last: 0.58 | 
2026-01-01T21:47:31 | step: 29800 | train samples/s: 265.2 | train mfu (16-bit): -1.0 | lr mean: 4.681367863668129e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.24 | train loss last: 3.54 | consumed tokens: 976486400.0 | grad norm avg: 0.63 | grad norm last: 0.63 | 
2026-01-01T21:48:00 | step: 29900 | train samples/s: 266.5 | train mfu (16-bit): -1.0 | lr mean: 4.679142512031831e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.24 | train loss last: 3.49 | consumed tokens: 979763200.0 | grad norm avg: 0.62 | grad norm last: 0.6 | 
2026-01-01T21:48:28 | step: 30000 | train samples/s: 266.8 | train mfu (16-bit): -1.0 | lr mean: 4.676909884437919e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 3.27 | consumed tokens: 983040000.0 | grad norm avg: 0.62 | grad norm last: 0.58 | 
2026-01-01T21:48:58 | step: 30100 | train samples/s: 269.0 | train mfu (16-bit): -1.0 | lr mean: 4.674669980886392e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.23 | train loss last: 3.38 | consumed tokens: 986316800.0 | grad norm avg: 0.61 | grad norm last: 0.6 | 
2026-01-01T21:49:27 | step: 30200 | train samples/s: 269.7 | train mfu (16-bit): -1.0 | lr mean: 4.6724231651751325e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.24 | train loss last: 3.18 | consumed tokens: 989593600.0 | grad norm avg: 0.63 | grad norm last: 0.6 | 
2026-01-01T21:49:56 | step: 30300 | train samples/s: 260.9 | train mfu (16-bit): -1.0 | lr mean: 4.6701690735062584e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.25 | train loss last: 3.23 | consumed tokens: 992870400.0 | grad norm avg: 0.63 | grad norm last: 0.6 | 
2026-01-01T21:50:24 | step: 30400 | train samples/s: 268.0 | train mfu (16-bit): -1.0 | lr mean: 4.66790770587977e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 2.99 | consumed tokens: 996147200.0 | grad norm avg: 0.63 | grad norm last: 0.61 | 
2026-01-01T21:50:53 | step: 30500 | train samples/s: 265.4 | train mfu (16-bit): -1.0 | lr mean: 4.6656394260935485e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.23 | train loss last: 3.29 | consumed tokens: 999424000.0 | grad norm avg: 0.63 | grad norm last: 0.59 | 
2026-01-01T21:51:21 | step: 30600 | train samples/s: 268.3 | train mfu (16-bit): -1.0 | lr mean: 4.663363870349713e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.23 | train loss last: 3.44 | consumed tokens: 1002700800.0 | grad norm avg: 0.63 | grad norm last: 0.6 | 
2026-01-01T21:51:50 | step: 30700 | train samples/s: 269.5 | train mfu (16-bit): -1.0 | lr mean: 4.6610810386482626e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 3.29 | consumed tokens: 1005977600.0 | grad norm avg: 0.62 | grad norm last: 0.65 | 
2026-01-01T21:52:18 | step: 30800 | train samples/s: 268.5 | train mfu (16-bit): -1.0 | lr mean: 4.6587909309891984e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 3.13 | consumed tokens: 1009254400.0 | grad norm avg: 0.62 | grad norm last: 0.57 | 
2026-01-01T21:52:46 | step: 30900 | train samples/s: 269.6 | train mfu (16-bit): -1.0 | lr mean: 4.656493911170401e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.23 | train loss last: 3.17 | consumed tokens: 1012531200.0 | grad norm avg: 0.63 | grad norm last: 0.58 | 
2026-01-01T21:53:15 | step: 31000 | train samples/s: 264.8 | train mfu (16-bit): -1.0 | lr mean: 4.654189615393989e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.24 | train loss last: 3.51 | consumed tokens: 1015808000.0 | grad norm avg: 0.63 | grad norm last: 0.67 | 
2026-01-01T21:53:44 | step: 31100 | train samples/s: 266.3 | train mfu (16-bit): -1.0 | lr mean: 4.6518784074578434e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 3.03 | consumed tokens: 1019084800.0 | grad norm avg: 0.63 | grad norm last: 0.63 | 
2026-01-01T21:54:12 | step: 31200 | train samples/s: 265.9 | train mfu (16-bit): -1.0 | lr mean: 4.649559923564084e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.23 | train loss last: 3.3 | consumed tokens: 1022361600.0 | grad norm avg: 0.62 | grad norm last: 0.61 | 
2026-01-01T21:54:41 | step: 31300 | train samples/s: 268.0 | train mfu (16-bit): -1.0 | lr mean: 4.64723416371271e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 3.01 | consumed tokens: 1025638400.0 | grad norm avg: 0.63 | grad norm last: 0.64 | 
2026-01-01T21:55:09 | step: 31400 | train samples/s: 268.6 | train mfu (16-bit): -1.0 | lr mean: 4.644901491701603e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.23 | train loss last: 3.34 | consumed tokens: 1028915200.0 | grad norm avg: 0.62 | grad norm last: 0.56 | 
2026-01-01T21:55:37 | step: 31500 | train samples/s: 268.3 | train mfu (16-bit): -1.0 | lr mean: 4.642561907530762e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 3.22 | consumed tokens: 1032192000.0 | grad norm avg: 0.62 | grad norm last: 0.74 | 
2026-01-01T21:56:06 | step: 31600 | train samples/s: 265.7 | train mfu (16-bit): -1.0 | lr mean: 4.6402150474023074e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 3.1 | consumed tokens: 1035468800.0 | grad norm avg: 0.62 | grad norm last: 0.57 | 
2026-01-01T21:56:35 | step: 31700 | train samples/s: 267.9 | train mfu (16-bit): -1.0 | lr mean: 4.6378609113162383e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 3.19 | consumed tokens: 1038745600.0 | grad norm avg: 0.62 | grad norm last: 0.62 | 
2026-01-01T21:57:03 | step: 31800 | train samples/s: 268.6 | train mfu (16-bit): -1.0 | lr mean: 4.635499863070436e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.38 | consumed tokens: 1042022400.0 | grad norm avg: 0.62 | grad norm last: 0.64 | 
2026-01-01T21:57:32 | step: 31900 | train samples/s: 266.6 | train mfu (16-bit): -1.0 | lr mean: 4.6331319026649e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.13 | consumed tokens: 1045299200.0 | grad norm avg: 0.64 | grad norm last: 0.64 | 
2026-01-01T21:58:00 | step: 32000 | train samples/s: 268.9 | train mfu (16-bit): -1.0 | lr mean: 4.6307566663017496e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 3.35 | consumed tokens: 1048576000.0 | grad norm avg: 0.63 | grad norm last: 0.58 | 
2026-01-01T21:58:28 | step: 32100 | train samples/s: 268.3 | train mfu (16-bit): -1.0 | lr mean: 4.628374517778866e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.24 | train loss last: 3.27 | consumed tokens: 1051852800.0 | grad norm avg: 0.63 | grad norm last: 0.61 | 
2026-01-01T21:58:57 | step: 32200 | train samples/s: 269.1 | train mfu (16-bit): -1.0 | lr mean: 4.625985093298368e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 3.52 | consumed tokens: 1055129600.0 | grad norm avg: 0.62 | grad norm last: 0.59 | 
2026-01-01T21:59:26 | step: 32300 | train samples/s: 263.5 | train mfu (16-bit): -1.0 | lr mean: 4.6235891204560176e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 2.7 | consumed tokens: 1058406400.0 | grad norm avg: 0.62 | grad norm last: 0.63 | 
2026-01-01T21:59:54 | step: 32400 | train samples/s: 268.7 | train mfu (16-bit): -1.0 | lr mean: 4.621185507858172e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 3.19 | consumed tokens: 1061683200.0 | grad norm avg: 0.63 | grad norm last: 0.57 | 
2026-01-01T22:00:23 | step: 32500 | train samples/s: 266.1 | train mfu (16-bit): -1.0 | lr mean: 4.618775346898474e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.13 | consumed tokens: 1064960000.0 | grad norm avg: 0.63 | grad norm last: 0.65 | 
2026-01-01T22:00:51 | step: 32600 | train samples/s: 266.5 | train mfu (16-bit): -1.0 | lr mean: 4.6163579099811614e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.23 | train loss last: 3.27 | consumed tokens: 1068236800.0 | grad norm avg: 0.62 | grad norm last: 0.59 | 
2026-01-01T22:01:20 | step: 32700 | train samples/s: 269.0 | train mfu (16-bit): -1.0 | lr mean: 4.6139335609041154e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 3.2 | consumed tokens: 1071513600.0 | grad norm avg: 0.63 | grad norm last: 0.66 | 
2026-01-01T22:01:48 | step: 32800 | train samples/s: 269.3 | train mfu (16-bit): -1.0 | lr mean: 4.611502299667336e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 2.92 | consumed tokens: 1074790400.0 | grad norm avg: 0.63 | grad norm last: 0.63 | 
2026-01-01T22:02:17 | step: 32900 | train samples/s: 266.4 | train mfu (16-bit): -1.0 | lr mean: 4.609064126270823e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.21 | consumed tokens: 1078067200.0 | grad norm avg: 0.63 | grad norm last: 0.63 | 
2026-01-01T22:02:45 | step: 33000 | train samples/s: 266.3 | train mfu (16-bit): -1.0 | lr mean: 4.606618676916696e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 3.38 | consumed tokens: 1081344000.0 | grad norm avg: 0.63 | grad norm last: 0.6 | 
2026-01-01T22:03:14 | step: 33100 | train samples/s: 269.7 | train mfu (16-bit): -1.0 | lr mean: 4.6041663154028356e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 3.05 | consumed tokens: 1084620800.0 | grad norm avg: 0.63 | grad norm last: 0.69 | 
2026-01-01T22:03:42 | step: 33200 | train samples/s: 266.8 | train mfu (16-bit): -1.0 | lr mean: 4.601707405527122e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.17 | consumed tokens: 1087897600.0 | grad norm avg: 0.63 | grad norm last: 0.66 | 
2026-01-01T22:04:11 | step: 33300 | train samples/s: 264.7 | train mfu (16-bit): -1.0 | lr mean: 4.599241219693795e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.23 | train loss last: 3.44 | consumed tokens: 1091174400.0 | grad norm avg: 0.62 | grad norm last: 0.64 | 
2026-01-01T22:04:39 | step: 33400 | train samples/s: 268.1 | train mfu (16-bit): -1.0 | lr mean: 4.596768121700734e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.07 | consumed tokens: 1094451200.0 | grad norm avg: 0.63 | grad norm last: 0.66 | 
2026-01-01T22:05:08 | step: 33500 | train samples/s: 268.2 | train mfu (16-bit): -1.0 | lr mean: 4.594287747750059e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 3.29 | consumed tokens: 1097728000.0 | grad norm avg: 0.62 | grad norm last: 0.65 | 
2026-01-01T22:05:37 | step: 33600 | train samples/s: 264.6 | train mfu (16-bit): -1.0 | lr mean: 4.591800825437531e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 2.96 | consumed tokens: 1101004800.0 | grad norm avg: 0.63 | grad norm last: 0.76 | 
2026-01-01T22:06:05 | step: 33700 | train samples/s: 264.6 | train mfu (16-bit): -1.0 | lr mean: 4.5893069909652695e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.0 | consumed tokens: 1104281600.0 | grad norm avg: 0.62 | grad norm last: 0.59 | 
2026-01-01T22:06:34 | step: 33800 | train samples/s: 267.4 | train mfu (16-bit): -1.0 | lr mean: 4.586806244333275e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.13 | consumed tokens: 1107558400.0 | grad norm avg: 0.62 | grad norm last: 0.62 | 
2026-01-01T22:07:03 | step: 33900 | train samples/s: 265.4 | train mfu (16-bit): -1.0 | lr mean: 4.5842985855415463e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.35 | consumed tokens: 1110835200.0 | grad norm avg: 0.63 | grad norm last: 0.71 | 
2026-01-01T22:07:31 | step: 34000 | train samples/s: 269.2 | train mfu (16-bit): -1.0 | lr mean: 4.581783650792204e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.17 | consumed tokens: 1114112000.0 | grad norm avg: 0.63 | grad norm last: 0.73 | 
2026-01-01T22:08:00 | step: 34100 | train samples/s: 265.7 | train mfu (16-bit): -1.0 | lr mean: 4.5792621676810086e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.05 | consumed tokens: 1117388800.0 | grad norm avg: 0.63 | grad norm last: 0.66 | 
2026-01-01T22:08:28 | step: 34200 | train samples/s: 266.0 | train mfu (16-bit): -1.0 | lr mean: 4.57673377241008e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.5 | consumed tokens: 1120665600.0 | grad norm avg: 0.62 | grad norm last: 0.58 | 
2026-01-01T22:08:57 | step: 34300 | train samples/s: 268.1 | train mfu (16-bit): -1.0 | lr mean: 4.5741984649794176e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.11 | consumed tokens: 1123942400.0 | grad norm avg: 0.62 | grad norm last: 0.58 | 
2026-01-01T22:09:25 | step: 34400 | train samples/s: 266.4 | train mfu (16-bit): -1.0 | lr mean: 4.5716566091869026e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 3.05 | consumed tokens: 1127219200.0 | grad norm avg: 0.62 | grad norm last: 0.64 | 
2026-01-01T22:09:54 | step: 34500 | train samples/s: 268.4 | train mfu (16-bit): -1.0 | lr mean: 4.5691074774367735e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.3 | consumed tokens: 1130496000.0 | grad norm avg: 0.62 | grad norm last: 0.57 | 
2026-01-01T22:10:22 | step: 34600 | train samples/s: 265.4 | train mfu (16-bit): -1.0 | lr mean: 4.5665517973247916e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 3.38 | consumed tokens: 1133772800.0 | grad norm avg: 0.63 | grad norm last: 0.57 | 
2026-01-01T22:10:51 | step: 34700 | train samples/s: 268.1 | train mfu (16-bit): -1.0 | lr mean: 4.5639888412551954e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 3.5 | consumed tokens: 1137049600.0 | grad norm avg: 0.63 | grad norm last: 0.59 | 
2026-01-01T22:11:19 | step: 34800 | train samples/s: 265.9 | train mfu (16-bit): -1.0 | lr mean: 4.5614193368237466e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.19 | train loss last: 3.09 | consumed tokens: 1140326400.0 | grad norm avg: 0.62 | grad norm last: 0.65 | 
2026-01-01T22:11:48 | step: 34900 | train samples/s: 265.0 | train mfu (16-bit): -1.0 | lr mean: 4.558843284030445e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.19 | train loss last: 3.07 | consumed tokens: 1143603200.0 | grad norm avg: 0.63 | grad norm last: 0.58 | 
2026-01-01T22:12:16 | step: 35000 | train samples/s: 268.9 | train mfu (16-bit): -1.0 | lr mean: 4.556259955279529e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 2.97 | consumed tokens: 1146880000.0 | grad norm avg: 0.62 | grad norm last: 0.64 | 
2026-01-01T22:12:47 | step: 35100 | train samples/s: 266.4 | train mfu (16-bit): -1.0 | lr mean: 4.5536700781667605e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.27 | consumed tokens: 1150156800.0 | grad norm avg: 0.63 | grad norm last: 0.61 | 
2026-01-01T22:13:15 | step: 35200 | train samples/s: 268.2 | train mfu (16-bit): -1.0 | lr mean: 4.5510732888942584e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.28 | consumed tokens: 1153433600.0 | grad norm avg: 0.62 | grad norm last: 0.64 | 
2026-01-01T22:13:44 | step: 35300 | train samples/s: 264.7 | train mfu (16-bit): -1.0 | lr mean: 4.5484699512599036e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.08 | consumed tokens: 1156710400.0 | grad norm avg: 0.63 | grad norm last: 0.65 | 
2026-01-01T22:14:12 | step: 35400 | train samples/s: 267.4 | train mfu (16-bit): -1.0 | lr mean: 4.545859701465815e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.23 | train loss last: 2.95 | consumed tokens: 1159987200.0 | grad norm avg: 0.63 | grad norm last: 0.68 | 
2026-01-01T22:14:41 | step: 35500 | train samples/s: 268.6 | train mfu (16-bit): -1.0 | lr mean: 4.5432425395119935e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.12 | consumed tokens: 1163264000.0 | grad norm avg: 0.63 | grad norm last: 0.63 | 
2026-01-01T22:15:09 | step: 35600 | train samples/s: 262.9 | train mfu (16-bit): -1.0 | lr mean: 4.540618829196319e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.24 | consumed tokens: 1166540800.0 | grad norm avg: 0.63 | grad norm last: 0.61 | 
2026-01-01T22:15:38 | step: 35700 | train samples/s: 265.0 | train mfu (16-bit): -1.0 | lr mean: 4.537988206720911e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.04 | consumed tokens: 1169817600.0 | grad norm avg: 0.63 | grad norm last: 0.61 | 
2026-01-01T22:16:07 | step: 35800 | train samples/s: 267.1 | train mfu (16-bit): -1.0 | lr mean: 4.5353506720857695e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.03 | consumed tokens: 1173094400.0 | grad norm avg: 0.64 | grad norm last: 0.64 | 
2026-01-01T22:16:35 | step: 35900 | train samples/s: 266.2 | train mfu (16-bit): -1.0 | lr mean: 4.532706952886656e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.32 | consumed tokens: 1176371200.0 | grad norm avg: 0.63 | grad norm last: 0.58 | 
2026-01-01T22:17:04 | step: 36000 | train samples/s: 268.6 | train mfu (16-bit): -1.0 | lr mean: 4.530055957729928e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 2.91 | consumed tokens: 1179648000.0 | grad norm avg: 0.63 | grad norm last: 0.64 | 
2026-01-01T22:17:32 | step: 36100 | train samples/s: 268.3 | train mfu (16-bit): -1.0 | lr mean: 4.527398414211348e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.49 | consumed tokens: 1182924800.0 | grad norm avg: 0.63 | grad norm last: 0.59 | 
2026-01-01T22:18:01 | step: 36200 | train samples/s: 268.0 | train mfu (16-bit): -1.0 | lr mean: 4.5247343223309144e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.5 | consumed tokens: 1186201600.0 | grad norm avg: 0.62 | grad norm last: 0.61 | 
2026-01-01T22:18:30 | step: 36300 | train samples/s: 262.4 | train mfu (16-bit): -1.0 | lr mean: 4.522063318290748e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.25 | consumed tokens: 1189478400.0 | grad norm avg: 0.64 | grad norm last: 0.64 | 
2026-01-01T22:18:58 | step: 36400 | train samples/s: 265.4 | train mfu (16-bit): -1.0 | lr mean: 4.519385765888728e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 3.16 | consumed tokens: 1192755200.0 | grad norm avg: 0.63 | grad norm last: 0.59 | 
2026-01-01T22:19:27 | step: 36500 | train samples/s: 268.5 | train mfu (16-bit): -1.0 | lr mean: 4.516701665124856e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.02 | consumed tokens: 1196032000.0 | grad norm avg: 0.62 | grad norm last: 0.61 | 
2026-01-01T22:19:55 | step: 36600 | train samples/s: 265.4 | train mfu (16-bit): -1.0 | lr mean: 4.51401065220125e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.18 | consumed tokens: 1199308800.0 | grad norm avg: 0.64 | grad norm last: 0.67 | 
2026-01-01T22:20:24 | step: 36700 | train samples/s: 267.1 | train mfu (16-bit): -1.0 | lr mean: 4.511313090915792e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.23 | consumed tokens: 1202585600.0 | grad norm avg: 0.63 | grad norm last: 0.63 | 
2026-01-01T22:20:52 | step: 36800 | train samples/s: 269.3 | train mfu (16-bit): -1.0 | lr mean: 4.5086086174706e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.22 | train loss last: 2.88 | consumed tokens: 1205862400.0 | grad norm avg: 0.62 | grad norm last: 0.7 | 
2026-01-01T22:21:21 | step: 36900 | train samples/s: 268.2 | train mfu (16-bit): -1.0 | lr mean: 4.505897959461436e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 2.81 | consumed tokens: 1209139200.0 | grad norm avg: 0.64 | grad norm last: 0.64 | 
2026-01-01T22:21:49 | step: 37000 | train samples/s: 269.4 | train mfu (16-bit): -1.0 | lr mean: 4.503180389292538e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.3 | consumed tokens: 1212416000.0 | grad norm avg: 0.64 | grad norm last: 0.62 | 
2026-01-01T22:22:18 | step: 37100 | train samples/s: 265.2 | train mfu (16-bit): -1.0 | lr mean: 4.500456270761788e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.61 | consumed tokens: 1215692800.0 | grad norm avg: 0.63 | grad norm last: 0.66 | 
2026-01-01T22:22:46 | step: 37200 | train samples/s: 269.3 | train mfu (16-bit): -1.0 | lr mean: 4.497725240071304e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.05 | consumed tokens: 1218969600.0 | grad norm avg: 0.63 | grad norm last: 0.58 | 
2026-01-01T22:23:14 | step: 37300 | train samples/s: 267.6 | train mfu (16-bit): -1.0 | lr mean: 4.494988024816848e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.19 | train loss last: 3.02 | consumed tokens: 1222246400.0 | grad norm avg: 0.64 | grad norm last: 0.64 | 
2026-01-01T22:23:42 | step: 37400 | train samples/s: 269.3 | train mfu (16-bit): -1.0 | lr mean: 4.492243897402659e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.14 | consumed tokens: 1225523200.0 | grad norm avg: 0.63 | grad norm last: 0.68 | 
2026-01-01T22:24:11 | step: 37500 | train samples/s: 267.3 | train mfu (16-bit): -1.0 | lr mean: 4.489493221626617e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.05 | consumed tokens: 1228800000.0 | grad norm avg: 0.64 | grad norm last: 0.65 | 
2026-01-01T22:24:40 | step: 37600 | train samples/s: 265.8 | train mfu (16-bit): -1.0 | lr mean: 4.486736361286603e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.08 | consumed tokens: 1232076800.0 | grad norm avg: 0.64 | grad norm last: 0.71 | 
2026-01-01T22:25:08 | step: 37700 | train samples/s: 272.1 | train mfu (16-bit): -1.0 | lr mean: 4.4839725887868553e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.48 | consumed tokens: 1235353600.0 | grad norm avg: 0.63 | grad norm last: 0.64 | 
2026-01-01T22:25:36 | step: 37800 | train samples/s: 269.6 | train mfu (16-bit): -1.0 | lr mean: 4.481202267925255e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.06 | consumed tokens: 1238630400.0 | grad norm avg: 0.63 | grad norm last: 0.66 | 
2026-01-01T22:26:04 | step: 37900 | train samples/s: 267.1 | train mfu (16-bit): -1.0 | lr mean: 4.478425398701802e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.19 | train loss last: 3.3 | consumed tokens: 1241907200.0 | grad norm avg: 0.63 | grad norm last: 0.62 | 
2026-01-01T22:26:33 | step: 38000 | train samples/s: 266.0 | train mfu (16-bit): -1.0 | lr mean: 4.475641981116496e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.2 | consumed tokens: 1245184000.0 | grad norm avg: 0.64 | grad norm last: 0.64 | 
2026-01-01T22:27:01 | step: 38100 | train samples/s: 270.4 | train mfu (16-bit): -1.0 | lr mean: 4.4728520151693374e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.38 | consumed tokens: 1248460800.0 | grad norm avg: 0.63 | grad norm last: 0.64 | 
2026-01-01T22:27:29 | step: 38200 | train samples/s: 272.0 | train mfu (16-bit): -1.0 | lr mean: 4.470055500860326e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.1 | consumed tokens: 1251737600.0 | grad norm avg: 0.64 | grad norm last: 0.63 | 
2026-01-01T22:27:57 | step: 38300 | train samples/s: 265.7 | train mfu (16-bit): -1.0 | lr mean: 4.467252438189462e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.07 | consumed tokens: 1255014400.0 | grad norm avg: 0.63 | grad norm last: 0.66 | 
2026-01-01T22:28:26 | step: 38400 | train samples/s: 265.8 | train mfu (16-bit): -1.0 | lr mean: 4.464442827156745e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.36 | consumed tokens: 1258291200.0 | grad norm avg: 0.64 | grad norm last: 0.61 | 
2026-01-01T22:28:54 | step: 38500 | train samples/s: 269.8 | train mfu (16-bit): -1.0 | lr mean: 4.461627031560056e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.26 | consumed tokens: 1261568000.0 | grad norm avg: 0.64 | grad norm last: 0.65 | 
2026-01-01T22:29:23 | step: 38600 | train samples/s: 267.3 | train mfu (16-bit): -1.0 | lr mean: 4.4588043238036335e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 2.98 | consumed tokens: 1264844800.0 | grad norm avg: 0.64 | grad norm last: 0.69 | 
2026-01-01T22:29:51 | step: 38700 | train samples/s: 267.1 | train mfu (16-bit): -1.0 | lr mean: 4.455975431483239e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.19 | train loss last: 3.34 | consumed tokens: 1268121600.0 | grad norm avg: 0.64 | grad norm last: 0.63 | 
2026-01-01T22:30:19 | step: 38800 | train samples/s: 269.0 | train mfu (16-bit): -1.0 | lr mean: 4.4531399908009917e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 2.87 | consumed tokens: 1271398400.0 | grad norm avg: 0.63 | grad norm last: 0.67 | 
2026-01-01T22:30:47 | step: 38900 | train samples/s: 270.6 | train mfu (16-bit): -1.0 | lr mean: 4.450298365554772e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.48 | consumed tokens: 1274675200.0 | grad norm avg: 0.64 | grad norm last: 0.68 | 
2026-01-01T22:31:16 | step: 39000 | train samples/s: 269.5 | train mfu (16-bit): -1.0 | lr mean: 4.4474498281488195e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.19 | train loss last: 3.26 | consumed tokens: 1277952000.0 | grad norm avg: 0.63 | grad norm last: 0.71 | 
2026-01-01T22:31:44 | step: 39100 | train samples/s: 266.8 | train mfu (16-bit): -1.0 | lr mean: 4.4445951061788946e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.27 | consumed tokens: 1281228800.0 | grad norm avg: 0.64 | grad norm last: 0.59 | 
2026-01-01T22:32:12 | step: 39200 | train samples/s: 268.3 | train mfu (16-bit): -1.0 | lr mean: 4.441733835847117e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.27 | consumed tokens: 1284505600.0 | grad norm avg: 0.64 | grad norm last: 0.65 | 
2026-01-01T22:32:41 | step: 39300 | train samples/s: 268.4 | train mfu (16-bit): -1.0 | lr mean: 4.4388660171534866e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.23 | consumed tokens: 1287782400.0 | grad norm avg: 0.63 | grad norm last: 0.64 | 
2026-01-01T22:33:09 | step: 39400 | train samples/s: 263.9 | train mfu (16-bit): -1.0 | lr mean: 4.435992013895884e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.15 | consumed tokens: 1291059200.0 | grad norm avg: 0.64 | grad norm last: 0.68 | 
2026-01-01T22:33:38 | step: 39500 | train samples/s: 269.4 | train mfu (16-bit): -1.0 | lr mean: 4.433111462276429e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.03 | consumed tokens: 1294336000.0 | grad norm avg: 0.65 | grad norm last: 0.64 | 
2026-01-01T22:34:06 | step: 39600 | train samples/s: 266.2 | train mfu (16-bit): -1.0 | lr mean: 4.430224726093002e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.19 | train loss last: 3.04 | consumed tokens: 1297612800.0 | grad norm avg: 0.64 | grad norm last: 0.63 | 
2026-01-01T22:34:34 | step: 39700 | train samples/s: 269.6 | train mfu (16-bit): -1.0 | lr mean: 4.4273314415477216e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.19 | train loss last: 3.19 | consumed tokens: 1300889600.0 | grad norm avg: 0.64 | grad norm last: 0.64 | 
2026-01-01T22:35:03 | step: 39800 | train samples/s: 266.7 | train mfu (16-bit): -1.0 | lr mean: 4.4244319724384695e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.21 | train loss last: 3.24 | consumed tokens: 1304166400.0 | grad norm avg: 0.63 | grad norm last: 0.63 | 
2026-01-01T22:35:31 | step: 39900 | train samples/s: 269.0 | train mfu (16-bit): -1.0 | lr mean: 4.421525954967365e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.38 | consumed tokens: 1307443200.0 | grad norm avg: 0.64 | grad norm last: 0.61 | 
2026-01-01T22:36:00 | step: 40000 | train samples/s: 266.0 | train mfu (16-bit): -1.0 | lr mean: 4.418613389134407e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.28 | consumed tokens: 1310720000.0 | grad norm avg: 0.65 | grad norm last: 0.66 | 
2026-01-01T22:36:30 | step: 40100 | train samples/s: 265.9 | train mfu (16-bit): -1.0 | lr mean: 4.415695002535358e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.19 | train loss last: 3.5 | consumed tokens: 1313996800.0 | grad norm avg: 0.64 | grad norm last: 0.6 | 
2026-01-01T22:36:59 | step: 40200 | train samples/s: 266.2 | train mfu (16-bit): -1.0 | lr mean: 4.4127697037765756e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.17 | consumed tokens: 1317273600.0 | grad norm avg: 0.64 | grad norm last: 0.6 | 
2026-01-01T22:37:27 | step: 40300 | train samples/s: 268.9 | train mfu (16-bit): -1.0 | lr mean: 4.409838584251702e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.02 | consumed tokens: 1320550400.0 | grad norm avg: 0.64 | grad norm last: 0.6 | 
2026-01-01T22:37:55 | step: 40400 | train samples/s: 269.4 | train mfu (16-bit): -1.0 | lr mean: 4.406900916364975e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.08 | consumed tokens: 1323827200.0 | grad norm avg: 0.64 | grad norm last: 0.68 | 
2026-01-01T22:38:24 | step: 40500 | train samples/s: 266.9 | train mfu (16-bit): -1.0 | lr mean: 4.403956700116396e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.18 | consumed tokens: 1327104000.0 | grad norm avg: 0.65 | grad norm last: 0.73 | 
2026-01-01T22:38:52 | step: 40600 | train samples/s: 270.2 | train mfu (16-bit): -1.0 | lr mean: 4.4010062993038446e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.19 | train loss last: 3.07 | consumed tokens: 1330380800.0 | grad norm avg: 0.63 | grad norm last: 0.63 | 
2026-01-01T22:39:20 | step: 40700 | train samples/s: 266.5 | train mfu (16-bit): -1.0 | lr mean: 4.398049713927321e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.19 | train loss last: 3.17 | consumed tokens: 1333657600.0 | grad norm avg: 0.64 | grad norm last: 0.69 | 
2026-01-01T22:39:49 | step: 40800 | train samples/s: 267.0 | train mfu (16-bit): -1.0 | lr mean: 4.3950869439868256e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.19 | train loss last: 3.0 | consumed tokens: 1336934400.0 | grad norm avg: 0.64 | grad norm last: 0.64 | 
2026-01-01T22:40:17 | step: 40900 | train samples/s: 266.2 | train mfu (16-bit): -1.0 | lr mean: 4.392117989482358e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.27 | consumed tokens: 1340211200.0 | grad norm avg: 0.63 | grad norm last: 0.64 | 
2026-01-01T22:40:46 | step: 41000 | train samples/s: 268.4 | train mfu (16-bit): -1.0 | lr mean: 4.389142486616038e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.19 | train loss last: 3.45 | consumed tokens: 1343488000.0 | grad norm avg: 0.64 | grad norm last: 0.64 | 
2026-01-01T22:41:14 | step: 41100 | train samples/s: 266.7 | train mfu (16-bit): -1.0 | lr mean: 4.3861607991857454e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.48 | consumed tokens: 1346764800.0 | grad norm avg: 0.63 | grad norm last: 0.67 | 
2026-01-01T22:41:42 | step: 41200 | train samples/s: 269.2 | train mfu (16-bit): -1.0 | lr mean: 4.383172927191481e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.3 | consumed tokens: 1350041600.0 | grad norm avg: 0.64 | grad norm last: 0.67 | 
2026-01-01T22:42:11 | step: 41300 | train samples/s: 269.8 | train mfu (16-bit): -1.0 | lr mean: 4.3801788706332445e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 2.71 | consumed tokens: 1353318400.0 | grad norm avg: 0.64 | grad norm last: 0.66 | 
2026-01-01T22:42:39 | step: 41400 | train samples/s: 267.7 | train mfu (16-bit): -1.0 | lr mean: 4.377178629511036e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.19 | train loss last: 3.02 | consumed tokens: 1356595200.0 | grad norm avg: 0.64 | grad norm last: 0.64 | 
2026-01-01T22:43:07 | step: 41500 | train samples/s: 269.9 | train mfu (16-bit): -1.0 | lr mean: 4.374171840026975e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.2 | consumed tokens: 1359872000.0 | grad norm avg: 0.64 | grad norm last: 0.64 | 
2026-01-01T22:43:36 | step: 41600 | train samples/s: 264.6 | train mfu (16-bit): -1.0 | lr mean: 4.371159229776822e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.07 | consumed tokens: 1363148800.0 | grad norm avg: 0.65 | grad norm last: 0.58 | 
2026-01-01T22:44:04 | step: 41700 | train samples/s: 269.5 | train mfu (16-bit): -1.0 | lr mean: 4.368140434962697e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.16 | consumed tokens: 1366425600.0 | grad norm avg: 0.65 | grad norm last: 0.59 | 
2026-01-01T22:44:33 | step: 41800 | train samples/s: 265.6 | train mfu (16-bit): -1.0 | lr mean: 4.36511509178672e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.34 | consumed tokens: 1369702400.0 | grad norm avg: 0.65 | grad norm last: 0.63 | 
2026-01-01T22:45:01 | step: 41900 | train samples/s: 268.8 | train mfu (16-bit): -1.0 | lr mean: 4.362083927844651e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.31 | consumed tokens: 1372979200.0 | grad norm avg: 0.65 | grad norm last: 0.71 | 
2026-01-01T22:45:29 | step: 42000 | train samples/s: 268.3 | train mfu (16-bit): -1.0 | lr mean: 4.35904657933861e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.07 | consumed tokens: 1376256000.0 | grad norm avg: 0.64 | grad norm last: 0.66 | 
2026-01-01T22:45:58 | step: 42100 | train samples/s: 266.5 | train mfu (16-bit): -1.0 | lr mean: 4.356003046268597e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.48 | consumed tokens: 1379532800.0 | grad norm avg: 0.65 | grad norm last: 0.63 | 
2026-01-01T22:46:27 | step: 42200 | train samples/s: 265.7 | train mfu (16-bit): -1.0 | lr mean: 4.352953328634612e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.27 | consumed tokens: 1382809600.0 | grad norm avg: 0.65 | grad norm last: 0.63 | 
2026-01-01T22:46:55 | step: 42300 | train samples/s: 268.6 | train mfu (16-bit): -1.0 | lr mean: 4.349897426436655e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.19 | train loss last: 3.01 | consumed tokens: 1386086400.0 | grad norm avg: 0.65 | grad norm last: 0.65 | 
2026-01-01T22:47:23 | step: 42400 | train samples/s: 270.0 | train mfu (16-bit): -1.0 | lr mean: 4.346835339674726e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.22 | consumed tokens: 1389363200.0 | grad norm avg: 0.65 | grad norm last: 0.63 | 
2026-01-01T22:47:52 | step: 42500 | train samples/s: 267.2 | train mfu (16-bit): -1.0 | lr mean: 4.343767068348825e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.14 | consumed tokens: 1392640000.0 | grad norm avg: 0.66 | grad norm last: 0.66 | 
2026-01-01T22:48:20 | step: 42600 | train samples/s: 269.9 | train mfu (16-bit): -1.0 | lr mean: 4.3406929762568325e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.08 | consumed tokens: 1395916800.0 | grad norm avg: 0.64 | grad norm last: 0.64 | 
2026-01-01T22:48:48 | step: 42700 | train samples/s: 269.1 | train mfu (16-bit): -1.0 | lr mean: 4.337612699600868e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.2 | train loss last: 3.23 | consumed tokens: 1399193600.0 | grad norm avg: 0.64 | grad norm last: 0.64 | 
2026-01-01T22:49:17 | step: 42800 | train samples/s: 266.4 | train mfu (16-bit): -1.0 | lr mean: 4.334526238380931e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.2 | consumed tokens: 1402470400.0 | grad norm avg: 0.65 | grad norm last: 0.63 | 
2026-01-01T22:49:45 | step: 42900 | train samples/s: 266.1 | train mfu (16-bit): -1.0 | lr mean: 4.3314339563949034e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 2.93 | consumed tokens: 1405747200.0 | grad norm avg: 0.64 | grad norm last: 0.64 | 
2026-01-01T22:50:13 | step: 43000 | train samples/s: 269.2 | train mfu (16-bit): -1.0 | lr mean: 4.3283354898449033e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.22 | consumed tokens: 1409024000.0 | grad norm avg: 0.64 | grad norm last: 0.64 | 
2026-01-01T22:50:42 | step: 43100 | train samples/s: 268.0 | train mfu (16-bit): -1.0 | lr mean: 4.325230838730931e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.19 | consumed tokens: 1412300800.0 | grad norm avg: 0.65 | grad norm last: 0.71 | 
2026-01-01T22:51:10 | step: 43200 | train samples/s: 267.1 | train mfu (16-bit): -1.0 | lr mean: 4.322120366850868e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.67 | consumed tokens: 1415577600.0 | grad norm avg: 0.66 | grad norm last: 0.67 | 
2026-01-01T22:51:38 | step: 43300 | train samples/s: 269.6 | train mfu (16-bit): -1.0 | lr mean: 4.3190037104068324e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.11 | consumed tokens: 1418854400.0 | grad norm avg: 0.65 | grad norm last: 0.68 | 
2026-01-01T22:52:07 | step: 43400 | train samples/s: 266.3 | train mfu (16-bit): -1.0 | lr mean: 4.3158812331967056e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.43 | consumed tokens: 1422131200.0 | grad norm avg: 0.64 | grad norm last: 0.6 | 
2026-01-01T22:52:35 | step: 43500 | train samples/s: 267.3 | train mfu (16-bit): -1.0 | lr mean: 4.312752571422607e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.07 | consumed tokens: 1425408000.0 | grad norm avg: 0.64 | grad norm last: 0.65 | 
2026-01-01T22:53:04 | step: 43600 | train samples/s: 268.3 | train mfu (16-bit): -1.0 | lr mean: 4.3096180888824165e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.68 | consumed tokens: 1428684800.0 | grad norm avg: 0.65 | grad norm last: 0.82 | 
2026-01-01T22:53:32 | step: 43700 | train samples/s: 269.3 | train mfu (16-bit): -1.0 | lr mean: 4.306477421778254e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.12 | consumed tokens: 1431961600.0 | grad norm avg: 0.64 | grad norm last: 0.65 | 
2026-01-01T22:54:01 | step: 43800 | train samples/s: 266.9 | train mfu (16-bit): -1.0 | lr mean: 4.30333057011012e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.15 | consumed tokens: 1435238400.0 | grad norm avg: 0.65 | grad norm last: 0.58 | 
2026-01-01T22:54:29 | step: 43900 | train samples/s: 267.1 | train mfu (16-bit): -1.0 | lr mean: 4.300178261473775e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 2.98 | consumed tokens: 1438515200.0 | grad norm avg: 0.64 | grad norm last: 0.63 | 
2026-01-01T22:54:57 | step: 44000 | train samples/s: 269.5 | train mfu (16-bit): -1.0 | lr mean: 4.297019768273458e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.52 | consumed tokens: 1441792000.0 | grad norm avg: 0.65 | grad norm last: 0.74 | 
2026-01-01T22:55:26 | step: 44100 | train samples/s: 266.8 | train mfu (16-bit): -1.0 | lr mean: 4.293855090509169e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.01 | consumed tokens: 1445068800.0 | grad norm avg: 0.64 | grad norm last: 0.73 | 
2026-01-01T22:55:54 | step: 44200 | train samples/s: 266.8 | train mfu (16-bit): -1.0 | lr mean: 4.290684955776669e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.07 | consumed tokens: 1448345600.0 | grad norm avg: 0.65 | grad norm last: 0.67 | 
2026-01-01T22:56:22 | step: 44300 | train samples/s: 269.0 | train mfu (16-bit): -1.0 | lr mean: 4.287508636480197e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.16 | consumed tokens: 1451622400.0 | grad norm avg: 0.65 | grad norm last: 0.6 | 
2026-01-01T22:56:51 | step: 44400 | train samples/s: 267.3 | train mfu (16-bit): -1.0 | lr mean: 4.284326496417634e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.25 | consumed tokens: 1454899200.0 | grad norm avg: 0.65 | grad norm last: 0.68 | 
2026-01-01T22:57:20 | step: 44500 | train samples/s: 265.3 | train mfu (16-bit): -1.0 | lr mean: 4.281138171791099e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.12 | consumed tokens: 1458176000.0 | grad norm avg: 0.65 | grad norm last: 0.63 | 
2026-01-01T22:57:48 | step: 44600 | train samples/s: 265.6 | train mfu (16-bit): -1.0 | lr mean: 4.2779440263984725e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.2 | consumed tokens: 1461452800.0 | grad norm avg: 0.65 | grad norm last: 0.68 | 
2026-01-01T22:58:17 | step: 44700 | train samples/s: 269.3 | train mfu (16-bit): -1.0 | lr mean: 4.274744424037635e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.2 | consumed tokens: 1464729600.0 | grad norm avg: 0.65 | grad norm last: 0.61 | 
2026-01-01T22:58:45 | step: 44800 | train samples/s: 267.3 | train mfu (16-bit): -1.0 | lr mean: 4.271538637112826e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.47 | consumed tokens: 1468006400.0 | grad norm avg: 0.65 | grad norm last: 0.57 | 
2026-01-01T22:59:14 | step: 44900 | train samples/s: 266.4 | train mfu (16-bit): -1.0 | lr mean: 4.2683270294219255e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.5 | consumed tokens: 1471283200.0 | grad norm avg: 0.64 | grad norm last: 0.68 | 
2026-01-01T22:59:42 | step: 45000 | train samples/s: 269.6 | train mfu (16-bit): -1.0 | lr mean: 4.265109237167053e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.07 | consumed tokens: 1474560000.0 | grad norm avg: 0.64 | grad norm last: 0.69 | 
2026-01-01T23:00:12 | step: 45100 | train samples/s: 269.8 | train mfu (16-bit): -1.0 | lr mean: 4.26188598794397e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.27 | consumed tokens: 1477836800.0 | grad norm avg: 0.65 | grad norm last: 0.68 | 
2026-01-01T23:00:40 | step: 45200 | train samples/s: 266.6 | train mfu (16-bit): -1.0 | lr mean: 4.258656917954795e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 2.86 | consumed tokens: 1481113600.0 | grad norm avg: 0.65 | grad norm last: 0.63 | 
2026-01-01T23:01:08 | step: 45300 | train samples/s: 269.5 | train mfu (16-bit): -1.0 | lr mean: 4.255422027199529e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.07 | consumed tokens: 1484390400.0 | grad norm avg: 0.66 | grad norm last: 0.72 | 
2026-01-01T23:01:37 | step: 45400 | train samples/s: 267.0 | train mfu (16-bit): -1.0 | lr mean: 4.252181315678172e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.08 | consumed tokens: 1487667200.0 | grad norm avg: 0.66 | grad norm last: 0.61 | 
2026-01-01T23:02:06 | step: 45500 | train samples/s: 264.2 | train mfu (16-bit): -1.0 | lr mean: 4.248934783390723e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.22 | consumed tokens: 1490944000.0 | grad norm avg: 0.66 | grad norm last: 0.69 | 
2026-01-01T23:02:34 | step: 45600 | train samples/s: 270.0 | train mfu (16-bit): -1.0 | lr mean: 4.245682430337183e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 2.7 | consumed tokens: 1494220800.0 | grad norm avg: 0.66 | grad norm last: 0.71 | 
2026-01-01T23:03:02 | step: 45700 | train samples/s: 269.7 | train mfu (16-bit): -1.0 | lr mean: 4.242424256517552e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.2 | consumed tokens: 1497497600.0 | grad norm avg: 0.66 | grad norm last: 0.65 | 
2026-01-01T23:03:30 | step: 45800 | train samples/s: 269.3 | train mfu (16-bit): -1.0 | lr mean: 4.239160261931829e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.15 | consumed tokens: 1500774400.0 | grad norm avg: 0.65 | grad norm last: 0.65 | 
2026-01-01T23:03:59 | step: 45900 | train samples/s: 266.7 | train mfu (16-bit): -1.0 | lr mean: 4.235890810377896e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.03 | consumed tokens: 1504051200.0 | grad norm avg: 0.65 | grad norm last: 0.63 | 
2026-01-01T23:04:27 | step: 46000 | train samples/s: 269.0 | train mfu (16-bit): -1.0 | lr mean: 4.2326151742599905e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.31 | consumed tokens: 1507328000.0 | grad norm avg: 0.65 | grad norm last: 0.63 | 
2026-01-01T23:04:56 | step: 46100 | train samples/s: 266.5 | train mfu (16-bit): -1.0 | lr mean: 4.2293340811738744e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.29 | consumed tokens: 1510604800.0 | grad norm avg: 0.65 | grad norm last: 0.6 | 
2026-01-01T23:05:24 | step: 46200 | train samples/s: 263.4 | train mfu (16-bit): -1.0 | lr mean: 4.226047167321667e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.39 | consumed tokens: 1513881600.0 | grad norm avg: 0.64 | grad norm last: 0.64 | 
2026-01-01T23:05:53 | step: 46300 | train samples/s: 268.3 | train mfu (16-bit): -1.0 | lr mean: 4.222754796501249e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.21 | consumed tokens: 1517158400.0 | grad norm avg: 0.65 | grad norm last: 0.66 | 
2026-01-01T23:06:21 | step: 46400 | train samples/s: 271.1 | train mfu (16-bit): -1.0 | lr mean: 4.21945660491474e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.33 | consumed tokens: 1520435200.0 | grad norm avg: 0.66 | grad norm last: 0.63 | 
2026-01-01T23:06:49 | step: 46500 | train samples/s: 268.8 | train mfu (16-bit): -1.0 | lr mean: 4.216152592562139e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.26 | consumed tokens: 1523712000.0 | grad norm avg: 0.65 | grad norm last: 0.73 | 
2026-01-01T23:07:17 | step: 46600 | train samples/s: 267.3 | train mfu (16-bit): -1.0 | lr mean: 4.212843123241328e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.31 | consumed tokens: 1526988800.0 | grad norm avg: 0.65 | grad norm last: 0.63 | 
2026-01-01T23:07:46 | step: 46700 | train samples/s: 269.0 | train mfu (16-bit): -1.0 | lr mean: 4.209527833154425e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.23 | consumed tokens: 1530265600.0 | grad norm avg: 0.64 | grad norm last: 0.65 | 
2026-01-01T23:08:14 | step: 46800 | train samples/s: 263.9 | train mfu (16-bit): -1.0 | lr mean: 4.206206722301431e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.17 | consumed tokens: 1533542400.0 | grad norm avg: 0.66 | grad norm last: 0.67 | 
2026-01-01T23:08:43 | step: 46900 | train samples/s: 267.5 | train mfu (16-bit): -1.0 | lr mean: 4.202880154480226e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.19 | train loss last: 3.29 | consumed tokens: 1536819200.0 | grad norm avg: 0.66 | grad norm last: 0.67 | 
2026-01-01T23:09:11 | step: 47000 | train samples/s: 266.7 | train mfu (16-bit): -1.0 | lr mean: 4.199548129690811e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 2.95 | consumed tokens: 1540096000.0 | grad norm avg: 0.65 | grad norm last: 0.67 | 
2026-01-01T23:09:40 | step: 47100 | train samples/s: 268.4 | train mfu (16-bit): -1.0 | lr mean: 4.1962102841353044e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.34 | consumed tokens: 1543372800.0 | grad norm avg: 0.67 | grad norm last: 0.63 | 
2026-01-01T23:10:08 | step: 47200 | train samples/s: 268.4 | train mfu (16-bit): -1.0 | lr mean: 4.1928666178137064e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.53 | consumed tokens: 1546649600.0 | grad norm avg: 0.65 | grad norm last: 0.68 | 
2026-01-01T23:10:36 | step: 47300 | train samples/s: 265.6 | train mfu (16-bit): -1.0 | lr mean: 4.1895178583217785e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.2 | consumed tokens: 1549926400.0 | grad norm avg: 0.65 | grad norm last: 0.64 | 
2026-01-01T23:11:05 | step: 47400 | train samples/s: 269.6 | train mfu (16-bit): -1.0 | lr mean: 4.186163278063759e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.07 | consumed tokens: 1553203200.0 | grad norm avg: 0.66 | grad norm last: 0.63 | 
2026-01-01T23:11:33 | step: 47500 | train samples/s: 263.4 | train mfu (16-bit): -1.0 | lr mean: 4.1828028770396486e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 2.98 | consumed tokens: 1556480000.0 | grad norm avg: 0.65 | grad norm last: 0.66 | 
2026-01-01T23:12:02 | step: 47600 | train samples/s: 266.3 | train mfu (16-bit): -1.0 | lr mean: 4.1794370190473273e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.05 | consumed tokens: 1559756800.0 | grad norm avg: 0.65 | grad norm last: 0.61 | 
2026-01-01T23:12:30 | step: 47700 | train samples/s: 269.6 | train mfu (16-bit): -1.0 | lr mean: 4.1760657040867954e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.36 | consumed tokens: 1563033600.0 | grad norm avg: 0.66 | grad norm last: 0.65 | 
2026-01-01T23:12:58 | step: 47800 | train samples/s: 268.1 | train mfu (16-bit): -1.0 | lr mean: 4.172688932158053e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.19 | consumed tokens: 1566310400.0 | grad norm avg: 0.66 | grad norm last: 0.68 | 
2026-01-01T23:13:27 | step: 47900 | train samples/s: 266.1 | train mfu (16-bit): -1.0 | lr mean: 4.1693067032611e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.38 | consumed tokens: 1569587200.0 | grad norm avg: 0.66 | grad norm last: 0.64 | 
2026-01-01T23:13:55 | step: 48000 | train samples/s: 268.9 | train mfu (16-bit): -1.0 | lr mean: 4.165918653598055e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.14 | consumed tokens: 1572864000.0 | grad norm avg: 0.65 | grad norm last: 0.65 | 
2026-01-01T23:14:23 | step: 48100 | train samples/s: 270.5 | train mfu (16-bit): -1.0 | lr mean: 4.1625251469668e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 2.81 | consumed tokens: 1576140800.0 | grad norm avg: 0.66 | grad norm last: 0.69 | 
2026-01-01T23:14:52 | step: 48200 | train samples/s: 264.2 | train mfu (16-bit): -1.0 | lr mean: 4.159126183367334e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.38 | consumed tokens: 1579417600.0 | grad norm avg: 0.65 | grad norm last: 0.65 | 
2026-01-01T23:15:20 | step: 48300 | train samples/s: 268.8 | train mfu (16-bit): -1.0 | lr mean: 4.155721762799658e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.05 | consumed tokens: 1582694400.0 | grad norm avg: 0.66 | grad norm last: 0.63 | 
2026-01-01T23:15:49 | step: 48400 | train samples/s: 267.5 | train mfu (16-bit): -1.0 | lr mean: 4.152311885263771e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.21 | consumed tokens: 1585971200.0 | grad norm avg: 0.67 | grad norm last: 0.71 | 
2026-01-01T23:16:17 | step: 48500 | train samples/s: 269.4 | train mfu (16-bit): -1.0 | lr mean: 4.148896550759673e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.25 | consumed tokens: 1589248000.0 | grad norm avg: 0.65 | grad norm last: 0.66 | 
2026-01-01T23:16:45 | step: 48600 | train samples/s: 267.4 | train mfu (16-bit): -1.0 | lr mean: 4.145475759287365e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.13 | consumed tokens: 1592524800.0 | grad norm avg: 0.66 | grad norm last: 0.77 | 
2026-01-01T23:17:14 | step: 48700 | train samples/s: 268.6 | train mfu (16-bit): -1.0 | lr mean: 4.142049510846846e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.18 | train loss last: 3.07 | consumed tokens: 1595801600.0 | grad norm avg: 0.67 | grad norm last: 0.66 | 
2026-01-01T23:17:42 | step: 48800 | train samples/s: 268.8 | train mfu (16-bit): -1.0 | lr mean: 4.138617805438116e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.24 | consumed tokens: 1599078400.0 | grad norm avg: 0.66 | grad norm last: 0.6 | 
2026-01-01T23:18:11 | step: 48900 | train samples/s: 263.3 | train mfu (16-bit): -1.0 | lr mean: 4.135180643061176e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.27 | consumed tokens: 1602355200.0 | grad norm avg: 0.66 | grad norm last: 0.71 | 
2026-01-01T23:18:39 | step: 49000 | train samples/s: 268.9 | train mfu (16-bit): -1.0 | lr mean: 4.131738387513906e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.17 | consumed tokens: 1605632000.0 | grad norm avg: 0.66 | grad norm last: 0.59 | 
2026-01-01T23:19:08 | step: 49100 | train samples/s: 266.4 | train mfu (16-bit): -1.0 | lr mean: 4.128290311200544e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.18 | consumed tokens: 1608908800.0 | grad norm avg: 0.65 | grad norm last: 0.6 | 
2026-01-01T23:19:36 | step: 49200 | train samples/s: 269.4 | train mfu (16-bit): -1.0 | lr mean: 4.124837141716853e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.24 | consumed tokens: 1612185600.0 | grad norm avg: 0.66 | grad norm last: 0.59 | 
2026-01-01T23:20:04 | step: 49300 | train samples/s: 270.4 | train mfu (16-bit): -1.0 | lr mean: 4.121378515264951e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.07 | consumed tokens: 1615462400.0 | grad norm avg: 0.64 | grad norm last: 0.59 | 
2026-01-01T23:20:32 | step: 49400 | train samples/s: 269.8 | train mfu (16-bit): -1.0 | lr mean: 4.117914431844838e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.45 | consumed tokens: 1618739200.0 | grad norm avg: 0.64 | grad norm last: 0.62 | 
2026-01-01T23:21:01 | step: 49500 | train samples/s: 266.3 | train mfu (16-bit): -1.0 | lr mean: 4.1144448914565146e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.21 | consumed tokens: 1622016000.0 | grad norm avg: 0.66 | grad norm last: 0.6 | 
2026-01-01T23:21:29 | step: 49600 | train samples/s: 264.9 | train mfu (16-bit): -1.0 | lr mean: 4.110970257897861e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.04 | consumed tokens: 1625292800.0 | grad norm avg: 0.67 | grad norm last: 0.63 | 
2026-01-01T23:21:58 | step: 49700 | train samples/s: 268.7 | train mfu (16-bit): -1.0 | lr mean: 4.1074901673709974e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.32 | consumed tokens: 1628569600.0 | grad norm avg: 0.65 | grad norm last: 0.59 | 
2026-01-01T23:22:26 | step: 49800 | train samples/s: 269.5 | train mfu (16-bit): -1.0 | lr mean: 4.104004619875923e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.27 | consumed tokens: 1631846400.0 | grad norm avg: 0.65 | grad norm last: 0.6 | 
2026-01-01T23:22:54 | step: 49900 | train samples/s: 266.9 | train mfu (16-bit): -1.0 | lr mean: 4.100513979210518e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.21 | consumed tokens: 1635123200.0 | grad norm avg: 0.66 | grad norm last: 0.64 | 
2026-01-01T23:23:23 | step: 50000 | train samples/s: 267.4 | train mfu (16-bit): -1.0 | lr mean: 4.097018245374784e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.02 | consumed tokens: 1638400000.0 | grad norm avg: 0.66 | grad norm last: 0.64 | 
2026-01-01T23:23:53 | step: 50100 | train samples/s: 269.0 | train mfu (16-bit): -1.0 | lr mean: 4.093516690772958e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.32 | consumed tokens: 1641676800.0 | grad norm avg: 0.65 | grad norm last: 0.62 | 
2026-01-01T23:24:21 | step: 50200 | train samples/s: 264.2 | train mfu (16-bit): -1.0 | lr mean: 4.090010406798683e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.01 | consumed tokens: 1644953600.0 | grad norm avg: 0.65 | grad norm last: 0.63 | 
2026-01-01T23:24:50 | step: 50300 | train samples/s: 270.2 | train mfu (16-bit): -1.0 | lr mean: 4.0864986658561975e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.24 | consumed tokens: 1648230400.0 | grad norm avg: 0.66 | grad norm last: 0.67 | 
2026-01-01T23:25:18 | step: 50400 | train samples/s: 269.2 | train mfu (16-bit): -1.0 | lr mean: 4.082981467945501e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.02 | consumed tokens: 1651507200.0 | grad norm avg: 0.66 | grad norm last: 0.63 | 
2026-01-01T23:25:46 | step: 50500 | train samples/s: 268.6 | train mfu (16-bit): -1.0 | lr mean: 4.079459176864475e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.02 | consumed tokens: 1654784000.0 | grad norm avg: 0.66 | grad norm last: 0.67 | 
2026-01-01T23:26:15 | step: 50600 | train samples/s: 269.0 | train mfu (16-bit): -1.0 | lr mean: 4.075931792613119e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 2.94 | consumed tokens: 1658060800.0 | grad norm avg: 0.66 | grad norm last: 0.75 | 
2026-01-01T23:26:43 | step: 50700 | train samples/s: 265.0 | train mfu (16-bit): -1.0 | lr mean: 4.072398951393552e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 2.85 | consumed tokens: 1661337600.0 | grad norm avg: 0.67 | grad norm last: 0.6 | 
2026-01-01T23:27:11 | step: 50800 | train samples/s: 269.6 | train mfu (16-bit): -1.0 | lr mean: 4.0688610170036554e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 2.96 | consumed tokens: 1664614400.0 | grad norm avg: 0.66 | grad norm last: 0.68 | 
2026-01-01T23:27:40 | step: 50900 | train samples/s: 264.0 | train mfu (16-bit): -1.0 | lr mean: 4.065317989443429e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 2.76 | consumed tokens: 1667891200.0 | grad norm avg: 0.65 | grad norm last: 0.63 | 
2026-01-01T23:28:08 | step: 51000 | train samples/s: 270.1 | train mfu (16-bit): -1.0 | lr mean: 4.061769868712872e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.25 | consumed tokens: 1671168000.0 | grad norm avg: 0.66 | grad norm last: 0.66 | 
2026-01-01T23:28:37 | step: 51100 | train samples/s: 269.6 | train mfu (16-bit): -1.0 | lr mean: 4.058216291014105e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.48 | consumed tokens: 1674444800.0 | grad norm avg: 0.67 | grad norm last: 0.62 | 
2026-01-01T23:29:05 | step: 51200 | train samples/s: 270.4 | train mfu (16-bit): -1.0 | lr mean: 4.054657620145008e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.25 | consumed tokens: 1677721600.0 | grad norm avg: 0.67 | grad norm last: 0.67 | 
2026-01-01T23:29:33 | step: 51300 | train samples/s: 266.5 | train mfu (16-bit): -1.0 | lr mean: 4.0510942199034616e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.07 | consumed tokens: 1680998400.0 | grad norm avg: 0.65 | grad norm last: 0.74 | 
2026-01-01T23:30:02 | step: 51400 | train samples/s: 266.0 | train mfu (16-bit): -1.0 | lr mean: 4.047525362693705e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.26 | consumed tokens: 1684275200.0 | grad norm avg: 0.67 | grad norm last: 0.64 | 
2026-01-01T23:30:30 | step: 51500 | train samples/s: 266.2 | train mfu (16-bit): -1.0 | lr mean: 4.043951048515737e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.2 | consumed tokens: 1687552000.0 | grad norm avg: 0.66 | grad norm last: 0.7 | 
2026-01-01T23:30:59 | step: 51600 | train samples/s: 266.4 | train mfu (16-bit): -1.0 | lr mean: 4.04037200496532e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.33 | consumed tokens: 1690828800.0 | grad norm avg: 0.66 | grad norm last: 0.71 | 
2026-01-01T23:31:27 | step: 51700 | train samples/s: 269.3 | train mfu (16-bit): -1.0 | lr mean: 4.0367878682445735e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.3 | consumed tokens: 1694105600.0 | grad norm avg: 0.67 | grad norm last: 0.64 | 
2026-01-01T23:31:55 | step: 51800 | train samples/s: 269.2 | train mfu (16-bit): -1.0 | lr mean: 4.033198638353497e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.09 | consumed tokens: 1697382400.0 | grad norm avg: 0.66 | grad norm last: 0.75 | 
2026-01-01T23:32:24 | step: 51900 | train samples/s: 269.0 | train mfu (16-bit): -1.0 | lr mean: 4.02960431529209e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.42 | consumed tokens: 1700659200.0 | grad norm avg: 0.66 | grad norm last: 0.62 | 
2026-01-01T23:32:52 | step: 52000 | train samples/s: 266.5 | train mfu (16-bit): -1.0 | lr mean: 4.0260048990603536e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.26 | consumed tokens: 1703936000.0 | grad norm avg: 0.67 | grad norm last: 0.69 | 
2026-01-01T23:33:20 | step: 52100 | train samples/s: 269.6 | train mfu (16-bit): -1.0 | lr mean: 4.022400389658287e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.11 | consumed tokens: 1707212800.0 | grad norm avg: 0.66 | grad norm last: 0.65 | 
2026-01-01T23:33:49 | step: 52200 | train samples/s: 251.8 | train mfu (16-bit): -1.0 | lr mean: 4.0187911508837715e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.29 | consumed tokens: 1710489600.0 | grad norm avg: 0.66 | grad norm last: 0.6 | 
2026-01-01T23:34:18 | step: 52300 | train samples/s: 256.2 | train mfu (16-bit): -1.0 | lr mean: 4.015176455141045e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.41 | consumed tokens: 1713766400.0 | grad norm avg: 0.67 | grad norm last: 0.69 | 
2026-01-01T23:34:46 | step: 52400 | train samples/s: 269.2 | train mfu (16-bit): -1.0 | lr mean: 4.0115570300258696e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.03 | consumed tokens: 1717043200.0 | grad norm avg: 0.66 | grad norm last: 0.65 | 
2026-01-01T23:35:14 | step: 52500 | train samples/s: 270.0 | train mfu (16-bit): -1.0 | lr mean: 4.007932511740364e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 2.85 | consumed tokens: 1720320000.0 | grad norm avg: 0.66 | grad norm last: 0.63 | 
2026-01-01T23:35:42 | step: 52600 | train samples/s: 269.4 | train mfu (16-bit): -1.0 | lr mean: 4.004302900284529e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.17 | consumed tokens: 1723596800.0 | grad norm avg: 0.67 | grad norm last: 0.69 | 
2026-01-01T23:36:11 | step: 52700 | train samples/s: 266.6 | train mfu (16-bit): -1.0 | lr mean: 4.000668559456244e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 3.26 | consumed tokens: 1726873600.0 | grad norm avg: 0.67 | grad norm last: 0.72 | 
2026-01-01T23:36:39 | step: 52800 | train samples/s: 266.4 | train mfu (16-bit): -1.0 | lr mean: 3.9970291254576296e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.33 | consumed tokens: 1730150400.0 | grad norm avg: 0.66 | grad norm last: 0.69 | 
2026-01-01T23:37:07 | step: 52900 | train samples/s: 268.1 | train mfu (16-bit): -1.0 | lr mean: 3.993384962086566e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 2.98 | consumed tokens: 1733427200.0 | grad norm avg: 0.67 | grad norm last: 0.61 | 
2026-01-01T23:37:36 | step: 53000 | train samples/s: 266.1 | train mfu (16-bit): -1.0 | lr mean: 3.9897353417472914e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.47 | consumed tokens: 1736704000.0 | grad norm avg: 0.67 | grad norm last: 0.75 | 
2026-01-01T23:38:04 | step: 53100 | train samples/s: 268.5 | train mfu (16-bit): -1.0 | lr mean: 3.9860813558334485e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 2.93 | consumed tokens: 1739980800.0 | grad norm avg: 0.67 | grad norm last: 0.72 | 
2026-01-01T23:38:32 | step: 53200 | train samples/s: 270.4 | train mfu (16-bit): -1.0 | lr mean: 3.982421912951395e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 2.85 | consumed tokens: 1743257600.0 | grad norm avg: 0.66 | grad norm last: 0.67 | 
2026-01-01T23:39:01 | step: 53300 | train samples/s: 270.3 | train mfu (16-bit): -1.0 | lr mean: 3.978758104494773e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 2.85 | consumed tokens: 1746534400.0 | grad norm avg: 0.68 | grad norm last: 0.67 | 
2026-01-01T23:39:29 | step: 53400 | train samples/s: 267.5 | train mfu (16-bit): -1.0 | lr mean: 3.975089202867821e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.28 | consumed tokens: 1749811200.0 | grad norm avg: 0.67 | grad norm last: 0.64 | 
2026-01-01T23:39:57 | step: 53500 | train samples/s: 266.7 | train mfu (16-bit): -1.0 | lr mean: 3.971415208070539e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.28 | consumed tokens: 1753088000.0 | grad norm avg: 0.67 | grad norm last: 0.61 | 
2026-01-01T23:40:26 | step: 53600 | train samples/s: 267.4 | train mfu (16-bit): -1.0 | lr mean: 3.967736483900808e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.26 | consumed tokens: 1756364800.0 | grad norm avg: 0.67 | grad norm last: 0.64 | 
2026-01-01T23:40:54 | step: 53700 | train samples/s: 268.0 | train mfu (16-bit): -1.0 | lr mean: 3.9640530303586274e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.18 | consumed tokens: 1759641600.0 | grad norm avg: 0.67 | grad norm last: 0.69 | 
2026-01-01T23:41:22 | step: 53800 | train samples/s: 268.4 | train mfu (16-bit): -1.0 | lr mean: 3.960364483646117e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 2.98 | consumed tokens: 1762918400.0 | grad norm avg: 0.67 | grad norm last: 0.68 | 
2026-01-01T23:41:51 | step: 53900 | train samples/s: 268.4 | train mfu (16-bit): -1.0 | lr mean: 3.9566712075611576e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.02 | consumed tokens: 1766195200.0 | grad norm avg: 0.67 | grad norm last: 0.68 | 
2026-01-01T23:42:19 | step: 54000 | train samples/s: 268.2 | train mfu (16-bit): -1.0 | lr mean: 3.952973202103749e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.2 | consumed tokens: 1769472000.0 | grad norm avg: 0.67 | grad norm last: 0.69 | 
2026-01-01T23:42:47 | step: 54100 | train samples/s: 269.5 | train mfu (16-bit): -1.0 | lr mean: 3.949270467273891e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 2.98 | consumed tokens: 1772748800.0 | grad norm avg: 0.67 | grad norm last: 0.72 | 
2026-01-01T23:43:16 | step: 54200 | train samples/s: 267.4 | train mfu (16-bit): -1.0 | lr mean: 3.945563003071584e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.04 | consumed tokens: 1776025600.0 | grad norm avg: 0.68 | grad norm last: 0.7 | 
2026-01-01T23:43:44 | step: 54300 | train samples/s: 267.0 | train mfu (16-bit): -1.0 | lr mean: 3.941850445698947e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.04 | consumed tokens: 1779302400.0 | grad norm avg: 0.67 | grad norm last: 0.64 | 
2026-01-01T23:44:12 | step: 54400 | train samples/s: 266.9 | train mfu (16-bit): -1.0 | lr mean: 3.9381331589538604e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 2.87 | consumed tokens: 1782579200.0 | grad norm avg: 0.68 | grad norm last: 0.65 | 
2026-01-01T23:44:41 | step: 54500 | train samples/s: 269.7 | train mfu (16-bit): -1.0 | lr mean: 3.934411142836325e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.06 | consumed tokens: 1785856000.0 | grad norm avg: 0.68 | grad norm last: 0.72 | 
2026-01-01T23:45:09 | step: 54600 | train samples/s: 270.2 | train mfu (16-bit): -1.0 | lr mean: 3.930684761144221e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.3 | consumed tokens: 1789132800.0 | grad norm avg: 0.68 | grad norm last: 0.72 | 
2026-01-01T23:45:37 | step: 54700 | train samples/s: 266.5 | train mfu (16-bit): -1.0 | lr mean: 3.926953286281787e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.17 | consumed tokens: 1792409600.0 | grad norm avg: 0.68 | grad norm last: 0.69 | 
2026-01-01T23:46:06 | step: 54800 | train samples/s: 266.9 | train mfu (16-bit): -1.0 | lr mean: 3.923217082046904e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.27 | consumed tokens: 1795686400.0 | grad norm avg: 0.68 | grad norm last: 0.66 | 
2026-01-01T23:46:34 | step: 54900 | train samples/s: 270.0 | train mfu (16-bit): -1.0 | lr mean: 3.919476148439571e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.01 | consumed tokens: 1798963200.0 | grad norm avg: 0.67 | grad norm last: 0.72 | 
2026-01-01T23:47:02 | step: 55000 | train samples/s: 267.0 | train mfu (16-bit): -1.0 | lr mean: 3.9157308492576703e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.08 | consumed tokens: 1802240000.0 | grad norm avg: 0.68 | grad norm last: 0.66 | 
2026-01-01T23:47:32 | step: 55100 | train samples/s: 269.8 | train mfu (16-bit): -1.0 | lr mean: 3.9119804569054395e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.14 | consumed tokens: 1805516800.0 | grad norm avg: 0.68 | grad norm last: 0.65 | 
2026-01-01T23:48:01 | step: 55200 | train samples/s: 266.2 | train mfu (16-bit): -1.0 | lr mean: 3.90822569897864e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.17 | train loss last: 2.68 | consumed tokens: 1808793600.0 | grad norm avg: 0.67 | grad norm last: 0.72 | 
2026-01-01T23:48:29 | step: 55300 | train samples/s: 268.0 | train mfu (16-bit): -1.0 | lr mean: 3.9044662116793916e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 2.95 | consumed tokens: 1812070400.0 | grad norm avg: 0.67 | grad norm last: 0.67 | 
2026-01-01T23:48:58 | step: 55400 | train samples/s: 266.9 | train mfu (16-bit): -1.0 | lr mean: 3.900701995007694e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.09 | consumed tokens: 1815347200.0 | grad norm avg: 0.68 | grad norm last: 0.64 | 
2026-01-01T23:49:26 | step: 55500 | train samples/s: 266.0 | train mfu (16-bit): -1.0 | lr mean: 3.896933048963547e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.37 | consumed tokens: 1818624000.0 | grad norm avg: 0.68 | grad norm last: 0.61 | 
2026-01-01T23:49:55 | step: 55600 | train samples/s: 267.6 | train mfu (16-bit): -1.0 | lr mean: 3.893159737344831e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.14 | consumed tokens: 1821900800.0 | grad norm avg: 0.68 | grad norm last: 0.64 | 
2026-01-01T23:50:23 | step: 55700 | train samples/s: 266.1 | train mfu (16-bit): -1.0 | lr mean: 3.8893816963536665e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.27 | consumed tokens: 1825177600.0 | grad norm avg: 0.69 | grad norm last: 0.69 | 
2026-01-01T23:50:51 | step: 55800 | train samples/s: 269.3 | train mfu (16-bit): -1.0 | lr mean: 3.8855989259900525e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 2.98 | consumed tokens: 1828454400.0 | grad norm avg: 0.68 | grad norm last: 0.69 | 
2026-01-01T23:51:20 | step: 55900 | train samples/s: 269.5 | train mfu (16-bit): -1.0 | lr mean: 3.88181179005187e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.31 | consumed tokens: 1831731200.0 | grad norm avg: 0.69 | grad norm last: 0.76 | 
2026-01-01T23:51:48 | step: 56000 | train samples/s: 267.1 | train mfu (16-bit): -1.0 | lr mean: 3.8780199247412384e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.12 | consumed tokens: 1835008000.0 | grad norm avg: 0.68 | grad norm last: 0.68 | 
2026-01-01T23:52:17 | step: 56100 | train samples/s: 266.3 | train mfu (16-bit): -1.0 | lr mean: 3.874223693856038e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.53 | consumed tokens: 1838284800.0 | grad norm avg: 0.69 | grad norm last: 0.67 | 
2026-01-01T23:52:45 | step: 56200 | train samples/s: 266.3 | train mfu (16-bit): -1.0 | lr mean: 3.870422733598389e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 2.93 | consumed tokens: 1841561600.0 | grad norm avg: 0.67 | grad norm last: 0.63 | 
2026-01-01T23:53:13 | step: 56300 | train samples/s: 268.9 | train mfu (16-bit): -1.0 | lr mean: 3.866617407766171e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.0 | consumed tokens: 1844838400.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T23:53:42 | step: 56400 | train samples/s: 264.6 | train mfu (16-bit): -1.0 | lr mean: 3.8628073525615036e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.11 | consumed tokens: 1848115200.0 | grad norm avg: 0.7 | grad norm last: 0.73 | 
2026-01-01T23:54:10 | step: 56500 | train samples/s: 269.0 | train mfu (16-bit): -1.0 | lr mean: 3.858992931782268e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.05 | consumed tokens: 1851392000.0 | grad norm avg: 0.68 | grad norm last: 0.67 | 
2026-01-01T23:54:39 | step: 56600 | train samples/s: 269.5 | train mfu (16-bit): -1.0 | lr mean: 3.855174145428464e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.16 | consumed tokens: 1854668800.0 | grad norm avg: 0.7 | grad norm last: 0.65 | 
2026-01-01T23:55:07 | step: 56700 | train samples/s: 268.4 | train mfu (16-bit): -1.0 | lr mean: 3.8513506297022104e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.08 | consumed tokens: 1857945600.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-01T23:55:36 | step: 56800 | train samples/s: 264.4 | train mfu (16-bit): -1.0 | lr mean: 3.8475227484013885e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.11 | consumed tokens: 1861222400.0 | grad norm avg: 0.68 | grad norm last: 0.66 | 
2026-01-01T23:56:04 | step: 56900 | train samples/s: 269.6 | train mfu (16-bit): -1.0 | lr mean: 3.8436901377281174e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.21 | consumed tokens: 1864499200.0 | grad norm avg: 0.7 | grad norm last: 0.7 | 
2026-01-01T23:56:32 | step: 57000 | train samples/s: 266.2 | train mfu (16-bit): -1.0 | lr mean: 3.8398535252781585e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 2.66 | consumed tokens: 1867776000.0 | grad norm avg: 0.69 | grad norm last: 0.71 | 
2026-01-01T23:57:00 | step: 57100 | train samples/s: 269.5 | train mfu (16-bit): -1.0 | lr mean: 3.8360121834557503e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.29 | consumed tokens: 1871052800.0 | grad norm avg: 0.69 | grad norm last: 0.73 | 
2026-01-01T23:57:29 | step: 57200 | train samples/s: 268.8 | train mfu (16-bit): -1.0 | lr mean: 3.8321668398566544e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.19 | consumed tokens: 1874329600.0 | grad norm avg: 0.72 | grad norm last: 0.73 | 
2026-01-01T23:57:57 | step: 57300 | train samples/s: 268.3 | train mfu (16-bit): -1.0 | lr mean: 3.828316766885109e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.39 | consumed tokens: 1877606400.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-01T23:58:26 | step: 57400 | train samples/s: 267.0 | train mfu (16-bit): -1.0 | lr mean: 3.8244623283389956e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.03 | consumed tokens: 1880883200.0 | grad norm avg: 0.7 | grad norm last: 0.79 | 
2026-01-01T23:58:54 | step: 57500 | train samples/s: 264.0 | train mfu (16-bit): -1.0 | lr mean: 3.8206035242183134e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.16 | train loss last: 3.12 | consumed tokens: 1884160000.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-01T23:59:23 | step: 57600 | train samples/s: 269.2 | train mfu (16-bit): -1.0 | lr mean: 3.816740354523063e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.35 | consumed tokens: 1887436800.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-01T23:59:51 | step: 57700 | train samples/s: 267.1 | train mfu (16-bit): -1.0 | lr mean: 3.8128728192532435e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.12 | consumed tokens: 1890713600.0 | grad norm avg: 0.71 | grad norm last: 0.76 | 
2026-01-02T00:00:19 | step: 57800 | train samples/s: 269.8 | train mfu (16-bit): -1.0 | lr mean: 3.809000918408856e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 2.91 | consumed tokens: 1893990400.0 | grad norm avg: 0.71 | grad norm last: 0.7 | 
2026-01-02T00:00:47 | step: 57900 | train samples/s: 269.1 | train mfu (16-bit): -1.0 | lr mean: 3.8051246519898996e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.21 | consumed tokens: 1897267200.0 | grad norm avg: 0.71 | grad norm last: 0.76 | 
2026-01-02T00:01:16 | step: 58000 | train samples/s: 269.3 | train mfu (16-bit): -1.0 | lr mean: 3.801244019996375e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 2.93 | consumed tokens: 1900544000.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T00:01:44 | step: 58100 | train samples/s: 266.1 | train mfu (16-bit): -1.0 | lr mean: 3.797359386226162e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.09 | consumed tokens: 1903820800.0 | grad norm avg: 0.71 | grad norm last: 0.83 | 
2026-01-02T00:02:13 | step: 58200 | train samples/s: 263.6 | train mfu (16-bit): -1.0 | lr mean: 3.7934700230835006e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.1 | consumed tokens: 1907097600.0 | grad norm avg: 0.71 | grad norm last: 0.75 | 
2026-01-02T00:02:41 | step: 58300 | train samples/s: 269.4 | train mfu (16-bit): -1.0 | lr mean: 3.789576658164151e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.3 | consumed tokens: 1910374400.0 | grad norm avg: 0.7 | grad norm last: 0.68 | 
2026-01-02T00:03:10 | step: 58400 | train samples/s: 267.1 | train mfu (16-bit): -1.0 | lr mean: 3.7856792914681137e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 2.8 | consumed tokens: 1913651200.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T00:03:38 | step: 58500 | train samples/s: 269.7 | train mfu (16-bit): -1.0 | lr mean: 3.781777195399627e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.17 | consumed tokens: 1916928000.0 | grad norm avg: 0.71 | grad norm last: 0.75 | 
2026-01-02T00:04:06 | step: 58600 | train samples/s: 271.4 | train mfu (16-bit): -1.0 | lr mean: 3.777871097554453e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.27 | consumed tokens: 1920204800.0 | grad norm avg: 0.7 | grad norm last: 0.65 | 
2026-01-02T00:04:34 | step: 58700 | train samples/s: 269.0 | train mfu (16-bit): -1.0 | lr mean: 3.77396063413471e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.06 | consumed tokens: 1923481600.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-02T00:05:03 | step: 58800 | train samples/s: 263.6 | train mfu (16-bit): -1.0 | lr mean: 3.770046168938279e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.23 | consumed tokens: 1926758400.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T00:05:31 | step: 58900 | train samples/s: 269.7 | train mfu (16-bit): -1.0 | lr mean: 3.76612733816728e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.16 | consumed tokens: 1930035200.0 | grad norm avg: 0.68 | grad norm last: 0.64 | 
2026-01-02T00:05:59 | step: 59000 | train samples/s: 265.7 | train mfu (16-bit): -1.0 | lr mean: 3.762204505619593e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 2.86 | consumed tokens: 1933312000.0 | grad norm avg: 0.69 | grad norm last: 0.7 | 
2026-01-02T00:06:28 | step: 59100 | train samples/s: 266.2 | train mfu (16-bit): -1.0 | lr mean: 3.7582773074973375e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.26 | consumed tokens: 1936588800.0 | grad norm avg: 0.7 | grad norm last: 0.69 | 
2026-01-02T00:06:56 | step: 59200 | train samples/s: 268.9 | train mfu (16-bit): -1.0 | lr mean: 3.754346107598394e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.19 | consumed tokens: 1939865600.0 | grad norm avg: 0.71 | grad norm last: 0.79 | 
2026-01-02T00:07:24 | step: 59300 | train samples/s: 270.2 | train mfu (16-bit): -1.0 | lr mean: 3.7504105421248823e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.0 | consumed tokens: 1943142400.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-02T00:07:52 | step: 59400 | train samples/s: 270.4 | train mfu (16-bit): -1.0 | lr mean: 3.746470974874683e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.42 | consumed tokens: 1946419200.0 | grad norm avg: 0.7 | grad norm last: 0.72 | 
2026-01-02T00:08:21 | step: 59500 | train samples/s: 264.2 | train mfu (16-bit): -1.0 | lr mean: 3.742527405847795e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 2.94 | consumed tokens: 1949696000.0 | grad norm avg: 0.7 | grad norm last: 0.64 | 
2026-01-02T00:08:49 | step: 59600 | train samples/s: 269.7 | train mfu (16-bit): -1.0 | lr mean: 3.7385794712463394e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 2.91 | consumed tokens: 1952972800.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-02T00:09:18 | step: 59700 | train samples/s: 266.6 | train mfu (16-bit): -1.0 | lr mean: 3.7346275348681957e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.24 | consumed tokens: 1956249600.0 | grad norm avg: 0.72 | grad norm last: 0.65 | 
2026-01-02T00:09:46 | step: 59800 | train samples/s: 265.6 | train mfu (16-bit): -1.0 | lr mean: 3.730671596713364e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.25 | consumed tokens: 1959526400.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-02T00:10:15 | step: 59900 | train samples/s: 268.3 | train mfu (16-bit): -1.0 | lr mean: 3.726711656781845e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.3 | consumed tokens: 1962803200.0 | grad norm avg: 0.71 | grad norm last: 0.67 | 
2026-01-02T00:10:43 | step: 60000 | train samples/s: 269.4 | train mfu (16-bit): -1.0 | lr mean: 3.722747715073638e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.18 | consumed tokens: 1966080000.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-02T00:11:14 | step: 60100 | train samples/s: 263.9 | train mfu (16-bit): -1.0 | lr mean: 3.718779407790862e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.02 | consumed tokens: 1969356800.0 | grad norm avg: 0.7 | grad norm last: 0.66 | 
2026-01-02T00:11:42 | step: 60200 | train samples/s: 269.5 | train mfu (16-bit): -1.0 | lr mean: 3.7148070987313986e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.48 | consumed tokens: 1972633600.0 | grad norm avg: 0.7 | grad norm last: 0.71 | 
2026-01-02T00:12:10 | step: 60300 | train samples/s: 268.7 | train mfu (16-bit): -1.0 | lr mean: 3.710831151693128e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.34 | consumed tokens: 1975910400.0 | grad norm avg: 0.7 | grad norm last: 0.78 | 
2026-01-02T00:12:38 | step: 60400 | train samples/s: 267.5 | train mfu (16-bit): -1.0 | lr mean: 3.706850839080289e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.18 | consumed tokens: 1979187200.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-02T00:13:07 | step: 60500 | train samples/s: 268.0 | train mfu (16-bit): -1.0 | lr mean: 3.702866524690762e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.33 | consumed tokens: 1982464000.0 | grad norm avg: 0.72 | grad norm last: 0.68 | 
2026-01-02T00:13:35 | step: 60600 | train samples/s: 269.4 | train mfu (16-bit): -1.0 | lr mean: 3.698878572322428e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.25 | consumed tokens: 1985740800.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-02T00:14:03 | step: 60700 | train samples/s: 268.7 | train mfu (16-bit): -1.0 | lr mean: 3.694886254379526e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.1 | consumed tokens: 1989017600.0 | grad norm avg: 0.72 | grad norm last: 0.69 | 
2026-01-02T00:14:32 | step: 60800 | train samples/s: 264.0 | train mfu (16-bit): -1.0 | lr mean: 3.690890298457816e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.16 | consumed tokens: 1992294400.0 | grad norm avg: 0.73 | grad norm last: 0.72 | 
2026-01-02T00:15:00 | step: 60900 | train samples/s: 269.5 | train mfu (16-bit): -1.0 | lr mean: 3.686890340759419e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.35 | consumed tokens: 1995571200.0 | grad norm avg: 0.73 | grad norm last: 0.67 | 
2026-01-02T00:15:28 | step: 61000 | train samples/s: 272.0 | train mfu (16-bit): -1.0 | lr mean: 3.682886381284334e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 2.86 | consumed tokens: 1998848000.0 | grad norm avg: 0.72 | grad norm last: 0.67 | 
2026-01-02T00:15:56 | step: 61100 | train samples/s: 269.3 | train mfu (16-bit): -1.0 | lr mean: 3.678878420032561e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.28 | consumed tokens: 2002124800.0 | grad norm avg: 0.72 | grad norm last: 0.7 | 
2026-01-02T00:16:25 | step: 61200 | train samples/s: 268.8 | train mfu (16-bit): -1.0 | lr mean: 3.674866820801981e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.07 | consumed tokens: 2005401600.0 | grad norm avg: 0.72 | grad norm last: 0.71 | 
2026-01-02T00:16:53 | step: 61300 | train samples/s: 264.9 | train mfu (16-bit): -1.0 | lr mean: 3.670851219794713e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.22 | consumed tokens: 2008678400.0 | grad norm avg: 0.72 | grad norm last: 0.73 | 
2026-01-02T00:17:22 | step: 61400 | train samples/s: 267.3 | train mfu (16-bit): -1.0 | lr mean: 3.666831617010757e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.2 | consumed tokens: 2011955200.0 | grad norm avg: 0.72 | grad norm last: 0.78 | 
2026-01-02T00:17:50 | step: 61500 | train samples/s: 266.8 | train mfu (16-bit): -1.0 | lr mean: 3.6628083762479946e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.46 | consumed tokens: 2015232000.0 | grad norm avg: 0.72 | grad norm last: 0.69 | 
2026-01-02T00:18:19 | step: 61600 | train samples/s: 268.0 | train mfu (16-bit): -1.0 | lr mean: 3.658781133708544e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.04 | consumed tokens: 2018508800.0 | grad norm avg: 0.71 | grad norm last: 0.66 | 
2026-01-02T00:18:47 | step: 61700 | train samples/s: 267.5 | train mfu (16-bit): -1.0 | lr mean: 3.6547502531902865e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.28 | consumed tokens: 2021785600.0 | grad norm avg: 0.72 | grad norm last: 0.7 | 
2026-01-02T00:19:15 | step: 61800 | train samples/s: 269.4 | train mfu (16-bit): -1.0 | lr mean: 3.650715370895341e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.16 | consumed tokens: 2025062400.0 | grad norm avg: 0.71 | grad norm last: 0.71 | 
2026-01-02T00:19:43 | step: 61900 | train samples/s: 268.9 | train mfu (16-bit): -1.0 | lr mean: 3.6466768506215885e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.01 | consumed tokens: 2028339200.0 | grad norm avg: 0.71 | grad norm last: 0.68 | 
2026-01-02T00:20:12 | step: 62000 | train samples/s: 267.4 | train mfu (16-bit): -1.0 | lr mean: 3.642634328571148e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.09 | consumed tokens: 2031616000.0 | grad norm avg: 0.71 | grad norm last: 0.84 | 
2026-01-02T00:20:40 | step: 62100 | train samples/s: 266.4 | train mfu (16-bit): -1.0 | lr mean: 3.638588168541901e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.16 | consumed tokens: 2034892800.0 | grad norm avg: 0.71 | grad norm last: 0.72 | 
2026-01-02T00:21:09 | step: 62200 | train samples/s: 265.8 | train mfu (16-bit): -1.0 | lr mean: 3.6345380067359656e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 2.94 | consumed tokens: 2038169600.0 | grad norm avg: 0.71 | grad norm last: 0.73 | 
2026-01-02T00:21:37 | step: 62300 | train samples/s: 267.9 | train mfu (16-bit): -1.0 | lr mean: 3.630484206951223e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 2.99 | consumed tokens: 2041446400.0 | grad norm avg: 0.71 | grad norm last: 0.76 | 
2026-01-02T00:22:06 | step: 62400 | train samples/s: 268.4 | train mfu (16-bit): -1.0 | lr mean: 3.626426769187674e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.04 | consumed tokens: 2044723200.0 | grad norm avg: 0.74 | grad norm last: 0.81 | 
2026-01-02T00:22:34 | step: 62500 | train samples/s: 265.3 | train mfu (16-bit): -1.0 | lr mean: 3.6223656934453174e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.11 | consumed tokens: 2048000000.0 | grad norm avg: 0.71 | grad norm last: 0.66 | 
2026-01-02T00:23:03 | step: 62600 | train samples/s: 269.2 | train mfu (16-bit): -1.0 | lr mean: 3.618300979724154e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 2.69 | consumed tokens: 2051276800.0 | grad norm avg: 0.73 | grad norm last: 0.82 | 
2026-01-02T00:23:31 | step: 62700 | train samples/s: 267.5 | train mfu (16-bit): -1.0 | lr mean: 3.6142322642263025e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 2.98 | consumed tokens: 2054553600.0 | grad norm avg: 0.73 | grad norm last: 0.79 | 
2026-01-02T00:24:00 | step: 62800 | train samples/s: 264.0 | train mfu (16-bit): -1.0 | lr mean: 3.610159910749644e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.01 | consumed tokens: 2057830400.0 | grad norm avg: 0.74 | grad norm last: 0.8 | 
2026-01-02T00:24:28 | step: 62900 | train samples/s: 259.7 | train mfu (16-bit): -1.0 | lr mean: 3.6060839192941785e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.28 | consumed tokens: 2061107200.0 | grad norm avg: 0.72 | grad norm last: 0.76 | 
2026-01-02T00:24:56 | step: 63000 | train samples/s: 262.6 | train mfu (16-bit): -1.0 | lr mean: 3.602004289859906e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 2.81 | consumed tokens: 2064384000.0 | grad norm avg: 0.74 | grad norm last: 0.7 | 
2026-01-02T00:25:24 | step: 63100 | train samples/s: 263.4 | train mfu (16-bit): -1.0 | lr mean: 3.597921386244707e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.34 | consumed tokens: 2067660800.0 | grad norm avg: 0.73 | grad norm last: 0.72 | 
2026-01-02T00:25:53 | step: 63200 | train samples/s: 254.9 | train mfu (16-bit): -1.0 | lr mean: 3.59383448085282e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.35 | consumed tokens: 2070937600.0 | grad norm avg: 0.72 | grad norm last: 0.79 | 
2026-01-02T00:26:21 | step: 63300 | train samples/s: 267.4 | train mfu (16-bit): -1.0 | lr mean: 3.589743937482126e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.43 | consumed tokens: 2074214400.0 | grad norm avg: 0.73 | grad norm last: 0.69 | 
2026-01-02T00:26:49 | step: 63400 | train samples/s: 265.9 | train mfu (16-bit): -1.0 | lr mean: 3.585649756132625e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.04 | consumed tokens: 2077491200.0 | grad norm avg: 0.73 | grad norm last: 0.8 | 
2026-01-02T00:27:18 | step: 63500 | train samples/s: 266.0 | train mfu (16-bit): -1.0 | lr mean: 3.581551936804317e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.09 | consumed tokens: 2080768000.0 | grad norm avg: 0.73 | grad norm last: 0.69 | 
2026-01-02T00:27:46 | step: 63600 | train samples/s: 269.2 | train mfu (16-bit): -1.0 | lr mean: 3.5774508432950824e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.42 | consumed tokens: 2084044800.0 | grad norm avg: 0.72 | grad norm last: 0.79 | 
2026-01-02T00:28:14 | step: 63700 | train samples/s: 268.1 | train mfu (16-bit): -1.0 | lr mean: 3.573346111807041e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.0 | consumed tokens: 2087321600.0 | grad norm avg: 0.72 | grad norm last: 0.75 | 
2026-01-02T00:28:43 | step: 63800 | train samples/s: 261.6 | train mfu (16-bit): -1.0 | lr mean: 3.569237742340192e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.0 | consumed tokens: 2090598400.0 | grad norm avg: 0.74 | grad norm last: 0.67 | 
2026-01-02T00:29:11 | step: 63900 | train samples/s: 264.7 | train mfu (16-bit): -1.0 | lr mean: 3.5651257348945364e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.26 | consumed tokens: 2093875200.0 | grad norm avg: 0.74 | grad norm last: 0.77 | 
2026-01-02T00:29:40 | step: 64000 | train samples/s: 265.2 | train mfu (16-bit): -1.0 | lr mean: 3.561010453267954e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.14 | consumed tokens: 2097152000.0 | grad norm avg: 0.75 | grad norm last: 0.74 | 
2026-01-02T00:30:09 | step: 64100 | train samples/s: 254.6 | train mfu (16-bit): -1.0 | lr mean: 3.556891533662565e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.3 | consumed tokens: 2100428800.0 | grad norm avg: 0.74 | grad norm last: 0.84 | 
2026-01-02T00:30:38 | step: 64200 | train samples/s: 261.6 | train mfu (16-bit): -1.0 | lr mean: 3.552768976078369e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.22 | consumed tokens: 2103705600.0 | grad norm avg: 0.75 | grad norm last: 0.77 | 
2026-01-02T00:31:07 | step: 64300 | train samples/s: 262.4 | train mfu (16-bit): -1.0 | lr mean: 3.548643144313246e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 2.79 | consumed tokens: 2106982400.0 | grad norm avg: 0.73 | grad norm last: 0.75 | 
2026-01-02T00:31:35 | step: 64400 | train samples/s: 257.0 | train mfu (16-bit): -1.0 | lr mean: 3.544513674569316e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 2.96 | consumed tokens: 2110259200.0 | grad norm avg: 0.75 | grad norm last: 0.83 | 
2026-01-02T00:32:04 | step: 64500 | train samples/s: 262.7 | train mfu (16-bit): -1.0 | lr mean: 3.54038093064446e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.34 | consumed tokens: 2113536000.0 | grad norm avg: 0.76 | grad norm last: 0.79 | 
2026-01-02T00:32:33 | step: 64600 | train samples/s: 264.5 | train mfu (16-bit): -1.0 | lr mean: 3.5362449125386775e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.6 | consumed tokens: 2116812800.0 | grad norm avg: 0.74 | grad norm last: 0.71 | 
2026-01-02T00:33:01 | step: 64700 | train samples/s: 253.4 | train mfu (16-bit): -1.0 | lr mean: 3.532105256454088e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 2.77 | consumed tokens: 2120089600.0 | grad norm avg: 0.73 | grad norm last: 0.75 | 
2026-01-02T00:33:30 | step: 64800 | train samples/s: 256.1 | train mfu (16-bit): -1.0 | lr mean: 3.527961962390691e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.31 | consumed tokens: 2123366400.0 | grad norm avg: 0.73 | grad norm last: 0.82 | 
2026-01-02T00:33:59 | step: 64900 | train samples/s: 255.8 | train mfu (16-bit): -1.0 | lr mean: 3.5238157579442486e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 2.91 | consumed tokens: 2126643200.0 | grad norm avg: 0.75 | grad norm last: 0.75 | 
2026-01-02T00:34:28 | step: 65000 | train samples/s: 260.5 | train mfu (16-bit): -1.0 | lr mean: 3.5196655517211184e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 2.91 | consumed tokens: 2129920000.0 | grad norm avg: 0.75 | grad norm last: 0.73 | 
2026-01-02T00:34:58 | step: 65100 | train samples/s: 266.5 | train mfu (16-bit): -1.0 | lr mean: 3.5155124351149425e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.36 | consumed tokens: 2133196800.0 | grad norm avg: 0.74 | grad norm last: 0.72 | 
2026-01-02T00:35:26 | step: 65200 | train samples/s: 268.3 | train mfu (16-bit): -1.0 | lr mean: 3.51135604432784e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.02 | consumed tokens: 2136473600.0 | grad norm avg: 0.74 | grad norm last: 0.71 | 
2026-01-02T00:35:54 | step: 65300 | train samples/s: 260.5 | train mfu (16-bit): -1.0 | lr mean: 3.507196015561931e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.03 | consumed tokens: 2139750400.0 | grad norm avg: 0.74 | grad norm last: 0.72 | 
2026-01-02T00:36:23 | step: 65400 | train samples/s: 255.4 | train mfu (16-bit): -1.0 | lr mean: 3.503032712615095e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.57 | consumed tokens: 2143027200.0 | grad norm avg: 0.74 | grad norm last: 0.74 | 
2026-01-02T00:36:52 | step: 65500 | train samples/s: 252.7 | train mfu (16-bit): -1.0 | lr mean: 3.498866135487333e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.07 | consumed tokens: 2146304000.0 | grad norm avg: 0.76 | grad norm last: 0.73 | 
2026-01-02T00:37:20 | step: 65600 | train samples/s: 264.6 | train mfu (16-bit): -1.0 | lr mean: 3.4946962841786444e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.05 | consumed tokens: 2149580800.0 | grad norm avg: 0.74 | grad norm last: 0.71 | 
2026-01-02T00:37:49 | step: 65700 | train samples/s: 263.3 | train mfu (16-bit): -1.0 | lr mean: 3.4905231586890295e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 2.77 | consumed tokens: 2152857600.0 | grad norm avg: 0.74 | grad norm last: 0.69 | 
2026-01-02T00:38:17 | step: 65800 | train samples/s: 260.0 | train mfu (16-bit): -1.0 | lr mean: 3.486346759018488e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.06 | consumed tokens: 2156134400.0 | grad norm avg: 0.74 | grad norm last: 0.74 | 
2026-01-02T00:38:46 | step: 65900 | train samples/s: 261.3 | train mfu (16-bit): -1.0 | lr mean: 3.4821670851670206e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.19 | consumed tokens: 2159411200.0 | grad norm avg: 0.76 | grad norm last: 0.7 | 
2026-01-02T00:39:15 | step: 66000 | train samples/s: 263.4 | train mfu (16-bit): -1.0 | lr mean: 3.4779841371346265e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.39 | consumed tokens: 2162688000.0 | grad norm avg: 0.76 | grad norm last: 0.77 | 
2026-01-02T00:39:43 | step: 66100 | train samples/s: 265.1 | train mfu (16-bit): -1.0 | lr mean: 3.473797914921306e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.38 | consumed tokens: 2165964800.0 | grad norm avg: 0.76 | grad norm last: 0.72 | 
2026-01-02T00:40:12 | step: 66200 | train samples/s: 260.8 | train mfu (16-bit): -1.0 | lr mean: 3.469608418527059e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.37 | consumed tokens: 2169241600.0 | grad norm avg: 0.74 | grad norm last: 0.65 | 
2026-01-02T00:40:41 | step: 66300 | train samples/s: 263.6 | train mfu (16-bit): -1.0 | lr mean: 3.465416011749767e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.32 | consumed tokens: 2172518400.0 | grad norm avg: 0.77 | grad norm last: 0.91 | 
2026-01-02T00:41:09 | step: 66400 | train samples/s: 263.9 | train mfu (16-bit): -1.0 | lr mean: 3.461220330791548e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.15 | consumed tokens: 2175795200.0 | grad norm avg: 0.76 | grad norm last: 0.79 | 
2026-01-02T00:41:38 | step: 66500 | train samples/s: 251.5 | train mfu (16-bit): -1.0 | lr mean: 3.4570213756524026e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 2.97 | consumed tokens: 2179072000.0 | grad norm avg: 0.75 | grad norm last: 0.74 | 
2026-01-02T00:42:07 | step: 66600 | train samples/s: 252.2 | train mfu (16-bit): -1.0 | lr mean: 3.452819146332331e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.15 | train loss last: 3.41 | consumed tokens: 2182348800.0 | grad norm avg: 0.74 | grad norm last: 0.72 | 
2026-01-02T00:42:36 | step: 66700 | train samples/s: 251.9 | train mfu (16-bit): -1.0 | lr mean: 3.448614006629214e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 2.98 | consumed tokens: 2185625600.0 | grad norm avg: 0.74 | grad norm last: 0.72 | 
2026-01-02T00:43:05 | step: 66800 | train samples/s: 260.7 | train mfu (16-bit): -1.0 | lr mean: 3.44440559274517e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.13 | consumed tokens: 2188902400.0 | grad norm avg: 0.75 | grad norm last: 0.7 | 
2026-01-02T00:43:34 | step: 66900 | train samples/s: 260.3 | train mfu (16-bit): -1.0 | lr mean: 3.4401939046802e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.5 | consumed tokens: 2192179200.0 | grad norm avg: 0.75 | grad norm last: 0.69 | 
2026-01-02T00:44:02 | step: 67000 | train samples/s: 264.4 | train mfu (16-bit): -1.0 | lr mean: 3.435979306232184e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.03 | consumed tokens: 2195456000.0 | grad norm avg: 0.75 | grad norm last: 0.85 | 
2026-01-02T00:44:31 | step: 67100 | train samples/s: 265.2 | train mfu (16-bit): -1.0 | lr mean: 3.431761797401123e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 2.95 | consumed tokens: 2198732800.0 | grad norm avg: 0.76 | grad norm last: 0.8 | 
2026-01-02T00:44:59 | step: 67200 | train samples/s: 265.2 | train mfu (16-bit): -1.0 | lr mean: 3.427541014389135e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 2.95 | consumed tokens: 2202009600.0 | grad norm avg: 0.75 | grad norm last: 0.82 | 
2026-01-02T00:45:28 | step: 67300 | train samples/s: 250.9 | train mfu (16-bit): -1.0 | lr mean: 3.423316957196221e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.35 | consumed tokens: 2205286400.0 | grad norm avg: 0.75 | grad norm last: 0.65 | 
2026-01-02T00:45:57 | step: 67400 | train samples/s: 254.2 | train mfu (16-bit): -1.0 | lr mean: 3.419089989620261e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.11 | consumed tokens: 2208563200.0 | grad norm avg: 0.78 | grad norm last: 0.77 | 
2026-01-02T00:46:26 | step: 67500 | train samples/s: 255.4 | train mfu (16-bit): -1.0 | lr mean: 3.4148601116612554e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.14 | consumed tokens: 2211840000.0 | grad norm avg: 0.77 | grad norm last: 0.75 | 
2026-01-02T00:46:54 | step: 67600 | train samples/s: 256.7 | train mfu (16-bit): -1.0 | lr mean: 3.410627323319204e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.29 | consumed tokens: 2215116800.0 | grad norm avg: 0.76 | grad norm last: 0.72 | 
2026-01-02T00:47:23 | step: 67700 | train samples/s: 263.5 | train mfu (16-bit): -1.0 | lr mean: 3.4063912607962266e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.18 | consumed tokens: 2218393600.0 | grad norm avg: 0.76 | grad norm last: 0.79 | 
2026-01-02T00:47:52 | step: 67800 | train samples/s: 263.6 | train mfu (16-bit): -1.0 | lr mean: 3.402152287890203e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.1 | consumed tokens: 2221670400.0 | grad norm avg: 0.77 | grad norm last: 0.87 | 
2026-01-02T00:48:20 | step: 67900 | train samples/s: 264.1 | train mfu (16-bit): -1.0 | lr mean: 3.3979104046011344e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.15 | consumed tokens: 2224947200.0 | grad norm avg: 0.78 | grad norm last: 0.8 | 
2026-01-02T00:48:49 | step: 68000 | train samples/s: 259.3 | train mfu (16-bit): -1.0 | lr mean: 3.393665247131139e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 2.78 | consumed tokens: 2228224000.0 | grad norm avg: 0.77 | grad norm last: 0.73 | 
2026-01-02T00:49:18 | step: 68100 | train samples/s: 261.0 | train mfu (16-bit): -1.0 | lr mean: 3.389417543075979e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.33 | consumed tokens: 2231500800.0 | grad norm avg: 0.78 | grad norm last: 0.83 | 
2026-01-02T00:49:47 | step: 68200 | train samples/s: 262.9 | train mfu (16-bit): -1.0 | lr mean: 3.385166564839892e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 2.94 | consumed tokens: 2234777600.0 | grad norm avg: 0.77 | grad norm last: 0.74 | 
2026-01-02T00:50:16 | step: 68300 | train samples/s: 261.7 | train mfu (16-bit): -1.0 | lr mean: 3.3809130400186405e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.14 | train loss last: 3.33 | consumed tokens: 2238054400.0 | grad norm avg: 0.77 | grad norm last: 0.77 | 
2026-01-02T00:50:45 | step: 68400 | train samples/s: 262.0 | train mfu (16-bit): -1.0 | lr mean: 3.3766562410164624e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.2 | consumed tokens: 2241331200.0 | grad norm avg: 0.77 | grad norm last: 0.72 | 
2026-01-02T00:51:13 | step: 68500 | train samples/s: 263.7 | train mfu (16-bit): -1.0 | lr mean: 3.3723968954291195e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.01 | consumed tokens: 2244608000.0 | grad norm avg: 0.77 | grad norm last: 0.73 | 
2026-01-02T00:51:42 | step: 68600 | train samples/s: 261.5 | train mfu (16-bit): -1.0 | lr mean: 3.36813427566085e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 2.71 | consumed tokens: 2247884800.0 | grad norm avg: 0.77 | grad norm last: 0.81 | 
2026-01-02T00:52:11 | step: 68700 | train samples/s: 264.1 | train mfu (16-bit): -1.0 | lr mean: 3.363869109307416e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.0 | consumed tokens: 2251161600.0 | grad norm avg: 0.79 | grad norm last: 0.77 | 
2026-01-02T00:52:40 | step: 68800 | train samples/s: 260.3 | train mfu (16-bit): -1.0 | lr mean: 3.359601032570936e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.12 | consumed tokens: 2254438400.0 | grad norm avg: 0.77 | grad norm last: 0.75 | 
2026-01-02T00:53:08 | step: 68900 | train samples/s: 253.6 | train mfu (16-bit): -1.0 | lr mean: 3.35533004545141e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.02 | consumed tokens: 2257715200.0 | grad norm avg: 0.78 | grad norm last: 0.85 | 
2026-01-02T00:53:37 | step: 69000 | train samples/s: 260.2 | train mfu (16-bit): -1.0 | lr mean: 3.351056147948839e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.36 | consumed tokens: 2260992000.0 | grad norm avg: 0.78 | grad norm last: 0.74 | 
2026-01-02T00:54:06 | step: 69100 | train samples/s: 267.6 | train mfu (16-bit): -1.0 | lr mean: 3.3467797038611025e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.11 | consumed tokens: 2264268800.0 | grad norm avg: 0.79 | grad norm last: 0.74 | 
2026-01-02T00:54:34 | step: 69200 | train samples/s: 267.3 | train mfu (16-bit): -1.0 | lr mean: 3.3425003493903205e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 2.93 | consumed tokens: 2267545600.0 | grad norm avg: 0.77 | grad norm last: 0.99 | 
2026-01-02T00:55:03 | step: 69300 | train samples/s: 264.6 | train mfu (16-bit): -1.0 | lr mean: 3.338218084536493e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.27 | consumed tokens: 2270822400.0 | grad norm avg: 0.78 | grad norm last: 0.72 | 
2026-01-02T00:55:31 | step: 69400 | train samples/s: 265.4 | train mfu (16-bit): -1.0 | lr mean: 3.3339329092996195e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.52 | consumed tokens: 2274099200.0 | grad norm avg: 0.78 | grad norm last: 0.72 | 
2026-01-02T00:56:00 | step: 69500 | train samples/s: 263.2 | train mfu (16-bit): -1.0 | lr mean: 3.329645187477581e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 2.91 | consumed tokens: 2277376000.0 | grad norm avg: 0.77 | grad norm last: 0.81 | 
2026-01-02T00:56:29 | step: 69600 | train samples/s: 252.5 | train mfu (16-bit): -1.0 | lr mean: 3.325354919070378e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.3 | consumed tokens: 2280652800.0 | grad norm avg: 0.78 | grad norm last: 0.78 | 
2026-01-02T00:56:57 | step: 69700 | train samples/s: 257.7 | train mfu (16-bit): -1.0 | lr mean: 3.321061740280129e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 2.95 | consumed tokens: 2283929600.0 | grad norm avg: 0.79 | grad norm last: 0.8 | 
2026-01-02T00:57:26 | step: 69800 | train samples/s: 256.3 | train mfu (16-bit): -1.0 | lr mean: 3.3167656511068344e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.46 | consumed tokens: 2287206400.0 | grad norm avg: 0.79 | grad norm last: 0.78 | 
2026-01-02T00:57:54 | step: 69900 | train samples/s: 257.9 | train mfu (16-bit): -1.0 | lr mean: 3.3124673791462556e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.35 | consumed tokens: 2290483200.0 | grad norm avg: 0.8 | grad norm last: 0.79 | 
2026-01-02T00:58:23 | step: 70000 | train samples/s: 250.9 | train mfu (16-bit): -1.0 | lr mean: 3.30816583300475e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.06 | consumed tokens: 2293760000.0 | grad norm avg: 0.78 | grad norm last: 0.83 | 
2026-01-02T00:58:53 | step: 70100 | train samples/s: 254.4 | train mfu (16-bit): -1.0 | lr mean: 3.303862104075961e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.19 | consumed tokens: 2297036800.0 | grad norm avg: 0.79 | grad norm last: 0.76 | 
2026-01-02T00:59:22 | step: 70200 | train samples/s: 258.4 | train mfu (16-bit): -1.0 | lr mean: 3.2995554647641256e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 2.98 | consumed tokens: 2300313600.0 | grad norm avg: 0.78 | grad norm last: 0.77 | 
2026-01-02T00:59:50 | step: 70300 | train samples/s: 252.3 | train mfu (16-bit): -1.0 | lr mean: 3.2952462788671255e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 2.95 | consumed tokens: 2303590400.0 | grad norm avg: 0.8 | grad norm last: 0.78 | 
2026-01-02T01:00:19 | step: 70400 | train samples/s: 259.7 | train mfu (16-bit): -1.0 | lr mean: 3.29093418258708e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.18 | consumed tokens: 2306867200.0 | grad norm avg: 0.78 | grad norm last: 0.73 | 
2026-01-02T01:00:47 | step: 70500 | train samples/s: 258.6 | train mfu (16-bit): -1.0 | lr mean: 3.2866199035197496e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.11 | consumed tokens: 2310144000.0 | grad norm avg: 0.79 | grad norm last: 0.77 | 
2026-01-02T01:01:15 | step: 70600 | train samples/s: 258.1 | train mfu (16-bit): -1.0 | lr mean: 3.282302714069374e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.04 | consumed tokens: 2313420800.0 | grad norm avg: 0.79 | grad norm last: 0.77 | 
2026-01-02T01:01:44 | step: 70700 | train samples/s: 255.9 | train mfu (16-bit): -1.0 | lr mean: 3.277982978033833e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.27 | consumed tokens: 2316697600.0 | grad norm avg: 0.79 | grad norm last: 0.72 | 
2026-01-02T01:02:12 | step: 70800 | train samples/s: 257.7 | train mfu (16-bit): -1.0 | lr mean: 3.2736606954131275e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.09 | consumed tokens: 2319974400.0 | grad norm avg: 0.79 | grad norm last: 0.81 | 
2026-01-02T01:02:41 | step: 70900 | train samples/s: 257.7 | train mfu (16-bit): -1.0 | lr mean: 3.2693362300051376e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.93 | consumed tokens: 2323251200.0 | grad norm avg: 0.79 | grad norm last: 0.94 | 
2026-01-02T01:03:09 | step: 71000 | train samples/s: 256.4 | train mfu (16-bit): -1.0 | lr mean: 3.265008854214102e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.07 | consumed tokens: 2326528000.0 | grad norm avg: 0.79 | grad norm last: 0.82 | 
2026-01-02T01:03:37 | step: 71100 | train samples/s: 257.5 | train mfu (16-bit): -1.0 | lr mean: 3.2606789318379015e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.09 | consumed tokens: 2329804800.0 | grad norm avg: 0.8 | grad norm last: 0.74 | 
2026-01-02T01:04:06 | step: 71200 | train samples/s: 263.5 | train mfu (16-bit): -1.0 | lr mean: 3.256346462876536e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.72 | consumed tokens: 2333081600.0 | grad norm avg: 0.81 | grad norm last: 0.77 | 
2026-01-02T01:04:34 | step: 71300 | train samples/s: 262.9 | train mfu (16-bit): -1.0 | lr mean: 3.252011811127886e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.07 | consumed tokens: 2336358400.0 | grad norm avg: 0.8 | grad norm last: 0.72 | 
2026-01-02T01:05:02 | step: 71400 | train samples/s: 254.3 | train mfu (16-bit): -1.0 | lr mean: 3.247674248996191e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.13 | consumed tokens: 2339635200.0 | grad norm avg: 0.79 | grad norm last: 0.74 | 
2026-01-02T01:05:31 | step: 71500 | train samples/s: 260.9 | train mfu (16-bit): -1.0 | lr mean: 3.243334504077211e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.09 | consumed tokens: 2342912000.0 | grad norm avg: 0.8 | grad norm last: 0.85 | 
2026-01-02T01:05:59 | step: 71600 | train samples/s: 267.0 | train mfu (16-bit): -1.0 | lr mean: 3.2389922125730664e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.02 | consumed tokens: 2346188800.0 | grad norm avg: 0.81 | grad norm last: 0.78 | 
2026-01-02T01:06:27 | step: 71700 | train samples/s: 264.8 | train mfu (16-bit): -1.0 | lr mean: 3.2346477382816374e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.01 | consumed tokens: 2349465600.0 | grad norm avg: 0.79 | grad norm last: 0.76 | 
2026-01-02T01:06:56 | step: 71800 | train samples/s: 263.5 | train mfu (16-bit): -1.0 | lr mean: 3.230300353607163e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.0 | consumed tokens: 2352742400.0 | grad norm avg: 0.81 | grad norm last: 0.8 | 
2026-01-02T01:07:24 | step: 71900 | train samples/s: 264.6 | train mfu (16-bit): -1.0 | lr mean: 3.225951149943285e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.15 | consumed tokens: 2356019200.0 | grad norm avg: 0.79 | grad norm last: 0.79 | 
2026-01-02T01:07:53 | step: 72000 | train samples/s: 262.2 | train mfu (16-bit): -1.0 | lr mean: 3.221599035896361e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.23 | consumed tokens: 2359296000.0 | grad norm avg: 0.81 | grad norm last: 0.8 | 
2026-01-02T01:08:22 | step: 72100 | train samples/s: 255.6 | train mfu (16-bit): -1.0 | lr mean: 3.217244739062153e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.28 | consumed tokens: 2362572800.0 | grad norm avg: 0.81 | grad norm last: 0.75 | 
2026-01-02T01:08:50 | step: 72200 | train samples/s: 265.4 | train mfu (16-bit): -1.0 | lr mean: 3.21288789564278e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.82 | consumed tokens: 2365849600.0 | grad norm avg: 0.81 | grad norm last: 0.82 | 
2026-01-02T01:09:19 | step: 72300 | train samples/s: 265.2 | train mfu (16-bit): -1.0 | lr mean: 3.2085288694361225e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 2.89 | consumed tokens: 2369126400.0 | grad norm avg: 0.82 | grad norm last: 0.87 | 
2026-01-02T01:09:47 | step: 72400 | train samples/s: 256.2 | train mfu (16-bit): -1.0 | lr mean: 3.204167660442181e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 2.96 | consumed tokens: 2372403200.0 | grad norm avg: 0.81 | grad norm last: 0.79 | 
2026-01-02T01:10:16 | step: 72500 | train samples/s: 260.2 | train mfu (16-bit): -1.0 | lr mean: 3.1998039048630744e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.24 | consumed tokens: 2375680000.0 | grad norm avg: 0.82 | grad norm last: 0.81 | 
2026-01-02T01:10:44 | step: 72600 | train samples/s: 263.0 | train mfu (16-bit): -1.0 | lr mean: 3.1954379664966837e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.89 | consumed tokens: 2378956800.0 | grad norm avg: 0.82 | grad norm last: 0.86 | 
2026-01-02T01:11:14 | step: 72700 | train samples/s: 255.3 | train mfu (16-bit): -1.0 | lr mean: 3.191069481545128e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.4 | consumed tokens: 2382233600.0 | grad norm avg: 0.8 | grad norm last: 0.92 | 
2026-01-02T01:11:42 | step: 72800 | train samples/s: 264.7 | train mfu (16-bit): -1.0 | lr mean: 3.1866991776041687e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.01 | consumed tokens: 2385510400.0 | grad norm avg: 0.8 | grad norm last: 0.78 | 
2026-01-02T01:12:11 | step: 72900 | train samples/s: 261.2 | train mfu (16-bit): -1.0 | lr mean: 3.1823263270780444e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.02 | consumed tokens: 2388787200.0 | grad norm avg: 0.81 | grad norm last: 0.82 | 
2026-01-02T01:12:40 | step: 73000 | train samples/s: 251.5 | train mfu (16-bit): -1.0 | lr mean: 3.177950929966755e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.35 | consumed tokens: 2392064000.0 | grad norm avg: 0.83 | grad norm last: 0.8 | 
2026-01-02T01:13:08 | step: 73100 | train samples/s: 253.5 | train mfu (16-bit): -1.0 | lr mean: 3.1735737138660625e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.02 | consumed tokens: 2395340800.0 | grad norm avg: 0.82 | grad norm last: 0.78 | 
2026-01-02T01:13:37 | step: 73200 | train samples/s: 253.7 | train mfu (16-bit): -1.0 | lr mean: 3.1691943149780855e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.81 | consumed tokens: 2398617600.0 | grad norm avg: 0.8 | grad norm last: 0.83 | 
2026-01-02T01:14:06 | step: 73300 | train samples/s: 252.8 | train mfu (16-bit): -1.0 | lr mean: 3.1648123695049435e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.12 | consumed tokens: 2401894400.0 | grad norm avg: 0.82 | grad norm last: 0.83 | 
2026-01-02T01:14:35 | step: 73400 | train samples/s: 250.6 | train mfu (16-bit): -1.0 | lr mean: 3.160428605042398e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.06 | consumed tokens: 2405171200.0 | grad norm avg: 0.81 | grad norm last: 0.79 | 
2026-01-02T01:15:04 | step: 73500 | train samples/s: 253.8 | train mfu (16-bit): -1.0 | lr mean: 3.1560422939946875e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.14 | consumed tokens: 2408448000.0 | grad norm avg: 0.82 | grad norm last: 0.82 | 
2026-01-02T01:15:32 | step: 73600 | train samples/s: 254.6 | train mfu (16-bit): -1.0 | lr mean: 3.1516541639575735e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.1 | consumed tokens: 2411724800.0 | grad norm avg: 0.83 | grad norm last: 0.92 | 
2026-01-02T01:16:01 | step: 73700 | train samples/s: 252.6 | train mfu (16-bit): -1.0 | lr mean: 3.1472634873352945e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.05 | consumed tokens: 2415001600.0 | grad norm avg: 0.82 | grad norm last: 0.74 | 
2026-01-02T01:16:30 | step: 73800 | train samples/s: 261.2 | train mfu (16-bit): -1.0 | lr mean: 3.142870991723612e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.46 | consumed tokens: 2418278400.0 | grad norm avg: 0.82 | grad norm last: 0.76 | 
2026-01-02T01:16:58 | step: 73900 | train samples/s: 265.3 | train mfu (16-bit): -1.0 | lr mean: 3.138476313324645e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.22 | consumed tokens: 2421555200.0 | grad norm avg: 0.81 | grad norm last: 0.81 | 
2026-01-02T01:17:27 | step: 74000 | train samples/s: 264.8 | train mfu (16-bit): -1.0 | lr mean: 3.134079452138394e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.34 | consumed tokens: 2424832000.0 | grad norm avg: 0.82 | grad norm last: 0.79 | 
2026-01-02T01:17:56 | step: 74100 | train samples/s: 262.2 | train mfu (16-bit): -1.0 | lr mean: 3.129680408164859e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.25 | consumed tokens: 2428108800.0 | grad norm avg: 0.8 | grad norm last: 0.82 | 
2026-01-02T01:18:24 | step: 74200 | train samples/s: 265.0 | train mfu (16-bit): -1.0 | lr mean: 3.12527954520192e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 2.87 | consumed tokens: 2431385600.0 | grad norm avg: 0.82 | grad norm last: 0.86 | 
2026-01-02T01:18:52 | step: 74300 | train samples/s: 263.6 | train mfu (16-bit): -1.0 | lr mean: 3.120876499451697e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.17 | consumed tokens: 2434662400.0 | grad norm avg: 0.84 | grad norm last: 0.83 | 
2026-01-02T01:19:21 | step: 74400 | train samples/s: 262.7 | train mfu (16-bit): -1.0 | lr mean: 3.1164712709141895e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 2.87 | consumed tokens: 2437939200.0 | grad norm avg: 0.83 | grad norm last: 0.88 | 
2026-01-02T01:19:49 | step: 74500 | train samples/s: 264.9 | train mfu (16-bit): -1.0 | lr mean: 3.1120642233872786e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.06 | consumed tokens: 2441216000.0 | grad norm avg: 0.83 | grad norm last: 0.89 | 
2026-01-02T01:20:18 | step: 74600 | train samples/s: 266.0 | train mfu (16-bit): -1.0 | lr mean: 3.1076549930730835e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.03 | consumed tokens: 2444492800.0 | grad norm avg: 0.83 | grad norm last: 0.79 | 
2026-01-02T01:20:47 | step: 74700 | train samples/s: 258.9 | train mfu (16-bit): -1.0 | lr mean: 3.103243943769485e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.08 | consumed tokens: 2447769600.0 | grad norm avg: 0.82 | grad norm last: 0.83 | 
2026-01-02T01:21:15 | step: 74800 | train samples/s: 264.2 | train mfu (16-bit): -1.0 | lr mean: 3.098830711678602e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 2.77 | consumed tokens: 2451046400.0 | grad norm avg: 0.82 | grad norm last: 0.88 | 
2026-01-02T01:21:44 | step: 74900 | train samples/s: 264.4 | train mfu (16-bit): -1.0 | lr mean: 3.094415660598315e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.06 | consumed tokens: 2454323200.0 | grad norm avg: 0.83 | grad norm last: 0.94 | 
2026-01-02T01:22:12 | step: 75000 | train samples/s: 268.7 | train mfu (16-bit): -1.0 | lr mean: 3.0899984267307445e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.97 | consumed tokens: 2457600000.0 | grad norm avg: 0.84 | grad norm last: 0.76 | 
2026-01-02T01:22:42 | step: 75100 | train samples/s: 261.2 | train mfu (16-bit): -1.0 | lr mean: 3.08557937387377e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.35 | consumed tokens: 2460876800.0 | grad norm avg: 0.84 | grad norm last: 0.82 | 
2026-01-02T01:23:11 | step: 75200 | train samples/s: 261.8 | train mfu (16-bit): -1.0 | lr mean: 3.0811585020273924e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.21 | consumed tokens: 2464153600.0 | grad norm avg: 0.83 | grad norm last: 0.89 | 
2026-01-02T01:23:39 | step: 75300 | train samples/s: 259.2 | train mfu (16-bit): -1.0 | lr mean: 3.07673544739373e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.49 | consumed tokens: 2467430400.0 | grad norm avg: 0.83 | grad norm last: 0.85 | 
2026-01-02T01:24:08 | step: 75400 | train samples/s: 253.7 | train mfu (16-bit): -1.0 | lr mean: 3.0723109375685453e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 2.97 | consumed tokens: 2470707200.0 | grad norm avg: 0.85 | grad norm last: 0.81 | 
2026-01-02T01:24:36 | step: 75500 | train samples/s: 259.2 | train mfu (16-bit): -1.0 | lr mean: 3.067884244956076e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.22 | consumed tokens: 2473984000.0 | grad norm avg: 0.84 | grad norm last: 0.88 | 
2026-01-02T01:25:04 | step: 75600 | train samples/s: 257.3 | train mfu (16-bit): -1.0 | lr mean: 3.0634557333542034e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.56 | consumed tokens: 2477260800.0 | grad norm avg: 0.85 | grad norm last: 0.84 | 
2026-01-02T01:25:33 | step: 75700 | train samples/s: 260.4 | train mfu (16-bit): -1.0 | lr mean: 3.0590250389650464e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.41 | consumed tokens: 2480537600.0 | grad norm avg: 0.85 | grad norm last: 0.87 | 
2026-01-02T01:26:01 | step: 75800 | train samples/s: 260.1 | train mfu (16-bit): -1.0 | lr mean: 3.0545928893843666e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.8 | consumed tokens: 2483814400.0 | grad norm avg: 0.85 | grad norm last: 0.86 | 
2026-01-02T01:26:29 | step: 75900 | train samples/s: 261.7 | train mfu (16-bit): -1.0 | lr mean: 3.0501589208142832e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.76 | consumed tokens: 2487091200.0 | grad norm avg: 0.84 | grad norm last: 0.84 | 
2026-01-02T01:26:58 | step: 76000 | train samples/s: 255.7 | train mfu (16-bit): -1.0 | lr mean: 3.045722951355856e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.9 | consumed tokens: 2490368000.0 | grad norm avg: 0.85 | grad norm last: 0.94 | 
2026-01-02T01:27:27 | step: 76100 | train samples/s: 258.3 | train mfu (16-bit): -1.0 | lr mean: 3.0412853448069654e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.02 | consumed tokens: 2493644800.0 | grad norm avg: 0.83 | grad norm last: 0.83 | 
2026-01-02T01:27:55 | step: 76200 | train samples/s: 260.1 | train mfu (16-bit): -1.0 | lr mean: 3.0368459192686714e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.95 | consumed tokens: 2496921600.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-02T01:28:24 | step: 76300 | train samples/s: 266.2 | train mfu (16-bit): -1.0 | lr mean: 3.032404674740974e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.07 | consumed tokens: 2500198400.0 | grad norm avg: 0.85 | grad norm last: 0.75 | 
2026-01-02T01:28:52 | step: 76400 | train samples/s: 263.4 | train mfu (16-bit): -1.0 | lr mean: 3.0279616112238728e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.3 | consumed tokens: 2503475200.0 | grad norm avg: 0.87 | grad norm last: 0.93 | 
2026-01-02T01:29:21 | step: 76500 | train samples/s: 268.0 | train mfu (16-bit): -1.0 | lr mean: 3.0235169106163085e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.14 | consumed tokens: 2506752000.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-02T01:29:49 | step: 76600 | train samples/s: 268.8 | train mfu (16-bit): -1.0 | lr mean: 3.0190703910193406e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.11 | consumed tokens: 2510028800.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-02T01:30:18 | step: 76700 | train samples/s: 265.3 | train mfu (16-bit): -1.0 | lr mean: 3.0146222343319096e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.19 | consumed tokens: 2513305600.0 | grad norm avg: 0.84 | grad norm last: 0.9 | 
2026-01-02T01:30:47 | step: 76800 | train samples/s: 262.0 | train mfu (16-bit): -1.0 | lr mean: 3.010172258655075e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.06 | consumed tokens: 2516582400.0 | grad norm avg: 0.86 | grad norm last: 0.92 | 
2026-01-02T01:31:15 | step: 76900 | train samples/s: 260.2 | train mfu (16-bit): -1.0 | lr mean: 3.0057208277867176e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.22 | consumed tokens: 2519859200.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-02T01:31:43 | step: 77000 | train samples/s: 258.5 | train mfu (16-bit): -1.0 | lr mean: 3.0012675779289566e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.89 | consumed tokens: 2523136000.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-02T01:32:12 | step: 77100 | train samples/s: 256.3 | train mfu (16-bit): -1.0 | lr mean: 2.9968126909807324e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.19 | consumed tokens: 2526412800.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-02T01:32:40 | step: 77200 | train samples/s: 260.4 | train mfu (16-bit): -1.0 | lr mean: 2.992356166942045e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.14 | consumed tokens: 2529689600.0 | grad norm avg: 0.86 | grad norm last: 0.84 | 
2026-01-02T01:33:08 | step: 77300 | train samples/s: 260.6 | train mfu (16-bit): -1.0 | lr mean: 2.9878980058128946e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.9 | consumed tokens: 2532966400.0 | grad norm avg: 0.85 | grad norm last: 0.92 | 
2026-01-02T01:33:37 | step: 77400 | train samples/s: 252.6 | train mfu (16-bit): -1.0 | lr mean: 2.9834382075932808e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.93 | consumed tokens: 2536243200.0 | grad norm avg: 0.9 | grad norm last: 0.74 | 
2026-01-02T01:34:06 | step: 77500 | train samples/s: 255.8 | train mfu (16-bit): -1.0 | lr mean: 2.9789769541821443e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.37 | consumed tokens: 2539520000.0 | grad norm avg: 0.86 | grad norm last: 0.92 | 
2026-01-02T01:34:35 | step: 77600 | train samples/s: 263.5 | train mfu (16-bit): -1.0 | lr mean: 2.9745140636805445e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.11 | consumed tokens: 2542796800.0 | grad norm avg: 0.87 | grad norm last: 0.89 | 
2026-01-02T01:35:03 | step: 77700 | train samples/s: 264.9 | train mfu (16-bit): -1.0 | lr mean: 2.9700495360884815e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.96 | consumed tokens: 2546073600.0 | grad norm avg: 0.85 | grad norm last: 0.83 | 
2026-01-02T01:35:32 | step: 77800 | train samples/s: 263.2 | train mfu (16-bit): -1.0 | lr mean: 2.9655835533048958e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 2.89 | consumed tokens: 2549350400.0 | grad norm avg: 0.88 | grad norm last: 0.99 | 
2026-01-02T01:36:00 | step: 77900 | train samples/s: 264.5 | train mfu (16-bit): -1.0 | lr mean: 2.9611159334308468e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.88 | consumed tokens: 2552627200.0 | grad norm avg: 0.88 | grad norm last: 0.86 | 
2026-01-02T01:36:29 | step: 78000 | train samples/s: 263.2 | train mfu (16-bit): -1.0 | lr mean: 2.956646858365275e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.01 | consumed tokens: 2555904000.0 | grad norm avg: 0.86 | grad norm last: 1.02 | 
2026-01-02T01:36:58 | step: 78100 | train samples/s: 262.3 | train mfu (16-bit): -1.0 | lr mean: 2.9521763281081803e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.25 | consumed tokens: 2559180800.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-02T01:37:27 | step: 78200 | train samples/s: 249.5 | train mfu (16-bit): -1.0 | lr mean: 2.9477041607606225e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.02 | consumed tokens: 2562457600.0 | grad norm avg: 0.87 | grad norm last: 0.92 | 
2026-01-02T01:37:55 | step: 78300 | train samples/s: 257.9 | train mfu (16-bit): -1.0 | lr mean: 2.943230720120482e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.17 | consumed tokens: 2565734400.0 | grad norm avg: 0.87 | grad norm last: 0.9 | 
2026-01-02T01:38:23 | step: 78400 | train samples/s: 259.8 | train mfu (16-bit): -1.0 | lr mean: 2.9387556423898786e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.25 | consumed tokens: 2569011200.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-02T01:38:52 | step: 78500 | train samples/s: 263.1 | train mfu (16-bit): -1.0 | lr mean: 2.9342791094677523e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 2.97 | consumed tokens: 2572288000.0 | grad norm avg: 0.87 | grad norm last: 0.88 | 
2026-01-02T01:39:21 | step: 78600 | train samples/s: 262.1 | train mfu (16-bit): -1.0 | lr mean: 2.9298013032530434e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.24 | consumed tokens: 2575564800.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-02T01:39:49 | step: 78700 | train samples/s: 263.4 | train mfu (16-bit): -1.0 | lr mean: 2.9253220418468118e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.44 | consumed tokens: 2578841600.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-02T01:40:18 | step: 78800 | train samples/s: 259.6 | train mfu (16-bit): -1.0 | lr mean: 2.9208413252490573e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.43 | consumed tokens: 2582118400.0 | grad norm avg: 0.88 | grad norm last: 0.95 | 
2026-01-02T01:40:46 | step: 78900 | train samples/s: 261.3 | train mfu (16-bit): -1.0 | lr mean: 2.91635915345978e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.22 | consumed tokens: 2585395200.0 | grad norm avg: 0.87 | grad norm last: 0.86 | 
2026-01-02T01:41:15 | step: 79000 | train samples/s: 258.5 | train mfu (16-bit): -1.0 | lr mean: 2.91187570837792e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.88 | consumed tokens: 2588672000.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-02T01:41:43 | step: 79100 | train samples/s: 257.7 | train mfu (16-bit): -1.0 | lr mean: 2.9073909900034778e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 3.04 | consumed tokens: 2591948800.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-02T01:42:12 | step: 79200 | train samples/s: 259.9 | train mfu (16-bit): -1.0 | lr mean: 2.9029048164375126e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.91 | consumed tokens: 2595225600.0 | grad norm avg: 0.86 | grad norm last: 0.91 | 
2026-01-02T01:42:40 | step: 79300 | train samples/s: 259.6 | train mfu (16-bit): -1.0 | lr mean: 2.898417369578965e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.89 | consumed tokens: 2598502400.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-02T01:43:09 | step: 79400 | train samples/s: 252.5 | train mfu (16-bit): -1.0 | lr mean: 2.8939284675288945e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.38 | consumed tokens: 2601779200.0 | grad norm avg: 0.88 | grad norm last: 0.91 | 
2026-01-02T01:43:38 | step: 79500 | train samples/s: 253.8 | train mfu (16-bit): -1.0 | lr mean: 2.889438474085182e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.11 | consumed tokens: 2605056000.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-02T01:44:06 | step: 79600 | train samples/s: 258.7 | train mfu (16-bit): -1.0 | lr mean: 2.8849470254499465e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.04 | consumed tokens: 2608332800.0 | grad norm avg: 0.9 | grad norm last: 0.9 | 
2026-01-02T01:44:34 | step: 79700 | train samples/s: 261.4 | train mfu (16-bit): -1.0 | lr mean: 2.8804543035221286e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.31 | consumed tokens: 2611609600.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-02T01:45:03 | step: 79800 | train samples/s: 263.8 | train mfu (16-bit): -1.0 | lr mean: 2.8759604902006686e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.98 | consumed tokens: 2614886400.0 | grad norm avg: 0.89 | grad norm last: 0.85 | 
2026-01-02T01:45:31 | step: 79900 | train samples/s: 256.2 | train mfu (16-bit): -1.0 | lr mean: 2.871465403586626e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.96 | consumed tokens: 2618163200.0 | grad norm avg: 0.86 | grad norm last: 0.89 | 
2026-01-02T01:46:00 | step: 80000 | train samples/s: 259.9 | train mfu (16-bit): -1.0 | lr mean: 2.866969043680001e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.26 | consumed tokens: 2621440000.0 | grad norm avg: 0.88 | grad norm last: 0.83 | 
2026-01-02T01:46:30 | step: 80100 | train samples/s: 263.8 | train mfu (16-bit): -1.0 | lr mean: 2.8624714104807936e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.89 | consumed tokens: 2624716800.0 | grad norm avg: 0.9 | grad norm last: 0.78 | 
2026-01-02T01:47:00 | step: 80200 | train samples/s: 257.4 | train mfu (16-bit): -1.0 | lr mean: 2.857972685887944e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.94 | consumed tokens: 2627993600.0 | grad norm avg: 0.88 | grad norm last: 0.9 | 
2026-01-02T01:47:28 | step: 80300 | train samples/s: 264.8 | train mfu (16-bit): -1.0 | lr mean: 2.853472688002512e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.29 | consumed tokens: 2631270400.0 | grad norm avg: 0.91 | grad norm last: 0.97 | 
2026-01-02T01:47:57 | step: 80400 | train samples/s: 265.2 | train mfu (16-bit): -1.0 | lr mean: 2.8489715987234376e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.22 | consumed tokens: 2634547200.0 | grad norm avg: 0.88 | grad norm last: 0.89 | 
2026-01-02T01:48:25 | step: 80500 | train samples/s: 257.5 | train mfu (16-bit): -1.0 | lr mean: 2.8444694180507213e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.99 | consumed tokens: 2637824000.0 | grad norm avg: 0.88 | grad norm last: 0.95 | 
2026-01-02T01:48:54 | step: 80600 | train samples/s: 254.7 | train mfu (16-bit): -1.0 | lr mean: 2.8399661459843628e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.09 | consumed tokens: 2641100800.0 | grad norm avg: 0.92 | grad norm last: 0.98 | 
2026-01-02T01:49:23 | step: 80700 | train samples/s: 252.5 | train mfu (16-bit): -1.0 | lr mean: 2.835461600625422e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 2.94 | consumed tokens: 2644377600.0 | grad norm avg: 0.91 | grad norm last: 0.94 | 
2026-01-02T01:49:52 | step: 80800 | train samples/s: 252.1 | train mfu (16-bit): -1.0 | lr mean: 2.8309559638728388e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.08 | consumed tokens: 2647654400.0 | grad norm avg: 0.89 | grad norm last: 0.84 | 
2026-01-02T01:50:21 | step: 80900 | train samples/s: 255.0 | train mfu (16-bit): -1.0 | lr mean: 2.8264492357266136e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.16 | consumed tokens: 2650931200.0 | grad norm avg: 0.9 | grad norm last: 0.96 | 
2026-01-02T01:50:49 | step: 81000 | train samples/s: 253.9 | train mfu (16-bit): -1.0 | lr mean: 2.8219415980856866e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.11 | consumed tokens: 2654208000.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-02T01:51:18 | step: 81100 | train samples/s: 254.7 | train mfu (16-bit): -1.0 | lr mean: 2.817432687152177e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.43 | consumed tokens: 2657484800.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-02T01:51:47 | step: 81200 | train samples/s: 250.9 | train mfu (16-bit): -1.0 | lr mean: 2.812922866723966e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.21 | consumed tokens: 2660761600.0 | grad norm avg: 0.88 | grad norm last: 0.95 | 
2026-01-02T01:52:16 | step: 81300 | train samples/s: 256.2 | train mfu (16-bit): -1.0 | lr mean: 2.8084119549021125e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.32 | consumed tokens: 2664038400.0 | grad norm avg: 0.9 | grad norm last: 0.91 | 
2026-01-02T01:52:45 | step: 81400 | train samples/s: 255.0 | train mfu (16-bit): -1.0 | lr mean: 2.8039001335855573e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.28 | consumed tokens: 2667315200.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-02T01:53:13 | step: 81500 | train samples/s: 258.5 | train mfu (16-bit): -1.0 | lr mean: 2.79938722087536e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.18 | consumed tokens: 2670592000.0 | grad norm avg: 0.91 | grad norm last: 0.86 | 
2026-01-02T01:53:42 | step: 81600 | train samples/s: 265.8 | train mfu (16-bit): -1.0 | lr mean: 2.794873398670461e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.2 | consumed tokens: 2673868800.0 | grad norm avg: 0.89 | grad norm last: 1.0 | 
2026-01-02T01:54:10 | step: 81700 | train samples/s: 269.3 | train mfu (16-bit): -1.0 | lr mean: 2.79035848507192e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.78 | consumed tokens: 2677145600.0 | grad norm avg: 0.88 | grad norm last: 0.98 | 
2026-01-02T01:54:38 | step: 81800 | train samples/s: 265.6 | train mfu (16-bit): -1.0 | lr mean: 2.785842661978677e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.54 | consumed tokens: 2680422400.0 | grad norm avg: 0.89 | grad norm last: 0.86 | 
2026-01-02T01:55:07 | step: 81900 | train samples/s: 263.1 | train mfu (16-bit): -1.0 | lr mean: 2.7813259293907322e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.22 | consumed tokens: 2683699200.0 | grad norm avg: 0.91 | grad norm last: 1.08 | 
2026-01-02T01:55:35 | step: 82000 | train samples/s: 265.2 | train mfu (16-bit): -1.0 | lr mean: 2.7768082873080857e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.03 | consumed tokens: 2686976000.0 | grad norm avg: 0.9 | grad norm last: 1.04 | 
2026-01-02T01:56:04 | step: 82100 | train samples/s: 265.6 | train mfu (16-bit): -1.0 | lr mean: 2.7722897357307374e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.95 | consumed tokens: 2690252800.0 | grad norm avg: 0.9 | grad norm last: 0.82 | 
2026-01-02T01:56:32 | step: 82200 | train samples/s: 264.4 | train mfu (16-bit): -1.0 | lr mean: 2.7677702746586874e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.07 | consumed tokens: 2693529600.0 | grad norm avg: 0.89 | grad norm last: 0.97 | 
2026-01-02T01:57:01 | step: 82300 | train samples/s: 258.3 | train mfu (16-bit): -1.0 | lr mean: 2.7632499040919356e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.24 | consumed tokens: 2696806400.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-02T01:57:29 | step: 82400 | train samples/s: 267.3 | train mfu (16-bit): -1.0 | lr mean: 2.758728624030482e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.38 | consumed tokens: 2700083200.0 | grad norm avg: 0.9 | grad norm last: 0.86 | 
2026-01-02T01:57:58 | step: 82500 | train samples/s: 264.4 | train mfu (16-bit): -1.0 | lr mean: 2.754206616373267e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.18 | consumed tokens: 2703360000.0 | grad norm avg: 0.9 | grad norm last: 0.89 | 
2026-01-02T01:58:26 | step: 82600 | train samples/s: 262.3 | train mfu (16-bit): -1.0 | lr mean: 2.7496836992213503e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.0 | consumed tokens: 2706636800.0 | grad norm avg: 0.91 | grad norm last: 1.07 | 
2026-01-02T01:58:55 | step: 82700 | train samples/s: 253.8 | train mfu (16-bit): -1.0 | lr mean: 2.745160054473672e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.97 | consumed tokens: 2709913600.0 | grad norm avg: 0.92 | grad norm last: 0.99 | 
2026-01-02T01:59:24 | step: 82800 | train samples/s: 254.3 | train mfu (16-bit): -1.0 | lr mean: 2.740635500231292e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.1 | consumed tokens: 2713190400.0 | grad norm avg: 0.91 | grad norm last: 0.8 | 
2026-01-02T01:59:53 | step: 82900 | train samples/s: 255.2 | train mfu (16-bit): -1.0 | lr mean: 2.7361102183931507e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 2.93 | consumed tokens: 2716467200.0 | grad norm avg: 0.9 | grad norm last: 0.99 | 
2026-01-02T02:00:21 | step: 83000 | train samples/s: 264.2 | train mfu (16-bit): -1.0 | lr mean: 2.731584208959248e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.49 | consumed tokens: 2719744000.0 | grad norm avg: 0.91 | grad norm last: 1.11 | 
2026-01-02T02:00:50 | step: 83100 | train samples/s: 263.4 | train mfu (16-bit): -1.0 | lr mean: 2.7270572900306433e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.11 | consumed tokens: 2723020800.0 | grad norm avg: 0.91 | grad norm last: 0.95 | 
2026-01-02T02:01:18 | step: 83200 | train samples/s: 265.1 | train mfu (16-bit): -1.0 | lr mean: 2.7225296435062774e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.11 | consumed tokens: 2726297600.0 | grad norm avg: 0.91 | grad norm last: 0.84 | 
2026-01-02T02:01:47 | step: 83300 | train samples/s: 264.8 | train mfu (16-bit): -1.0 | lr mean: 2.7180014512850903e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.05 | consumed tokens: 2729574400.0 | grad norm avg: 0.89 | grad norm last: 0.89 | 
2026-01-02T02:02:15 | step: 83400 | train samples/s: 268.2 | train mfu (16-bit): -1.0 | lr mean: 2.7134723495692015e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.1 | consumed tokens: 2732851200.0 | grad norm avg: 0.92 | grad norm last: 0.91 | 
2026-01-02T02:02:44 | step: 83500 | train samples/s: 266.3 | train mfu (16-bit): -1.0 | lr mean: 2.7089427021564916e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.86 | consumed tokens: 2736128000.0 | grad norm avg: 0.93 | grad norm last: 0.98 | 
2026-01-02T02:03:13 | step: 83600 | train samples/s: 261.8 | train mfu (16-bit): -1.0 | lr mean: 2.7044123271480203e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.44 | consumed tokens: 2739404800.0 | grad norm avg: 0.91 | grad norm last: 0.9 | 
2026-01-02T02:03:41 | step: 83700 | train samples/s: 267.1 | train mfu (16-bit): -1.0 | lr mean: 2.6998812245437875e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.2 | consumed tokens: 2742681600.0 | grad norm avg: 0.91 | grad norm last: 0.84 | 
2026-01-02T02:04:09 | step: 83800 | train samples/s: 262.7 | train mfu (16-bit): -1.0 | lr mean: 2.6953493943437934e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.04 | consumed tokens: 2745958400.0 | grad norm avg: 0.91 | grad norm last: 0.93 | 
2026-01-02T02:04:38 | step: 83900 | train samples/s: 254.8 | train mfu (16-bit): -1.0 | lr mean: 2.6908170184469782e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.2 | consumed tokens: 2749235200.0 | grad norm avg: 0.91 | grad norm last: 0.83 | 
2026-01-02T02:05:07 | step: 84000 | train samples/s: 263.4 | train mfu (16-bit): -1.0 | lr mean: 2.686284096853342e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.98 | consumed tokens: 2752512000.0 | grad norm avg: 0.91 | grad norm last: 0.88 | 
2026-01-02T02:05:35 | step: 84100 | train samples/s: 266.4 | train mfu (16-bit): -1.0 | lr mean: 2.6817504476639442e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.11 | consumed tokens: 2755788800.0 | grad norm avg: 0.92 | grad norm last: 0.98 | 
2026-01-02T02:06:04 | step: 84200 | train samples/s: 266.7 | train mfu (16-bit): -1.0 | lr mean: 2.6772162527777255e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.98 | consumed tokens: 2759065600.0 | grad norm avg: 0.92 | grad norm last: 0.95 | 
2026-01-02T02:06:32 | step: 84300 | train samples/s: 263.0 | train mfu (16-bit): -1.0 | lr mean: 2.6726815121946856e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.42 | consumed tokens: 2762342400.0 | grad norm avg: 0.92 | grad norm last: 0.89 | 
2026-01-02T02:07:01 | step: 84400 | train samples/s: 265.3 | train mfu (16-bit): -1.0 | lr mean: 2.6681462259148248e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.2 | consumed tokens: 2765619200.0 | grad norm avg: 0.92 | grad norm last: 1.07 | 
2026-01-02T02:07:29 | step: 84500 | train samples/s: 266.6 | train mfu (16-bit): -1.0 | lr mean: 2.6636103939381428e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.26 | consumed tokens: 2768896000.0 | grad norm avg: 0.92 | grad norm last: 1.0 | 
2026-01-02T02:07:58 | step: 84600 | train samples/s: 259.5 | train mfu (16-bit): -1.0 | lr mean: 2.6590738343656994e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.17 | consumed tokens: 2772172800.0 | grad norm avg: 0.91 | grad norm last: 0.91 | 
2026-01-02T02:08:26 | step: 84700 | train samples/s: 268.9 | train mfu (16-bit): -1.0 | lr mean: 2.6545369109953754e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.51 | consumed tokens: 2775449600.0 | grad norm avg: 0.91 | grad norm last: 0.85 | 
2026-01-02T02:08:55 | step: 84800 | train samples/s: 264.8 | train mfu (16-bit): -1.0 | lr mean: 2.6499994419282302e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.49 | consumed tokens: 2778726400.0 | grad norm avg: 0.92 | grad norm last: 0.9 | 
2026-01-02T02:09:23 | step: 84900 | train samples/s: 264.6 | train mfu (16-bit): -1.0 | lr mean: 2.6454616090632044e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.21 | consumed tokens: 2782003200.0 | grad norm avg: 0.91 | grad norm last: 0.99 | 
2026-01-02T02:09:52 | step: 85000 | train samples/s: 254.6 | train mfu (16-bit): -1.0 | lr mean: 2.6409232305013575e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.11 | consumed tokens: 2785280000.0 | grad norm avg: 0.92 | grad norm last: 0.93 | 
2026-01-02T02:10:23 | step: 85100 | train samples/s: 253.0 | train mfu (16-bit): -1.0 | lr mean: 2.6363843062426895e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.5 | consumed tokens: 2788556800.0 | grad norm avg: 0.92 | grad norm last: 0.86 | 
2026-01-02T02:10:52 | step: 85200 | train samples/s: 253.5 | train mfu (16-bit): -1.0 | lr mean: 2.6318450181861408e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.01 | consumed tokens: 2791833600.0 | grad norm avg: 0.92 | grad norm last: 0.85 | 
2026-01-02T02:11:21 | step: 85300 | train samples/s: 249.9 | train mfu (16-bit): -1.0 | lr mean: 2.6273053663317114e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.27 | consumed tokens: 2795110400.0 | grad norm avg: 0.94 | grad norm last: 0.91 | 
2026-01-02T02:11:50 | step: 85400 | train samples/s: 262.5 | train mfu (16-bit): -1.0 | lr mean: 2.622765168780461e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.13 | train loss last: 2.76 | consumed tokens: 2798387200.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T02:12:18 | step: 85500 | train samples/s: 268.7 | train mfu (16-bit): -1.0 | lr mean: 2.6182246074313298e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.01 | consumed tokens: 2801664000.0 | grad norm avg: 0.93 | grad norm last: 0.9 | 
2026-01-02T02:12:47 | step: 85600 | train samples/s: 264.0 | train mfu (16-bit): -1.0 | lr mean: 2.613683682284318e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.17 | consumed tokens: 2804940800.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T02:13:15 | step: 85700 | train samples/s: 265.1 | train mfu (16-bit): -1.0 | lr mean: 2.6091423933394253e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.05 | consumed tokens: 2808217600.0 | grad norm avg: 0.93 | grad norm last: 0.92 | 
2026-01-02T02:13:44 | step: 85800 | train samples/s: 263.5 | train mfu (16-bit): -1.0 | lr mean: 2.604600740596652e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.95 | consumed tokens: 2811494400.0 | grad norm avg: 0.93 | grad norm last: 0.85 | 
2026-01-02T02:14:12 | step: 85900 | train samples/s: 257.0 | train mfu (16-bit): -1.0 | lr mean: 2.600058724055998e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.83 | consumed tokens: 2814771200.0 | grad norm avg: 0.94 | grad norm last: 0.82 | 
2026-01-02T02:14:41 | step: 86000 | train samples/s: 256.1 | train mfu (16-bit): -1.0 | lr mean: 2.5955165256164037e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.26 | consumed tokens: 2818048000.0 | grad norm avg: 0.94 | grad norm last: 0.95 | 
2026-01-02T02:15:09 | step: 86100 | train samples/s: 255.6 | train mfu (16-bit): -1.0 | lr mean: 2.5909737814799882e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.23 | consumed tokens: 2821324800.0 | grad norm avg: 0.92 | grad norm last: 0.92 | 
2026-01-02T02:15:38 | step: 86200 | train samples/s: 258.4 | train mfu (16-bit): -1.0 | lr mean: 2.5864308554446325e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.98 | consumed tokens: 2824601600.0 | grad norm avg: 0.93 | grad norm last: 1.02 | 
2026-01-02T02:16:06 | step: 86300 | train samples/s: 256.7 | train mfu (16-bit): -1.0 | lr mean: 2.5818877475103363e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.55 | consumed tokens: 2827878400.0 | grad norm avg: 0.92 | grad norm last: 0.97 | 
2026-01-02T02:16:34 | step: 86400 | train samples/s: 259.7 | train mfu (16-bit): -1.0 | lr mean: 2.5773442757781595e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.04 | consumed tokens: 2831155200.0 | grad norm avg: 0.93 | grad norm last: 1.06 | 
2026-01-02T02:17:02 | step: 86500 | train samples/s: 259.8 | train mfu (16-bit): -1.0 | lr mean: 2.5728006221470423e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.47 | consumed tokens: 2834432000.0 | grad norm avg: 0.94 | grad norm last: 0.83 | 
2026-01-02T02:17:31 | step: 86600 | train samples/s: 254.9 | train mfu (16-bit): -1.0 | lr mean: 2.5682566047180444e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.21 | consumed tokens: 2837708800.0 | grad norm avg: 0.94 | grad norm last: 0.9 | 
2026-01-02T02:17:59 | step: 86700 | train samples/s: 261.4 | train mfu (16-bit): -1.0 | lr mean: 2.563712405390106e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.99 | consumed tokens: 2840985600.0 | grad norm avg: 0.93 | grad norm last: 0.86 | 
2026-01-02T02:18:28 | step: 86800 | train samples/s: 262.5 | train mfu (16-bit): -1.0 | lr mean: 2.559168206062168e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.46 | consumed tokens: 2844262400.0 | grad norm avg: 0.95 | grad norm last: 0.82 | 
2026-01-02T02:18:56 | step: 86900 | train samples/s: 257.5 | train mfu (16-bit): -1.0 | lr mean: 2.554623642936349e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.1 | consumed tokens: 2847539200.0 | grad norm avg: 0.93 | grad norm last: 0.94 | 
2026-01-02T02:19:25 | step: 87000 | train samples/s: 253.3 | train mfu (16-bit): -1.0 | lr mean: 2.5500788979115896e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.0 | consumed tokens: 2850816000.0 | grad norm avg: 0.93 | grad norm last: 0.99 | 
2026-01-02T02:19:53 | step: 87100 | train samples/s: 258.8 | train mfu (16-bit): -1.0 | lr mean: 2.54553397098789e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.91 | consumed tokens: 2854092800.0 | grad norm avg: 0.93 | grad norm last: 1.03 | 
2026-01-02T02:20:22 | step: 87200 | train samples/s: 256.7 | train mfu (16-bit): -1.0 | lr mean: 2.5409890440641902e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.98 | consumed tokens: 2857369600.0 | grad norm avg: 0.95 | grad norm last: 0.96 | 
2026-01-02T02:20:50 | step: 87300 | train samples/s: 257.6 | train mfu (16-bit): -1.0 | lr mean: 2.53644375334261e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.27 | consumed tokens: 2860646400.0 | grad norm avg: 0.95 | grad norm last: 0.85 | 
2026-01-02T02:21:18 | step: 87400 | train samples/s: 263.6 | train mfu (16-bit): -1.0 | lr mean: 2.5318986445199698e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.02 | consumed tokens: 2863923200.0 | grad norm avg: 0.95 | grad norm last: 1.01 | 
2026-01-02T02:21:46 | step: 87500 | train samples/s: 263.3 | train mfu (16-bit): -1.0 | lr mean: 2.527353171899449e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.86 | consumed tokens: 2867200000.0 | grad norm avg: 0.95 | grad norm last: 0.92 | 
2026-01-02T02:22:15 | step: 87600 | train samples/s: 260.6 | train mfu (16-bit): -1.0 | lr mean: 2.5228078811778687e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.8 | consumed tokens: 2870476800.0 | grad norm avg: 0.96 | grad norm last: 0.86 | 
2026-01-02T02:22:44 | step: 87700 | train samples/s: 253.8 | train mfu (16-bit): -1.0 | lr mean: 2.5182622266584076e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.23 | consumed tokens: 2873753600.0 | grad norm avg: 0.98 | grad norm last: 0.94 | 
2026-01-02T02:23:12 | step: 87800 | train samples/s: 259.1 | train mfu (16-bit): -1.0 | lr mean: 2.513716754037887e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.12 | train loss last: 3.35 | consumed tokens: 2877030400.0 | grad norm avg: 0.96 | grad norm last: 0.92 | 
2026-01-02T02:23:41 | step: 87900 | train samples/s: 259.1 | train mfu (16-bit): -1.0 | lr mean: 2.5091710995184258e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.89 | consumed tokens: 2880307200.0 | grad norm avg: 0.98 | grad norm last: 0.95 | 
2026-01-02T02:24:09 | step: 88000 | train samples/s: 254.5 | train mfu (16-bit): -1.0 | lr mean: 2.5046254449989647e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.01 | consumed tokens: 2883584000.0 | grad norm avg: 0.96 | grad norm last: 0.93 | 
2026-01-02T02:24:38 | step: 88100 | train samples/s: 259.9 | train mfu (16-bit): -1.0 | lr mean: 2.500079972378444e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.81 | consumed tokens: 2886860800.0 | grad norm avg: 0.99 | grad norm last: 1.04 | 
2026-01-02T02:25:06 | step: 88200 | train samples/s: 267.7 | train mfu (16-bit): -1.0 | lr mean: 2.495534317858983e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.89 | consumed tokens: 2890137600.0 | grad norm avg: 0.95 | grad norm last: 0.99 | 
2026-01-02T02:25:35 | step: 88300 | train samples/s: 254.9 | train mfu (16-bit): -1.0 | lr mean: 2.4909886633395217e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.29 | consumed tokens: 2893414400.0 | grad norm avg: 0.95 | grad norm last: 0.86 | 
2026-01-02T02:26:03 | step: 88400 | train samples/s: 262.9 | train mfu (16-bit): -1.0 | lr mean: 2.486443190719001e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.25 | consumed tokens: 2896691200.0 | grad norm avg: 0.96 | grad norm last: 0.85 | 
2026-01-02T02:26:31 | step: 88500 | train samples/s: 266.1 | train mfu (16-bit): -1.0 | lr mean: 2.4818977180984803e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.13 | consumed tokens: 2899968000.0 | grad norm avg: 0.97 | grad norm last: 0.9 | 
2026-01-02T02:27:00 | step: 88600 | train samples/s: 254.2 | train mfu (16-bit): -1.0 | lr mean: 2.4773522454779595e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.32 | consumed tokens: 2903244800.0 | grad norm avg: 0.95 | grad norm last: 0.93 | 
2026-01-02T02:27:29 | step: 88700 | train samples/s: 261.6 | train mfu (16-bit): -1.0 | lr mean: 2.472806954756379e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.9 | consumed tokens: 2906521600.0 | grad norm avg: 0.95 | grad norm last: 0.84 | 
2026-01-02T02:27:57 | step: 88800 | train samples/s: 265.9 | train mfu (16-bit): -1.0 | lr mean: 2.4682616640347987e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.08 | consumed tokens: 2909798400.0 | grad norm avg: 0.95 | grad norm last: 1.02 | 
2026-01-02T02:28:25 | step: 88900 | train samples/s: 262.2 | train mfu (16-bit): -1.0 | lr mean: 2.4637165552121587e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.2 | consumed tokens: 2913075200.0 | grad norm avg: 0.93 | grad norm last: 0.99 | 
2026-01-02T02:28:54 | step: 89000 | train samples/s: 254.2 | train mfu (16-bit): -1.0 | lr mean: 2.4591714463895187e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.28 | consumed tokens: 2916352000.0 | grad norm avg: 0.96 | grad norm last: 0.95 | 
2026-01-02T02:29:23 | step: 89100 | train samples/s: 257.0 | train mfu (16-bit): -1.0 | lr mean: 2.4546267013647594e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.91 | consumed tokens: 2919628800.0 | grad norm avg: 0.98 | grad norm last: 0.9 | 
2026-01-02T02:29:51 | step: 89200 | train samples/s: 261.5 | train mfu (16-bit): -1.0 | lr mean: 2.45008195634e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.23 | consumed tokens: 2922905600.0 | grad norm avg: 0.97 | grad norm last: 0.99 | 
2026-01-02T02:30:19 | step: 89300 | train samples/s: 256.2 | train mfu (16-bit): -1.0 | lr mean: 2.445537393214181e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.1 | consumed tokens: 2926182400.0 | grad norm avg: 0.98 | grad norm last: 0.92 | 
2026-01-02T02:30:48 | step: 89400 | train samples/s: 257.1 | train mfu (16-bit): -1.0 | lr mean: 2.4409930119873025e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.23 | consumed tokens: 2929459200.0 | grad norm avg: 0.97 | grad norm last: 1.16 | 
2026-01-02T02:31:16 | step: 89500 | train samples/s: 257.6 | train mfu (16-bit): -1.0 | lr mean: 2.4364489945583045e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.4 | consumed tokens: 2932736000.0 | grad norm avg: 1.02 | grad norm last: 0.95 | 
2026-01-02T02:31:44 | step: 89600 | train samples/s: 259.9 | train mfu (16-bit): -1.0 | lr mean: 2.4319049771293066e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.06 | consumed tokens: 2936012800.0 | grad norm avg: 0.98 | grad norm last: 0.94 | 
2026-01-02T02:32:13 | step: 89700 | train samples/s: 257.5 | train mfu (16-bit): -1.0 | lr mean: 2.4273613234981894e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.01 | consumed tokens: 2939289600.0 | grad norm avg: 0.96 | grad norm last: 1.13 | 
2026-01-02T02:32:41 | step: 89800 | train samples/s: 261.3 | train mfu (16-bit): -1.0 | lr mean: 2.4228178517660126e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.96 | consumed tokens: 2942566400.0 | grad norm avg: 0.99 | grad norm last: 1.02 | 
2026-01-02T02:33:09 | step: 89900 | train samples/s: 259.0 | train mfu (16-bit): -1.0 | lr mean: 2.4182747438317165e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.08 | consumed tokens: 2945843200.0 | grad norm avg: 0.98 | grad norm last: 0.98 | 
2026-01-02T02:33:38 | step: 90000 | train samples/s: 255.0 | train mfu (16-bit): -1.0 | lr mean: 2.4137318177963607e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.27 | consumed tokens: 2949120000.0 | grad norm avg: 1.0 | grad norm last: 0.99 | 
2026-01-02T02:34:08 | step: 90100 | train samples/s: 259.6 | train mfu (16-bit): -1.0 | lr mean: 2.4091892555588856e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.17 | consumed tokens: 2952396800.0 | grad norm avg: 0.98 | grad norm last: 0.98 | 
2026-01-02T02:34:36 | step: 90200 | train samples/s: 258.5 | train mfu (16-bit): -1.0 | lr mean: 2.404646875220351e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.15 | consumed tokens: 2955673600.0 | grad norm avg: 0.97 | grad norm last: 1.02 | 
2026-01-02T02:35:04 | step: 90300 | train samples/s: 261.4 | train mfu (16-bit): -1.0 | lr mean: 2.4001050405786373e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.82 | consumed tokens: 2958950400.0 | grad norm avg: 0.98 | grad norm last: 0.95 | 
2026-01-02T02:35:33 | step: 90400 | train samples/s: 263.0 | train mfu (16-bit): -1.0 | lr mean: 2.395563387835864e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.11 | consumed tokens: 2962227200.0 | grad norm avg: 1.0 | grad norm last: 0.99 | 
2026-01-02T02:36:02 | step: 90500 | train samples/s: 258.1 | train mfu (16-bit): -1.0 | lr mean: 2.3910220988909714e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.21 | consumed tokens: 2965504000.0 | grad norm avg: 0.98 | grad norm last: 0.91 | 
2026-01-02T02:36:30 | step: 90600 | train samples/s: 262.2 | train mfu (16-bit): -1.0 | lr mean: 2.3864811737439595e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.13 | consumed tokens: 2968780800.0 | grad norm avg: 0.98 | grad norm last: 1.07 | 
2026-01-02T02:36:59 | step: 90700 | train samples/s: 258.2 | train mfu (16-bit): -1.0 | lr mean: 2.3819406123948283e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.9 | consumed tokens: 2972057600.0 | grad norm avg: 0.99 | grad norm last: 1.06 | 
2026-01-02T02:37:27 | step: 90800 | train samples/s: 269.2 | train mfu (16-bit): -1.0 | lr mean: 2.3774005967425182e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.46 | consumed tokens: 2975334400.0 | grad norm avg: 0.98 | grad norm last: 0.89 | 
2026-01-02T02:37:55 | step: 90900 | train samples/s: 261.5 | train mfu (16-bit): -1.0 | lr mean: 2.3728607629891485e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.59 | consumed tokens: 2978611200.0 | grad norm avg: 0.98 | grad norm last: 1.04 | 
2026-01-02T02:38:23 | step: 91000 | train samples/s: 260.0 | train mfu (16-bit): -1.0 | lr mean: 2.3683214749325998e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.85 | consumed tokens: 2981888000.0 | grad norm avg: 0.99 | grad norm last: 1.02 | 
2026-01-02T02:38:52 | step: 91100 | train samples/s: 256.5 | train mfu (16-bit): -1.0 | lr mean: 2.3637827325728722e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.03 | consumed tokens: 2985164800.0 | grad norm avg: 0.98 | grad norm last: 0.98 | 
2026-01-02T02:39:20 | step: 91200 | train samples/s: 260.2 | train mfu (16-bit): -1.0 | lr mean: 2.3592443540110253e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.92 | consumed tokens: 2988441600.0 | grad norm avg: 0.97 | grad norm last: 0.96 | 
2026-01-02T02:39:48 | step: 91300 | train samples/s: 259.2 | train mfu (16-bit): -1.0 | lr mean: 2.354706339247059e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.91 | consumed tokens: 2991718400.0 | grad norm avg: 0.98 | grad norm last: 0.98 | 
2026-01-02T02:40:17 | step: 91400 | train samples/s: 256.5 | train mfu (16-bit): -1.0 | lr mean: 2.3501690520788543e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.43 | consumed tokens: 2994995200.0 | grad norm avg: 0.98 | grad norm last: 0.98 | 
2026-01-02T02:40:45 | step: 91500 | train samples/s: 260.0 | train mfu (16-bit): -1.0 | lr mean: 2.3456321287085302e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.09 | consumed tokens: 2998272000.0 | grad norm avg: 1.02 | grad norm last: 1.09 | 
2026-01-02T02:41:14 | step: 91600 | train samples/s: 258.1 | train mfu (16-bit): -1.0 | lr mean: 2.3410957510350272e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.9 | consumed tokens: 3001548800.0 | grad norm avg: 1.03 | grad norm last: 1.0 | 
2026-01-02T02:41:42 | step: 91700 | train samples/s: 253.2 | train mfu (16-bit): -1.0 | lr mean: 2.3365599190583453e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.3 | consumed tokens: 3004825600.0 | grad norm avg: 1.02 | grad norm last: 0.95 | 
2026-01-02T02:42:11 | step: 91800 | train samples/s: 266.3 | train mfu (16-bit): -1.0 | lr mean: 2.3320246327784844e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.07 | consumed tokens: 3008102400.0 | grad norm avg: 0.99 | grad norm last: 0.97 | 
2026-01-02T02:42:39 | step: 91900 | train samples/s: 261.4 | train mfu (16-bit): -1.0 | lr mean: 2.3274898921954446e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.13 | consumed tokens: 3011379200.0 | grad norm avg: 0.98 | grad norm last: 0.97 | 
2026-01-02T02:43:08 | step: 92000 | train samples/s: 252.9 | train mfu (16-bit): -1.0 | lr mean: 2.3229556973092258e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.86 | consumed tokens: 3014656000.0 | grad norm avg: 0.99 | grad norm last: 1.16 | 
2026-01-02T02:43:36 | step: 92100 | train samples/s: 258.2 | train mfu (16-bit): -1.0 | lr mean: 2.318422048119828e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.99 | consumed tokens: 3017932800.0 | grad norm avg: 1.02 | grad norm last: 0.94 | 
2026-01-02T02:44:05 | step: 92200 | train samples/s: 256.5 | train mfu (16-bit): -1.0 | lr mean: 2.313889126526192e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.18 | consumed tokens: 3021209600.0 | grad norm avg: 1.02 | grad norm last: 1.12 | 
2026-01-02T02:44:33 | step: 92300 | train samples/s: 259.7 | train mfu (16-bit): -1.0 | lr mean: 2.309356932528317e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.13 | consumed tokens: 3024486400.0 | grad norm avg: 1.02 | grad norm last: 1.04 | 
2026-01-02T02:45:02 | step: 92400 | train samples/s: 255.0 | train mfu (16-bit): -1.0 | lr mean: 2.3048251023283228e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.95 | consumed tokens: 3027763200.0 | grad norm avg: 0.98 | grad norm last: 1.03 | 
2026-01-02T02:45:30 | step: 92500 | train samples/s: 258.6 | train mfu (16-bit): -1.0 | lr mean: 2.3002941816230305e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.07 | consumed tokens: 3031040000.0 | grad norm avg: 1.01 | grad norm last: 1.02 | 
2026-01-02T02:45:58 | step: 92600 | train samples/s: 256.2 | train mfu (16-bit): -1.0 | lr mean: 2.295763806614559e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.43 | consumed tokens: 3034316800.0 | grad norm avg: 1.0 | grad norm last: 1.12 | 
2026-01-02T02:46:27 | step: 92700 | train samples/s: 263.4 | train mfu (16-bit): -1.0 | lr mean: 2.2912341592018493e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.96 | consumed tokens: 3037593600.0 | grad norm avg: 1.0 | grad norm last: 1.0 | 
2026-01-02T02:46:55 | step: 92800 | train samples/s: 267.6 | train mfu (16-bit): -1.0 | lr mean: 2.2867050574859604e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.17 | consumed tokens: 3040870400.0 | grad norm avg: 1.01 | grad norm last: 0.92 | 
2026-01-02T02:47:24 | step: 92900 | train samples/s: 259.0 | train mfu (16-bit): -1.0 | lr mean: 2.2821768652647734e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.32 | consumed tokens: 3044147200.0 | grad norm avg: 1.0 | grad norm last: 1.05 | 
2026-01-02T02:47:52 | step: 93000 | train samples/s: 256.9 | train mfu (16-bit): -1.0 | lr mean: 2.2776494006393477e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.97 | consumed tokens: 3047424000.0 | grad norm avg: 1.01 | grad norm last: 0.94 | 
2026-01-02T02:48:22 | step: 93100 | train samples/s: 249.4 | train mfu (16-bit): -1.0 | lr mean: 2.273122481710743e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.46 | consumed tokens: 3050700800.0 | grad norm avg: 1.03 | grad norm last: 1.14 | 
2026-01-02T02:48:50 | step: 93200 | train samples/s: 265.3 | train mfu (16-bit): -1.0 | lr mean: 2.2685964722768404e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.19 | consumed tokens: 3053977600.0 | grad norm avg: 0.99 | grad norm last: 1.13 | 
2026-01-02T02:49:19 | step: 93300 | train samples/s: 258.4 | train mfu (16-bit): -1.0 | lr mean: 2.264071190438699e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.07 | consumed tokens: 3057254400.0 | grad norm avg: 0.99 | grad norm last: 1.05 | 
2026-01-02T02:49:48 | step: 93400 | train samples/s: 251.2 | train mfu (16-bit): -1.0 | lr mean: 2.2595468180952594e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.43 | consumed tokens: 3060531200.0 | grad norm avg: 1.01 | grad norm last: 0.99 | 
2026-01-02T02:50:17 | step: 93500 | train samples/s: 252.9 | train mfu (16-bit): -1.0 | lr mean: 2.2550231733475812e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.24 | consumed tokens: 3063808000.0 | grad norm avg: 1.01 | grad norm last: 1.01 | 
2026-01-02T02:50:45 | step: 93600 | train samples/s: 253.2 | train mfu (16-bit): -1.0 | lr mean: 2.2505002561956644e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 2.93 | consumed tokens: 3067084800.0 | grad norm avg: 1.01 | grad norm last: 1.06 | 
2026-01-02T02:51:14 | step: 93700 | train samples/s: 249.8 | train mfu (16-bit): -1.0 | lr mean: 2.2459782485384494e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.25 | consumed tokens: 3070361600.0 | grad norm avg: 1.03 | grad norm last: 0.97 | 
2026-01-02T02:51:44 | step: 93800 | train samples/s: 249.8 | train mfu (16-bit): -1.0 | lr mean: 2.2414571503759362e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.04 | consumed tokens: 3073638400.0 | grad norm avg: 1.02 | grad norm last: 0.92 | 
2026-01-02T02:52:12 | step: 93900 | train samples/s: 259.4 | train mfu (16-bit): -1.0 | lr mean: 2.2369369617081247e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.11 | consumed tokens: 3076915200.0 | grad norm avg: 1.0 | grad norm last: 1.03 | 
2026-01-02T02:52:41 | step: 94000 | train samples/s: 251.4 | train mfu (16-bit): -1.0 | lr mean: 2.2324175006360747e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.09 | consumed tokens: 3080192000.0 | grad norm avg: 1.01 | grad norm last: 1.13 | 
2026-01-02T02:53:10 | step: 94100 | train samples/s: 249.3 | train mfu (16-bit): -1.0 | lr mean: 2.2278989490587264e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.09 | consumed tokens: 3083468800.0 | grad norm avg: 0.99 | grad norm last: 0.9 | 
2026-01-02T02:53:39 | step: 94200 | train samples/s: 254.6 | train mfu (16-bit): -1.0 | lr mean: 2.22338130697608e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.74 | consumed tokens: 3086745600.0 | grad norm avg: 1.0 | grad norm last: 1.12 | 
2026-01-02T02:54:08 | step: 94300 | train samples/s: 255.7 | train mfu (16-bit): -1.0 | lr mean: 2.2188647562870756e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.04 | consumed tokens: 3090022400.0 | grad norm avg: 1.01 | grad norm last: 0.97 | 
2026-01-02T02:54:37 | step: 94400 | train samples/s: 250.7 | train mfu (16-bit): -1.0 | lr mean: 2.2143489331938326e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.73 | consumed tokens: 3093299200.0 | grad norm avg: 1.0 | grad norm last: 1.01 | 
2026-01-02T02:55:06 | step: 94500 | train samples/s: 253.4 | train mfu (16-bit): -1.0 | lr mean: 2.2098342014942318e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.8 | consumed tokens: 3096576000.0 | grad norm avg: 0.99 | grad norm last: 0.99 | 
2026-01-02T02:55:35 | step: 94600 | train samples/s: 251.1 | train mfu (16-bit): -1.0 | lr mean: 2.2053203792893328e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.23 | consumed tokens: 3099852800.0 | grad norm avg: 1.0 | grad norm last: 1.07 | 
2026-01-02T02:56:04 | step: 94700 | train samples/s: 250.4 | train mfu (16-bit): -1.0 | lr mean: 2.2008074665791355e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.19 | consumed tokens: 3103129600.0 | grad norm avg: 1.01 | grad norm last: 1.02 | 
2026-01-02T02:56:33 | step: 94800 | train samples/s: 252.8 | train mfu (16-bit): -1.0 | lr mean: 2.1962956452625804e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.93 | consumed tokens: 3106406400.0 | grad norm avg: 0.99 | grad norm last: 1.04 | 
2026-01-02T02:57:01 | step: 94900 | train samples/s: 255.8 | train mfu (16-bit): -1.0 | lr mean: 2.1917849153396674e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.23 | consumed tokens: 3109683200.0 | grad norm avg: 1.01 | grad norm last: 0.87 | 
2026-01-02T02:57:30 | step: 95000 | train samples/s: 253.8 | train mfu (16-bit): -1.0 | lr mean: 2.187275094911456e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.42 | consumed tokens: 3112960000.0 | grad norm avg: 1.0 | grad norm last: 0.95 | 
2026-01-02T02:58:00 | step: 95100 | train samples/s: 254.6 | train mfu (16-bit): -1.0 | lr mean: 2.182766365876887e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.07 | consumed tokens: 3116236800.0 | grad norm avg: 1.01 | grad norm last: 0.96 | 
2026-01-02T02:58:30 | step: 95200 | train samples/s: 248.7 | train mfu (16-bit): -1.0 | lr mean: 2.1782585463370197e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.84 | consumed tokens: 3119513600.0 | grad norm avg: 1.0 | grad norm last: 1.0 | 
2026-01-02T02:58:59 | step: 95300 | train samples/s: 250.6 | train mfu (16-bit): -1.0 | lr mean: 2.1737520000897348e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.2 | consumed tokens: 3122790400.0 | grad norm avg: 1.03 | grad norm last: 1.07 | 
2026-01-02T02:59:28 | step: 95400 | train samples/s: 259.7 | train mfu (16-bit): -1.0 | lr mean: 2.169246545236092e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.39 | consumed tokens: 3126067200.0 | grad norm avg: 1.01 | grad norm last: 1.02 | 
2026-01-02T02:59:57 | step: 95500 | train samples/s: 254.5 | train mfu (16-bit): -1.0 | lr mean: 2.164741999877151e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.98 | consumed tokens: 3129344000.0 | grad norm avg: 1.03 | grad norm last: 1.12 | 
2026-01-02T03:00:25 | step: 95600 | train samples/s: 252.1 | train mfu (16-bit): -1.0 | lr mean: 2.1602387278107926e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.87 | consumed tokens: 3132620800.0 | grad norm avg: 1.02 | grad norm last: 1.01 | 
2026-01-02T03:00:54 | step: 95700 | train samples/s: 252.5 | train mfu (16-bit): -1.0 | lr mean: 2.1557365471380763e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.54 | consumed tokens: 3135897600.0 | grad norm avg: 1.01 | grad norm last: 0.96 | 
2026-01-02T03:01:23 | step: 95800 | train samples/s: 253.9 | train mfu (16-bit): -1.0 | lr mean: 2.1512356397579424e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.19 | consumed tokens: 3139174400.0 | grad norm avg: 1.02 | grad norm last: 1.22 | 
2026-01-02T03:01:52 | step: 95900 | train samples/s: 256.8 | train mfu (16-bit): -1.0 | lr mean: 2.1467358237714507e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.15 | consumed tokens: 3142451200.0 | grad norm avg: 1.01 | grad norm last: 1.07 | 
2026-01-02T03:02:21 | step: 96000 | train samples/s: 256.1 | train mfu (16-bit): -1.0 | lr mean: 2.142237099178601e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.13 | consumed tokens: 3145728000.0 | grad norm avg: 1.02 | grad norm last: 1.1 | 
2026-01-02T03:02:50 | step: 96100 | train samples/s: 259.7 | train mfu (16-bit): -1.0 | lr mean: 2.137739647878334e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.18 | consumed tokens: 3149004800.0 | grad norm avg: 1.03 | grad norm last: 0.99 | 
2026-01-02T03:03:18 | step: 96200 | train samples/s: 264.0 | train mfu (16-bit): -1.0 | lr mean: 2.133243287971709e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.18 | consumed tokens: 3152281600.0 | grad norm avg: 1.02 | grad norm last: 1.25 | 
2026-01-02T03:03:47 | step: 96300 | train samples/s: 265.0 | train mfu (16-bit): -1.0 | lr mean: 2.1287482013576664e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.91 | consumed tokens: 3155558400.0 | grad norm avg: 1.0 | grad norm last: 1.0 | 
2026-01-02T03:04:15 | step: 96400 | train samples/s: 265.1 | train mfu (16-bit): -1.0 | lr mean: 2.1242543880362064e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.05 | consumed tokens: 3158835200.0 | grad norm avg: 1.03 | grad norm last: 1.01 | 
2026-01-02T03:04:44 | step: 96500 | train samples/s: 261.7 | train mfu (16-bit): -1.0 | lr mean: 2.1197618480073288e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.18 | consumed tokens: 3162112000.0 | grad norm avg: 1.04 | grad norm last: 1.03 | 
2026-01-02T03:05:13 | step: 96600 | train samples/s: 265.7 | train mfu (16-bit): -1.0 | lr mean: 2.1152705812710337e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.8 | consumed tokens: 3165388800.0 | grad norm avg: 1.01 | grad norm last: 0.98 | 
2026-01-02T03:05:41 | step: 96700 | train samples/s: 264.9 | train mfu (16-bit): -1.0 | lr mean: 2.110780587827321e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.09 | consumed tokens: 3168665600.0 | grad norm avg: 1.03 | grad norm last: 1.17 | 
2026-01-02T03:06:10 | step: 96800 | train samples/s: 263.3 | train mfu (16-bit): -1.0 | lr mean: 2.106291867676191e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.93 | consumed tokens: 3171942400.0 | grad norm avg: 1.04 | grad norm last: 1.06 | 
2026-01-02T03:06:39 | step: 96900 | train samples/s: 256.6 | train mfu (16-bit): -1.0 | lr mean: 2.1018044208176434e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.0 | consumed tokens: 3175219200.0 | grad norm avg: 1.03 | grad norm last: 1.13 | 
2026-01-02T03:07:07 | step: 97000 | train samples/s: 264.0 | train mfu (16-bit): -1.0 | lr mean: 2.0973184291506186e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.34 | consumed tokens: 3178496000.0 | grad norm avg: 1.05 | grad norm last: 1.04 | 
2026-01-02T03:07:36 | step: 97100 | train samples/s: 258.6 | train mfu (16-bit): -1.0 | lr mean: 2.0928337107761763e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.98 | consumed tokens: 3181772800.0 | grad norm avg: 1.03 | grad norm last: 0.97 | 
2026-01-02T03:08:04 | step: 97200 | train samples/s: 255.0 | train mfu (16-bit): -1.0 | lr mean: 2.0883502656943165e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.41 | consumed tokens: 3185049600.0 | grad norm avg: 1.03 | grad norm last: 1.08 | 
2026-01-02T03:08:33 | step: 97300 | train samples/s: 255.5 | train mfu (16-bit): -1.0 | lr mean: 2.0838682758039795e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.86 | consumed tokens: 3188326400.0 | grad norm avg: 1.04 | grad norm last: 1.15 | 
2026-01-02T03:09:01 | step: 97400 | train samples/s: 259.4 | train mfu (16-bit): -1.0 | lr mean: 2.0793877411051653e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.27 | consumed tokens: 3191603200.0 | grad norm avg: 1.02 | grad norm last: 1.01 | 
2026-01-02T03:09:30 | step: 97500 | train samples/s: 258.8 | train mfu (16-bit): -1.0 | lr mean: 2.0749084796989337e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.27 | consumed tokens: 3194880000.0 | grad norm avg: 1.03 | grad norm last: 1.07 | 
2026-01-02T03:09:58 | step: 97600 | train samples/s: 265.7 | train mfu (16-bit): -1.0 | lr mean: 2.0704306734842248e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.88 | consumed tokens: 3198156800.0 | grad norm avg: 1.03 | grad norm last: 1.0 | 
2026-01-02T03:10:27 | step: 97700 | train samples/s: 264.7 | train mfu (16-bit): -1.0 | lr mean: 2.0659543224610388e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.76 | consumed tokens: 3201433600.0 | grad norm avg: 1.03 | grad norm last: 1.0 | 
2026-01-02T03:10:55 | step: 97800 | train samples/s: 264.4 | train mfu (16-bit): -1.0 | lr mean: 2.0614794266293757e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.0 | consumed tokens: 3204710400.0 | grad norm avg: 1.02 | grad norm last: 0.96 | 
2026-01-02T03:11:24 | step: 97900 | train samples/s: 260.2 | train mfu (16-bit): -1.0 | lr mean: 2.0570059859892353e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.11 | consumed tokens: 3207987200.0 | grad norm avg: 1.02 | grad norm last: 0.99 | 
2026-01-02T03:11:53 | step: 98000 | train samples/s: 263.3 | train mfu (16-bit): -1.0 | lr mean: 2.052534000540618e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.56 | consumed tokens: 3211264000.0 | grad norm avg: 1.04 | grad norm last: 0.93 | 
2026-01-02T03:12:21 | step: 98100 | train samples/s: 265.8 | train mfu (16-bit): -1.0 | lr mean: 2.0480634702835232e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.98 | consumed tokens: 3214540800.0 | grad norm avg: 1.04 | grad norm last: 1.22 | 
2026-01-02T03:12:50 | step: 98200 | train samples/s: 270.8 | train mfu (16-bit): -1.0 | lr mean: 2.0435945771168917e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.86 | consumed tokens: 3217817600.0 | grad norm avg: 1.03 | grad norm last: 0.93 | 
2026-01-02T03:13:18 | step: 98300 | train samples/s: 270.0 | train mfu (16-bit): -1.0 | lr mean: 2.039127139141783e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.55 | consumed tokens: 3221094400.0 | grad norm avg: 1.06 | grad norm last: 1.07 | 
2026-01-02T03:13:46 | step: 98400 | train samples/s: 271.2 | train mfu (16-bit): -1.0 | lr mean: 2.0346611563581973e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.16 | consumed tokens: 3224371200.0 | grad norm avg: 1.05 | grad norm last: 0.98 | 
2026-01-02T03:14:15 | step: 98500 | train samples/s: 270.6 | train mfu (16-bit): -1.0 | lr mean: 2.0301968106650747e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.81 | consumed tokens: 3227648000.0 | grad norm avg: 1.04 | grad norm last: 1.0 | 
2026-01-02T03:14:44 | step: 98600 | train samples/s: 263.7 | train mfu (16-bit): -1.0 | lr mean: 2.025733920163475e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.11 | consumed tokens: 3230924800.0 | grad norm avg: 1.04 | grad norm last: 1.02 | 
2026-01-02T03:15:12 | step: 98700 | train samples/s: 268.5 | train mfu (16-bit): -1.0 | lr mean: 2.0212726667523384e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.12 | consumed tokens: 3234201600.0 | grad norm avg: 1.04 | grad norm last: 1.04 | 
2026-01-02T03:15:41 | step: 98800 | train samples/s: 266.3 | train mfu (16-bit): -1.0 | lr mean: 2.016813050431665e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.11 | consumed tokens: 3237478400.0 | grad norm avg: 1.06 | grad norm last: 0.94 | 
2026-01-02T03:16:09 | step: 98900 | train samples/s: 271.7 | train mfu (16-bit): -1.0 | lr mean: 2.012355071201455e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.25 | consumed tokens: 3240755200.0 | grad norm avg: 1.05 | grad norm last: 1.15 | 
2026-01-02T03:16:38 | step: 99000 | train samples/s: 270.4 | train mfu (16-bit): -1.0 | lr mean: 2.0078985471627675e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.11 | train loss last: 3.32 | consumed tokens: 3244032000.0 | grad norm avg: 1.04 | grad norm last: 0.93 | 
2026-01-02T03:17:06 | step: 99100 | train samples/s: 270.2 | train mfu (16-bit): -1.0 | lr mean: 2.0034438421134837e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.03 | consumed tokens: 3247308800.0 | grad norm avg: 1.04 | grad norm last: 1.0 | 
2026-01-02T03:17:34 | step: 99200 | train samples/s: 272.2 | train mfu (16-bit): -1.0 | lr mean: 1.998990774154663e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.32 | consumed tokens: 3250585600.0 | grad norm avg: 1.06 | grad norm last: 1.11 | 
2026-01-02T03:18:04 | step: 99300 | train samples/s: 260.4 | train mfu (16-bit): -1.0 | lr mean: 1.9945393432863057e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.05 | consumed tokens: 3253862400.0 | grad norm avg: 1.03 | grad norm last: 1.06 | 
2026-01-02T03:18:32 | step: 99400 | train samples/s: 270.2 | train mfu (16-bit): -1.0 | lr mean: 1.9900895495084114e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.05 | consumed tokens: 3257139200.0 | grad norm avg: 1.04 | grad norm last: 0.98 | 
2026-01-02T03:19:01 | step: 99500 | train samples/s: 263.9 | train mfu (16-bit): -1.0 | lr mean: 1.9856413928209804e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.36 | consumed tokens: 3260416000.0 | grad norm avg: 1.06 | grad norm last: 0.97 | 
2026-01-02T03:19:30 | step: 99600 | train samples/s: 267.0 | train mfu (16-bit): -1.0 | lr mean: 1.981195055122953e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.0 | consumed tokens: 3263692800.0 | grad norm avg: 1.05 | grad norm last: 1.03 | 
2026-01-02T03:19:58 | step: 99700 | train samples/s: 267.3 | train mfu (16-bit): -1.0 | lr mean: 1.976750536414329e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.16 | consumed tokens: 3266969600.0 | grad norm avg: 1.05 | grad norm last: 0.98 | 
2026-01-02T03:20:26 | step: 99800 | train samples/s: 271.8 | train mfu (16-bit): -1.0 | lr mean: 1.9723076547961682e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.48 | consumed tokens: 3270246400.0 | grad norm avg: 1.06 | grad norm last: 1.12 | 
2026-01-02T03:20:55 | step: 99900 | train samples/s: 269.6 | train mfu (16-bit): -1.0 | lr mean: 1.9678664102684706e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.13 | consumed tokens: 3273523200.0 | grad norm avg: 1.07 | grad norm last: 1.01 | 
2026-01-02T03:21:23 | step: 100000 | train samples/s: 269.2 | train mfu (16-bit): -1.0 | lr mean: 1.963427166629117e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.68 | consumed tokens: 3276800000.0 | grad norm avg: 1.06 | grad norm last: 1.16 | 
2026-01-02T03:21:53 | step: 100100 | train samples/s: 270.9 | train mfu (16-bit): -1.0 | lr mean: 1.9589895600802265e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.77 | consumed tokens: 3280076800.0 | grad norm avg: 1.06 | grad norm last: 0.97 | 
2026-01-02T03:22:22 | step: 100200 | train samples/s: 268.7 | train mfu (16-bit): -1.0 | lr mean: 1.9545537725207396e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.57 | consumed tokens: 3283353600.0 | grad norm avg: 1.05 | grad norm last: 1.08 | 
2026-01-02T03:22:50 | step: 100300 | train samples/s: 268.3 | train mfu (16-bit): -1.0 | lr mean: 1.9501198039506562e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.17 | consumed tokens: 3286630400.0 | grad norm avg: 1.05 | grad norm last: 1.02 | 
2026-01-02T03:23:19 | step: 100400 | train samples/s: 268.8 | train mfu (16-bit): -1.0 | lr mean: 1.9456876543699764e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.23 | consumed tokens: 3289907200.0 | grad norm avg: 1.06 | grad norm last: 1.04 | 
2026-01-02T03:23:47 | step: 100500 | train samples/s: 265.6 | train mfu (16-bit): -1.0 | lr mean: 1.9412573237787e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.11 | consumed tokens: 3293184000.0 | grad norm avg: 1.06 | grad norm last: 1.0 | 
2026-01-02T03:24:16 | step: 100600 | train samples/s: 268.5 | train mfu (16-bit): -1.0 | lr mean: 1.9368289940757677e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.01 | consumed tokens: 3296460800.0 | grad norm avg: 1.06 | grad norm last: 1.02 | 
2026-01-02T03:24:44 | step: 100700 | train samples/s: 272.2 | train mfu (16-bit): -1.0 | lr mean: 1.9324023014632985e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.13 | consumed tokens: 3299737600.0 | grad norm avg: 1.05 | grad norm last: 1.02 | 
2026-01-02T03:25:13 | step: 100800 | train samples/s: 269.4 | train mfu (16-bit): -1.0 | lr mean: 1.9279777916381136e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.92 | consumed tokens: 3303014400.0 | grad norm avg: 1.1 | grad norm last: 1.14 | 
2026-01-02T03:25:41 | step: 100900 | train samples/s: 269.3 | train mfu (16-bit): -1.0 | lr mean: 1.9235549189033918e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.04 | consumed tokens: 3306291200.0 | grad norm avg: 1.08 | grad norm last: 1.1 | 
2026-01-02T03:26:09 | step: 101000 | train samples/s: 271.5 | train mfu (16-bit): -1.0 | lr mean: 1.919134047057014e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.08 | consumed tokens: 3309568000.0 | grad norm avg: 1.07 | grad norm last: 1.13 | 
2026-01-02T03:26:38 | step: 101100 | train samples/s: 269.0 | train mfu (16-bit): -1.0 | lr mean: 1.91471517609898e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.94 | consumed tokens: 3312844800.0 | grad norm avg: 1.09 | grad norm last: 1.16 | 
2026-01-02T03:27:06 | step: 101200 | train samples/s: 266.9 | train mfu (16-bit): -1.0 | lr mean: 1.91029830602929e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.04 | consumed tokens: 3316121600.0 | grad norm avg: 1.07 | grad norm last: 1.04 | 
2026-01-02T03:27:35 | step: 101300 | train samples/s: 265.8 | train mfu (16-bit): -1.0 | lr mean: 1.9058832549490035e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.81 | consumed tokens: 3319398400.0 | grad norm avg: 1.07 | grad norm last: 1.14 | 
2026-01-02T03:28:03 | step: 101400 | train samples/s: 271.3 | train mfu (16-bit): -1.0 | lr mean: 1.901470204757061e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.8 | consumed tokens: 3322675200.0 | grad norm avg: 1.09 | grad norm last: 0.98 | 
2026-01-02T03:28:32 | step: 101500 | train samples/s: 268.5 | train mfu (16-bit): -1.0 | lr mean: 1.897059155453462e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.33 | consumed tokens: 3325952000.0 | grad norm avg: 1.06 | grad norm last: 1.02 | 
2026-01-02T03:29:00 | step: 101600 | train samples/s: 268.4 | train mfu (16-bit): -1.0 | lr mean: 1.8926501070382074e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.73 | consumed tokens: 3329228800.0 | grad norm avg: 1.09 | grad norm last: 1.04 | 
2026-01-02T03:29:28 | step: 101700 | train samples/s: 272.6 | train mfu (16-bit): -1.0 | lr mean: 1.8882430595112965e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.26 | consumed tokens: 3332505600.0 | grad norm avg: 1.09 | grad norm last: 1.01 | 
2026-01-02T03:29:57 | step: 101800 | train samples/s: 270.9 | train mfu (16-bit): -1.0 | lr mean: 1.8838381947716698e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.9 | consumed tokens: 3335782400.0 | grad norm avg: 1.09 | grad norm last: 1.04 | 
2026-01-02T03:30:25 | step: 101900 | train samples/s: 266.2 | train mfu (16-bit): -1.0 | lr mean: 1.879435330920387e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.3 | consumed tokens: 3339059200.0 | grad norm avg: 1.1 | grad norm last: 1.17 | 
2026-01-02T03:30:54 | step: 102000 | train samples/s: 265.4 | train mfu (16-bit): -1.0 | lr mean: 1.8750344679574482e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.01 | consumed tokens: 3342336000.0 | grad norm avg: 1.11 | grad norm last: 1.12 | 
2026-01-02T03:31:22 | step: 102100 | train samples/s: 271.7 | train mfu (16-bit): -1.0 | lr mean: 1.8706356058828533e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.11 | consumed tokens: 3345612800.0 | grad norm avg: 1.15 | grad norm last: 1.12 | 
2026-01-02T03:31:51 | step: 102200 | train samples/s: 270.5 | train mfu (16-bit): -1.0 | lr mean: 1.8662389265955426e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.1 | consumed tokens: 3348889600.0 | grad norm avg: 1.15 | grad norm last: 1.09 | 
2026-01-02T03:32:19 | step: 102300 | train samples/s: 269.2 | train mfu (16-bit): -1.0 | lr mean: 1.861844430095516e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.19 | consumed tokens: 3352166400.0 | grad norm avg: 1.11 | grad norm last: 1.25 | 
2026-01-02T03:32:47 | step: 102400 | train samples/s: 269.5 | train mfu (16-bit): -1.0 | lr mean: 1.8574519344838336e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.22 | consumed tokens: 3355443200.0 | grad norm avg: 1.13 | grad norm last: 1.4 | 
2026-01-02T03:33:15 | step: 102500 | train samples/s: 274.2 | train mfu (16-bit): -1.0 | lr mean: 1.8530616216594353e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.26 | consumed tokens: 3358720000.0 | grad norm avg: 1.16 | grad norm last: 1.32 | 
2026-01-02T03:33:44 | step: 102600 | train samples/s: 264.8 | train mfu (16-bit): -1.0 | lr mean: 1.848673309723381e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.96 | consumed tokens: 3361996800.0 | grad norm avg: 1.12 | grad norm last: 1.37 | 
2026-01-02T03:34:12 | step: 102700 | train samples/s: 267.0 | train mfu (16-bit): -1.0 | lr mean: 1.8442873624735512e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.83 | consumed tokens: 3365273600.0 | grad norm avg: 1.15 | grad norm last: 1.17 | 
2026-01-02T03:34:41 | step: 102800 | train samples/s: 271.5 | train mfu (16-bit): -1.0 | lr mean: 1.8399035980110057e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.2 | consumed tokens: 3368550400.0 | grad norm avg: 1.12 | grad norm last: 1.05 | 
2026-01-02T03:35:09 | step: 102900 | train samples/s: 269.6 | train mfu (16-bit): -1.0 | lr mean: 1.8355220163357444e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.92 | consumed tokens: 3371827200.0 | grad norm avg: 1.13 | grad norm last: 1.06 | 
2026-01-02T03:35:37 | step: 103000 | train samples/s: 274.1 | train mfu (16-bit): -1.0 | lr mean: 1.831142435548827e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.05 | consumed tokens: 3375104000.0 | grad norm avg: 1.13 | grad norm last: 1.02 | 
2026-01-02T03:36:05 | step: 103100 | train samples/s: 276.8 | train mfu (16-bit): -1.0 | lr mean: 1.8267654013470747e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.88 | consumed tokens: 3378380800.0 | grad norm avg: 1.14 | grad norm last: 1.04 | 
2026-01-02T03:36:33 | step: 103200 | train samples/s: 273.6 | train mfu (16-bit): -1.0 | lr mean: 1.822390368033666e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.06 | consumed tokens: 3381657600.0 | grad norm avg: 1.15 | grad norm last: 1.1 | 
2026-01-02T03:37:01 | step: 103300 | train samples/s: 279.4 | train mfu (16-bit): -1.0 | lr mean: 1.8180176994064823e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.96 | consumed tokens: 3384934400.0 | grad norm avg: 1.1 | grad norm last: 1.19 | 
2026-01-02T03:37:29 | step: 103400 | train samples/s: 271.8 | train mfu (16-bit): -1.0 | lr mean: 1.8136472135665826e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.66 | consumed tokens: 3388211200.0 | grad norm avg: 1.15 | grad norm last: 1.05 | 
2026-01-02T03:37:58 | step: 103500 | train samples/s: 273.3 | train mfu (16-bit): -1.0 | lr mean: 1.8092790924129076e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.0 | consumed tokens: 3391488000.0 | grad norm avg: 1.1 | grad norm last: 1.26 | 
2026-01-02T03:38:26 | step: 103600 | train samples/s: 275.2 | train mfu (16-bit): -1.0 | lr mean: 1.804913154046517e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.04 | consumed tokens: 3394764800.0 | grad norm avg: 1.14 | grad norm last: 1.19 | 
2026-01-02T03:38:54 | step: 103700 | train samples/s: 274.3 | train mfu (16-bit): -1.0 | lr mean: 1.8005495803663507e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.03 | consumed tokens: 3398041600.0 | grad norm avg: 1.15 | grad norm last: 0.98 | 
2026-01-02T03:39:22 | step: 103800 | train samples/s: 278.2 | train mfu (16-bit): -1.0 | lr mean: 1.796188371372409e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.17 | consumed tokens: 3401318400.0 | grad norm avg: 1.13 | grad norm last: 1.43 | 
2026-01-02T03:39:50 | step: 103900 | train samples/s: 274.9 | train mfu (16-bit): -1.0 | lr mean: 1.7918295270646922e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.19 | consumed tokens: 3404595200.0 | grad norm avg: 1.13 | grad norm last: 1.02 | 
2026-01-02T03:40:18 | step: 104000 | train samples/s: 275.4 | train mfu (16-bit): -1.0 | lr mean: 1.7874730474432e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.05 | consumed tokens: 3407872000.0 | grad norm avg: 1.16 | grad norm last: 1.15 | 
2026-01-02T03:40:46 | step: 104100 | train samples/s: 279.2 | train mfu (16-bit): -1.0 | lr mean: 1.7831189325079322e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.88 | consumed tokens: 3411148800.0 | grad norm avg: 1.13 | grad norm last: 1.07 | 
2026-01-02T03:41:14 | step: 104200 | train samples/s: 272.8 | train mfu (16-bit): -1.0 | lr mean: 1.778767182258889e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.03 | consumed tokens: 3414425600.0 | grad norm avg: 1.14 | grad norm last: 1.02 | 
2026-01-02T03:41:42 | step: 104300 | train samples/s: 272.6 | train mfu (16-bit): -1.0 | lr mean: 1.7744177966960706e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.1 | consumed tokens: 3417702400.0 | grad norm avg: 1.19 | grad norm last: 1.18 | 
2026-01-02T03:42:10 | step: 104400 | train samples/s: 277.1 | train mfu (16-bit): -1.0 | lr mean: 1.7700707758194767e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.23 | consumed tokens: 3420979200.0 | grad norm avg: 1.14 | grad norm last: 1.23 | 
2026-01-02T03:42:38 | step: 104500 | train samples/s: 272.6 | train mfu (16-bit): -1.0 | lr mean: 1.7657263015280478e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.95 | consumed tokens: 3424256000.0 | grad norm avg: 1.13 | grad norm last: 1.03 | 
2026-01-02T03:43:06 | step: 104600 | train samples/s: 278.6 | train mfu (16-bit): -1.0 | lr mean: 1.7613841919228435e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.48 | consumed tokens: 3427532800.0 | grad norm avg: 1.18 | grad norm last: 1.19 | 
2026-01-02T03:43:34 | step: 104700 | train samples/s: 274.7 | train mfu (16-bit): -1.0 | lr mean: 1.7570444470038638e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.18 | consumed tokens: 3430809600.0 | grad norm avg: 1.15 | grad norm last: 1.07 | 
2026-01-02T03:44:02 | step: 104800 | train samples/s: 277.5 | train mfu (16-bit): -1.0 | lr mean: 1.752707248670049e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.27 | consumed tokens: 3434086400.0 | grad norm avg: 1.19 | grad norm last: 1.11 | 
2026-01-02T03:44:30 | step: 104900 | train samples/s: 276.3 | train mfu (16-bit): -1.0 | lr mean: 1.7483725969213992e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.13 | consumed tokens: 3437363200.0 | grad norm avg: 1.17 | grad norm last: 1.07 | 
2026-01-02T03:44:58 | step: 105000 | train samples/s: 274.4 | train mfu (16-bit): -1.0 | lr mean: 1.7440404917579144e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.83 | consumed tokens: 3440640000.0 | grad norm avg: 1.13 | grad norm last: 1.08 | 
2026-01-02T03:45:28 | step: 105100 | train samples/s: 276.4 | train mfu (16-bit): -1.0 | lr mean: 1.7397107512806542e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.03 | consumed tokens: 3443916800.0 | grad norm avg: 1.16 | grad norm last: 1.08 | 
2026-01-02T03:45:56 | step: 105200 | train samples/s: 274.0 | train mfu (16-bit): -1.0 | lr mean: 1.735383557388559e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.07 | consumed tokens: 3447193600.0 | grad norm avg: 1.15 | grad norm last: 1.09 | 
2026-01-02T03:46:25 | step: 105300 | train samples/s: 274.6 | train mfu (16-bit): -1.0 | lr mean: 1.7310589100816287e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.38 | consumed tokens: 3450470400.0 | grad norm avg: 1.16 | grad norm last: 1.19 | 
2026-01-02T03:46:53 | step: 105400 | train samples/s: 275.1 | train mfu (16-bit): -1.0 | lr mean: 1.7267369912588038e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.32 | consumed tokens: 3453747200.0 | grad norm avg: 1.18 | grad norm last: 1.23 | 
2026-01-02T03:47:21 | step: 105500 | train samples/s: 275.6 | train mfu (16-bit): -1.0 | lr mean: 1.7224174371222034e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.43 | consumed tokens: 3457024000.0 | grad norm avg: 1.19 | grad norm last: 1.06 | 
2026-01-02T03:47:49 | step: 105600 | train samples/s: 274.6 | train mfu (16-bit): -1.0 | lr mean: 1.7181006114697084e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.96 | consumed tokens: 3460300800.0 | grad norm avg: 1.17 | grad norm last: 1.01 | 
2026-01-02T03:48:17 | step: 105700 | train samples/s: 278.1 | train mfu (16-bit): -1.0 | lr mean: 1.713786150503438e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.8 | consumed tokens: 3463577600.0 | grad norm avg: 1.17 | grad norm last: 1.18 | 
2026-01-02T03:48:45 | step: 105800 | train samples/s: 272.1 | train mfu (16-bit): -1.0 | lr mean: 1.7094745999202132e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.3 | consumed tokens: 3466854400.0 | grad norm avg: 1.19 | grad norm last: 1.14 | 
2026-01-02T03:49:13 | step: 105900 | train samples/s: 275.5 | train mfu (16-bit): -1.0 | lr mean: 1.705165414023213e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.22 | consumed tokens: 3470131200.0 | grad norm avg: 1.19 | grad norm last: 1.24 | 
2026-01-02T03:49:41 | step: 106000 | train samples/s: 277.9 | train mfu (16-bit): -1.0 | lr mean: 1.7008589566103183e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.23 | consumed tokens: 3473408000.0 | grad norm avg: 1.18 | grad norm last: 1.23 | 
2026-01-02T03:50:09 | step: 106100 | train samples/s: 272.3 | train mfu (16-bit): -1.0 | lr mean: 1.6965552276815288e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.03 | consumed tokens: 3476684800.0 | grad norm avg: 1.22 | grad norm last: 1.23 | 
2026-01-02T03:50:37 | step: 106200 | train samples/s: 278.9 | train mfu (16-bit): -1.0 | lr mean: 1.6922542272368446e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.98 | consumed tokens: 3479961600.0 | grad norm avg: 1.17 | grad norm last: 1.13 | 
2026-01-02T03:51:05 | step: 106300 | train samples/s: 275.0 | train mfu (16-bit): -1.0 | lr mean: 1.6879557733773254e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.0 | consumed tokens: 3483238400.0 | grad norm avg: 1.21 | grad norm last: 1.09 | 
2026-01-02T03:51:33 | step: 106400 | train samples/s: 279.9 | train mfu (16-bit): -1.0 | lr mean: 1.6836600480019115e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.82 | consumed tokens: 3486515200.0 | grad norm avg: 1.17 | grad norm last: 1.13 | 
2026-01-02T03:52:01 | step: 106500 | train samples/s: 277.9 | train mfu (16-bit): -1.0 | lr mean: 1.679367051110603e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.79 | consumed tokens: 3489792000.0 | grad norm avg: 1.19 | grad norm last: 1.35 | 
2026-01-02T03:52:29 | step: 106600 | train samples/s: 278.0 | train mfu (16-bit): -1.0 | lr mean: 1.6750767827033997e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.18 | consumed tokens: 3493068800.0 | grad norm avg: 1.2 | grad norm last: 1.21 | 
2026-01-02T03:52:57 | step: 106700 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 1.6707892427803017e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.06 | consumed tokens: 3496345600.0 | grad norm avg: 1.18 | grad norm last: 1.25 | 
2026-01-02T03:53:25 | step: 106800 | train samples/s: 277.9 | train mfu (16-bit): -1.0 | lr mean: 1.666504431341309e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.12 | consumed tokens: 3499622400.0 | grad norm avg: 1.18 | grad norm last: 1.23 | 
2026-01-02T03:53:52 | step: 106900 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 1.6622223483864218e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.01 | consumed tokens: 3502899200.0 | grad norm avg: 1.21 | grad norm last: 1.11 | 
2026-01-02T03:54:20 | step: 107000 | train samples/s: 278.2 | train mfu (16-bit): -1.0 | lr mean: 1.6579431758145802e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.95 | consumed tokens: 3506176000.0 | grad norm avg: 1.17 | grad norm last: 1.45 | 
2026-01-02T03:54:48 | step: 107100 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 1.653666731726844e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.83 | consumed tokens: 3509452800.0 | grad norm avg: 1.2 | grad norm last: 1.17 | 
2026-01-02T03:55:16 | step: 107200 | train samples/s: 277.8 | train mfu (16-bit): -1.0 | lr mean: 1.6493931980221532e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.36 | consumed tokens: 3512729600.0 | grad norm avg: 1.15 | grad norm last: 1.09 | 
2026-01-02T03:55:44 | step: 107300 | train samples/s: 278.4 | train mfu (16-bit): -1.0 | lr mean: 1.645122392801568e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.15 | consumed tokens: 3516006400.0 | grad norm avg: 1.21 | grad norm last: 1.31 | 
2026-01-02T03:56:12 | step: 107400 | train samples/s: 278.0 | train mfu (16-bit): -1.0 | lr mean: 1.6408544979640283e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.18 | consumed tokens: 3519283200.0 | grad norm avg: 1.19 | grad norm last: 1.09 | 
2026-01-02T03:56:40 | step: 107500 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 1.636589331610594e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.29 | consumed tokens: 3522560000.0 | grad norm avg: 1.16 | grad norm last: 1.29 | 
2026-01-02T03:57:08 | step: 107600 | train samples/s: 278.0 | train mfu (16-bit): -1.0 | lr mean: 1.6323270756402053e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.06 | consumed tokens: 3525836800.0 | grad norm avg: 1.17 | grad norm last: 1.09 | 
2026-01-02T03:57:36 | step: 107700 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 1.6280677300528623e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.03 | consumed tokens: 3529113600.0 | grad norm avg: 1.16 | grad norm last: 1.07 | 
2026-01-02T03:58:03 | step: 107800 | train samples/s: 280.7 | train mfu (16-bit): -1.0 | lr mean: 1.623811294848565e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.91 | consumed tokens: 3532390400.0 | grad norm avg: 1.23 | grad norm last: 1.14 | 
2026-01-02T03:58:31 | step: 107900 | train samples/s: 278.2 | train mfu (16-bit): -1.0 | lr mean: 1.6195577700273134e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.18 | consumed tokens: 3535667200.0 | grad norm avg: 1.19 | grad norm last: 1.16 | 
2026-01-02T03:58:59 | step: 108000 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 1.6153071555891074e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.41 | consumed tokens: 3538944000.0 | grad norm avg: 1.23 | grad norm last: 1.12 | 
2026-01-02T03:59:27 | step: 108100 | train samples/s: 275.7 | train mfu (16-bit): -1.0 | lr mean: 1.611059451533947e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.11 | consumed tokens: 3542220800.0 | grad norm avg: 1.2 | grad norm last: 1.33 | 
2026-01-02T03:59:55 | step: 108200 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 1.6068146578618325e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.16 | consumed tokens: 3545497600.0 | grad norm avg: 1.21 | grad norm last: 1.14 | 
2026-01-02T04:00:23 | step: 108300 | train samples/s: 278.2 | train mfu (16-bit): -1.0 | lr mean: 1.602572956471704e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.25 | consumed tokens: 3548774400.0 | grad norm avg: 1.22 | grad norm last: 1.11 | 
2026-01-02T04:00:51 | step: 108400 | train samples/s: 280.7 | train mfu (16-bit): -1.0 | lr mean: 1.598334165464621e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.06 | consumed tokens: 3552051200.0 | grad norm avg: 1.19 | grad norm last: 1.04 | 
2026-01-02T04:01:19 | step: 108500 | train samples/s: 278.1 | train mfu (16-bit): -1.0 | lr mean: 1.594098466739524e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.43 | consumed tokens: 3555328000.0 | grad norm avg: 1.18 | grad norm last: 1.19 | 
2026-01-02T04:01:46 | step: 108600 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 1.589865678397473e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.89 | consumed tokens: 3558604800.0 | grad norm avg: 1.19 | grad norm last: 1.23 | 
2026-01-02T04:02:14 | step: 108700 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 1.5856359823374078e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.28 | consumed tokens: 3561881600.0 | grad norm avg: 1.24 | grad norm last: 1.16 | 
2026-01-02T04:02:42 | step: 108800 | train samples/s: 275.5 | train mfu (16-bit): -1.0 | lr mean: 1.5814091966603883e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.19 | consumed tokens: 3565158400.0 | grad norm avg: 1.22 | grad norm last: 1.14 | 
2026-01-02T04:03:10 | step: 108900 | train samples/s: 280.2 | train mfu (16-bit): -1.0 | lr mean: 1.5771855032653548e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.07 | consumed tokens: 3568435200.0 | grad norm avg: 1.19 | grad norm last: 1.46 | 
2026-01-02T04:03:38 | step: 109000 | train samples/s: 278.1 | train mfu (16-bit): -1.0 | lr mean: 1.5729649021523073e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.96 | consumed tokens: 3571712000.0 | grad norm avg: 1.17 | grad norm last: 1.19 | 
2026-01-02T04:04:06 | step: 109100 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 1.568747393321246e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.85 | consumed tokens: 3574988800.0 | grad norm avg: 1.21 | grad norm last: 1.31 | 
2026-01-02T04:04:34 | step: 109200 | train samples/s: 278.1 | train mfu (16-bit): -1.0 | lr mean: 1.5645329767721705e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.01 | consumed tokens: 3578265600.0 | grad norm avg: 1.21 | grad norm last: 1.08 | 
2026-01-02T04:05:02 | step: 109300 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 1.560321652505081e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.04 | consumed tokens: 3581542400.0 | grad norm avg: 1.24 | grad norm last: 1.28 | 
2026-01-02T04:05:29 | step: 109400 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 1.556113602418918e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.16 | consumed tokens: 3584819200.0 | grad norm avg: 1.17 | grad norm last: 1.24 | 
2026-01-02T04:05:57 | step: 109500 | train samples/s: 278.2 | train mfu (16-bit): -1.0 | lr mean: 1.551908462715801e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.12 | consumed tokens: 3588096000.0 | grad norm avg: 1.19 | grad norm last: 1.23 | 
2026-01-02T04:06:25 | step: 109600 | train samples/s: 278.2 | train mfu (16-bit): -1.0 | lr mean: 1.54770659719361e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.62 | consumed tokens: 3591372800.0 | grad norm avg: 1.21 | grad norm last: 1.33 | 
2026-01-02T04:06:53 | step: 109700 | train samples/s: 278.0 | train mfu (16-bit): -1.0 | lr mean: 1.543507823953405e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.24 | consumed tokens: 3594649600.0 | grad norm avg: 1.21 | grad norm last: 1.1 | 
2026-01-02T04:07:21 | step: 109800 | train samples/s: 280.2 | train mfu (16-bit): -1.0 | lr mean: 1.5393123248941265e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.07 | consumed tokens: 3597926400.0 | grad norm avg: 1.17 | grad norm last: 1.07 | 
2026-01-02T04:07:49 | step: 109900 | train samples/s: 277.5 | train mfu (16-bit): -1.0 | lr mean: 1.535119918116834e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.11 | consumed tokens: 3601203200.0 | grad norm avg: 1.19 | grad norm last: 1.1 | 
2026-01-02T04:08:17 | step: 110000 | train samples/s: 280.2 | train mfu (16-bit): -1.0 | lr mean: 1.530930785520468e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.99 | consumed tokens: 3604480000.0 | grad norm avg: 1.2 | grad norm last: 1.22 | 
2026-01-02T04:08:46 | step: 110100 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 1.5267447452060878e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.98 | consumed tokens: 3607756800.0 | grad norm avg: 1.18 | grad norm last: 1.27 | 
2026-01-02T04:09:14 | step: 110200 | train samples/s: 278.0 | train mfu (16-bit): -1.0 | lr mean: 1.5225619790726341e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.2 | consumed tokens: 3611033600.0 | grad norm avg: 1.23 | grad norm last: 1.25 | 
2026-01-02T04:09:42 | step: 110300 | train samples/s: 278.9 | train mfu (16-bit): -1.0 | lr mean: 1.518382578069577e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.13 | consumed tokens: 3614310400.0 | grad norm avg: 1.2 | grad norm last: 1.09 | 
2026-01-02T04:10:10 | step: 110400 | train samples/s: 278.7 | train mfu (16-bit): -1.0 | lr mean: 1.514206360297976e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.52 | consumed tokens: 3617587200.0 | grad norm avg: 1.19 | grad norm last: 1.22 | 
2026-01-02T04:10:38 | step: 110500 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 1.5100334167073015e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.53 | consumed tokens: 3620864000.0 | grad norm avg: 1.21 | grad norm last: 1.13 | 
2026-01-02T04:11:05 | step: 110600 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 1.5058637472975533e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.07 | consumed tokens: 3624140800.0 | grad norm avg: 1.19 | grad norm last: 1.38 | 
2026-01-02T04:11:33 | step: 110700 | train samples/s: 281.8 | train mfu (16-bit): -1.0 | lr mean: 1.5016973520687316e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.61 | consumed tokens: 3627417600.0 | grad norm avg: 1.18 | grad norm last: 1.13 | 
2026-01-02T04:12:01 | step: 110800 | train samples/s: 278.6 | train mfu (16-bit): -1.0 | lr mean: 1.4975343219703063e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.98 | consumed tokens: 3630694400.0 | grad norm avg: 1.2 | grad norm last: 1.25 | 
2026-01-02T04:12:29 | step: 110900 | train samples/s: 281.3 | train mfu (16-bit): -1.0 | lr mean: 1.4933746570022777e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.03 | consumed tokens: 3633971200.0 | grad norm avg: 1.19 | grad norm last: 1.43 | 
2026-01-02T04:12:57 | step: 111000 | train samples/s: 279.0 | train mfu (16-bit): -1.0 | lr mean: 1.4892182662151754e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.79 | consumed tokens: 3637248000.0 | grad norm avg: 1.23 | grad norm last: 1.2 | 
2026-01-02T04:13:24 | step: 111100 | train samples/s: 279.1 | train mfu (16-bit): -1.0 | lr mean: 1.4850652405584697e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.0 | consumed tokens: 3640524800.0 | grad norm avg: 1.19 | grad norm last: 1.22 | 
2026-01-02T04:13:52 | step: 111200 | train samples/s: 279.0 | train mfu (16-bit): -1.0 | lr mean: 1.4809155800321605e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.18 | consumed tokens: 3643801600.0 | grad norm avg: 1.22 | grad norm last: 1.08 | 
2026-01-02T04:14:20 | step: 111300 | train samples/s: 281.6 | train mfu (16-bit): -1.0 | lr mean: 1.476769375585718e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.08 | consumed tokens: 3647078400.0 | grad norm avg: 1.23 | grad norm last: 1.15 | 
2026-01-02T04:14:48 | step: 111400 | train samples/s: 281.6 | train mfu (16-bit): -1.0 | lr mean: 1.4726265362696722e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.87 | consumed tokens: 3650355200.0 | grad norm avg: 1.23 | grad norm last: 1.13 | 
2026-01-02T04:15:16 | step: 111500 | train samples/s: 278.6 | train mfu (16-bit): -1.0 | lr mean: 1.4684870620840229e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.17 | consumed tokens: 3653632000.0 | grad norm avg: 1.23 | grad norm last: 1.17 | 
2026-01-02T04:15:43 | step: 111600 | train samples/s: 281.5 | train mfu (16-bit): -1.0 | lr mean: 1.4643510439782403e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.96 | consumed tokens: 3656908800.0 | grad norm avg: 1.2 | grad norm last: 1.13 | 
2026-01-02T04:16:11 | step: 111700 | train samples/s: 278.9 | train mfu (16-bit): -1.0 | lr mean: 1.4602184819523245e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.77 | consumed tokens: 3660185600.0 | grad norm avg: 1.19 | grad norm last: 1.1 | 
2026-01-02T04:16:39 | step: 111800 | train samples/s: 279.0 | train mfu (16-bit): -1.0 | lr mean: 1.4560893760062754e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.02 | consumed tokens: 3663462400.0 | grad norm avg: 1.18 | grad norm last: 1.26 | 
2026-01-02T04:17:07 | step: 111900 | train samples/s: 278.9 | train mfu (16-bit): -1.0 | lr mean: 1.451963726140093e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.73 | consumed tokens: 3666739200.0 | grad norm avg: 1.18 | grad norm last: 1.17 | 
2026-01-02T04:17:34 | step: 112000 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 1.4478415323537774e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.2 | consumed tokens: 3670016000.0 | grad norm avg: 1.19 | grad norm last: 1.05 | 
2026-01-02T04:18:02 | step: 112100 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 1.4437227946473286e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.22 | consumed tokens: 3673292800.0 | grad norm avg: 1.24 | grad norm last: 1.1 | 
2026-01-02T04:18:30 | step: 112200 | train samples/s: 278.6 | train mfu (16-bit): -1.0 | lr mean: 1.4396076039702166e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.2 | consumed tokens: 3676569600.0 | grad norm avg: 1.2 | grad norm last: 1.33 | 
2026-01-02T04:18:58 | step: 112300 | train samples/s: 281.2 | train mfu (16-bit): -1.0 | lr mean: 1.4354959603224415e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.21 | consumed tokens: 3679846400.0 | grad norm avg: 1.21 | grad norm last: 1.12 | 
2026-01-02T04:19:26 | step: 112400 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 1.4313878637040034e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.09 | consumed tokens: 3683123200.0 | grad norm avg: 1.23 | grad norm last: 1.03 | 
2026-01-02T04:19:54 | step: 112500 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 1.4272833141149022e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.13 | consumed tokens: 3686400000.0 | grad norm avg: 1.21 | grad norm last: 1.12 | 
2026-01-02T04:20:21 | step: 112600 | train samples/s: 279.0 | train mfu (16-bit): -1.0 | lr mean: 1.4231822206056677e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.21 | consumed tokens: 3689676800.0 | grad norm avg: 1.23 | grad norm last: 1.47 | 
2026-01-02T04:20:49 | step: 112700 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 1.4190848560247105e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.9 | consumed tokens: 3692953600.0 | grad norm avg: 1.25 | grad norm last: 1.19 | 
2026-01-02T04:21:17 | step: 112800 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 1.41499094752362e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.03 | consumed tokens: 3696230400.0 | grad norm avg: 1.2 | grad norm last: 1.12 | 
2026-01-02T04:21:45 | step: 112900 | train samples/s: 278.3 | train mfu (16-bit): -1.0 | lr mean: 1.4109006770013366e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.06 | consumed tokens: 3699507200.0 | grad norm avg: 1.17 | grad norm last: 1.11 | 
2026-01-02T04:22:12 | step: 113000 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 1.4068141354073305e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.09 | consumed tokens: 3702784000.0 | grad norm avg: 1.22 | grad norm last: 1.36 | 
2026-01-02T04:22:40 | step: 113100 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 1.402731049893191e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.5 | consumed tokens: 3706060800.0 | grad norm avg: 1.2 | grad norm last: 1.18 | 
2026-01-02T04:23:08 | step: 113200 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 1.398651693307329e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.29 | consumed tokens: 3709337600.0 | grad norm avg: 1.2 | grad norm last: 1.13 | 
2026-01-02T04:23:36 | step: 113300 | train samples/s: 278.9 | train mfu (16-bit): -1.0 | lr mean: 1.3945760656497441e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.89 | consumed tokens: 3712614400.0 | grad norm avg: 1.17 | grad norm last: 1.07 | 
2026-01-02T04:24:04 | step: 113400 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 1.3905039850214962e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.19 | consumed tokens: 3715891200.0 | grad norm avg: 1.19 | grad norm last: 1.26 | 
2026-01-02T04:24:32 | step: 113500 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 1.3864356333215255e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.0 | consumed tokens: 3719168000.0 | grad norm avg: 1.21 | grad norm last: 1.01 | 
2026-01-02T04:24:59 | step: 113600 | train samples/s: 277.9 | train mfu (16-bit): -1.0 | lr mean: 1.3823710105498321e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.35 | consumed tokens: 3722444800.0 | grad norm avg: 1.2 | grad norm last: 1.14 | 
2026-01-02T04:25:27 | step: 113700 | train samples/s: 277.8 | train mfu (16-bit): -1.0 | lr mean: 1.3783100257569458e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.21 | consumed tokens: 3725721600.0 | grad norm avg: 1.21 | grad norm last: 1.14 | 
2026-01-02T04:25:55 | step: 113800 | train samples/s: 278.6 | train mfu (16-bit): -1.0 | lr mean: 1.374252860841807e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.84 | consumed tokens: 3728998400.0 | grad norm avg: 1.18 | grad norm last: 1.3 | 
2026-01-02T04:26:23 | step: 113900 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 1.3701993339054752e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.67 | consumed tokens: 3732275200.0 | grad norm avg: 1.18 | grad norm last: 1.36 | 
2026-01-02T04:26:51 | step: 114000 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 1.3661496268468909e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.32 | consumed tokens: 3735552000.0 | grad norm avg: 1.2 | grad norm last: 1.17 | 
2026-01-02T04:27:19 | step: 114100 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 1.3621036487165838e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.19 | consumed tokens: 3738828800.0 | grad norm avg: 1.22 | grad norm last: 1.28 | 
2026-01-02T04:27:46 | step: 114200 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 1.3580614904640242e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.29 | consumed tokens: 3742105600.0 | grad norm avg: 1.23 | grad norm last: 1.16 | 
2026-01-02T04:28:14 | step: 114300 | train samples/s: 278.1 | train mfu (16-bit): -1.0 | lr mean: 1.3540230611397419e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.43 | consumed tokens: 3745382400.0 | grad norm avg: 1.19 | grad norm last: 1.1 | 
2026-01-02T04:28:42 | step: 114400 | train samples/s: 278.7 | train mfu (16-bit): -1.0 | lr mean: 1.3499885426426772e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.9 | consumed tokens: 3748659200.0 | grad norm avg: 1.21 | grad norm last: 1.19 | 
2026-01-02T04:29:10 | step: 114500 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 1.3459577530738898e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.39 | consumed tokens: 3751936000.0 | grad norm avg: 1.21 | grad norm last: 1.23 | 
2026-01-02T04:29:38 | step: 114600 | train samples/s: 281.4 | train mfu (16-bit): -1.0 | lr mean: 1.3419307833828498e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.77 | consumed tokens: 3755212800.0 | grad norm avg: 1.24 | grad norm last: 1.21 | 
2026-01-02T04:30:05 | step: 114700 | train samples/s: 281.3 | train mfu (16-bit): -1.0 | lr mean: 1.3379077245190274e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.95 | consumed tokens: 3758489600.0 | grad norm avg: 1.19 | grad norm last: 1.2 | 
2026-01-02T04:30:33 | step: 114800 | train samples/s: 281.4 | train mfu (16-bit): -1.0 | lr mean: 1.3338884855329525e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.08 | consumed tokens: 3761766400.0 | grad norm avg: 1.21 | grad norm last: 1.46 | 
2026-01-02T04:31:01 | step: 114900 | train samples/s: 276.3 | train mfu (16-bit): -1.0 | lr mean: 1.329873066424625e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.18 | consumed tokens: 3765043200.0 | grad norm avg: 1.24 | grad norm last: 1.15 | 
2026-01-02T04:31:29 | step: 115000 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 1.3258615581435151e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.08 | consumed tokens: 3768320000.0 | grad norm avg: 1.23 | grad norm last: 1.16 | 
2026-01-02T04:31:58 | step: 115100 | train samples/s: 278.1 | train mfu (16-bit): -1.0 | lr mean: 1.3218540516390931e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.11 | consumed tokens: 3771596800.0 | grad norm avg: 1.24 | grad norm last: 1.12 | 
2026-01-02T04:32:27 | step: 115200 | train samples/s: 277.0 | train mfu (16-bit): -1.0 | lr mean: 1.3178503650124185e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.0 | consumed tokens: 3774873600.0 | grad norm avg: 1.21 | grad norm last: 1.15 | 
2026-01-02T04:32:54 | step: 115300 | train samples/s: 279.6 | train mfu (16-bit): -1.0 | lr mean: 1.3138505892129615e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.98 | consumed tokens: 3778150400.0 | grad norm avg: 1.18 | grad norm last: 1.25 | 
2026-01-02T04:33:22 | step: 115400 | train samples/s: 280.2 | train mfu (16-bit): -1.0 | lr mean: 1.3098548151901923e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.95 | consumed tokens: 3781427200.0 | grad norm avg: 1.2 | grad norm last: 1.09 | 
2026-01-02T04:33:50 | step: 115500 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 1.3058629519946408e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.1 | consumed tokens: 3784704000.0 | grad norm avg: 1.19 | grad norm last: 0.97 | 
2026-01-02T04:34:18 | step: 115600 | train samples/s: 275.5 | train mfu (16-bit): -1.0 | lr mean: 1.3018749996263068e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.95 | consumed tokens: 3787980800.0 | grad norm avg: 1.18 | grad norm last: 1.15 | 
2026-01-02T04:34:46 | step: 115700 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 1.2978911399841309e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.97 | consumed tokens: 3791257600.0 | grad norm avg: 1.23 | grad norm last: 1.14 | 
2026-01-02T04:35:14 | step: 115800 | train samples/s: 275.6 | train mfu (16-bit): -1.0 | lr mean: 1.2939111911691725e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.78 | consumed tokens: 3794534400.0 | grad norm avg: 1.17 | grad norm last: 1.16 | 
2026-01-02T04:35:42 | step: 115900 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 1.289935244130902e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.05 | train loss last: 3.1 | consumed tokens: 3797811200.0 | grad norm avg: 1.21 | grad norm last: 1.31 | 
2026-01-02T04:36:10 | step: 116000 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 1.2859632988693193e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.96 | consumed tokens: 3801088000.0 | grad norm avg: 1.17 | grad norm last: 1.13 | 
2026-01-02T04:36:37 | step: 116100 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 1.2819954463338945e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.11 | consumed tokens: 3804364800.0 | grad norm avg: 1.2 | grad norm last: 1.41 | 
2026-01-02T04:37:05 | step: 116200 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 1.2780315955751576e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.14 | consumed tokens: 3807641600.0 | grad norm avg: 1.22 | grad norm last: 1.18 | 
2026-01-02T04:37:33 | step: 116300 | train samples/s: 277.8 | train mfu (16-bit): -1.0 | lr mean: 1.2740718375425786e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.02 | consumed tokens: 3810918400.0 | grad norm avg: 1.2 | grad norm last: 1.1 | 
2026-01-02T04:38:01 | step: 116400 | train samples/s: 276.2 | train mfu (16-bit): -1.0 | lr mean: 1.2701161722361576e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.22 | consumed tokens: 3814195200.0 | grad norm avg: 1.21 | grad norm last: 1.12 | 
2026-01-02T04:38:29 | step: 116500 | train samples/s: 277.9 | train mfu (16-bit): -1.0 | lr mean: 1.2661645087064244e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.81 | consumed tokens: 3817472000.0 | grad norm avg: 1.22 | grad norm last: 1.21 | 
2026-01-02T04:38:57 | step: 116600 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 1.2622169379028492e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.82 | consumed tokens: 3820748800.0 | grad norm avg: 1.22 | grad norm last: 1.18 | 
2026-01-02T04:39:25 | step: 116700 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 1.2582735507749021e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.09 | consumed tokens: 3824025600.0 | grad norm avg: 1.2 | grad norm last: 1.06 | 
2026-01-02T04:39:52 | step: 116800 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 1.254334256373113e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.0 | consumed tokens: 3827302400.0 | grad norm avg: 1.18 | grad norm last: 1.11 | 
2026-01-02T04:40:20 | step: 116900 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 1.250399054697482e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.06 | consumed tokens: 3830579200.0 | grad norm avg: 1.2 | grad norm last: 1.16 | 
2026-01-02T04:40:48 | step: 117000 | train samples/s: 278.2 | train mfu (16-bit): -1.0 | lr mean: 1.246468036697479e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.84 | consumed tokens: 3833856000.0 | grad norm avg: 1.21 | grad norm last: 1.17 | 
2026-01-02T04:41:16 | step: 117100 | train samples/s: 273.6 | train mfu (16-bit): -1.0 | lr mean: 1.2425412023731042e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.94 | consumed tokens: 3837132800.0 | grad norm avg: 1.24 | grad norm last: 1.25 | 
2026-01-02T04:41:44 | step: 117200 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 1.2386185517243575e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.11 | consumed tokens: 3840409600.0 | grad norm avg: 1.19 | grad norm last: 1.34 | 
2026-01-02T04:42:12 | step: 117300 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 1.2346999938017689e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.33 | consumed tokens: 3843686400.0 | grad norm avg: 1.19 | grad norm last: 1.1 | 
2026-01-02T04:42:40 | step: 117400 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 1.2307857105042785e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.18 | consumed tokens: 3846963200.0 | grad norm avg: 1.18 | grad norm last: 1.08 | 
2026-01-02T04:43:08 | step: 117500 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 1.2268756108824164e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.01 | consumed tokens: 3850240000.0 | grad norm avg: 1.18 | grad norm last: 1.11 | 
2026-01-02T04:43:35 | step: 117600 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 1.2229697858856525e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.05 | consumed tokens: 3853516800.0 | grad norm avg: 1.2 | grad norm last: 1.31 | 
2026-01-02T04:44:03 | step: 117700 | train samples/s: 278.2 | train mfu (16-bit): -1.0 | lr mean: 1.2190681445645168e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.89 | consumed tokens: 3856793600.0 | grad norm avg: 1.22 | grad norm last: 1.13 | 
2026-01-02T04:44:31 | step: 117800 | train samples/s: 276.8 | train mfu (16-bit): -1.0 | lr mean: 1.2151707778684795e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.05 | consumed tokens: 3860070400.0 | grad norm avg: 1.21 | grad norm last: 1.31 | 
2026-01-02T04:44:59 | step: 117900 | train samples/s: 279.0 | train mfu (16-bit): -1.0 | lr mean: 1.2112776857975405e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.94 | consumed tokens: 3863347200.0 | grad norm avg: 1.23 | grad norm last: 1.37 | 
2026-01-02T04:45:27 | step: 118000 | train samples/s: 281.4 | train mfu (16-bit): -1.0 | lr mean: 1.2073888683516998e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.2 | consumed tokens: 3866624000.0 | grad norm avg: 1.26 | grad norm last: 1.09 | 
2026-01-02T04:45:55 | step: 118100 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 1.2035043255309574e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.84 | consumed tokens: 3869900800.0 | grad norm avg: 1.22 | grad norm last: 1.17 | 
2026-01-02T04:46:22 | step: 118200 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 1.1996240573353134e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.14 | consumed tokens: 3873177600.0 | grad norm avg: 1.23 | grad norm last: 1.24 | 
2026-01-02T04:46:50 | step: 118300 | train samples/s: 278.2 | train mfu (16-bit): -1.0 | lr mean: 1.1957481547142379e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.09 | consumed tokens: 3876454400.0 | grad norm avg: 1.23 | grad norm last: 1.14 | 
2026-01-02T04:47:18 | step: 118400 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 1.1918765267182607e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.03 | consumed tokens: 3879731200.0 | grad norm avg: 1.21 | grad norm last: 1.16 | 
2026-01-02T04:47:46 | step: 118500 | train samples/s: 276.6 | train mfu (16-bit): -1.0 | lr mean: 1.188009264296852e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.18 | consumed tokens: 3883008000.0 | grad norm avg: 1.23 | grad norm last: 1.23 | 
2026-01-02T04:48:14 | step: 118600 | train samples/s: 278.5 | train mfu (16-bit): -1.0 | lr mean: 1.184146458399482e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.09 | consumed tokens: 3886284800.0 | grad norm avg: 1.23 | grad norm last: 1.13 | 
2026-01-02T04:48:42 | step: 118700 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 1.1802879271272104e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.05 | consumed tokens: 3889561600.0 | grad norm avg: 1.19 | grad norm last: 1.19 | 
2026-01-02T04:49:10 | step: 118800 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 1.1764337614295073e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.96 | consumed tokens: 3892838400.0 | grad norm avg: 1.21 | grad norm last: 1.22 | 
2026-01-02T04:49:38 | step: 118900 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 1.1725839613063727e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.16 | consumed tokens: 3896115200.0 | grad norm avg: 1.21 | grad norm last: 1.12 | 
2026-01-02T04:50:06 | step: 119000 | train samples/s: 278.2 | train mfu (16-bit): -1.0 | lr mean: 1.1687386177072767e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.41 | consumed tokens: 3899392000.0 | grad norm avg: 1.24 | grad norm last: 1.19 | 
2026-01-02T04:50:34 | step: 119100 | train samples/s: 276.8 | train mfu (16-bit): -1.0 | lr mean: 1.1648977306322195e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.15 | consumed tokens: 3902668800.0 | grad norm avg: 1.21 | grad norm last: 1.35 | 
2026-01-02T04:51:01 | step: 119200 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 1.1610612091317307e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.68 | consumed tokens: 3905945600.0 | grad norm avg: 1.24 | grad norm last: 1.13 | 
2026-01-02T04:51:29 | step: 119300 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 1.1572291441552807e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.45 | consumed tokens: 3909222400.0 | grad norm avg: 1.26 | grad norm last: 1.13 | 
2026-01-02T04:51:57 | step: 119400 | train samples/s: 278.6 | train mfu (16-bit): -1.0 | lr mean: 1.1534015357028693e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.21 | consumed tokens: 3912499200.0 | grad norm avg: 1.21 | grad norm last: 1.12 | 
2026-01-02T04:52:25 | step: 119500 | train samples/s: 280.7 | train mfu (16-bit): -1.0 | lr mean: 1.1495783837744966e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.07 | consumed tokens: 3915776000.0 | grad norm avg: 1.22 | grad norm last: 1.24 | 
2026-01-02T04:52:53 | step: 119600 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 1.1457597793196328e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.21 | consumed tokens: 3919052800.0 | grad norm avg: 1.22 | grad norm last: 1.2 | 
2026-01-02T04:53:21 | step: 119700 | train samples/s: 278.3 | train mfu (16-bit): -1.0 | lr mean: 1.1419456313888077e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.08 | consumed tokens: 3922329600.0 | grad norm avg: 1.23 | grad norm last: 1.17 | 
2026-01-02T04:53:49 | step: 119800 | train samples/s: 276.6 | train mfu (16-bit): -1.0 | lr mean: 1.1381359399820212e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.18 | consumed tokens: 3925606400.0 | grad norm avg: 1.23 | grad norm last: 1.13 | 
2026-01-02T04:54:16 | step: 119900 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 1.1343308869982138e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.34 | consumed tokens: 3928883200.0 | grad norm avg: 1.23 | grad norm last: 1.37 | 
2026-01-02T04:54:44 | step: 120000 | train samples/s: 280.7 | train mfu (16-bit): -1.0 | lr mean: 1.1305302905384451e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.98 | consumed tokens: 3932160000.0 | grad norm avg: 1.23 | grad norm last: 1.23 | 
2026-01-02T04:55:14 | step: 120100 | train samples/s: 279.1 | train mfu (16-bit): -1.0 | lr mean: 1.1267342415521853e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.1 | consumed tokens: 3935436800.0 | grad norm avg: 1.22 | grad norm last: 1.19 | 
2026-01-02T04:55:41 | step: 120200 | train samples/s: 281.4 | train mfu (16-bit): -1.0 | lr mean: 1.1229427400394343e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.16 | consumed tokens: 3938713600.0 | grad norm avg: 1.24 | grad norm last: 1.27 | 
2026-01-02T04:56:09 | step: 120300 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 1.1191557860001922e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.12 | consumed tokens: 3941990400.0 | grad norm avg: 1.21 | grad norm last: 1.27 | 
2026-01-02T04:56:37 | step: 120400 | train samples/s: 276.3 | train mfu (16-bit): -1.0 | lr mean: 1.1153734703839291e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.08 | consumed tokens: 3945267200.0 | grad norm avg: 1.23 | grad norm last: 1.3 | 
2026-01-02T04:57:05 | step: 120500 | train samples/s: 279.7 | train mfu (16-bit): -1.0 | lr mean: 1.1115957022411749e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.85 | consumed tokens: 3948544000.0 | grad norm avg: 1.22 | grad norm last: 1.14 | 
2026-01-02T04:57:33 | step: 120600 | train samples/s: 281.4 | train mfu (16-bit): -1.0 | lr mean: 1.1078225725213997e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.27 | consumed tokens: 3951820800.0 | grad norm avg: 1.21 | grad norm last: 1.29 | 
2026-01-02T04:58:00 | step: 120700 | train samples/s: 281.6 | train mfu (16-bit): -1.0 | lr mean: 1.1040540812246036e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.34 | consumed tokens: 3955097600.0 | grad norm avg: 1.24 | grad norm last: 1.28 | 
2026-01-02T04:58:28 | step: 120800 | train samples/s: 281.7 | train mfu (16-bit): -1.0 | lr mean: 1.1002901374013163e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.94 | consumed tokens: 3958374400.0 | grad norm avg: 1.24 | grad norm last: 1.14 | 
2026-01-02T04:58:56 | step: 120900 | train samples/s: 279.4 | train mfu (16-bit): -1.0 | lr mean: 1.0965309229504783e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.14 | consumed tokens: 3961651200.0 | grad norm avg: 1.21 | grad norm last: 1.15 | 
2026-01-02T04:59:24 | step: 121000 | train samples/s: 281.5 | train mfu (16-bit): -1.0 | lr mean: 1.0927763469226193e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.24 | consumed tokens: 3964928000.0 | grad norm avg: 1.21 | grad norm last: 1.1 | 
2026-01-02T04:59:52 | step: 121100 | train samples/s: 276.1 | train mfu (16-bit): -1.0 | lr mean: 1.0890264093177393e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.11 | consumed tokens: 3968204800.0 | grad norm avg: 1.22 | grad norm last: 1.13 | 
2026-01-02T05:00:20 | step: 121200 | train samples/s: 279.4 | train mfu (16-bit): -1.0 | lr mean: 1.0852812010853086e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.68 | consumed tokens: 3971481600.0 | grad norm avg: 1.23 | grad norm last: 1.26 | 
2026-01-02T05:00:47 | step: 121300 | train samples/s: 281.5 | train mfu (16-bit): -1.0 | lr mean: 1.0815406312758569e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.03 | consumed tokens: 3974758400.0 | grad norm avg: 1.26 | grad norm last: 1.12 | 
2026-01-02T05:01:15 | step: 121400 | train samples/s: 281.3 | train mfu (16-bit): -1.0 | lr mean: 1.0778048817883246e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.06 | consumed tokens: 3978035200.0 | grad norm avg: 1.24 | grad norm last: 1.29 | 
2026-01-02T05:01:43 | step: 121500 | train samples/s: 281.3 | train mfu (16-bit): -1.0 | lr mean: 1.0740737707237713e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.05 | consumed tokens: 3981312000.0 | grad norm avg: 1.22 | grad norm last: 1.18 | 
2026-01-02T05:02:10 | step: 121600 | train samples/s: 281.7 | train mfu (16-bit): -1.0 | lr mean: 1.0703473890316673e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.98 | consumed tokens: 3984588800.0 | grad norm avg: 1.25 | grad norm last: 1.21 | 
2026-01-02T05:02:39 | step: 121700 | train samples/s: 276.7 | train mfu (16-bit): -1.0 | lr mean: 1.0666257367120124e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.89 | consumed tokens: 3987865600.0 | grad norm avg: 1.24 | grad norm last: 1.3 | 
2026-01-02T05:03:06 | step: 121800 | train samples/s: 279.3 | train mfu (16-bit): -1.0 | lr mean: 1.0629088137648068e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.09 | consumed tokens: 3991142400.0 | grad norm avg: 1.27 | grad norm last: 1.34 | 
2026-01-02T05:03:34 | step: 121900 | train samples/s: 279.9 | train mfu (16-bit): -1.0 | lr mean: 1.0591967111395206e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.48 | consumed tokens: 3994419200.0 | grad norm avg: 1.27 | grad norm last: 1.39 | 
2026-01-02T05:04:02 | step: 122000 | train samples/s: 281.9 | train mfu (16-bit): -1.0 | lr mean: 1.0554894288361538e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.05 | consumed tokens: 3997696000.0 | grad norm avg: 1.25 | grad norm last: 1.12 | 
2026-01-02T05:04:30 | step: 122100 | train samples/s: 281.5 | train mfu (16-bit): -1.0 | lr mean: 1.0517868759052362e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.48 | consumed tokens: 4000972800.0 | grad norm avg: 1.22 | grad norm last: 1.23 | 
2026-01-02T05:04:57 | step: 122200 | train samples/s: 281.8 | train mfu (16-bit): -1.0 | lr mean: 1.048089143296238e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.78 | consumed tokens: 4004249600.0 | grad norm avg: 1.25 | grad norm last: 1.32 | 
2026-01-02T05:05:25 | step: 122300 | train samples/s: 281.9 | train mfu (16-bit): -1.0 | lr mean: 1.0443962310091592e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.08 | consumed tokens: 4007526400.0 | grad norm avg: 1.22 | grad norm last: 1.55 | 
2026-01-02T05:05:53 | step: 122400 | train samples/s: 276.9 | train mfu (16-bit): -1.0 | lr mean: 1.0407081390439998e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.02 | consumed tokens: 4010803200.0 | grad norm avg: 1.25 | grad norm last: 1.18 | 
2026-01-02T05:06:21 | step: 122500 | train samples/s: 277.6 | train mfu (16-bit): -1.0 | lr mean: 1.03702495835023e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.25 | consumed tokens: 4014080000.0 | grad norm avg: 1.25 | grad norm last: 1.33 | 
2026-01-02T05:06:49 | step: 122600 | train samples/s: 281.8 | train mfu (16-bit): -1.0 | lr mean: 1.0333465070289094e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.17 | consumed tokens: 4017356800.0 | grad norm avg: 1.24 | grad norm last: 1.39 | 
2026-01-02T05:07:16 | step: 122700 | train samples/s: 281.7 | train mfu (16-bit): -1.0 | lr mean: 1.0296730579284485e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.01 | consumed tokens: 4020633600.0 | grad norm avg: 1.24 | grad norm last: 1.08 | 
2026-01-02T05:07:44 | step: 122800 | train samples/s: 282.2 | train mfu (16-bit): -1.0 | lr mean: 1.026004429149907e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.17 | consumed tokens: 4023910400.0 | grad norm avg: 1.23 | grad norm last: 1.26 | 
2026-01-02T05:08:12 | step: 122900 | train samples/s: 281.8 | train mfu (16-bit): -1.0 | lr mean: 1.022340620693285e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.13 | consumed tokens: 4027187200.0 | grad norm avg: 1.21 | grad norm last: 1.23 | 
2026-01-02T05:08:39 | step: 123000 | train samples/s: 281.6 | train mfu (16-bit): -1.0 | lr mean: 1.0186818144575227e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.26 | consumed tokens: 4030464000.0 | grad norm avg: 1.22 | grad norm last: 1.26 | 
2026-01-02T05:09:07 | step: 123100 | train samples/s: 276.5 | train mfu (16-bit): -1.0 | lr mean: 1.01502791949315e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.91 | consumed tokens: 4033740800.0 | grad norm avg: 1.28 | grad norm last: 1.39 | 
2026-01-02T05:09:35 | step: 123200 | train samples/s: 277.6 | train mfu (16-bit): -1.0 | lr mean: 1.0113788448506966e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.29 | consumed tokens: 4037017600.0 | grad norm avg: 1.27 | grad norm last: 1.17 | 
2026-01-02T05:10:03 | step: 123300 | train samples/s: 281.4 | train mfu (16-bit): -1.0 | lr mean: 1.0077348633785732e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.29 | consumed tokens: 4040294400.0 | grad norm avg: 1.27 | grad norm last: 1.35 | 
2026-01-02T05:10:31 | step: 123400 | train samples/s: 281.5 | train mfu (16-bit): -1.0 | lr mean: 1.0040957022283692e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.98 | consumed tokens: 4043571200.0 | grad norm avg: 1.28 | grad norm last: 1.11 | 
2026-01-02T05:10:58 | step: 123500 | train samples/s: 281.7 | train mfu (16-bit): -1.0 | lr mean: 1.000461543299025e-05 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.08 | consumed tokens: 4046848000.0 | grad norm avg: 1.26 | grad norm last: 1.14 | 
2026-01-02T05:11:26 | step: 123600 | train samples/s: 281.6 | train mfu (16-bit): -1.0 | lr mean: 9.968323865905404e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.11 | consumed tokens: 4050124800.0 | grad norm avg: 1.27 | grad norm last: 1.18 | 
2026-01-02T05:11:54 | step: 123700 | train samples/s: 281.7 | train mfu (16-bit): -1.0 | lr mean: 9.932082321029156e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.17 | consumed tokens: 4053401600.0 | grad norm avg: 1.24 | grad norm last: 1.26 | 
2026-01-02T05:12:22 | step: 123800 | train samples/s: 276.8 | train mfu (16-bit): -1.0 | lr mean: 9.895890798361506e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.21 | consumed tokens: 4056678400.0 | grad norm avg: 1.28 | grad norm last: 1.59 | 
2026-01-02T05:12:50 | step: 123900 | train samples/s: 279.9 | train mfu (16-bit): -1.0 | lr mean: 9.859748388407752e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.98 | consumed tokens: 4059955200.0 | grad norm avg: 1.23 | grad norm last: 1.22 | 
2026-01-02T05:13:17 | step: 124000 | train samples/s: 279.5 | train mfu (16-bit): -1.0 | lr mean: 9.823656910157297e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.29 | consumed tokens: 4063232000.0 | grad norm avg: 1.28 | grad norm last: 1.53 | 
2026-01-02T05:13:45 | step: 124100 | train samples/s: 281.7 | train mfu (16-bit): -1.0 | lr mean: 9.787616363610141e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.97 | consumed tokens: 4066508800.0 | grad norm avg: 1.27 | grad norm last: 1.41 | 
2026-01-02T05:14:13 | step: 124200 | train samples/s: 282.0 | train mfu (16-bit): -1.0 | lr mean: 9.751625839271583e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.8 | consumed tokens: 4069785600.0 | grad norm avg: 1.27 | grad norm last: 1.18 | 
2026-01-02T05:14:40 | step: 124300 | train samples/s: 281.9 | train mfu (16-bit): -1.0 | lr mean: 9.715685337141622e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.29 | consumed tokens: 4073062400.0 | grad norm avg: 1.25 | grad norm last: 1.24 | 
2026-01-02T05:15:08 | step: 124400 | train samples/s: 279.3 | train mfu (16-bit): -1.0 | lr mean: 9.679796676209662e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.28 | consumed tokens: 4076339200.0 | grad norm avg: 1.23 | grad norm last: 1.21 | 
2026-01-02T05:15:36 | step: 124500 | train samples/s: 279.0 | train mfu (16-bit): -1.0 | lr mean: 9.6439580374863e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.23 | consumed tokens: 4079616000.0 | grad norm avg: 1.24 | grad norm last: 1.53 | 
2026-01-02T05:16:04 | step: 124600 | train samples/s: 280.2 | train mfu (16-bit): -1.0 | lr mean: 9.608170330466237e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.98 | consumed tokens: 4082892800.0 | grad norm avg: 1.23 | grad norm last: 1.19 | 
2026-01-02T05:16:32 | step: 124700 | train samples/s: 279.6 | train mfu (16-bit): -1.0 | lr mean: 9.572433555149473e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.05 | train loss last: 2.93 | consumed tokens: 4086169600.0 | grad norm avg: 1.26 | grad norm last: 1.13 | 
2026-01-02T05:16:59 | step: 124800 | train samples/s: 282.0 | train mfu (16-bit): -1.0 | lr mean: 9.53674862103071e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.18 | consumed tokens: 4089446400.0 | grad norm avg: 1.25 | grad norm last: 1.27 | 
2026-01-02T05:17:27 | step: 124900 | train samples/s: 281.8 | train mfu (16-bit): -1.0 | lr mean: 9.501114618615247e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.39 | consumed tokens: 4092723200.0 | grad norm avg: 1.25 | grad norm last: 1.28 | 
2026-01-02T05:17:55 | step: 125000 | train samples/s: 281.7 | train mfu (16-bit): -1.0 | lr mean: 9.465532457397785e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.13 | consumed tokens: 4096000000.0 | grad norm avg: 1.23 | grad norm last: 1.34 | 
2026-01-02T05:18:25 | step: 125100 | train samples/s: 275.6 | train mfu (16-bit): -1.0 | lr mean: 9.430001227883622e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.15 | consumed tokens: 4099276800.0 | grad norm avg: 1.29 | grad norm last: 1.33 | 
2026-01-02T05:18:52 | step: 125200 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 9.39452183956746e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.25 | consumed tokens: 4102553600.0 | grad norm avg: 1.29 | grad norm last: 1.54 | 
2026-01-02T05:19:20 | step: 125300 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 9.3590942924493e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.38 | consumed tokens: 4105830400.0 | grad norm avg: 1.3 | grad norm last: 1.31 | 
2026-01-02T05:19:48 | step: 125400 | train samples/s: 278.3 | train mfu (16-bit): -1.0 | lr mean: 9.32371858652914e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.74 | consumed tokens: 4109107200.0 | grad norm avg: 1.27 | grad norm last: 1.27 | 
2026-01-02T05:20:16 | step: 125500 | train samples/s: 280.7 | train mfu (16-bit): -1.0 | lr mean: 9.28839472180698e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.77 | consumed tokens: 4112384000.0 | grad norm avg: 1.24 | grad norm last: 1.23 | 
2026-01-02T05:20:44 | step: 125600 | train samples/s: 280.7 | train mfu (16-bit): -1.0 | lr mean: 9.253123607777525e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.35 | consumed tokens: 4115660800.0 | grad norm avg: 1.25 | grad norm last: 1.31 | 
2026-01-02T05:21:12 | step: 125700 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 9.21790433494607e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.11 | consumed tokens: 4118937600.0 | grad norm avg: 1.26 | grad norm last: 1.26 | 
2026-01-02T05:21:40 | step: 125800 | train samples/s: 275.4 | train mfu (16-bit): -1.0 | lr mean: 9.182736903312616e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.91 | consumed tokens: 4122214400.0 | grad norm avg: 1.28 | grad norm last: 1.09 | 
2026-01-02T05:22:08 | step: 125900 | train samples/s: 278.9 | train mfu (16-bit): -1.0 | lr mean: 9.147623131866567e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.5 | consumed tokens: 4125491200.0 | grad norm avg: 1.27 | grad norm last: 1.37 | 
2026-01-02T05:22:35 | step: 126000 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 9.112561201618519e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.0 | consumed tokens: 4128768000.0 | grad norm avg: 1.27 | grad norm last: 1.27 | 
2026-01-02T05:23:03 | step: 126100 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 9.077552022063173e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.13 | consumed tokens: 4132044800.0 | grad norm avg: 1.31 | grad norm last: 1.34 | 
2026-01-02T05:23:31 | step: 126200 | train samples/s: 278.1 | train mfu (16-bit): -1.0 | lr mean: 9.042595593200531e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.83 | consumed tokens: 4135321600.0 | grad norm avg: 1.25 | grad norm last: 1.3 | 
2026-01-02T05:23:59 | step: 126300 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 9.007691915030591e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.09 | consumed tokens: 4138598400.0 | grad norm avg: 1.29 | grad norm last: 1.29 | 
2026-01-02T05:24:27 | step: 126400 | train samples/s: 278.1 | train mfu (16-bit): -1.0 | lr mean: 8.972841897048056e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.21 | consumed tokens: 4141875200.0 | grad norm avg: 1.28 | grad norm last: 1.12 | 
2026-01-02T05:24:55 | step: 126500 | train samples/s: 278.0 | train mfu (16-bit): -1.0 | lr mean: 8.938044629758224e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.62 | consumed tokens: 4145152000.0 | grad norm avg: 1.29 | grad norm last: 1.16 | 
2026-01-02T05:25:23 | step: 126600 | train samples/s: 279.7 | train mfu (16-bit): -1.0 | lr mean: 8.903301022655796e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.04 | consumed tokens: 4148428800.0 | grad norm avg: 1.27 | grad norm last: 1.31 | 
2026-01-02T05:25:51 | step: 126700 | train samples/s: 281.2 | train mfu (16-bit): -1.0 | lr mean: 8.868611075740773e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.13 | consumed tokens: 4151705600.0 | grad norm avg: 1.32 | grad norm last: 1.28 | 
2026-01-02T05:26:18 | step: 126800 | train samples/s: 281.2 | train mfu (16-bit): -1.0 | lr mean: 8.833973879518453e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.14 | consumed tokens: 4154982400.0 | grad norm avg: 1.26 | grad norm last: 1.2 | 
2026-01-02T05:26:46 | step: 126900 | train samples/s: 279.0 | train mfu (16-bit): -1.0 | lr mean: 8.799390343483537e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.2 | consumed tokens: 4158259200.0 | grad norm avg: 1.26 | grad norm last: 1.27 | 
2026-01-02T05:27:14 | step: 127000 | train samples/s: 281.4 | train mfu (16-bit): -1.0 | lr mean: 8.764861377130728e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.07 | consumed tokens: 4161536000.0 | grad norm avg: 1.25 | grad norm last: 1.3 | 
2026-01-02T05:27:42 | step: 127100 | train samples/s: 278.5 | train mfu (16-bit): -1.0 | lr mean: 8.730385161470622e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.94 | consumed tokens: 4164812800.0 | grad norm avg: 1.25 | grad norm last: 1.3 | 
2026-01-02T05:28:10 | step: 127200 | train samples/s: 278.6 | train mfu (16-bit): -1.0 | lr mean: 8.695963515492622e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.83 | consumed tokens: 4168089600.0 | grad norm avg: 1.29 | grad norm last: 1.32 | 
2026-01-02T05:28:38 | step: 127300 | train samples/s: 279.3 | train mfu (16-bit): -1.0 | lr mean: 8.661596439196728e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.53 | consumed tokens: 4171366400.0 | grad norm avg: 1.26 | grad norm last: 1.52 | 
2026-01-02T05:29:05 | step: 127400 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 8.627283023088239e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.09 | consumed tokens: 4174643200.0 | grad norm avg: 1.27 | grad norm last: 1.3 | 
2026-01-02T05:29:33 | step: 127500 | train samples/s: 281.2 | train mfu (16-bit): -1.0 | lr mean: 8.593024176661856e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.25 | consumed tokens: 4177920000.0 | grad norm avg: 1.3 | grad norm last: 1.26 | 
2026-01-02T05:30:01 | step: 127600 | train samples/s: 281.3 | train mfu (16-bit): -1.0 | lr mean: 8.558818990422878e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.86 | consumed tokens: 4181196800.0 | grad norm avg: 1.29 | grad norm last: 1.29 | 
2026-01-02T05:30:29 | step: 127700 | train samples/s: 278.9 | train mfu (16-bit): -1.0 | lr mean: 8.524669283360709e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.08 | consumed tokens: 4184473600.0 | grad norm avg: 1.27 | grad norm last: 1.27 | 
2026-01-02T05:30:57 | step: 127800 | train samples/s: 278.7 | train mfu (16-bit): -1.0 | lr mean: 8.490573236485943e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.96 | consumed tokens: 4187750400.0 | grad norm avg: 1.29 | grad norm last: 1.2 | 
2026-01-02T05:31:25 | step: 127900 | train samples/s: 278.4 | train mfu (16-bit): -1.0 | lr mean: 8.456532668787986e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.17 | consumed tokens: 4191027200.0 | grad norm avg: 1.28 | grad norm last: 1.32 | 
2026-01-02T05:31:53 | step: 128000 | train samples/s: 279.4 | train mfu (16-bit): -1.0 | lr mean: 8.422547580266837e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.83 | consumed tokens: 4194304000.0 | grad norm avg: 1.28 | grad norm last: 1.2 | 
2026-01-02T05:32:20 | step: 128100 | train samples/s: 281.3 | train mfu (16-bit): -1.0 | lr mean: 8.388616151933093e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.12 | consumed tokens: 4197580800.0 | grad norm avg: 1.27 | grad norm last: 1.25 | 
2026-01-02T05:32:48 | step: 128200 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 8.354741112270858e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.86 | consumed tokens: 4200857600.0 | grad norm avg: 1.27 | grad norm last: 1.24 | 
2026-01-02T05:33:16 | step: 128300 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 8.32092064229073e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.06 | consumed tokens: 4204134400.0 | grad norm avg: 1.29 | grad norm last: 1.19 | 
2026-01-02T05:33:44 | step: 128400 | train samples/s: 278.6 | train mfu (16-bit): -1.0 | lr mean: 8.28715565148741e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.59 | consumed tokens: 4207411200.0 | grad norm avg: 1.27 | grad norm last: 1.5 | 
2026-01-02T05:34:12 | step: 128500 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 8.253446139860898e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.54 | consumed tokens: 4210688000.0 | grad norm avg: 1.29 | grad norm last: 1.19 | 
2026-01-02T05:34:40 | step: 128600 | train samples/s: 278.2 | train mfu (16-bit): -1.0 | lr mean: 8.219792107411195e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.0 | consumed tokens: 4213964800.0 | grad norm avg: 1.29 | grad norm last: 1.23 | 
2026-01-02T05:35:07 | step: 128700 | train samples/s: 279.3 | train mfu (16-bit): -1.0 | lr mean: 8.186193554138299e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.99 | consumed tokens: 4217241600.0 | grad norm avg: 1.27 | grad norm last: 1.3 | 
2026-01-02T05:35:35 | step: 128800 | train samples/s: 281.5 | train mfu (16-bit): -1.0 | lr mean: 8.152650480042212e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.1 | consumed tokens: 4220518400.0 | grad norm avg: 1.3 | grad norm last: 1.19 | 
2026-01-02T05:36:03 | step: 128900 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 8.119163794617634e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.93 | consumed tokens: 4223795200.0 | grad norm avg: 1.31 | grad norm last: 1.29 | 
2026-01-02T05:36:31 | step: 129000 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 8.085733497864567e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.27 | consumed tokens: 4227072000.0 | grad norm avg: 1.29 | grad norm last: 1.33 | 
2026-01-02T05:36:59 | step: 129100 | train samples/s: 278.3 | train mfu (16-bit): -1.0 | lr mean: 8.052358680288307e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.29 | consumed tokens: 4230348800.0 | grad norm avg: 1.28 | grad norm last: 1.26 | 
2026-01-02T05:37:27 | step: 129200 | train samples/s: 275.6 | train mfu (16-bit): -1.0 | lr mean: 8.019040251383558e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.96 | consumed tokens: 4233625600.0 | grad norm avg: 1.3 | grad norm last: 1.43 | 
2026-01-02T05:37:55 | step: 129300 | train samples/s: 279.0 | train mfu (16-bit): -1.0 | lr mean: 7.985778211150318e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.07 | consumed tokens: 4236902400.0 | grad norm avg: 1.28 | grad norm last: 1.41 | 
2026-01-02T05:38:23 | step: 129400 | train samples/s: 279.3 | train mfu (16-bit): -1.0 | lr mean: 7.952572559588589e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.9 | consumed tokens: 4240179200.0 | grad norm avg: 1.28 | grad norm last: 1.21 | 
2026-01-02T05:38:51 | step: 129500 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 7.919423296698369e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.05 | consumed tokens: 4243456000.0 | grad norm avg: 1.27 | grad norm last: 1.16 | 
2026-01-02T05:39:18 | step: 129600 | train samples/s: 280.2 | train mfu (16-bit): -1.0 | lr mean: 7.886331331974361e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.21 | consumed tokens: 4246732800.0 | grad norm avg: 1.28 | grad norm last: 1.31 | 
2026-01-02T05:39:46 | step: 129700 | train samples/s: 280.2 | train mfu (16-bit): -1.0 | lr mean: 7.853295755921863e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.77 | consumed tokens: 4250009600.0 | grad norm avg: 1.29 | grad norm last: 1.17 | 
2026-01-02T05:40:14 | step: 129800 | train samples/s: 277.9 | train mfu (16-bit): -1.0 | lr mean: 7.820316568540875e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.77 | consumed tokens: 4253286400.0 | grad norm avg: 1.29 | grad norm last: 1.27 | 
2026-01-02T05:40:42 | step: 129900 | train samples/s: 277.5 | train mfu (16-bit): -1.0 | lr mean: 7.787394679326098e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.03 | consumed tokens: 4256563200.0 | grad norm avg: 1.3 | grad norm last: 1.29 | 
2026-01-02T05:41:10 | step: 130000 | train samples/s: 276.3 | train mfu (16-bit): -1.0 | lr mean: 7.754530088277534e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.27 | consumed tokens: 4259840000.0 | grad norm avg: 1.31 | grad norm last: 1.22 | 
2026-01-02T05:41:40 | step: 130100 | train samples/s: 281.3 | train mfu (16-bit): -1.0 | lr mean: 7.72172279539518e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.14 | consumed tokens: 4263116800.0 | grad norm avg: 1.3 | grad norm last: 1.28 | 
2026-01-02T05:42:07 | step: 130200 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 7.68897280067904e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.09 | consumed tokens: 4266393600.0 | grad norm avg: 1.31 | grad norm last: 1.25 | 
2026-01-02T05:42:35 | step: 130300 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 7.65628010412911e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.18 | consumed tokens: 4269670400.0 | grad norm avg: 1.31 | grad norm last: 1.3 | 
2026-01-02T05:43:03 | step: 130400 | train samples/s: 278.3 | train mfu (16-bit): -1.0 | lr mean: 7.6236451604927424e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.04 | consumed tokens: 4272947200.0 | grad norm avg: 1.3 | grad norm last: 1.19 | 
2026-01-02T05:43:31 | step: 130500 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 7.591067515022587e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.29 | consumed tokens: 4276224000.0 | grad norm avg: 1.31 | grad norm last: 1.33 | 
2026-01-02T05:43:59 | step: 130600 | train samples/s: 277.9 | train mfu (16-bit): -1.0 | lr mean: 7.558547622465994e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.12 | consumed tokens: 4279500800.0 | grad norm avg: 1.31 | grad norm last: 1.31 | 
2026-01-02T05:44:27 | step: 130700 | train samples/s: 276.6 | train mfu (16-bit): -1.0 | lr mean: 7.526085937570315e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.41 | consumed tokens: 4282777600.0 | grad norm avg: 1.28 | grad norm last: 1.27 | 
2026-01-02T05:44:54 | step: 130800 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 7.493682005588198e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.26 | consumed tokens: 4286054400.0 | grad norm avg: 1.29 | grad norm last: 1.35 | 
2026-01-02T05:45:22 | step: 130900 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 7.461336281266995e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.87 | consumed tokens: 4289331200.0 | grad norm avg: 1.3 | grad norm last: 1.17 | 
2026-01-02T05:45:50 | step: 131000 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 7.429048309859354e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.03 | consumed tokens: 4292608000.0 | grad norm avg: 1.32 | grad norm last: 1.32 | 
2026-01-02T05:46:18 | step: 131100 | train samples/s: 278.5 | train mfu (16-bit): -1.0 | lr mean: 7.396819000859978e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.09 | consumed tokens: 4295884800.0 | grad norm avg: 1.31 | grad norm last: 1.29 | 
2026-01-02T05:46:45 | step: 131200 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 7.364648354268866e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.22 | consumed tokens: 4299161600.0 | grad norm avg: 1.33 | grad norm last: 1.28 | 
2026-01-02T05:47:13 | step: 131300 | train samples/s: 277.9 | train mfu (16-bit): -1.0 | lr mean: 7.332535460591316e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.03 | consumed tokens: 4302438400.0 | grad norm avg: 1.29 | grad norm last: 1.18 | 
2026-01-02T05:47:41 | step: 131400 | train samples/s: 279.4 | train mfu (16-bit): -1.0 | lr mean: 7.300481684069382e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.15 | consumed tokens: 4305715200.0 | grad norm avg: 1.33 | grad norm last: 1.46 | 
2026-01-02T05:48:09 | step: 131500 | train samples/s: 279.0 | train mfu (16-bit): -1.0 | lr mean: 7.268486569955712e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.27 | consumed tokens: 4308992000.0 | grad norm avg: 1.31 | grad norm last: 1.27 | 
2026-01-02T05:48:37 | step: 131600 | train samples/s: 281.3 | train mfu (16-bit): -1.0 | lr mean: 7.236550118250307e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.95 | consumed tokens: 4312268800.0 | grad norm avg: 1.31 | grad norm last: 1.22 | 
2026-01-02T05:49:04 | step: 131700 | train samples/s: 281.4 | train mfu (16-bit): -1.0 | lr mean: 7.2046727837005164e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.63 | consumed tokens: 4315545600.0 | grad norm avg: 1.28 | grad norm last: 1.25 | 
2026-01-02T05:49:32 | step: 131800 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 7.1728545663063414e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.93 | consumed tokens: 4318822400.0 | grad norm avg: 1.32 | grad norm last: 1.35 | 
2026-01-02T05:50:00 | step: 131900 | train samples/s: 281.3 | train mfu (16-bit): -1.0 | lr mean: 7.141095466067782e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.2 | consumed tokens: 4322099200.0 | grad norm avg: 1.33 | grad norm last: 1.32 | 
2026-01-02T05:50:28 | step: 132000 | train samples/s: 278.7 | train mfu (16-bit): -1.0 | lr mean: 7.109395482984837e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.29 | consumed tokens: 4325376000.0 | grad norm avg: 1.32 | grad norm last: 1.52 | 
2026-01-02T05:50:56 | step: 132100 | train samples/s: 279.6 | train mfu (16-bit): -1.0 | lr mean: 7.077754617057508e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.23 | consumed tokens: 4328652800.0 | grad norm avg: 1.36 | grad norm last: 1.29 | 
2026-01-02T05:51:24 | step: 132200 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 7.046173323033145e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.11 | consumed tokens: 4331929600.0 | grad norm avg: 1.32 | grad norm last: 1.24 | 
2026-01-02T05:51:52 | step: 132300 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 7.0146520556590986e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.78 | consumed tokens: 4335206400.0 | grad norm avg: 1.3 | grad norm last: 1.68 | 
2026-01-02T05:52:19 | step: 132400 | train samples/s: 278.7 | train mfu (16-bit): -1.0 | lr mean: 6.983189905440668e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.07 | consumed tokens: 4338483200.0 | grad norm avg: 1.34 | grad norm last: 1.26 | 
2026-01-02T05:52:47 | step: 132500 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 6.951787781872554e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.12 | consumed tokens: 4341760000.0 | grad norm avg: 1.3 | grad norm last: 1.29 | 
2026-01-02T05:53:15 | step: 132600 | train samples/s: 277.0 | train mfu (16-bit): -1.0 | lr mean: 6.920445230207406e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.25 | consumed tokens: 4345036800.0 | grad norm avg: 1.33 | grad norm last: 1.4 | 
2026-01-02T05:53:43 | step: 132700 | train samples/s: 279.5 | train mfu (16-bit): -1.0 | lr mean: 6.889163159939926e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.21 | consumed tokens: 4348313600.0 | grad norm avg: 1.32 | grad norm last: 1.21 | 
2026-01-02T05:54:11 | step: 132800 | train samples/s: 281.6 | train mfu (16-bit): -1.0 | lr mean: 6.857940661575412e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.98 | consumed tokens: 4351590400.0 | grad norm avg: 1.31 | grad norm last: 1.24 | 
2026-01-02T05:54:38 | step: 132900 | train samples/s: 281.3 | train mfu (16-bit): -1.0 | lr mean: 6.8267786446085665e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.08 | consumed tokens: 4354867200.0 | grad norm avg: 1.34 | grad norm last: 1.21 | 
2026-01-02T05:55:06 | step: 133000 | train samples/s: 279.3 | train mfu (16-bit): -1.0 | lr mean: 6.795676654292038e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.05 | consumed tokens: 4358144000.0 | grad norm avg: 1.37 | grad norm last: 1.4 | 
2026-01-02T05:55:34 | step: 133100 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 6.764635600120528e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.47 | consumed tokens: 4361420800.0 | grad norm avg: 1.34 | grad norm last: 1.23 | 
2026-01-02T05:56:02 | step: 133200 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 6.733654572599335e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.84 | consumed tokens: 4364697600.0 | grad norm avg: 1.35 | grad norm last: 1.33 | 
2026-01-02T05:56:30 | step: 133300 | train samples/s: 278.5 | train mfu (16-bit): -1.0 | lr mean: 6.7027340264758095e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.25 | consumed tokens: 4367974400.0 | grad norm avg: 1.35 | grad norm last: 1.44 | 
2026-01-02T05:56:58 | step: 133400 | train samples/s: 279.8 | train mfu (16-bit): -1.0 | lr mean: 6.671874416497303e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.41 | consumed tokens: 4371251200.0 | grad norm avg: 1.33 | grad norm last: 1.38 | 
2026-01-02T05:57:25 | step: 133500 | train samples/s: 281.5 | train mfu (16-bit): -1.0 | lr mean: 6.641075742663816e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.04 | consumed tokens: 4374528000.0 | grad norm avg: 1.36 | grad norm last: 1.37 | 
2026-01-02T05:57:53 | step: 133600 | train samples/s: 281.5 | train mfu (16-bit): -1.0 | lr mean: 6.610337550227996e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.77 | consumed tokens: 4377804800.0 | grad norm avg: 1.37 | grad norm last: 1.32 | 
2026-01-02T05:58:21 | step: 133700 | train samples/s: 276.8 | train mfu (16-bit): -1.0 | lr mean: 6.579660748684546e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.37 | consumed tokens: 4381081600.0 | grad norm avg: 1.36 | grad norm last: 1.28 | 
2026-01-02T05:58:49 | step: 133800 | train samples/s: 281.4 | train mfu (16-bit): -1.0 | lr mean: 6.549044883286115e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.0 | consumed tokens: 4384358400.0 | grad norm avg: 1.35 | grad norm last: 1.57 | 
2026-01-02T05:59:16 | step: 133900 | train samples/s: 281.5 | train mfu (16-bit): -1.0 | lr mean: 6.518490408780053e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.26 | consumed tokens: 4387635200.0 | grad norm avg: 1.34 | grad norm last: 1.27 | 
2026-01-02T05:59:44 | step: 134000 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 6.4879968704190105e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.92 | consumed tokens: 4390912000.0 | grad norm avg: 1.31 | grad norm last: 1.31 | 
2026-01-02T06:00:12 | step: 134100 | train samples/s: 280.0 | train mfu (16-bit): -1.0 | lr mean: 6.457565177697688e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.9 | consumed tokens: 4394188800.0 | grad norm avg: 1.35 | grad norm last: 1.34 | 
2026-01-02T06:00:40 | step: 134200 | train samples/s: 281.5 | train mfu (16-bit): -1.0 | lr mean: 6.427194421121385e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.25 | consumed tokens: 4397465600.0 | grad norm avg: 1.36 | grad norm last: 1.25 | 
2026-01-02T06:01:07 | step: 134300 | train samples/s: 281.5 | train mfu (16-bit): -1.0 | lr mean: 6.396885964932153e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.3 | consumed tokens: 4400742400.0 | grad norm avg: 1.36 | grad norm last: 1.34 | 
2026-01-02T06:01:35 | step: 134400 | train samples/s: 278.9 | train mfu (16-bit): -1.0 | lr mean: 6.366638899635291e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.61 | consumed tokens: 4404019200.0 | grad norm avg: 1.33 | grad norm last: 1.4 | 
2026-01-02T06:02:03 | step: 134500 | train samples/s: 279.2 | train mfu (16-bit): -1.0 | lr mean: 6.336453225230798e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.91 | consumed tokens: 4407296000.0 | grad norm avg: 1.37 | grad norm last: 1.27 | 
2026-01-02T06:02:31 | step: 134600 | train samples/s: 281.2 | train mfu (16-bit): -1.0 | lr mean: 6.306329851213377e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.75 | consumed tokens: 4410572800.0 | grad norm avg: 1.33 | grad norm last: 1.23 | 
2026-01-02T06:02:59 | step: 134700 | train samples/s: 278.6 | train mfu (16-bit): -1.0 | lr mean: 6.276268777583027e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.26 | consumed tokens: 4413849600.0 | grad norm avg: 1.35 | grad norm last: 1.34 | 
2026-01-02T06:03:27 | step: 134800 | train samples/s: 279.9 | train mfu (16-bit): -1.0 | lr mean: 6.246269549592398e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.05 | consumed tokens: 4417126400.0 | grad norm avg: 1.36 | grad norm last: 1.47 | 
2026-01-02T06:03:54 | step: 134900 | train samples/s: 281.8 | train mfu (16-bit): -1.0 | lr mean: 6.2163321672414895e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.3 | consumed tokens: 4420403200.0 | grad norm avg: 1.36 | grad norm last: 1.3 | 
2026-01-02T06:04:22 | step: 135000 | train samples/s: 281.7 | train mfu (16-bit): -1.0 | lr mean: 6.186457540025003e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.04 | consumed tokens: 4423680000.0 | grad norm avg: 1.34 | grad norm last: 1.35 | 
2026-01-02T06:04:52 | step: 135100 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 6.1566452131955884e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.22 | consumed tokens: 4426956800.0 | grad norm avg: 1.36 | grad norm last: 1.19 | 
2026-01-02T06:05:19 | step: 135200 | train samples/s: 278.4 | train mfu (16-bit): -1.0 | lr mean: 6.126895186753245e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.04 | consumed tokens: 4430233600.0 | grad norm avg: 1.35 | grad norm last: 1.56 | 
2026-01-02T06:05:47 | step: 135300 | train samples/s: 280.7 | train mfu (16-bit): -1.0 | lr mean: 6.097207915445324e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.06 | consumed tokens: 4433510400.0 | grad norm avg: 1.33 | grad norm last: 1.27 | 
2026-01-02T06:06:15 | step: 135400 | train samples/s: 277.7 | train mfu (16-bit): -1.0 | lr mean: 6.067583399271825e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.27 | consumed tokens: 4436787200.0 | grad norm avg: 1.36 | grad norm last: 1.3 | 
2026-01-02T06:06:43 | step: 135500 | train samples/s: 278.7 | train mfu (16-bit): -1.0 | lr mean: 6.038021638232749e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.82 | consumed tokens: 4440064000.0 | grad norm avg: 1.37 | grad norm last: 1.21 | 
2026-01-02T06:07:11 | step: 135600 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 6.008523087075446e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.92 | consumed tokens: 4443340800.0 | grad norm avg: 1.38 | grad norm last: 1.43 | 
2026-01-02T06:07:39 | step: 135700 | train samples/s: 278.1 | train mfu (16-bit): -1.0 | lr mean: 5.979087291052565e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.06 | consumed tokens: 4446617600.0 | grad norm avg: 1.38 | grad norm last: 1.34 | 
2026-01-02T06:08:07 | step: 135800 | train samples/s: 280.2 | train mfu (16-bit): -1.0 | lr mean: 5.9497142501641065e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.99 | consumed tokens: 4449894400.0 | grad norm avg: 1.36 | grad norm last: 1.51 | 
2026-01-02T06:08:34 | step: 135900 | train samples/s: 280.2 | train mfu (16-bit): -1.0 | lr mean: 5.920404873904772e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.95 | consumed tokens: 4453171200.0 | grad norm avg: 1.34 | grad norm last: 1.4 | 
2026-01-02T06:09:02 | step: 136000 | train samples/s: 276.9 | train mfu (16-bit): -1.0 | lr mean: 5.891158707527211e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.27 | consumed tokens: 4456448000.0 | grad norm avg: 1.36 | grad norm last: 1.22 | 
2026-01-02T06:09:31 | step: 136100 | train samples/s: 275.6 | train mfu (16-bit): -1.0 | lr mean: 5.861975751031423e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.04 | consumed tokens: 4459724800.0 | grad norm avg: 1.36 | grad norm last: 1.53 | 
2026-01-02T06:09:58 | step: 136200 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 5.832856004417408e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.12 | consumed tokens: 4463001600.0 | grad norm avg: 1.36 | grad norm last: 1.23 | 
2026-01-02T06:10:26 | step: 136300 | train samples/s: 279.9 | train mfu (16-bit): -1.0 | lr mean: 5.8038003771798685e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.17 | consumed tokens: 4466278400.0 | grad norm avg: 1.39 | grad norm last: 1.37 | 
2026-01-02T06:10:54 | step: 136400 | train samples/s: 278.0 | train mfu (16-bit): -1.0 | lr mean: 5.774807959824102e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.81 | consumed tokens: 4469555200.0 | grad norm avg: 1.38 | grad norm last: 1.24 | 
2026-01-02T06:11:22 | step: 136500 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 5.7458796618448105e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.13 | consumed tokens: 4472832000.0 | grad norm avg: 1.34 | grad norm last: 1.59 | 
2026-01-02T06:11:50 | step: 136600 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 5.717015028494643e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.98 | consumed tokens: 4476108800.0 | grad norm avg: 1.34 | grad norm last: 1.32 | 
2026-01-02T06:12:18 | step: 136700 | train samples/s: 275.5 | train mfu (16-bit): -1.0 | lr mean: 5.688214514520951e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.88 | consumed tokens: 4479385600.0 | grad norm avg: 1.38 | grad norm last: 1.34 | 
2026-01-02T06:12:46 | step: 136800 | train samples/s: 279.2 | train mfu (16-bit): -1.0 | lr mean: 5.659478119923733e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.8 | consumed tokens: 4482662400.0 | grad norm avg: 1.35 | grad norm last: 1.34 | 
2026-01-02T06:13:14 | step: 136900 | train samples/s: 280.7 | train mfu (16-bit): -1.0 | lr mean: 5.630805844702991e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.05 | consumed tokens: 4485939200.0 | grad norm avg: 1.38 | grad norm last: 1.3 | 
2026-01-02T06:13:42 | step: 137000 | train samples/s: 278.2 | train mfu (16-bit): -1.0 | lr mean: 5.602197688858723e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.33 | consumed tokens: 4489216000.0 | grad norm avg: 1.36 | grad norm last: 1.49 | 
2026-01-02T06:14:09 | step: 137100 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 5.573653652390931e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.95 | consumed tokens: 4492492800.0 | grad norm avg: 1.37 | grad norm last: 1.25 | 
2026-01-02T06:14:37 | step: 137200 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 5.545174644794315e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.01 | consumed tokens: 4495769600.0 | grad norm avg: 1.37 | grad norm last: 1.3 | 
2026-01-02T06:15:05 | step: 137300 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 5.516759756574174e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.02 | consumed tokens: 4499046400.0 | grad norm avg: 1.37 | grad norm last: 1.41 | 
2026-01-02T06:15:33 | step: 137400 | train samples/s: 278.1 | train mfu (16-bit): -1.0 | lr mean: 5.4884094424778596e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.05 | train loss last: 2.7 | consumed tokens: 4502323200.0 | grad norm avg: 1.39 | grad norm last: 1.28 | 
2026-01-02T06:16:01 | step: 137500 | train samples/s: 276.2 | train mfu (16-bit): -1.0 | lr mean: 5.4601241572527215e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.12 | consumed tokens: 4505600000.0 | grad norm avg: 1.34 | grad norm last: 1.49 | 
2026-01-02T06:16:29 | step: 137600 | train samples/s: 280.2 | train mfu (16-bit): -1.0 | lr mean: 5.431903446151409e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.06 | consumed tokens: 4508876800.0 | grad norm avg: 1.37 | grad norm last: 1.51 | 
2026-01-02T06:16:57 | step: 137700 | train samples/s: 278.0 | train mfu (16-bit): -1.0 | lr mean: 5.403747763921274e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.71 | consumed tokens: 4512153600.0 | grad norm avg: 1.41 | grad norm last: 1.43 | 
2026-01-02T06:17:25 | step: 137800 | train samples/s: 280.7 | train mfu (16-bit): -1.0 | lr mean: 5.375656655814964e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.12 | consumed tokens: 4515430400.0 | grad norm avg: 1.36 | grad norm last: 1.39 | 
2026-01-02T06:17:52 | step: 137900 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 5.3476310313271824e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.12 | consumed tokens: 4518707200.0 | grad norm avg: 1.37 | grad norm last: 1.38 | 
2026-01-02T06:18:20 | step: 138000 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 5.319670890457928e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.12 | consumed tokens: 4521984000.0 | grad norm avg: 1.35 | grad norm last: 1.27 | 
2026-01-02T06:18:48 | step: 138100 | train samples/s: 277.9 | train mfu (16-bit): -1.0 | lr mean: 5.2917753237125e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.0 | consumed tokens: 4525260800.0 | grad norm avg: 1.36 | grad norm last: 1.26 | 
2026-01-02T06:19:16 | step: 138200 | train samples/s: 276.4 | train mfu (16-bit): -1.0 | lr mean: 5.26394569533295e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.01 | consumed tokens: 4528537600.0 | grad norm avg: 1.36 | grad norm last: 1.32 | 
2026-01-02T06:19:44 | step: 138300 | train samples/s: 278.4 | train mfu (16-bit): -1.0 | lr mean: 5.236181095824577e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.87 | consumed tokens: 4531814400.0 | grad norm avg: 1.38 | grad norm last: 1.46 | 
2026-01-02T06:20:12 | step: 138400 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 5.208482434682082e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.09 | consumed tokens: 4535091200.0 | grad norm avg: 1.38 | grad norm last: 1.17 | 
2026-01-02T06:20:40 | step: 138500 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 5.1808492571581155e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.53 | consumed tokens: 4538368000.0 | grad norm avg: 1.4 | grad norm last: 1.59 | 
2026-01-02T06:21:07 | step: 138600 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 5.153282018000027e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.0 | consumed tokens: 4541644800.0 | grad norm avg: 1.38 | grad norm last: 1.34 | 
2026-01-02T06:21:35 | step: 138700 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 5.1257802624604665e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.46 | consumed tokens: 4544921600.0 | grad norm avg: 1.35 | grad norm last: 1.37 | 
2026-01-02T06:22:03 | step: 138800 | train samples/s: 276.3 | train mfu (16-bit): -1.0 | lr mean: 5.098344445286784e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.42 | consumed tokens: 4548198400.0 | grad norm avg: 1.36 | grad norm last: 1.59 | 
2026-01-02T06:22:31 | step: 138900 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 5.070975021226332e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.96 | consumed tokens: 4551475200.0 | grad norm avg: 1.44 | grad norm last: 1.27 | 
2026-01-02T06:22:59 | step: 139000 | train samples/s: 276.3 | train mfu (16-bit): -1.0 | lr mean: 5.0436710807844065e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.0 | consumed tokens: 4554752000.0 | grad norm avg: 1.38 | grad norm last: 1.32 | 
2026-01-02T06:23:27 | step: 139100 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 5.016433988203062e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.4 | consumed tokens: 4558028800.0 | grad norm avg: 1.37 | grad norm last: 1.32 | 
2026-01-02T06:23:55 | step: 139200 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 4.9892628339875955e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.14 | consumed tokens: 4561305600.0 | grad norm avg: 1.4 | grad norm last: 1.31 | 
2026-01-02T06:24:22 | step: 139300 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 4.962158072885359e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.32 | consumed tokens: 4564582400.0 | grad norm avg: 1.38 | grad norm last: 1.29 | 
2026-01-02T06:24:50 | step: 139400 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 4.935119704896351e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.36 | consumed tokens: 4567859200.0 | grad norm avg: 1.37 | grad norm last: 1.57 | 
2026-01-02T06:25:18 | step: 139500 | train samples/s: 276.1 | train mfu (16-bit): -1.0 | lr mean: 4.908148184767924e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.8 | consumed tokens: 4571136000.0 | grad norm avg: 1.38 | grad norm last: 1.53 | 
2026-01-02T06:25:46 | step: 139600 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 4.881243057752727e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.04 | consumed tokens: 4574412800.0 | grad norm avg: 1.38 | grad norm last: 1.34 | 
2026-01-02T06:26:14 | step: 139700 | train samples/s: 275.5 | train mfu (16-bit): -1.0 | lr mean: 4.854404778598109e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.83 | consumed tokens: 4577689600.0 | grad norm avg: 1.4 | grad norm last: 1.23 | 
2026-01-02T06:26:42 | step: 139800 | train samples/s: 280.1 | train mfu (16-bit): -1.0 | lr mean: 4.827632892556721e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.16 | consumed tokens: 4580966400.0 | grad norm avg: 1.37 | grad norm last: 1.31 | 
2026-01-02T06:27:10 | step: 139900 | train samples/s: 280.2 | train mfu (16-bit): -1.0 | lr mean: 4.800928309123265e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.09 | consumed tokens: 4584243200.0 | grad norm avg: 1.4 | grad norm last: 1.43 | 
2026-01-02T06:27:38 | step: 140000 | train samples/s: 280.1 | train mfu (16-bit): -1.0 | lr mean: 4.774290573550388e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.12 | consumed tokens: 4587520000.0 | grad norm avg: 1.39 | grad norm last: 1.34 | 
2026-01-02T06:28:07 | step: 140100 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 4.747720140585443e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.72 | consumed tokens: 4590796800.0 | grad norm avg: 1.42 | grad norm last: 1.36 | 
2026-01-02T06:28:35 | step: 140200 | train samples/s: 276.8 | train mfu (16-bit): -1.0 | lr mean: 4.721217010228429e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.22 | consumed tokens: 4594073600.0 | grad norm avg: 1.39 | grad norm last: 1.41 | 
2026-01-02T06:29:03 | step: 140300 | train samples/s: 278.5 | train mfu (16-bit): -1.0 | lr mean: 4.694780727731995e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.09 | consumed tokens: 4597350400.0 | grad norm avg: 1.34 | grad norm last: 1.28 | 
2026-01-02T06:29:31 | step: 140400 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 4.668411747843493e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.16 | consumed tokens: 4600627200.0 | grad norm avg: 1.38 | grad norm last: 1.31 | 
2026-01-02T06:29:59 | step: 140500 | train samples/s: 279.3 | train mfu (16-bit): -1.0 | lr mean: 4.642110525310272e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.2 | consumed tokens: 4603904000.0 | grad norm avg: 1.34 | grad norm last: 1.3 | 
2026-01-02T06:30:26 | step: 140600 | train samples/s: 281.5 | train mfu (16-bit): -1.0 | lr mean: 4.615876605384983e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.07 | consumed tokens: 4607180800.0 | grad norm avg: 1.36 | grad norm last: 1.23 | 
2026-01-02T06:30:54 | step: 140700 | train samples/s: 281.4 | train mfu (16-bit): -1.0 | lr mean: 4.589710442814976e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 2.87 | consumed tokens: 4610457600.0 | grad norm avg: 1.34 | grad norm last: 1.5 | 
2026-01-02T06:31:22 | step: 140800 | train samples/s: 281.7 | train mfu (16-bit): -1.0 | lr mean: 4.563612037600251e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.16 | consumed tokens: 4613734400.0 | grad norm avg: 1.37 | grad norm last: 1.39 | 
2026-01-02T06:31:50 | step: 140900 | train samples/s: 276.8 | train mfu (16-bit): -1.0 | lr mean: 4.537581389740808e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.09 | consumed tokens: 4617011200.0 | grad norm avg: 1.33 | grad norm last: 1.31 | 
2026-01-02T06:32:18 | step: 141000 | train samples/s: 278.9 | train mfu (16-bit): -1.0 | lr mean: 4.511618499236647e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.14 | consumed tokens: 4620288000.0 | grad norm avg: 1.37 | grad norm last: 1.26 | 
2026-01-02T06:32:45 | step: 141100 | train samples/s: 281.7 | train mfu (16-bit): -1.0 | lr mean: 4.485723366087768e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.05 | consumed tokens: 4623564800.0 | grad norm avg: 1.37 | grad norm last: 1.38 | 
2026-01-02T06:33:13 | step: 141200 | train samples/s: 281.2 | train mfu (16-bit): -1.0 | lr mean: 4.459896445041522e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.94 | consumed tokens: 4626841600.0 | grad norm avg: 1.39 | grad norm last: 1.39 | 
2026-01-02T06:33:41 | step: 141300 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 4.4341377360979095e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.27 | consumed tokens: 4630118400.0 | grad norm avg: 1.37 | grad norm last: 1.25 | 
2026-01-02T06:34:09 | step: 141400 | train samples/s: 281.3 | train mfu (16-bit): -1.0 | lr mean: 4.40844723925693e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.87 | consumed tokens: 4633395200.0 | grad norm avg: 1.33 | grad norm last: 1.22 | 
2026-01-02T06:34:37 | step: 141500 | train samples/s: 276.9 | train mfu (16-bit): -1.0 | lr mean: 4.382824954518583e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.93 | consumed tokens: 4636672000.0 | grad norm avg: 1.33 | grad norm last: 1.32 | 
2026-01-02T06:35:04 | step: 141600 | train samples/s: 281.5 | train mfu (16-bit): -1.0 | lr mean: 4.35727133663022e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.19 | consumed tokens: 4639948800.0 | grad norm avg: 1.34 | grad norm last: 1.36 | 
2026-01-02T06:35:32 | step: 141700 | train samples/s: 278.9 | train mfu (16-bit): -1.0 | lr mean: 4.3317859308444895e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.97 | consumed tokens: 4643225600.0 | grad norm avg: 1.38 | grad norm last: 1.33 | 
2026-01-02T06:36:00 | step: 141800 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 4.306369191908743e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.87 | consumed tokens: 4646502400.0 | grad norm avg: 1.4 | grad norm last: 1.54 | 
2026-01-02T06:36:28 | step: 141900 | train samples/s: 281.3 | train mfu (16-bit): -1.0 | lr mean: 4.28102066507563e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.05 | train loss last: 3.17 | consumed tokens: 4649779200.0 | grad norm avg: 1.37 | grad norm last: 1.37 | 
2026-01-02T06:36:55 | step: 142000 | train samples/s: 279.0 | train mfu (16-bit): -1.0 | lr mean: 4.255741259839851e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.22 | consumed tokens: 4653056000.0 | grad norm avg: 1.39 | grad norm last: 1.46 | 
2026-01-02T06:37:23 | step: 142100 | train samples/s: 281.2 | train mfu (16-bit): -1.0 | lr mean: 4.230530521454057e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.06 | consumed tokens: 4656332800.0 | grad norm avg: 1.42 | grad norm last: 1.55 | 
2026-01-02T06:37:51 | step: 142200 | train samples/s: 276.6 | train mfu (16-bit): -1.0 | lr mean: 4.205388904665597e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.99 | consumed tokens: 4659609600.0 | grad norm avg: 1.39 | grad norm last: 1.6 | 
2026-01-02T06:38:19 | step: 142300 | train samples/s: 278.6 | train mfu (16-bit): -1.0 | lr mean: 4.180315954727121e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.13 | consumed tokens: 4662886400.0 | grad norm avg: 1.37 | grad norm last: 1.28 | 
2026-01-02T06:38:47 | step: 142400 | train samples/s: 281.2 | train mfu (16-bit): -1.0 | lr mean: 4.155312126385979e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.05 | consumed tokens: 4666163200.0 | grad norm avg: 1.38 | grad norm last: 1.42 | 
2026-01-02T06:39:14 | step: 142500 | train samples/s: 281.2 | train mfu (16-bit): -1.0 | lr mean: 4.130377419642173e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.02 | consumed tokens: 4669440000.0 | grad norm avg: 1.37 | grad norm last: 1.51 | 
2026-01-02T06:39:42 | step: 142600 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 4.105511834495701e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.04 | consumed tokens: 4672716800.0 | grad norm avg: 1.36 | grad norm last: 1.2 | 
2026-01-02T06:40:10 | step: 142700 | train samples/s: 279.3 | train mfu (16-bit): -1.0 | lr mean: 4.080715825693915e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.93 | consumed tokens: 4675993600.0 | grad norm avg: 1.36 | grad norm last: 1.22 | 
2026-01-02T06:40:38 | step: 142800 | train samples/s: 281.4 | train mfu (16-bit): -1.0 | lr mean: 4.055988938489463e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.22 | consumed tokens: 4679270400.0 | grad norm avg: 1.39 | grad norm last: 1.58 | 
2026-01-02T06:41:06 | step: 142900 | train samples/s: 276.7 | train mfu (16-bit): -1.0 | lr mean: 4.031331627629697e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.04 | consumed tokens: 4682547200.0 | grad norm avg: 1.37 | grad norm last: 1.2 | 
2026-01-02T06:41:34 | step: 143000 | train samples/s: 279.1 | train mfu (16-bit): -1.0 | lr mean: 4.006743893114617e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.66 | consumed tokens: 4685824000.0 | grad norm avg: 1.41 | grad norm last: 1.33 | 
2026-01-02T06:42:01 | step: 143100 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 3.9822257349442225e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.38 | consumed tokens: 4689100800.0 | grad norm avg: 1.4 | grad norm last: 1.6 | 
2026-01-02T06:42:29 | step: 143200 | train samples/s: 281.4 | train mfu (16-bit): -1.0 | lr mean: 3.957777607865864e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.74 | consumed tokens: 4692377600.0 | grad norm avg: 1.39 | grad norm last: 1.35 | 
2026-01-02T06:42:57 | step: 143300 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 3.933399057132192e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.36 | consumed tokens: 4695654400.0 | grad norm avg: 1.39 | grad norm last: 1.43 | 
2026-01-02T06:43:25 | step: 143400 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 3.909090082743205e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.16 | consumed tokens: 4698931200.0 | grad norm avg: 1.38 | grad norm last: 1.35 | 
2026-01-02T06:43:52 | step: 143500 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 3.884851139446255e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.2 | consumed tokens: 4702208000.0 | grad norm avg: 1.4 | grad norm last: 1.26 | 
2026-01-02T06:44:21 | step: 143600 | train samples/s: 276.3 | train mfu (16-bit): -1.0 | lr mean: 3.860682681988692e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.96 | consumed tokens: 4705484800.0 | grad norm avg: 1.42 | grad norm last: 1.48 | 
2026-01-02T06:44:48 | step: 143700 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 3.836583800875815e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.75 | consumed tokens: 4708761600.0 | grad norm avg: 1.4 | grad norm last: 1.24 | 
2026-01-02T06:45:16 | step: 143800 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 3.8125554056023248e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.07 | consumed tokens: 4712038400.0 | grad norm avg: 1.42 | grad norm last: 1.28 | 
2026-01-02T06:45:44 | step: 143900 | train samples/s: 281.2 | train mfu (16-bit): -1.0 | lr mean: 3.7885970414208714e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.98 | consumed tokens: 4715315200.0 | grad norm avg: 1.37 | grad norm last: 1.25 | 
2026-01-02T06:46:12 | step: 144000 | train samples/s: 281.2 | train mfu (16-bit): -1.0 | lr mean: 3.7647091630788054e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.27 | consumed tokens: 4718592000.0 | grad norm avg: 1.38 | grad norm last: 1.42 | 
2026-01-02T06:46:39 | step: 144100 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 3.740891770576127e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.99 | consumed tokens: 4721868800.0 | grad norm avg: 1.39 | grad norm last: 1.36 | 
2026-01-02T06:47:07 | step: 144200 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 3.7171448639128357e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.75 | consumed tokens: 4725145600.0 | grad norm avg: 1.38 | grad norm last: 1.38 | 
2026-01-02T06:47:35 | step: 144300 | train samples/s: 274.7 | train mfu (16-bit): -1.0 | lr mean: 3.693468443088932e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.35 | consumed tokens: 4728422400.0 | grad norm avg: 1.39 | grad norm last: 1.39 | 
2026-01-02T06:48:03 | step: 144400 | train samples/s: 281.4 | train mfu (16-bit): -1.0 | lr mean: 3.669862735478091e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.05 | train loss last: 3.39 | consumed tokens: 4731699200.0 | grad norm avg: 1.41 | grad norm last: 1.34 | 
2026-01-02T06:48:31 | step: 144500 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 3.6463279684539884e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.14 | consumed tokens: 4734976000.0 | grad norm avg: 1.41 | grad norm last: 1.31 | 
2026-01-02T06:48:58 | step: 144600 | train samples/s: 281.3 | train mfu (16-bit): -1.0 | lr mean: 3.6228636872692732e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.05 | train loss last: 3.13 | consumed tokens: 4738252800.0 | grad norm avg: 1.4 | grad norm last: 1.35 | 
2026-01-02T06:49:26 | step: 144700 | train samples/s: 281.2 | train mfu (16-bit): -1.0 | lr mean: 3.5994705740449717e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.11 | consumed tokens: 4741529600.0 | grad norm avg: 1.41 | grad norm last: 1.29 | 
2026-01-02T06:49:54 | step: 144800 | train samples/s: 281.4 | train mfu (16-bit): -1.0 | lr mean: 3.5761484014074085e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.25 | consumed tokens: 4744806400.0 | grad norm avg: 1.39 | grad norm last: 1.38 | 
2026-01-02T06:50:22 | step: 144900 | train samples/s: 277.5 | train mfu (16-bit): -1.0 | lr mean: 3.5528971693565836e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.93 | consumed tokens: 4748083200.0 | grad norm avg: 1.4 | grad norm last: 1.29 | 
2026-01-02T06:50:50 | step: 145000 | train samples/s: 276.8 | train mfu (16-bit): -1.0 | lr mean: 3.5297171052661724e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.88 | consumed tokens: 4751360000.0 | grad norm avg: 1.39 | grad norm last: 1.34 | 
2026-01-02T06:51:19 | step: 145100 | train samples/s: 280.7 | train mfu (16-bit): -1.0 | lr mean: 3.506608209136175e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.09 | consumed tokens: 4754636800.0 | grad norm avg: 1.46 | grad norm last: 1.38 | 
2026-01-02T06:51:47 | step: 145200 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 3.4835704809665913e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.06 | consumed tokens: 4757913600.0 | grad norm avg: 1.42 | grad norm last: 1.28 | 
2026-01-02T06:52:15 | step: 145300 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 3.460604375504772e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.18 | consumed tokens: 4761190400.0 | grad norm avg: 1.4 | grad norm last: 1.32 | 
2026-01-02T06:52:43 | step: 145400 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 3.4377096653770423e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.98 | consumed tokens: 4764467200.0 | grad norm avg: 1.42 | grad norm last: 1.3 | 
2026-01-02T06:53:10 | step: 145500 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 3.4148863505834015e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.28 | consumed tokens: 4767744000.0 | grad norm avg: 1.45 | grad norm last: 1.49 | 
2026-01-02T06:53:38 | step: 145600 | train samples/s: 276.8 | train mfu (16-bit): -1.0 | lr mean: 3.3921346584975254e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.12 | consumed tokens: 4771020800.0 | grad norm avg: 1.39 | grad norm last: 1.36 | 
2026-01-02T06:54:06 | step: 145700 | train samples/s: 276.4 | train mfu (16-bit): -1.0 | lr mean: 3.369454589119414e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.84 | consumed tokens: 4774297600.0 | grad norm avg: 1.41 | grad norm last: 1.44 | 
2026-01-02T06:54:34 | step: 145800 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 3.3468463698227424e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.14 | consumed tokens: 4777574400.0 | grad norm avg: 1.4 | grad norm last: 1.5 | 
2026-01-02T06:55:02 | step: 145900 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 3.3243097732338356e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.97 | consumed tokens: 4780851200.0 | grad norm avg: 1.41 | grad norm last: 1.41 | 
2026-01-02T06:55:30 | step: 146000 | train samples/s: 280.1 | train mfu (16-bit): -1.0 | lr mean: 3.3018452541000443e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.23 | consumed tokens: 4784128000.0 | grad norm avg: 1.4 | grad norm last: 1.44 | 
2026-01-02T06:55:58 | step: 146100 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 3.279452585047693e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.07 | consumed tokens: 4787404800.0 | grad norm avg: 1.46 | grad norm last: 1.32 | 
2026-01-02T06:56:25 | step: 146200 | train samples/s: 280.1 | train mfu (16-bit): -1.0 | lr mean: 3.2571319934504572e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.07 | consumed tokens: 4790681600.0 | grad norm avg: 1.41 | grad norm last: 1.38 | 
2026-01-02T06:56:54 | step: 146300 | train samples/s: 274.4 | train mfu (16-bit): -1.0 | lr mean: 3.234883479308337e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.85 | consumed tokens: 4793958400.0 | grad norm avg: 1.39 | grad norm last: 1.34 | 
2026-01-02T06:57:21 | step: 146400 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 3.2127072699950077e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.79 | consumed tokens: 4797235200.0 | grad norm avg: 1.45 | grad norm last: 1.67 | 
2026-01-02T06:57:49 | step: 146500 | train samples/s: 278.5 | train mfu (16-bit): -1.0 | lr mean: 3.190603138136794e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.21 | consumed tokens: 4800512000.0 | grad norm avg: 1.38 | grad norm last: 1.28 | 
2026-01-02T06:58:17 | step: 146600 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 3.1685715384810464e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.18 | consumed tokens: 4803788800.0 | grad norm avg: 1.41 | grad norm last: 1.38 | 
2026-01-02T06:58:45 | step: 146700 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 3.14661224365409e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.95 | consumed tokens: 4807065600.0 | grad norm avg: 1.42 | grad norm last: 1.45 | 
2026-01-02T06:59:13 | step: 146800 | train samples/s: 280.7 | train mfu (16-bit): -1.0 | lr mean: 3.1247252536559245e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.99 | consumed tokens: 4810342400.0 | grad norm avg: 1.41 | grad norm last: 1.32 | 
2026-01-02T06:59:41 | step: 146900 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 3.1029110232339008e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.14 | consumed tokens: 4813619200.0 | grad norm avg: 1.44 | grad norm last: 1.38 | 
2026-01-02T07:00:09 | step: 147000 | train samples/s: 276.3 | train mfu (16-bit): -1.0 | lr mean: 3.0811693250143435e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.24 | consumed tokens: 4816896000.0 | grad norm avg: 1.43 | grad norm last: 1.28 | 
2026-01-02T07:00:36 | step: 147100 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 3.059500386370928e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.03 | consumed tokens: 4820172800.0 | grad norm avg: 1.4 | grad norm last: 1.32 | 
2026-01-02T07:01:04 | step: 147200 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 3.0379042073036544e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.3 | consumed tokens: 4823449600.0 | grad norm avg: 1.45 | grad norm last: 1.36 | 
2026-01-02T07:01:32 | step: 147300 | train samples/s: 278.2 | train mfu (16-bit): -1.0 | lr mean: 3.0163807878125226e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.13 | consumed tokens: 4826726400.0 | grad norm avg: 1.45 | grad norm last: 1.51 | 
2026-01-02T07:02:00 | step: 147400 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 2.994930355271208e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.0 | consumed tokens: 4830003200.0 | grad norm avg: 1.46 | grad norm last: 1.7 | 
2026-01-02T07:02:28 | step: 147500 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 2.973552909679711e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.32 | consumed tokens: 4833280000.0 | grad norm avg: 1.41 | grad norm last: 1.34 | 
2026-01-02T07:02:56 | step: 147600 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 2.952248451038031e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.93 | consumed tokens: 4836556800.0 | grad norm avg: 1.43 | grad norm last: 1.5 | 
2026-01-02T07:03:24 | step: 147700 | train samples/s: 275.9 | train mfu (16-bit): -1.0 | lr mean: 2.9310172067198437e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.05 | consumed tokens: 4839833600.0 | grad norm avg: 1.39 | grad norm last: 1.37 | 
2026-01-02T07:03:52 | step: 147800 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 2.9098589493514737e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.88 | consumed tokens: 4843110400.0 | grad norm avg: 1.43 | grad norm last: 1.48 | 
2026-01-02T07:04:19 | step: 147900 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 2.888774133680272e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.9 | consumed tokens: 4846387200.0 | grad norm avg: 1.4 | grad norm last: 1.39 | 
2026-01-02T07:04:47 | step: 148000 | train samples/s: 278.1 | train mfu (16-bit): -1.0 | lr mean: 2.867762532332563e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.04 | consumed tokens: 4849664000.0 | grad norm avg: 1.44 | grad norm last: 1.33 | 
2026-01-02T07:05:15 | step: 148100 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 2.846824372682022e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.88 | consumed tokens: 4852940800.0 | grad norm avg: 1.44 | grad norm last: 1.23 | 
2026-01-02T07:05:43 | step: 148200 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 2.825959654728649e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.29 | consumed tokens: 4856217600.0 | grad norm avg: 1.43 | grad norm last: 1.69 | 
2026-01-02T07:06:11 | step: 148300 | train samples/s: 274.4 | train mfu (16-bit): -1.0 | lr mean: 2.80516860584612e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.21 | consumed tokens: 4859494400.0 | grad norm avg: 1.46 | grad norm last: 1.44 | 
2026-01-02T07:06:39 | step: 148400 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 2.784450998660759e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.25 | consumed tokens: 4862771200.0 | grad norm avg: 1.44 | grad norm last: 1.49 | 
2026-01-02T07:07:07 | step: 148500 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 2.763807287919917e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.08 | consumed tokens: 4866048000.0 | grad norm avg: 1.46 | grad norm last: 1.39 | 
2026-01-02T07:07:35 | step: 148600 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 2.7432370188762434e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.54 | consumed tokens: 4869324800.0 | grad norm avg: 1.42 | grad norm last: 1.23 | 
2026-01-02T07:08:02 | step: 148700 | train samples/s: 280.7 | train mfu (16-bit): -1.0 | lr mean: 2.722740873650764e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.89 | consumed tokens: 4872601600.0 | grad norm avg: 1.42 | grad norm last: 1.49 | 
2026-01-02T07:08:30 | step: 148800 | train samples/s: 278.4 | train mfu (16-bit): -1.0 | lr mean: 2.7023183974961285e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.79 | consumed tokens: 4875878400.0 | grad norm avg: 1.42 | grad norm last: 1.32 | 
2026-01-02T07:08:58 | step: 148900 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 2.681969817786012e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.15 | consumed tokens: 4879155200.0 | grad norm avg: 1.44 | grad norm last: 1.55 | 
2026-01-02T07:09:26 | step: 149000 | train samples/s: 274.6 | train mfu (16-bit): -1.0 | lr mean: 2.6616953618940897e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.09 | consumed tokens: 4882432000.0 | grad norm avg: 1.45 | grad norm last: 1.56 | 
2026-01-02T07:09:54 | step: 149100 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 2.641495029820362e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.11 | consumed tokens: 4885708800.0 | grad norm avg: 1.44 | grad norm last: 1.35 | 
2026-01-02T07:10:22 | step: 149200 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 2.621368821564829e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.87 | consumed tokens: 4888985600.0 | grad norm avg: 1.42 | grad norm last: 1.37 | 
2026-01-02T07:10:50 | step: 149300 | train samples/s: 279.5 | train mfu (16-bit): -1.0 | lr mean: 2.6013167371274903e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.2 | consumed tokens: 4892262400.0 | grad norm avg: 1.41 | grad norm last: 1.35 | 
2026-01-02T07:11:18 | step: 149400 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 2.5813390038820216e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.01 | consumed tokens: 4895539200.0 | grad norm avg: 1.42 | grad norm last: 1.66 | 
2026-01-02T07:11:45 | step: 149500 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 2.561435621828423e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.37 | consumed tokens: 4898816000.0 | grad norm avg: 1.46 | grad norm last: 1.35 | 
2026-01-02T07:12:13 | step: 149600 | train samples/s: 278.0 | train mfu (16-bit): -1.0 | lr mean: 2.5416068183403695e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.02 | consumed tokens: 4902092800.0 | grad norm avg: 1.42 | grad norm last: 1.52 | 
2026-01-02T07:12:42 | step: 149700 | train samples/s: 274.6 | train mfu (16-bit): -1.0 | lr mean: 2.521852366044186e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.11 | consumed tokens: 4905369600.0 | grad norm avg: 1.4 | grad norm last: 1.5 | 
2026-01-02T07:13:10 | step: 149800 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 2.5021722649398725e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.11 | consumed tokens: 4908646400.0 | grad norm avg: 1.47 | grad norm last: 1.78 | 
2026-01-02T07:13:37 | step: 149900 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 2.48256696977478e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.16 | consumed tokens: 4911923200.0 | grad norm avg: 1.43 | grad norm last: 1.54 | 
2026-01-02T07:14:05 | step: 150000 | train samples/s: 280.7 | train mfu (16-bit): -1.0 | lr mean: 2.4630362531752326e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.2 | consumed tokens: 4915200000.0 | grad norm avg: 1.44 | grad norm last: 1.99 | 
2026-01-02T07:14:34 | step: 150100 | train samples/s: 281.6 | train mfu (16-bit): -1.0 | lr mean: 2.443580342514906e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.09 | consumed tokens: 4918476800.0 | grad norm avg: 1.43 | grad norm last: 1.32 | 
2026-01-02T07:15:02 | step: 150200 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 2.4241992377938004e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.04 | consumed tokens: 4921753600.0 | grad norm avg: 1.42 | grad norm last: 1.51 | 
2026-01-02T07:15:30 | step: 150300 | train samples/s: 274.8 | train mfu (16-bit): -1.0 | lr mean: 2.4048929390119156e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.44 | consumed tokens: 4925030400.0 | grad norm avg: 1.43 | grad norm last: 1.37 | 
2026-01-02T07:15:58 | step: 150400 | train samples/s: 278.6 | train mfu (16-bit): -1.0 | lr mean: 2.385661673542927e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.88 | consumed tokens: 4928307200.0 | grad norm avg: 1.43 | grad norm last: 1.38 | 
2026-01-02T07:16:26 | step: 150500 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 2.3665054413868347e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.02 | consumed tokens: 4931584000.0 | grad norm avg: 1.47 | grad norm last: 1.25 | 
2026-01-02T07:16:53 | step: 150600 | train samples/s: 281.6 | train mfu (16-bit): -1.0 | lr mean: 2.3474242425436387e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.05 | train loss last: 3.17 | consumed tokens: 4934860800.0 | grad norm avg: 1.42 | grad norm last: 1.58 | 
2026-01-02T07:17:21 | step: 150700 | train samples/s: 281.3 | train mfu (16-bit): -1.0 | lr mean: 2.328418077013339e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.35 | consumed tokens: 4938137600.0 | grad norm avg: 1.43 | grad norm last: 1.57 | 
2026-01-02T07:17:49 | step: 150800 | train samples/s: 281.3 | train mfu (16-bit): -1.0 | lr mean: 2.3094869447959354e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.11 | consumed tokens: 4941414400.0 | grad norm avg: 1.4 | grad norm last: 1.31 | 
2026-01-02T07:18:17 | step: 150900 | train samples/s: 281.2 | train mfu (16-bit): -1.0 | lr mean: 2.290631300638779e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.34 | consumed tokens: 4944691200.0 | grad norm avg: 1.42 | grad norm last: 1.42 | 
2026-01-02T07:18:45 | step: 151000 | train samples/s: 275.3 | train mfu (16-bit): -1.0 | lr mean: 2.2718509171681944e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.98 | consumed tokens: 4947968000.0 | grad norm avg: 1.43 | grad norm last: 1.38 | 
2026-01-02T07:19:13 | step: 151100 | train samples/s: 279.3 | train mfu (16-bit): -1.0 | lr mean: 2.253146021757857e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.05 | consumed tokens: 4951244800.0 | grad norm avg: 1.41 | grad norm last: 1.27 | 
2026-01-02T07:19:40 | step: 151200 | train samples/s: 281.5 | train mfu (16-bit): -1.0 | lr mean: 2.234516387034091e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.97 | consumed tokens: 4954521600.0 | grad norm avg: 1.4 | grad norm last: 1.26 | 
2026-01-02T07:20:08 | step: 151300 | train samples/s: 281.2 | train mfu (16-bit): -1.0 | lr mean: 2.2159622403705725e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.05 | consumed tokens: 4957798400.0 | grad norm avg: 1.4 | grad norm last: 1.64 | 
2026-01-02T07:20:36 | step: 151400 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 2.1974838091409765e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.74 | consumed tokens: 4961075200.0 | grad norm avg: 1.43 | grad norm last: 1.53 | 
2026-01-02T07:21:03 | step: 151500 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 2.1790808659716276e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.5 | consumed tokens: 4964352000.0 | grad norm avg: 1.44 | grad norm last: 1.32 | 
2026-01-02T07:21:31 | step: 151600 | train samples/s: 278.6 | train mfu (16-bit): -1.0 | lr mean: 2.1607536382362014e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.03 | consumed tokens: 4967628800.0 | grad norm avg: 1.44 | grad norm last: 1.42 | 
2026-01-02T07:21:59 | step: 151700 | train samples/s: 276.9 | train mfu (16-bit): -1.0 | lr mean: 2.1425021259346977e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.17 | consumed tokens: 4970905600.0 | grad norm avg: 1.41 | grad norm last: 1.44 | 
2026-01-02T07:22:27 | step: 151800 | train samples/s: 278.4 | train mfu (16-bit): -1.0 | lr mean: 2.1243263290671166e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.77 | consumed tokens: 4974182400.0 | grad norm avg: 1.39 | grad norm last: 1.42 | 
2026-01-02T07:22:55 | step: 151900 | train samples/s: 281.2 | train mfu (16-bit): -1.0 | lr mean: 2.106226702380809e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.07 | consumed tokens: 4977459200.0 | grad norm avg: 1.44 | grad norm last: 1.58 | 
2026-01-02T07:23:23 | step: 152000 | train samples/s: 281.2 | train mfu (16-bit): -1.0 | lr mean: 2.088202791128424e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.2 | consumed tokens: 4980736000.0 | grad norm avg: 1.45 | grad norm last: 1.47 | 
2026-01-02T07:23:50 | step: 152100 | train samples/s: 281.2 | train mfu (16-bit): -1.0 | lr mean: 2.070254822683637e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.13 | consumed tokens: 4984012800.0 | grad norm avg: 1.46 | grad norm last: 1.49 | 
2026-01-02T07:24:18 | step: 152200 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 2.0523830244201235e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.16 | consumed tokens: 4987289600.0 | grad norm avg: 1.44 | grad norm last: 1.53 | 
2026-01-02T07:24:46 | step: 152300 | train samples/s: 278.7 | train mfu (16-bit): -1.0 | lr mean: 2.034587168964208e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.79 | consumed tokens: 4990566400.0 | grad norm avg: 1.42 | grad norm last: 1.31 | 
2026-01-02T07:25:14 | step: 152400 | train samples/s: 276.8 | train mfu (16-bit): -1.0 | lr mean: 2.016867483689566e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.52 | consumed tokens: 4993843200.0 | grad norm avg: 1.44 | grad norm last: 1.48 | 
2026-01-02T07:25:42 | step: 152500 | train samples/s: 279.0 | train mfu (16-bit): -1.0 | lr mean: 1.999224195969873e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.04 | consumed tokens: 4997120000.0 | grad norm avg: 1.43 | grad norm last: 1.35 | 
2026-01-02T07:26:10 | step: 152600 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 1.9816570784314536e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.11 | consumed tokens: 5000396800.0 | grad norm avg: 1.44 | grad norm last: 1.27 | 
2026-01-02T07:26:37 | step: 152700 | train samples/s: 280.1 | train mfu (16-bit): -1.0 | lr mean: 1.9641661310743075e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.14 | consumed tokens: 5003673600.0 | grad norm avg: 1.43 | grad norm last: 1.59 | 
2026-01-02T07:27:05 | step: 152800 | train samples/s: 281.8 | train mfu (16-bit): -1.0 | lr mean: 1.9467518086457858e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.88 | consumed tokens: 5006950400.0 | grad norm avg: 1.47 | grad norm last: 1.39 | 
2026-01-02T07:27:33 | step: 152900 | train samples/s: 281.7 | train mfu (16-bit): -1.0 | lr mean: 1.929413883772213e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.85 | consumed tokens: 5010227200.0 | grad norm avg: 1.43 | grad norm last: 1.34 | 
2026-01-02T07:28:01 | step: 153000 | train samples/s: 277.7 | train mfu (16-bit): -1.0 | lr mean: 1.912152356453589e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.82 | consumed tokens: 5013504000.0 | grad norm avg: 1.43 | grad norm last: 1.32 | 
2026-01-02T07:28:29 | step: 153100 | train samples/s: 279.5 | train mfu (16-bit): -1.0 | lr mean: 1.8949675677504274e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.37 | consumed tokens: 5016780800.0 | grad norm avg: 1.46 | grad norm last: 1.48 | 
2026-01-02T07:28:56 | step: 153200 | train samples/s: 281.2 | train mfu (16-bit): -1.0 | lr mean: 1.8778592902890523e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.24 | consumed tokens: 5020057600.0 | grad norm avg: 1.45 | grad norm last: 1.32 | 
2026-01-02T07:29:24 | step: 153300 | train samples/s: 278.9 | train mfu (16-bit): -1.0 | lr mean: 1.8608277514431393e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.88 | consumed tokens: 5023334400.0 | grad norm avg: 1.44 | grad norm last: 1.48 | 
2026-01-02T07:29:52 | step: 153400 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 1.8438728375258506e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.99 | consumed tokens: 5026611200.0 | grad norm avg: 1.4 | grad norm last: 1.29 | 
2026-01-02T07:30:20 | step: 153500 | train samples/s: 281.4 | train mfu (16-bit): -1.0 | lr mean: 1.8269947759108618e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.05 | train loss last: 3.05 | consumed tokens: 5029888000.0 | grad norm avg: 1.46 | grad norm last: 1.35 | 
2026-01-02T07:30:47 | step: 153600 | train samples/s: 279.3 | train mfu (16-bit): -1.0 | lr mean: 1.8101935665981728e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.08 | consumed tokens: 5033164800.0 | grad norm avg: 1.45 | grad norm last: 1.59 | 
2026-01-02T07:31:15 | step: 153700 | train samples/s: 279.7 | train mfu (16-bit): -1.0 | lr mean: 1.7934693232746213e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.13 | consumed tokens: 5036441600.0 | grad norm avg: 1.42 | grad norm last: 1.41 | 
2026-01-02T07:31:43 | step: 153800 | train samples/s: 279.4 | train mfu (16-bit): -1.0 | lr mean: 1.7768219322533696e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.91 | consumed tokens: 5039718400.0 | grad norm avg: 1.43 | grad norm last: 1.25 | 
2026-01-02T07:32:11 | step: 153900 | train samples/s: 281.7 | train mfu (16-bit): -1.0 | lr mean: 1.7602516209080932e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.05 | consumed tokens: 5042995200.0 | grad norm avg: 1.4 | grad norm last: 1.56 | 
2026-01-02T07:32:38 | step: 154000 | train samples/s: 281.6 | train mfu (16-bit): -1.0 | lr mean: 1.743758389238792e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.12 | consumed tokens: 5046272000.0 | grad norm avg: 1.45 | grad norm last: 1.36 | 
2026-01-02T07:33:06 | step: 154100 | train samples/s: 279.0 | train mfu (16-bit): -1.0 | lr mean: 1.727342237245466e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.1 | consumed tokens: 5049548800.0 | grad norm avg: 1.45 | grad norm last: 1.35 | 
2026-01-02T07:33:34 | step: 154200 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 1.7110032786149532e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.93 | consumed tokens: 5052825600.0 | grad norm avg: 1.46 | grad norm last: 1.37 | 
2026-01-02T07:34:02 | step: 154300 | train samples/s: 279.2 | train mfu (16-bit): -1.0 | lr mean: 1.6947415133472532e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.34 | consumed tokens: 5056102400.0 | grad norm avg: 1.41 | grad norm last: 1.43 | 
2026-01-02T07:34:30 | step: 154400 | train samples/s: 279.4 | train mfu (16-bit): -1.0 | lr mean: 1.678557055129204e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.9 | consumed tokens: 5059379200.0 | grad norm avg: 1.43 | grad norm last: 1.25 | 
2026-01-02T07:34:58 | step: 154500 | train samples/s: 279.2 | train mfu (16-bit): -1.0 | lr mean: 1.6624500176476431e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.39 | consumed tokens: 5062656000.0 | grad norm avg: 1.4 | grad norm last: 1.27 | 
2026-01-02T07:35:25 | step: 154600 | train samples/s: 281.6 | train mfu (16-bit): -1.0 | lr mean: 1.646420287215733e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.93 | consumed tokens: 5065932800.0 | grad norm avg: 1.46 | grad norm last: 1.26 | 
2026-01-02T07:35:53 | step: 154700 | train samples/s: 281.7 | train mfu (16-bit): -1.0 | lr mean: 1.6304679775203113e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.12 | consumed tokens: 5069209600.0 | grad norm avg: 1.45 | grad norm last: 1.29 | 
2026-01-02T07:36:21 | step: 154800 | train samples/s: 279.1 | train mfu (16-bit): -1.0 | lr mean: 1.6145932022482157e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.17 | consumed tokens: 5072486400.0 | grad norm avg: 1.41 | grad norm last: 1.43 | 
2026-01-02T07:36:49 | step: 154900 | train samples/s: 279.0 | train mfu (16-bit): -1.0 | lr mean: 1.5987959613994462e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.58 | consumed tokens: 5075763200.0 | grad norm avg: 1.43 | grad norm last: 1.56 | 
2026-01-02T07:37:16 | step: 155000 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 1.5830763686608407e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.95 | consumed tokens: 5079040000.0 | grad norm avg: 1.45 | grad norm last: 1.48 | 
2026-01-02T07:37:46 | step: 155100 | train samples/s: 278.5 | train mfu (16-bit): -1.0 | lr mean: 1.567434424032399e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.05 | train loss last: 3.15 | consumed tokens: 5082316800.0 | grad norm avg: 1.45 | grad norm last: 1.42 | 
2026-01-02T07:38:14 | step: 155200 | train samples/s: 278.3 | train mfu (16-bit): -1.0 | lr mean: 1.5518701275141211e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.11 | consumed tokens: 5085593600.0 | grad norm avg: 1.41 | grad norm last: 1.28 | 
2026-01-02T07:38:42 | step: 155300 | train samples/s: 279.9 | train mfu (16-bit): -1.0 | lr mean: 1.5363837064796826e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.32 | consumed tokens: 5088870400.0 | grad norm avg: 1.42 | grad norm last: 1.34 | 
2026-01-02T07:39:10 | step: 155400 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 1.520974933555408e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.25 | consumed tokens: 5092147200.0 | grad norm avg: 1.44 | grad norm last: 1.69 | 
2026-01-02T07:39:37 | step: 155500 | train samples/s: 280.2 | train mfu (16-bit): -1.0 | lr mean: 1.5056441498018103e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.96 | consumed tokens: 5095424000.0 | grad norm avg: 1.42 | grad norm last: 1.3 | 
2026-01-02T07:40:05 | step: 155600 | train samples/s: 276.1 | train mfu (16-bit): -1.0 | lr mean: 1.490391241532052e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.12 | consumed tokens: 5098700800.0 | grad norm avg: 1.44 | grad norm last: 1.71 | 
2026-01-02T07:40:33 | step: 155700 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 1.4752163224329706e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.92 | consumed tokens: 5101977600.0 | grad norm avg: 1.39 | grad norm last: 1.32 | 
2026-01-02T07:41:01 | step: 155800 | train samples/s: 276.0 | train mfu (16-bit): -1.0 | lr mean: 1.4601192788177286e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.89 | consumed tokens: 5105254400.0 | grad norm avg: 1.41 | grad norm last: 1.56 | 
2026-01-02T07:41:29 | step: 155900 | train samples/s: 280.2 | train mfu (16-bit): -1.0 | lr mean: 1.445100451746839e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.92 | consumed tokens: 5108531200.0 | grad norm avg: 1.4 | grad norm last: 1.31 | 
2026-01-02T07:41:57 | step: 156000 | train samples/s: 279.9 | train mfu (16-bit): -1.0 | lr mean: 1.4301597275334643e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.91 | consumed tokens: 5111808000.0 | grad norm avg: 1.44 | grad norm last: 1.61 | 
2026-01-02T07:42:25 | step: 156100 | train samples/s: 279.5 | train mfu (16-bit): -1.0 | lr mean: 1.4152971061776043e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.75 | consumed tokens: 5115084800.0 | grad norm avg: 1.44 | grad norm last: 1.81 | 
2026-01-02T07:42:53 | step: 156200 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 1.4005127013660967e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.28 | consumed tokens: 5118361600.0 | grad norm avg: 1.45 | grad norm last: 1.42 | 
2026-01-02T07:43:21 | step: 156300 | train samples/s: 278.0 | train mfu (16-bit): -1.0 | lr mean: 1.3858065130989417e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.87 | consumed tokens: 5121638400.0 | grad norm avg: 1.44 | grad norm last: 1.57 | 
2026-01-02T07:43:49 | step: 156400 | train samples/s: 278.1 | train mfu (16-bit): -1.0 | lr mean: 1.3711786550629768e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.09 | consumed tokens: 5124915200.0 | grad norm avg: 1.42 | grad norm last: 1.41 | 
2026-01-02T07:44:17 | step: 156500 | train samples/s: 276.1 | train mfu (16-bit): -1.0 | lr mean: 1.3566292409450398e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.77 | consumed tokens: 5128192000.0 | grad norm avg: 1.48 | grad norm last: 1.2 | 
2026-01-02T07:44:45 | step: 156600 | train samples/s: 279.9 | train mfu (16-bit): -1.0 | lr mean: 1.342158157058293e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.73 | consumed tokens: 5131468800.0 | grad norm avg: 1.44 | grad norm last: 1.32 | 
2026-01-02T07:45:12 | step: 156700 | train samples/s: 280.1 | train mfu (16-bit): -1.0 | lr mean: 1.3277655170895741e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.05 | consumed tokens: 5134745600.0 | grad norm avg: 1.41 | grad norm last: 1.42 | 
2026-01-02T07:45:40 | step: 156800 | train samples/s: 280.1 | train mfu (16-bit): -1.0 | lr mean: 1.313451434725721e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.97 | consumed tokens: 5138022400.0 | grad norm avg: 1.42 | grad norm last: 1.44 | 
2026-01-02T07:46:08 | step: 156900 | train samples/s: 278.2 | train mfu (16-bit): -1.0 | lr mean: 1.2992159099667333e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.98 | consumed tokens: 5141299200.0 | grad norm avg: 1.47 | grad norm last: 1.43 | 
2026-01-02T07:46:36 | step: 157000 | train samples/s: 280.1 | train mfu (16-bit): -1.0 | lr mean: 1.2850589428126113e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.76 | consumed tokens: 5144576000.0 | grad norm avg: 1.44 | grad norm last: 1.22 | 
2026-01-02T07:47:04 | step: 157100 | train samples/s: 276.0 | train mfu (16-bit): -1.0 | lr mean: 1.270980533263355e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.04 | consumed tokens: 5147852800.0 | grad norm avg: 1.41 | grad norm last: 1.48 | 
2026-01-02T07:47:32 | step: 157200 | train samples/s: 277.8 | train mfu (16-bit): -1.0 | lr mean: 1.2569809086926398e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.05 | consumed tokens: 5151129600.0 | grad norm avg: 1.43 | grad norm last: 1.56 | 
2026-01-02T07:48:00 | step: 157300 | train samples/s: 280.1 | train mfu (16-bit): -1.0 | lr mean: 1.2430600691004656e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.11 | consumed tokens: 5154406400.0 | grad norm avg: 1.4 | grad norm last: 1.45 | 
2026-01-02T07:48:28 | step: 157400 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 1.2292179007999948e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.93 | consumed tokens: 5157683200.0 | grad norm avg: 1.42 | grad norm last: 1.43 | 
2026-01-02T07:48:56 | step: 157500 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 1.2154546311649028e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.26 | consumed tokens: 5160960000.0 | grad norm avg: 1.41 | grad norm last: 1.43 | 
2026-01-02T07:49:24 | step: 157600 | train samples/s: 278.6 | train mfu (16-bit): -1.0 | lr mean: 1.201770146508352e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.16 | consumed tokens: 5164236800.0 | grad norm avg: 1.45 | grad norm last: 1.67 | 
2026-01-02T07:49:51 | step: 157700 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 1.1881646742040175e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.05 | consumed tokens: 5167513600.0 | grad norm avg: 1.45 | grad norm last: 1.41 | 
2026-01-02T07:50:19 | step: 157800 | train samples/s: 278.6 | train mfu (16-bit): -1.0 | lr mean: 1.174638100565062e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.06 | consumed tokens: 5170790400.0 | grad norm avg: 1.37 | grad norm last: 1.43 | 
2026-01-02T07:50:47 | step: 157900 | train samples/s: 276.3 | train mfu (16-bit): -1.0 | lr mean: 1.1611905392783228e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.02 | consumed tokens: 5174067200.0 | grad norm avg: 1.42 | grad norm last: 1.39 | 
2026-01-02T07:51:15 | step: 158000 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 1.147822104030638e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.9 | consumed tokens: 5177344000.0 | grad norm avg: 1.41 | grad norm last: 1.37 | 
2026-01-02T07:51:43 | step: 158100 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 1.1345326811351697e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.02 | consumed tokens: 5180620800.0 | grad norm avg: 1.44 | grad norm last: 1.35 | 
2026-01-02T07:52:11 | step: 158200 | train samples/s: 278.4 | train mfu (16-bit): -1.0 | lr mean: 1.1213224979655934e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.14 | consumed tokens: 5183897600.0 | grad norm avg: 1.42 | grad norm last: 1.28 | 
2026-01-02T07:52:39 | step: 158300 | train samples/s: 280.7 | train mfu (16-bit): -1.0 | lr mean: 1.1081914408350713e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.11 | consumed tokens: 5187174400.0 | grad norm avg: 1.43 | grad norm last: 1.37 | 
2026-01-02T07:53:07 | step: 158400 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 1.0951396234304411e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.33 | consumed tokens: 5190451200.0 | grad norm avg: 1.43 | grad norm last: 1.25 | 
2026-01-02T07:53:35 | step: 158500 | train samples/s: 278.3 | train mfu (16-bit): -1.0 | lr mean: 1.082167045751703e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.34 | consumed tokens: 5193728000.0 | grad norm avg: 1.43 | grad norm last: 1.37 | 
2026-01-02T07:54:03 | step: 158600 | train samples/s: 276.0 | train mfu (16-bit): -1.0 | lr mean: 1.0692737077988568e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.82 | consumed tokens: 5197004800.0 | grad norm avg: 1.47 | grad norm last: 1.62 | 
2026-01-02T07:54:30 | step: 158700 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 1.056459836945578e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.96 | consumed tokens: 5200281600.0 | grad norm avg: 1.45 | grad norm last: 1.48 | 
2026-01-02T07:54:58 | step: 158800 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 1.0437254331918666e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.32 | consumed tokens: 5203558400.0 | grad norm avg: 1.44 | grad norm last: 1.35 | 
2026-01-02T07:55:26 | step: 158900 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 1.031070382850885e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.44 | consumed tokens: 5206835200.0 | grad norm avg: 1.43 | grad norm last: 1.43 | 
2026-01-02T07:55:54 | step: 159000 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 1.0184947996094706e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.05 | consumed tokens: 5210112000.0 | grad norm avg: 1.45 | grad norm last: 1.4 | 
2026-01-02T07:56:22 | step: 159100 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 1.0059986834676238e-06 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.83 | consumed tokens: 5213388800.0 | grad norm avg: 1.41 | grad norm last: 1.41 | 
2026-01-02T07:56:50 | step: 159200 | train samples/s: 276.8 | train mfu (16-bit): -1.0 | lr mean: 9.935822617990198e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.91 | consumed tokens: 5216665600.0 | grad norm avg: 1.42 | grad norm last: 1.38 | 
2026-01-02T07:57:18 | step: 159300 | train samples/s: 280.0 | train mfu (16-bit): -1.0 | lr mean: 9.812454209168209e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.31 | consumed tokens: 5219942400.0 | grad norm avg: 1.44 | grad norm last: 1.28 | 
2026-01-02T07:57:46 | step: 159400 | train samples/s: 277.6 | train mfu (16-bit): -1.0 | lr mean: 9.689881608210271e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.12 | consumed tokens: 5223219200.0 | grad norm avg: 1.44 | grad norm last: 1.53 | 
2026-01-02T07:58:13 | step: 159500 | train samples/s: 280.7 | train mfu (16-bit): -1.0 | lr mean: 9.568105951984762e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.08 | consumed tokens: 5226496000.0 | grad norm avg: 1.4 | grad norm last: 1.47 | 
2026-01-02T07:58:41 | step: 159600 | train samples/s: 278.4 | train mfu (16-bit): -1.0 | lr mean: 9.447128377360059e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.32 | consumed tokens: 5229772800.0 | grad norm avg: 1.43 | grad norm last: 1.3 | 
2026-01-02T07:59:09 | step: 159700 | train samples/s: 280.0 | train mfu (16-bit): -1.0 | lr mean: 9.326947747467784e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.25 | consumed tokens: 5233049600.0 | grad norm avg: 1.41 | grad norm last: 1.45 | 
2026-01-02T07:59:37 | step: 159800 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 9.207565767610504e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.97 | consumed tokens: 5236326400.0 | grad norm avg: 1.43 | grad norm last: 1.55 | 
2026-01-02T08:00:05 | step: 159900 | train samples/s: 276.7 | train mfu (16-bit): -1.0 | lr mean: 9.088981869354029e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.05 | train loss last: 2.91 | consumed tokens: 5239603200.0 | grad norm avg: 1.45 | grad norm last: 1.53 | 
2026-01-02T08:00:33 | step: 160000 | train samples/s: 280.7 | train mfu (16-bit): -1.0 | lr mean: 8.971197189566738e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.52 | consumed tokens: 5242880000.0 | grad norm avg: 1.51 | grad norm last: 1.53 | 
2026-01-02T08:01:02 | step: 160100 | train samples/s: 279.0 | train mfu (16-bit): -1.0 | lr mean: 8.854211728248629e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.12 | consumed tokens: 5246156800.0 | grad norm avg: 1.44 | grad norm last: 1.35 | 
2026-01-02T08:01:30 | step: 160200 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 8.738025485399703e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.01 | consumed tokens: 5249433600.0 | grad norm avg: 1.44 | grad norm last: 1.46 | 
2026-01-02T08:01:58 | step: 160300 | train samples/s: 281.4 | train mfu (16-bit): -1.0 | lr mean: 8.622639597888337e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.38 | consumed tokens: 5252710400.0 | grad norm avg: 1.48 | grad norm last: 1.4 | 
2026-01-02T08:02:26 | step: 160400 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 8.508054634148721e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.93 | consumed tokens: 5255987200.0 | grad norm avg: 1.45 | grad norm last: 1.36 | 
2026-01-02T08:02:53 | step: 160500 | train samples/s: 279.1 | train mfu (16-bit): -1.0 | lr mean: 8.394269457312475e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.84 | consumed tokens: 5259264000.0 | grad norm avg: 1.44 | grad norm last: 1.55 | 
2026-01-02T08:03:21 | step: 160600 | train samples/s: 279.2 | train mfu (16-bit): -1.0 | lr mean: 8.281286341116356e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.0 | consumed tokens: 5262540800.0 | grad norm avg: 1.44 | grad norm last: 1.55 | 
2026-01-02T08:03:49 | step: 160700 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 8.169104148691986e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.43 | consumed tokens: 5265817600.0 | grad norm avg: 1.39 | grad norm last: 1.51 | 
2026-01-02T08:04:17 | step: 160800 | train samples/s: 281.5 | train mfu (16-bit): -1.0 | lr mean: 8.05772458534193e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.95 | consumed tokens: 5269094400.0 | grad norm avg: 1.41 | grad norm last: 1.39 | 
2026-01-02T08:04:45 | step: 160900 | train samples/s: 276.8 | train mfu (16-bit): -1.0 | lr mean: 7.947146514197811e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.02 | consumed tokens: 5272371200.0 | grad norm avg: 1.41 | grad norm last: 1.49 | 
2026-01-02T08:05:12 | step: 161000 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 7.837371640562196e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.04 | consumed tokens: 5275648000.0 | grad norm avg: 1.41 | grad norm last: 1.39 | 
2026-01-02T08:05:40 | step: 161100 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 7.728399964435084e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.49 | consumed tokens: 5278924800.0 | grad norm avg: 1.43 | grad norm last: 1.4 | 
2026-01-02T08:06:08 | step: 161200 | train samples/s: 279.4 | train mfu (16-bit): -1.0 | lr mean: 7.620230917382287e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.52 | consumed tokens: 5282201600.0 | grad norm avg: 1.45 | grad norm last: 1.5 | 
2026-01-02T08:06:36 | step: 161300 | train samples/s: 279.1 | train mfu (16-bit): -1.0 | lr mean: 7.51286620470637e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.91 | consumed tokens: 5285478400.0 | grad norm avg: 1.46 | grad norm last: 1.69 | 
2026-01-02T08:07:04 | step: 161400 | train samples/s: 281.7 | train mfu (16-bit): -1.0 | lr mean: 7.406305826407333e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.16 | consumed tokens: 5288755200.0 | grad norm avg: 1.43 | grad norm last: 1.32 | 
2026-01-02T08:07:31 | step: 161500 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 7.300549214050989e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.3 | consumed tokens: 5292032000.0 | grad norm avg: 1.42 | grad norm last: 1.42 | 
2026-01-02T08:07:59 | step: 161600 | train samples/s: 277.2 | train mfu (16-bit): -1.0 | lr mean: 7.195598072939902e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.04 | consumed tokens: 5295308800.0 | grad norm avg: 1.4 | grad norm last: 1.5 | 
2026-01-02T08:08:27 | step: 161700 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 7.091451266205695e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.55 | consumed tokens: 5298585600.0 | grad norm avg: 1.45 | grad norm last: 1.53 | 
2026-01-02T08:08:55 | step: 161800 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 6.988110499150935e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.18 | consumed tokens: 5301862400.0 | grad norm avg: 1.44 | grad norm last: 1.37 | 
2026-01-02T08:09:23 | step: 161900 | train samples/s: 279.3 | train mfu (16-bit): -1.0 | lr mean: 6.88557577177562e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.03 | consumed tokens: 5305139200.0 | grad norm avg: 1.4 | grad norm last: 1.42 | 
2026-01-02T08:09:50 | step: 162000 | train samples/s: 278.7 | train mfu (16-bit): -1.0 | lr mean: 6.783847084079753e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.19 | consumed tokens: 5308416000.0 | grad norm avg: 1.42 | grad norm last: 1.77 | 
2026-01-02T08:10:18 | step: 162100 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 6.682924436063331e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.11 | consumed tokens: 5311692800.0 | grad norm avg: 1.43 | grad norm last: 1.35 | 
2026-01-02T08:10:46 | step: 162200 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 6.582808964594733e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.11 | consumed tokens: 5314969600.0 | grad norm avg: 1.41 | grad norm last: 1.37 | 
2026-01-02T08:11:14 | step: 162300 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 6.483500669673958e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.05 | train loss last: 2.84 | consumed tokens: 5318246400.0 | grad norm avg: 1.48 | grad norm last: 1.67 | 
2026-01-02T08:11:42 | step: 162400 | train samples/s: 278.5 | train mfu (16-bit): -1.0 | lr mean: 6.385000119735196e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.14 | consumed tokens: 5321523200.0 | grad norm avg: 1.43 | grad norm last: 1.44 | 
2026-01-02T08:12:09 | step: 162500 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 6.287307314778445e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.34 | consumed tokens: 5324800000.0 | grad norm avg: 1.45 | grad norm last: 1.42 | 
2026-01-02T08:12:37 | step: 162600 | train samples/s: 278.8 | train mfu (16-bit): -1.0 | lr mean: 6.190422254803707e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.21 | consumed tokens: 5328076800.0 | grad norm avg: 1.43 | grad norm last: 1.59 | 
2026-01-02T08:13:05 | step: 162700 | train samples/s: 277.7 | train mfu (16-bit): -1.0 | lr mean: 6.094346076679358e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.12 | consumed tokens: 5331353600.0 | grad norm avg: 1.44 | grad norm last: 1.43 | 
2026-01-02T08:13:33 | step: 162800 | train samples/s: 281.3 | train mfu (16-bit): -1.0 | lr mean: 5.999078780405398e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.99 | consumed tokens: 5334630400.0 | grad norm avg: 1.36 | grad norm last: 1.4 | 
2026-01-02T08:14:01 | step: 162900 | train samples/s: 279.1 | train mfu (16-bit): -1.0 | lr mean: 5.904620365981827e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.17 | consumed tokens: 5337907200.0 | grad norm avg: 1.44 | grad norm last: 1.71 | 
2026-01-02T08:14:29 | step: 163000 | train samples/s: 281.2 | train mfu (16-bit): -1.0 | lr mean: 5.810971401842835e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.69 | consumed tokens: 5341184000.0 | grad norm avg: 1.45 | grad norm last: 1.46 | 
2026-01-02T08:14:56 | step: 163100 | train samples/s: 278.7 | train mfu (16-bit): -1.0 | lr mean: 5.718132456422609e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.94 | consumed tokens: 5344460800.0 | grad norm avg: 1.41 | grad norm last: 1.47 | 
2026-01-02T08:15:24 | step: 163200 | train samples/s: 281.0 | train mfu (16-bit): -1.0 | lr mean: 5.626103529721149e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.15 | consumed tokens: 5347737600.0 | grad norm avg: 1.43 | grad norm last: 1.52 | 
2026-01-02T08:15:52 | step: 163300 | train samples/s: 279.4 | train mfu (16-bit): -1.0 | lr mean: 5.534884621738456e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.72 | consumed tokens: 5351014400.0 | grad norm avg: 1.44 | grad norm last: 1.33 | 
2026-01-02T08:16:20 | step: 163400 | train samples/s: 278.7 | train mfu (16-bit): -1.0 | lr mean: 5.444476300908718e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.22 | consumed tokens: 5354291200.0 | grad norm avg: 1.45 | grad norm last: 1.38 | 
2026-01-02T08:16:48 | step: 163500 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 5.354879135666124e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.12 | consumed tokens: 5357568000.0 | grad norm avg: 1.43 | grad norm last: 1.66 | 
2026-01-02T08:17:16 | step: 163600 | train samples/s: 278.7 | train mfu (16-bit): -1.0 | lr mean: 5.266093126010674e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.52 | consumed tokens: 5360844800.0 | grad norm avg: 1.42 | grad norm last: 1.53 | 
2026-01-02T08:17:43 | step: 163700 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 5.178118840376555e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.24 | consumed tokens: 5364121600.0 | grad norm avg: 1.43 | grad norm last: 1.53 | 
2026-01-02T08:18:11 | step: 163800 | train samples/s: 281.1 | train mfu (16-bit): -1.0 | lr mean: 5.09095627876377e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.05 | train loss last: 3.24 | consumed tokens: 5367398400.0 | grad norm avg: 1.4 | grad norm last: 1.42 | 
2026-01-02T08:18:39 | step: 163900 | train samples/s: 277.1 | train mfu (16-bit): -1.0 | lr mean: 5.004606009606505e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.1 | consumed tokens: 5370675200.0 | grad norm avg: 1.41 | grad norm last: 1.46 | 
2026-01-02T08:19:07 | step: 164000 | train samples/s: 279.0 | train mfu (16-bit): -1.0 | lr mean: 4.919068032904761e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.37 | consumed tokens: 5373952000.0 | grad norm avg: 1.45 | grad norm last: 1.43 | 
2026-01-02T08:19:35 | step: 164100 | train samples/s: 281.5 | train mfu (16-bit): -1.0 | lr mean: 4.834342917092727e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.27 | consumed tokens: 5377228800.0 | grad norm avg: 1.42 | grad norm last: 1.38 | 
2026-01-02T08:20:02 | step: 164200 | train samples/s: 279.3 | train mfu (16-bit): -1.0 | lr mean: 4.750430662170402e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.05 | train loss last: 3.3 | consumed tokens: 5380505600.0 | grad norm avg: 1.43 | grad norm last: 1.48 | 
2026-01-02T08:20:30 | step: 164300 | train samples/s: 281.3 | train mfu (16-bit): -1.0 | lr mean: 4.667331552354881e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.21 | consumed tokens: 5383782400.0 | grad norm avg: 1.45 | grad norm last: 1.68 | 
2026-01-02T08:20:58 | step: 164400 | train samples/s: 281.3 | train mfu (16-bit): -1.0 | lr mean: 4.585045871863258e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.92 | consumed tokens: 5387059200.0 | grad norm avg: 1.43 | grad norm last: 1.45 | 
2026-01-02T08:21:26 | step: 164500 | train samples/s: 281.4 | train mfu (16-bit): -1.0 | lr mean: 4.503574189129722e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.9 | consumed tokens: 5390336000.0 | grad norm avg: 1.46 | grad norm last: 1.45 | 
2026-01-02T08:21:53 | step: 164600 | train samples/s: 279.6 | train mfu (16-bit): -1.0 | lr mean: 4.422916504154273e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.75 | consumed tokens: 5393612800.0 | grad norm avg: 1.41 | grad norm last: 1.35 | 
2026-01-02T08:22:21 | step: 164700 | train samples/s: 276.5 | train mfu (16-bit): -1.0 | lr mean: 4.343073385371099e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.11 | consumed tokens: 5396889600.0 | grad norm avg: 1.42 | grad norm last: 1.37 | 
2026-01-02T08:22:49 | step: 164800 | train samples/s: 281.3 | train mfu (16-bit): -1.0 | lr mean: 4.264044548563106e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.67 | consumed tokens: 5400166400.0 | grad norm avg: 1.49 | grad norm last: 1.52 | 
2026-01-02T08:23:17 | step: 164900 | train samples/s: 279.1 | train mfu (16-bit): -1.0 | lr mean: 4.1858308463815774e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.14 | consumed tokens: 5403443200.0 | grad norm avg: 1.42 | grad norm last: 1.37 | 
2026-01-02T08:23:45 | step: 165000 | train samples/s: 281.2 | train mfu (16-bit): -1.0 | lr mean: 4.1084319946094183e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.05 | train loss last: 2.92 | consumed tokens: 5406720000.0 | grad norm avg: 1.43 | grad norm last: 1.32 | 
2026-01-02T08:24:14 | step: 165100 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 4.0318485616808175e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.11 | consumed tokens: 5409996800.0 | grad norm avg: 1.45 | grad norm last: 1.66 | 
2026-01-02T08:24:42 | step: 165200 | train samples/s: 280.7 | train mfu (16-bit): -1.0 | lr mean: 3.9560811160299636e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.95 | consumed tokens: 5413273600.0 | grad norm avg: 1.42 | grad norm last: 1.36 | 
2026-01-02T08:25:10 | step: 165300 | train samples/s: 277.9 | train mfu (16-bit): -1.0 | lr mean: 3.881129089222668e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.05 | train loss last: 3.11 | consumed tokens: 5416550400.0 | grad norm avg: 1.45 | grad norm last: 1.56 | 
2026-01-02T08:25:38 | step: 165400 | train samples/s: 275.5 | train mfu (16-bit): -1.0 | lr mean: 3.806993618127308e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.0 | consumed tokens: 5419827200.0 | grad norm avg: 1.44 | grad norm last: 1.5 | 
2026-01-02T08:26:06 | step: 165500 | train samples/s: 279.8 | train mfu (16-bit): -1.0 | lr mean: 3.7336741343096946e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.21 | consumed tokens: 5423104000.0 | grad norm avg: 1.49 | grad norm last: 1.38 | 
2026-01-02T08:26:34 | step: 165600 | train samples/s: 278.1 | train mfu (16-bit): -1.0 | lr mean: 3.661171490421111e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.39 | consumed tokens: 5426380800.0 | grad norm avg: 1.44 | grad norm last: 1.56 | 
2026-01-02T08:27:02 | step: 165700 | train samples/s: 280.2 | train mfu (16-bit): -1.0 | lr mean: 3.5894856864615576e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.11 | consumed tokens: 5429657600.0 | grad norm avg: 1.44 | grad norm last: 1.34 | 
2026-01-02T08:27:29 | step: 165800 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 3.518617006648128e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.8 | consumed tokens: 5432934400.0 | grad norm avg: 1.44 | grad norm last: 1.31 | 
2026-01-02T08:27:57 | step: 165900 | train samples/s: 278.4 | train mfu (16-bit): -1.0 | lr mean: 3.448565450980823e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.27 | consumed tokens: 5436211200.0 | grad norm avg: 1.44 | grad norm last: 1.48 | 
2026-01-02T08:28:25 | step: 166000 | train samples/s: 279.3 | train mfu (16-bit): -1.0 | lr mean: 3.37933158789383e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.91 | consumed tokens: 5439488000.0 | grad norm avg: 1.48 | grad norm last: 1.69 | 
2026-01-02T08:28:53 | step: 166100 | train samples/s: 276.0 | train mfu (16-bit): -1.0 | lr mean: 3.3109157016042445e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.37 | consumed tokens: 5442764800.0 | grad norm avg: 1.43 | grad norm last: 1.42 | 
2026-01-02T08:29:21 | step: 166200 | train samples/s: 278.2 | train mfu (16-bit): -1.0 | lr mean: 3.243317792112066e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.66 | consumed tokens: 5446041600.0 | grad norm avg: 1.42 | grad norm last: 1.5 | 
2026-01-02T08:29:49 | step: 166300 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 3.1765378594172944e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.21 | consumed tokens: 5449318400.0 | grad norm avg: 1.45 | grad norm last: 1.43 | 
2026-01-02T08:30:17 | step: 166400 | train samples/s: 280.2 | train mfu (16-bit): -1.0 | lr mean: 3.110576756171213e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.41 | consumed tokens: 5452595200.0 | grad norm avg: 1.43 | grad norm last: 1.36 | 
2026-01-02T08:30:45 | step: 166500 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 3.0454339139396325e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.73 | consumed tokens: 5455872000.0 | grad norm avg: 1.42 | grad norm last: 1.54 | 
2026-01-02T08:31:13 | step: 166600 | train samples/s: 278.4 | train mfu (16-bit): -1.0 | lr mean: 2.9811104695909307e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.07 | consumed tokens: 5459148800.0 | grad norm avg: 1.44 | grad norm last: 1.5 | 
2026-01-02T08:31:40 | step: 166700 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 2.917605854690919e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.22 | consumed tokens: 5462425600.0 | grad norm avg: 1.47 | grad norm last: 1.48 | 
2026-01-02T08:32:08 | step: 166800 | train samples/s: 278.3 | train mfu (16-bit): -1.0 | lr mean: 2.8549203534566914e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.91 | consumed tokens: 5465702400.0 | grad norm avg: 1.43 | grad norm last: 1.41 | 
2026-01-02T08:32:36 | step: 166900 | train samples/s: 276.0 | train mfu (16-bit): -1.0 | lr mean: 2.793054818539531e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.03 | consumed tokens: 5468979200.0 | grad norm avg: 1.46 | grad norm last: 1.5 | 
2026-01-02T08:33:04 | step: 167000 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 2.732008681505249e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.95 | consumed tokens: 5472256000.0 | grad norm avg: 1.43 | grad norm last: 1.42 | 
2026-01-02T08:33:32 | step: 167100 | train samples/s: 280.4 | train mfu (16-bit): -1.0 | lr mean: 2.6717827950051287e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.05 | train loss last: 2.82 | consumed tokens: 5475532800.0 | grad norm avg: 1.42 | grad norm last: 1.41 | 
2026-01-02T08:34:00 | step: 167200 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 2.6123768748220755e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.08 | consumed tokens: 5478809600.0 | grad norm avg: 1.47 | grad norm last: 1.77 | 
2026-01-02T08:34:28 | step: 167300 | train samples/s: 278.7 | train mfu (16-bit): -1.0 | lr mean: 2.5537912051731837e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.89 | consumed tokens: 5482086400.0 | grad norm avg: 1.43 | grad norm last: 1.39 | 
2026-01-02T08:34:56 | step: 167400 | train samples/s: 278.5 | train mfu (16-bit): -1.0 | lr mean: 2.4960260702755477e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.0 | consumed tokens: 5485363200.0 | grad norm avg: 1.45 | grad norm last: 1.48 | 
2026-01-02T08:35:24 | step: 167500 | train samples/s: 278.1 | train mfu (16-bit): -1.0 | lr mean: 2.4390817543462617e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.05 | consumed tokens: 5488640000.0 | grad norm avg: 1.42 | grad norm last: 1.89 | 
2026-01-02T08:35:52 | step: 167600 | train samples/s: 278.1 | train mfu (16-bit): -1.0 | lr mean: 2.382958399493873e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.15 | consumed tokens: 5491916800.0 | grad norm avg: 1.44 | grad norm last: 1.31 | 
2026-01-02T08:36:19 | step: 167700 | train samples/s: 280.0 | train mfu (16-bit): -1.0 | lr mean: 2.3276561478269286e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.26 | consumed tokens: 5495193600.0 | grad norm avg: 1.46 | grad norm last: 1.46 | 
2026-01-02T08:36:47 | step: 167800 | train samples/s: 280.0 | train mfu (16-bit): -1.0 | lr mean: 2.2731751414539758e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.02 | consumed tokens: 5498470400.0 | grad norm avg: 1.42 | grad norm last: 1.32 | 
2026-01-02T08:37:15 | step: 167900 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 2.2195155224835617e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.0 | consumed tokens: 5501747200.0 | grad norm avg: 1.47 | grad norm last: 1.32 | 
2026-01-02T08:37:43 | step: 168000 | train samples/s: 279.0 | train mfu (16-bit): -1.0 | lr mean: 2.1666775751327805e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.86 | consumed tokens: 5505024000.0 | grad norm avg: 1.48 | grad norm last: 1.38 | 
2026-01-02T08:38:11 | step: 168100 | train samples/s: 278.6 | train mfu (16-bit): -1.0 | lr mean: 2.1146614415101794e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.74 | consumed tokens: 5508300800.0 | grad norm avg: 1.46 | grad norm last: 1.5 | 
2026-01-02T08:38:39 | step: 168200 | train samples/s: 278.7 | train mfu (16-bit): -1.0 | lr mean: 2.0634672637243057e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.08 | consumed tokens: 5511577600.0 | grad norm avg: 1.45 | grad norm last: 1.3 | 
2026-01-02T08:39:06 | step: 168300 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 2.0130953259922535e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.93 | consumed tokens: 5514854400.0 | grad norm avg: 1.43 | grad norm last: 1.62 | 
2026-01-02T08:39:34 | step: 168400 | train samples/s: 278.3 | train mfu (16-bit): -1.0 | lr mean: 1.963545628314023e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.95 | consumed tokens: 5518131200.0 | grad norm avg: 1.46 | grad norm last: 1.55 | 
2026-01-02T08:40:02 | step: 168500 | train samples/s: 280.9 | train mfu (16-bit): -1.0 | lr mean: 1.9148184549067082e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.96 | consumed tokens: 5521408000.0 | grad norm avg: 1.44 | grad norm last: 1.39 | 
2026-01-02T08:40:30 | step: 168600 | train samples/s: 280.8 | train mfu (16-bit): -1.0 | lr mean: 1.8669139478788566e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.07 | consumed tokens: 5524684800.0 | grad norm avg: 1.43 | grad norm last: 1.47 | 
2026-01-02T08:40:58 | step: 168700 | train samples/s: 279.0 | train mfu (16-bit): -1.0 | lr mean: 1.819832249339015e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.87 | consumed tokens: 5527961600.0 | grad norm avg: 1.49 | grad norm last: 1.4 | 
2026-01-02T08:41:26 | step: 168800 | train samples/s: 278.6 | train mfu (16-bit): -1.0 | lr mean: 1.773573501395731e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.32 | consumed tokens: 5531238400.0 | grad norm avg: 1.38 | grad norm last: 1.57 | 
2026-01-02T08:41:54 | step: 168900 | train samples/s: 278.3 | train mfu (16-bit): -1.0 | lr mean: 1.7281378461575514e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.73 | consumed tokens: 5534515200.0 | grad norm avg: 1.45 | grad norm last: 1.32 | 
2026-01-02T08:42:21 | step: 169000 | train samples/s: 280.2 | train mfu (16-bit): -1.0 | lr mean: 1.6835254257330234e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.1 | consumed tokens: 5537792000.0 | grad norm avg: 1.49 | grad norm last: 1.35 | 
2026-01-02T08:42:49 | step: 169100 | train samples/s: 280.3 | train mfu (16-bit): -1.0 | lr mean: 1.6397363822306943e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.16 | consumed tokens: 5541068800.0 | grad norm avg: 1.48 | grad norm last: 1.35 | 
2026-01-02T08:43:17 | step: 169200 | train samples/s: 278.1 | train mfu (16-bit): -1.0 | lr mean: 1.5967709998676582e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.85 | consumed tokens: 5544345600.0 | grad norm avg: 1.47 | grad norm last: 1.4 | 
2026-01-02T08:43:45 | step: 169300 | train samples/s: 280.6 | train mfu (16-bit): -1.0 | lr mean: 1.5546292786439153e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.05 | train loss last: 2.8 | consumed tokens: 5547622400.0 | grad norm avg: 1.43 | grad norm last: 1.47 | 
2026-01-02T08:44:13 | step: 169400 | train samples/s: 277.6 | train mfu (16-bit): -1.0 | lr mean: 1.5133115027765598e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.23 | consumed tokens: 5550899200.0 | grad norm avg: 1.44 | grad norm last: 1.27 | 
2026-01-02T08:44:41 | step: 169500 | train samples/s: 278.3 | train mfu (16-bit): -1.0 | lr mean: 1.4728175301570445e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.25 | consumed tokens: 5554176000.0 | grad norm avg: 1.46 | grad norm last: 1.69 | 
2026-01-02T08:45:09 | step: 169600 | train samples/s: 278.2 | train mfu (16-bit): -1.0 | lr mean: 1.433147787111011e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.24 | consumed tokens: 5557452800.0 | grad norm avg: 1.41 | grad norm last: 1.29 | 
2026-01-02T08:45:37 | step: 169700 | train samples/s: 280.1 | train mfu (16-bit): -1.0 | lr mean: 1.3943022736384592e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.1 | train loss last: 3.19 | consumed tokens: 5560729600.0 | grad norm avg: 1.44 | grad norm last: 1.4 | 
2026-01-02T08:46:05 | step: 169800 | train samples/s: 280.5 | train mfu (16-bit): -1.0 | lr mean: 1.356280989739389e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.03 | consumed tokens: 5564006400.0 | grad norm avg: 1.44 | grad norm last: 1.48 | 
2026-01-02T08:46:33 | step: 169900 | train samples/s: 277.9 | train mfu (16-bit): -1.0 | lr mean: 1.319084361739442e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.89 | consumed tokens: 5567283200.0 | grad norm avg: 1.46 | grad norm last: 1.62 | 
2026-01-02T08:47:01 | step: 170000 | train samples/s: 273.7 | train mfu (16-bit): -1.0 | lr mean: 1.2827123896386183e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.4 | consumed tokens: 5570560000.0 | grad norm avg: 1.4 | grad norm last: 1.4 | 
2026-01-02T08:47:31 | step: 170100 | train samples/s: 275.4 | train mfu (16-bit): -1.0 | lr mean: 1.2471650734369177e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.26 | consumed tokens: 5573836800.0 | grad norm avg: 1.44 | grad norm last: 1.55 | 
2026-01-02T08:47:59 | step: 170200 | train samples/s: 270.1 | train mfu (16-bit): -1.0 | lr mean: 1.2124425552428875e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.11 | consumed tokens: 5577113600.0 | grad norm avg: 1.43 | grad norm last: 1.5 | 
2026-01-02T08:48:28 | step: 170300 | train samples/s: 275.2 | train mfu (16-bit): -1.0 | lr mean: 1.1785451192736218e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.11 | consumed tokens: 5580390400.0 | grad norm avg: 1.44 | grad norm last: 1.6 | 
2026-01-02T08:48:56 | step: 170400 | train samples/s: 275.0 | train mfu (16-bit): -1.0 | lr mean: 1.1454726944748472e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.99 | consumed tokens: 5583667200.0 | grad norm avg: 1.42 | grad norm last: 1.5 | 
2026-01-02T08:49:24 | step: 170500 | train samples/s: 274.0 | train mfu (16-bit): -1.0 | lr mean: 1.1132254940093844e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.41 | consumed tokens: 5586944000.0 | grad norm avg: 1.45 | grad norm last: 1.19 | 
2026-01-02T08:49:52 | step: 170600 | train samples/s: 275.3 | train mfu (16-bit): -1.0 | lr mean: 1.0818036599857805e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.11 | consumed tokens: 5590220800.0 | grad norm avg: 1.43 | grad norm last: 1.44 | 
2026-01-02T08:50:21 | step: 170700 | train samples/s: 271.3 | train mfu (16-bit): -1.0 | lr mean: 1.051207121349762e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.22 | consumed tokens: 5593497600.0 | grad norm avg: 1.4 | grad norm last: 1.5 | 
2026-01-02T08:50:49 | step: 170800 | train samples/s: 270.7 | train mfu (16-bit): -1.0 | lr mean: 1.0214361623184232e-07 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.23 | consumed tokens: 5596774400.0 | grad norm avg: 1.43 | grad norm last: 1.51 | 
2026-01-02T08:51:18 | step: 170900 | train samples/s: 274.9 | train mfu (16-bit): -1.0 | lr mean: 9.92490782891764e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.05 | train loss last: 3.02 | consumed tokens: 5600051200.0 | grad norm avg: 1.41 | grad norm last: 1.38 | 
2026-01-02T08:51:46 | step: 171000 | train samples/s: 275.2 | train mfu (16-bit): -1.0 | lr mean: 9.643711251783316e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.98 | consumed tokens: 5603328000.0 | grad norm avg: 1.4 | grad norm last: 1.45 | 
2026-01-02T08:52:14 | step: 171100 | train samples/s: 274.7 | train mfu (16-bit): -1.0 | lr mean: 9.370772602323996e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.09 | consumed tokens: 5606604800.0 | grad norm avg: 1.43 | grad norm last: 1.31 | 
2026-01-02T08:52:42 | step: 171200 | train samples/s: 274.3 | train mfu (16-bit): -1.0 | lr mean: 9.106092591082415e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.05 | consumed tokens: 5609881600.0 | grad norm avg: 1.38 | grad norm last: 1.43 | 
2026-01-02T08:53:11 | step: 171300 | train samples/s: 274.6 | train mfu (16-bit): -1.0 | lr mean: 8.849672639144046e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.02 | consumed tokens: 5613158400.0 | grad norm avg: 1.43 | grad norm last: 1.59 | 
2026-01-02T08:53:39 | step: 171400 | train samples/s: 273.1 | train mfu (16-bit): -1.0 | lr mean: 8.601513457051624e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.27 | consumed tokens: 5616435200.0 | grad norm avg: 1.4 | grad norm last: 1.37 | 
2026-01-02T08:54:08 | step: 171500 | train samples/s: 268.1 | train mfu (16-bit): -1.0 | lr mean: 8.361615044805149e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.0 | consumed tokens: 5619712000.0 | grad norm avg: 1.45 | grad norm last: 1.33 | 
2026-01-02T08:54:36 | step: 171600 | train samples/s: 274.3 | train mfu (16-bit): -1.0 | lr mean: 8.129978823490092e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.93 | consumed tokens: 5622988800.0 | grad norm avg: 1.43 | grad norm last: 1.43 | 
2026-01-02T08:55:04 | step: 171700 | train samples/s: 274.7 | train mfu (16-bit): -1.0 | lr mean: 7.906606214191925e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.88 | consumed tokens: 5626265600.0 | grad norm avg: 1.39 | grad norm last: 1.41 | 
2026-01-02T08:55:33 | step: 171800 | train samples/s: 274.8 | train mfu (16-bit): -1.0 | lr mean: 7.691497216910648e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.95 | consumed tokens: 5629542400.0 | grad norm avg: 1.41 | grad norm last: 1.36 | 
2026-01-02T08:56:01 | step: 171900 | train samples/s: 274.9 | train mfu (16-bit): -1.0 | lr mean: 7.484651831646261e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.44 | consumed tokens: 5632819200.0 | grad norm avg: 1.36 | grad norm last: 1.25 | 
2026-01-02T08:56:29 | step: 172000 | train samples/s: 273.2 | train mfu (16-bit): -1.0 | lr mean: 7.286072190026971e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.05 | train loss last: 2.96 | consumed tokens: 5636096000.0 | grad norm avg: 1.39 | grad norm last: 1.46 | 
2026-01-02T08:56:58 | step: 172100 | train samples/s: 272.8 | train mfu (16-bit): -1.0 | lr mean: 7.095758292052778e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 3.28 | consumed tokens: 5639372800.0 | grad norm avg: 1.39 | grad norm last: 1.45 | 
2026-01-02T08:57:26 | step: 172200 | train samples/s: 268.9 | train mfu (16-bit): -1.0 | lr mean: 6.913710848266419e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.36 | consumed tokens: 5642649600.0 | grad norm avg: 1.37 | grad norm last: 1.31 | 
2026-01-02T08:57:55 | step: 172300 | train samples/s: 275.7 | train mfu (16-bit): -1.0 | lr mean: 6.739930569210628e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 2.87 | consumed tokens: 5645926400.0 | grad norm avg: 1.37 | grad norm last: 1.32 | 
2026-01-02T08:58:23 | step: 172400 | train samples/s: 275.6 | train mfu (16-bit): -1.0 | lr mean: 6.574417454885406e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.89 | consumed tokens: 5649203200.0 | grad norm avg: 1.38 | grad norm last: 1.56 | 
2026-01-02T08:58:51 | step: 172500 | train samples/s: 277.0 | train mfu (16-bit): -1.0 | lr mean: 6.417172926376224e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.09 | consumed tokens: 5652480000.0 | grad norm avg: 1.41 | grad norm last: 1.56 | 
2026-01-02T08:59:19 | step: 172600 | train samples/s: 275.1 | train mfu (16-bit): -1.0 | lr mean: 6.268196273140347e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.44 | consumed tokens: 5655756800.0 | grad norm avg: 1.4 | grad norm last: 1.2 | 
2026-01-02T08:59:47 | step: 172700 | train samples/s: 275.0 | train mfu (16-bit): -1.0 | lr mean: 6.127489626805982e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.09 | train loss last: 2.79 | consumed tokens: 5659033600.0 | grad norm avg: 1.37 | grad norm last: 1.4 | 
2026-01-02T09:00:15 | step: 172800 | train samples/s: 274.7 | train mfu (16-bit): -1.0 | lr mean: 5.995052276830393e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.15 | consumed tokens: 5662310400.0 | grad norm avg: 1.39 | grad norm last: 1.46 | 
2026-01-02T09:00:44 | step: 172900 | train samples/s: 270.1 | train mfu (16-bit): -1.0 | lr mean: 5.870884578484947e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.34 | consumed tokens: 5665587200.0 | grad norm avg: 1.37 | grad norm last: 1.25 | 
2026-01-02T09:01:12 | step: 173000 | train samples/s: 273.7 | train mfu (16-bit): -1.0 | lr mean: 5.7549875975837494e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.12 | consumed tokens: 5668864000.0 | grad norm avg: 1.37 | grad norm last: 1.39 | 
2026-01-02T09:01:41 | step: 173100 | train samples/s: 275.7 | train mfu (16-bit): -1.0 | lr mean: 5.647361334126799e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.07 | consumed tokens: 5672140800.0 | grad norm avg: 1.39 | grad norm last: 1.28 | 
2026-01-02T09:02:09 | step: 173200 | train samples/s: 275.7 | train mfu (16-bit): -1.0 | lr mean: 5.548006498656832e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.2 | consumed tokens: 5675417600.0 | grad norm avg: 1.45 | grad norm last: 1.46 | 
2026-01-02T09:02:37 | step: 173300 | train samples/s: 275.4 | train mfu (16-bit): -1.0 | lr mean: 5.4569230911738487e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 3.04 | consumed tokens: 5678694400.0 | grad norm avg: 1.4 | grad norm last: 1.43 | 
2026-01-02T09:03:05 | step: 173400 | train samples/s: 273.4 | train mfu (16-bit): -1.0 | lr mean: 5.374111466949216e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.47 | consumed tokens: 5681971200.0 | grad norm avg: 1.41 | grad norm last: 1.42 | 
2026-01-02T09:03:34 | step: 173500 | train samples/s: 271.7 | train mfu (16-bit): -1.0 | lr mean: 5.299571981254303e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.85 | consumed tokens: 5685248000.0 | grad norm avg: 1.42 | grad norm last: 1.41 | 
2026-01-02T09:04:02 | step: 173600 | train samples/s: 273.8 | train mfu (16-bit): -1.0 | lr mean: 5.2333049893604766e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.85 | consumed tokens: 5688524800.0 | grad norm avg: 1.33 | grad norm last: 1.3 | 
2026-01-02T09:04:30 | step: 173700 | train samples/s: 272.1 | train mfu (16-bit): -1.0 | lr mean: 5.175310491267737e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.24 | consumed tokens: 5691801600.0 | grad norm avg: 1.36 | grad norm last: 1.38 | 
2026-01-02T09:04:59 | step: 173800 | train samples/s: 275.6 | train mfu (16-bit): -1.0 | lr mean: 5.125588842247453e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.01 | consumed tokens: 5695078400.0 | grad norm avg: 1.35 | grad norm last: 1.29 | 
2026-01-02T09:05:27 | step: 173900 | train samples/s: 275.8 | train mfu (16-bit): -1.0 | lr mean: 5.084139687028255e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.06 | train loss last: 2.99 | consumed tokens: 5698355200.0 | grad norm avg: 1.39 | grad norm last: 1.31 | 
2026-01-02T09:05:55 | step: 174000 | train samples/s: 275.6 | train mfu (16-bit): -1.0 | lr mean: 5.050964091424248e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.8 | consumed tokens: 5701632000.0 | grad norm avg: 1.41 | grad norm last: 1.29 | 
2026-01-02T09:06:23 | step: 174100 | train samples/s: 274.6 | train mfu (16-bit): -1.0 | lr mean: 5.026061344892696e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.07 | train loss last: 3.12 | consumed tokens: 5704908800.0 | grad norm avg: 1.34 | grad norm last: 1.3 | 
2026-01-02T09:06:52 | step: 174200 | train samples/s: 271.3 | train mfu (16-bit): -1.0 | lr mean: 5.0094321579763346e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 3.5 | consumed tokens: 5708185600.0 | grad norm avg: 1.35 | grad norm last: 1.4 | 
2026-01-02T09:07:20 | step: 174300 | train samples/s: 275.9 | train mfu (16-bit): -1.0 | lr mean: 5.001075820132428e-08 | peak memory rank 0 (MB): 2511.46 | train loss avg: 3.08 | train loss last: 2.78 | consumed tokens: 5711462400.0 | grad norm avg: 1.44 | grad norm last: 1.47 | 
Training done at 2026-01-02 09:07:35.811015.
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /home/s472389/modalities_test/wandb_storage/wandb/offline-run-20260101_192611-6ti5wxjr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb_storage/wandb/offline-run-20260101_192611-6ti5wxjr/logs[0m
==========================================
Job finished at: Fri Jan  2 09:07:37 AM CET 2026
==========================================
