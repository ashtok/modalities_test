Rank 0 received experiment_id: 2025-12-27__23-05-14_a535941fb82852f1
Instantiated <class 'int'>: settings -> training_target -> num_target_tokens
Instantiated <class 'int'>: settings -> training_target -> num_target_steps -> config -> global_num_tokens
Instantiated <class 'int'>: settings -> training_target -> num_target_steps
Expected `ffn_hidden` to be 4 * `n_embd` (1024), but got `n_embd = 256` and `ffn_hidden = 256`.
Expected `ffn_hidden` to be 4 * `n_embd` (1024), but got `n_embd = 256` and `ffn_hidden = 256`.
Expected `ffn_hidden` to be 4 * `n_embd` (1024), but got `n_embd = 256` and `ffn_hidden = 256`.
Expected `ffn_hidden` to be 4 * `n_embd` (1024), but got `n_embd = 256` and `ffn_hidden = 256`.
Instantiated <class 'modalities.models.gpt2.gpt2_model.GPT2LLM'>: model_raw
Instantiated <class 'modalities.nn.model_initialization.composed_initialization.ModelInitializerWrapper'>: model -> config -> model_initializer
Instantiated <class 'modalities.models.gpt2.gpt2_model.GPT2LLM'>: model
/home/s472389/miniconda3/envs/modalities/lib/python3.11/site-packages/modalities/config/component_factory.py:167: FutureWarning: With version 0.4, we upgraded FSDP to FSDP 2.0. Use get_fsdp_2_wrapped_model(...) and FSDP2WrappedModelConfig instead.
  comp_config = component_config_type(**config_dict, strict=True)
/home/s472389/miniconda3/envs/modalities/lib/python3.11/site-packages/modalities/config/component_factory.py:194: FutureWarning: With version 0.4, we upgraded FSDP to FSDP 2.0. Use GeneralModelFactory.get_fsdp2_wrapped_model(...) instead.
  component = component_type(**component_config_dict)
model_factory - INFO - Rank 0 unsharded number of parameters: 27602432

Wrapped layer classes: [<class 'modalities.models.gpt2.gpt2_model.GPT2Block'>]

/home/s472389/miniconda3/envs/modalities/lib/python3.11/site-packages/torch/distributed/fsdp/_init_utils.py:430: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.
  warnings.warn(
model_factory - INFO - Rank 0 sharded number of parameters: 27602432
INFO:model_factory:Rank 0 sharded number of parameters: 27602432
Instantiated <class 'torch.distributed.fsdp.fully_sharded_data_parallel.FullyShardedDataParallel'>: wrapped_model
=> optimizer groups:
linear (57 modules with 14,720,000 parameters): weight_decay = 0.1
embedding (1 modules with 12,877,824 parameters): weight_decay = 0.0
layernorm (18 modules with 4,608 parameters): weight_decay = 0.0
=> all (76 modules with 27,602,432 parameters)
Instantiated <class 'torch.optim.adamw.AdamW'>: optimizer
Instantiated <class 'int'>: lr_scheduler -> config -> total_steps -> config -> global_num_tokens
Instantiated <class 'int'>: lr_scheduler -> config -> total_steps
Instantiated <class 'torch.optim.lr_scheduler.OneCycleLR'>: lr_scheduler
Instantiated <class 'modalities.checkpointing.stateful.app_state.AppState'>: app_state
Instantiated <class 'modalities.loss_functions.CLMCrossEntropyLoss'>: loss_fn
Instantiated <class 'modalities.dataloader.dataset.PackedMemMapDatasetContinuous'>: train_dataset
Instantiated <class 'modalities.dataloader.samplers.ResumableDistributedSampler'>: train_dataloader -> config -> batch_sampler -> config -> sampler
Instantiated <class 'torch.utils.data.sampler.BatchSampler'>: train_dataloader -> config -> batch_sampler
Instantiated <class 'modalities.models.gpt2.collator.GPT2LLMCollateFn'>: collate_fn
Instantiated <class 'modalities.dataloader.dataloader.LLMDataLoader'>: train_dataloader
Instantiated <class 'int'>: progress_subscriber -> config -> num_target_steps -> config -> global_num_tokens
Instantiated <class 'int'>: progress_subscriber -> config -> num_target_steps
Instantiated <class 'modalities.logging_broker.subscriber_impl.progress_subscriber.RichProgressSubscriber'>: progress_subscriber
wandb: Tracking run with wandb version 0.23.1
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /home/s472389/modalities_test/wandb_storage/wandb/offline-run-20251227_230515-l3fzp0zw
Instantiated <class 'modalities.logging_broker.subscriber_impl.results_subscriber.WandBEvaluationResultSubscriber'>: evaluation_subscriber
Instantiated <class 'modalities.checkpointing.checkpoint_saving_strategies.SaveKMostRecentCheckpointsStrategy'>: checkpoint_saving -> config -> checkpoint_saving_strategy
Instantiated <class 'modalities.checkpointing.fsdp.fsdp_checkpoint_saving.FSDP1CheckpointSaving'>: checkpoint_saving -> config -> checkpoint_saving_execution
Instantiated <class 'modalities.checkpointing.checkpoint_saving.CheckpointSaving'>: checkpoint_saving
Instantiated <class 'modalities.training.gradient_clipping.fsdp_gradient_clipper.FSDP1GradientClipper'>: gradient_clipper
/home/s472389/miniconda3/envs/modalities/lib/python3.11/site-packages/modalities/utils/mfu.py:133: UserWarning: Could not get theoretical GPU peak performance for unknown device = NVIDIA L40S.
  warnings.warn(f"Could not get theoretical GPU peak performance for unknown device = {device_name}.")
Instantiated <class 'modalities.utils.mfu.GPT2MFUCalculator'>: mfu_calculator
/home/s472389/miniconda3/envs/modalities/lib/python3.11/site-packages/modalities/util.py:38: UserWarning: [91m Last step will not be logged. Since remaining_steps (1023268) is not a multiple of training_log_interval_in_steps (100) [00m
  warnings.warn(message_with_color_code)
/home/s472389/miniconda3/envs/modalities/lib/python3.11/site-packages/modalities/util.py:38: UserWarning: [91m Last step will not be evaluated. Since remaining_steps (1023268) is not a multiple of evaluation_interval_in_steps (1000) [00m
  warnings.warn(message_with_color_code)
/home/s472389/miniconda3/envs/modalities/lib/python3.11/site-packages/modalities/util.py:38: UserWarning: [91m Last step will not be checkpointed. Since remaining_steps (1023268) is not a multiple of checkpointing_interval_in_steps (2000) [00m
  warnings.warn(message_with_color_code)
/home/s472389/miniconda3/envs/modalities/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
  warnings.warn(  # warn only once
main - INFO - Training model with 27602432 parameters.
INFO:main:Training model with 27602432 parameters.
Model initialized at 2025-12-27 23:05:16.040554.



======================== Training Report ========================
Training target: 
	num_target_tokens: 523913216
	num_target_steps: 1023268 
Intervals: 
	training_log_interval_in_steps: 100
	checkpointing_interval_in_steps: 2000
	evaluation_interval_in_steps: 1000
Step profile: 
	gradient_accumulation_steps: 1
	local_train_micro_batch_size: 2
	sequence_length: 256
	dp_degree: 1
CUDA environment settings: 
	local_rank: 0
	world_size: 1
	global_rank: 0
Consistency enforcement: 
	enforce_tokens_per_step_consistency: True
	enforce_last_step_logged: False
	enforce_last_step_evaluated: False
	enforce_last_step_checkpointed: False
Training progress: 
	global_num_seen_tokens: 0
	num_seen_steps: 0
	num_seen_samples: 0
	last_step: -1
Warnings: 
	[38;5;214mNumber of tokens in the dataset (523913472) does not match the number of target tokens (523913216). Missing 0.00% of tokens in the dataset.
	Last step will not be logged. Since remaining_steps (1023268) is not a multiple of training_log_interval_in_steps (100).
	Last step will not be evaluated. Since remaining_steps (1023268) is not a multiple of evaluation_interval_in_steps (1000).
	Last step will not be checkpointed. Since remaining_steps (1023268) is not a multiple of checkpointing_interval_in_steps (2000). [0m 
====================================================================



Start model training at 2025-12-27 23:05:16.040948.
2025-12-27T23:05:19 | step: 100 | train samples/s: 69.2 | train mfu (16-bit): -1.0 | lr mean: 1.00212109828135e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 10.69 | train loss last: 10.5 | consumed tokens: 51200.0 | grad norm avg: 5.75 | grad norm last: 3.64 | 
2025-12-27T23:05:21 | step: 200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0084822861244902e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 10.32 | train loss last: 10.19 | consumed tokens: 102400.0 | grad norm avg: 2.7 | grad norm last: 2.38 | 
2025-12-27T23:05:23 | step: 300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 1.0190776265517343e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 10.0 | train loss last: 9.81 | consumed tokens: 153600.0 | grad norm avg: 2.07 | grad norm last: 1.99 | 
2025-12-27T23:05:25 | step: 400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 1.0338971151213627e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 9.68 | train loss last: 9.44 | consumed tokens: 204800.0 | grad norm avg: 1.92 | grad norm last: 1.82 | 
2025-12-27T23:05:27 | step: 500 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 1.0529267456149682e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 9.35 | train loss last: 9.19 | consumed tokens: 256000.0 | grad norm avg: 1.82 | grad norm last: 1.59 | 
2025-12-27T23:05:29 | step: 600 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 1.076148691936396e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 9.01 | train loss last: 8.75 | consumed tokens: 307200.0 | grad norm avg: 1.8 | grad norm last: 1.66 | 
2025-12-27T23:05:31 | step: 700 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 1.1035408533643931e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 8.67 | train loss last: 8.44 | consumed tokens: 358400.0 | grad norm avg: 1.74 | grad norm last: 2.0 | 
2025-12-27T23:05:33 | step: 800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 1.1350776730978396e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 8.38 | train loss last: 8.31 | consumed tokens: 409600.0 | grad norm avg: 1.74 | grad norm last: 1.76 | 
2025-12-27T23:05:35 | step: 900 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 1.1707292287610471e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 8.11 | train loss last: 8.19 | consumed tokens: 460800.0 | grad norm avg: 1.76 | grad norm last: 2.38 | 
2025-12-27T23:05:37 | step: 1000 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 1.2104620509489905e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 7.83 | train loss last: 7.84 | consumed tokens: 512000.0 | grad norm avg: 1.76 | grad norm last: 1.62 | 
2025-12-27T23:05:39 | step: 1100 | train samples/s: 108.2 | train mfu (16-bit): -1.0 | lr mean: 1.2542385775304865e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 7.52 | train loss last: 7.44 | consumed tokens: 563200.0 | grad norm avg: 1.73 | grad norm last: 1.68 | 
2025-12-27T23:05:41 | step: 1200 | train samples/s: 108.2 | train mfu (16-bit): -1.0 | lr mean: 1.3020174264966045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 7.39 | train loss last: 6.97 | consumed tokens: 614400.0 | grad norm avg: 1.74 | grad norm last: 1.55 | 
2025-12-27T23:05:43 | step: 1300 | train samples/s: 108.1 | train mfu (16-bit): -1.0 | lr mean: 1.353753759758547e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 7.14 | train loss last: 6.75 | consumed tokens: 665600.0 | grad norm avg: 1.74 | grad norm last: 1.64 | 
2025-12-27T23:05:45 | step: 1400 | train samples/s: 108.1 | train mfu (16-bit): -1.0 | lr mean: 1.409398828400299e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 7.07 | train loss last: 6.97 | consumed tokens: 716800.0 | grad norm avg: 1.8 | grad norm last: 1.94 | 
2025-12-27T23:05:47 | step: 1500 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 1.468900063628098e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 6.96 | train loss last: 7.03 | consumed tokens: 768000.0 | grad norm avg: 1.95 | grad norm last: 1.96 | 
2025-12-27T23:05:49 | step: 1600 | train samples/s: 108.2 | train mfu (16-bit): -1.0 | lr mean: 1.5322013496188447e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 6.88 | train loss last: 6.94 | consumed tokens: 819200.0 | grad norm avg: 2.11 | grad norm last: 2.11 | 
2025-12-27T23:05:51 | step: 1700 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 1.599243114469573e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 6.8 | train loss last: 6.78 | consumed tokens: 870400.0 | grad norm avg: 2.44 | grad norm last: 2.47 | 
2025-12-27T23:05:53 | step: 1800 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 1.6699621482985094e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 6.75 | train loss last: 6.41 | consumed tokens: 921600.0 | grad norm avg: 2.76 | grad norm last: 3.02 | 
2025-12-27T23:05:55 | step: 1900 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 1.744291694194544e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 6.68 | train loss last: 6.47 | consumed tokens: 972800.0 | grad norm avg: 3.34 | grad norm last: 2.64 | 
2025-12-27T23:05:57 | step: 2000 | train samples/s: 108.2 | train mfu (16-bit): -1.0 | lr mean: 1.8221617210656404e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 6.54 | train loss last: 6.44 | consumed tokens: 1024000.0 | grad norm avg: 3.51 | grad norm last: 3.1 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
/home/s472389/miniconda3/envs/modalities/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:675: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/home/s472389/miniconda3/envs/modalities/lib/python3.11/site-packages/torch/distributed/fsdp/_state_dict_utils.py:763: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict will be returned.
  warnings.warn(
/home/s472389/miniconda3/envs/modalities/lib/python3.11/site-packages/torch/distributed/fsdp/_state_dict_utils.py:701: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict will be returned.
  warnings.warn(
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_2000-seen_tokens_1024000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_2000-seen_tokens_1024000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_2000-seen_tokens_1024000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_2000-seen_tokens_1024000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_2000-seen_tokens_1024000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_2000-seen_tokens_1024000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_2000-seen_tokens_1024000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_2000-seen_tokens_1024000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
/home/s472389/miniconda3/envs/modalities/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
  warnings.warn(  # warn only once
2025-12-27T23:06:00 | step: 2100 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 1.9034987417398952e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 6.48 | train loss last: 6.28 | consumed tokens: 1075200.0 | grad norm avg: 3.68 | grad norm last: 3.6 | 
2025-12-27T23:06:02 | step: 2200 | train samples/s: 108.1 | train mfu (16-bit): -1.0 | lr mean: 1.9882263586623594e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 6.48 | train loss last: 6.44 | consumed tokens: 1126400.0 | grad norm avg: 4.16 | grad norm last: 5.14 | 
2025-12-27T23:06:04 | step: 2300 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 2.0762643544003367e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 6.42 | train loss last: 6.5 | consumed tokens: 1177600.0 | grad norm avg: 4.88 | grad norm last: 4.72 | 
2025-12-27T23:06:06 | step: 2400 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 2.1675301468349062e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 6.31 | train loss last: 5.88 | consumed tokens: 1228800.0 | grad norm avg: 4.54 | grad norm last: 5.56 | 
2025-12-27T23:06:08 | step: 2500 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 2.261937152070459e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 6.34 | train loss last: 6.47 | consumed tokens: 1280000.0 | grad norm avg: 5.02 | grad norm last: 4.51 | 
2025-12-27T23:06:10 | step: 2600 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 2.359396603424102e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 6.24 | train loss last: 6.12 | consumed tokens: 1331200.0 | grad norm avg: 5.11 | grad norm last: 4.58 | 
2025-12-27T23:06:12 | step: 2700 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 2.459817005728837e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 6.19 | train loss last: 5.97 | consumed tokens: 1382400.0 | grad norm avg: 4.99 | grad norm last: 4.44 | 
2025-12-27T23:06:14 | step: 2800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 2.5631030439399183e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 6.11 | train loss last: 5.53 | consumed tokens: 1433600.0 | grad norm avg: 5.19 | grad norm last: 4.81 | 
2025-12-27T23:06:16 | step: 2900 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 2.669157947821077e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 6.02 | train loss last: 6.09 | consumed tokens: 1484800.0 | grad norm avg: 5.09 | grad norm last: 4.24 | 
2025-12-27T23:06:18 | step: 3000 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 2.7778813091572374e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.95 | train loss last: 5.66 | consumed tokens: 1536000.0 | grad norm avg: 4.66 | grad norm last: 3.75 | 
2025-12-27T23:06:20 | step: 3100 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 2.8891709007439204e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.84 | train loss last: 5.72 | consumed tokens: 1587200.0 | grad norm avg: 4.68 | grad norm last: 4.32 | 
2025-12-27T23:06:22 | step: 3200 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 3.0029217668925412e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.91 | train loss last: 6.16 | consumed tokens: 1638400.0 | grad norm avg: 5.2 | grad norm last: 6.16 | 
2025-12-27T23:06:24 | step: 3300 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 3.119026587228291e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.87 | train loss last: 5.75 | consumed tokens: 1689600.0 | grad norm avg: 5.58 | grad norm last: 4.7 | 
2025-12-27T23:06:26 | step: 3400 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 3.2373758585890755e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.74 | train loss last: 6.75 | consumed tokens: 1740800.0 | grad norm avg: 4.99 | grad norm last: 8.4 | 
2025-12-27T23:06:28 | step: 3500 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 3.357858076924458e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.72 | train loss last: 5.62 | consumed tokens: 1792000.0 | grad norm avg: 4.83 | grad norm last: 6.12 | 
2025-12-27T23:06:30 | step: 3600 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 3.4803597372956574e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.77 | train loss last: 5.38 | consumed tokens: 1843200.0 | grad norm avg: 5.18 | grad norm last: 4.43 | 
2025-12-27T23:06:32 | step: 3700 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 3.6047655157744884e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.78 | train loss last: 5.56 | consumed tokens: 1894400.0 | grad norm avg: 5.39 | grad norm last: 4.29 | 
2025-12-27T23:06:34 | step: 3800 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 3.7309575418476015e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.69 | train loss last: 5.28 | consumed tokens: 1945600.0 | grad norm avg: 5.53 | grad norm last: 5.83 | 
2025-12-27T23:06:36 | step: 3900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 3.858817581203766e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.65 | train loss last: 5.69 | consumed tokens: 1996800.0 | grad norm avg: 5.29 | grad norm last: 6.89 | 
2025-12-27T23:06:38 | step: 4000 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 3.988224489148706e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.52 | train loss last: 7.0 | consumed tokens: 2048000.0 | grad norm avg: 5.11 | grad norm last: 7.06 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_4000-seen_tokens_2048000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_4000-seen_tokens_2048000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_4000-seen_tokens_2048000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_4000-seen_tokens_2048000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_4000-seen_tokens_2048000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_4000-seen_tokens_2048000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_4000-seen_tokens_2048000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_4000-seen_tokens_2048000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:06:40 | step: 4100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 4.119056757190265e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.48 | train loss last: 4.91 | consumed tokens: 2099200.0 | grad norm avg: 5.29 | grad norm last: 4.05 | 
2025-12-27T23:06:42 | step: 4200 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 4.251190694049001e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.46 | train loss last: 5.19 | consumed tokens: 2150400.0 | grad norm avg: 5.47 | grad norm last: 5.4 | 
2025-12-27T23:06:44 | step: 4300 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 4.3845018808497116e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.46 | train loss last: 4.84 | consumed tokens: 2201600.0 | grad norm avg: 5.38 | grad norm last: 4.75 | 
2025-12-27T23:06:46 | step: 4400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 4.518864443525672e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.45 | train loss last: 5.38 | consumed tokens: 2252800.0 | grad norm avg: 5.62 | grad norm last: 4.82 | 
2025-12-27T23:06:48 | step: 4500 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 4.654152144212276e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.4 | train loss last: 5.06 | consumed tokens: 2304000.0 | grad norm avg: 5.38 | grad norm last: 5.43 | 
2025-12-27T23:06:50 | step: 4600 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 4.790237289853394e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.38 | train loss last: 5.19 | consumed tokens: 2355200.0 | grad norm avg: 5.66 | grad norm last: 5.22 | 
2025-12-27T23:06:52 | step: 4700 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 4.9269914597971365e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.4 | train loss last: 4.97 | consumed tokens: 2406400.0 | grad norm avg: 5.56 | grad norm last: 5.13 | 
2025-12-27T23:06:54 | step: 4800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 5.064285869593732e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.43 | train loss last: 4.91 | consumed tokens: 2457600.0 | grad norm avg: 5.84 | grad norm last: 4.58 | 
2025-12-27T23:06:56 | step: 4900 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 5.201991007197648e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.29 | train loss last: 5.88 | consumed tokens: 2508800.0 | grad norm avg: 5.68 | grad norm last: 6.54 | 
2025-12-27T23:06:58 | step: 5000 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 5.339976996765472e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.25 | train loss last: 5.38 | consumed tokens: 2560000.0 | grad norm avg: 5.64 | grad norm last: 4.66 | 
2025-12-27T23:07:00 | step: 5100 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 5.47811396245379e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.19 | train loss last: 5.66 | consumed tokens: 2611200.0 | grad norm avg: 5.53 | grad norm last: 6.12 | 
2025-12-27T23:07:02 | step: 5200 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 5.616271300823428e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.13 | train loss last: 4.41 | consumed tokens: 2662400.0 | grad norm avg: 5.84 | grad norm last: 5.74 | 
2025-12-27T23:07:04 | step: 5300 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 5.754319136030972e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.21 | train loss last: 5.12 | consumed tokens: 2713600.0 | grad norm avg: 5.74 | grad norm last: 6.02 | 
2025-12-27T23:07:06 | step: 5400 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 5.8921275922330096e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.2 | train loss last: 4.88 | consumed tokens: 2764800.0 | grad norm avg: 5.83 | grad norm last: 9.61 | 
2025-12-27T23:07:08 | step: 5500 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 6.029566065990366e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.14 | train loss last: 4.75 | consumed tokens: 2816000.0 | grad norm avg: 5.82 | grad norm last: 5.47 | 
2025-12-27T23:07:10 | step: 5600 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 6.166505045257509e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.24 | train loss last: 5.62 | consumed tokens: 2867200.0 | grad norm avg: 6.06 | grad norm last: 6.03 | 
2025-12-27T23:07:12 | step: 5700 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 6.302816473180428e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.23 | train loss last: 5.25 | consumed tokens: 2918400.0 | grad norm avg: 5.91 | grad norm last: 5.25 | 
2025-12-27T23:07:14 | step: 5800 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 6.438370473915711e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.09 | train loss last: 4.91 | consumed tokens: 2969600.0 | grad norm avg: 5.87 | grad norm last: 5.52 | 
2025-12-27T23:07:16 | step: 5900 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 6.573039718205109e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.06 | train loss last: 5.41 | consumed tokens: 3020800.0 | grad norm avg: 6.06 | grad norm last: 5.78 | 
2025-12-27T23:07:18 | step: 6000 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 6.706697604386136e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.08 | train loss last: 5.5 | consumed tokens: 3072000.0 | grad norm avg: 5.86 | grad norm last: 6.23 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_6000-seen_tokens_3072000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_6000-seen_tokens_3072000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_6000-seen_tokens_3072000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_6000-seen_tokens_3072000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_6000-seen_tokens_3072000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_6000-seen_tokens_3072000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_6000-seen_tokens_3072000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_6000-seen_tokens_3072000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:07:21 | step: 6100 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 6.839218258392066e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 5.05 | train loss last: 4.62 | consumed tokens: 3123200.0 | grad norm avg: 6.05 | grad norm last: 5.13 | 
2025-12-27T23:07:23 | step: 6200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 6.970476533751935e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.04 | train loss last: 4.81 | consumed tokens: 3174400.0 | grad norm avg: 6.31 | grad norm last: 6.33 | 
2025-12-27T23:07:25 | step: 6300 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 7.10034801159054e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.06 | train loss last: 4.69 | consumed tokens: 3225600.0 | grad norm avg: 6.15 | grad norm last: 5.71 | 
2025-12-27T23:07:27 | step: 6400 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 7.228711183415726e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 5.01 | train loss last: 4.84 | consumed tokens: 3276800.0 | grad norm avg: 6.25 | grad norm last: 5.93 | 
2025-12-27T23:07:29 | step: 6500 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 7.355444540735334e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.99 | train loss last: 4.59 | consumed tokens: 3328000.0 | grad norm avg: 6.24 | grad norm last: 5.66 | 
2025-12-27T23:07:31 | step: 6600 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 7.480428757844493e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.94 | train loss last: 5.44 | consumed tokens: 3379200.0 | grad norm avg: 5.98 | grad norm last: 5.78 | 
2025-12-27T23:07:33 | step: 6700 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 7.603546691825613e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.99 | train loss last: 4.91 | consumed tokens: 3430400.0 | grad norm avg: 6.11 | grad norm last: 6.67 | 
2025-12-27T23:07:35 | step: 6800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 7.724681199761108e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.86 | train loss last: 4.28 | consumed tokens: 3481600.0 | grad norm avg: 5.95 | grad norm last: 5.9 | 
2025-12-27T23:07:37 | step: 6900 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 7.843718049116433e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.95 | train loss last: 4.66 | consumed tokens: 3532800.0 | grad norm avg: 6.24 | grad norm last: 6.34 | 
2025-12-27T23:07:39 | step: 7000 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 7.960545917740092e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.96 | train loss last: 4.91 | consumed tokens: 3584000.0 | grad norm avg: 6.13 | grad norm last: 6.11 | 
2025-12-27T23:07:41 | step: 7100 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 8.075054211076349e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.93 | train loss last: 5.06 | consumed tokens: 3635200.0 | grad norm avg: 6.17 | grad norm last: 5.6 | 
2025-12-27T23:07:43 | step: 7200 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 8.187134517356753e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.88 | train loss last: 4.53 | consumed tokens: 3686400.0 | grad norm avg: 6.27 | grad norm last: 6.64 | 
2025-12-27T23:07:45 | step: 7300 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 8.296683517983183e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.95 | train loss last: 4.25 | consumed tokens: 3737600.0 | grad norm avg: 6.2 | grad norm last: 6.19 | 
2025-12-27T23:07:47 | step: 7400 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 8.403593528782949e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.8 | train loss last: 4.69 | consumed tokens: 3788800.0 | grad norm avg: 6.08 | grad norm last: 5.65 | 
2025-12-27T23:07:49 | step: 7500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 8.507767779519781e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.92 | train loss last: 4.16 | consumed tokens: 3840000.0 | grad norm avg: 6.26 | grad norm last: 5.42 | 
2025-12-27T23:07:51 | step: 7600 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 8.609105861978605e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.79 | train loss last: 5.28 | consumed tokens: 3891200.0 | grad norm avg: 5.99 | grad norm last: 6.79 | 
2025-12-27T23:07:53 | step: 7700 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 8.707513916306198e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.77 | train loss last: 4.41 | consumed tokens: 3942400.0 | grad norm avg: 6.05 | grad norm last: 5.14 | 
2025-12-27T23:07:55 | step: 7800 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 8.802898082649335e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.78 | train loss last: 4.72 | consumed tokens: 3993600.0 | grad norm avg: 6.07 | grad norm last: 6.49 | 
2025-12-27T23:07:57 | step: 7900 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 8.895168866729364e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.83 | train loss last: 4.09 | consumed tokens: 4044800.0 | grad norm avg: 6.29 | grad norm last: 5.84 | 
2025-12-27T23:07:59 | step: 8000 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 8.984238229459152e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.68 | train loss last: 5.69 | consumed tokens: 4096000.0 | grad norm avg: 6.25 | grad norm last: 6.7 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_8000-seen_tokens_4096000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_8000-seen_tokens_4096000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_8000-seen_tokens_4096000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_8000-seen_tokens_4096000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_8000-seen_tokens_4096000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_8000-seen_tokens_4096000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_8000-seen_tokens_4096000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_8000-seen_tokens_4096000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:08:01 | step: 8100 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.070022497326136e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.78 | train loss last: 4.91 | consumed tokens: 4147200.0 | grad norm avg: 6.14 | grad norm last: 5.61 | 
2025-12-27T23:08:03 | step: 8200 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.152442362392321e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.74 | train loss last: 4.28 | consumed tokens: 4198400.0 | grad norm avg: 6.3 | grad norm last: 6.21 | 
2025-12-27T23:08:05 | step: 8300 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.231418516719714e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.74 | train loss last: 4.53 | consumed tokens: 4249600.0 | grad norm avg: 6.13 | grad norm last: 5.84 | 
2025-12-27T23:08:07 | step: 8400 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 9.30687747313641e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.64 | train loss last: 3.83 | consumed tokens: 4300800.0 | grad norm avg: 5.98 | grad norm last: 4.89 | 
2025-12-27T23:08:09 | step: 8500 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.378747927257791e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.83 | train loss last: 4.53 | consumed tokens: 4352000.0 | grad norm avg: 6.34 | grad norm last: 5.36 | 
2025-12-27T23:08:11 | step: 8600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.446961485082284e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.72 | train loss last: 4.84 | consumed tokens: 4403200.0 | grad norm avg: 6.17 | grad norm last: 5.73 | 
2025-12-27T23:08:13 | step: 8700 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.511454845778644e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.66 | train loss last: 5.75 | consumed tokens: 4454400.0 | grad norm avg: 6.03 | grad norm last: 6.62 | 
2025-12-27T23:08:15 | step: 8800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.572166163707152e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.7 | train loss last: 4.94 | consumed tokens: 4505600.0 | grad norm avg: 6.2 | grad norm last: 6.53 | 
2025-12-27T23:08:17 | step: 8900 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.629039413994178e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.74 | train loss last: 4.69 | consumed tokens: 4556800.0 | grad norm avg: 6.2 | grad norm last: 5.25 | 
2025-12-27T23:08:19 | step: 9000 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 9.682018571766093e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.64 | train loss last: 4.47 | consumed tokens: 4608000.0 | grad norm avg: 6.25 | grad norm last: 5.05 | 
2025-12-27T23:08:21 | step: 9100 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.731055615702644e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.72 | train loss last: 5.06 | consumed tokens: 4659200.0 | grad norm avg: 6.28 | grad norm last: 11.13 | 
2025-12-27T23:08:23 | step: 9200 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 9.776105434866622e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.68 | train loss last: 4.16 | consumed tokens: 4710400.0 | grad norm avg: 6.03 | grad norm last: 5.41 | 
2025-12-27T23:08:25 | step: 9300 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.817123645916581e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.64 | train loss last: 6.03 | consumed tokens: 4761600.0 | grad norm avg: 5.99 | grad norm last: 7.18 | 
2025-12-27T23:08:27 | step: 9400 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.854071686277166e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.64 | train loss last: 4.66 | consumed tokens: 4812800.0 | grad norm avg: 6.24 | grad norm last: 5.22 | 
2025-12-27T23:08:29 | step: 9500 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.88691535894759e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.53 | train loss last: 4.16 | consumed tokens: 4864000.0 | grad norm avg: 5.95 | grad norm last: 4.75 | 
2025-12-27T23:08:31 | step: 9600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.915623377310112e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.59 | train loss last: 4.06 | consumed tokens: 4915200.0 | grad norm avg: 6.04 | grad norm last: 5.6 | 
2025-12-27T23:08:33 | step: 9700 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.940169547917321e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.69 | train loss last: 4.97 | consumed tokens: 4966400.0 | grad norm avg: 6.22 | grad norm last: 6.17 | 
2025-12-27T23:08:35 | step: 9800 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.96052913251333e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.56 | train loss last: 4.34 | consumed tokens: 5017600.0 | grad norm avg: 5.93 | grad norm last: 5.23 | 
2025-12-27T23:08:37 | step: 9900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.976684668799862e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.7 | train loss last: 5.03 | consumed tokens: 5068800.0 | grad norm avg: 6.04 | grad norm last: 6.57 | 
2025-12-27T23:08:39 | step: 10000 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.988618694478646e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.64 | train loss last: 4.47 | consumed tokens: 5120000.0 | grad norm avg: 6.13 | grad norm last: 5.82 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_10000-seen_tokens_5120000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_10000-seen_tokens_5120000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_10000-seen_tokens_5120000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_10000-seen_tokens_5120000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_10000-seen_tokens_5120000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_10000-seen_tokens_5120000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_10000-seen_tokens_5120000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_10000-seen_tokens_5120000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:08:42 | step: 10100 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.996322478400543e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.64 | train loss last: 4.16 | consumed tokens: 5171200.0 | grad norm avg: 5.97 | grad norm last: 5.87 | 
2025-12-27T23:08:44 | step: 10200 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.999787289416417e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.62 | train loss last: 4.22 | consumed tokens: 5222400.0 | grad norm avg: 5.78 | grad norm last: 5.04 | 
2025-12-27T23:08:46 | step: 10300 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.999999747378752e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.64 | train loss last: 6.5 | consumed tokens: 5273600.0 | grad norm avg: 5.95 | grad norm last: 9.02 | 
2025-12-27T23:08:48 | step: 10400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.999999747378752e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.57 | train loss last: 3.98 | consumed tokens: 5324800.0 | grad norm avg: 5.81 | grad norm last: 4.98 | 
2025-12-27T23:08:50 | step: 10500 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999998292187229e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.56 | train loss last: 4.41 | consumed tokens: 5376000.0 | grad norm avg: 5.98 | grad norm last: 5.47 | 
2025-12-27T23:08:52 | step: 10600 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999996836995706e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.71 | train loss last: 4.69 | consumed tokens: 5427200.0 | grad norm avg: 6.01 | grad norm last: 6.08 | 
2025-12-27T23:08:54 | step: 10700 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999995381804183e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.59 | train loss last: 4.34 | consumed tokens: 5478400.0 | grad norm avg: 6.0 | grad norm last: 5.74 | 
2025-12-27T23:08:56 | step: 10800 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.999992471421137e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.59 | train loss last: 4.5 | consumed tokens: 5529600.0 | grad norm avg: 6.19 | grad norm last: 5.16 | 
2025-12-27T23:08:58 | step: 10900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.999991016229615e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.64 | train loss last: 4.44 | consumed tokens: 5580800.0 | grad norm avg: 6.08 | grad norm last: 5.63 | 
2025-12-27T23:09:00 | step: 11000 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.999986650655046e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.54 | train loss last: 3.84 | consumed tokens: 5632000.0 | grad norm avg: 5.85 | grad norm last: 5.64 | 
2025-12-27T23:09:02 | step: 11100 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.999983740272e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.63 | train loss last: 4.06 | consumed tokens: 5683200.0 | grad norm avg: 6.13 | grad norm last: 5.32 | 
2025-12-27T23:09:04 | step: 11200 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.999979374697432e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.54 | train loss last: 3.88 | consumed tokens: 5734400.0 | grad norm avg: 5.95 | grad norm last: 6.37 | 
2025-12-27T23:09:06 | step: 11300 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.999975009122863e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.56 | train loss last: 4.16 | consumed tokens: 5785600.0 | grad norm avg: 5.96 | grad norm last: 6.43 | 
2025-12-27T23:09:08 | step: 11400 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.999970643548295e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.46 | train loss last: 4.31 | consumed tokens: 5836800.0 | grad norm avg: 5.89 | grad norm last: 5.9 | 
2025-12-27T23:09:10 | step: 11500 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999965550377965e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.55 | train loss last: 5.59 | consumed tokens: 5888000.0 | grad norm avg: 6.19 | grad norm last: 8.28 | 
2025-12-27T23:09:12 | step: 11600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.999959729611874e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.41 | train loss last: 4.16 | consumed tokens: 5939200.0 | grad norm avg: 5.86 | grad norm last: 5.2 | 
2025-12-27T23:09:14 | step: 11700 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999953181250021e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.49 | train loss last: 4.91 | consumed tokens: 5990400.0 | grad norm avg: 5.88 | grad norm last: 5.79 | 
2025-12-27T23:09:16 | step: 11800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.999945905292407e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.53 | train loss last: 3.98 | consumed tokens: 6041600.0 | grad norm avg: 6.02 | grad norm last: 6.08 | 
2025-12-27T23:09:18 | step: 11900 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.999940084526315e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.52 | train loss last: 4.06 | consumed tokens: 6092800.0 | grad norm avg: 5.89 | grad norm last: 5.01 | 
2025-12-27T23:09:20 | step: 12000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999932808568701e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.55 | train loss last: 4.47 | consumed tokens: 6144000.0 | grad norm avg: 5.92 | grad norm last: 6.44 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_12000-seen_tokens_6144000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_12000-seen_tokens_6144000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_12000-seen_tokens_6144000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_12000-seen_tokens_6144000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_12000-seen_tokens_6144000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_12000-seen_tokens_6144000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_12000-seen_tokens_6144000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_12000-seen_tokens_6144000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:09:22 | step: 12100 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.999924805015326e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.54 | train loss last: 5.0 | consumed tokens: 6195200.0 | grad norm avg: 5.97 | grad norm last: 5.95 | 
2025-12-27T23:09:24 | step: 12200 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999916073866189e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.48 | train loss last: 4.25 | consumed tokens: 6246400.0 | grad norm avg: 5.86 | grad norm last: 7.1 | 
2025-12-27T23:09:26 | step: 12300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999907342717052e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.51 | train loss last: 4.19 | consumed tokens: 6297600.0 | grad norm avg: 5.94 | grad norm last: 6.59 | 
2025-12-27T23:09:28 | step: 12400 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 9.999898611567914e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.6 | train loss last: 4.31 | consumed tokens: 6348800.0 | grad norm avg: 5.89 | grad norm last: 5.13 | 
2025-12-27T23:09:30 | step: 12500 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.999887697631493e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.57 | train loss last: 4.25 | consumed tokens: 6400000.0 | grad norm avg: 5.95 | grad norm last: 6.02 | 
2025-12-27T23:09:32 | step: 12600 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.999878966482356e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.43 | train loss last: 4.5 | consumed tokens: 6451200.0 | grad norm avg: 6.16 | grad norm last: 5.78 | 
2025-12-27T23:09:34 | step: 12700 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999868780141696e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.51 | train loss last: 3.75 | consumed tokens: 6502400.0 | grad norm avg: 6.27 | grad norm last: 6.92 | 
2025-12-27T23:09:36 | step: 12800 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.999857138609514e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.46 | train loss last: 4.47 | consumed tokens: 6553600.0 | grad norm avg: 6.12 | grad norm last: 7.33 | 
2025-12-27T23:09:38 | step: 12900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999846224673092e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.44 | train loss last: 4.44 | consumed tokens: 6604800.0 | grad norm avg: 5.75 | grad norm last: 5.69 | 
2025-12-27T23:09:40 | step: 13000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999833855545148e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.4 | train loss last: 3.95 | consumed tokens: 6656000.0 | grad norm avg: 5.74 | grad norm last: 5.4 | 
2025-12-27T23:09:42 | step: 13100 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999822214012966e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.33 | train loss last: 4.22 | consumed tokens: 6707200.0 | grad norm avg: 5.91 | grad norm last: 6.19 | 
2025-12-27T23:09:44 | step: 13200 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 9.99980911728926e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.47 | train loss last: 4.12 | consumed tokens: 6758400.0 | grad norm avg: 5.88 | grad norm last: 4.83 | 
2025-12-27T23:09:46 | step: 13300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999796020565554e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.53 | train loss last: 4.03 | consumed tokens: 6809600.0 | grad norm avg: 6.06 | grad norm last: 6.65 | 
2025-12-27T23:09:48 | step: 13400 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.999782923841849e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.38 | train loss last: 4.41 | consumed tokens: 6860800.0 | grad norm avg: 5.75 | grad norm last: 5.93 | 
2025-12-27T23:09:50 | step: 13500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.999769827118143e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.49 | train loss last: 4.12 | consumed tokens: 6912000.0 | grad norm avg: 5.91 | grad norm last: 5.73 | 
2025-12-27T23:09:52 | step: 13600 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.999753820011392e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.55 | train loss last: 4.16 | consumed tokens: 6963200.0 | grad norm avg: 5.85 | grad norm last: 5.46 | 
2025-12-27T23:09:54 | step: 13700 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.999740723287687e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.47 | train loss last: 4.66 | consumed tokens: 7014400.0 | grad norm avg: 6.01 | grad norm last: 7.82 | 
2025-12-27T23:09:56 | step: 13800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999724716180936e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.45 | train loss last: 4.44 | consumed tokens: 7065600.0 | grad norm avg: 6.17 | grad norm last: 6.63 | 
2025-12-27T23:09:58 | step: 13900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999708709074184e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.43 | train loss last: 3.95 | consumed tokens: 7116800.0 | grad norm avg: 5.87 | grad norm last: 5.8 | 
2025-12-27T23:10:00 | step: 14000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999692701967433e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.48 | train loss last: 4.56 | consumed tokens: 7168000.0 | grad norm avg: 6.02 | grad norm last: 5.74 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_14000-seen_tokens_7168000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_14000-seen_tokens_7168000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_14000-seen_tokens_7168000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_14000-seen_tokens_7168000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_14000-seen_tokens_7168000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_14000-seen_tokens_7168000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_14000-seen_tokens_7168000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_14000-seen_tokens_7168000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:10:02 | step: 14100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.999676694860682e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.48 | train loss last: 4.66 | consumed tokens: 7219200.0 | grad norm avg: 5.82 | grad norm last: 6.74 | 
2025-12-27T23:10:04 | step: 14200 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999659232562408e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.42 | train loss last: 4.31 | consumed tokens: 7270400.0 | grad norm avg: 5.82 | grad norm last: 5.15 | 
2025-12-27T23:10:06 | step: 14300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999641770264134e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.47 | train loss last: 3.98 | consumed tokens: 7321600.0 | grad norm avg: 5.92 | grad norm last: 5.84 | 
2025-12-27T23:10:08 | step: 14400 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.99962430796586e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.44 | train loss last: 4.81 | consumed tokens: 7372800.0 | grad norm avg: 5.98 | grad norm last: 6.02 | 
2025-12-27T23:10:10 | step: 14500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.999606845667586e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.36 | train loss last: 4.25 | consumed tokens: 7424000.0 | grad norm avg: 5.95 | grad norm last: 4.85 | 
2025-12-27T23:10:12 | step: 14600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.999587200582027e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.52 | train loss last: 4.06 | consumed tokens: 7475200.0 | grad norm avg: 6.12 | grad norm last: 5.31 | 
2025-12-27T23:10:14 | step: 14700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.999567555496469e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.46 | train loss last: 6.19 | consumed tokens: 7526400.0 | grad norm avg: 5.87 | grad norm last: 8.91 | 
2025-12-27T23:10:16 | step: 14800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.999548638006672e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.46 | train loss last: 4.72 | consumed tokens: 7577600.0 | grad norm avg: 5.92 | grad norm last: 5.8 | 
2025-12-27T23:10:18 | step: 14900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.999528265325353e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.41 | train loss last: 4.34 | consumed tokens: 7628800.0 | grad norm avg: 6.07 | grad norm last: 5.28 | 
2025-12-27T23:10:20 | step: 15000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.999507892644033e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.5 | train loss last: 6.53 | consumed tokens: 7680000.0 | grad norm avg: 6.03 | grad norm last: 6.92 | 
2025-12-27T23:10:22 | step: 15100 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.999487519962713e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.45 | train loss last: 3.86 | consumed tokens: 7731200.0 | grad norm avg: 5.82 | grad norm last: 4.92 | 
2025-12-27T23:10:24 | step: 15200 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.99946569208987e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.47 | train loss last: 3.92 | consumed tokens: 7782400.0 | grad norm avg: 6.02 | grad norm last: 5.86 | 
2025-12-27T23:10:26 | step: 15300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999443864217028e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.38 | train loss last: 4.69 | consumed tokens: 7833600.0 | grad norm avg: 5.73 | grad norm last: 5.18 | 
2025-12-27T23:10:28 | step: 15400 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999422036344185e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.42 | train loss last: 4.75 | consumed tokens: 7884800.0 | grad norm avg: 5.88 | grad norm last: 6.7 | 
2025-12-27T23:10:30 | step: 15500 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.99939875327982e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.48 | train loss last: 4.91 | consumed tokens: 7936000.0 | grad norm avg: 5.9 | grad norm last: 5.41 | 
2025-12-27T23:10:32 | step: 15600 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999375470215455e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.44 | train loss last: 4.5 | consumed tokens: 7987200.0 | grad norm avg: 5.87 | grad norm last: 5.18 | 
2025-12-27T23:10:34 | step: 15700 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999352187151089e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.44 | train loss last: 3.91 | consumed tokens: 8038400.0 | grad norm avg: 5.96 | grad norm last: 4.75 | 
2025-12-27T23:10:36 | step: 15800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999328904086724e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.32 | train loss last: 4.5 | consumed tokens: 8089600.0 | grad norm avg: 5.84 | grad norm last: 5.62 | 
2025-12-27T23:10:38 | step: 15900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999304893426597e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.35 | train loss last: 4.22 | consumed tokens: 8140800.0 | grad norm avg: 5.77 | grad norm last: 6.04 | 
2025-12-27T23:10:40 | step: 16000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.99928088276647e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.43 | train loss last: 4.34 | consumed tokens: 8192000.0 | grad norm avg: 5.84 | grad norm last: 5.35 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_16000-seen_tokens_8192000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_16000-seen_tokens_8192000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_16000-seen_tokens_8192000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_16000-seen_tokens_8192000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_16000-seen_tokens_8192000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_16000-seen_tokens_8192000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_16000-seen_tokens_8192000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_16000-seen_tokens_8192000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:10:43 | step: 16100 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.999254689319059e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.41 | train loss last: 5.81 | consumed tokens: 8243200.0 | grad norm avg: 5.86 | grad norm last: 8.37 | 
2025-12-27T23:10:45 | step: 16200 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.99922922346741e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.35 | train loss last: 4.5 | consumed tokens: 8294400.0 | grad norm avg: 5.82 | grad norm last: 6.44 | 
2025-12-27T23:10:47 | step: 16300 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.999203030019999e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.35 | train loss last: 4.0 | consumed tokens: 8345600.0 | grad norm avg: 5.81 | grad norm last: 5.15 | 
2025-12-27T23:10:49 | step: 16400 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999176836572587e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.44 | train loss last: 5.72 | consumed tokens: 8396800.0 | grad norm avg: 5.83 | grad norm last: 6.69 | 
2025-12-27T23:10:51 | step: 16500 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.999149915529415e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.34 | train loss last: 3.8 | consumed tokens: 8448000.0 | grad norm avg: 5.79 | grad norm last: 5.03 | 
2025-12-27T23:10:53 | step: 16600 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 9.999122266890481e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.36 | train loss last: 4.56 | consumed tokens: 8499200.0 | grad norm avg: 6.06 | grad norm last: 5.46 | 
2025-12-27T23:10:55 | step: 16700 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.999094618251547e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.28 | train loss last: 4.31 | consumed tokens: 8550400.0 | grad norm avg: 5.8 | grad norm last: 5.91 | 
2025-12-27T23:10:57 | step: 16800 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 9.999066242016852e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.38 | train loss last: 3.86 | consumed tokens: 8601600.0 | grad norm avg: 5.88 | grad norm last: 4.86 | 
2025-12-27T23:10:59 | step: 16900 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.999037865782157e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.36 | train loss last: 4.06 | consumed tokens: 8652800.0 | grad norm avg: 5.85 | grad norm last: 5.38 | 
2025-12-27T23:11:01 | step: 17000 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.9990087619517e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.43 | train loss last: 4.53 | consumed tokens: 8704000.0 | grad norm avg: 5.99 | grad norm last: 6.33 | 
2025-12-27T23:11:03 | step: 17100 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.998978930525482e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.35 | train loss last: 4.38 | consumed tokens: 8755200.0 | grad norm avg: 5.81 | grad norm last: 5.39 | 
2025-12-27T23:11:05 | step: 17200 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.998949099099264e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.32 | train loss last: 4.5 | consumed tokens: 8806400.0 | grad norm avg: 5.9 | grad norm last: 5.72 | 
2025-12-27T23:11:07 | step: 17300 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.998919995268807e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.39 | train loss last: 4.38 | consumed tokens: 8857600.0 | grad norm avg: 5.94 | grad norm last: 4.96 | 
2025-12-27T23:11:09 | step: 17400 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.998887981055304e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.26 | train loss last: 3.81 | consumed tokens: 8908800.0 | grad norm avg: 5.74 | grad norm last: 5.19 | 
2025-12-27T23:11:11 | step: 17500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.998856694437563e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.31 | train loss last: 4.22 | consumed tokens: 8960000.0 | grad norm avg: 5.78 | grad norm last: 5.56 | 
2025-12-27T23:11:13 | step: 17600 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.998825407819822e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.34 | train loss last: 4.56 | consumed tokens: 9011200.0 | grad norm avg: 5.85 | grad norm last: 5.49 | 
2025-12-27T23:11:15 | step: 17700 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.99879339360632e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.45 | train loss last: 4.22 | consumed tokens: 9062400.0 | grad norm avg: 5.89 | grad norm last: 5.26 | 
2025-12-27T23:11:17 | step: 17800 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.998760651797056e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.37 | train loss last: 5.06 | consumed tokens: 9113600.0 | grad norm avg: 5.85 | grad norm last: 6.35 | 
2025-12-27T23:11:19 | step: 17900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.998727909987792e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.36 | train loss last: 4.22 | consumed tokens: 9164800.0 | grad norm avg: 5.67 | grad norm last: 5.68 | 
2025-12-27T23:11:21 | step: 18000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.998694440582767e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.33 | train loss last: 4.16 | consumed tokens: 9216000.0 | grad norm avg: 5.85 | grad norm last: 6.2 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_18000-seen_tokens_9216000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_18000-seen_tokens_9216000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_18000-seen_tokens_9216000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_18000-seen_tokens_9216000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_18000-seen_tokens_9216000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_18000-seen_tokens_9216000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_18000-seen_tokens_9216000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_18000-seen_tokens_9216000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:11:23 | step: 18100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.998659515986219e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.26 | train loss last: 3.94 | consumed tokens: 9267200.0 | grad norm avg: 5.74 | grad norm last: 5.76 | 
2025-12-27T23:11:25 | step: 18200 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.998626046581194e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.32 | train loss last: 3.77 | consumed tokens: 9318400.0 | grad norm avg: 5.85 | grad norm last: 5.67 | 
2025-12-27T23:11:27 | step: 18300 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.998591121984646e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.33 | train loss last: 3.8 | consumed tokens: 9369600.0 | grad norm avg: 5.78 | grad norm last: 5.5 | 
2025-12-27T23:11:29 | step: 18400 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.998556197388098e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.39 | train loss last: 4.34 | consumed tokens: 9420800.0 | grad norm avg: 5.74 | grad norm last: 5.18 | 
2025-12-27T23:11:31 | step: 18500 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.998519817600027e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.32 | train loss last: 4.16 | consumed tokens: 9472000.0 | grad norm avg: 5.78 | grad norm last: 5.48 | 
2025-12-27T23:11:33 | step: 18600 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 9.998484893003479e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.34 | train loss last: 3.52 | consumed tokens: 9523200.0 | grad norm avg: 5.78 | grad norm last: 6.09 | 
2025-12-27T23:11:35 | step: 18700 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.998448513215408e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.4 | train loss last: 4.19 | consumed tokens: 9574400.0 | grad norm avg: 5.97 | grad norm last: 5.4 | 
2025-12-27T23:11:37 | step: 18800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.998411405831575e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.38 | train loss last: 4.66 | consumed tokens: 9625600.0 | grad norm avg: 5.72 | grad norm last: 5.36 | 
2025-12-27T23:11:39 | step: 18900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.998374298447743e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.36 | train loss last: 5.69 | consumed tokens: 9676800.0 | grad norm avg: 5.89 | grad norm last: 10.35 | 
2025-12-27T23:11:41 | step: 19000 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.998336463468149e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.24 | train loss last: 4.69 | consumed tokens: 9728000.0 | grad norm avg: 5.72 | grad norm last: 5.5 | 
2025-12-27T23:11:43 | step: 19100 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 9.998298628488556e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.32 | train loss last: 4.53 | consumed tokens: 9779200.0 | grad norm avg: 5.71 | grad norm last: 6.34 | 
2025-12-27T23:11:45 | step: 19200 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.998259338317439e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.36 | train loss last: 4.53 | consumed tokens: 9830400.0 | grad norm avg: 5.79 | grad norm last: 5.43 | 
2025-12-27T23:11:47 | step: 19300 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.998221503337845e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.33 | train loss last: 4.41 | consumed tokens: 9881600.0 | grad norm avg: 5.84 | grad norm last: 5.22 | 
2025-12-27T23:11:49 | step: 19400 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.998181485570967e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.35 | train loss last: 4.44 | consumed tokens: 9932800.0 | grad norm avg: 5.81 | grad norm last: 6.43 | 
2025-12-27T23:11:51 | step: 19500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.998141467804089e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.4 | train loss last: 5.0 | consumed tokens: 9984000.0 | grad norm avg: 6.07 | grad norm last: 6.12 | 
2025-12-27T23:11:53 | step: 19600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.99810072244145e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.32 | train loss last: 4.78 | consumed tokens: 10035200.0 | grad norm avg: 5.8 | grad norm last: 5.63 | 
2025-12-27T23:11:55 | step: 19700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.99805997707881e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.31 | train loss last: 4.34 | consumed tokens: 10086400.0 | grad norm avg: 5.71 | grad norm last: 6.85 | 
2025-12-27T23:11:57 | step: 19800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.998019231716171e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.36 | train loss last: 4.12 | consumed tokens: 10137600.0 | grad norm avg: 5.69 | grad norm last: 5.42 | 
2025-12-27T23:11:59 | step: 19900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.99797775875777e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.32 | train loss last: 4.09 | consumed tokens: 10188800.0 | grad norm avg: 5.93 | grad norm last: 5.48 | 
2025-12-27T23:12:01 | step: 20000 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.997936285799369e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.38 | train loss last: 4.69 | consumed tokens: 10240000.0 | grad norm avg: 5.95 | grad norm last: 5.76 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_20000-seen_tokens_10240000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_20000-seen_tokens_10240000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_20000-seen_tokens_10240000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_20000-seen_tokens_10240000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_20000-seen_tokens_10240000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_20000-seen_tokens_10240000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_20000-seen_tokens_10240000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_20000-seen_tokens_10240000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:12:04 | step: 20100 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.997892630053684e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.27 | train loss last: 4.88 | consumed tokens: 10291200.0 | grad norm avg: 5.95 | grad norm last: 6.8 | 
2025-12-27T23:12:06 | step: 20200 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.99784970190376e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.32 | train loss last: 4.53 | consumed tokens: 10342400.0 | grad norm avg: 5.96 | grad norm last: 6.08 | 
2025-12-27T23:12:08 | step: 20300 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.997806773753837e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.4 | train loss last: 4.59 | consumed tokens: 10393600.0 | grad norm avg: 5.81 | grad norm last: 5.73 | 
2025-12-27T23:12:10 | step: 20400 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.997763118008152e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.36 | train loss last: 4.22 | consumed tokens: 10444800.0 | grad norm avg: 5.89 | grad norm last: 5.46 | 
2025-12-27T23:12:12 | step: 20500 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.997718734666705e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.33 | train loss last: 5.62 | consumed tokens: 10496000.0 | grad norm avg: 5.83 | grad norm last: 5.62 | 
2025-12-27T23:12:14 | step: 20600 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.997674351325259e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.29 | train loss last: 4.56 | consumed tokens: 10547200.0 | grad norm avg: 5.74 | grad norm last: 6.03 | 
2025-12-27T23:12:16 | step: 20700 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 9.99762924038805e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.25 | train loss last: 4.59 | consumed tokens: 10598400.0 | grad norm avg: 5.69 | grad norm last: 5.46 | 
2025-12-27T23:12:18 | step: 20800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.99758267425932e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.29 | train loss last: 3.42 | consumed tokens: 10649600.0 | grad norm avg: 5.74 | grad norm last: 6.27 | 
2025-12-27T23:12:20 | step: 20900 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.997537563322112e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.35 | train loss last: 4.09 | consumed tokens: 10700800.0 | grad norm avg: 5.86 | grad norm last: 5.52 | 
2025-12-27T23:12:22 | step: 21000 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.997490997193381e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.29 | train loss last: 4.38 | consumed tokens: 10752000.0 | grad norm avg: 5.78 | grad norm last: 5.84 | 
2025-12-27T23:12:24 | step: 21100 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.99744443106465e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.29 | train loss last: 4.44 | consumed tokens: 10803200.0 | grad norm avg: 5.79 | grad norm last: 5.92 | 
2025-12-27T23:12:26 | step: 21200 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.997396409744397e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.28 | train loss last: 4.03 | consumed tokens: 10854400.0 | grad norm avg: 5.64 | grad norm last: 5.35 | 
2025-12-27T23:12:28 | step: 21300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.997349116019905e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.28 | train loss last: 3.77 | consumed tokens: 10905600.0 | grad norm avg: 5.72 | grad norm last: 5.51 | 
2025-12-27T23:12:30 | step: 21400 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.997301822295412e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.26 | train loss last: 4.06 | consumed tokens: 10956800.0 | grad norm avg: 6.42 | grad norm last: 5.25 | 
2025-12-27T23:12:32 | step: 21500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.997252345783636e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.22 | train loss last: 4.31 | consumed tokens: 11008000.0 | grad norm avg: 5.96 | grad norm last: 6.53 | 
2025-12-27T23:12:34 | step: 21600 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.997203596867621e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.31 | train loss last: 4.56 | consumed tokens: 11059200.0 | grad norm avg: 5.82 | grad norm last: 6.32 | 
2025-12-27T23:12:36 | step: 21700 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.997154120355844e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.24 | train loss last: 4.38 | consumed tokens: 11110400.0 | grad norm avg: 5.89 | grad norm last: 6.28 | 
2025-12-27T23:12:38 | step: 21800 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.997104643844068e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.31 | train loss last: 5.16 | consumed tokens: 11161600.0 | grad norm avg: 5.71 | grad norm last: 5.28 | 
2025-12-27T23:12:40 | step: 21900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.99705443973653e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.15 | train loss last: 3.61 | consumed tokens: 11212800.0 | grad norm avg: 5.77 | grad norm last: 5.35 | 
2025-12-27T23:12:42 | step: 22000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.997003508033231e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.34 | train loss last: 3.88 | consumed tokens: 11264000.0 | grad norm avg: 5.78 | grad norm last: 5.23 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_22000-seen_tokens_11264000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_22000-seen_tokens_11264000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_22000-seen_tokens_11264000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_22000-seen_tokens_11264000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_22000-seen_tokens_11264000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_22000-seen_tokens_11264000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_22000-seen_tokens_11264000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_22000-seen_tokens_11264000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:12:44 | step: 22100 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.996952576329932e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.32 | train loss last: 4.81 | consumed tokens: 11315200.0 | grad norm avg: 5.83 | grad norm last: 6.23 | 
2025-12-27T23:12:46 | step: 22200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.996900917030871e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.3 | train loss last: 3.81 | consumed tokens: 11366400.0 | grad norm avg: 5.73 | grad norm last: 4.8 | 
2025-12-27T23:12:48 | step: 22300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.996848530136049e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.2 | train loss last: 4.34 | consumed tokens: 11417600.0 | grad norm avg: 5.62 | grad norm last: 5.42 | 
2025-12-27T23:12:50 | step: 22400 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.996796143241227e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.27 | train loss last: 5.06 | consumed tokens: 11468800.0 | grad norm avg: 5.83 | grad norm last: 5.67 | 
2025-12-27T23:12:52 | step: 22500 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.996743756346405e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.3 | train loss last: 3.77 | consumed tokens: 11520000.0 | grad norm avg: 5.74 | grad norm last: 5.73 | 
2025-12-27T23:12:54 | step: 22600 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.996690641855821e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.27 | train loss last: 4.44 | consumed tokens: 11571200.0 | grad norm avg: 6.17 | grad norm last: 5.37 | 
2025-12-27T23:12:56 | step: 22700 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.996636799769476e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.26 | train loss last: 3.73 | consumed tokens: 11622400.0 | grad norm avg: 5.69 | grad norm last: 5.39 | 
2025-12-27T23:12:58 | step: 22800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.996581502491608e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.28 | train loss last: 4.47 | consumed tokens: 11673600.0 | grad norm avg: 5.76 | grad norm last: 5.59 | 
2025-12-27T23:13:00 | step: 22900 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.996527660405263e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.22 | train loss last: 4.22 | consumed tokens: 11724800.0 | grad norm avg: 6.01 | grad norm last: 5.1 | 
2025-12-27T23:13:02 | step: 23000 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 9.996472363127396e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.19 | train loss last: 4.53 | consumed tokens: 11776000.0 | grad norm avg: 5.7 | grad norm last: 6.01 | 
2025-12-27T23:13:04 | step: 23100 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.996417065849528e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.22 | train loss last: 4.72 | consumed tokens: 11827200.0 | grad norm avg: 5.68 | grad norm last: 6.79 | 
2025-12-27T23:13:06 | step: 23200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.996360313380137e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.26 | train loss last: 5.47 | consumed tokens: 11878400.0 | grad norm avg: 6.08 | grad norm last: 6.94 | 
2025-12-27T23:13:08 | step: 23300 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 9.996305016102269e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.29 | train loss last: 4.5 | consumed tokens: 11929600.0 | grad norm avg: 5.72 | grad norm last: 6.35 | 
2025-12-27T23:13:10 | step: 23400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.996248263632879e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.33 | train loss last: 4.09 | consumed tokens: 11980800.0 | grad norm avg: 5.74 | grad norm last: 5.48 | 
2025-12-27T23:13:12 | step: 23500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.996190783567727e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.27 | train loss last: 4.34 | consumed tokens: 12032000.0 | grad norm avg: 5.86 | grad norm last: 5.81 | 
2025-12-27T23:13:14 | step: 23600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.996133303502575e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.36 | train loss last: 4.16 | consumed tokens: 12083200.0 | grad norm avg: 5.84 | grad norm last: 4.91 | 
2025-12-27T23:13:16 | step: 23700 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.996075095841661e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.3 | train loss last: 5.94 | consumed tokens: 12134400.0 | grad norm avg: 5.86 | grad norm last: 6.41 | 
2025-12-27T23:13:18 | step: 23800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.996016888180748e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.26 | train loss last: 4.0 | consumed tokens: 12185600.0 | grad norm avg: 5.81 | grad norm last: 5.73 | 
2025-12-27T23:13:20 | step: 23900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.995957952924073e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.22 | train loss last: 4.03 | consumed tokens: 12236800.0 | grad norm avg: 5.78 | grad norm last: 4.78 | 
2025-12-27T23:13:22 | step: 24000 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.995899017667398e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.18 | train loss last: 4.28 | consumed tokens: 12288000.0 | grad norm avg: 5.76 | grad norm last: 5.02 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_24000-seen_tokens_12288000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_24000-seen_tokens_12288000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_24000-seen_tokens_12288000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_24000-seen_tokens_12288000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_24000-seen_tokens_12288000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_24000-seen_tokens_12288000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_24000-seen_tokens_12288000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_24000-seen_tokens_12288000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:13:25 | step: 24100 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.9958386272192e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.24 | train loss last: 4.44 | consumed tokens: 12339200.0 | grad norm avg: 5.94 | grad norm last: 8.42 | 
2025-12-27T23:13:27 | step: 24200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.995778236771002e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.18 | train loss last: 4.12 | consumed tokens: 12390400.0 | grad norm avg: 5.83 | grad norm last: 5.94 | 
2025-12-27T23:13:29 | step: 24300 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.995718573918566e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.2 | train loss last: 3.48 | consumed tokens: 12441600.0 | grad norm avg: 5.74 | grad norm last: 5.93 | 
2025-12-27T23:13:31 | step: 24400 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.995656000683084e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.24 | train loss last: 3.98 | consumed tokens: 12492800.0 | grad norm avg: 5.83 | grad norm last: 5.91 | 
2025-12-27T23:13:33 | step: 24500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.995596337830648e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.23 | train loss last: 3.81 | consumed tokens: 12544000.0 | grad norm avg: 5.73 | grad norm last: 5.18 | 
2025-12-27T23:13:35 | step: 24600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.995533764595166e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.19 | train loss last: 5.12 | consumed tokens: 12595200.0 | grad norm avg: 5.75 | grad norm last: 5.98 | 
2025-12-27T23:13:37 | step: 24700 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.995471191359684e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.22 | train loss last: 4.44 | consumed tokens: 12646400.0 | grad norm avg: 5.77 | grad norm last: 6.75 | 
2025-12-27T23:13:39 | step: 24800 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.99540789052844e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.17 | train loss last: 4.62 | consumed tokens: 12697600.0 | grad norm avg: 5.78 | grad norm last: 6.05 | 
2025-12-27T23:13:41 | step: 24900 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 9.99534604488872e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.34 | train loss last: 5.38 | consumed tokens: 12748800.0 | grad norm avg: 5.85 | grad norm last: 5.73 | 
2025-12-27T23:13:43 | step: 25000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.995282016461715e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.37 | train loss last: 4.62 | consumed tokens: 12800000.0 | grad norm avg: 5.83 | grad norm last: 4.91 | 
2025-12-27T23:13:45 | step: 25100 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.99521798803471e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.18 | train loss last: 4.06 | consumed tokens: 12851200.0 | grad norm avg: 5.68 | grad norm last: 6.3 | 
2025-12-27T23:13:47 | step: 25200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.995152504416183e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.27 | train loss last: 5.47 | consumed tokens: 12902400.0 | grad norm avg: 5.89 | grad norm last: 5.79 | 
2025-12-27T23:13:49 | step: 25300 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.995087748393416e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.21 | train loss last: 3.94 | consumed tokens: 12953600.0 | grad norm avg: 5.8 | grad norm last: 5.0 | 
2025-12-27T23:13:51 | step: 25400 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.995021537179127e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.16 | train loss last: 5.28 | consumed tokens: 13004800.0 | grad norm avg: 5.69 | grad norm last: 6.75 | 
2025-12-27T23:13:53 | step: 25500 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.994956781156361e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.21 | train loss last: 3.89 | consumed tokens: 13056000.0 | grad norm avg: 5.95 | grad norm last: 5.01 | 
2025-12-27T23:13:55 | step: 25600 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.99488984234631e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.14 | train loss last: 4.47 | consumed tokens: 13107200.0 | grad norm avg: 5.78 | grad norm last: 6.51 | 
2025-12-27T23:13:57 | step: 25700 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.994823631132022e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.32 | train loss last: 4.69 | consumed tokens: 13158400.0 | grad norm avg: 6.41 | grad norm last: 5.18 | 
2025-12-27T23:13:59 | step: 25800 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.994756692321971e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.24 | train loss last: 4.22 | consumed tokens: 13209600.0 | grad norm avg: 5.91 | grad norm last: 6.11 | 
2025-12-27T23:14:01 | step: 25900 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.994689025916159e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.26 | train loss last: 4.47 | consumed tokens: 13260800.0 | grad norm avg: 5.8 | grad norm last: 5.62 | 
2025-12-27T23:14:03 | step: 26000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.994619904318824e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.26 | train loss last: 4.38 | consumed tokens: 13312000.0 | grad norm avg: 6.06 | grad norm last: 5.44 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_26000-seen_tokens_13312000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_26000-seen_tokens_13312000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_26000-seen_tokens_13312000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_26000-seen_tokens_13312000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_26000-seen_tokens_13312000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_26000-seen_tokens_13312000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_26000-seen_tokens_13312000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_26000-seen_tokens_13312000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:14:05 | step: 26100 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.994552237913013e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.32 | train loss last: 3.45 | consumed tokens: 13363200.0 | grad norm avg: 6.1 | grad norm last: 5.08 | 
2025-12-27T23:14:07 | step: 26200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.9944845715072e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.14 | train loss last: 5.25 | consumed tokens: 13414400.0 | grad norm avg: 5.71 | grad norm last: 6.01 | 
2025-12-27T23:14:09 | step: 26300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.994414722314104e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.13 | train loss last: 3.94 | consumed tokens: 13465600.0 | grad norm avg: 5.82 | grad norm last: 5.52 | 
2025-12-27T23:14:11 | step: 26400 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.994344873121008e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.33 | train loss last: 3.69 | consumed tokens: 13516800.0 | grad norm avg: 5.86 | grad norm last: 5.26 | 
2025-12-27T23:14:13 | step: 26500 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.994275023927912e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.26 | train loss last: 3.53 | consumed tokens: 13568000.0 | grad norm avg: 5.66 | grad norm last: 5.06 | 
2025-12-27T23:14:15 | step: 26600 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.994203719543293e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.37 | train loss last: 4.84 | consumed tokens: 13619200.0 | grad norm avg: 5.85 | grad norm last: 6.56 | 
2025-12-27T23:14:17 | step: 26700 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.994132415158674e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.17 | train loss last: 3.88 | consumed tokens: 13670400.0 | grad norm avg: 5.77 | grad norm last: 6.06 | 
2025-12-27T23:14:19 | step: 26800 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.994061110774055e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.31 | train loss last: 4.75 | consumed tokens: 13721600.0 | grad norm avg: 5.88 | grad norm last: 6.1 | 
2025-12-27T23:14:21 | step: 26900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.993989806389436e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.25 | train loss last: 3.78 | consumed tokens: 13772800.0 | grad norm avg: 5.86 | grad norm last: 6.04 | 
2025-12-27T23:14:23 | step: 27000 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 9.993917046813294e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.24 | train loss last: 4.44 | consumed tokens: 13824000.0 | grad norm avg: 6.06 | grad norm last: 6.04 | 
2025-12-27T23:14:25 | step: 27100 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.993844287237152e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.22 | train loss last: 4.62 | consumed tokens: 13875200.0 | grad norm avg: 5.84 | grad norm last: 6.41 | 
2025-12-27T23:14:27 | step: 27200 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.993770072469488e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.18 | train loss last: 4.78 | consumed tokens: 13926400.0 | grad norm avg: 5.75 | grad norm last: 5.47 | 
2025-12-27T23:14:29 | step: 27300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.993697312893346e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.19 | train loss last: 3.17 | consumed tokens: 13977600.0 | grad norm avg: 5.8 | grad norm last: 5.47 | 
2025-12-27T23:14:31 | step: 27400 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.993623098125681e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.15 | train loss last: 3.84 | consumed tokens: 14028800.0 | grad norm avg: 5.83 | grad norm last: 5.46 | 
2025-12-27T23:14:33 | step: 27500 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.993548883358017e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.17 | train loss last: 3.36 | consumed tokens: 14080000.0 | grad norm avg: 5.71 | grad norm last: 4.96 | 
2025-12-27T23:14:35 | step: 27600 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.993473213398829e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.17 | train loss last: 4.62 | consumed tokens: 14131200.0 | grad norm avg: 5.95 | grad norm last: 7.65 | 
2025-12-27T23:14:37 | step: 27700 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.993398998631164e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.18 | train loss last: 4.28 | consumed tokens: 14182400.0 | grad norm avg: 5.84 | grad norm last: 5.81 | 
2025-12-27T23:14:39 | step: 27800 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.993321873480454e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.21 | train loss last: 4.06 | consumed tokens: 14233600.0 | grad norm avg: 5.81 | grad norm last: 5.93 | 
2025-12-27T23:14:41 | step: 27900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.993246203521267e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.27 | train loss last: 4.38 | consumed tokens: 14284800.0 | grad norm avg: 5.89 | grad norm last: 5.7 | 
2025-12-27T23:14:43 | step: 28000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.993169805966318e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.16 | train loss last: 4.69 | consumed tokens: 14336000.0 | grad norm avg: 5.83 | grad norm last: 6.04 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_28000-seen_tokens_14336000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_28000-seen_tokens_14336000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_28000-seen_tokens_14336000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_28000-seen_tokens_14336000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_28000-seen_tokens_14336000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_28000-seen_tokens_14336000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_28000-seen_tokens_14336000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_28000-seen_tokens_14336000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:14:45 | step: 28100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.993093408411369e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.18 | train loss last: 3.67 | consumed tokens: 14387200.0 | grad norm avg: 5.88 | grad norm last: 5.39 | 
2025-12-27T23:14:47 | step: 28200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.993015555664897e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.3 | train loss last: 3.89 | consumed tokens: 14438400.0 | grad norm avg: 6.12 | grad norm last: 5.8 | 
2025-12-27T23:14:49 | step: 28300 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.992937702918425e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.3 | train loss last: 5.09 | consumed tokens: 14489600.0 | grad norm avg: 5.94 | grad norm last: 7.13 | 
2025-12-27T23:14:51 | step: 28400 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.992859122576192e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.21 | train loss last: 4.03 | consumed tokens: 14540800.0 | grad norm avg: 6.08 | grad norm last: 6.29 | 
2025-12-27T23:14:53 | step: 28500 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.992780542233959e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.28 | train loss last: 4.22 | consumed tokens: 14592000.0 | grad norm avg: 5.86 | grad norm last: 5.78 | 
2025-12-27T23:14:55 | step: 28600 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.992701234295964e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.35 | train loss last: 4.25 | consumed tokens: 14643200.0 | grad norm avg: 6.07 | grad norm last: 5.79 | 
2025-12-27T23:14:57 | step: 28700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.99262192635797e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.23 | train loss last: 4.0 | consumed tokens: 14694400.0 | grad norm avg: 5.85 | grad norm last: 5.51 | 
2025-12-27T23:14:59 | step: 28800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.992541163228452e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.24 | train loss last: 4.0 | consumed tokens: 14745600.0 | grad norm avg: 5.84 | grad norm last: 5.43 | 
2025-12-27T23:15:01 | step: 28900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.992460400098935e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.22 | train loss last: 3.77 | consumed tokens: 14796800.0 | grad norm avg: 5.89 | grad norm last: 5.04 | 
2025-12-27T23:15:03 | step: 29000 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.992378909373656e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.18 | train loss last: 4.25 | consumed tokens: 14848000.0 | grad norm avg: 5.81 | grad norm last: 5.89 | 
2025-12-27T23:15:05 | step: 29100 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.992297418648377e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.23 | train loss last: 4.12 | consumed tokens: 14899200.0 | grad norm avg: 5.81 | grad norm last: 5.91 | 
2025-12-27T23:15:07 | step: 29200 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.992215927923098e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.27 | train loss last: 4.56 | consumed tokens: 14950400.0 | grad norm avg: 6.13 | grad norm last: 8.28 | 
2025-12-27T23:15:09 | step: 29300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.99213443719782e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.23 | train loss last: 4.69 | consumed tokens: 15001600.0 | grad norm avg: 5.88 | grad norm last: 5.48 | 
2025-12-27T23:15:11 | step: 29400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.992051491281018e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.11 | train loss last: 3.75 | consumed tokens: 15052800.0 | grad norm avg: 5.68 | grad norm last: 5.27 | 
2025-12-27T23:15:13 | step: 29500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.991968545364216e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.14 | train loss last: 3.62 | consumed tokens: 15104000.0 | grad norm avg: 5.67 | grad norm last: 5.13 | 
2025-12-27T23:15:15 | step: 29600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.991884144255891e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.27 | train loss last: 6.41 | consumed tokens: 15155200.0 | grad norm avg: 6.11 | grad norm last: 10.19 | 
2025-12-27T23:15:17 | step: 29700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.99180119833909e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.2 | train loss last: 3.62 | consumed tokens: 15206400.0 | grad norm avg: 5.89 | grad norm last: 6.18 | 
2025-12-27T23:15:19 | step: 29800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.991716797230765e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.2 | train loss last: 4.56 | consumed tokens: 15257600.0 | grad norm avg: 5.95 | grad norm last: 5.73 | 
2025-12-27T23:15:21 | step: 29900 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.991632396122441e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.29 | train loss last: 4.94 | consumed tokens: 15308800.0 | grad norm avg: 5.99 | grad norm last: 7.0 | 
2025-12-27T23:15:23 | step: 30000 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 9.991546539822593e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.19 | train loss last: 3.59 | consumed tokens: 15360000.0 | grad norm avg: 5.77 | grad norm last: 4.79 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_30000-seen_tokens_15360000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_30000-seen_tokens_15360000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_30000-seen_tokens_15360000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_30000-seen_tokens_15360000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_30000-seen_tokens_15360000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_30000-seen_tokens_15360000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_30000-seen_tokens_15360000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_30000-seen_tokens_15360000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:15:26 | step: 30100 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.991460683522746e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.29 | train loss last: 5.09 | consumed tokens: 15411200.0 | grad norm avg: 6.05 | grad norm last: 5.98 | 
2025-12-27T23:15:28 | step: 30200 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.991374827222899e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.21 | train loss last: 3.67 | consumed tokens: 15462400.0 | grad norm avg: 5.77 | grad norm last: 5.2 | 
2025-12-27T23:15:30 | step: 30300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.991288970923051e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.12 | train loss last: 3.53 | consumed tokens: 15513600.0 | grad norm avg: 5.73 | grad norm last: 4.88 | 
2025-12-27T23:15:32 | step: 30400 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.991201659431681e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.26 | train loss last: 3.53 | consumed tokens: 15564800.0 | grad norm avg: 5.93 | grad norm last: 5.81 | 
2025-12-27T23:15:34 | step: 30500 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.991114347940311e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.22 | train loss last: 3.83 | consumed tokens: 15616000.0 | grad norm avg: 5.87 | grad norm last: 5.72 | 
2025-12-27T23:15:36 | step: 30600 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.991025581257418e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.25 | train loss last: 5.06 | consumed tokens: 15667200.0 | grad norm avg: 6.23 | grad norm last: 6.45 | 
2025-12-27T23:15:38 | step: 30700 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.990937542170286e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.12 | train loss last: 3.62 | consumed tokens: 15718400.0 | grad norm avg: 5.7 | grad norm last: 5.4 | 
2025-12-27T23:15:40 | step: 30800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.990848047891632e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.16 | train loss last: 3.75 | consumed tokens: 15769600.0 | grad norm avg: 6.01 | grad norm last: 4.88 | 
2025-12-27T23:15:42 | step: 30900 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.990759281208739e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.13 | train loss last: 3.92 | consumed tokens: 15820800.0 | grad norm avg: 5.75 | grad norm last: 5.1 | 
2025-12-27T23:15:44 | step: 31000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.990669786930084e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.18 | train loss last: 3.97 | consumed tokens: 15872000.0 | grad norm avg: 5.85 | grad norm last: 5.29 | 
2025-12-27T23:15:46 | step: 31100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.990579565055668e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.16 | train loss last: 3.78 | consumed tokens: 15923200.0 | grad norm avg: 5.83 | grad norm last: 4.38 | 
2025-12-27T23:15:48 | step: 31200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.990489343181252e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.16 | train loss last: 3.8 | consumed tokens: 15974400.0 | grad norm avg: 5.84 | grad norm last: 4.86 | 
2025-12-27T23:15:50 | step: 31300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.990398393711075e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.15 | train loss last: 3.55 | consumed tokens: 16025600.0 | grad norm avg: 5.87 | grad norm last: 5.13 | 
2025-12-27T23:15:52 | step: 31400 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.990306716645136e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.14 | train loss last: 4.25 | consumed tokens: 16076800.0 | grad norm avg: 5.83 | grad norm last: 5.05 | 
2025-12-27T23:15:54 | step: 31500 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.990215767174959e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.21 | train loss last: 4.19 | consumed tokens: 16128000.0 | grad norm avg: 5.92 | grad norm last: 7.05 | 
2025-12-27T23:15:56 | step: 31600 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.990123362513259e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.18 | train loss last: 4.66 | consumed tokens: 16179200.0 | grad norm avg: 5.82 | grad norm last: 6.35 | 
2025-12-27T23:15:58 | step: 31700 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.99003168544732e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.3 | train loss last: 4.56 | consumed tokens: 16230400.0 | grad norm avg: 6.26 | grad norm last: 6.94 | 
2025-12-27T23:16:00 | step: 31800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.989938553189859e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.24 | train loss last: 4.75 | consumed tokens: 16281600.0 | grad norm avg: 6.01 | grad norm last: 5.77 | 
2025-12-27T23:16:02 | step: 31900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.989843965740874e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.24 | train loss last: 3.53 | consumed tokens: 16332800.0 | grad norm avg: 5.97 | grad norm last: 5.68 | 
2025-12-27T23:16:04 | step: 32000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.989750105887651e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.28 | train loss last: 3.8 | consumed tokens: 16384000.0 | grad norm avg: 5.97 | grad norm last: 8.91 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_32000-seen_tokens_16384000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_32000-seen_tokens_16384000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_32000-seen_tokens_16384000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_32000-seen_tokens_16384000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_32000-seen_tokens_16384000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_32000-seen_tokens_16384000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_32000-seen_tokens_16384000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_32000-seen_tokens_16384000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:16:06 | step: 32100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.989654790842906e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.2 | train loss last: 3.95 | consumed tokens: 16435200.0 | grad norm avg: 5.98 | grad norm last: 6.12 | 
2025-12-27T23:16:08 | step: 32200 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.989560930989683e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.19 | train loss last: 4.66 | consumed tokens: 16486400.0 | grad norm avg: 5.98 | grad norm last: 5.68 | 
2025-12-27T23:16:10 | step: 32300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.989465615944937e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.08 | train loss last: 3.73 | consumed tokens: 16537600.0 | grad norm avg: 5.8 | grad norm last: 6.58 | 
2025-12-27T23:16:12 | step: 32400 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.98936957330443e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.29 | train loss last: 3.88 | consumed tokens: 16588800.0 | grad norm avg: 6.03 | grad norm last: 4.99 | 
2025-12-27T23:16:14 | step: 32500 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.989274985855445e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.19 | train loss last: 4.62 | consumed tokens: 16640000.0 | grad norm avg: 5.93 | grad norm last: 7.24 | 
2025-12-27T23:16:16 | step: 32600 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.989177488023415e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.18 | train loss last: 4.38 | consumed tokens: 16691200.0 | grad norm avg: 5.96 | grad norm last: 5.42 | 
2025-12-27T23:16:18 | step: 32700 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.989080717787147e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.29 | train loss last: 5.09 | consumed tokens: 16742400.0 | grad norm avg: 5.9 | grad norm last: 5.77 | 
2025-12-27T23:16:20 | step: 32800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.988983947550878e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.15 | train loss last: 4.31 | consumed tokens: 16793600.0 | grad norm avg: 5.88 | grad norm last: 5.79 | 
2025-12-27T23:16:22 | step: 32900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.988885722123086e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.18 | train loss last: 4.19 | consumed tokens: 16844800.0 | grad norm avg: 5.96 | grad norm last: 6.05 | 
2025-12-27T23:16:24 | step: 33000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.988787496695295e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.29 | train loss last: 4.53 | consumed tokens: 16896000.0 | grad norm avg: 5.97 | grad norm last: 5.71 | 
2025-12-27T23:16:26 | step: 33100 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.988688543671742e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.24 | train loss last: 4.59 | consumed tokens: 16947200.0 | grad norm avg: 6.01 | grad norm last: 5.63 | 
2025-12-27T23:16:28 | step: 33200 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.988589590648189e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.16 | train loss last: 3.77 | consumed tokens: 16998400.0 | grad norm avg: 5.93 | grad norm last: 5.11 | 
2025-12-27T23:16:30 | step: 33300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.988489910028875e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.26 | train loss last: 4.0 | consumed tokens: 17049600.0 | grad norm avg: 6.07 | grad norm last: 5.28 | 
2025-12-27T23:16:32 | step: 33400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.98839022940956e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.14 | train loss last: 3.98 | consumed tokens: 17100800.0 | grad norm avg: 5.91 | grad norm last: 5.18 | 
2025-12-27T23:16:34 | step: 33500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.988289821194485e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.22 | train loss last: 3.09 | consumed tokens: 17152000.0 | grad norm avg: 6.07 | grad norm last: 5.07 | 
2025-12-27T23:16:36 | step: 33600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.988187957787886e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.22 | train loss last: 3.42 | consumed tokens: 17203200.0 | grad norm avg: 5.99 | grad norm last: 4.99 | 
2025-12-27T23:16:38 | step: 33700 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.98808754957281e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.2 | train loss last: 4.31 | consumed tokens: 17254400.0 | grad norm avg: 5.85 | grad norm last: 5.36 | 
2025-12-27T23:16:40 | step: 33800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.987985686166212e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.11 | train loss last: 4.59 | consumed tokens: 17305600.0 | grad norm avg: 5.8 | grad norm last: 5.55 | 
2025-12-27T23:16:42 | step: 33900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.987883822759613e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.21 | train loss last: 3.56 | consumed tokens: 17356800.0 | grad norm avg: 6.14 | grad norm last: 5.45 | 
2025-12-27T23:16:44 | step: 34000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.987780504161492e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.2 | train loss last: 3.94 | consumed tokens: 17408000.0 | grad norm avg: 5.84 | grad norm last: 5.26 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_34000-seen_tokens_17408000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_34000-seen_tokens_17408000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_34000-seen_tokens_17408000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_34000-seen_tokens_17408000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_34000-seen_tokens_17408000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_34000-seen_tokens_17408000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_34000-seen_tokens_17408000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_34000-seen_tokens_17408000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:16:47 | step: 34100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.987677913159132e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.12 | train loss last: 4.47 | consumed tokens: 17459200.0 | grad norm avg: 5.87 | grad norm last: 7.08 | 
2025-12-27T23:16:49 | step: 34200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.987575322156772e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.12 | train loss last: 4.03 | consumed tokens: 17510400.0 | grad norm avg: 5.8 | grad norm last: 5.41 | 
2025-12-27T23:16:51 | step: 34300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.987470548367128e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.23 | train loss last: 3.66 | consumed tokens: 17561600.0 | grad norm avg: 5.86 | grad norm last: 5.56 | 
2025-12-27T23:16:53 | step: 34400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.987366502173245e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.21 | train loss last: 3.95 | consumed tokens: 17612800.0 | grad norm avg: 5.93 | grad norm last: 5.01 | 
2025-12-27T23:16:55 | step: 34500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.987261728383601e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.15 | train loss last: 3.45 | consumed tokens: 17664000.0 | grad norm avg: 5.84 | grad norm last: 5.01 | 
2025-12-27T23:16:57 | step: 34600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.987156954593956e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.22 | train loss last: 4.44 | consumed tokens: 17715200.0 | grad norm avg: 6.01 | grad norm last: 5.79 | 
2025-12-27T23:16:59 | step: 34700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.987051453208551e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.1 | train loss last: 3.91 | consumed tokens: 17766400.0 | grad norm avg: 5.77 | grad norm last: 5.61 | 
2025-12-27T23:17:01 | step: 34800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.986945224227384e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.21 | train loss last: 5.19 | consumed tokens: 17817600.0 | grad norm avg: 5.89 | grad norm last: 6.72 | 
2025-12-27T23:17:03 | step: 34900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.986838995246217e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.14 | train loss last: 4.44 | consumed tokens: 17868800.0 | grad norm avg: 5.91 | grad norm last: 5.91 | 
2025-12-27T23:17:05 | step: 35000 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.986732038669288e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.15 | train loss last: 4.28 | consumed tokens: 17920000.0 | grad norm avg: 5.97 | grad norm last: 5.25 | 
2025-12-27T23:17:07 | step: 35100 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.986624354496598e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.23 | train loss last: 3.81 | consumed tokens: 17971200.0 | grad norm avg: 6.14 | grad norm last: 5.41 | 
2025-12-27T23:17:09 | step: 35200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.986516670323908e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.14 | train loss last: 3.56 | consumed tokens: 18022400.0 | grad norm avg: 5.95 | grad norm last: 5.46 | 
2025-12-27T23:17:11 | step: 35300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.986408258555457e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.23 | train loss last: 4.44 | consumed tokens: 18073600.0 | grad norm avg: 5.98 | grad norm last: 6.57 | 
2025-12-27T23:17:13 | step: 35400 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.986300574382767e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.25 | train loss last: 4.62 | consumed tokens: 18124800.0 | grad norm avg: 6.17 | grad norm last: 6.88 | 
2025-12-27T23:17:15 | step: 35500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.986190707422793e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.22 | train loss last: 4.16 | consumed tokens: 18176000.0 | grad norm avg: 5.88 | grad norm last: 6.0 | 
2025-12-27T23:17:17 | step: 35600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.986080840462819e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.22 | train loss last: 3.8 | consumed tokens: 18227200.0 | grad norm avg: 5.94 | grad norm last: 6.17 | 
2025-12-27T23:17:19 | step: 35700 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.985971701098606e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.21 | train loss last: 4.44 | consumed tokens: 18278400.0 | grad norm avg: 6.01 | grad norm last: 5.14 | 
2025-12-27T23:17:21 | step: 35800 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.98586110654287e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.19 | train loss last: 4.38 | consumed tokens: 18329600.0 | grad norm avg: 5.92 | grad norm last: 7.34 | 
2025-12-27T23:17:23 | step: 35900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.985750511987135e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.16 | train loss last: 4.34 | consumed tokens: 18380800.0 | grad norm avg: 5.94 | grad norm last: 6.02 | 
2025-12-27T23:17:25 | step: 36000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.985638462239876e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.19 | train loss last: 3.95 | consumed tokens: 18432000.0 | grad norm avg: 5.86 | grad norm last: 5.88 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_36000-seen_tokens_18432000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_36000-seen_tokens_18432000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_36000-seen_tokens_18432000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_36000-seen_tokens_18432000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_36000-seen_tokens_18432000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_36000-seen_tokens_18432000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_36000-seen_tokens_18432000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_36000-seen_tokens_18432000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:17:27 | step: 36100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.985527867684141e-05 | peak memory rank 0 (MB): 874.57 | train loss avg: 4.16 | train loss last: 4.19 | consumed tokens: 18483200.0 | grad norm avg: 5.85 | grad norm last: 5.72 | 
2025-12-27T23:17:29 | step: 36200 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.985415817936882e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.23 | train loss last: 3.69 | consumed tokens: 18534400.0 | grad norm avg: 5.98 | grad norm last: 6.21 | 
2025-12-27T23:17:31 | step: 36300 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.985303040593863e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.12 | train loss last: 4.16 | consumed tokens: 18585600.0 | grad norm avg: 5.9 | grad norm last: 5.11 | 
2025-12-27T23:17:33 | step: 36400 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 9.985190263250843e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.22 | train loss last: 3.94 | consumed tokens: 18636800.0 | grad norm avg: 5.8 | grad norm last: 5.28 | 
2025-12-27T23:17:35 | step: 36500 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.985076758312061e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.18 | train loss last: 3.55 | consumed tokens: 18688000.0 | grad norm avg: 6.09 | grad norm last: 5.08 | 
2025-12-27T23:17:37 | step: 36600 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.98496325337328e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.15 | train loss last: 3.38 | consumed tokens: 18739200.0 | grad norm avg: 5.92 | grad norm last: 5.6 | 
2025-12-27T23:17:39 | step: 36700 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.984849020838737e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.23 | train loss last: 4.22 | consumed tokens: 18790400.0 | grad norm avg: 5.9 | grad norm last: 5.5 | 
2025-12-27T23:17:41 | step: 36800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.984734788304195e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.06 | train loss last: 3.89 | consumed tokens: 18841600.0 | grad norm avg: 5.8 | grad norm last: 6.23 | 
2025-12-27T23:17:43 | step: 36900 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.984619100578129e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.11 | train loss last: 3.8 | consumed tokens: 18892800.0 | grad norm avg: 5.78 | grad norm last: 5.28 | 
2025-12-27T23:17:45 | step: 37000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.984503412852064e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.08 | train loss last: 4.56 | consumed tokens: 18944000.0 | grad norm avg: 5.94 | grad norm last: 5.93 | 
2025-12-27T23:17:47 | step: 37100 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.984386997530237e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.13 | train loss last: 3.95 | consumed tokens: 18995200.0 | grad norm avg: 6.12 | grad norm last: 6.01 | 
2025-12-27T23:17:49 | step: 37200 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.98427058220841e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.24 | train loss last: 5.09 | consumed tokens: 19046400.0 | grad norm avg: 6.03 | grad norm last: 7.01 | 
2025-12-27T23:17:51 | step: 37300 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.984154166886583e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.11 | train loss last: 3.73 | consumed tokens: 19097600.0 | grad norm avg: 5.91 | grad norm last: 5.36 | 
2025-12-27T23:17:53 | step: 37400 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.984037751564756e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.09 | train loss last: 4.28 | consumed tokens: 19148800.0 | grad norm avg: 5.85 | grad norm last: 6.21 | 
2025-12-27T23:17:55 | step: 37500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.983919881051406e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.18 | train loss last: 4.34 | consumed tokens: 19200000.0 | grad norm avg: 6.2 | grad norm last: 6.58 | 
2025-12-27T23:17:57 | step: 37600 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 9.983802010538056e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.16 | train loss last: 3.62 | consumed tokens: 19251200.0 | grad norm avg: 5.83 | grad norm last: 5.66 | 
2025-12-27T23:17:59 | step: 37700 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.983682684833184e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.2 | train loss last: 3.86 | consumed tokens: 19302400.0 | grad norm avg: 6.07 | grad norm last: 6.48 | 
2025-12-27T23:18:01 | step: 37800 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.983564814319834e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.12 | train loss last: 4.22 | consumed tokens: 19353600.0 | grad norm avg: 6.01 | grad norm last: 6.39 | 
2025-12-27T23:18:03 | step: 37900 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.983444033423439e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.19 | train loss last: 5.22 | consumed tokens: 19404800.0 | grad norm avg: 5.95 | grad norm last: 8.85 | 
2025-12-27T23:18:05 | step: 38000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.983326162910089e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.19 | train loss last: 4.53 | consumed tokens: 19456000.0 | grad norm avg: 5.81 | grad norm last: 5.94 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_38000-seen_tokens_19456000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_38000-seen_tokens_19456000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_38000-seen_tokens_19456000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_38000-seen_tokens_19456000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_38000-seen_tokens_19456000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_38000-seen_tokens_19456000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_38000-seen_tokens_19456000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_38000-seen_tokens_19456000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:18:07 | step: 38100 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.983204654417932e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.14 | train loss last: 4.16 | consumed tokens: 19507200.0 | grad norm avg: 5.86 | grad norm last: 6.62 | 
2025-12-27T23:18:09 | step: 38200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.983083145925775e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.19 | train loss last: 5.28 | consumed tokens: 19558400.0 | grad norm avg: 6.11 | grad norm last: 6.63 | 
2025-12-27T23:18:11 | step: 38300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.982963092625141e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.17 | train loss last: 5.09 | consumed tokens: 19609600.0 | grad norm avg: 5.85 | grad norm last: 6.55 | 
2025-12-27T23:18:13 | step: 38400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.982841584132984e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.16 | train loss last: 4.31 | consumed tokens: 19660800.0 | grad norm avg: 5.82 | grad norm last: 5.3 | 
2025-12-27T23:18:15 | step: 38500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.982719348045066e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.19 | train loss last: 4.31 | consumed tokens: 19712000.0 | grad norm avg: 6.28 | grad norm last: 5.44 | 
2025-12-27T23:18:17 | step: 38600 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.982597111957148e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.14 | train loss last: 4.69 | consumed tokens: 19763200.0 | grad norm avg: 5.99 | grad norm last: 5.92 | 
2025-12-27T23:18:19 | step: 38700 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.982474148273468e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.14 | train loss last: 3.95 | consumed tokens: 19814400.0 | grad norm avg: 6.12 | grad norm last: 4.92 | 
2025-12-27T23:18:22 | step: 38800 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 9.982351184589788e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 4.22 | train loss last: 4.62 | consumed tokens: 19865600.0 | grad norm avg: 6.13 | grad norm last: 6.21 | 
2025-12-27T23:18:24 | step: 38900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.982227493310347e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 3.81 | consumed tokens: 19916800.0 | grad norm avg: 5.85 | grad norm last: 5.22 | 
2025-12-27T23:18:26 | step: 39000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.982103802030906e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 3.92 | consumed tokens: 19968000.0 | grad norm avg: 5.88 | grad norm last: 5.35 | 
2025-12-27T23:18:28 | step: 39100 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.981978655559942e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.84 | consumed tokens: 20019200.0 | grad norm avg: 5.68 | grad norm last: 5.98 | 
2025-12-27T23:18:30 | step: 39200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.981853509088978e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.17 | train loss last: 3.62 | consumed tokens: 20070400.0 | grad norm avg: 6.08 | grad norm last: 4.69 | 
2025-12-27T23:18:32 | step: 39300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.981728362618014e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.22 | train loss last: 4.72 | consumed tokens: 20121600.0 | grad norm avg: 5.95 | grad norm last: 5.94 | 
2025-12-27T23:18:34 | step: 39400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.98160321614705e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 5.56 | consumed tokens: 20172800.0 | grad norm avg: 5.88 | grad norm last: 8.17 | 
2025-12-27T23:18:36 | step: 39500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.981475886888802e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.2 | train loss last: 4.56 | consumed tokens: 20224000.0 | grad norm avg: 6.11 | grad norm last: 5.45 | 
2025-12-27T23:18:38 | step: 39600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.981348557630554e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.24 | train loss last: 4.44 | consumed tokens: 20275200.0 | grad norm avg: 6.04 | grad norm last: 5.25 | 
2025-12-27T23:18:40 | step: 39700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.981222683563828e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 4.31 | consumed tokens: 20326400.0 | grad norm avg: 5.83 | grad norm last: 5.79 | 
2025-12-27T23:18:42 | step: 39800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.981094626709819e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.17 | train loss last: 3.7 | consumed tokens: 20377600.0 | grad norm avg: 6.15 | grad norm last: 5.45 | 
2025-12-27T23:18:44 | step: 39900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.980966569855809e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.12 | train loss last: 4.09 | consumed tokens: 20428800.0 | grad norm avg: 5.87 | grad norm last: 5.54 | 
2025-12-27T23:18:46 | step: 40000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.9808385130018e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.18 | train loss last: 3.86 | consumed tokens: 20480000.0 | grad norm avg: 5.9 | grad norm last: 5.22 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_40000-seen_tokens_20480000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_40000-seen_tokens_20480000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_40000-seen_tokens_20480000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_40000-seen_tokens_20480000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_40000-seen_tokens_20480000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_40000-seen_tokens_20480000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_40000-seen_tokens_20480000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_40000-seen_tokens_20480000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:18:48 | step: 40100 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.980709728552029e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.18 | train loss last: 5.12 | consumed tokens: 20531200.0 | grad norm avg: 5.91 | grad norm last: 6.19 | 
2025-12-27T23:18:50 | step: 40200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.980580216506496e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.17 | train loss last: 4.47 | consumed tokens: 20582400.0 | grad norm avg: 5.9 | grad norm last: 9.16 | 
2025-12-27T23:18:52 | step: 40300 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.980450704460964e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.14 | train loss last: 3.86 | consumed tokens: 20633600.0 | grad norm avg: 5.92 | grad norm last: 4.88 | 
2025-12-27T23:18:54 | step: 40400 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.98032046481967e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 4.22 | consumed tokens: 20684800.0 | grad norm avg: 5.93 | grad norm last: 5.93 | 
2025-12-27T23:18:56 | step: 40500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.980189497582614e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.2 | train loss last: 4.03 | consumed tokens: 20736000.0 | grad norm avg: 5.91 | grad norm last: 5.64 | 
2025-12-27T23:18:58 | step: 40600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.980058530345559e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.15 | train loss last: 4.09 | consumed tokens: 20787200.0 | grad norm avg: 6.0 | grad norm last: 5.35 | 
2025-12-27T23:19:00 | step: 40700 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.979927563108504e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 4.28 | consumed tokens: 20838400.0 | grad norm avg: 5.96 | grad norm last: 5.53 | 
2025-12-27T23:19:02 | step: 40800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.979794413084164e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.14 | train loss last: 3.69 | consumed tokens: 20889600.0 | grad norm avg: 6.26 | grad norm last: 5.91 | 
2025-12-27T23:19:04 | step: 40900 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.979662718251348e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.19 | train loss last: 5.06 | consumed tokens: 20940800.0 | grad norm avg: 6.16 | grad norm last: 5.73 | 
2025-12-27T23:19:06 | step: 41000 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.979531023418531e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.22 | consumed tokens: 20992000.0 | grad norm avg: 5.84 | grad norm last: 5.42 | 
2025-12-27T23:19:08 | step: 41100 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.97939714579843e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.17 | train loss last: 4.0 | consumed tokens: 21043200.0 | grad norm avg: 5.85 | grad norm last: 6.05 | 
2025-12-27T23:19:10 | step: 41200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.979263268178329e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.8 | consumed tokens: 21094400.0 | grad norm avg: 6.02 | grad norm last: 4.82 | 
2025-12-27T23:19:12 | step: 41300 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.979129390558228e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 5.09 | consumed tokens: 21145600.0 | grad norm avg: 5.83 | grad norm last: 6.38 | 
2025-12-27T23:19:14 | step: 41400 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.978995512938127e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 3.58 | consumed tokens: 21196800.0 | grad norm avg: 5.74 | grad norm last: 5.5 | 
2025-12-27T23:19:16 | step: 41500 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.978860180126503e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 4.06 | consumed tokens: 21248000.0 | grad norm avg: 5.9 | grad norm last: 6.3 | 
2025-12-27T23:19:18 | step: 41600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.978724847314879e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 4.28 | consumed tokens: 21299200.0 | grad norm avg: 5.91 | grad norm last: 6.01 | 
2025-12-27T23:19:20 | step: 41700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.978588786907494e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.19 | train loss last: 4.09 | consumed tokens: 21350400.0 | grad norm avg: 5.94 | grad norm last: 6.28 | 
2025-12-27T23:19:22 | step: 41800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.978452726500109e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.13 | train loss last: 4.78 | consumed tokens: 21401600.0 | grad norm avg: 5.92 | grad norm last: 6.06 | 
2025-12-27T23:19:24 | step: 41900 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.978315938496962e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.17 | train loss last: 4.41 | consumed tokens: 21452800.0 | grad norm avg: 5.97 | grad norm last: 5.52 | 
2025-12-27T23:19:26 | step: 42000 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.978179150493816e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.13 | train loss last: 3.73 | consumed tokens: 21504000.0 | grad norm avg: 6.25 | grad norm last: 6.05 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_42000-seen_tokens_21504000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_42000-seen_tokens_21504000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_42000-seen_tokens_21504000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_42000-seen_tokens_21504000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_42000-seen_tokens_21504000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_42000-seen_tokens_21504000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_42000-seen_tokens_21504000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_42000-seen_tokens_21504000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:19:29 | step: 42100 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.978041634894907e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.13 | train loss last: 3.95 | consumed tokens: 21555200.0 | grad norm avg: 5.93 | grad norm last: 6.07 | 
2025-12-27T23:19:31 | step: 42200 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.977904119296e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 4.06 | consumed tokens: 21606400.0 | grad norm avg: 5.91 | grad norm last: 5.5 | 
2025-12-27T23:19:33 | step: 42300 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.977765148505569e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.15 | train loss last: 3.95 | consumed tokens: 21657600.0 | grad norm avg: 5.98 | grad norm last: 5.75 | 
2025-12-27T23:19:35 | step: 42400 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.97762763290666e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 4.44 | consumed tokens: 21708800.0 | grad norm avg: 6.04 | grad norm last: 5.65 | 
2025-12-27T23:19:37 | step: 42500 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.977487934520468e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.22 | train loss last: 3.86 | consumed tokens: 21760000.0 | grad norm avg: 5.97 | grad norm last: 5.1 | 
2025-12-27T23:19:39 | step: 42600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.977348236134276e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.15 | train loss last: 3.73 | consumed tokens: 21811200.0 | grad norm avg: 6.12 | grad norm last: 5.0 | 
2025-12-27T23:19:41 | step: 42700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.977208537748083e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.21 | train loss last: 4.12 | consumed tokens: 21862400.0 | grad norm avg: 6.17 | grad norm last: 6.73 | 
2025-12-27T23:19:43 | step: 42800 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.977067384170368e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.15 | train loss last: 3.91 | consumed tokens: 21913600.0 | grad norm avg: 6.21 | grad norm last: 5.45 | 
2025-12-27T23:19:45 | step: 42900 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.976926230592653e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 3.67 | consumed tokens: 21964800.0 | grad norm avg: 5.93 | grad norm last: 5.83 | 
2025-12-27T23:19:47 | step: 43000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.976785077014938e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 3.56 | consumed tokens: 22016000.0 | grad norm avg: 5.94 | grad norm last: 5.52 | 
2025-12-27T23:19:49 | step: 43100 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.976643923437223e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.16 | train loss last: 4.5 | consumed tokens: 22067200.0 | grad norm avg: 6.06 | grad norm last: 5.66 | 
2025-12-27T23:19:51 | step: 43200 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.976501314667985e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.17 | train loss last: 3.62 | consumed tokens: 22118400.0 | grad norm avg: 6.01 | grad norm last: 5.21 | 
2025-12-27T23:19:53 | step: 43300 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.976358705898747e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.19 | train loss last: 4.09 | consumed tokens: 22169600.0 | grad norm avg: 6.21 | grad norm last: 5.32 | 
2025-12-27T23:19:55 | step: 43400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.976214641937986e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.22 | train loss last: 3.77 | consumed tokens: 22220800.0 | grad norm avg: 6.07 | grad norm last: 5.2 | 
2025-12-27T23:19:57 | step: 43500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.976072033168748e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.22 | train loss last: 3.83 | consumed tokens: 22272000.0 | grad norm avg: 6.07 | grad norm last: 5.88 | 
2025-12-27T23:19:59 | step: 43600 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.975927969207987e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.14 | train loss last: 4.5 | consumed tokens: 22323200.0 | grad norm avg: 6.06 | grad norm last: 5.75 | 
2025-12-27T23:20:01 | step: 43700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.975783177651465e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.16 | train loss last: 3.11 | consumed tokens: 22374400.0 | grad norm avg: 6.17 | grad norm last: 4.68 | 
2025-12-27T23:20:03 | step: 43800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.975638386094943e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.18 | train loss last: 3.84 | consumed tokens: 22425600.0 | grad norm avg: 6.22 | grad norm last: 5.91 | 
2025-12-27T23:20:05 | step: 43900 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.975492866942659e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.18 | train loss last: 4.47 | consumed tokens: 22476800.0 | grad norm avg: 6.15 | grad norm last: 6.26 | 
2025-12-27T23:20:07 | step: 44000 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.975347347790375e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.69 | consumed tokens: 22528000.0 | grad norm avg: 6.11 | grad norm last: 6.16 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_44000-seen_tokens_22528000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_44000-seen_tokens_22528000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_44000-seen_tokens_22528000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_44000-seen_tokens_22528000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_44000-seen_tokens_22528000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_44000-seen_tokens_22528000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_44000-seen_tokens_22528000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_44000-seen_tokens_22528000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:20:09 | step: 44100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.975201828638092e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.25 | train loss last: 3.58 | consumed tokens: 22579200.0 | grad norm avg: 6.16 | grad norm last: 5.44 | 
2025-12-27T23:20:11 | step: 44200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 9.975055581890047e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.16 | train loss last: 3.75 | consumed tokens: 22630400.0 | grad norm avg: 6.06 | grad norm last: 5.27 | 
2025-12-27T23:20:13 | step: 44300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.974909335142002e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 3.64 | consumed tokens: 22681600.0 | grad norm avg: 5.91 | grad norm last: 5.28 | 
2025-12-27T23:20:15 | step: 44400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.974760905606672e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 4.25 | consumed tokens: 22732800.0 | grad norm avg: 5.82 | grad norm last: 6.4 | 
2025-12-27T23:20:17 | step: 44500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.974613203667104e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.12 | train loss last: 3.84 | consumed tokens: 22784000.0 | grad norm avg: 5.98 | grad norm last: 5.01 | 
2025-12-27T23:20:19 | step: 44600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.974464774131775e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.69 | consumed tokens: 22835200.0 | grad norm avg: 5.9 | grad norm last: 5.46 | 
2025-12-27T23:20:21 | step: 44700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.974316344596446e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 4.16 | consumed tokens: 22886400.0 | grad norm avg: 5.89 | grad norm last: 7.02 | 
2025-12-27T23:20:23 | step: 44800 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.974167187465355e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.06 | consumed tokens: 22937600.0 | grad norm avg: 6.02 | grad norm last: 5.53 | 
2025-12-27T23:20:25 | step: 44900 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.974017302738503e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 3.48 | consumed tokens: 22988800.0 | grad norm avg: 5.93 | grad norm last: 5.86 | 
2025-12-27T23:20:27 | step: 45000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.97386741801165e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 4.12 | consumed tokens: 23040000.0 | grad norm avg: 5.89 | grad norm last: 6.0 | 
2025-12-27T23:20:29 | step: 45100 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.973717533284798e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 3.86 | consumed tokens: 23091200.0 | grad norm avg: 5.95 | grad norm last: 6.5 | 
2025-12-27T23:20:31 | step: 45200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.973566193366423e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.17 | train loss last: 3.73 | consumed tokens: 23142400.0 | grad norm avg: 6.09 | grad norm last: 5.33 | 
2025-12-27T23:20:33 | step: 45300 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.973414853448048e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.15 | train loss last: 3.98 | consumed tokens: 23193600.0 | grad norm avg: 6.03 | grad norm last: 5.59 | 
2025-12-27T23:20:35 | step: 45400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.973263513529673e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.17 | train loss last: 3.81 | consumed tokens: 23244800.0 | grad norm avg: 6.08 | grad norm last: 5.46 | 
2025-12-27T23:20:37 | step: 45500 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.973111446015537e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.14 | train loss last: 3.36 | consumed tokens: 23296000.0 | grad norm avg: 5.92 | grad norm last: 5.88 | 
2025-12-27T23:20:39 | step: 45600 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.9729593785014e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 3.84 | consumed tokens: 23347200.0 | grad norm avg: 6.1 | grad norm last: 5.33 | 
2025-12-27T23:20:41 | step: 45700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.972805855795741e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 3.52 | consumed tokens: 23398400.0 | grad norm avg: 5.84 | grad norm last: 4.87 | 
2025-12-27T23:20:43 | step: 45800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.972652333090082e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 3.86 | consumed tokens: 23449600.0 | grad norm avg: 5.96 | grad norm last: 5.66 | 
2025-12-27T23:20:45 | step: 45900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.972499537980184e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 3.31 | consumed tokens: 23500800.0 | grad norm avg: 6.03 | grad norm last: 5.87 | 
2025-12-27T23:20:47 | step: 46000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.97234383248724e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.12 | train loss last: 3.56 | consumed tokens: 23552000.0 | grad norm avg: 5.86 | grad norm last: 4.98 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_46000-seen_tokens_23552000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_46000-seen_tokens_23552000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_46000-seen_tokens_23552000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_46000-seen_tokens_23552000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_46000-seen_tokens_23552000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_46000-seen_tokens_23552000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_46000-seen_tokens_23552000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_46000-seen_tokens_23552000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:20:49 | step: 46100 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.97218958218582e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.56 | consumed tokens: 23603200.0 | grad norm avg: 6.25 | grad norm last: 5.68 | 
2025-12-27T23:20:51 | step: 46200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.972034604288638e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.14 | train loss last: 3.62 | consumed tokens: 23654400.0 | grad norm avg: 6.17 | grad norm last: 5.85 | 
2025-12-27T23:20:53 | step: 46300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.971878171199933e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.17 | train loss last: 5.06 | consumed tokens: 23705600.0 | grad norm avg: 6.16 | grad norm last: 6.46 | 
2025-12-27T23:20:55 | step: 46400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.97172319330275e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.17 | train loss last: 3.62 | consumed tokens: 23756800.0 | grad norm avg: 6.03 | grad norm last: 6.02 | 
2025-12-27T23:20:57 | step: 46500 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.971566760214046e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 3.95 | consumed tokens: 23808000.0 | grad norm avg: 6.08 | grad norm last: 5.16 | 
2025-12-27T23:21:00 | step: 46600 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.971409599529579e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.15 | train loss last: 4.03 | consumed tokens: 23859200.0 | grad norm avg: 5.88 | grad norm last: 5.39 | 
2025-12-27T23:21:02 | step: 46700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.971252438845113e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.78 | consumed tokens: 23910400.0 | grad norm avg: 6.01 | grad norm last: 6.17 | 
2025-12-27T23:21:04 | step: 46800 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.971094550564885e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.17 | train loss last: 3.81 | consumed tokens: 23961600.0 | grad norm avg: 5.94 | grad norm last: 5.33 | 
2025-12-27T23:21:06 | step: 46900 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.970936662284657e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 4.41 | consumed tokens: 24012800.0 | grad norm avg: 6.16 | grad norm last: 5.5 | 
2025-12-27T23:21:08 | step: 47000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.970778046408668e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 4.38 | consumed tokens: 24064000.0 | grad norm avg: 6.17 | grad norm last: 5.88 | 
2025-12-27T23:21:10 | step: 47100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.970619430532679e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.17 | train loss last: 3.89 | consumed tokens: 24115200.0 | grad norm avg: 6.08 | grad norm last: 6.09 | 
2025-12-27T23:21:12 | step: 47200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.970459359465167e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.22 | train loss last: 4.56 | consumed tokens: 24166400.0 | grad norm avg: 6.23 | grad norm last: 5.56 | 
2025-12-27T23:21:14 | step: 47300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.970300015993416e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.14 | train loss last: 3.66 | consumed tokens: 24217600.0 | grad norm avg: 6.05 | grad norm last: 5.17 | 
2025-12-27T23:21:16 | step: 47400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.970139217330143e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.12 | train loss last: 4.25 | consumed tokens: 24268800.0 | grad norm avg: 6.12 | grad norm last: 5.63 | 
2025-12-27T23:21:18 | step: 47500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.969979146262631e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 3.47 | consumed tokens: 24320000.0 | grad norm avg: 6.13 | grad norm last: 6.43 | 
2025-12-27T23:21:20 | step: 47600 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.969817620003596e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 4.03 | consumed tokens: 24371200.0 | grad norm avg: 5.87 | grad norm last: 5.87 | 
2025-12-27T23:21:22 | step: 47700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.969656093744561e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 3.84 | consumed tokens: 24422400.0 | grad norm avg: 5.99 | grad norm last: 5.46 | 
2025-12-27T23:21:24 | step: 47800 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.969493839889765e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 4.59 | consumed tokens: 24473600.0 | grad norm avg: 6.08 | grad norm last: 6.36 | 
2025-12-27T23:21:26 | step: 47900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.969331586034968e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 3.89 | consumed tokens: 24524800.0 | grad norm avg: 5.91 | grad norm last: 7.46 | 
2025-12-27T23:21:28 | step: 48000 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.969168604584411e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 4.5 | consumed tokens: 24576000.0 | grad norm avg: 6.09 | grad norm last: 6.23 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_48000-seen_tokens_24576000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_48000-seen_tokens_24576000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_48000-seen_tokens_24576000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_48000-seen_tokens_24576000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_48000-seen_tokens_24576000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_48000-seen_tokens_24576000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_48000-seen_tokens_24576000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_48000-seen_tokens_24576000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:21:30 | step: 48100 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.969005623133853e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 3.8 | consumed tokens: 24627200.0 | grad norm avg: 6.13 | grad norm last: 6.4 | 
2025-12-27T23:21:32 | step: 48200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.968841914087534e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.17 | train loss last: 4.28 | consumed tokens: 24678400.0 | grad norm avg: 6.3 | grad norm last: 5.39 | 
2025-12-27T23:21:34 | step: 48300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.968676749849692e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.13 | train loss last: 2.94 | consumed tokens: 24729600.0 | grad norm avg: 6.14 | grad norm last: 5.5 | 
2025-12-27T23:21:36 | step: 48400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.968513040803373e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 4.75 | consumed tokens: 24780800.0 | grad norm avg: 6.0 | grad norm last: 7.06 | 
2025-12-27T23:21:38 | step: 48500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.968347876565531e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 5.44 | consumed tokens: 24832000.0 | grad norm avg: 6.2 | grad norm last: 8.26 | 
2025-12-27T23:21:40 | step: 48600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.968181984731928e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.14 | train loss last: 4.31 | consumed tokens: 24883200.0 | grad norm avg: 5.95 | grad norm last: 5.64 | 
2025-12-27T23:21:42 | step: 48700 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.968017548089847e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 3.97 | consumed tokens: 24934400.0 | grad norm avg: 5.96 | grad norm last: 5.93 | 
2025-12-27T23:21:44 | step: 48800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.967850201064721e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 3.92 | consumed tokens: 24985600.0 | grad norm avg: 5.92 | grad norm last: 4.87 | 
2025-12-27T23:21:46 | step: 48900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.967683581635356e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.16 | train loss last: 4.09 | consumed tokens: 25036800.0 | grad norm avg: 6.27 | grad norm last: 6.65 | 
2025-12-27T23:21:48 | step: 49000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.967516962205991e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.22 | train loss last: 3.5 | consumed tokens: 25088000.0 | grad norm avg: 6.21 | grad norm last: 5.19 | 
2025-12-27T23:21:50 | step: 49100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 9.967348887585104e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 3.77 | consumed tokens: 25139200.0 | grad norm avg: 5.91 | grad norm last: 5.67 | 
2025-12-27T23:21:52 | step: 49200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.967180812964216e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.84 | consumed tokens: 25190400.0 | grad norm avg: 5.88 | grad norm last: 5.76 | 
2025-12-27T23:21:54 | step: 49300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.967012010747567e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.14 | train loss last: 6.09 | consumed tokens: 25241600.0 | grad norm avg: 6.18 | grad norm last: 8.12 | 
2025-12-27T23:21:56 | step: 49400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.966843208530918e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.15 | train loss last: 4.62 | consumed tokens: 25292800.0 | grad norm avg: 6.02 | grad norm last: 6.63 | 
2025-12-27T23:21:58 | step: 49500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.966674406314269e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 3.95 | consumed tokens: 25344000.0 | grad norm avg: 6.22 | grad norm last: 6.5 | 
2025-12-27T23:22:00 | step: 49600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.966504148906097e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.14 | train loss last: 4.19 | consumed tokens: 25395200.0 | grad norm avg: 5.98 | grad norm last: 5.72 | 
2025-12-27T23:22:02 | step: 49700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.966335346689448e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 3.64 | consumed tokens: 25446400.0 | grad norm avg: 5.93 | grad norm last: 5.48 | 
2025-12-27T23:22:04 | step: 49800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.966163634089753e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.13 | train loss last: 4.81 | consumed tokens: 25497600.0 | grad norm avg: 6.07 | grad norm last: 7.31 | 
2025-12-27T23:22:06 | step: 49900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.96599264908582e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.89 | consumed tokens: 25548800.0 | grad norm avg: 6.02 | grad norm last: 5.77 | 
2025-12-27T23:22:08 | step: 50000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.965820936486125e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 4.28 | consumed tokens: 25600000.0 | grad norm avg: 6.14 | grad norm last: 5.83 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_50000-seen_tokens_25600000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_50000-seen_tokens_25600000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_50000-seen_tokens_25600000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_50000-seen_tokens_25600000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_50000-seen_tokens_25600000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_50000-seen_tokens_25600000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_50000-seen_tokens_25600000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_50000-seen_tokens_25600000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:22:10 | step: 50100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.96564922388643e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.21 | train loss last: 4.12 | consumed tokens: 25651200.0 | grad norm avg: 6.1 | grad norm last: 6.02 | 
2025-12-27T23:22:12 | step: 50200 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.965476783690974e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.22 | consumed tokens: 25702400.0 | grad norm avg: 5.85 | grad norm last: 5.74 | 
2025-12-27T23:22:14 | step: 50300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.96530507109128e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 4.53 | consumed tokens: 25753600.0 | grad norm avg: 5.89 | grad norm last: 5.24 | 
2025-12-27T23:22:16 | step: 50400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.9651311757043e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 3.83 | consumed tokens: 25804800.0 | grad norm avg: 5.96 | grad norm last: 6.44 | 
2025-12-27T23:22:18 | step: 50500 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.964957280317321e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.12 | train loss last: 4.06 | consumed tokens: 25856000.0 | grad norm avg: 6.09 | grad norm last: 6.3 | 
2025-12-27T23:22:20 | step: 50600 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.964782657334581e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.89 | consumed tokens: 25907200.0 | grad norm avg: 6.01 | grad norm last: 6.08 | 
2025-12-27T23:22:22 | step: 50700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.96460803435184e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 3.66 | consumed tokens: 25958400.0 | grad norm avg: 6.02 | grad norm last: 5.45 | 
2025-12-27T23:22:24 | step: 50800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.9644334113691e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.15 | train loss last: 4.16 | consumed tokens: 26009600.0 | grad norm avg: 6.03 | grad norm last: 7.09 | 
2025-12-27T23:22:27 | step: 50900 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.96425878838636e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 3.81 | consumed tokens: 26060800.0 | grad norm avg: 5.88 | grad norm last: 5.8 | 
2025-12-27T23:22:29 | step: 51000 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.964082710212097e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.17 | train loss last: 4.09 | consumed tokens: 26112000.0 | grad norm avg: 6.12 | grad norm last: 5.96 | 
2025-12-27T23:22:31 | step: 51100 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.963906632037833e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.91 | consumed tokens: 26163200.0 | grad norm avg: 5.8 | grad norm last: 5.23 | 
2025-12-27T23:22:33 | step: 51200 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.96373055386357e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 4.69 | consumed tokens: 26214400.0 | grad norm avg: 5.94 | grad norm last: 6.18 | 
2025-12-27T23:22:35 | step: 51300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.963553020497784e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 4.19 | consumed tokens: 26265600.0 | grad norm avg: 5.96 | grad norm last: 6.3 | 
2025-12-27T23:22:37 | step: 51400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.963375487131998e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.22 | consumed tokens: 26316800.0 | grad norm avg: 5.99 | grad norm last: 6.1 | 
2025-12-27T23:22:39 | step: 51500 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.963197953766212e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.58 | consumed tokens: 26368000.0 | grad norm avg: 6.02 | grad norm last: 5.56 | 
2025-12-27T23:22:41 | step: 51600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.963018965208903e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.16 | train loss last: 4.41 | consumed tokens: 26419200.0 | grad norm avg: 6.09 | grad norm last: 5.25 | 
2025-12-27T23:22:43 | step: 51700 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.962840704247355e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.92 | consumed tokens: 26470400.0 | grad norm avg: 6.05 | grad norm last: 6.63 | 
2025-12-27T23:22:45 | step: 51800 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.962662443285808e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 4.03 | consumed tokens: 26521600.0 | grad norm avg: 6.04 | grad norm last: 8.31 | 
2025-12-27T23:22:47 | step: 51900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.962481999536976e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.15 | train loss last: 3.05 | consumed tokens: 26572800.0 | grad norm avg: 6.14 | grad norm last: 5.63 | 
2025-12-27T23:22:49 | step: 52000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.962301555788144e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 4.28 | consumed tokens: 26624000.0 | grad norm avg: 6.08 | grad norm last: 6.31 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_52000-seen_tokens_26624000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_52000-seen_tokens_26624000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_52000-seen_tokens_26624000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_52000-seen_tokens_26624000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_52000-seen_tokens_26624000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_52000-seen_tokens_26624000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_52000-seen_tokens_26624000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_52000-seen_tokens_26624000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:22:51 | step: 52100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.962121112039313e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 3.58 | consumed tokens: 26675200.0 | grad norm avg: 6.23 | grad norm last: 5.45 | 
2025-12-27T23:22:53 | step: 52200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.961940668290481e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.95 | consumed tokens: 26726400.0 | grad norm avg: 6.1 | grad norm last: 4.55 | 
2025-12-27T23:22:55 | step: 52300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.961760224541649e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 4.44 | consumed tokens: 26777600.0 | grad norm avg: 6.0 | grad norm last: 6.23 | 
2025-12-27T23:22:57 | step: 52400 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.961577598005533e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.52 | consumed tokens: 26828800.0 | grad norm avg: 6.01 | grad norm last: 5.52 | 
2025-12-27T23:22:59 | step: 52500 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.961394971469417e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 4.16 | consumed tokens: 26880000.0 | grad norm avg: 6.05 | grad norm last: 6.08 | 
2025-12-27T23:23:01 | step: 52600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.961213072529063e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.12 | train loss last: 4.31 | consumed tokens: 26931200.0 | grad norm avg: 6.22 | grad norm last: 5.33 | 
2025-12-27T23:23:03 | step: 52700 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.961029718397185e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.14 | consumed tokens: 26982400.0 | grad norm avg: 5.98 | grad norm last: 5.78 | 
2025-12-27T23:23:05 | step: 52800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.960846364265308e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.12 | train loss last: 4.16 | consumed tokens: 27033600.0 | grad norm avg: 6.15 | grad norm last: 6.12 | 
2025-12-27T23:23:07 | step: 52900 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 9.960661554941908e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.64 | consumed tokens: 27084800.0 | grad norm avg: 6.17 | grad norm last: 8.1 | 
2025-12-27T23:23:09 | step: 53000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.960477473214269e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 5.12 | consumed tokens: 27136000.0 | grad norm avg: 6.1 | grad norm last: 9.28 | 
2025-12-27T23:23:11 | step: 53100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.96029339148663e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 3.8 | consumed tokens: 27187200.0 | grad norm avg: 5.98 | grad norm last: 5.74 | 
2025-12-27T23:23:13 | step: 53200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.960107854567468e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.69 | consumed tokens: 27238400.0 | grad norm avg: 5.91 | grad norm last: 7.74 | 
2025-12-27T23:23:15 | step: 53300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.959922317648306e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 3.52 | consumed tokens: 27289600.0 | grad norm avg: 6.03 | grad norm last: 4.98 | 
2025-12-27T23:23:17 | step: 53400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.959736053133383e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 3.72 | consumed tokens: 27340800.0 | grad norm avg: 6.06 | grad norm last: 5.03 | 
2025-12-27T23:23:19 | step: 53500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.95954978861846e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.53 | consumed tokens: 27392000.0 | grad norm avg: 6.08 | grad norm last: 5.76 | 
2025-12-27T23:23:21 | step: 53600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.959362796507776e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.16 | consumed tokens: 27443200.0 | grad norm avg: 6.11 | grad norm last: 5.08 | 
2025-12-27T23:23:23 | step: 53700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 9.959175804397091e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 5.53 | consumed tokens: 27494400.0 | grad norm avg: 6.12 | grad norm last: 6.18 | 
2025-12-27T23:23:25 | step: 53800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.958987357094884e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 3.73 | consumed tokens: 27545600.0 | grad norm avg: 6.11 | grad norm last: 5.24 | 
2025-12-27T23:23:27 | step: 53900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.958798909792677e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.12 | train loss last: 3.53 | consumed tokens: 27596800.0 | grad norm avg: 6.33 | grad norm last: 5.57 | 
2025-12-27T23:23:29 | step: 54000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.95861119008623e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.98 | consumed tokens: 27648000.0 | grad norm avg: 5.87 | grad norm last: 5.87 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_54000-seen_tokens_27648000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_54000-seen_tokens_27648000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_54000-seen_tokens_27648000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_54000-seen_tokens_27648000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_54000-seen_tokens_27648000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_54000-seen_tokens_27648000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_54000-seen_tokens_27648000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_54000-seen_tokens_27648000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:23:31 | step: 54100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.958422015188262e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.24 | train loss last: 3.73 | consumed tokens: 27699200.0 | grad norm avg: 6.27 | grad norm last: 5.34 | 
2025-12-27T23:23:33 | step: 54200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.958232840290293e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.91 | consumed tokens: 27750400.0 | grad norm avg: 6.0 | grad norm last: 5.41 | 
2025-12-27T23:23:35 | step: 54300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.958042210200801e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.86 | consumed tokens: 27801600.0 | grad norm avg: 5.98 | grad norm last: 6.07 | 
2025-12-27T23:23:37 | step: 54400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.957852307707071e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 4.12 | consumed tokens: 27852800.0 | grad norm avg: 6.34 | grad norm last: 5.66 | 
2025-12-27T23:23:39 | step: 54500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.957662405213341e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.13 | train loss last: 4.31 | consumed tokens: 27904000.0 | grad norm avg: 6.11 | grad norm last: 5.98 | 
2025-12-27T23:23:42 | step: 54600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.957470319932327e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.55 | consumed tokens: 27955200.0 | grad norm avg: 6.02 | grad norm last: 6.25 | 
2025-12-27T23:23:44 | step: 54700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.957278234651312e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.13 | train loss last: 4.22 | consumed tokens: 28006400.0 | grad norm avg: 6.16 | grad norm last: 5.76 | 
2025-12-27T23:23:46 | step: 54800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.957086149370298e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.12 | train loss last: 3.81 | consumed tokens: 28057600.0 | grad norm avg: 6.09 | grad norm last: 6.32 | 
2025-12-27T23:23:48 | step: 54900 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.956894064089283e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.19 | train loss last: 4.25 | consumed tokens: 28108800.0 | grad norm avg: 6.46 | grad norm last: 6.75 | 
2025-12-27T23:23:50 | step: 55000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.956701978808269e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 5.34 | consumed tokens: 28160000.0 | grad norm avg: 5.84 | grad norm last: 8.47 | 
2025-12-27T23:23:52 | step: 55100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.95650771073997e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.34 | consumed tokens: 28211200.0 | grad norm avg: 6.06 | grad norm last: 5.61 | 
2025-12-27T23:23:54 | step: 55200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.956313442671672e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 4.38 | consumed tokens: 28262400.0 | grad norm avg: 6.18 | grad norm last: 5.82 | 
2025-12-27T23:23:56 | step: 55300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.956119902199134e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 4.03 | consumed tokens: 28313600.0 | grad norm avg: 5.99 | grad norm last: 5.5 | 
2025-12-27T23:23:58 | step: 55400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.955924906535074e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 3.78 | consumed tokens: 28364800.0 | grad norm avg: 6.18 | grad norm last: 5.94 | 
2025-12-27T23:24:00 | step: 55500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.955729910871014e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.14 | train loss last: 5.44 | consumed tokens: 28416000.0 | grad norm avg: 6.08 | grad norm last: 11.32 | 
2025-12-27T23:24:02 | step: 55600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.955534915206954e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.66 | consumed tokens: 28467200.0 | grad norm avg: 6.14 | grad norm last: 5.73 | 
2025-12-27T23:24:04 | step: 55700 | train samples/s: 108.0 | train mfu (16-bit): -1.0 | lr mean: 9.955338464351371e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 4.0 | consumed tokens: 28518400.0 | grad norm avg: 6.31 | grad norm last: 5.72 | 
2025-12-27T23:24:06 | step: 55800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.955142013495788e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 4.62 | consumed tokens: 28569600.0 | grad norm avg: 6.29 | grad norm last: 5.69 | 
2025-12-27T23:24:08 | step: 55900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.954945562640205e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.45 | consumed tokens: 28620800.0 | grad norm avg: 6.07 | grad norm last: 5.43 | 
2025-12-27T23:24:10 | step: 56000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.954747656593099e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.91 | consumed tokens: 28672000.0 | grad norm avg: 5.97 | grad norm last: 5.21 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_56000-seen_tokens_28672000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_56000-seen_tokens_28672000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_56000-seen_tokens_28672000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_56000-seen_tokens_28672000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_56000-seen_tokens_28672000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_56000-seen_tokens_28672000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_56000-seen_tokens_28672000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_56000-seen_tokens_28672000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:24:12 | step: 56100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.954549750545993e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.25 | train loss last: 3.55 | consumed tokens: 28723200.0 | grad norm avg: 6.37 | grad norm last: 5.03 | 
2025-12-27T23:24:14 | step: 56200 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.954351844498888e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 3.38 | consumed tokens: 28774400.0 | grad norm avg: 6.17 | grad norm last: 5.21 | 
2025-12-27T23:24:16 | step: 56300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.954153938451782e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.34 | consumed tokens: 28825600.0 | grad norm avg: 6.01 | grad norm last: 10.91 | 
2025-12-27T23:24:18 | step: 56400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.953955304808915e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.5 | consumed tokens: 28876800.0 | grad norm avg: 6.03 | grad norm last: 5.51 | 
2025-12-27T23:24:20 | step: 56500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.953756671166047e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.12 | train loss last: 5.0 | consumed tokens: 28928000.0 | grad norm avg: 6.13 | grad norm last: 6.49 | 
2025-12-27T23:24:22 | step: 56600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.953556582331657e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 4.38 | consumed tokens: 28979200.0 | grad norm avg: 6.22 | grad norm last: 6.37 | 
2025-12-27T23:24:24 | step: 56700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.953355765901506e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 5.19 | consumed tokens: 29030400.0 | grad norm avg: 6.26 | grad norm last: 7.9 | 
2025-12-27T23:24:26 | step: 56800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.953155677067116e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.12 | train loss last: 4.72 | consumed tokens: 29081600.0 | grad norm avg: 6.17 | grad norm last: 6.8 | 
2025-12-27T23:24:28 | step: 56900 | train samples/s: 99.5 | train mfu (16-bit): -1.0 | lr mean: 9.952954133041203e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 3.69 | consumed tokens: 29132800.0 | grad norm avg: 5.99 | grad norm last: 5.98 | 
2025-12-27T23:24:30 | step: 57000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.95275258901529e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.22 | train loss last: 4.62 | consumed tokens: 29184000.0 | grad norm avg: 6.05 | grad norm last: 7.44 | 
2025-12-27T23:24:32 | step: 57100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.952551772585139e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 4.12 | consumed tokens: 29235200.0 | grad norm avg: 6.05 | grad norm last: 6.05 | 
2025-12-27T23:24:34 | step: 57200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.952348773367703e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.13 | train loss last: 4.03 | consumed tokens: 29286400.0 | grad norm avg: 6.32 | grad norm last: 6.91 | 
2025-12-27T23:24:36 | step: 57300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.952145774150267e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.13 | train loss last: 4.53 | consumed tokens: 29337600.0 | grad norm avg: 6.12 | grad norm last: 6.8 | 
2025-12-27T23:24:38 | step: 57400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.95194204733707e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.83 | consumed tokens: 29388800.0 | grad norm avg: 6.01 | grad norm last: 5.13 | 
2025-12-27T23:24:40 | step: 57500 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.951738320523873e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 4.25 | consumed tokens: 29440000.0 | grad norm avg: 6.09 | grad norm last: 6.84 | 
2025-12-27T23:24:42 | step: 57600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.951534593710676e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.44 | consumed tokens: 29491200.0 | grad norm avg: 6.02 | grad norm last: 5.67 | 
2025-12-27T23:24:44 | step: 57700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.951330866897479e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 4.09 | consumed tokens: 29542400.0 | grad norm avg: 6.14 | grad norm last: 5.67 | 
2025-12-27T23:24:46 | step: 57800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.951125684892759e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.84 | consumed tokens: 29593600.0 | grad norm avg: 6.19 | grad norm last: 5.23 | 
2025-12-27T23:24:48 | step: 57900 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.950920502888039e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 4.06 | consumed tokens: 29644800.0 | grad norm avg: 6.15 | grad norm last: 5.29 | 
2025-12-27T23:24:50 | step: 58000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.950713865691796e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 4.59 | consumed tokens: 29696000.0 | grad norm avg: 6.11 | grad norm last: 7.61 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_58000-seen_tokens_29696000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_58000-seen_tokens_29696000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_58000-seen_tokens_29696000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_58000-seen_tokens_29696000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_58000-seen_tokens_29696000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_58000-seen_tokens_29696000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_58000-seen_tokens_29696000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_58000-seen_tokens_29696000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:24:53 | step: 58100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.950508683687076e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.94 | consumed tokens: 29747200.0 | grad norm avg: 5.95 | grad norm last: 7.49 | 
2025-12-27T23:24:55 | step: 58200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.950302046490833e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.94 | consumed tokens: 29798400.0 | grad norm avg: 5.99 | grad norm last: 6.63 | 
2025-12-27T23:24:57 | step: 58300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.95009540929459e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.25 | consumed tokens: 29849600.0 | grad norm avg: 6.18 | grad norm last: 5.75 | 
2025-12-27T23:24:59 | step: 58400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.949887316906825e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.03 | consumed tokens: 29900800.0 | grad norm avg: 6.05 | grad norm last: 5.37 | 
2025-12-27T23:25:01 | step: 58500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.949679224519059e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 5.31 | consumed tokens: 29952000.0 | grad norm avg: 6.08 | grad norm last: 6.14 | 
2025-12-27T23:25:03 | step: 58600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.949471132131293e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 3.23 | consumed tokens: 30003200.0 | grad norm avg: 6.02 | grad norm last: 5.18 | 
2025-12-27T23:25:05 | step: 58700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.949263039743528e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 3.64 | consumed tokens: 30054400.0 | grad norm avg: 6.23 | grad norm last: 5.75 | 
2025-12-27T23:25:07 | step: 58800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.949053492164239e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.14 | train loss last: 4.47 | consumed tokens: 30105600.0 | grad norm avg: 6.26 | grad norm last: 6.82 | 
2025-12-27T23:25:09 | step: 58900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 9.948843944584951e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 4.19 | consumed tokens: 30156800.0 | grad norm avg: 6.05 | grad norm last: 5.3 | 
2025-12-27T23:25:11 | step: 59000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.948634397005662e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.84 | consumed tokens: 30208000.0 | grad norm avg: 6.58 | grad norm last: 5.24 | 
2025-12-27T23:25:13 | step: 59100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.94842266663909e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 3.53 | consumed tokens: 30259200.0 | grad norm avg: 6.1 | grad norm last: 6.19 | 
2025-12-27T23:25:15 | step: 59200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.94821239146404e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.12 | train loss last: 6.88 | consumed tokens: 30310400.0 | grad norm avg: 6.17 | grad norm last: 7.71 | 
2025-12-27T23:25:17 | step: 59300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.948000661097467e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.59 | consumed tokens: 30361600.0 | grad norm avg: 6.11 | grad norm last: 5.18 | 
2025-12-27T23:25:19 | step: 59400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.947788930730894e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.16 | consumed tokens: 30412800.0 | grad norm avg: 6.08 | grad norm last: 5.48 | 
2025-12-27T23:25:21 | step: 59500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.94757647276856e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.86 | consumed tokens: 30464000.0 | grad norm avg: 5.97 | grad norm last: 6.47 | 
2025-12-27T23:25:23 | step: 59600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.947364014806226e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 3.95 | consumed tokens: 30515200.0 | grad norm avg: 6.19 | grad norm last: 5.81 | 
2025-12-27T23:25:25 | step: 59700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.94715082924813e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.84 | consumed tokens: 30566400.0 | grad norm avg: 5.95 | grad norm last: 5.11 | 
2025-12-27T23:25:27 | step: 59800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.946937643690035e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 4.94 | consumed tokens: 30617600.0 | grad norm avg: 6.04 | grad norm last: 9.18 | 
2025-12-27T23:25:29 | step: 59900 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.946723730536178e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 5.19 | consumed tokens: 30668800.0 | grad norm avg: 6.14 | grad norm last: 6.49 | 
2025-12-27T23:25:31 | step: 60000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.946509817382321e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.69 | consumed tokens: 30720000.0 | grad norm avg: 6.07 | grad norm last: 5.72 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_60000-seen_tokens_30720000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_60000-seen_tokens_30720000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_60000-seen_tokens_30720000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_60000-seen_tokens_30720000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_60000-seen_tokens_30720000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_60000-seen_tokens_30720000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_60000-seen_tokens_30720000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_60000-seen_tokens_30720000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:25:33 | step: 60100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.946294449036941e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 4.31 | consumed tokens: 30771200.0 | grad norm avg: 6.05 | grad norm last: 6.03 | 
2025-12-27T23:25:35 | step: 60200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.946079808287323e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.12 | train loss last: 4.53 | consumed tokens: 30822400.0 | grad norm avg: 5.99 | grad norm last: 7.28 | 
2025-12-27T23:25:37 | step: 60300 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.945863712346181e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.61 | consumed tokens: 30873600.0 | grad norm avg: 6.09 | grad norm last: 5.89 | 
2025-12-27T23:25:39 | step: 60400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.945648344000801e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 3.89 | consumed tokens: 30924800.0 | grad norm avg: 6.04 | grad norm last: 6.18 | 
2025-12-27T23:25:41 | step: 60500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.945431520463899e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 3.77 | consumed tokens: 30976000.0 | grad norm avg: 6.15 | grad norm last: 5.25 | 
2025-12-27T23:25:43 | step: 60600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.945214696926996e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.12 | train loss last: 4.19 | consumed tokens: 31027200.0 | grad norm avg: 6.22 | grad norm last: 6.24 | 
2025-12-27T23:25:45 | step: 60700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.944997145794332e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 4.72 | consumed tokens: 31078400.0 | grad norm avg: 6.15 | grad norm last: 7.88 | 
2025-12-27T23:25:47 | step: 60800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.944779594661668e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.09 | consumed tokens: 31129600.0 | grad norm avg: 6.17 | grad norm last: 5.54 | 
2025-12-27T23:25:49 | step: 60900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.944561315933242e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 4.34 | consumed tokens: 31180800.0 | grad norm avg: 6.09 | grad norm last: 5.81 | 
2025-12-27T23:25:51 | step: 61000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.944343037204817e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.31 | consumed tokens: 31232000.0 | grad norm avg: 5.8 | grad norm last: 5.52 | 
2025-12-27T23:25:53 | step: 61100 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.94412403088063e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 3.39 | consumed tokens: 31283200.0 | grad norm avg: 6.22 | grad norm last: 5.65 | 
2025-12-27T23:25:55 | step: 61200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.94390356936492e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.12 | consumed tokens: 31334400.0 | grad norm avg: 6.01 | grad norm last: 5.75 | 
2025-12-27T23:25:57 | step: 61300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.943684563040733e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.24 | train loss last: 4.5 | consumed tokens: 31385600.0 | grad norm avg: 6.25 | grad norm last: 5.8 | 
2025-12-27T23:25:59 | step: 61400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.943464101525024e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 6.12 | consumed tokens: 31436800.0 | grad norm avg: 6.12 | grad norm last: 6.42 | 
2025-12-27T23:26:01 | step: 61500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.943244367605075e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.16 | consumed tokens: 31488000.0 | grad norm avg: 6.04 | grad norm last: 5.76 | 
2025-12-27T23:26:03 | step: 61600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.943023178493604e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.13 | train loss last: 4.25 | consumed tokens: 31539200.0 | grad norm avg: 6.1 | grad norm last: 5.86 | 
2025-12-27T23:26:05 | step: 61700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.94280053419061e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 2.98 | consumed tokens: 31590400.0 | grad norm avg: 6.18 | grad norm last: 5.24 | 
2025-12-27T23:26:07 | step: 61800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.942578617483377e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 4.0 | consumed tokens: 31641600.0 | grad norm avg: 6.05 | grad norm last: 5.82 | 
2025-12-27T23:26:09 | step: 61900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.942355245584622e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.06 | consumed tokens: 31692800.0 | grad norm avg: 5.93 | grad norm last: 5.76 | 
2025-12-27T23:26:11 | step: 62000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.94213332887739e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 4.38 | consumed tokens: 31744000.0 | grad norm avg: 6.23 | grad norm last: 6.61 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_62000-seen_tokens_31744000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_62000-seen_tokens_31744000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_62000-seen_tokens_31744000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_62000-seen_tokens_31744000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_62000-seen_tokens_31744000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_62000-seen_tokens_31744000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_62000-seen_tokens_31744000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_62000-seen_tokens_31744000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:26:14 | step: 62100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.941909956978634e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.19 | consumed tokens: 31795200.0 | grad norm avg: 6.24 | grad norm last: 5.39 | 
2025-12-27T23:26:16 | step: 62200 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.941685857484117e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.17 | train loss last: 4.22 | consumed tokens: 31846400.0 | grad norm avg: 6.42 | grad norm last: 5.99 | 
2025-12-27T23:26:18 | step: 62300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.941463213181123e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 4.03 | consumed tokens: 31897600.0 | grad norm avg: 6.25 | grad norm last: 6.42 | 
2025-12-27T23:26:20 | step: 62400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.941237658495083e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.12 | train loss last: 3.06 | consumed tokens: 31948800.0 | grad norm avg: 6.18 | grad norm last: 6.05 | 
2025-12-27T23:26:22 | step: 62500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.941012831404805e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.28 | consumed tokens: 32000000.0 | grad norm avg: 6.28 | grad norm last: 5.96 | 
2025-12-27T23:26:24 | step: 62600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.940788004314527e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.12 | consumed tokens: 32051200.0 | grad norm avg: 6.24 | grad norm last: 5.95 | 
2025-12-27T23:26:26 | step: 62700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.940560994436964e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 3.98 | consumed tokens: 32102400.0 | grad norm avg: 6.16 | grad norm last: 5.74 | 
2025-12-27T23:26:28 | step: 62800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.940334712155163e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 4.31 | consumed tokens: 32153600.0 | grad norm avg: 6.43 | grad norm last: 5.85 | 
2025-12-27T23:26:30 | step: 62900 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.940108429873362e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 4.41 | consumed tokens: 32204800.0 | grad norm avg: 6.14 | grad norm last: 6.83 | 
2025-12-27T23:26:32 | step: 63000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.9398814199958e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 4.66 | consumed tokens: 32256000.0 | grad norm avg: 6.08 | grad norm last: 6.88 | 
2025-12-27T23:26:34 | step: 63100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.939653682522476e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 4.41 | consumed tokens: 32307200.0 | grad norm avg: 5.83 | grad norm last: 5.98 | 
2025-12-27T23:26:36 | step: 63200 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.939425945049152e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.25 | consumed tokens: 32358400.0 | grad norm avg: 5.96 | grad norm last: 5.69 | 
2025-12-27T23:26:38 | step: 63300 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.939197479980066e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 6.03 | consumed tokens: 32409600.0 | grad norm avg: 6.32 | grad norm last: 8.08 | 
2025-12-27T23:26:40 | step: 63400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.938967559719458e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 3.97 | consumed tokens: 32460800.0 | grad norm avg: 6.15 | grad norm last: 8.06 | 
2025-12-27T23:26:42 | step: 63500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.938739094650373e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 4.59 | consumed tokens: 32512000.0 | grad norm avg: 6.49 | grad norm last: 5.71 | 
2025-12-27T23:26:44 | step: 63600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.938509174389765e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 4.22 | consumed tokens: 32563200.0 | grad norm avg: 6.05 | grad norm last: 7.99 | 
2025-12-27T23:26:46 | step: 63700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.938279254129156e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.59 | consumed tokens: 32614400.0 | grad norm avg: 6.14 | grad norm last: 6.02 | 
2025-12-27T23:26:48 | step: 63800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.938047878677025e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.38 | consumed tokens: 32665600.0 | grad norm avg: 6.08 | grad norm last: 5.76 | 
2025-12-27T23:26:50 | step: 63900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.937817958416417e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.86 | consumed tokens: 32716800.0 | grad norm avg: 6.01 | grad norm last: 5.61 | 
2025-12-27T23:26:52 | step: 64000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.937586582964286e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 4.94 | consumed tokens: 32768000.0 | grad norm avg: 6.1 | grad norm last: 7.14 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_64000-seen_tokens_32768000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_64000-seen_tokens_32768000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_64000-seen_tokens_32768000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_64000-seen_tokens_32768000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_64000-seen_tokens_32768000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_64000-seen_tokens_32768000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_64000-seen_tokens_32768000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_64000-seen_tokens_32768000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:26:54 | step: 64100 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.937354479916394e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.09 | train loss last: 4.19 | consumed tokens: 32819200.0 | grad norm avg: 6.09 | grad norm last: 7.0 | 
2025-12-27T23:26:56 | step: 64200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.937122376868501e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 4.38 | consumed tokens: 32870400.0 | grad norm avg: 6.19 | grad norm last: 5.95 | 
2025-12-27T23:26:58 | step: 64300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.936889546224847e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.67 | consumed tokens: 32921600.0 | grad norm avg: 6.18 | grad norm last: 4.75 | 
2025-12-27T23:27:00 | step: 64400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.936656715581194e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.09 | consumed tokens: 32972800.0 | grad norm avg: 6.04 | grad norm last: 5.62 | 
2025-12-27T23:27:02 | step: 64500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.936423157341778e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.92 | consumed tokens: 33024000.0 | grad norm avg: 6.07 | grad norm last: 6.15 | 
2025-12-27T23:27:04 | step: 64600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 9.936189599102363e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.48 | consumed tokens: 33075200.0 | grad norm avg: 6.14 | grad norm last: 6.01 | 
2025-12-27T23:27:06 | step: 64700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 9.935954585671425e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.31 | consumed tokens: 33126400.0 | grad norm avg: 5.89 | grad norm last: 7.22 | 
2025-12-27T23:27:08 | step: 64800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.935719572240487e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.97 | consumed tokens: 33177600.0 | grad norm avg: 6.04 | grad norm last: 5.61 | 
2025-12-27T23:27:10 | step: 64900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.93548528640531e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 5.0 | consumed tokens: 33228800.0 | grad norm avg: 6.07 | grad norm last: 7.46 | 
2025-12-27T23:27:12 | step: 65000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.935248090187088e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 3.88 | consumed tokens: 33280000.0 | grad norm avg: 6.15 | grad norm last: 5.22 | 
2025-12-27T23:27:14 | step: 65100 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.935013804351911e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 4.25 | consumed tokens: 33331200.0 | grad norm avg: 6.13 | grad norm last: 5.98 | 
2025-12-27T23:27:16 | step: 65200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.934775880537927e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 4.09 | consumed tokens: 33382400.0 | grad norm avg: 6.31 | grad norm last: 6.25 | 
2025-12-27T23:27:18 | step: 65300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.934539411915466e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 4.78 | consumed tokens: 33433600.0 | grad norm avg: 6.04 | grad norm last: 8.03 | 
2025-12-27T23:27:20 | step: 65400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.934302215697244e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 4.78 | consumed tokens: 33484800.0 | grad norm avg: 6.17 | grad norm last: 8.35 | 
2025-12-27T23:27:22 | step: 65500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.934065019479021e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.8 | consumed tokens: 33536000.0 | grad norm avg: 6.06 | grad norm last: 5.76 | 
2025-12-27T23:27:24 | step: 65600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.933826368069276e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 3.02 | consumed tokens: 33587200.0 | grad norm avg: 6.18 | grad norm last: 5.01 | 
2025-12-27T23:27:26 | step: 65700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.933587716659531e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 4.84 | consumed tokens: 33638400.0 | grad norm avg: 6.25 | grad norm last: 5.99 | 
2025-12-27T23:27:28 | step: 65800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.933349065249786e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 3.45 | consumed tokens: 33689600.0 | grad norm avg: 6.25 | grad norm last: 5.8 | 
2025-12-27T23:27:30 | step: 65900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.933108231052756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 3.5 | consumed tokens: 33740800.0 | grad norm avg: 6.28 | grad norm last: 5.34 | 
2025-12-27T23:27:32 | step: 66000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.93286885204725e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 3.25 | consumed tokens: 33792000.0 | grad norm avg: 6.37 | grad norm last: 4.78 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_66000-seen_tokens_33792000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_66000-seen_tokens_33792000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_66000-seen_tokens_33792000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_66000-seen_tokens_33792000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_66000-seen_tokens_33792000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_66000-seen_tokens_33792000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_66000-seen_tokens_33792000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_66000-seen_tokens_33792000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:27:35 | step: 66100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.93262801785022e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 4.47 | consumed tokens: 33843200.0 | grad norm avg: 6.15 | grad norm last: 5.83 | 
2025-12-27T23:27:37 | step: 66200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.932387183653191e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.27 | consumed tokens: 33894400.0 | grad norm avg: 5.99 | grad norm last: 4.88 | 
2025-12-27T23:27:39 | step: 66300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.9321456218604e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.0 | consumed tokens: 33945600.0 | grad norm avg: 5.96 | grad norm last: 5.76 | 
2025-12-27T23:27:41 | step: 66400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.931905515259132e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.25 | consumed tokens: 33996800.0 | grad norm avg: 6.17 | grad norm last: 5.44 | 
2025-12-27T23:27:43 | step: 66500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.931662498274818e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.95 | consumed tokens: 34048000.0 | grad norm avg: 5.98 | grad norm last: 5.38 | 
2025-12-27T23:27:45 | step: 66600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.931420208886266e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.58 | consumed tokens: 34099200.0 | grad norm avg: 6.11 | grad norm last: 4.96 | 
2025-12-27T23:27:47 | step: 66700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.931177919497713e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.16 | consumed tokens: 34150400.0 | grad norm avg: 6.02 | grad norm last: 6.37 | 
2025-12-27T23:27:49 | step: 66800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.930933447321877e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.84 | consumed tokens: 34201600.0 | grad norm avg: 5.88 | grad norm last: 5.49 | 
2025-12-27T23:27:51 | step: 66900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.930689702741802e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.78 | consumed tokens: 34252800.0 | grad norm avg: 6.14 | grad norm last: 6.51 | 
2025-12-27T23:27:53 | step: 67000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.930445958161727e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 4.0 | consumed tokens: 34304000.0 | grad norm avg: 6.06 | grad norm last: 5.73 | 
2025-12-27T23:27:55 | step: 67100 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.93020148598589e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.97 | consumed tokens: 34355200.0 | grad norm avg: 6.01 | grad norm last: 5.47 | 
2025-12-27T23:27:57 | step: 67200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.929956286214292e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.12 | train loss last: 5.03 | consumed tokens: 34406400.0 | grad norm avg: 6.3 | grad norm last: 6.81 | 
2025-12-27T23:27:59 | step: 67300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.929711086442694e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 4.69 | consumed tokens: 34457600.0 | grad norm avg: 6.14 | grad norm last: 5.52 | 
2025-12-27T23:28:01 | step: 67400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.929464431479573e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.77 | consumed tokens: 34508800.0 | grad norm avg: 6.04 | grad norm last: 5.81 | 
2025-12-27T23:28:03 | step: 67500 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.929217776516452e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.94 | consumed tokens: 34560000.0 | grad norm avg: 6.12 | grad norm last: 5.88 | 
2025-12-27T23:28:05 | step: 67600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.928971849149093e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.09 | consumed tokens: 34611200.0 | grad norm avg: 6.32 | grad norm last: 6.07 | 
2025-12-27T23:28:07 | step: 67700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.928724466590211e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.45 | consumed tokens: 34662400.0 | grad norm avg: 6.3 | grad norm last: 6.27 | 
2025-12-27T23:28:09 | step: 67800 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.928477084031329e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 3.78 | consumed tokens: 34713600.0 | grad norm avg: 6.46 | grad norm last: 5.83 | 
2025-12-27T23:28:11 | step: 67900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.928228246280923e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.95 | consumed tokens: 34764800.0 | grad norm avg: 6.09 | grad norm last: 5.38 | 
2025-12-27T23:28:13 | step: 68000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.92798013612628e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.06 | consumed tokens: 34816000.0 | grad norm avg: 6.16 | grad norm last: 5.41 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_68000-seen_tokens_34816000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_68000-seen_tokens_34816000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_68000-seen_tokens_34816000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_68000-seen_tokens_34816000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_68000-seen_tokens_34816000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_68000-seen_tokens_34816000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_68000-seen_tokens_34816000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_68000-seen_tokens_34816000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:28:15 | step: 68100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.927732025971636e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.15 | train loss last: 4.88 | consumed tokens: 34867200.0 | grad norm avg: 6.17 | grad norm last: 7.63 | 
2025-12-27T23:28:17 | step: 68200 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.92748246062547e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.62 | consumed tokens: 34918400.0 | grad norm avg: 6.09 | grad norm last: 5.31 | 
2025-12-27T23:28:19 | step: 68300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.927232167683542e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.41 | consumed tokens: 34969600.0 | grad norm avg: 6.13 | grad norm last: 5.97 | 
2025-12-27T23:28:21 | step: 68400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.926982602337375e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.75 | consumed tokens: 35020800.0 | grad norm avg: 6.19 | grad norm last: 5.74 | 
2025-12-27T23:28:23 | step: 68500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.926731581799686e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 3.64 | consumed tokens: 35072000.0 | grad norm avg: 6.19 | grad norm last: 5.45 | 
2025-12-27T23:28:25 | step: 68600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.926480561261997e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.44 | consumed tokens: 35123200.0 | grad norm avg: 6.1 | grad norm last: 7.35 | 
2025-12-27T23:28:27 | step: 68700 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.926230268320069e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.44 | consumed tokens: 35174400.0 | grad norm avg: 6.1 | grad norm last: 5.03 | 
2025-12-27T23:28:29 | step: 68800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.925977064995095e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.61 | consumed tokens: 35225600.0 | grad norm avg: 6.17 | grad norm last: 5.36 | 
2025-12-27T23:28:31 | step: 68900 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.925725316861644e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.92 | consumed tokens: 35276800.0 | grad norm avg: 6.11 | grad norm last: 5.82 | 
2025-12-27T23:28:33 | step: 69000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.925472113536671e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.66 | consumed tokens: 35328000.0 | grad norm avg: 6.14 | grad norm last: 4.77 | 
2025-12-27T23:28:35 | step: 69100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.925218910211697e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 4.38 | consumed tokens: 35379200.0 | grad norm avg: 6.13 | grad norm last: 6.6 | 
2025-12-27T23:28:37 | step: 69200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.924965706886724e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.47 | consumed tokens: 35430400.0 | grad norm avg: 6.02 | grad norm last: 5.26 | 
2025-12-27T23:28:39 | step: 69300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.924711775965989e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.2 | consumed tokens: 35481600.0 | grad norm avg: 6.03 | grad norm last: 5.02 | 
2025-12-27T23:28:41 | step: 69400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.924456389853731e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.89 | consumed tokens: 35532800.0 | grad norm avg: 6.06 | grad norm last: 5.94 | 
2025-12-27T23:28:43 | step: 69500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.924202458932996e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.06 | consumed tokens: 35584000.0 | grad norm avg: 6.0 | grad norm last: 7.5 | 
2025-12-27T23:28:45 | step: 69600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.923947072820738e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.69 | consumed tokens: 35635200.0 | grad norm avg: 6.11 | grad norm last: 5.01 | 
2025-12-27T23:28:47 | step: 69700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.923692414304242e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.12 | consumed tokens: 35686400.0 | grad norm avg: 5.99 | grad norm last: 6.02 | 
2025-12-27T23:28:49 | step: 69800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.923436300596222e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.16 | consumed tokens: 35737600.0 | grad norm avg: 6.17 | grad norm last: 7.11 | 
2025-12-27T23:28:51 | step: 69900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.92317873169668e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 4.09 | consumed tokens: 35788800.0 | grad norm avg: 6.09 | grad norm last: 6.98 | 
2025-12-27T23:28:53 | step: 70000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.9229218903929e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.13 | train loss last: 3.77 | consumed tokens: 35840000.0 | grad norm avg: 6.34 | grad norm last: 5.76 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_70000-seen_tokens_35840000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_70000-seen_tokens_35840000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_70000-seen_tokens_35840000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_70000-seen_tokens_35840000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_70000-seen_tokens_35840000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_70000-seen_tokens_35840000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_70000-seen_tokens_35840000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_70000-seen_tokens_35840000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:28:56 | step: 70100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.922663593897596e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.27 | consumed tokens: 35891200.0 | grad norm avg: 6.06 | grad norm last: 4.7 | 
2025-12-27T23:28:58 | step: 70200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.922406752593815e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.91 | consumed tokens: 35942400.0 | grad norm avg: 5.93 | grad norm last: 5.83 | 
2025-12-27T23:29:00 | step: 70300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.922148456098512e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 3.66 | consumed tokens: 35993600.0 | grad norm avg: 6.13 | grad norm last: 5.59 | 
2025-12-27T23:29:02 | step: 70400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.921889432007447e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.36 | consumed tokens: 36044800.0 | grad norm avg: 6.0 | grad norm last: 6.19 | 
2025-12-27T23:29:04 | step: 70500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.921630407916382e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 4.31 | consumed tokens: 36096000.0 | grad norm avg: 6.2 | grad norm last: 5.97 | 
2025-12-27T23:29:06 | step: 70600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.921371383825317e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 3.98 | consumed tokens: 36147200.0 | grad norm avg: 6.25 | grad norm last: 6.52 | 
2025-12-27T23:29:08 | step: 70700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.921110904542729e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 5.75 | consumed tokens: 36198400.0 | grad norm avg: 6.08 | grad norm last: 7.9 | 
2025-12-27T23:29:10 | step: 70800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.920850425260141e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 4.5 | consumed tokens: 36249600.0 | grad norm avg: 6.36 | grad norm last: 8.27 | 
2025-12-27T23:29:12 | step: 70900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.920589945977554e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.94 | consumed tokens: 36300800.0 | grad norm avg: 5.99 | grad norm last: 6.28 | 
2025-12-27T23:29:14 | step: 71000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.920328739099205e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 4.22 | consumed tokens: 36352000.0 | grad norm avg: 6.27 | grad norm last: 5.69 | 
2025-12-27T23:29:16 | step: 71100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.920066804625094e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.78 | consumed tokens: 36403200.0 | grad norm avg: 6.31 | grad norm last: 6.67 | 
2025-12-27T23:29:18 | step: 71200 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.919804870150983e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 4.03 | consumed tokens: 36454400.0 | grad norm avg: 6.08 | grad norm last: 5.84 | 
2025-12-27T23:29:20 | step: 71300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.919542208081111e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.98 | consumed tokens: 36505600.0 | grad norm avg: 6.15 | grad norm last: 6.64 | 
2025-12-27T23:29:22 | step: 71400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.919280273607001e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.16 | train loss last: 3.56 | consumed tokens: 36556800.0 | grad norm avg: 6.3 | grad norm last: 5.95 | 
2025-12-27T23:29:24 | step: 71500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.919016156345606e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.27 | consumed tokens: 36608000.0 | grad norm avg: 6.27 | grad norm last: 8.49 | 
2025-12-27T23:29:26 | step: 71600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.918752039084211e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 5.12 | consumed tokens: 36659200.0 | grad norm avg: 6.22 | grad norm last: 6.43 | 
2025-12-27T23:29:28 | step: 71700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.918488649418578e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.47 | consumed tokens: 36710400.0 | grad norm avg: 6.08 | grad norm last: 5.58 | 
2025-12-27T23:29:30 | step: 71800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.918223804561421e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.84 | consumed tokens: 36761600.0 | grad norm avg: 6.25 | grad norm last: 5.47 | 
2025-12-27T23:29:32 | step: 71900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.917958959704265e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 3.8 | consumed tokens: 36812800.0 | grad norm avg: 6.23 | grad norm last: 5.94 | 
2025-12-27T23:29:34 | step: 72000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.917692659655586e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.7 | consumed tokens: 36864000.0 | grad norm avg: 6.33 | grad norm last: 6.66 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_72000-seen_tokens_36864000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_72000-seen_tokens_36864000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_72000-seen_tokens_36864000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_72000-seen_tokens_36864000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_72000-seen_tokens_36864000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_72000-seen_tokens_36864000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_72000-seen_tokens_36864000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_72000-seen_tokens_36864000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:29:36 | step: 72100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.917427087202668e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.97 | train loss last: 3.78 | consumed tokens: 36915200.0 | grad norm avg: 6.15 | grad norm last: 5.2 | 
2025-12-27T23:29:38 | step: 72200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.91716151474975e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.98 | consumed tokens: 36966400.0 | grad norm avg: 6.24 | grad norm last: 6.16 | 
2025-12-27T23:29:40 | step: 72300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.916893759509549e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 4.72 | consumed tokens: 37017600.0 | grad norm avg: 6.27 | grad norm last: 6.66 | 
2025-12-27T23:29:42 | step: 72400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.916626731865108e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.48 | consumed tokens: 37068800.0 | grad norm avg: 6.19 | grad norm last: 5.07 | 
2025-12-27T23:29:44 | step: 72500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.916359704220667e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.8 | consumed tokens: 37120000.0 | grad norm avg: 6.14 | grad norm last: 5.87 | 
2025-12-27T23:29:46 | step: 72600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.916091221384704e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 4.09 | consumed tokens: 37171200.0 | grad norm avg: 6.03 | grad norm last: 5.68 | 
2025-12-27T23:29:48 | step: 72700 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.915822738548741e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 3.44 | consumed tokens: 37222400.0 | grad norm avg: 6.45 | grad norm last: 5.3 | 
2025-12-27T23:29:50 | step: 72800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.915554983308539e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 7.16 | consumed tokens: 37273600.0 | grad norm avg: 6.72 | grad norm last: 52.13 | 
2025-12-27T23:29:52 | step: 72900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.915285045281053e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.25 | consumed tokens: 37324800.0 | grad norm avg: 6.29 | grad norm last: 5.88 | 
2025-12-27T23:29:54 | step: 73000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.915015107253566e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 4.22 | consumed tokens: 37376000.0 | grad norm avg: 6.24 | grad norm last: 6.58 | 
2025-12-27T23:29:56 | step: 73100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.914745896821842e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.48 | consumed tokens: 37427200.0 | grad norm avg: 6.15 | grad norm last: 5.27 | 
2025-12-27T23:29:58 | step: 73200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.914473776007071e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.75 | consumed tokens: 37478400.0 | grad norm avg: 6.1 | grad norm last: 5.58 | 
2025-12-27T23:30:00 | step: 73300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.914203110383824e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.22 | consumed tokens: 37529600.0 | grad norm avg: 6.02 | grad norm last: 5.78 | 
2025-12-27T23:30:02 | step: 73400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.913931717164814e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.66 | consumed tokens: 37580800.0 | grad norm avg: 6.15 | grad norm last: 10.75 | 
2025-12-27T23:30:04 | step: 73500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.913660323945805e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 4.31 | consumed tokens: 37632000.0 | grad norm avg: 6.2 | grad norm last: 5.57 | 
2025-12-27T23:30:06 | step: 73600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.913387475535274e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 4.19 | consumed tokens: 37683200.0 | grad norm avg: 6.26 | grad norm last: 5.86 | 
2025-12-27T23:30:08 | step: 73700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.913116082316265e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.53 | consumed tokens: 37734400.0 | grad norm avg: 6.33 | grad norm last: 6.34 | 
2025-12-27T23:30:10 | step: 73800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.912842506309971e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.25 | consumed tokens: 37785600.0 | grad norm avg: 6.3 | grad norm last: 5.39 | 
2025-12-27T23:30:12 | step: 73900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.912568930303678e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.44 | consumed tokens: 37836800.0 | grad norm avg: 6.08 | grad norm last: 5.83 | 
2025-12-27T23:30:14 | step: 74000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.912295354297385e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.78 | consumed tokens: 37888000.0 | grad norm avg: 6.14 | grad norm last: 5.95 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_74000-seen_tokens_37888000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_74000-seen_tokens_37888000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_74000-seen_tokens_37888000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_74000-seen_tokens_37888000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_74000-seen_tokens_37888000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_74000-seen_tokens_37888000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_74000-seen_tokens_37888000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_74000-seen_tokens_37888000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:30:17 | step: 74100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.912020323099568e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.01 | train loss last: 4.19 | consumed tokens: 37939200.0 | grad norm avg: 6.2 | grad norm last: 6.67 | 
2025-12-27T23:30:19 | step: 74200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.911745291901752e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.16 | consumed tokens: 37990400.0 | grad norm avg: 5.99 | grad norm last: 4.89 | 
2025-12-27T23:30:21 | step: 74300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.911470260703936e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.64 | consumed tokens: 38041600.0 | grad norm avg: 6.26 | grad norm last: 6.21 | 
2025-12-27T23:30:23 | step: 74400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.91119522950612e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.66 | consumed tokens: 38092800.0 | grad norm avg: 6.38 | grad norm last: 5.16 | 
2025-12-27T23:30:25 | step: 74500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.910917287925258e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 4.0 | consumed tokens: 38144000.0 | grad norm avg: 6.32 | grad norm last: 5.52 | 
2025-12-27T23:30:27 | step: 74600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.910642256727442e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.34 | consumed tokens: 38195200.0 | grad norm avg: 6.53 | grad norm last: 7.21 | 
2025-12-27T23:30:29 | step: 74700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.91036431514658e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.98 | consumed tokens: 38246400.0 | grad norm avg: 6.57 | grad norm last: 5.98 | 
2025-12-27T23:30:31 | step: 74800 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 9.91008710116148e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 4.0 | consumed tokens: 38297600.0 | grad norm avg: 6.21 | grad norm last: 4.96 | 
2025-12-27T23:30:33 | step: 74900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.90980988717638e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.0 | consumed tokens: 38348800.0 | grad norm avg: 6.02 | grad norm last: 7.23 | 
2025-12-27T23:30:35 | step: 75000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.909531217999756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 4.09 | consumed tokens: 38400000.0 | grad norm avg: 6.12 | grad norm last: 5.43 | 
2025-12-27T23:30:37 | step: 75100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.909252548823133e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.66 | consumed tokens: 38451200.0 | grad norm avg: 6.31 | grad norm last: 6.28 | 
2025-12-27T23:30:39 | step: 75200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.908973152050748e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.34 | consumed tokens: 38502400.0 | grad norm avg: 6.49 | grad norm last: 5.87 | 
2025-12-27T23:30:41 | step: 75300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.908693755278364e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 5.0 | consumed tokens: 38553600.0 | grad norm avg: 6.42 | grad norm last: 7.83 | 
2025-12-27T23:30:43 | step: 75400 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.908414358505979e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.47 | consumed tokens: 38604800.0 | grad norm avg: 6.23 | grad norm last: 5.56 | 
2025-12-27T23:30:45 | step: 75500 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.908134234137833e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 4.31 | consumed tokens: 38656000.0 | grad norm avg: 6.44 | grad norm last: 5.95 | 
2025-12-27T23:30:47 | step: 75600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.907854109769687e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.8 | consumed tokens: 38707200.0 | grad norm avg: 6.38 | grad norm last: 5.76 | 
2025-12-27T23:30:49 | step: 75700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.907571802614257e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.86 | consumed tokens: 38758400.0 | grad norm avg: 6.25 | grad norm last: 5.86 | 
2025-12-27T23:30:51 | step: 75800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.907290223054588e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.33 | consumed tokens: 38809600.0 | grad norm avg: 6.01 | grad norm last: 5.22 | 
2025-12-27T23:30:53 | step: 75900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.907008643494919e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.28 | consumed tokens: 38860800.0 | grad norm avg: 6.71 | grad norm last: 6.85 | 
2025-12-27T23:30:55 | step: 76000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.906726336339489e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.94 | consumed tokens: 38912000.0 | grad norm avg: 6.29 | grad norm last: 7.31 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_76000-seen_tokens_38912000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_76000-seen_tokens_38912000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_76000-seen_tokens_38912000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_76000-seen_tokens_38912000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_76000-seen_tokens_38912000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_76000-seen_tokens_38912000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_76000-seen_tokens_38912000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_76000-seen_tokens_38912000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:30:57 | step: 76100 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.906443301588297e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.98 | train loss last: 3.84 | consumed tokens: 38963200.0 | grad norm avg: 6.21 | grad norm last: 5.39 | 
2025-12-27T23:30:59 | step: 76200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.906160266837105e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.19 | consumed tokens: 39014400.0 | grad norm avg: 6.12 | grad norm last: 6.6 | 
2025-12-27T23:31:02 | step: 76300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.90587577689439e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 4.28 | consumed tokens: 39065600.0 | grad norm avg: 6.44 | grad norm last: 5.6 | 
2025-12-27T23:31:04 | step: 76400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.905591286951676e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 3.5 | consumed tokens: 39116800.0 | grad norm avg: 6.3 | grad norm last: 5.14 | 
2025-12-27T23:31:06 | step: 76500 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.905307524604723e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 4.41 | consumed tokens: 39168000.0 | grad norm avg: 6.27 | grad norm last: 6.28 | 
2025-12-27T23:31:08 | step: 76600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.905022307066247e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 3.41 | consumed tokens: 39219200.0 | grad norm avg: 6.16 | grad norm last: 5.35 | 
2025-12-27T23:31:10 | step: 76700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.904737089527771e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 4.34 | consumed tokens: 39270400.0 | grad norm avg: 6.22 | grad norm last: 6.51 | 
2025-12-27T23:31:12 | step: 76800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.904450416797772e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.88 | consumed tokens: 39321600.0 | grad norm avg: 6.37 | grad norm last: 6.62 | 
2025-12-27T23:31:14 | step: 76900 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.904165199259296e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.8 | consumed tokens: 39372800.0 | grad norm avg: 6.39 | grad norm last: 5.75 | 
2025-12-27T23:31:16 | step: 77000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.903878526529297e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.98 | consumed tokens: 39424000.0 | grad norm avg: 6.48 | grad norm last: 5.51 | 
2025-12-27T23:31:18 | step: 77100 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.903591126203537e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.12 | consumed tokens: 39475200.0 | grad norm avg: 6.13 | grad norm last: 6.59 | 
2025-12-27T23:31:20 | step: 77200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.903303725877777e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.44 | consumed tokens: 39526400.0 | grad norm avg: 5.96 | grad norm last: 6.4 | 
2025-12-27T23:31:22 | step: 77300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.903015597956255e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 2.94 | consumed tokens: 39577600.0 | grad norm avg: 6.06 | grad norm last: 5.24 | 
2025-12-27T23:31:24 | step: 77400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.902727470034733e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 4.28 | consumed tokens: 39628800.0 | grad norm avg: 6.28 | grad norm last: 5.79 | 
2025-12-27T23:31:26 | step: 77500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.90243861451745e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 4.47 | consumed tokens: 39680000.0 | grad norm avg: 6.36 | grad norm last: 6.32 | 
2025-12-27T23:31:28 | step: 77600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.902149759000167e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.97 | consumed tokens: 39731200.0 | grad norm avg: 6.22 | grad norm last: 5.53 | 
2025-12-27T23:31:30 | step: 77700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.901859448291361e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.44 | consumed tokens: 39782400.0 | grad norm avg: 6.46 | grad norm last: 8.56 | 
2025-12-27T23:31:32 | step: 77800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.901569137582555e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.84 | consumed tokens: 39833600.0 | grad norm avg: 6.43 | grad norm last: 6.56 | 
2025-12-27T23:31:34 | step: 77900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.901278099277988e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 4.0 | consumed tokens: 39884800.0 | grad norm avg: 6.32 | grad norm last: 6.3 | 
2025-12-27T23:31:36 | step: 78000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.900987060973421e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.73 | consumed tokens: 39936000.0 | grad norm avg: 6.34 | grad norm last: 6.02 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_78000-seen_tokens_39936000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_78000-seen_tokens_39936000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_78000-seen_tokens_39936000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_78000-seen_tokens_39936000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_78000-seen_tokens_39936000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_78000-seen_tokens_39936000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_78000-seen_tokens_39936000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_78000-seen_tokens_39936000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:31:38 | step: 78100 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.900696022668853e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.09 | train loss last: 4.62 | consumed tokens: 39987200.0 | grad norm avg: 6.78 | grad norm last: 7.7 | 
2025-12-27T23:31:40 | step: 78200 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.900404984364286e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 5.09 | consumed tokens: 40038400.0 | grad norm avg: 6.19 | grad norm last: 7.75 | 
2025-12-27T23:31:42 | step: 78300 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.900112490868196e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.83 | consumed tokens: 40089600.0 | grad norm avg: 6.16 | grad norm last: 6.9 | 
2025-12-27T23:31:44 | step: 78400 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.899819997372106e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 4.66 | consumed tokens: 40140800.0 | grad norm avg: 6.19 | grad norm last: 7.43 | 
2025-12-27T23:31:46 | step: 78500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.899527503876016e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.64 | consumed tokens: 40192000.0 | grad norm avg: 6.1 | grad norm last: 6.06 | 
2025-12-27T23:31:48 | step: 78600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.899233555188403e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.47 | consumed tokens: 40243200.0 | grad norm avg: 6.65 | grad norm last: 5.37 | 
2025-12-27T23:31:50 | step: 78700 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.89893960650079e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.98 | consumed tokens: 40294400.0 | grad norm avg: 6.22 | grad norm last: 6.03 | 
2025-12-27T23:31:52 | step: 78800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.898645657813177e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.28 | consumed tokens: 40345600.0 | grad norm avg: 6.28 | grad norm last: 7.54 | 
2025-12-27T23:31:54 | step: 78900 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.89835025393404e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.09 | consumed tokens: 40396800.0 | grad norm avg: 6.21 | grad norm last: 6.07 | 
2025-12-27T23:31:56 | step: 79000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.898055577650666e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 4.34 | consumed tokens: 40448000.0 | grad norm avg: 6.18 | grad norm last: 7.63 | 
2025-12-27T23:31:58 | step: 79100 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.897760901367292e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 4.19 | consumed tokens: 40499200.0 | grad norm avg: 6.61 | grad norm last: 7.13 | 
2025-12-27T23:32:00 | step: 79200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.897464042296633e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.12 | consumed tokens: 40550400.0 | grad norm avg: 6.19 | grad norm last: 5.55 | 
2025-12-27T23:32:02 | step: 79300 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.897167910821736e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.67 | consumed tokens: 40601600.0 | grad norm avg: 6.32 | grad norm last: 6.3 | 
2025-12-27T23:32:04 | step: 79400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.896871051751077e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 5.03 | consumed tokens: 40652800.0 | grad norm avg: 6.33 | grad norm last: 7.93 | 
2025-12-27T23:32:06 | step: 79500 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.896573465084657e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.64 | consumed tokens: 40704000.0 | grad norm avg: 6.13 | grad norm last: 5.2 | 
2025-12-27T23:32:08 | step: 79600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.896276606013998e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.13 | train loss last: 4.16 | consumed tokens: 40755200.0 | grad norm avg: 6.61 | grad norm last: 6.5 | 
2025-12-27T23:32:10 | step: 79700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.895977564156055e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 3.41 | consumed tokens: 40806400.0 | grad norm avg: 6.43 | grad norm last: 4.91 | 
2025-12-27T23:32:12 | step: 79800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.895678522298113e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.06 | consumed tokens: 40857600.0 | grad norm avg: 6.22 | grad norm last: 6.7 | 
2025-12-27T23:32:14 | step: 79900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.895380208035931e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 3.47 | consumed tokens: 40908800.0 | grad norm avg: 6.63 | grad norm last: 5.7 | 
2025-12-27T23:32:16 | step: 80000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 9.895081166177988e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.55 | consumed tokens: 40960000.0 | grad norm avg: 6.3 | grad norm last: 4.83 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_80000-seen_tokens_40960000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_80000-seen_tokens_40960000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_80000-seen_tokens_40960000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_80000-seen_tokens_40960000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_80000-seen_tokens_40960000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_80000-seen_tokens_40960000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_80000-seen_tokens_40960000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_80000-seen_tokens_40960000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:32:18 | step: 80100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 9.894781396724284e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.72 | consumed tokens: 41011200.0 | grad norm avg: 6.32 | grad norm last: 5.74 | 
2025-12-27T23:32:20 | step: 80200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.894480899674818e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.81 | consumed tokens: 41062400.0 | grad norm avg: 6.27 | grad norm last: 6.53 | 
2025-12-27T23:32:22 | step: 80300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.894181130221114e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 4.19 | consumed tokens: 41113600.0 | grad norm avg: 6.45 | grad norm last: 7.86 | 
2025-12-27T23:32:25 | step: 80400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.893879177980125e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 3.83 | consumed tokens: 41164800.0 | grad norm avg: 6.69 | grad norm last: 6.22 | 
2025-12-27T23:32:27 | step: 80500 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.893577225739136e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.34 | consumed tokens: 41216000.0 | grad norm avg: 6.36 | grad norm last: 7.33 | 
2025-12-27T23:32:29 | step: 80600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.893276001093909e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 3.44 | consumed tokens: 41267200.0 | grad norm avg: 6.4 | grad norm last: 7.26 | 
2025-12-27T23:32:31 | step: 80700 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.892973321257159e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.83 | consumed tokens: 41318400.0 | grad norm avg: 6.16 | grad norm last: 5.67 | 
2025-12-27T23:32:33 | step: 80800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.892670641420409e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.31 | consumed tokens: 41369600.0 | grad norm avg: 6.36 | grad norm last: 5.54 | 
2025-12-27T23:32:35 | step: 80900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.892366506392136e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 4.16 | consumed tokens: 41420800.0 | grad norm avg: 6.3 | grad norm last: 6.42 | 
2025-12-27T23:32:37 | step: 81000 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.892063826555386e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.56 | consumed tokens: 41472000.0 | grad norm avg: 6.32 | grad norm last: 7.45 | 
2025-12-27T23:32:39 | step: 81100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.891759691527113e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.13 | train loss last: 3.97 | consumed tokens: 41523200.0 | grad norm avg: 6.46 | grad norm last: 5.54 | 
2025-12-27T23:32:41 | step: 81200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.89145555649884e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.48 | consumed tokens: 41574400.0 | grad norm avg: 6.36 | grad norm last: 6.95 | 
2025-12-27T23:32:43 | step: 81300 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.891149966279045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.09 | consumed tokens: 41625600.0 | grad norm avg: 6.22 | grad norm last: 5.44 | 
2025-12-27T23:32:45 | step: 81400 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.890845831250772e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.03 | consumed tokens: 41676800.0 | grad norm avg: 6.06 | grad norm last: 5.81 | 
2025-12-27T23:32:47 | step: 81500 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.890538785839453e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.48 | consumed tokens: 41728000.0 | grad norm avg: 6.27 | grad norm last: 5.59 | 
2025-12-27T23:32:49 | step: 81600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.890233195619658e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 5.03 | consumed tokens: 41779200.0 | grad norm avg: 6.25 | grad norm last: 6.53 | 
2025-12-27T23:32:51 | step: 81700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.8899268778041e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.94 | consumed tokens: 41830400.0 | grad norm avg: 6.49 | grad norm last: 5.39 | 
2025-12-27T23:32:53 | step: 81800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.88961910479702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.28 | consumed tokens: 41881600.0 | grad norm avg: 6.23 | grad norm last: 6.58 | 
2025-12-27T23:32:55 | step: 81900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.889312059385702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.31 | consumed tokens: 41932800.0 | grad norm avg: 6.21 | grad norm last: 5.48 | 
2025-12-27T23:32:57 | step: 82000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.889004286378622e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.09 | consumed tokens: 41984000.0 | grad norm avg: 6.52 | grad norm last: 6.21 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_82000-seen_tokens_41984000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_82000-seen_tokens_41984000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_82000-seen_tokens_41984000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_82000-seen_tokens_41984000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_82000-seen_tokens_41984000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_82000-seen_tokens_41984000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_82000-seen_tokens_41984000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_82000-seen_tokens_41984000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:32:59 | step: 82100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.888696513371542e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.99 | train loss last: 4.75 | consumed tokens: 42035200.0 | grad norm avg: 6.22 | grad norm last: 7.44 | 
2025-12-27T23:33:01 | step: 82200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.888387285172939e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 3.62 | consumed tokens: 42086400.0 | grad norm avg: 6.31 | grad norm last: 6.35 | 
2025-12-27T23:33:03 | step: 82300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.888078784570098e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.67 | consumed tokens: 42137600.0 | grad norm avg: 6.35 | grad norm last: 5.72 | 
2025-12-27T23:33:05 | step: 82400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.887768101179972e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 4.59 | consumed tokens: 42188800.0 | grad norm avg: 6.35 | grad norm last: 7.69 | 
2025-12-27T23:33:07 | step: 82500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.88745887298137e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.36 | consumed tokens: 42240000.0 | grad norm avg: 6.26 | grad norm last: 5.41 | 
2025-12-27T23:33:09 | step: 82600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.887149644782767e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 3.97 | consumed tokens: 42291200.0 | grad norm avg: 6.38 | grad norm last: 5.31 | 
2025-12-27T23:33:11 | step: 82700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.88683823379688e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.38 | consumed tokens: 42342400.0 | grad norm avg: 6.38 | grad norm last: 5.46 | 
2025-12-27T23:33:13 | step: 82800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.886526822810993e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.31 | consumed tokens: 42393600.0 | grad norm avg: 6.36 | grad norm last: 5.54 | 
2025-12-27T23:33:15 | step: 82900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.886215411825106e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.66 | consumed tokens: 42444800.0 | grad norm avg: 6.51 | grad norm last: 5.9 | 
2025-12-27T23:33:17 | step: 83000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.885904000839218e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.59 | consumed tokens: 42496000.0 | grad norm avg: 6.32 | grad norm last: 6.69 | 
2025-12-27T23:33:19 | step: 83100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.885590407066047e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.44 | consumed tokens: 42547200.0 | grad norm avg: 6.27 | grad norm last: 6.1 | 
2025-12-27T23:33:21 | step: 83200 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.885276813292876e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.88 | consumed tokens: 42598400.0 | grad norm avg: 6.17 | grad norm last: 5.57 | 
2025-12-27T23:33:23 | step: 83300 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.884964674711227e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.89 | consumed tokens: 42649600.0 | grad norm avg: 6.42 | grad norm last: 6.06 | 
2025-12-27T23:33:25 | step: 83400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.884650353342295e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.48 | consumed tokens: 42700800.0 | grad norm avg: 6.05 | grad norm last: 7.0 | 
2025-12-27T23:33:27 | step: 83500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.884336759569123e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.81 | consumed tokens: 42752000.0 | grad norm avg: 6.39 | grad norm last: 5.49 | 
2025-12-27T23:33:29 | step: 83600 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.884021710604429e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.15 | train loss last: 5.62 | consumed tokens: 42803200.0 | grad norm avg: 6.52 | grad norm last: 11.04 | 
2025-12-27T23:33:31 | step: 83700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.883706661639735e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 4.78 | consumed tokens: 42854400.0 | grad norm avg: 6.59 | grad norm last: 5.86 | 
2025-12-27T23:33:33 | step: 83800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.88339088507928e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.97 | consumed tokens: 42905600.0 | grad norm avg: 6.11 | grad norm last: 5.71 | 
2025-12-27T23:33:35 | step: 83900 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.883075836114585e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 3.73 | consumed tokens: 42956800.0 | grad norm avg: 6.52 | grad norm last: 5.41 | 
2025-12-27T23:33:37 | step: 84000 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.882759331958368e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 4.28 | consumed tokens: 43008000.0 | grad norm avg: 6.43 | grad norm last: 5.35 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_84000-seen_tokens_43008000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_84000-seen_tokens_43008000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_84000-seen_tokens_43008000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_84000-seen_tokens_43008000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_84000-seen_tokens_43008000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_84000-seen_tokens_43008000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_84000-seen_tokens_43008000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_84000-seen_tokens_43008000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:33:39 | step: 84100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.88244210020639e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.97 | train loss last: 3.38 | consumed tokens: 43059200.0 | grad norm avg: 6.08 | grad norm last: 5.3 | 
2025-12-27T23:33:41 | step: 84200 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.882126323645934e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.34 | consumed tokens: 43110400.0 | grad norm avg: 6.34 | grad norm last: 5.53 | 
2025-12-27T23:33:43 | step: 84300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.881807636702433e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 2.92 | consumed tokens: 43161600.0 | grad norm avg: 6.28 | grad norm last: 5.06 | 
2025-12-27T23:33:45 | step: 84400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.881490404950455e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.19 | consumed tokens: 43212800.0 | grad norm avg: 6.21 | grad norm last: 5.93 | 
2025-12-27T23:33:47 | step: 84500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.881171718006954e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.72 | consumed tokens: 43264000.0 | grad norm avg: 6.16 | grad norm last: 5.39 | 
2025-12-27T23:33:49 | step: 84600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.880853031063452e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 4.38 | consumed tokens: 43315200.0 | grad norm avg: 6.99 | grad norm last: 8.42 | 
2025-12-27T23:33:51 | step: 84700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 9.880532888928428e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.09 | consumed tokens: 43366400.0 | grad norm avg: 6.5 | grad norm last: 5.78 | 
2025-12-27T23:33:53 | step: 84800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.880214201984927e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.12 | consumed tokens: 43417600.0 | grad norm avg: 6.17 | grad norm last: 7.01 | 
2025-12-27T23:33:55 | step: 84900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.879894059849903e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.0 | consumed tokens: 43468800.0 | grad norm avg: 6.45 | grad norm last: 5.98 | 
2025-12-27T23:33:57 | step: 85000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.879573917714879e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.78 | consumed tokens: 43520000.0 | grad norm avg: 6.16 | grad norm last: 6.41 | 
2025-12-27T23:34:00 | step: 85100 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.879252320388332e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.19 | consumed tokens: 43571200.0 | grad norm avg: 5.99 | grad norm last: 5.68 | 
2025-12-27T23:34:02 | step: 85200 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.878931450657547e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 4.31 | consumed tokens: 43622400.0 | grad norm avg: 6.43 | grad norm last: 5.64 | 
2025-12-27T23:34:04 | step: 85300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.878610580926761e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.25 | consumed tokens: 43673600.0 | grad norm avg: 6.43 | grad norm last: 7.71 | 
2025-12-27T23:34:06 | step: 85400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.878287528408691e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 4.03 | consumed tokens: 43724800.0 | grad norm avg: 6.31 | grad norm last: 6.0 | 
2025-12-27T23:34:08 | step: 85500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.877965203486383e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 4.16 | consumed tokens: 43776000.0 | grad norm avg: 6.45 | grad norm last: 6.85 | 
2025-12-27T23:34:10 | step: 85600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.877642150968313e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.5 | consumed tokens: 43827200.0 | grad norm avg: 6.06 | grad norm last: 5.77 | 
2025-12-27T23:34:12 | step: 85700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.877318370854482e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.62 | consumed tokens: 43878400.0 | grad norm avg: 6.67 | grad norm last: 5.38 | 
2025-12-27T23:34:14 | step: 85800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.87699386314489e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.81 | consumed tokens: 43929600.0 | grad norm avg: 6.49 | grad norm last: 6.64 | 
2025-12-27T23:34:16 | step: 85900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.876670083031058e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.59 | consumed tokens: 43980800.0 | grad norm avg: 6.34 | grad norm last: 8.15 | 
2025-12-27T23:34:18 | step: 86000 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.876346302917227e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.12 | train loss last: 3.55 | consumed tokens: 44032000.0 | grad norm avg: 6.52 | grad norm last: 5.44 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_86000-seen_tokens_44032000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_86000-seen_tokens_44032000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_86000-seen_tokens_44032000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_86000-seen_tokens_44032000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_86000-seen_tokens_44032000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_86000-seen_tokens_44032000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_86000-seen_tokens_44032000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_86000-seen_tokens_44032000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:34:20 | step: 86100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.876020340016112e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.01 | train loss last: 3.22 | consumed tokens: 44083200.0 | grad norm avg: 6.31 | grad norm last: 5.69 | 
2025-12-27T23:34:22 | step: 86200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.875695104710758e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.69 | consumed tokens: 44134400.0 | grad norm avg: 6.37 | grad norm last: 5.5 | 
2025-12-27T23:34:24 | step: 86300 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.875369141809642e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 6.16 | consumed tokens: 44185600.0 | grad norm avg: 6.38 | grad norm last: 15.83 | 
2025-12-27T23:34:26 | step: 86400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.875042451312765e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 3.67 | consumed tokens: 44236800.0 | grad norm avg: 6.25 | grad norm last: 5.49 | 
2025-12-27T23:34:28 | step: 86500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.87471648841165e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 4.12 | consumed tokens: 44288000.0 | grad norm avg: 6.3 | grad norm last: 5.49 | 
2025-12-27T23:34:30 | step: 86600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.874389070319012e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.06 | consumed tokens: 44339200.0 | grad norm avg: 6.7 | grad norm last: 7.61 | 
2025-12-27T23:34:32 | step: 86700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.874060197034851e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 3.27 | consumed tokens: 44390400.0 | grad norm avg: 6.32 | grad norm last: 5.83 | 
2025-12-27T23:34:34 | step: 86800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.873732778942212e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.83 | consumed tokens: 44441600.0 | grad norm avg: 6.23 | grad norm last: 5.7 | 
2025-12-27T23:34:36 | step: 86900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.873404633253813e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.2 | consumed tokens: 44492800.0 | grad norm avg: 6.32 | grad norm last: 5.44 | 
2025-12-27T23:34:38 | step: 87000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.873075759969652e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.81 | consumed tokens: 44544000.0 | grad norm avg: 6.35 | grad norm last: 5.34 | 
2025-12-27T23:34:40 | step: 87100 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.872746159089729e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.34 | consumed tokens: 44595200.0 | grad norm avg: 6.18 | grad norm last: 6.72 | 
2025-12-27T23:34:42 | step: 87200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.872417285805568e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.41 | consumed tokens: 44646400.0 | grad norm avg: 6.26 | grad norm last: 6.78 | 
2025-12-27T23:34:44 | step: 87300 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.872086229734123e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.28 | consumed tokens: 44697600.0 | grad norm avg: 6.29 | grad norm last: 5.74 | 
2025-12-27T23:34:46 | step: 87400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.871755173662677e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 4.06 | consumed tokens: 44748800.0 | grad norm avg: 6.45 | grad norm last: 6.9 | 
2025-12-27T23:34:48 | step: 87500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.871424845186993e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.27 | consumed tokens: 44800000.0 | grad norm avg: 6.23 | grad norm last: 6.06 | 
2025-12-27T23:34:50 | step: 87600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.871093789115548e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 4.56 | consumed tokens: 44851200.0 | grad norm avg: 6.45 | grad norm last: 6.79 | 
2025-12-27T23:34:52 | step: 87700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.87076127785258e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.53 | consumed tokens: 44902400.0 | grad norm avg: 6.39 | grad norm last: 5.49 | 
2025-12-27T23:34:54 | step: 87800 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.870429494185373e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 3.59 | consumed tokens: 44953600.0 | grad norm avg: 6.55 | grad norm last: 6.1 | 
2025-12-27T23:34:56 | step: 87900 | train samples/s: 96.7 | train mfu (16-bit): -1.0 | lr mean: 9.870096255326644e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.41 | consumed tokens: 45004800.0 | grad norm avg: 6.3 | grad norm last: 10.6 | 
2025-12-27T23:34:58 | step: 88000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.869763744063675e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.83 | consumed tokens: 45056000.0 | grad norm avg: 6.24 | grad norm last: 5.75 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_88000-seen_tokens_45056000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_88000-seen_tokens_45056000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_88000-seen_tokens_45056000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_88000-seen_tokens_45056000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_88000-seen_tokens_45056000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_88000-seen_tokens_45056000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_88000-seen_tokens_45056000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_88000-seen_tokens_45056000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:35:01 | step: 88100 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.869429777609184e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.9 | train loss last: 3.53 | consumed tokens: 45107200.0 | grad norm avg: 6.15 | grad norm last: 6.26 | 
2025-12-27T23:35:03 | step: 88200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.869095083558932e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.28 | consumed tokens: 45158400.0 | grad norm avg: 6.21 | grad norm last: 5.13 | 
2025-12-27T23:35:05 | step: 88300 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.868761844700202e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 4.31 | consumed tokens: 45209600.0 | grad norm avg: 6.31 | grad norm last: 6.45 | 
2025-12-27T23:35:07 | step: 88400 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.86842715064995e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.06 | consumed tokens: 45260800.0 | grad norm avg: 6.22 | grad norm last: 5.7 | 
2025-12-27T23:35:09 | step: 88500 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.868092456599697e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.59 | consumed tokens: 45312000.0 | grad norm avg: 6.4 | grad norm last: 5.99 | 
2025-12-27T23:35:11 | step: 88600 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.867756307357922e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 4.44 | consumed tokens: 45363200.0 | grad norm avg: 6.46 | grad norm last: 6.84 | 
2025-12-27T23:35:13 | step: 88700 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.867420158116147e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.44 | consumed tokens: 45414400.0 | grad norm avg: 6.14 | grad norm last: 5.99 | 
2025-12-27T23:35:15 | step: 88800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.867084008874372e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 4.06 | consumed tokens: 45465600.0 | grad norm avg: 6.44 | grad norm last: 6.33 | 
2025-12-27T23:35:17 | step: 88900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.866747859632596e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 4.28 | consumed tokens: 45516800.0 | grad norm avg: 6.22 | grad norm last: 6.61 | 
2025-12-27T23:35:19 | step: 89000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.866410255199298e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.56 | consumed tokens: 45568000.0 | grad norm avg: 6.32 | grad norm last: 5.25 | 
2025-12-27T23:35:21 | step: 89100 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.866072650766e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 5.56 | consumed tokens: 45619200.0 | grad norm avg: 6.21 | grad norm last: 7.12 | 
2025-12-27T23:35:23 | step: 89200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.865733591141179e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.94 | consumed tokens: 45670400.0 | grad norm avg: 6.35 | grad norm last: 5.75 | 
2025-12-27T23:35:25 | step: 89300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.86539525911212e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.31 | consumed tokens: 45721600.0 | grad norm avg: 6.42 | grad norm last: 7.16 | 
2025-12-27T23:35:27 | step: 89400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.865055471891537e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.97 | consumed tokens: 45772800.0 | grad norm avg: 6.4 | grad norm last: 6.43 | 
2025-12-27T23:35:29 | step: 89500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.864716412266716e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.64 | consumed tokens: 45824000.0 | grad norm avg: 6.39 | grad norm last: 5.65 | 
2025-12-27T23:35:31 | step: 89600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.864376625046134e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.84 | consumed tokens: 45875200.0 | grad norm avg: 6.37 | grad norm last: 5.43 | 
2025-12-27T23:35:33 | step: 89700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.864036837825552e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 4.12 | consumed tokens: 45926400.0 | grad norm avg: 6.42 | grad norm last: 6.99 | 
2025-12-27T23:35:35 | step: 89800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 9.863695595413446e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.95 | consumed tokens: 45977600.0 | grad norm avg: 6.27 | grad norm last: 6.0 | 
2025-12-27T23:35:37 | step: 89900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.863355080597103e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.42 | consumed tokens: 46028800.0 | grad norm avg: 6.25 | grad norm last: 5.73 | 
2025-12-27T23:35:39 | step: 90000 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.863012382993475e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 3.34 | consumed tokens: 46080000.0 | grad norm avg: 6.25 | grad norm last: 5.56 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_90000-seen_tokens_46080000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_90000-seen_tokens_46080000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_90000-seen_tokens_46080000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_90000-seen_tokens_46080000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_90000-seen_tokens_46080000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_90000-seen_tokens_46080000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_90000-seen_tokens_46080000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_90000-seen_tokens_46080000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:35:41 | step: 90100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.86267114058137e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.61 | consumed tokens: 46131200.0 | grad norm avg: 6.18 | grad norm last: 6.26 | 
2025-12-27T23:35:43 | step: 90200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.862329898169264e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.88 | consumed tokens: 46182400.0 | grad norm avg: 6.16 | grad norm last: 5.8 | 
2025-12-27T23:35:45 | step: 90300 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.861986472969875e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.5 | consumed tokens: 46233600.0 | grad norm avg: 6.26 | grad norm last: 6.73 | 
2025-12-27T23:35:47 | step: 90400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.861643047770485e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.38 | consumed tokens: 46284800.0 | grad norm avg: 6.19 | grad norm last: 7.39 | 
2025-12-27T23:35:49 | step: 90500 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.861299622571096e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.41 | consumed tokens: 46336000.0 | grad norm avg: 6.35 | grad norm last: 6.71 | 
2025-12-27T23:35:51 | step: 90600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.860956197371706e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.47 | consumed tokens: 46387200.0 | grad norm avg: 6.12 | grad norm last: 9.02 | 
2025-12-27T23:35:53 | step: 90700 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.860611316980794e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.14 | consumed tokens: 46438400.0 | grad norm avg: 6.32 | grad norm last: 5.66 | 
2025-12-27T23:35:55 | step: 90800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.860266436589882e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 3.23 | consumed tokens: 46489600.0 | grad norm avg: 6.36 | grad norm last: 5.79 | 
2025-12-27T23:35:57 | step: 90900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.859920828603208e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.94 | consumed tokens: 46540800.0 | grad norm avg: 6.22 | grad norm last: 6.08 | 
2025-12-27T23:35:59 | step: 91000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.859575220616534e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.31 | consumed tokens: 46592000.0 | grad norm avg: 6.33 | grad norm last: 6.66 | 
2025-12-27T23:36:01 | step: 91100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.859228885034099e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.38 | consumed tokens: 46643200.0 | grad norm avg: 6.44 | grad norm last: 6.12 | 
2025-12-27T23:36:03 | step: 91200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.858882549451664e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 2.91 | consumed tokens: 46694400.0 | grad norm avg: 6.31 | grad norm last: 5.02 | 
2025-12-27T23:36:05 | step: 91300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.858535486273468e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.09 | consumed tokens: 46745600.0 | grad norm avg: 6.22 | grad norm last: 5.36 | 
2025-12-27T23:36:07 | step: 91400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.858188423095271e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.88 | consumed tokens: 46796800.0 | grad norm avg: 6.38 | grad norm last: 6.24 | 
2025-12-27T23:36:09 | step: 91500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.857840632321313e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 5.0 | consumed tokens: 46848000.0 | grad norm avg: 6.46 | grad norm last: 7.54 | 
2025-12-27T23:36:11 | step: 91600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.857492841547355e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.94 | consumed tokens: 46899200.0 | grad norm avg: 6.21 | grad norm last: 7.33 | 
2025-12-27T23:36:13 | step: 91700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.857143595581874e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.28 | consumed tokens: 46950400.0 | grad norm avg: 6.28 | grad norm last: 9.18 | 
2025-12-27T23:36:15 | step: 91800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.856794349616393e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.92 | consumed tokens: 47001600.0 | grad norm avg: 6.28 | grad norm last: 5.58 | 
2025-12-27T23:36:17 | step: 91900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.856445103650913e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.56 | consumed tokens: 47052800.0 | grad norm avg: 6.47 | grad norm last: 6.5 | 
2025-12-27T23:36:19 | step: 92000 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.856095857685432e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.56 | consumed tokens: 47104000.0 | grad norm avg: 6.16 | grad norm last: 6.55 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_92000-seen_tokens_47104000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_92000-seen_tokens_47104000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_92000-seen_tokens_47104000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_92000-seen_tokens_47104000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_92000-seen_tokens_47104000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_92000-seen_tokens_47104000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_92000-seen_tokens_47104000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_92000-seen_tokens_47104000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:36:22 | step: 92100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.855745156528428e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.93 | train loss last: 3.36 | consumed tokens: 47155200.0 | grad norm avg: 6.64 | grad norm last: 5.59 | 
2025-12-27T23:36:24 | step: 92200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.855394455371425e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.56 | consumed tokens: 47206400.0 | grad norm avg: 6.41 | grad norm last: 7.0 | 
2025-12-27T23:36:26 | step: 92300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.85504302661866e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 4.09 | consumed tokens: 47257600.0 | grad norm avg: 6.32 | grad norm last: 5.46 | 
2025-12-27T23:36:28 | step: 92400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.854691597865894e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.75 | consumed tokens: 47308800.0 | grad norm avg: 6.18 | grad norm last: 5.5 | 
2025-12-27T23:36:30 | step: 92500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.854339441517368e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 3.61 | consumed tokens: 47360000.0 | grad norm avg: 6.42 | grad norm last: 5.66 | 
2025-12-27T23:36:32 | step: 92600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.853987285168841e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.61 | consumed tokens: 47411200.0 | grad norm avg: 6.31 | grad norm last: 5.6 | 
2025-12-27T23:36:34 | step: 92700 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.853634401224554e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.31 | consumed tokens: 47462400.0 | grad norm avg: 6.25 | grad norm last: 5.45 | 
2025-12-27T23:36:36 | step: 92800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.853281517280266e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 4.22 | consumed tokens: 47513600.0 | grad norm avg: 6.69 | grad norm last: 6.36 | 
2025-12-27T23:36:38 | step: 92900 | train samples/s: 99.4 | train mfu (16-bit): -1.0 | lr mean: 9.852927905740216e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 3.08 | consumed tokens: 47564800.0 | grad norm avg: 6.39 | grad norm last: 6.09 | 
2025-12-27T23:36:40 | step: 93000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.852574294200167e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 3.64 | consumed tokens: 47616000.0 | grad norm avg: 6.54 | grad norm last: 5.78 | 
2025-12-27T23:36:42 | step: 93100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.852219227468595e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.38 | consumed tokens: 47667200.0 | grad norm avg: 6.26 | grad norm last: 5.77 | 
2025-12-27T23:36:44 | step: 93200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.851864160737023e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.61 | consumed tokens: 47718400.0 | grad norm avg: 6.47 | grad norm last: 6.26 | 
2025-12-27T23:36:46 | step: 93300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.85150909400545e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 2.98 | consumed tokens: 47769600.0 | grad norm avg: 6.32 | grad norm last: 5.78 | 
2025-12-27T23:36:48 | step: 93400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.851154027273878e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.41 | consumed tokens: 47820800.0 | grad norm avg: 6.21 | grad norm last: 6.66 | 
2025-12-27T23:36:50 | step: 93500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.850796777755022e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 5.06 | consumed tokens: 47872000.0 | grad norm avg: 6.56 | grad norm last: 6.5 | 
2025-12-27T23:36:52 | step: 93600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.850439528236166e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.19 | consumed tokens: 47923200.0 | grad norm avg: 6.26 | grad norm last: 5.99 | 
2025-12-27T23:36:54 | step: 93700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.85008300631307e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.91 | consumed tokens: 47974400.0 | grad norm avg: 6.17 | grad norm last: 5.98 | 
2025-12-27T23:36:56 | step: 93800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.849725756794214e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.64 | consumed tokens: 48025600.0 | grad norm avg: 6.37 | grad norm last: 5.47 | 
2025-12-27T23:36:58 | step: 93900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.849367779679596e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.62 | consumed tokens: 48076800.0 | grad norm avg: 6.31 | grad norm last: 5.89 | 
2025-12-27T23:37:00 | step: 94000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.849009802564979e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.77 | consumed tokens: 48128000.0 | grad norm avg: 6.18 | grad norm last: 5.67 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_94000-seen_tokens_48128000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_94000-seen_tokens_48128000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_94000-seen_tokens_48128000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_94000-seen_tokens_48128000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_94000-seen_tokens_48128000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_94000-seen_tokens_48128000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_94000-seen_tokens_48128000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_94000-seen_tokens_48128000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:37:02 | step: 94100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.8486510978546e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.56 | consumed tokens: 48179200.0 | grad norm avg: 6.22 | grad norm last: 5.25 | 
2025-12-27T23:37:04 | step: 94200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.848291665548459e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.92 | consumed tokens: 48230400.0 | grad norm avg: 6.44 | grad norm last: 6.76 | 
2025-12-27T23:37:06 | step: 94300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.847932233242318e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.59 | consumed tokens: 48281600.0 | grad norm avg: 6.29 | grad norm last: 6.26 | 
2025-12-27T23:37:08 | step: 94400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.847572800936177e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.97 | consumed tokens: 48332800.0 | grad norm avg: 6.34 | grad norm last: 5.74 | 
2025-12-27T23:37:10 | step: 94500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.847211913438514e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 4.19 | consumed tokens: 48384000.0 | grad norm avg: 6.46 | grad norm last: 5.95 | 
2025-12-27T23:37:12 | step: 94600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.846852481132373e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.34 | consumed tokens: 48435200.0 | grad norm avg: 6.38 | grad norm last: 5.64 | 
2025-12-27T23:37:14 | step: 94700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 9.846490138443187e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 3.84 | consumed tokens: 48486400.0 | grad norm avg: 6.37 | grad norm last: 5.99 | 
2025-12-27T23:37:16 | step: 94800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.846128523349762e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.78 | consumed tokens: 48537600.0 | grad norm avg: 6.18 | grad norm last: 5.75 | 
2025-12-27T23:37:18 | step: 94900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.845766908256337e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.34 | consumed tokens: 48588800.0 | grad norm avg: 6.31 | grad norm last: 7.58 | 
2025-12-27T23:37:20 | step: 95000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.845403837971389e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 4.16 | consumed tokens: 48640000.0 | grad norm avg: 6.38 | grad norm last: 6.77 | 
2025-12-27T23:37:22 | step: 95100 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.845042222877964e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.41 | consumed tokens: 48691200.0 | grad norm avg: 6.35 | grad norm last: 5.92 | 
2025-12-27T23:37:24 | step: 95200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.844676969805732e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.19 | consumed tokens: 48742400.0 | grad norm avg: 6.39 | grad norm last: 5.78 | 
2025-12-27T23:37:26 | step: 95300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.844314627116546e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.78 | consumed tokens: 48793600.0 | grad norm avg: 6.1 | grad norm last: 5.5 | 
2025-12-27T23:37:28 | step: 95400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.843949374044314e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.55 | consumed tokens: 48844800.0 | grad norm avg: 6.32 | grad norm last: 5.76 | 
2025-12-27T23:37:30 | step: 95500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.843585576163605e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.89 | consumed tokens: 48896000.0 | grad norm avg: 6.29 | grad norm last: 5.62 | 
2025-12-27T23:37:32 | step: 95600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.843221050687134e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.06 | consumed tokens: 48947200.0 | grad norm avg: 6.13 | grad norm last: 5.47 | 
2025-12-27T23:37:34 | step: 95700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.842855070019141e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.88 | consumed tokens: 48998400.0 | grad norm avg: 6.23 | grad norm last: 5.59 | 
2025-12-27T23:37:37 | step: 95800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.842489816946909e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.0 | consumed tokens: 49049600.0 | grad norm avg: 6.26 | grad norm last: 6.56 | 
2025-12-27T23:37:39 | step: 95900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.842123108683154e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 3.75 | consumed tokens: 49100800.0 | grad norm avg: 6.71 | grad norm last: 5.76 | 
2025-12-27T23:37:41 | step: 96000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.84175712801516e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.17 | consumed tokens: 49152000.0 | grad norm avg: 6.58 | grad norm last: 5.16 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_96000-seen_tokens_49152000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_96000-seen_tokens_49152000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_96000-seen_tokens_49152000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_96000-seen_tokens_49152000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_96000-seen_tokens_49152000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_96000-seen_tokens_49152000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_96000-seen_tokens_49152000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_96000-seen_tokens_49152000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:37:43 | step: 96100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.841389692155644e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.11 | train loss last: 3.77 | consumed tokens: 49203200.0 | grad norm avg: 6.49 | grad norm last: 6.2 | 
2025-12-27T23:37:45 | step: 96200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.841021528700367e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.66 | consumed tokens: 49254400.0 | grad norm avg: 6.3 | grad norm last: 7.9 | 
2025-12-27T23:37:47 | step: 96300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.840654820436612e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.81 | consumed tokens: 49305600.0 | grad norm avg: 6.34 | grad norm last: 6.25 | 
2025-12-27T23:37:49 | step: 96400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.840286656981334e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.44 | consumed tokens: 49356800.0 | grad norm avg: 6.44 | grad norm last: 6.07 | 
2025-12-27T23:37:51 | step: 96500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.839917765930295e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.45 | consumed tokens: 49408000.0 | grad norm avg: 6.3 | grad norm last: 5.8 | 
2025-12-27T23:37:53 | step: 96600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.839548147283494e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.84 | consumed tokens: 49459200.0 | grad norm avg: 6.33 | grad norm last: 7.49 | 
2025-12-27T23:37:55 | step: 96700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.839178528636694e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 6.53 | consumed tokens: 49510400.0 | grad norm avg: 6.16 | grad norm last: 8.35 | 
2025-12-27T23:37:57 | step: 96800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.838808909989893e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.27 | consumed tokens: 49561600.0 | grad norm avg: 6.18 | grad norm last: 5.76 | 
2025-12-27T23:37:59 | step: 96900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.838438563747332e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.12 | consumed tokens: 49612800.0 | grad norm avg: 6.28 | grad norm last: 5.24 | 
2025-12-27T23:38:01 | step: 97000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.838067489909008e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.8 | consumed tokens: 49664000.0 | grad norm avg: 6.24 | grad norm last: 6.13 | 
2025-12-27T23:38:03 | step: 97100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.837696416070685e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.3 | consumed tokens: 49715200.0 | grad norm avg: 6.16 | grad norm last: 5.29 | 
2025-12-27T23:38:05 | step: 97200 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.8373246146366e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.0 | consumed tokens: 49766400.0 | grad norm avg: 6.29 | grad norm last: 6.62 | 
2025-12-27T23:38:07 | step: 97300 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.836952813202515e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.59 | consumed tokens: 49817600.0 | grad norm avg: 6.15 | grad norm last: 5.55 | 
2025-12-27T23:38:09 | step: 97400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.836580284172669e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.72 | consumed tokens: 49868800.0 | grad norm avg: 6.21 | grad norm last: 6.07 | 
2025-12-27T23:38:11 | step: 97500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.836207755142823e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.97 | consumed tokens: 49920000.0 | grad norm avg: 6.23 | grad norm last: 5.6 | 
2025-12-27T23:38:13 | step: 97600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.835834498517215e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 4.84 | consumed tokens: 49971200.0 | grad norm avg: 6.48 | grad norm last: 6.37 | 
2025-12-27T23:38:15 | step: 97700 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.835461241891608e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.12 | consumed tokens: 50022400.0 | grad norm avg: 6.3 | grad norm last: 6.5 | 
2025-12-27T23:38:17 | step: 97800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.835086530074477e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 3.88 | consumed tokens: 50073600.0 | grad norm avg: 7.01 | grad norm last: 6.52 | 
2025-12-27T23:38:19 | step: 97900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.834711818257347e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 3.69 | consumed tokens: 50124800.0 | grad norm avg: 6.31 | grad norm last: 6.36 | 
2025-12-27T23:38:21 | step: 98000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.834337834035978e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.62 | consumed tokens: 50176000.0 | grad norm avg: 6.15 | grad norm last: 5.69 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_98000-seen_tokens_50176000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_98000-seen_tokens_50176000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_98000-seen_tokens_50176000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_98000-seen_tokens_50176000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_98000-seen_tokens_50176000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_98000-seen_tokens_50176000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_98000-seen_tokens_50176000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_98000-seen_tokens_50176000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:38:23 | step: 98100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.833960939431563e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.98 | train loss last: 3.91 | consumed tokens: 50227200.0 | grad norm avg: 6.09 | grad norm last: 6.14 | 
2025-12-27T23:38:25 | step: 98200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.833585500018671e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.25 | consumed tokens: 50278400.0 | grad norm avg: 6.31 | grad norm last: 5.66 | 
2025-12-27T23:38:27 | step: 98300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.833209333010018e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.73 | consumed tokens: 50329600.0 | grad norm avg: 6.34 | grad norm last: 5.64 | 
2025-12-27T23:38:29 | step: 98400 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.832833166001365e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.44 | consumed tokens: 50380800.0 | grad norm avg: 6.49 | grad norm last: 5.38 | 
2025-12-27T23:38:31 | step: 98500 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.832455543801188e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.91 | consumed tokens: 50432000.0 | grad norm avg: 6.28 | grad norm last: 6.1 | 
2025-12-27T23:38:33 | step: 98600 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.832079376792535e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.84 | consumed tokens: 50483200.0 | grad norm avg: 6.29 | grad norm last: 6.97 | 
2025-12-27T23:38:35 | step: 98700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.831701026996598e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.75 | consumed tokens: 50534400.0 | grad norm avg: 6.26 | grad norm last: 5.28 | 
2025-12-27T23:38:37 | step: 98800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.83132267720066e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.58 | consumed tokens: 50585600.0 | grad norm avg: 6.16 | grad norm last: 5.31 | 
2025-12-27T23:38:39 | step: 98900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.830944327404723e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.62 | consumed tokens: 50636800.0 | grad norm avg: 6.25 | grad norm last: 6.2 | 
2025-12-27T23:38:41 | step: 99000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.830564522417262e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.48 | consumed tokens: 50688000.0 | grad norm avg: 6.1 | grad norm last: 5.64 | 
2025-12-27T23:38:43 | step: 99100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.830184717429802e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.55 | consumed tokens: 50739200.0 | grad norm avg: 6.36 | grad norm last: 5.64 | 
2025-12-27T23:38:46 | step: 99200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.829804912442341e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.31 | consumed tokens: 50790400.0 | grad norm avg: 6.3 | grad norm last: 6.19 | 
2025-12-27T23:38:48 | step: 99300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.829425107454881e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.84 | consumed tokens: 50841600.0 | grad norm avg: 6.16 | grad norm last: 6.44 | 
2025-12-27T23:38:50 | step: 99400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.829043847275898e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.62 | consumed tokens: 50892800.0 | grad norm avg: 6.03 | grad norm last: 6.18 | 
2025-12-27T23:38:52 | step: 99500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.828662587096915e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.16 | consumed tokens: 50944000.0 | grad norm avg: 6.25 | grad norm last: 6.59 | 
2025-12-27T23:38:54 | step: 99600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.828279871726409e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.67 | consumed tokens: 50995200.0 | grad norm avg: 6.59 | grad norm last: 5.68 | 
2025-12-27T23:38:56 | step: 99700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.827898611547425e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.48 | consumed tokens: 51046400.0 | grad norm avg: 6.1 | grad norm last: 5.51 | 
2025-12-27T23:38:58 | step: 99800 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.827516623772681e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.64 | consumed tokens: 51097600.0 | grad norm avg: 6.01 | grad norm last: 6.1 | 
2025-12-27T23:39:00 | step: 99900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.827133180806413e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.44 | consumed tokens: 51148800.0 | grad norm avg: 6.17 | grad norm last: 8.14 | 
2025-12-27T23:39:02 | step: 100000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.826750465435907e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.69 | consumed tokens: 51200000.0 | grad norm avg: 6.46 | grad norm last: 6.53 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_100000-seen_tokens_51200000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_100000-seen_tokens_51200000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_100000-seen_tokens_51200000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_100000-seen_tokens_51200000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_100000-seen_tokens_51200000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_100000-seen_tokens_51200000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_100000-seen_tokens_51200000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_100000-seen_tokens_51200000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:39:04 | step: 100100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 9.826366294873878e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.27 | consumed tokens: 51251200.0 | grad norm avg: 6.1 | grad norm last: 5.88 | 
2025-12-27T23:39:06 | step: 100200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.82598212431185e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 4.09 | consumed tokens: 51302400.0 | grad norm avg: 6.31 | grad norm last: 6.24 | 
2025-12-27T23:39:08 | step: 100300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.82559795374982e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.97 | consumed tokens: 51353600.0 | grad norm avg: 6.21 | grad norm last: 5.98 | 
2025-12-27T23:39:10 | step: 100400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.825212327996269e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.95 | consumed tokens: 51404800.0 | grad norm avg: 6.11 | grad norm last: 6.01 | 
2025-12-27T23:39:12 | step: 100500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.824827429838479e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.88 | consumed tokens: 51456000.0 | grad norm avg: 6.25 | grad norm last: 5.9 | 
2025-12-27T23:39:14 | step: 100600 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.824442531680688e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.27 | consumed tokens: 51507200.0 | grad norm avg: 6.35 | grad norm last: 5.35 | 
2025-12-27T23:39:16 | step: 100700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.824055450735614e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.77 | consumed tokens: 51558400.0 | grad norm avg: 6.1 | grad norm last: 6.17 | 
2025-12-27T23:39:18 | step: 100800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.8236690973863e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.81 | consumed tokens: 51609600.0 | grad norm avg: 6.33 | grad norm last: 7.84 | 
2025-12-27T23:39:20 | step: 100900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.823282016441226e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.47 | consumed tokens: 51660800.0 | grad norm avg: 6.25 | grad norm last: 5.01 | 
2025-12-27T23:39:22 | step: 101000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.82289420790039e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.09 | consumed tokens: 51712000.0 | grad norm avg: 6.27 | grad norm last: 6.0 | 
2025-12-27T23:39:24 | step: 101100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.822505671763793e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.59 | consumed tokens: 51763200.0 | grad norm avg: 6.18 | grad norm last: 5.73 | 
2025-12-27T23:39:26 | step: 101200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.822118590818718e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.69 | consumed tokens: 51814400.0 | grad norm avg: 6.27 | grad norm last: 7.09 | 
2025-12-27T23:39:28 | step: 101300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.821730054682121e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.28 | consumed tokens: 51865600.0 | grad norm avg: 6.11 | grad norm last: 6.86 | 
2025-12-27T23:39:30 | step: 101400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.821340790949762e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.83 | consumed tokens: 51916800.0 | grad norm avg: 6.19 | grad norm last: 5.34 | 
2025-12-27T23:39:32 | step: 101500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.820950799621642e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.05 | consumed tokens: 51968000.0 | grad norm avg: 6.46 | grad norm last: 5.85 | 
2025-12-27T23:39:34 | step: 101600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.820560808293521e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.28 | consumed tokens: 52019200.0 | grad norm avg: 6.41 | grad norm last: 6.01 | 
2025-12-27T23:39:36 | step: 101700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.820170816965401e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 3.61 | consumed tokens: 52070400.0 | grad norm avg: 6.22 | grad norm last: 5.62 | 
2025-12-27T23:39:38 | step: 101800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.81978009804152e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.84 | consumed tokens: 52121600.0 | grad norm avg: 6.41 | grad norm last: 5.54 | 
2025-12-27T23:39:40 | step: 101900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.819388651521876e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 3.39 | consumed tokens: 52172800.0 | grad norm avg: 6.29 | grad norm last: 5.43 | 
2025-12-27T23:39:42 | step: 102000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.818997205002233e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.72 | consumed tokens: 52224000.0 | grad norm avg: 6.26 | grad norm last: 6.68 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_102000-seen_tokens_52224000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_102000-seen_tokens_52224000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_102000-seen_tokens_52224000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_102000-seen_tokens_52224000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_102000-seen_tokens_52224000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_102000-seen_tokens_52224000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_102000-seen_tokens_52224000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_102000-seen_tokens_52224000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:39:44 | step: 102100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.818605030886829e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.02 | train loss last: 4.25 | consumed tokens: 52275200.0 | grad norm avg: 6.19 | grad norm last: 6.5 | 
2025-12-27T23:39:47 | step: 102200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.818212856771424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.0 | consumed tokens: 52326400.0 | grad norm avg: 6.06 | grad norm last: 6.0 | 
2025-12-27T23:39:49 | step: 102300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.817819955060259e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.88 | consumed tokens: 52377600.0 | grad norm avg: 6.31 | grad norm last: 5.62 | 
2025-12-27T23:39:51 | step: 102400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.817426325753331e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 2.97 | consumed tokens: 52428800.0 | grad norm avg: 6.28 | grad norm last: 5.24 | 
2025-12-27T23:39:53 | step: 102500 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.817032696446404e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.59 | consumed tokens: 52480000.0 | grad norm avg: 6.28 | grad norm last: 5.66 | 
2025-12-27T23:39:55 | step: 102600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.816638339543715e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.06 | consumed tokens: 52531200.0 | grad norm avg: 6.41 | grad norm last: 5.64 | 
2025-12-27T23:39:57 | step: 102700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.816243982641026e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.77 | consumed tokens: 52582400.0 | grad norm avg: 6.42 | grad norm last: 5.56 | 
2025-12-27T23:39:59 | step: 102800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.815849625738338e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.16 | consumed tokens: 52633600.0 | grad norm avg: 6.52 | grad norm last: 7.05 | 
2025-12-27T23:40:01 | step: 102900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.815453813644126e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.53 | consumed tokens: 52684800.0 | grad norm avg: 6.18 | grad norm last: 5.59 | 
2025-12-27T23:40:03 | step: 103000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.815058001549914e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.06 | consumed tokens: 52736000.0 | grad norm avg: 6.16 | grad norm last: 6.8 | 
2025-12-27T23:40:05 | step: 103100 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.814662189455703e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.03 | consumed tokens: 52787200.0 | grad norm avg: 6.49 | grad norm last: 6.15 | 
2025-12-27T23:40:07 | step: 103200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.81426564976573e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 3.34 | consumed tokens: 52838400.0 | grad norm avg: 6.43 | grad norm last: 5.42 | 
2025-12-27T23:40:09 | step: 103300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.813867654884234e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 4.0 | consumed tokens: 52889600.0 | grad norm avg: 6.54 | grad norm last: 5.02 | 
2025-12-27T23:40:11 | step: 103400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.813471115194261e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.34 | consumed tokens: 52940800.0 | grad norm avg: 6.27 | grad norm last: 7.13 | 
2025-12-27T23:40:13 | step: 103500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.813073120312765e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 3.75 | consumed tokens: 52992000.0 | grad norm avg: 6.4 | grad norm last: 5.33 | 
2025-12-27T23:40:15 | step: 103600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.812674397835508e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.98 | consumed tokens: 53043200.0 | grad norm avg: 6.28 | grad norm last: 6.55 | 
2025-12-27T23:40:17 | step: 103700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.812277130549774e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.95 | consumed tokens: 53094400.0 | grad norm avg: 6.21 | grad norm last: 5.51 | 
2025-12-27T23:40:19 | step: 103800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.811876952880993e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.25 | consumed tokens: 53145600.0 | grad norm avg: 6.24 | grad norm last: 6.74 | 
2025-12-27T23:40:21 | step: 103900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.811477502807975e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.28 | consumed tokens: 53196800.0 | grad norm avg: 6.43 | grad norm last: 6.44 | 
2025-12-27T23:40:23 | step: 104000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.811078052734956e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.06 | consumed tokens: 53248000.0 | grad norm avg: 6.43 | grad norm last: 5.99 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_104000-seen_tokens_53248000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_104000-seen_tokens_53248000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_104000-seen_tokens_53248000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_104000-seen_tokens_53248000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_104000-seen_tokens_53248000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_104000-seen_tokens_53248000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_104000-seen_tokens_53248000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_104000-seen_tokens_53248000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:40:25 | step: 104100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.810677875066176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.5 | consumed tokens: 53299200.0 | grad norm avg: 6.45 | grad norm last: 5.67 | 
2025-12-27T23:40:27 | step: 104200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.810276242205873e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.19 | consumed tokens: 53350400.0 | grad norm avg: 6.45 | grad norm last: 6.81 | 
2025-12-27T23:40:29 | step: 104300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.80987460934557e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.41 | consumed tokens: 53401600.0 | grad norm avg: 6.32 | grad norm last: 5.9 | 
2025-12-27T23:40:31 | step: 104400 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.80947443167679e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.58 | consumed tokens: 53452800.0 | grad norm avg: 6.49 | grad norm last: 5.96 | 
2025-12-27T23:40:33 | step: 104500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.809071343624964e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.61 | consumed tokens: 53504000.0 | grad norm avg: 6.47 | grad norm last: 5.9 | 
2025-12-27T23:40:35 | step: 104600 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.808669710764661e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.53 | consumed tokens: 53555200.0 | grad norm avg: 6.52 | grad norm last: 6.19 | 
2025-12-27T23:40:37 | step: 104700 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.808266622712836e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.5 | consumed tokens: 53606400.0 | grad norm avg: 6.28 | grad norm last: 4.98 | 
2025-12-27T23:40:39 | step: 104800 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.80786353466101e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.19 | consumed tokens: 53657600.0 | grad norm avg: 6.44 | grad norm last: 6.0 | 
2025-12-27T23:40:41 | step: 104900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.807458991417661e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.62 | consumed tokens: 53708800.0 | grad norm avg: 6.2 | grad norm last: 5.74 | 
2025-12-27T23:40:43 | step: 105000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.807055903365836e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.09 | consumed tokens: 53760000.0 | grad norm avg: 6.38 | grad norm last: 5.74 | 
2025-12-27T23:40:45 | step: 105100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.806651360122487e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.39 | consumed tokens: 53811200.0 | grad norm avg: 6.31 | grad norm last: 5.77 | 
2025-12-27T23:40:47 | step: 105200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.806246816879138e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.41 | consumed tokens: 53862400.0 | grad norm avg: 6.57 | grad norm last: 5.36 | 
2025-12-27T23:40:49 | step: 105300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.805840818444267e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.94 | consumed tokens: 53913600.0 | grad norm avg: 6.41 | grad norm last: 7.6 | 
2025-12-27T23:40:51 | step: 105400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.805435547605157e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 5.47 | consumed tokens: 53964800.0 | grad norm avg: 6.37 | grad norm last: 8.46 | 
2025-12-27T23:40:53 | step: 105500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.805030276766047e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.52 | consumed tokens: 54016000.0 | grad norm avg: 6.37 | grad norm last: 6.02 | 
2025-12-27T23:40:55 | step: 105600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.804622823139653e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 4.22 | consumed tokens: 54067200.0 | grad norm avg: 6.49 | grad norm last: 6.0 | 
2025-12-27T23:40:57 | step: 105700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.80421609710902e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.56 | consumed tokens: 54118400.0 | grad norm avg: 6.59 | grad norm last: 6.31 | 
2025-12-27T23:40:59 | step: 105800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.803808643482625e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.08 | consumed tokens: 54169600.0 | grad norm avg: 6.58 | grad norm last: 5.85 | 
2025-12-27T23:41:01 | step: 105900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.803401189856231e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.22 | consumed tokens: 54220800.0 | grad norm avg: 6.33 | grad norm last: 6.31 | 
2025-12-27T23:41:03 | step: 106000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.802993008634076e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.38 | consumed tokens: 54272000.0 | grad norm avg: 6.39 | grad norm last: 6.77 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_106000-seen_tokens_54272000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_106000-seen_tokens_54272000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_106000-seen_tokens_54272000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_106000-seen_tokens_54272000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_106000-seen_tokens_54272000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_106000-seen_tokens_54272000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_106000-seen_tokens_54272000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_106000-seen_tokens_54272000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:41:06 | step: 106100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 9.802584099816158e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.08 | train loss last: 3.8 | consumed tokens: 54323200.0 | grad norm avg: 6.52 | grad norm last: 5.96 | 
2025-12-27T23:41:08 | step: 106200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.802175190998241e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.59 | consumed tokens: 54374400.0 | grad norm avg: 6.46 | grad norm last: 7.79 | 
2025-12-27T23:41:10 | step: 106300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.801765554584563e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.98 | consumed tokens: 54425600.0 | grad norm avg: 6.35 | grad norm last: 6.55 | 
2025-12-27T23:41:12 | step: 106400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.801355918170884e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.34 | consumed tokens: 54476800.0 | grad norm avg: 6.33 | grad norm last: 7.94 | 
2025-12-27T23:41:14 | step: 106500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 9.800945554161444e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.36 | consumed tokens: 54528000.0 | grad norm avg: 6.41 | grad norm last: 6.11 | 
2025-12-27T23:41:16 | step: 106600 | train samples/s: 103.1 | train mfu (16-bit): -1.0 | lr mean: 9.800535190152004e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.42 | consumed tokens: 54579200.0 | grad norm avg: 6.33 | grad norm last: 7.36 | 
2025-12-27T23:41:18 | step: 106700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.800124098546803e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 2.94 | consumed tokens: 54630400.0 | grad norm avg: 6.32 | grad norm last: 5.38 | 
2025-12-27T23:41:20 | step: 106800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.799711551750079e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.86 | consumed tokens: 54681600.0 | grad norm avg: 6.59 | grad norm last: 5.38 | 
2025-12-27T23:41:22 | step: 106900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.799300460144877e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.64 | consumed tokens: 54732800.0 | grad norm avg: 6.41 | grad norm last: 7.16 | 
2025-12-27T23:41:24 | step: 107000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.798887913348153e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.69 | consumed tokens: 54784000.0 | grad norm avg: 6.81 | grad norm last: 5.76 | 
2025-12-27T23:41:26 | step: 107100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.79847609414719e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.09 | consumed tokens: 54835200.0 | grad norm avg: 6.5 | grad norm last: 5.69 | 
2025-12-27T23:41:28 | step: 107200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.798062819754705e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.64 | consumed tokens: 54886400.0 | grad norm avg: 6.5 | grad norm last: 5.44 | 
2025-12-27T23:41:30 | step: 107300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.797649545362219e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.64 | consumed tokens: 54937600.0 | grad norm avg: 6.32 | grad norm last: 5.55 | 
2025-12-27T23:41:32 | step: 107400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.797234815778211e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.92 | consumed tokens: 54988800.0 | grad norm avg: 6.39 | grad norm last: 6.22 | 
2025-12-27T23:41:34 | step: 107500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.796820086194202e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.7 | consumed tokens: 55040000.0 | grad norm avg: 6.56 | grad norm last: 5.83 | 
2025-12-27T23:41:36 | step: 107600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.796405356610194e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.53 | consumed tokens: 55091200.0 | grad norm avg: 6.55 | grad norm last: 6.8 | 
2025-12-27T23:41:38 | step: 107700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.795990627026185e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.98 | consumed tokens: 55142400.0 | grad norm avg: 6.35 | grad norm last: 5.22 | 
2025-12-27T23:41:40 | step: 107800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.795574442250654e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.06 | consumed tokens: 55193600.0 | grad norm avg: 6.33 | grad norm last: 6.7 | 
2025-12-27T23:41:42 | step: 107900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.795158257475123e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.95 | consumed tokens: 55244800.0 | grad norm avg: 6.62 | grad norm last: 5.54 | 
2025-12-27T23:41:44 | step: 108000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.794742072699592e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.5 | consumed tokens: 55296000.0 | grad norm avg: 6.47 | grad norm last: 6.98 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_108000-seen_tokens_55296000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_108000-seen_tokens_55296000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_108000-seen_tokens_55296000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_108000-seen_tokens_55296000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_108000-seen_tokens_55296000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_108000-seen_tokens_55296000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_108000-seen_tokens_55296000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_108000-seen_tokens_55296000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:41:46 | step: 108100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.79432588792406e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.84 | consumed tokens: 55347200.0 | grad norm avg: 6.54 | grad norm last: 7.9 | 
2025-12-27T23:41:48 | step: 108200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.793908247957006e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 4.41 | consumed tokens: 55398400.0 | grad norm avg: 6.66 | grad norm last: 6.36 | 
2025-12-27T23:41:50 | step: 108300 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.793490607989952e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.22 | consumed tokens: 55449600.0 | grad norm avg: 6.62 | grad norm last: 6.81 | 
2025-12-27T23:41:52 | step: 108400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.793072240427136e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.52 | consumed tokens: 55500800.0 | grad norm avg: 6.59 | grad norm last: 6.2 | 
2025-12-27T23:41:54 | step: 108500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.792653872864321e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 4.09 | consumed tokens: 55552000.0 | grad norm avg: 6.68 | grad norm last: 7.31 | 
2025-12-27T23:41:56 | step: 108600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.792234777705744e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.44 | consumed tokens: 55603200.0 | grad norm avg: 6.52 | grad norm last: 6.54 | 
2025-12-27T23:41:58 | step: 108700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.791815682547167e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.55 | consumed tokens: 55654400.0 | grad norm avg: 6.68 | grad norm last: 6.06 | 
2025-12-27T23:42:00 | step: 108800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.791395859792829e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 4.06 | consumed tokens: 55705600.0 | grad norm avg: 6.57 | grad norm last: 6.93 | 
2025-12-27T23:42:02 | step: 108900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.790974581846967e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.78 | consumed tokens: 55756800.0 | grad norm avg: 6.46 | grad norm last: 5.32 | 
2025-12-27T23:42:04 | step: 109000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.790554759092629e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.28 | consumed tokens: 55808000.0 | grad norm avg: 6.59 | grad norm last: 5.72 | 
2025-12-27T23:42:06 | step: 109100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.790133481146768e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.77 | consumed tokens: 55859200.0 | grad norm avg: 6.58 | grad norm last: 6.32 | 
2025-12-27T23:42:08 | step: 109200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.789711475605145e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.16 | consumed tokens: 55910400.0 | grad norm avg: 6.55 | grad norm last: 6.74 | 
2025-12-27T23:42:10 | step: 109300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.789290925255045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.75 | consumed tokens: 55961600.0 | grad norm avg: 6.3 | grad norm last: 6.7 | 
2025-12-27T23:42:12 | step: 109400 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.7888674645219e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.89 | consumed tokens: 56012800.0 | grad norm avg: 6.63 | grad norm last: 6.31 | 
2025-12-27T23:42:14 | step: 109500 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.788445458980277e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 4.69 | consumed tokens: 56064000.0 | grad norm avg: 6.6 | grad norm last: 7.67 | 
2025-12-27T23:42:16 | step: 109600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.788022725842893e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.28 | consumed tokens: 56115200.0 | grad norm avg: 6.73 | grad norm last: 6.4 | 
2025-12-27T23:42:18 | step: 109700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.787598537513986e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.09 | consumed tokens: 56166400.0 | grad norm avg: 6.52 | grad norm last: 6.69 | 
2025-12-27T23:42:20 | step: 109800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.787175076780841e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.06 | consumed tokens: 56217600.0 | grad norm avg: 6.28 | grad norm last: 6.25 | 
2025-12-27T23:42:22 | step: 109900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.786750888451934e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.09 | consumed tokens: 56268800.0 | grad norm avg: 6.78 | grad norm last: 5.79 | 
2025-12-27T23:42:24 | step: 110000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.786325972527266e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.91 | consumed tokens: 56320000.0 | grad norm avg: 6.49 | grad norm last: 5.93 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_110000-seen_tokens_56320000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_110000-seen_tokens_56320000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_110000-seen_tokens_56320000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_110000-seen_tokens_56320000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_110000-seen_tokens_56320000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_110000-seen_tokens_56320000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_110000-seen_tokens_56320000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_110000-seen_tokens_56320000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:42:27 | step: 110100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.785901056602597e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.53 | consumed tokens: 56371200.0 | grad norm avg: 6.46 | grad norm last: 5.57 | 
2025-12-27T23:42:29 | step: 110200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.785475413082168e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.17 | consumed tokens: 56422400.0 | grad norm avg: 6.76 | grad norm last: 5.43 | 
2025-12-27T23:42:31 | step: 110300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 9.785049041965976e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.97 | consumed tokens: 56473600.0 | grad norm avg: 6.34 | grad norm last: 5.88 | 
2025-12-27T23:42:33 | step: 110400 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.784623398445547e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.75 | consumed tokens: 56524800.0 | grad norm avg: 6.66 | grad norm last: 6.51 | 
2025-12-27T23:42:35 | step: 110500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.784196299733594e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.98 | consumed tokens: 56576000.0 | grad norm avg: 6.63 | grad norm last: 7.27 | 
2025-12-27T23:42:37 | step: 110600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.78376847342588e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.77 | consumed tokens: 56627200.0 | grad norm avg: 6.74 | grad norm last: 5.65 | 
2025-12-27T23:42:39 | step: 110700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.783342102309689e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.81 | consumed tokens: 56678400.0 | grad norm avg: 6.79 | grad norm last: 6.14 | 
2025-12-27T23:42:41 | step: 110800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.782912820810452e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.34 | consumed tokens: 56729600.0 | grad norm avg: 6.72 | grad norm last: 5.96 | 
2025-12-27T23:42:43 | step: 110900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.782484994502738e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.97 | consumed tokens: 56780800.0 | grad norm avg: 7.15 | grad norm last: 6.57 | 
2025-12-27T23:42:45 | step: 111000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.782056440599263e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.25 | consumed tokens: 56832000.0 | grad norm avg: 6.47 | grad norm last: 5.95 | 
2025-12-27T23:42:47 | step: 111100 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 9.781626431504264e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 5.22 | consumed tokens: 56883200.0 | grad norm avg: 6.53 | grad norm last: 7.74 | 
2025-12-27T23:42:49 | step: 111200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.781197877600789e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 4.12 | consumed tokens: 56934400.0 | grad norm avg: 6.98 | grad norm last: 6.07 | 
2025-12-27T23:42:51 | step: 111300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.780767868505791e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.67 | consumed tokens: 56985600.0 | grad norm avg: 6.69 | grad norm last: 5.68 | 
2025-12-27T23:42:53 | step: 111400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.780337131815031e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.19 | consumed tokens: 57036800.0 | grad norm avg: 6.75 | grad norm last: 6.65 | 
2025-12-27T23:42:55 | step: 111500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.779906395124272e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.41 | consumed tokens: 57088000.0 | grad norm avg: 6.46 | grad norm last: 6.12 | 
2025-12-27T23:42:57 | step: 111600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.77947493083775e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.06 | consumed tokens: 57139200.0 | grad norm avg: 6.67 | grad norm last: 5.68 | 
2025-12-27T23:42:59 | step: 111700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.77904346655123e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 5.5 | consumed tokens: 57190400.0 | grad norm avg: 7.08 | grad norm last: 8.05 | 
2025-12-27T23:43:01 | step: 111800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 9.778611274668947e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 5.28 | consumed tokens: 57241600.0 | grad norm avg: 6.92 | grad norm last: 9.48 | 
2025-12-27T23:43:03 | step: 111900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.778179082786664e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.84 | consumed tokens: 57292800.0 | grad norm avg: 6.78 | grad norm last: 6.56 | 
2025-12-27T23:43:05 | step: 112000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.777745435712859e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.03 | consumed tokens: 57344000.0 | grad norm avg: 6.93 | grad norm last: 11.43 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_112000-seen_tokens_57344000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_112000-seen_tokens_57344000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_112000-seen_tokens_57344000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_112000-seen_tokens_57344000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_112000-seen_tokens_57344000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_112000-seen_tokens_57344000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_112000-seen_tokens_57344000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_112000-seen_tokens_57344000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:43:07 | step: 112100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.777312516234815e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.28 | consumed tokens: 57395200.0 | grad norm avg: 6.61 | grad norm last: 6.16 | 
2025-12-27T23:43:09 | step: 112200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.776878141565248e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.0 | consumed tokens: 57446400.0 | grad norm avg: 6.68 | grad norm last: 5.95 | 
2025-12-27T23:43:11 | step: 112300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.776444494491443e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.75 | consumed tokens: 57497600.0 | grad norm avg: 6.8 | grad norm last: 8.05 | 
2025-12-27T23:43:13 | step: 112400 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.776009392226115e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 4.47 | consumed tokens: 57548800.0 | grad norm avg: 6.76 | grad norm last: 6.28 | 
2025-12-27T23:43:15 | step: 112500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.775574289960787e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.8 | consumed tokens: 57600000.0 | grad norm avg: 6.9 | grad norm last: 5.89 | 
2025-12-27T23:43:17 | step: 112600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.775139187695459e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 6.31 | consumed tokens: 57651200.0 | grad norm avg: 6.85 | grad norm last: 9.9 | 
2025-12-27T23:43:19 | step: 112700 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.77470408543013e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.55 | consumed tokens: 57702400.0 | grad norm avg: 6.79 | grad norm last: 5.77 | 
2025-12-27T23:43:21 | step: 112800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.77426752797328e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 6.59 | consumed tokens: 57753600.0 | grad norm avg: 6.75 | grad norm last: 17.31 | 
2025-12-27T23:43:23 | step: 112900 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.773830970516428e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.75 | consumed tokens: 57804800.0 | grad norm avg: 6.76 | grad norm last: 6.06 | 
2025-12-27T23:43:26 | step: 113000 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.773394413059577e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.23 | consumed tokens: 57856000.0 | grad norm avg: 6.26 | grad norm last: 5.26 | 
2025-12-27T23:43:28 | step: 113100 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.772955672815442e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.28 | consumed tokens: 57907200.0 | grad norm avg: 7.35 | grad norm last: 5.95 | 
2025-12-27T23:43:30 | step: 113200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.77251838776283e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.22 | consumed tokens: 57958400.0 | grad norm avg: 6.75 | grad norm last: 6.27 | 
2025-12-27T23:43:32 | step: 113300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.772079647518694e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 4.12 | consumed tokens: 58009600.0 | grad norm avg: 6.86 | grad norm last: 6.57 | 
2025-12-27T23:43:34 | step: 113400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.771640907274559e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 2.98 | consumed tokens: 58060800.0 | grad norm avg: 6.89 | grad norm last: 5.04 | 
2025-12-27T23:43:36 | step: 113500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.771201439434662e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.28 | consumed tokens: 58112000.0 | grad norm avg: 6.84 | grad norm last: 15.29 | 
2025-12-27T23:43:38 | step: 113600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.770763426786289e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.38 | consumed tokens: 58163200.0 | grad norm avg: 6.65 | grad norm last: 5.34 | 
2025-12-27T23:43:40 | step: 113700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.770322503754869e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 3.92 | consumed tokens: 58214400.0 | grad norm avg: 6.66 | grad norm last: 5.71 | 
2025-12-27T23:43:42 | step: 113800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.769882308319211e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.92 | consumed tokens: 58265600.0 | grad norm avg: 6.42 | grad norm last: 6.38 | 
2025-12-27T23:43:44 | step: 113900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.769442112883553e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 5.0 | consumed tokens: 58316800.0 | grad norm avg: 6.64 | grad norm last: 6.43 | 
2025-12-27T23:43:46 | step: 114000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.769000462256372e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 5.22 | consumed tokens: 58368000.0 | grad norm avg: 6.7 | grad norm last: 7.47 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_114000-seen_tokens_58368000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_114000-seen_tokens_58368000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_114000-seen_tokens_58368000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_114000-seen_tokens_58368000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_114000-seen_tokens_58368000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_114000-seen_tokens_58368000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_114000-seen_tokens_58368000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_114000-seen_tokens_58368000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:43:48 | step: 114100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.768558811629191e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.55 | consumed tokens: 58419200.0 | grad norm avg: 6.5 | grad norm last: 5.56 | 
2025-12-27T23:43:50 | step: 114200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.768116433406249e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.89 | consumed tokens: 58470400.0 | grad norm avg: 6.94 | grad norm last: 6.74 | 
2025-12-27T23:43:52 | step: 114300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.767674055183306e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 5.66 | consumed tokens: 58521600.0 | grad norm avg: 6.83 | grad norm last: 9.33 | 
2025-12-27T23:43:54 | step: 114400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.767231676960364e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.16 | consumed tokens: 58572800.0 | grad norm avg: 6.73 | grad norm last: 6.88 | 
2025-12-27T23:43:56 | step: 114500 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.76678857114166e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.69 | consumed tokens: 58624000.0 | grad norm avg: 6.59 | grad norm last: 6.54 | 
2025-12-27T23:43:58 | step: 114600 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.766345465322956e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.84 | consumed tokens: 58675200.0 | grad norm avg: 6.66 | grad norm last: 5.39 | 
2025-12-27T23:44:00 | step: 114700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.76590090431273e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.67 | consumed tokens: 58726400.0 | grad norm avg: 6.43 | grad norm last: 5.8 | 
2025-12-27T23:44:02 | step: 114800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.765456343302503e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.8 | consumed tokens: 58777600.0 | grad norm avg: 6.82 | grad norm last: 5.68 | 
2025-12-27T23:44:04 | step: 114900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.765011054696515e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 4.0 | consumed tokens: 58828800.0 | grad norm avg: 6.74 | grad norm last: 6.29 | 
2025-12-27T23:44:06 | step: 115000 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.764565766090527e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 2.98 | consumed tokens: 58880000.0 | grad norm avg: 6.73 | grad norm last: 5.87 | 
2025-12-27T23:44:08 | step: 115100 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.764120477484539e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.25 | consumed tokens: 58931200.0 | grad norm avg: 6.61 | grad norm last: 5.84 | 
2025-12-27T23:44:10 | step: 115200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.76367446128279e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.81 | consumed tokens: 58982400.0 | grad norm avg: 6.78 | grad norm last: 11.52 | 
2025-12-27T23:44:12 | step: 115300 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.763226989889517e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 5.22 | consumed tokens: 59033600.0 | grad norm avg: 7.04 | grad norm last: 7.74 | 
2025-12-27T23:44:14 | step: 115400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.762780973687768e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.62 | consumed tokens: 59084800.0 | grad norm avg: 6.88 | grad norm last: 6.99 | 
2025-12-27T23:44:16 | step: 115500 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.762333502294496e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.72 | consumed tokens: 59136000.0 | grad norm avg: 7.36 | grad norm last: 5.36 | 
2025-12-27T23:44:18 | step: 115600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.761886758496985e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.66 | consumed tokens: 59187200.0 | grad norm avg: 6.69 | grad norm last: 6.31 | 
2025-12-27T23:44:20 | step: 115700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.761438559507951e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.83 | consumed tokens: 59238400.0 | grad norm avg: 7.22 | grad norm last: 5.67 | 
2025-12-27T23:44:22 | step: 115800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.760988905327395e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.66 | consumed tokens: 59289600.0 | grad norm avg: 6.55 | grad norm last: 6.81 | 
2025-12-27T23:44:24 | step: 115900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.7605399787426e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.38 | consumed tokens: 59340800.0 | grad norm avg: 6.82 | grad norm last: 8.16 | 
2025-12-27T23:44:26 | step: 116000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.760091052157804e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.94 | consumed tokens: 59392000.0 | grad norm avg: 6.8 | grad norm last: 6.88 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_116000-seen_tokens_59392000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_116000-seen_tokens_59392000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_116000-seen_tokens_59392000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_116000-seen_tokens_59392000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_116000-seen_tokens_59392000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_116000-seen_tokens_59392000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_116000-seen_tokens_59392000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_116000-seen_tokens_59392000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:44:28 | step: 116100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.759640670381486e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.01 | train loss last: 2.97 | consumed tokens: 59443200.0 | grad norm avg: 6.83 | grad norm last: 5.49 | 
2025-12-27T23:44:30 | step: 116200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.759191743796691e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.7 | consumed tokens: 59494400.0 | grad norm avg: 7.0 | grad norm last: 6.17 | 
2025-12-27T23:44:32 | step: 116300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.758739179233089e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.81 | consumed tokens: 59545600.0 | grad norm avg: 6.53 | grad norm last: 8.01 | 
2025-12-27T23:44:34 | step: 116400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.758289525052533e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.98 | consumed tokens: 59596800.0 | grad norm avg: 6.68 | grad norm last: 5.91 | 
2025-12-27T23:44:36 | step: 116500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.75783696048893e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.97 | consumed tokens: 59648000.0 | grad norm avg: 6.47 | grad norm last: 6.62 | 
2025-12-27T23:44:39 | step: 116600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.757385851116851e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.91 | consumed tokens: 59699200.0 | grad norm avg: 6.72 | grad norm last: 6.21 | 
2025-12-27T23:44:41 | step: 116700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.756933286553249e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 5.72 | consumed tokens: 59750400.0 | grad norm avg: 6.58 | grad norm last: 10.09 | 
2025-12-27T23:44:43 | step: 116800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.756480721989647e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.48 | consumed tokens: 59801600.0 | grad norm avg: 6.99 | grad norm last: 6.49 | 
2025-12-27T23:44:45 | step: 116900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.756028157426044e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.84 | consumed tokens: 59852800.0 | grad norm avg: 6.57 | grad norm last: 6.19 | 
2025-12-27T23:44:47 | step: 117000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.755574137670919e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.81 | consumed tokens: 59904000.0 | grad norm avg: 6.79 | grad norm last: 6.46 | 
2025-12-27T23:44:49 | step: 117100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.755120845511556e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.59 | consumed tokens: 59955200.0 | grad norm avg: 6.34 | grad norm last: 6.01 | 
2025-12-27T23:44:51 | step: 117200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.754666098160669e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.73 | consumed tokens: 60006400.0 | grad norm avg: 7.0 | grad norm last: 5.64 | 
2025-12-27T23:44:53 | step: 117300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.754210623214021e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.56 | consumed tokens: 60057600.0 | grad norm avg: 6.59 | grad norm last: 7.22 | 
2025-12-27T23:44:55 | step: 117400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 9.753756603458896e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.84 | consumed tokens: 60108800.0 | grad norm avg: 6.6 | grad norm last: 5.48 | 
2025-12-27T23:44:57 | step: 117500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.753301128512248e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.5 | consumed tokens: 60160000.0 | grad norm avg: 6.71 | grad norm last: 5.93 | 
2025-12-27T23:44:59 | step: 117600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.752844925969839e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.66 | consumed tokens: 60211200.0 | grad norm avg: 6.63 | grad norm last: 6.98 | 
2025-12-27T23:45:01 | step: 117700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.75238872342743e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 4.28 | consumed tokens: 60262400.0 | grad norm avg: 7.01 | grad norm last: 5.87 | 
2025-12-27T23:45:03 | step: 117800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.751931793289259e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.86 | consumed tokens: 60313600.0 | grad norm avg: 6.94 | grad norm last: 8.93 | 
2025-12-27T23:45:05 | step: 117900 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.751474863151088e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 4.03 | consumed tokens: 60364800.0 | grad norm avg: 6.95 | grad norm last: 6.64 | 
2025-12-27T23:45:07 | step: 118000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.751017205417156e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.15 | train loss last: 3.33 | consumed tokens: 60416000.0 | grad norm avg: 7.03 | grad norm last: 6.88 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_118000-seen_tokens_60416000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_118000-seen_tokens_60416000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_118000-seen_tokens_60416000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_118000-seen_tokens_60416000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_118000-seen_tokens_60416000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_118000-seen_tokens_60416000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_118000-seen_tokens_60416000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_118000-seen_tokens_60416000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:45:09 | step: 118100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.750559547683224e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.56 | consumed tokens: 60467200.0 | grad norm avg: 6.76 | grad norm last: 7.28 | 
2025-12-27T23:45:11 | step: 118200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.75010116235353e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.52 | consumed tokens: 60518400.0 | grad norm avg: 6.63 | grad norm last: 6.59 | 
2025-12-27T23:45:13 | step: 118300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.749641321832314e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.13 | train loss last: 3.94 | consumed tokens: 60569600.0 | grad norm avg: 6.78 | grad norm last: 7.12 | 
2025-12-27T23:45:15 | step: 118400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.74918293650262e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.8 | consumed tokens: 60620800.0 | grad norm avg: 6.62 | grad norm last: 6.29 | 
2025-12-27T23:45:17 | step: 118500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.748723095981404e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.8 | consumed tokens: 60672000.0 | grad norm avg: 6.43 | grad norm last: 6.61 | 
2025-12-27T23:45:19 | step: 118600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.748263255460188e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.64 | consumed tokens: 60723200.0 | grad norm avg: 6.75 | grad norm last: 5.66 | 
2025-12-27T23:45:21 | step: 118700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.747801959747449e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.22 | consumed tokens: 60774400.0 | grad norm avg: 6.7 | grad norm last: 5.59 | 
2025-12-27T23:45:23 | step: 118800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.747342119226232e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.5 | consumed tokens: 60825600.0 | grad norm avg: 6.78 | grad norm last: 7.93 | 
2025-12-27T23:45:25 | step: 118900 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.746880823513493e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.86 | consumed tokens: 60876800.0 | grad norm avg: 6.71 | grad norm last: 5.89 | 
2025-12-27T23:45:27 | step: 119000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.746419527800754e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.89 | consumed tokens: 60928000.0 | grad norm avg: 6.48 | grad norm last: 6.68 | 
2025-12-27T23:45:29 | step: 119100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.745956776896492e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.94 | consumed tokens: 60979200.0 | grad norm avg: 6.75 | grad norm last: 13.3 | 
2025-12-27T23:45:31 | step: 119200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.745495481183752e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 4.0 | consumed tokens: 61030400.0 | grad norm avg: 6.9 | grad norm last: 6.37 | 
2025-12-27T23:45:33 | step: 119300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.745031275087968e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.95 | consumed tokens: 61081600.0 | grad norm avg: 6.44 | grad norm last: 6.52 | 
2025-12-27T23:45:35 | step: 119400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.744568524183705e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.92 | consumed tokens: 61132800.0 | grad norm avg: 6.65 | grad norm last: 5.77 | 
2025-12-27T23:45:37 | step: 119500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.744105045683682e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.5 | consumed tokens: 61184000.0 | grad norm avg: 6.72 | grad norm last: 5.61 | 
2025-12-27T23:45:39 | step: 119600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.743640111992136e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.19 | consumed tokens: 61235200.0 | grad norm avg: 6.68 | grad norm last: 7.11 | 
2025-12-27T23:45:41 | step: 119700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.743176633492112e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.44 | consumed tokens: 61286400.0 | grad norm avg: 6.69 | grad norm last: 8.0 | 
2025-12-27T23:45:43 | step: 119800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.742711699800566e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.66 | consumed tokens: 61337600.0 | grad norm avg: 6.58 | grad norm last: 5.86 | 
2025-12-27T23:45:45 | step: 119900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.742246038513258e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.42 | consumed tokens: 61388800.0 | grad norm avg: 6.65 | grad norm last: 6.76 | 
2025-12-27T23:45:47 | step: 120000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.74178037722595e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.53 | consumed tokens: 61440000.0 | grad norm avg: 6.73 | grad norm last: 7.15 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_120000-seen_tokens_61440000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_120000-seen_tokens_61440000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_120000-seen_tokens_61440000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_120000-seen_tokens_61440000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_120000-seen_tokens_61440000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_120000-seen_tokens_61440000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_120000-seen_tokens_61440000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_120000-seen_tokens_61440000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:45:50 | step: 120100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.741313988342881e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.96 | train loss last: 3.84 | consumed tokens: 61491200.0 | grad norm avg: 6.34 | grad norm last: 6.45 | 
2025-12-27T23:45:52 | step: 120200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.740847599459812e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.38 | consumed tokens: 61542400.0 | grad norm avg: 6.49 | grad norm last: 5.65 | 
2025-12-27T23:45:54 | step: 120300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.740380482980981e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.84 | consumed tokens: 61593600.0 | grad norm avg: 6.58 | grad norm last: 7.34 | 
2025-12-27T23:45:56 | step: 120400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.739913366502151e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.42 | consumed tokens: 61644800.0 | grad norm avg: 6.4 | grad norm last: 5.47 | 
2025-12-27T23:45:58 | step: 120500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.739445522427559e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.81 | consumed tokens: 61696000.0 | grad norm avg: 6.71 | grad norm last: 7.01 | 
2025-12-27T23:46:00 | step: 120600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.738977678352967e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 4.25 | consumed tokens: 61747200.0 | grad norm avg: 6.53 | grad norm last: 7.03 | 
2025-12-27T23:46:02 | step: 120700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.738509106682613e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.88 | consumed tokens: 61798400.0 | grad norm avg: 6.6 | grad norm last: 7.02 | 
2025-12-27T23:46:04 | step: 120800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.738039807416499e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.67 | consumed tokens: 61849600.0 | grad norm avg: 6.58 | grad norm last: 5.94 | 
2025-12-27T23:46:06 | step: 120900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.737570508150384e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.69 | consumed tokens: 61900800.0 | grad norm avg: 7.12 | grad norm last: 5.51 | 
2025-12-27T23:46:08 | step: 121000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.737100481288508e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.61 | consumed tokens: 61952000.0 | grad norm avg: 6.68 | grad norm last: 6.27 | 
2025-12-27T23:46:10 | step: 121100 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.736630454426631e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.03 | consumed tokens: 62003200.0 | grad norm avg: 6.59 | grad norm last: 7.54 | 
2025-12-27T23:46:12 | step: 121200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.736159699968994e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.55 | consumed tokens: 62054400.0 | grad norm avg: 6.6 | grad norm last: 6.05 | 
2025-12-27T23:46:14 | step: 121300 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.735688945511356e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.95 | consumed tokens: 62105600.0 | grad norm avg: 6.62 | grad norm last: 5.94 | 
2025-12-27T23:46:16 | step: 121400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.735217463457957e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 5.0 | consumed tokens: 62156800.0 | grad norm avg: 6.41 | grad norm last: 8.27 | 
2025-12-27T23:46:18 | step: 121500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.734745253808796e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.33 | consumed tokens: 62208000.0 | grad norm avg: 6.58 | grad norm last: 6.99 | 
2025-12-27T23:46:20 | step: 121600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.734273044159636e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 4.59 | consumed tokens: 62259200.0 | grad norm avg: 6.82 | grad norm last: 7.39 | 
2025-12-27T23:46:22 | step: 121700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.733801562106237e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.86 | consumed tokens: 62310400.0 | grad norm avg: 6.37 | grad norm last: 6.75 | 
2025-12-27T23:46:24 | step: 121800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.733327897265553e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.41 | consumed tokens: 62361600.0 | grad norm avg: 6.46 | grad norm last: 6.3 | 
2025-12-27T23:46:26 | step: 121900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 9.73285423242487e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.06 | consumed tokens: 62412800.0 | grad norm avg: 6.75 | grad norm last: 6.45 | 
2025-12-27T23:46:28 | step: 122000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.732381295179948e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.83 | consumed tokens: 62464000.0 | grad norm avg: 6.53 | grad norm last: 6.35 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_122000-seen_tokens_62464000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_122000-seen_tokens_62464000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_122000-seen_tokens_62464000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_122000-seen_tokens_62464000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_122000-seen_tokens_62464000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_122000-seen_tokens_62464000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_122000-seen_tokens_62464000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_122000-seen_tokens_62464000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:46:30 | step: 122100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.73190544755198e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.06 | consumed tokens: 62515200.0 | grad norm avg: 6.75 | grad norm last: 5.72 | 
2025-12-27T23:46:32 | step: 122200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.731431055115536e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.7 | consumed tokens: 62566400.0 | grad norm avg: 6.58 | grad norm last: 6.35 | 
2025-12-27T23:46:34 | step: 122300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.73095593508333e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.41 | consumed tokens: 62617600.0 | grad norm avg: 6.48 | grad norm last: 6.36 | 
2025-12-27T23:46:36 | step: 122400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.730480815051123e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.56 | consumed tokens: 62668800.0 | grad norm avg: 6.64 | grad norm last: 5.81 | 
2025-12-27T23:46:38 | step: 122500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.730004967423156e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.42 | consumed tokens: 62720000.0 | grad norm avg: 6.58 | grad norm last: 6.22 | 
2025-12-27T23:46:40 | step: 122600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.729529119795188e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 4.38 | consumed tokens: 62771200.0 | grad norm avg: 6.56 | grad norm last: 5.99 | 
2025-12-27T23:46:42 | step: 122700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.729051816975698e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.62 | consumed tokens: 62822400.0 | grad norm avg: 6.37 | grad norm last: 5.72 | 
2025-12-27T23:46:44 | step: 122800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.728574514156207e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.73 | consumed tokens: 62873600.0 | grad norm avg: 6.79 | grad norm last: 5.89 | 
2025-12-27T23:46:46 | step: 122900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 9.728097211336717e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 6.06 | consumed tokens: 62924800.0 | grad norm avg: 6.74 | grad norm last: 15.99 | 
2025-12-27T23:46:48 | step: 123000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.727619908517227e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.94 | consumed tokens: 62976000.0 | grad norm avg: 6.49 | grad norm last: 5.95 | 
2025-12-27T23:46:50 | step: 123100 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.727140422910452e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.28 | consumed tokens: 63027200.0 | grad norm avg: 6.43 | grad norm last: 6.14 | 
2025-12-27T23:46:52 | step: 123200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.726660937303677e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 3.42 | consumed tokens: 63078400.0 | grad norm avg: 6.71 | grad norm last: 6.15 | 
2025-12-27T23:46:54 | step: 123300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.726182906888425e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.25 | consumed tokens: 63129600.0 | grad norm avg: 6.63 | grad norm last: 6.15 | 
2025-12-27T23:46:56 | step: 123400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.72570342128165e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 3.72 | consumed tokens: 63180800.0 | grad norm avg: 6.64 | grad norm last: 5.58 | 
2025-12-27T23:46:58 | step: 123500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.725223208079115e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.83 | consumed tokens: 63232000.0 | grad norm avg: 6.35 | grad norm last: 5.9 | 
2025-12-27T23:47:00 | step: 123600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.724742994876578e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.56 | consumed tokens: 63283200.0 | grad norm avg: 6.54 | grad norm last: 6.0 | 
2025-12-27T23:47:02 | step: 123700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.724262054078281e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.36 | consumed tokens: 63334400.0 | grad norm avg: 6.61 | grad norm last: 5.44 | 
2025-12-27T23:47:04 | step: 123800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 9.723781113279983e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.03 | consumed tokens: 63385600.0 | grad norm avg: 6.63 | grad norm last: 5.9 | 
2025-12-27T23:47:06 | step: 123900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.723299444885924e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.66 | consumed tokens: 63436800.0 | grad norm avg: 6.29 | grad norm last: 7.11 | 
2025-12-27T23:47:08 | step: 124000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.722817776491866e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 3.27 | consumed tokens: 63488000.0 | grad norm avg: 6.52 | grad norm last: 5.84 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_124000-seen_tokens_63488000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_124000-seen_tokens_63488000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_124000-seen_tokens_63488000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_124000-seen_tokens_63488000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_124000-seen_tokens_63488000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_124000-seen_tokens_63488000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_124000-seen_tokens_63488000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_124000-seen_tokens_63488000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:47:11 | step: 124100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.722334652906284e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.83 | consumed tokens: 63539200.0 | grad norm avg: 6.44 | grad norm last: 5.63 | 
2025-12-27T23:47:13 | step: 124200 | train samples/s: 107.9 | train mfu (16-bit): -1.0 | lr mean: 9.721852256916463e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.38 | consumed tokens: 63590400.0 | grad norm avg: 6.37 | grad norm last: 5.58 | 
2025-12-27T23:47:15 | step: 124300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.721369133330882e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.44 | consumed tokens: 63641600.0 | grad norm avg: 6.51 | grad norm last: 6.38 | 
2025-12-27T23:47:17 | step: 124400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.720885282149538e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 5.88 | consumed tokens: 63692800.0 | grad norm avg: 6.6 | grad norm last: 20.9 | 
2025-12-27T23:47:19 | step: 124500 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.720402158563957e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.81 | consumed tokens: 63744000.0 | grad norm avg: 6.56 | grad norm last: 6.31 | 
2025-12-27T23:47:21 | step: 124600 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.71991685219109e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.7 | consumed tokens: 63795200.0 | grad norm avg: 6.84 | grad norm last: 5.55 | 
2025-12-27T23:47:23 | step: 124700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.719431545818225e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.28 | consumed tokens: 63846400.0 | grad norm avg: 6.31 | grad norm last: 6.72 | 
2025-12-27T23:47:25 | step: 124800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.71894696704112e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.44 | consumed tokens: 63897600.0 | grad norm avg: 6.38 | grad norm last: 5.34 | 
2025-12-27T23:47:27 | step: 124900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.718460933072492e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.28 | consumed tokens: 63948800.0 | grad norm avg: 6.46 | grad norm last: 6.26 | 
2025-12-27T23:47:29 | step: 125000 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.717974899103865e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.09 | train loss last: 4.22 | consumed tokens: 64000000.0 | grad norm avg: 6.6 | grad norm last: 6.07 | 
2025-12-27T23:47:31 | step: 125100 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.717487409943715e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.02 | consumed tokens: 64051200.0 | grad norm avg: 6.25 | grad norm last: 5.48 | 
2025-12-27T23:47:33 | step: 125200 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.717001375975087e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.03 | consumed tokens: 64102400.0 | grad norm avg: 6.64 | grad norm last: 6.69 | 
2025-12-27T23:47:35 | step: 125300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.716514614410698e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.83 | consumed tokens: 64153600.0 | grad norm avg: 6.66 | grad norm last: 7.83 | 
2025-12-27T23:47:37 | step: 125400 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.716026397654787e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.28 | consumed tokens: 64204800.0 | grad norm avg: 6.36 | grad norm last: 5.28 | 
2025-12-27T23:47:39 | step: 125500 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.715537453303114e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.13 | train loss last: 4.5 | consumed tokens: 64256000.0 | grad norm avg: 6.64 | grad norm last: 6.53 | 
2025-12-27T23:47:41 | step: 125600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.715049964142963e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.25 | consumed tokens: 64307200.0 | grad norm avg: 6.61 | grad norm last: 6.39 | 
2025-12-27T23:47:43 | step: 125700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.71456101979129e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.47 | consumed tokens: 64358400.0 | grad norm avg: 6.49 | grad norm last: 6.31 | 
2025-12-27T23:47:45 | step: 125800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.714072075439617e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.27 | consumed tokens: 64409600.0 | grad norm avg: 6.58 | grad norm last: 5.02 | 
2025-12-27T23:47:47 | step: 125900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.713581675896421e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 4.5 | consumed tokens: 64460800.0 | grad norm avg: 6.67 | grad norm last: 6.56 | 
2025-12-27T23:47:49 | step: 126000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.713092003948987e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.41 | consumed tokens: 64512000.0 | grad norm avg: 6.67 | grad norm last: 6.16 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_126000-seen_tokens_64512000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_126000-seen_tokens_64512000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_126000-seen_tokens_64512000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_126000-seen_tokens_64512000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_126000-seen_tokens_64512000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_126000-seen_tokens_64512000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_126000-seen_tokens_64512000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_126000-seen_tokens_64512000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:47:51 | step: 126100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.712602332001552e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.0 | train loss last: 3.8 | consumed tokens: 64563200.0 | grad norm avg: 6.61 | grad norm last: 5.93 | 
2025-12-27T23:47:53 | step: 126200 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.712110477266833e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 2.78 | consumed tokens: 64614400.0 | grad norm avg: 6.47 | grad norm last: 5.33 | 
2025-12-27T23:47:55 | step: 126300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.711619350127876e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.22 | consumed tokens: 64665600.0 | grad norm avg: 6.42 | grad norm last: 7.17 | 
2025-12-27T23:47:57 | step: 126400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.711127495393157e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.67 | consumed tokens: 64716800.0 | grad norm avg: 6.46 | grad norm last: 5.84 | 
2025-12-27T23:47:59 | step: 126500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.710634913062677e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.3 | consumed tokens: 64768000.0 | grad norm avg: 6.43 | grad norm last: 6.27 | 
2025-12-27T23:48:01 | step: 126600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.710143058327958e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.16 | consumed tokens: 64819200.0 | grad norm avg: 6.49 | grad norm last: 6.52 | 
2025-12-27T23:48:03 | step: 126700 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.709649748401716e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.25 | consumed tokens: 64870400.0 | grad norm avg: 6.33 | grad norm last: 6.54 | 
2025-12-27T23:48:05 | step: 126800 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.709156438475475e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.67 | consumed tokens: 64921600.0 | grad norm avg: 6.56 | grad norm last: 6.49 | 
2025-12-27T23:48:07 | step: 126900 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.708662400953472e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.38 | consumed tokens: 64972800.0 | grad norm avg: 6.68 | grad norm last: 6.01 | 
2025-12-27T23:48:09 | step: 127000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.708168363431469e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.03 | consumed tokens: 65024000.0 | grad norm avg: 6.66 | grad norm last: 6.29 | 
2025-12-27T23:48:11 | step: 127100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.707673598313704e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.44 | consumed tokens: 65075200.0 | grad norm avg: 6.53 | grad norm last: 6.27 | 
2025-12-27T23:48:13 | step: 127200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.70717883319594e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.72 | consumed tokens: 65126400.0 | grad norm avg: 6.51 | grad norm last: 6.21 | 
2025-12-27T23:48:15 | step: 127300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.706683340482414e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.09 | consumed tokens: 65177600.0 | grad norm avg: 6.44 | grad norm last: 5.95 | 
2025-12-27T23:48:17 | step: 127400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.706187847768888e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.0 | consumed tokens: 65228800.0 | grad norm avg: 6.78 | grad norm last: 5.83 | 
2025-12-27T23:48:19 | step: 127500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.7056916274596e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.89 | consumed tokens: 65280000.0 | grad norm avg: 6.65 | grad norm last: 6.07 | 
2025-12-27T23:48:21 | step: 127600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.70519395195879e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.53 | consumed tokens: 65331200.0 | grad norm avg: 6.68 | grad norm last: 8.11 | 
2025-12-27T23:48:23 | step: 127700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.704697731649503e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.75 | consumed tokens: 65382400.0 | grad norm avg: 6.64 | grad norm last: 6.02 | 
2025-12-27T23:48:25 | step: 127800 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.704200783744454e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.33 | consumed tokens: 65433600.0 | grad norm avg: 6.48 | grad norm last: 5.85 | 
2025-12-27T23:48:27 | step: 127900 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.703702380647883e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.94 | consumed tokens: 65484800.0 | grad norm avg: 6.49 | grad norm last: 6.51 | 
2025-12-27T23:48:29 | step: 128000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.703204705147073e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.77 | consumed tokens: 65536000.0 | grad norm avg: 6.53 | grad norm last: 5.59 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_128000-seen_tokens_65536000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_128000-seen_tokens_65536000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_128000-seen_tokens_65536000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_128000-seen_tokens_65536000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_128000-seen_tokens_65536000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_128000-seen_tokens_65536000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_128000-seen_tokens_65536000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_128000-seen_tokens_65536000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:48:32 | step: 128100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.70270557445474e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.42 | consumed tokens: 65587200.0 | grad norm avg: 6.44 | grad norm last: 5.87 | 
2025-12-27T23:48:34 | step: 128200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.702207171358168e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.11 | train loss last: 4.03 | consumed tokens: 65638400.0 | grad norm avg: 6.79 | grad norm last: 8.53 | 
2025-12-27T23:48:36 | step: 128300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.701707313070074e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.77 | consumed tokens: 65689600.0 | grad norm avg: 6.38 | grad norm last: 5.92 | 
2025-12-27T23:48:38 | step: 128400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.701206727186218e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.92 | consumed tokens: 65740800.0 | grad norm avg: 6.51 | grad norm last: 6.83 | 
2025-12-27T23:48:40 | step: 128500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.700707596493885e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.53 | consumed tokens: 65792000.0 | grad norm avg: 6.72 | grad norm last: 5.43 | 
2025-12-27T23:48:42 | step: 128600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.700207010610029e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.77 | consumed tokens: 65843200.0 | grad norm avg: 7.4 | grad norm last: 6.54 | 
2025-12-27T23:48:44 | step: 128700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.69970496953465e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.11 | consumed tokens: 65894400.0 | grad norm avg: 6.38 | grad norm last: 5.28 | 
2025-12-27T23:48:46 | step: 128800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 9.699204383650795e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.84 | consumed tokens: 65945600.0 | grad norm avg: 6.81 | grad norm last: 5.95 | 
2025-12-27T23:48:48 | step: 128900 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 9.698702342575416e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.64 | consumed tokens: 65996800.0 | grad norm avg: 6.36 | grad norm last: 5.86 | 
2025-12-27T23:48:50 | step: 129000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 9.698200301500037e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.56 | consumed tokens: 66048000.0 | grad norm avg: 6.55 | grad norm last: 6.64 | 
2025-12-27T23:48:52 | step: 129100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.697696805233136e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.19 | consumed tokens: 66099200.0 | grad norm avg: 6.58 | grad norm last: 6.48 | 
2025-12-27T23:48:54 | step: 129200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 9.697194764157757e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.06 | consumed tokens: 66150400.0 | grad norm avg: 6.65 | grad norm last: 8.4 | 
2025-12-27T23:48:56 | step: 129300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.696691267890856e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.66 | consumed tokens: 66201600.0 | grad norm avg: 6.67 | grad norm last: 6.95 | 
2025-12-27T23:48:58 | step: 129400 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 9.696187771623954e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.91 | consumed tokens: 66252800.0 | grad norm avg: 6.49 | grad norm last: 8.0 | 
2025-12-27T23:49:00 | step: 129500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.69568282016553e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 5.66 | consumed tokens: 66304000.0 | grad norm avg: 6.43 | grad norm last: 12.69 | 
2025-12-27T23:49:02 | step: 129600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.695177868707106e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.27 | consumed tokens: 66355200.0 | grad norm avg: 6.63 | grad norm last: 5.67 | 
2025-12-27T23:49:04 | step: 129700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.694672917248681e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.0 | consumed tokens: 66406400.0 | grad norm avg: 6.52 | grad norm last: 7.55 | 
2025-12-27T23:49:06 | step: 129800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.694167965790257e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.45 | consumed tokens: 66457600.0 | grad norm avg: 6.41 | grad norm last: 7.72 | 
2025-12-27T23:49:08 | step: 129900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.69366155914031e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.0 | consumed tokens: 66508800.0 | grad norm avg: 6.33 | grad norm last: 6.14 | 
2025-12-27T23:49:10 | step: 130000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.693155152490363e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.06 | consumed tokens: 66560000.0 | grad norm avg: 6.36 | grad norm last: 6.26 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_130000-seen_tokens_66560000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_130000-seen_tokens_66560000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_130000-seen_tokens_66560000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_130000-seen_tokens_66560000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_130000-seen_tokens_66560000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_130000-seen_tokens_66560000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_130000-seen_tokens_66560000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_130000-seen_tokens_66560000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:49:13 | step: 130100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.692648745840415e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.8 | consumed tokens: 66611200.0 | grad norm avg: 6.76 | grad norm last: 5.74 | 
2025-12-27T23:49:15 | step: 130200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.692142339190468e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 3.34 | consumed tokens: 66662400.0 | grad norm avg: 6.59 | grad norm last: 6.23 | 
2025-12-27T23:49:17 | step: 130300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.691633749753237e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.1 | train loss last: 4.16 | consumed tokens: 66713600.0 | grad norm avg: 6.76 | grad norm last: 6.54 | 
2025-12-27T23:49:19 | step: 130400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.691125160316005e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.03 | consumed tokens: 66764800.0 | grad norm avg: 6.56 | grad norm last: 10.92 | 
2025-12-27T23:49:21 | step: 130500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.690618026070297e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.66 | consumed tokens: 66816000.0 | grad norm avg: 6.85 | grad norm last: 5.21 | 
2025-12-27T23:49:23 | step: 130600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.690109436633065e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.73 | consumed tokens: 66867200.0 | grad norm avg: 6.45 | grad norm last: 5.91 | 
2025-12-27T23:49:25 | step: 130700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.689600119600073e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.06 | consumed tokens: 66918400.0 | grad norm avg: 6.43 | grad norm last: 6.53 | 
2025-12-27T23:49:27 | step: 130800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.68909080256708e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.16 | consumed tokens: 66969600.0 | grad norm avg: 6.62 | grad norm last: 6.22 | 
2025-12-27T23:49:29 | step: 130900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.688580757938325e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.97 | consumed tokens: 67020800.0 | grad norm avg: 6.3 | grad norm last: 6.82 | 
2025-12-27T23:49:31 | step: 131000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.688069258118048e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.94 | consumed tokens: 67072000.0 | grad norm avg: 6.57 | grad norm last: 7.51 | 
2025-12-27T23:49:33 | step: 131100 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.687559213489294e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.5 | consumed tokens: 67123200.0 | grad norm avg: 6.52 | grad norm last: 7.07 | 
2025-12-27T23:49:35 | step: 131200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.68704916886054e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.59 | consumed tokens: 67174400.0 | grad norm avg: 6.63 | grad norm last: 6.66 | 
2025-12-27T23:49:37 | step: 131300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.686536941444501e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.81 | consumed tokens: 67225600.0 | grad norm avg: 6.62 | grad norm last: 5.71 | 
2025-12-27T23:49:39 | step: 131400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.686024714028463e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 4.44 | consumed tokens: 67276800.0 | grad norm avg: 6.66 | grad norm last: 6.88 | 
2025-12-27T23:49:41 | step: 131500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.685512486612424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.25 | consumed tokens: 67328000.0 | grad norm avg: 6.43 | grad norm last: 8.21 | 
2025-12-27T23:49:43 | step: 131600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.685000259196386e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 5.03 | consumed tokens: 67379200.0 | grad norm avg: 6.39 | grad norm last: 7.59 | 
2025-12-27T23:49:45 | step: 131700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.684486576588824e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.94 | consumed tokens: 67430400.0 | grad norm avg: 6.5 | grad norm last: 9.85 | 
2025-12-27T23:49:47 | step: 131800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.683972893981263e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 4.19 | consumed tokens: 67481600.0 | grad norm avg: 6.81 | grad norm last: 5.69 | 
2025-12-27T23:49:49 | step: 131900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.683459211373702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.92 | consumed tokens: 67532800.0 | grad norm avg: 6.53 | grad norm last: 6.06 | 
2025-12-27T23:49:51 | step: 132000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.68294552876614e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.55 | consumed tokens: 67584000.0 | grad norm avg: 6.51 | grad norm last: 5.56 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_132000-seen_tokens_67584000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_132000-seen_tokens_67584000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_132000-seen_tokens_67584000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_132000-seen_tokens_67584000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_132000-seen_tokens_67584000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_132000-seen_tokens_67584000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_132000-seen_tokens_67584000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_132000-seen_tokens_67584000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:49:53 | step: 132100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.682430390967056e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.22 | consumed tokens: 67635200.0 | grad norm avg: 6.31 | grad norm last: 5.83 | 
2025-12-27T23:49:55 | step: 132200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.681915253167972e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.72 | consumed tokens: 67686400.0 | grad norm avg: 6.5 | grad norm last: 6.02 | 
2025-12-27T23:49:57 | step: 132300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.681398660177365e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.47 | consumed tokens: 67737600.0 | grad norm avg: 6.41 | grad norm last: 5.39 | 
2025-12-27T23:49:59 | step: 132400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.680883522378281e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.77 | consumed tokens: 67788800.0 | grad norm avg: 6.64 | grad norm last: 6.46 | 
2025-12-27T23:50:01 | step: 132500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.680366929387674e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 4.16 | consumed tokens: 67840000.0 | grad norm avg: 6.69 | grad norm last: 8.38 | 
2025-12-27T23:50:03 | step: 132600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.679850336397067e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.83 | consumed tokens: 67891200.0 | grad norm avg: 6.56 | grad norm last: 6.43 | 
2025-12-27T23:50:05 | step: 132700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.679332288214937e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.89 | consumed tokens: 67942400.0 | grad norm avg: 6.75 | grad norm last: 6.09 | 
2025-12-27T23:50:07 | step: 132800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.67881569522433e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.66 | consumed tokens: 67993600.0 | grad norm avg: 6.68 | grad norm last: 7.62 | 
2025-12-27T23:50:09 | step: 132900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.6782976470422e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 2.69 | consumed tokens: 68044800.0 | grad norm avg: 6.52 | grad norm last: 5.2 | 
2025-12-27T23:50:11 | step: 133000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.67777959886007e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.61 | consumed tokens: 68096000.0 | grad norm avg: 6.41 | grad norm last: 6.4 | 
2025-12-27T23:50:13 | step: 133100 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.677260095486417e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.22 | consumed tokens: 68147200.0 | grad norm avg: 6.47 | grad norm last: 7.76 | 
2025-12-27T23:50:15 | step: 133200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.676741319708526e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 2.8 | consumed tokens: 68198400.0 | grad norm avg: 6.64 | grad norm last: 4.97 | 
2025-12-27T23:50:17 | step: 133300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.676222543930635e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.73 | consumed tokens: 68249600.0 | grad norm avg: 6.92 | grad norm last: 6.9 | 
2025-12-27T23:50:19 | step: 133400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.67570158536546e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 5.28 | consumed tokens: 68300800.0 | grad norm avg: 6.61 | grad norm last: 6.46 | 
2025-12-27T23:50:21 | step: 133500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.675181354396045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.12 | consumed tokens: 68352000.0 | grad norm avg: 6.54 | grad norm last: 5.89 | 
2025-12-27T23:50:23 | step: 133600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.67466039583087e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 5.03 | consumed tokens: 68403200.0 | grad norm avg: 6.32 | grad norm last: 6.55 | 
2025-12-27T23:50:25 | step: 133700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.674139437265694e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.3 | consumed tokens: 68454400.0 | grad norm avg: 6.58 | grad norm last: 5.78 | 
2025-12-27T23:50:27 | step: 133800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.673617751104757e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.84 | consumed tokens: 68505600.0 | grad norm avg: 6.64 | grad norm last: 5.49 | 
2025-12-27T23:50:29 | step: 133900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.673096792539582e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.41 | consumed tokens: 68556800.0 | grad norm avg: 6.55 | grad norm last: 9.23 | 
2025-12-27T23:50:31 | step: 134000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.672573651187122e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.95 | consumed tokens: 68608000.0 | grad norm avg: 6.45 | grad norm last: 9.03 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_134000-seen_tokens_68608000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_134000-seen_tokens_68608000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_134000-seen_tokens_68608000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_134000-seen_tokens_68608000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_134000-seen_tokens_68608000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_134000-seen_tokens_68608000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_134000-seen_tokens_68608000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_134000-seen_tokens_68608000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:50:34 | step: 134100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.672050509834662e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.93 | train loss last: 3.52 | consumed tokens: 68659200.0 | grad norm avg: 6.42 | grad norm last: 6.38 | 
2025-12-27T23:50:36 | step: 134200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.671526640886441e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.19 | consumed tokens: 68710400.0 | grad norm avg: 6.43 | grad norm last: 8.01 | 
2025-12-27T23:50:38 | step: 134300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.671004227129743e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 4.81 | consumed tokens: 68761600.0 | grad norm avg: 6.54 | grad norm last: 6.21 | 
2025-12-27T23:50:40 | step: 134400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.670480358181521e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.52 | consumed tokens: 68812800.0 | grad norm avg: 6.63 | grad norm last: 6.9 | 
2025-12-27T23:50:42 | step: 134500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.669955034041777e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.69 | consumed tokens: 68864000.0 | grad norm avg: 6.3 | grad norm last: 5.62 | 
2025-12-27T23:50:44 | step: 134600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 9.669431165093556e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.3 | consumed tokens: 68915200.0 | grad norm avg: 6.65 | grad norm last: 6.48 | 
2025-12-27T23:50:46 | step: 134700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.668905840953812e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.81 | consumed tokens: 68966400.0 | grad norm avg: 6.51 | grad norm last: 6.82 | 
2025-12-27T23:50:48 | step: 134800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.668379789218307e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.72 | consumed tokens: 69017600.0 | grad norm avg: 6.59 | grad norm last: 6.24 | 
2025-12-27T23:50:50 | step: 134900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.667853737482801e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.56 | consumed tokens: 69068800.0 | grad norm avg: 6.47 | grad norm last: 7.25 | 
2025-12-27T23:50:52 | step: 135000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.667328413343057e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.64 | consumed tokens: 69120000.0 | grad norm avg: 6.76 | grad norm last: 6.3 | 
2025-12-27T23:50:54 | step: 135100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.666800178820267e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.98 | consumed tokens: 69171200.0 | grad norm avg: 6.36 | grad norm last: 7.39 | 
2025-12-27T23:50:56 | step: 135200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.666273399489e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.56 | consumed tokens: 69222400.0 | grad norm avg: 6.66 | grad norm last: 7.04 | 
2025-12-27T23:50:58 | step: 135300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.665745892561972e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.92 | consumed tokens: 69273600.0 | grad norm avg: 6.88 | grad norm last: 6.0 | 
2025-12-27T23:51:00 | step: 135400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 9.665218385634944e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.44 | consumed tokens: 69324800.0 | grad norm avg: 6.53 | grad norm last: 6.27 | 
2025-12-27T23:51:02 | step: 135500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.664689423516393e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.03 | consumed tokens: 69376000.0 | grad norm avg: 6.41 | grad norm last: 7.08 | 
2025-12-27T23:51:04 | step: 135600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.664161916589364e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.58 | consumed tokens: 69427200.0 | grad norm avg: 6.84 | grad norm last: 5.34 | 
2025-12-27T23:51:06 | step: 135700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.663632226875052e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.44 | consumed tokens: 69478400.0 | grad norm avg: 6.61 | grad norm last: 5.63 | 
2025-12-27T23:51:08 | step: 135800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.663102537160739e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 5.28 | consumed tokens: 69529600.0 | grad norm avg: 6.69 | grad norm last: 8.46 | 
2025-12-27T23:51:10 | step: 135900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.662572847446427e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.62 | consumed tokens: 69580800.0 | grad norm avg: 6.51 | grad norm last: 6.48 | 
2025-12-27T23:51:12 | step: 136000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.662041702540591e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.7 | consumed tokens: 69632000.0 | grad norm avg: 6.43 | grad norm last: 6.2 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_136000-seen_tokens_69632000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_136000-seen_tokens_69632000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_136000-seen_tokens_69632000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_136000-seen_tokens_69632000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_136000-seen_tokens_69632000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_136000-seen_tokens_69632000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_136000-seen_tokens_69632000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_136000-seen_tokens_69632000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:51:14 | step: 136100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.661510557634756e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 4.01 | train loss last: 4.69 | consumed tokens: 69683200.0 | grad norm avg: 6.74 | grad norm last: 8.56 | 
2025-12-27T23:51:16 | step: 136200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.66097941272892e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.56 | consumed tokens: 69734400.0 | grad norm avg: 6.58 | grad norm last: 7.27 | 
2025-12-27T23:51:18 | step: 136300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.660448267823085e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.0 | consumed tokens: 69785600.0 | grad norm avg: 6.26 | grad norm last: 8.13 | 
2025-12-27T23:51:20 | step: 136400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.659916395321488e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.95 | consumed tokens: 69836800.0 | grad norm avg: 6.34 | grad norm last: 6.71 | 
2025-12-27T23:51:22 | step: 136500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.65938379522413e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.94 | consumed tokens: 69888000.0 | grad norm avg: 6.39 | grad norm last: 6.86 | 
2025-12-27T23:51:24 | step: 136600 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.658851195126772e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.16 | consumed tokens: 69939200.0 | grad norm avg: 6.51 | grad norm last: 6.92 | 
2025-12-27T23:51:26 | step: 136700 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.658317867433652e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.53 | consumed tokens: 69990400.0 | grad norm avg: 6.64 | grad norm last: 5.65 | 
2025-12-27T23:51:28 | step: 136800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.657783812144771e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.44 | consumed tokens: 70041600.0 | grad norm avg: 6.64 | grad norm last: 5.95 | 
2025-12-27T23:51:30 | step: 136900 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.65724975685589e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.36 | consumed tokens: 70092800.0 | grad norm avg: 6.53 | grad norm last: 5.52 | 
2025-12-27T23:51:32 | step: 137000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.656715701567009e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.34 | consumed tokens: 70144000.0 | grad norm avg: 6.46 | grad norm last: 9.64 | 
2025-12-27T23:51:34 | step: 137100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.656181646278128e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.66 | consumed tokens: 70195200.0 | grad norm avg: 6.64 | grad norm last: 6.41 | 
2025-12-27T23:51:36 | step: 137200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.655646135797724e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.38 | consumed tokens: 70246400.0 | grad norm avg: 6.55 | grad norm last: 7.12 | 
2025-12-27T23:51:38 | step: 137300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.65511062531732e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.06 | consumed tokens: 70297600.0 | grad norm avg: 6.39 | grad norm last: 5.58 | 
2025-12-27T23:51:40 | step: 137400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.654575114836916e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.73 | consumed tokens: 70348800.0 | grad norm avg: 6.49 | grad norm last: 8.36 | 
2025-12-27T23:51:42 | step: 137500 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.654037421569228e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.91 | consumed tokens: 70400000.0 | grad norm avg: 7.43 | grad norm last: 6.46 | 
2025-12-27T23:51:44 | step: 137600 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.653501183493063e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.66 | consumed tokens: 70451200.0 | grad norm avg: 6.54 | grad norm last: 6.13 | 
2025-12-27T23:51:46 | step: 137700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.652963490225375e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.86 | consumed tokens: 70502400.0 | grad norm avg: 6.63 | grad norm last: 8.49 | 
2025-12-27T23:51:48 | step: 137800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.652425796957687e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.12 | train loss last: 3.64 | consumed tokens: 70553600.0 | grad norm avg: 6.84 | grad norm last: 5.87 | 
2025-12-27T23:51:50 | step: 137900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.651887376094237e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.55 | consumed tokens: 70604800.0 | grad norm avg: 6.81 | grad norm last: 6.72 | 
2025-12-27T23:51:52 | step: 138000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.65135041042231e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.31 | consumed tokens: 70656000.0 | grad norm avg: 6.6 | grad norm last: 5.58 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_138000-seen_tokens_70656000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_138000-seen_tokens_70656000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_138000-seen_tokens_70656000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_138000-seen_tokens_70656000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_138000-seen_tokens_70656000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_138000-seen_tokens_70656000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_138000-seen_tokens_70656000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_138000-seen_tokens_70656000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:51:55 | step: 138100 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.650810534367338e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.94 | train loss last: 3.78 | consumed tokens: 70707200.0 | grad norm avg: 6.66 | grad norm last: 5.51 | 
2025-12-27T23:51:57 | step: 138200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.650271385908127e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.52 | consumed tokens: 70758400.0 | grad norm avg: 6.6 | grad norm last: 5.67 | 
2025-12-27T23:51:59 | step: 138300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.649732237448916e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.73 | consumed tokens: 70809600.0 | grad norm avg: 6.39 | grad norm last: 6.31 | 
2025-12-27T23:52:01 | step: 138400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.649192361393943e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.86 | consumed tokens: 70860800.0 | grad norm avg: 6.35 | grad norm last: 5.44 | 
2025-12-27T23:52:03 | step: 138500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.648651030147448e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.19 | consumed tokens: 70912000.0 | grad norm avg: 6.52 | grad norm last: 5.37 | 
2025-12-27T23:52:05 | step: 138600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.648111154092476e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.06 | consumed tokens: 70963200.0 | grad norm avg: 6.47 | grad norm last: 6.39 | 
2025-12-27T23:52:07 | step: 138700 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.64756982284598e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.12 | consumed tokens: 71014400.0 | grad norm avg: 6.54 | grad norm last: 5.83 | 
2025-12-27T23:52:09 | step: 138800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.647028491599485e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.38 | consumed tokens: 71065600.0 | grad norm avg: 6.58 | grad norm last: 6.89 | 
2025-12-27T23:52:11 | step: 138900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.646485705161467e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.41 | consumed tokens: 71116800.0 | grad norm avg: 6.41 | grad norm last: 5.44 | 
2025-12-27T23:52:13 | step: 139000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.64594364631921e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.19 | consumed tokens: 71168000.0 | grad norm avg: 6.7 | grad norm last: 6.56 | 
2025-12-27T23:52:15 | step: 139100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.645401587476954e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.28 | consumed tokens: 71219200.0 | grad norm avg: 6.73 | grad norm last: 8.42 | 
2025-12-27T23:52:17 | step: 139200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.644858073443174e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.42 | consumed tokens: 71270400.0 | grad norm avg: 6.62 | grad norm last: 6.19 | 
2025-12-27T23:52:19 | step: 139300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.644314559409395e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.59 | consumed tokens: 71321600.0 | grad norm avg: 6.68 | grad norm last: 6.09 | 
2025-12-27T23:52:21 | step: 139400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.643770317779854e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.52 | consumed tokens: 71372800.0 | grad norm avg: 6.95 | grad norm last: 5.94 | 
2025-12-27T23:52:23 | step: 139500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.643226076150313e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.0 | consumed tokens: 71424000.0 | grad norm avg: 6.69 | grad norm last: 6.83 | 
2025-12-27T23:52:25 | step: 139600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.642681106925011e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.27 | consumed tokens: 71475200.0 | grad norm avg: 6.53 | grad norm last: 6.8 | 
2025-12-27T23:52:27 | step: 139700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.642136137699708e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.25 | consumed tokens: 71526400.0 | grad norm avg: 6.68 | grad norm last: 6.47 | 
2025-12-27T23:52:29 | step: 139800 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.641590440878645e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.88 | consumed tokens: 71577600.0 | grad norm avg: 6.76 | grad norm last: 7.17 | 
2025-12-27T23:52:31 | step: 139900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.641044744057581e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 4.41 | consumed tokens: 71628800.0 | grad norm avg: 6.58 | grad norm last: 7.14 | 
2025-12-27T23:52:33 | step: 140000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.640498319640756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.05 | consumed tokens: 71680000.0 | grad norm avg: 6.5 | grad norm last: 5.31 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_140000-seen_tokens_71680000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_140000-seen_tokens_71680000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_140000-seen_tokens_71680000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_140000-seen_tokens_71680000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_140000-seen_tokens_71680000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_140000-seen_tokens_71680000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_140000-seen_tokens_71680000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_140000-seen_tokens_71680000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:52:35 | step: 140100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.639951167628169e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.98 | train loss last: 4.34 | consumed tokens: 71731200.0 | grad norm avg: 6.61 | grad norm last: 5.75 | 
2025-12-27T23:52:37 | step: 140200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 9.639404015615582e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.59 | consumed tokens: 71782400.0 | grad norm avg: 6.69 | grad norm last: 5.85 | 
2025-12-27T23:52:39 | step: 140300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.638856863602996e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.3 | consumed tokens: 71833600.0 | grad norm avg: 6.73 | grad norm last: 5.67 | 
2025-12-27T23:52:41 | step: 140400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.638307528803125e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.55 | consumed tokens: 71884800.0 | grad norm avg: 6.86 | grad norm last: 5.85 | 
2025-12-27T23:52:43 | step: 140500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.637760376790538e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.7 | consumed tokens: 71936000.0 | grad norm avg: 7.21 | grad norm last: 5.79 | 
2025-12-27T23:52:45 | step: 140600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.637211769586429e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.89 | consumed tokens: 71987200.0 | grad norm avg: 6.7 | grad norm last: 6.16 | 
2025-12-27T23:52:47 | step: 140700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.636662434786558e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.53 | consumed tokens: 72038400.0 | grad norm avg: 6.86 | grad norm last: 5.39 | 
2025-12-27T23:52:49 | step: 140800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.636113099986687e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.34 | consumed tokens: 72089600.0 | grad norm avg: 6.51 | grad norm last: 6.48 | 
2025-12-27T23:52:51 | step: 140900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.635563037591055e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 3.92 | consumed tokens: 72140800.0 | grad norm avg: 6.73 | grad norm last: 6.74 | 
2025-12-27T23:52:53 | step: 141000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.635012247599661e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.09 | consumed tokens: 72192000.0 | grad norm avg: 6.59 | grad norm last: 6.63 | 
2025-12-27T23:52:55 | step: 141100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.634461457608268e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.61 | consumed tokens: 72243200.0 | grad norm avg: 6.88 | grad norm last: 5.31 | 
2025-12-27T23:52:57 | step: 141200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.633911395212635e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.72 | consumed tokens: 72294400.0 | grad norm avg: 6.6 | grad norm last: 7.52 | 
2025-12-27T23:52:59 | step: 141300 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.633359150029719e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.88 | consumed tokens: 72345600.0 | grad norm avg: 6.57 | grad norm last: 5.96 | 
2025-12-27T23:53:01 | step: 141400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.632806904846802e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.28 | consumed tokens: 72396800.0 | grad norm avg: 6.78 | grad norm last: 7.82 | 
2025-12-27T23:53:04 | step: 141500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.632253932068124e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.28 | consumed tokens: 72448000.0 | grad norm avg: 6.94 | grad norm last: 6.93 | 
2025-12-27T23:53:06 | step: 141600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.631700959289446e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 4.44 | consumed tokens: 72499200.0 | grad norm avg: 6.84 | grad norm last: 7.15 | 
2025-12-27T23:53:08 | step: 141700 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.631147986510769e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.28 | consumed tokens: 72550400.0 | grad norm avg: 6.71 | grad norm last: 6.1 | 
2025-12-27T23:53:10 | step: 141800 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.63059501373209e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.19 | consumed tokens: 72601600.0 | grad norm avg: 6.82 | grad norm last: 6.8 | 
2025-12-27T23:53:12 | step: 141900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.630041313357651e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.89 | consumed tokens: 72652800.0 | grad norm avg: 6.73 | grad norm last: 5.92 | 
2025-12-27T23:53:14 | step: 142000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.629487612983212e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.48 | consumed tokens: 72704000.0 | grad norm avg: 6.62 | grad norm last: 5.4 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_142000-seen_tokens_72704000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_142000-seen_tokens_72704000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_142000-seen_tokens_72704000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_142000-seen_tokens_72704000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_142000-seen_tokens_72704000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_142000-seen_tokens_72704000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_142000-seen_tokens_72704000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_142000-seen_tokens_72704000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:53:16 | step: 142100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.62893245741725e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.05 | consumed tokens: 72755200.0 | grad norm avg: 6.55 | grad norm last: 5.47 | 
2025-12-27T23:53:18 | step: 142200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.628377301851287e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 5.94 | consumed tokens: 72806400.0 | grad norm avg: 6.55 | grad norm last: 6.66 | 
2025-12-27T23:53:20 | step: 142300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.627821418689564e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.31 | consumed tokens: 72857600.0 | grad norm avg: 6.86 | grad norm last: 7.69 | 
2025-12-27T23:53:22 | step: 142400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.62726553552784e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.92 | consumed tokens: 72908800.0 | grad norm avg: 6.59 | grad norm last: 5.96 | 
2025-12-27T23:53:24 | step: 142500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.626709652366117e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.81 | consumed tokens: 72960000.0 | grad norm avg: 6.95 | grad norm last: 6.46 | 
2025-12-27T23:53:26 | step: 142600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.626153041608632e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.06 | consumed tokens: 73011200.0 | grad norm avg: 6.56 | grad norm last: 6.17 | 
2025-12-27T23:53:28 | step: 142700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.625594975659624e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.81 | consumed tokens: 73062400.0 | grad norm avg: 6.69 | grad norm last: 5.82 | 
2025-12-27T23:53:30 | step: 142800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.625038364902139e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.34 | consumed tokens: 73113600.0 | grad norm avg: 6.84 | grad norm last: 7.48 | 
2025-12-27T23:53:32 | step: 142900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.624480298953131e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.78 | consumed tokens: 73164800.0 | grad norm avg: 6.71 | grad norm last: 6.42 | 
2025-12-27T23:53:34 | step: 143000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.623922960599884e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.58 | consumed tokens: 73216000.0 | grad norm avg: 6.58 | grad norm last: 7.27 | 
2025-12-27T23:53:36 | step: 143100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.623364167055115e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.77 | consumed tokens: 73267200.0 | grad norm avg: 6.76 | grad norm last: 6.22 | 
2025-12-27T23:53:38 | step: 143200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.622803918318823e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.83 | consumed tokens: 73318400.0 | grad norm avg: 6.75 | grad norm last: 6.81 | 
2025-12-27T23:53:40 | step: 143300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.622244397178292e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.34 | consumed tokens: 73369600.0 | grad norm avg: 6.53 | grad norm last: 6.39 | 
2025-12-27T23:53:42 | step: 143400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.621684876037762e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 4.06 | consumed tokens: 73420800.0 | grad norm avg: 6.85 | grad norm last: 7.94 | 
2025-12-27T23:53:44 | step: 143500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.62112462730147e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.67 | consumed tokens: 73472000.0 | grad norm avg: 6.81 | grad norm last: 5.73 | 
2025-12-27T23:53:46 | step: 143600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.620564378565177e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.06 | consumed tokens: 73523200.0 | grad norm avg: 6.78 | grad norm last: 7.15 | 
2025-12-27T23:53:48 | step: 143700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.620002674637362e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.98 | consumed tokens: 73574400.0 | grad norm avg: 6.84 | grad norm last: 6.45 | 
2025-12-27T23:53:50 | step: 143800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.619441698305309e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 4.03 | consumed tokens: 73625600.0 | grad norm avg: 7.14 | grad norm last: 6.63 | 
2025-12-27T23:53:52 | step: 143900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.618879266781732e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.47 | consumed tokens: 73676800.0 | grad norm avg: 6.72 | grad norm last: 9.43 | 
2025-12-27T23:53:54 | step: 144000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.618317562853917e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.19 | consumed tokens: 73728000.0 | grad norm avg: 6.7 | grad norm last: 5.75 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_144000-seen_tokens_73728000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_144000-seen_tokens_73728000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_144000-seen_tokens_73728000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_144000-seen_tokens_73728000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_144000-seen_tokens_73728000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_144000-seen_tokens_73728000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_144000-seen_tokens_73728000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_144000-seen_tokens_73728000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:53:56 | step: 144100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.61775440373458e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.92 | train loss last: 3.19 | consumed tokens: 73779200.0 | grad norm avg: 6.62 | grad norm last: 5.42 | 
2025-12-27T23:53:58 | step: 144200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.617191244615242e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.19 | consumed tokens: 73830400.0 | grad norm avg: 6.88 | grad norm last: 7.08 | 
2025-12-27T23:54:00 | step: 144300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.616628085495904e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.75 | consumed tokens: 73881600.0 | grad norm avg: 6.67 | grad norm last: 6.64 | 
2025-12-27T23:54:02 | step: 144400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.616064926376566e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.41 | consumed tokens: 73932800.0 | grad norm avg: 7.27 | grad norm last: 5.25 | 
2025-12-27T23:54:04 | step: 144500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.615500312065706e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.78 | consumed tokens: 73984000.0 | grad norm avg: 6.64 | grad norm last: 7.98 | 
2025-12-27T23:54:06 | step: 144600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.614935697754845e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.67 | consumed tokens: 74035200.0 | grad norm avg: 6.9 | grad norm last: 6.52 | 
2025-12-27T23:54:09 | step: 144700 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.614371083443984e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.38 | consumed tokens: 74086400.0 | grad norm avg: 6.87 | grad norm last: 12.91 | 
2025-12-27T23:54:11 | step: 144800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.613805013941601e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.55 | consumed tokens: 74137600.0 | grad norm avg: 6.45 | grad norm last: 5.95 | 
2025-12-27T23:54:13 | step: 144900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.613238944439217e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.84 | consumed tokens: 74188800.0 | grad norm avg: 6.7 | grad norm last: 6.98 | 
2025-12-27T23:54:15 | step: 145000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.612672874936834e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.8 | consumed tokens: 74240000.0 | grad norm avg: 6.52 | grad norm last: 6.13 | 
2025-12-27T23:54:17 | step: 145100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.61210680543445e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.28 | consumed tokens: 74291200.0 | grad norm avg: 6.63 | grad norm last: 7.35 | 
2025-12-27T23:54:19 | step: 145200 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.611539280740544e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 5.53 | consumed tokens: 74342400.0 | grad norm avg: 6.97 | grad norm last: 7.69 | 
2025-12-27T23:54:21 | step: 145300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.610971756046638e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.86 | consumed tokens: 74393600.0 | grad norm avg: 6.73 | grad norm last: 6.53 | 
2025-12-27T23:54:23 | step: 145400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.610404231352732e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.77 | consumed tokens: 74444800.0 | grad norm avg: 6.82 | grad norm last: 6.12 | 
2025-12-27T23:54:25 | step: 145500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.609836706658825e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.89 | consumed tokens: 74496000.0 | grad norm avg: 6.98 | grad norm last: 7.15 | 
2025-12-27T23:54:27 | step: 145600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 9.609266999177635e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.59 | consumed tokens: 74547200.0 | grad norm avg: 6.69 | grad norm last: 5.69 | 
2025-12-27T23:54:29 | step: 145700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 9.608697291696444e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 5.62 | consumed tokens: 74598400.0 | grad norm avg: 6.8 | grad norm last: 11.93 | 
2025-12-27T23:54:31 | step: 145800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.608129039406776e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.94 | consumed tokens: 74649600.0 | grad norm avg: 6.87 | grad norm last: 9.34 | 
2025-12-27T23:54:33 | step: 145900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.607559331925586e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.84 | consumed tokens: 74700800.0 | grad norm avg: 6.86 | grad norm last: 7.62 | 
2025-12-27T23:54:35 | step: 146000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.606988896848634e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.45 | consumed tokens: 74752000.0 | grad norm avg: 6.89 | grad norm last: 6.23 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_146000-seen_tokens_74752000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_146000-seen_tokens_74752000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_146000-seen_tokens_74752000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_146000-seen_tokens_74752000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_146000-seen_tokens_74752000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_146000-seen_tokens_74752000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_146000-seen_tokens_74752000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_146000-seen_tokens_74752000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:54:37 | step: 146100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.606418461771682e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.9 | train loss last: 4.06 | consumed tokens: 74803200.0 | grad norm avg: 6.67 | grad norm last: 6.31 | 
2025-12-27T23:54:39 | step: 146200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.605847299098969e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.47 | consumed tokens: 74854400.0 | grad norm avg: 6.9 | grad norm last: 7.55 | 
2025-12-27T23:54:41 | step: 146300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.605276136426255e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 4.41 | consumed tokens: 74905600.0 | grad norm avg: 7.06 | grad norm last: 6.58 | 
2025-12-27T23:54:43 | step: 146400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.60470424615778e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.5 | consumed tokens: 74956800.0 | grad norm avg: 6.58 | grad norm last: 7.41 | 
2025-12-27T23:54:45 | step: 146500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.604132355889305e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.06 | consumed tokens: 75008000.0 | grad norm avg: 6.84 | grad norm last: 5.71 | 
2025-12-27T23:54:47 | step: 146600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.603559738025069e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.72 | consumed tokens: 75059200.0 | grad norm avg: 6.56 | grad norm last: 5.84 | 
2025-12-27T23:54:49 | step: 146700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.602987120160833e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 5.59 | consumed tokens: 75110400.0 | grad norm avg: 7.12 | grad norm last: 9.69 | 
2025-12-27T23:54:51 | step: 146800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.602413774700835e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.72 | consumed tokens: 75161600.0 | grad norm avg: 6.82 | grad norm last: 6.62 | 
2025-12-27T23:54:53 | step: 146900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.601839701645076e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.19 | consumed tokens: 75212800.0 | grad norm avg: 6.65 | grad norm last: 6.31 | 
2025-12-27T23:54:55 | step: 147000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.601265628589317e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.88 | consumed tokens: 75264000.0 | grad norm avg: 7.21 | grad norm last: 9.83 | 
2025-12-27T23:54:57 | step: 147100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.600690827937797e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.95 | consumed tokens: 75315200.0 | grad norm avg: 6.81 | grad norm last: 6.83 | 
2025-12-27T23:54:59 | step: 147200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.600116027286276e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.66 | consumed tokens: 75366400.0 | grad norm avg: 6.8 | grad norm last: 7.5 | 
2025-12-27T23:55:01 | step: 147300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.599541226634756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.44 | consumed tokens: 75417600.0 | grad norm avg: 6.85 | grad norm last: 6.21 | 
2025-12-27T23:55:03 | step: 147400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.598964970791712e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.23 | consumed tokens: 75468800.0 | grad norm avg: 6.71 | grad norm last: 5.86 | 
2025-12-27T23:55:05 | step: 147500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.598388714948669e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.7 | consumed tokens: 75520000.0 | grad norm avg: 6.79 | grad norm last: 5.94 | 
2025-12-27T23:55:07 | step: 147600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.597812459105626e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.25 | consumed tokens: 75571200.0 | grad norm avg: 6.93 | grad norm last: 6.76 | 
2025-12-27T23:55:09 | step: 147700 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 9.597235475666821e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.12 | consumed tokens: 75622400.0 | grad norm avg: 6.69 | grad norm last: 7.58 | 
2025-12-27T23:55:11 | step: 147800 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.596658492228016e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.98 | consumed tokens: 75673600.0 | grad norm avg: 7.01 | grad norm last: 6.35 | 
2025-12-27T23:55:13 | step: 147900 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.59608078119345e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.66 | consumed tokens: 75724800.0 | grad norm avg: 6.64 | grad norm last: 8.36 | 
2025-12-27T23:55:15 | step: 148000 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.595503070158884e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.95 | consumed tokens: 75776000.0 | grad norm avg: 6.67 | grad norm last: 6.9 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_148000-seen_tokens_75776000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_148000-seen_tokens_75776000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_148000-seen_tokens_75776000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_148000-seen_tokens_75776000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_148000-seen_tokens_75776000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_148000-seen_tokens_75776000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_148000-seen_tokens_75776000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_148000-seen_tokens_75776000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:55:18 | step: 148100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.594924631528556e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.48 | consumed tokens: 75827200.0 | grad norm avg: 6.74 | grad norm last: 6.68 | 
2025-12-27T23:55:20 | step: 148200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.594345465302467e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.34 | consumed tokens: 75878400.0 | grad norm avg: 7.08 | grad norm last: 5.94 | 
2025-12-27T23:55:22 | step: 148300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.593766299076378e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.88 | consumed tokens: 75929600.0 | grad norm avg: 6.72 | grad norm last: 6.97 | 
2025-12-27T23:55:24 | step: 148400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.593186405254528e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.92 | consumed tokens: 75980800.0 | grad norm avg: 6.75 | grad norm last: 7.27 | 
2025-12-27T23:55:26 | step: 148500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.592607239028439e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.48 | consumed tokens: 76032000.0 | grad norm avg: 6.77 | grad norm last: 6.03 | 
2025-12-27T23:55:28 | step: 148600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.592025890015066e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.53 | consumed tokens: 76083200.0 | grad norm avg: 6.88 | grad norm last: 5.98 | 
2025-12-27T23:55:30 | step: 148700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.591444541001692e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.72 | consumed tokens: 76134400.0 | grad norm avg: 7.07 | grad norm last: 5.86 | 
2025-12-27T23:55:32 | step: 148800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.59086391958408e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.39 | consumed tokens: 76185600.0 | grad norm avg: 6.74 | grad norm last: 6.45 | 
2025-12-27T23:55:34 | step: 148900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.590282570570707e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.69 | consumed tokens: 76236800.0 | grad norm avg: 6.78 | grad norm last: 5.67 | 
2025-12-27T23:55:36 | step: 149000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.589700493961573e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.03 | consumed tokens: 76288000.0 | grad norm avg: 6.71 | grad norm last: 6.94 | 
2025-12-27T23:55:38 | step: 149100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.589118417352438e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 4.59 | consumed tokens: 76339200.0 | grad norm avg: 7.22 | grad norm last: 8.27 | 
2025-12-27T23:55:40 | step: 149200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.588535613147542e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.7 | consumed tokens: 76390400.0 | grad norm avg: 6.71 | grad norm last: 5.99 | 
2025-12-27T23:55:42 | step: 149300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.587952081346884e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.12 | consumed tokens: 76441600.0 | grad norm avg: 6.61 | grad norm last: 7.25 | 
2025-12-27T23:55:44 | step: 149400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.587368549546227e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.47 | consumed tokens: 76492800.0 | grad norm avg: 6.9 | grad norm last: 5.72 | 
2025-12-27T23:55:46 | step: 149500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.58678501774557e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.41 | consumed tokens: 76544000.0 | grad norm avg: 6.88 | grad norm last: 8.63 | 
2025-12-27T23:55:48 | step: 149600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.586200030753389e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.56 | consumed tokens: 76595200.0 | grad norm avg: 6.94 | grad norm last: 7.69 | 
2025-12-27T23:55:50 | step: 149700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.585616498952731e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 3.88 | consumed tokens: 76646400.0 | grad norm avg: 7.09 | grad norm last: 6.45 | 
2025-12-27T23:55:52 | step: 149800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.585030056769028e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.38 | consumed tokens: 76697600.0 | grad norm avg: 7.02 | grad norm last: 6.07 | 
2025-12-27T23:55:54 | step: 149900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.584445069776848e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.81 | consumed tokens: 76748800.0 | grad norm avg: 6.91 | grad norm last: 7.61 | 
2025-12-27T23:55:56 | step: 150000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.583859355188906e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.36 | consumed tokens: 76800000.0 | grad norm avg: 6.56 | grad norm last: 5.98 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_150000-seen_tokens_76800000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_150000-seen_tokens_76800000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_150000-seen_tokens_76800000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_150000-seen_tokens_76800000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_150000-seen_tokens_76800000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_150000-seen_tokens_76800000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_150000-seen_tokens_76800000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_150000-seen_tokens_76800000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:55:58 | step: 150100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.583272185409442e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.9 | train loss last: 4.12 | consumed tokens: 76851200.0 | grad norm avg: 6.69 | grad norm last: 6.34 | 
2025-12-27T23:56:00 | step: 150200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.582685743225738e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 5.5 | consumed tokens: 76902400.0 | grad norm avg: 6.92 | grad norm last: 17.52 | 
2025-12-27T23:56:02 | step: 150300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.582098573446274e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.53 | consumed tokens: 76953600.0 | grad norm avg: 6.97 | grad norm last: 6.36 | 
2025-12-27T23:56:04 | step: 150400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.581511403666809e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.08 | consumed tokens: 77004800.0 | grad norm avg: 6.8 | grad norm last: 5.53 | 
2025-12-27T23:56:06 | step: 150500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.580923506291583e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.41 | consumed tokens: 77056000.0 | grad norm avg: 6.78 | grad norm last: 8.46 | 
2025-12-27T23:56:08 | step: 150600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.580334881320596e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.83 | consumed tokens: 77107200.0 | grad norm avg: 7.01 | grad norm last: 6.33 | 
2025-12-27T23:56:10 | step: 150700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.579746256349608e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.06 | consumed tokens: 77158400.0 | grad norm avg: 6.86 | grad norm last: 6.7 | 
2025-12-27T23:56:12 | step: 150800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.57915690378286e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.61 | consumed tokens: 77209600.0 | grad norm avg: 6.73 | grad norm last: 6.43 | 
2025-12-27T23:56:14 | step: 150900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.578568278811872e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.8 | consumed tokens: 77260800.0 | grad norm avg: 6.76 | grad norm last: 6.92 | 
2025-12-27T23:56:16 | step: 151000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.577978198649362e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.5 | consumed tokens: 77312000.0 | grad norm avg: 6.65 | grad norm last: 7.03 | 
2025-12-27T23:56:18 | step: 151100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 9.57738739089109e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.28 | consumed tokens: 77363200.0 | grad norm avg: 6.93 | grad norm last: 6.65 | 
2025-12-27T23:56:20 | step: 151200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 9.576798038324341e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.28 | consumed tokens: 77414400.0 | grad norm avg: 6.98 | grad norm last: 7.0 | 
2025-12-27T23:56:22 | step: 151300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.576205775374547e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.81 | consumed tokens: 77465600.0 | grad norm avg: 6.64 | grad norm last: 7.19 | 
2025-12-27T23:56:24 | step: 151400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.575614967616275e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.62 | consumed tokens: 77516800.0 | grad norm avg: 6.66 | grad norm last: 6.84 | 
2025-12-27T23:56:26 | step: 151500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.57502270466648e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.41 | consumed tokens: 77568000.0 | grad norm avg: 6.74 | grad norm last: 6.95 | 
2025-12-27T23:56:28 | step: 151600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.574430441716686e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 5.38 | consumed tokens: 77619200.0 | grad norm avg: 6.7 | grad norm last: 9.21 | 
2025-12-27T23:56:30 | step: 151700 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.573838178766891e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.66 | consumed tokens: 77670400.0 | grad norm avg: 6.67 | grad norm last: 6.91 | 
2025-12-27T23:56:32 | step: 151800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.573245188221335e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.52 | consumed tokens: 77721600.0 | grad norm avg: 6.82 | grad norm last: 7.12 | 
2025-12-27T23:56:35 | step: 151900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 9.57265219767578e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 5.34 | consumed tokens: 77772800.0 | grad norm avg: 6.74 | grad norm last: 11.2 | 
2025-12-27T23:56:37 | step: 152000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.572058479534462e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.06 | consumed tokens: 77824000.0 | grad norm avg: 6.86 | grad norm last: 6.13 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_152000-seen_tokens_77824000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_152000-seen_tokens_77824000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_152000-seen_tokens_77824000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_152000-seen_tokens_77824000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_152000-seen_tokens_77824000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_152000-seen_tokens_77824000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_152000-seen_tokens_77824000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_152000-seen_tokens_77824000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:56:39 | step: 152100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.571464033797383e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.92 | consumed tokens: 77875200.0 | grad norm avg: 6.66 | grad norm last: 6.91 | 
2025-12-27T23:56:41 | step: 152200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.570869588060305e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.48 | consumed tokens: 77926400.0 | grad norm avg: 6.99 | grad norm last: 6.52 | 
2025-12-27T23:56:43 | step: 152300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.570274414727464e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.69 | consumed tokens: 77977600.0 | grad norm avg: 6.76 | grad norm last: 7.38 | 
2025-12-27T23:56:45 | step: 152400 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.569679241394624e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.39 | consumed tokens: 78028800.0 | grad norm avg: 6.77 | grad norm last: 5.89 | 
2025-12-27T23:56:47 | step: 152500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.569083340466022e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.89 | consumed tokens: 78080000.0 | grad norm avg: 6.85 | grad norm last: 6.38 | 
2025-12-27T23:56:49 | step: 152600 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.568487439537421e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.58 | consumed tokens: 78131200.0 | grad norm avg: 6.96 | grad norm last: 7.08 | 
2025-12-27T23:56:51 | step: 152700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.567890811013058e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.09 | consumed tokens: 78182400.0 | grad norm avg: 6.77 | grad norm last: 6.57 | 
2025-12-27T23:56:53 | step: 152800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.567294182488695e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.97 | consumed tokens: 78233600.0 | grad norm avg: 6.68 | grad norm last: 7.13 | 
2025-12-27T23:56:55 | step: 152900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.56669682636857e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.19 | consumed tokens: 78284800.0 | grad norm avg: 6.91 | grad norm last: 7.47 | 
2025-12-27T23:56:57 | step: 153000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.566099470248446e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.47 | consumed tokens: 78336000.0 | grad norm avg: 6.63 | grad norm last: 6.66 | 
2025-12-27T23:56:59 | step: 153100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.565500658936799e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.64 | consumed tokens: 78387200.0 | grad norm avg: 6.87 | grad norm last: 6.26 | 
2025-12-27T23:57:01 | step: 153200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.564901847625151e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.0 | consumed tokens: 78438400.0 | grad norm avg: 6.68 | grad norm last: 7.38 | 
2025-12-27T23:57:03 | step: 153300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.564303763909265e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.06 | consumed tokens: 78489600.0 | grad norm avg: 6.63 | grad norm last: 5.92 | 
2025-12-27T23:57:05 | step: 153400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.563704225001857e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.31 | consumed tokens: 78540800.0 | grad norm avg: 6.33 | grad norm last: 8.09 | 
2025-12-27T23:57:07 | step: 153500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.563104686094448e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.22 | consumed tokens: 78592000.0 | grad norm avg: 6.77 | grad norm last: 7.43 | 
2025-12-27T23:57:09 | step: 153600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.562503691995516e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.7 | consumed tokens: 78643200.0 | grad norm avg: 6.78 | grad norm last: 6.27 | 
2025-12-27T23:57:11 | step: 153700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.561904153088108e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.3 | consumed tokens: 78694400.0 | grad norm avg: 6.89 | grad norm last: 7.19 | 
2025-12-27T23:57:13 | step: 153800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.561303158989176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.16 | consumed tokens: 78745600.0 | grad norm avg: 6.65 | grad norm last: 9.61 | 
2025-12-27T23:57:15 | step: 153900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 9.560702164890245e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.09 | consumed tokens: 78796800.0 | grad norm avg: 6.9 | grad norm last: 7.8 | 
2025-12-27T23:57:17 | step: 154000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.56009971559979e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.94 | consumed tokens: 78848000.0 | grad norm avg: 6.67 | grad norm last: 6.68 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_154000-seen_tokens_78848000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_154000-seen_tokens_78848000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_154000-seen_tokens_78848000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_154000-seen_tokens_78848000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_154000-seen_tokens_78848000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_154000-seen_tokens_78848000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_154000-seen_tokens_78848000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_154000-seen_tokens_78848000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:57:19 | step: 154100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.559498721500859e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.91 | train loss last: 3.03 | consumed tokens: 78899200.0 | grad norm avg: 6.87 | grad norm last: 7.38 | 
2025-12-27T23:57:21 | step: 154200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.558896272210404e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.12 | consumed tokens: 78950400.0 | grad norm avg: 7.18 | grad norm last: 6.88 | 
2025-12-27T23:57:23 | step: 154300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.55829382291995e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.06 | consumed tokens: 79001600.0 | grad norm avg: 6.91 | grad norm last: 6.93 | 
2025-12-27T23:57:25 | step: 154400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.557689918437973e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.0 | consumed tokens: 79052800.0 | grad norm avg: 6.83 | grad norm last: 7.81 | 
2025-12-27T23:57:27 | step: 154500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.557086741551757e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.31 | consumed tokens: 79104000.0 | grad norm avg: 7.17 | grad norm last: 8.79 | 
2025-12-27T23:57:30 | step: 154600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.556483564665541e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.5 | consumed tokens: 79155200.0 | grad norm avg: 6.58 | grad norm last: 6.6 | 
2025-12-27T23:57:32 | step: 154700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.555878204992041e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.0 | consumed tokens: 79206400.0 | grad norm avg: 6.8 | grad norm last: 6.86 | 
2025-12-27T23:57:34 | step: 154800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.555273572914302e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.53 | consumed tokens: 79257600.0 | grad norm avg: 6.61 | grad norm last: 5.46 | 
2025-12-27T23:57:36 | step: 154900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.554668940836564e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.16 | consumed tokens: 79308800.0 | grad norm avg: 7.08 | grad norm last: 7.15 | 
2025-12-27T23:57:38 | step: 155000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.554063581163064e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.2 | consumed tokens: 79360000.0 | grad norm avg: 7.08 | grad norm last: 6.65 | 
2025-12-27T23:57:40 | step: 155100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.553457493893802e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.83 | consumed tokens: 79411200.0 | grad norm avg: 6.88 | grad norm last: 5.89 | 
2025-12-27T23:57:42 | step: 155200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.552851406624541e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.83 | consumed tokens: 79462400.0 | grad norm avg: 6.78 | grad norm last: 6.97 | 
2025-12-27T23:57:44 | step: 155300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.552244591759518e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.81 | consumed tokens: 79513600.0 | grad norm avg: 6.86 | grad norm last: 7.77 | 
2025-12-27T23:57:46 | step: 155400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.551636321702972e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.39 | consumed tokens: 79564800.0 | grad norm avg: 6.62 | grad norm last: 6.67 | 
2025-12-27T23:57:48 | step: 155500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.55103023443371e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.31 | consumed tokens: 79616000.0 | grad norm avg: 7.14 | grad norm last: 7.31 | 
2025-12-27T23:57:50 | step: 155600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.550421964377165e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.41 | consumed tokens: 79667200.0 | grad norm avg: 7.42 | grad norm last: 8.39 | 
2025-12-27T23:57:52 | step: 155700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.549813694320619e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.84 | consumed tokens: 79718400.0 | grad norm avg: 6.88 | grad norm last: 5.78 | 
2025-12-27T23:57:54 | step: 155800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.549205424264073e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.25 | consumed tokens: 79769600.0 | grad norm avg: 6.87 | grad norm last: 8.9 | 
2025-12-27T23:57:56 | step: 155900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.548596426611766e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.2 | consumed tokens: 79820800.0 | grad norm avg: 7.09 | grad norm last: 6.43 | 
2025-12-27T23:57:58 | step: 156000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.547986701363698e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 5.28 | consumed tokens: 79872000.0 | grad norm avg: 6.78 | grad norm last: 7.28 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_156000-seen_tokens_79872000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_156000-seen_tokens_79872000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_156000-seen_tokens_79872000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_156000-seen_tokens_79872000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_156000-seen_tokens_79872000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_156000-seen_tokens_79872000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_156000-seen_tokens_79872000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_156000-seen_tokens_79872000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:58:00 | step: 156100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 9.547376976115629e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.96 | train loss last: 3.78 | consumed tokens: 79923200.0 | grad norm avg: 6.9 | grad norm last: 6.97 | 
2025-12-27T23:58:02 | step: 156200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 9.54676725086756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.34 | consumed tokens: 79974400.0 | grad norm avg: 7.12 | grad norm last: 5.68 | 
2025-12-27T23:58:04 | step: 156300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.546156070427969e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.56 | consumed tokens: 80025600.0 | grad norm avg: 7.49 | grad norm last: 7.37 | 
2025-12-27T23:58:06 | step: 156400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.5455463451799e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.19 | consumed tokens: 80076800.0 | grad norm avg: 6.95 | grad norm last: 7.86 | 
2025-12-27T23:58:08 | step: 156500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.544935164740309e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 5.41 | consumed tokens: 80128000.0 | grad norm avg: 6.9 | grad norm last: 11.18 | 
2025-12-27T23:58:10 | step: 156600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.544322529109195e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.89 | consumed tokens: 80179200.0 | grad norm avg: 7.1 | grad norm last: 6.64 | 
2025-12-27T23:58:12 | step: 156700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.543710621073842e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.36 | consumed tokens: 80230400.0 | grad norm avg: 6.69 | grad norm last: 5.37 | 
2025-12-27T23:58:14 | step: 156800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.543097257846966e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.28 | consumed tokens: 80281600.0 | grad norm avg: 6.8 | grad norm last: 7.58 | 
2025-12-27T23:58:16 | step: 156900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.542484622215852e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.72 | consumed tokens: 80332800.0 | grad norm avg: 6.9 | grad norm last: 6.01 | 
2025-12-27T23:58:18 | step: 157000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.541871258988976e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 4.06 | consumed tokens: 80384000.0 | grad norm avg: 7.27 | grad norm last: 6.67 | 
2025-12-27T23:58:20 | step: 157100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.541257895762101e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 5.66 | consumed tokens: 80435200.0 | grad norm avg: 6.84 | grad norm last: 17.3 | 
2025-12-27T23:58:22 | step: 157200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.540643804939464e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.94 | consumed tokens: 80486400.0 | grad norm avg: 6.71 | grad norm last: 6.75 | 
2025-12-27T23:58:24 | step: 157300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.540029714116827e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.83 | consumed tokens: 80537600.0 | grad norm avg: 7.0 | grad norm last: 6.03 | 
2025-12-27T23:58:26 | step: 157400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.539414895698428e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.0 | consumed tokens: 80588800.0 | grad norm avg: 6.56 | grad norm last: 7.94 | 
2025-12-27T23:58:28 | step: 157500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.53880007728003e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.56 | consumed tokens: 80640000.0 | grad norm avg: 6.94 | grad norm last: 6.35 | 
2025-12-27T23:58:30 | step: 157600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.538183803670108e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.41 | consumed tokens: 80691200.0 | grad norm avg: 7.23 | grad norm last: 8.47 | 
2025-12-27T23:58:32 | step: 157700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.537567530060187e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.94 | consumed tokens: 80742400.0 | grad norm avg: 6.97 | grad norm last: 7.17 | 
2025-12-27T23:58:34 | step: 157800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.536950528854504e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.19 | consumed tokens: 80793600.0 | grad norm avg: 6.65 | grad norm last: 6.37 | 
2025-12-27T23:58:36 | step: 157900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.536333527648821e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.12 | consumed tokens: 80844800.0 | grad norm avg: 6.73 | grad norm last: 5.56 | 
2025-12-27T23:58:38 | step: 158000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.535716526443139e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.41 | consumed tokens: 80896000.0 | grad norm avg: 7.4 | grad norm last: 5.86 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_158000-seen_tokens_80896000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_158000-seen_tokens_80896000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_158000-seen_tokens_80896000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_158000-seen_tokens_80896000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_158000-seen_tokens_80896000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_158000-seen_tokens_80896000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_158000-seen_tokens_80896000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_158000-seen_tokens_80896000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:58:41 | step: 158100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.535099525237456e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.96 | train loss last: 3.38 | consumed tokens: 80947200.0 | grad norm avg: 6.89 | grad norm last: 5.93 | 
2025-12-27T23:58:43 | step: 158200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.534481796436012e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.81 | consumed tokens: 80998400.0 | grad norm avg: 6.98 | grad norm last: 9.18 | 
2025-12-27T23:58:45 | step: 158300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.533864067634568e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 4.19 | consumed tokens: 81049600.0 | grad norm avg: 6.89 | grad norm last: 6.87 | 
2025-12-27T23:58:47 | step: 158400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.5332448836416e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.91 | consumed tokens: 81100800.0 | grad norm avg: 6.81 | grad norm last: 7.1 | 
2025-12-27T23:58:49 | step: 158500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.532625699648634e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.22 | consumed tokens: 81152000.0 | grad norm avg: 6.63 | grad norm last: 6.42 | 
2025-12-27T23:58:51 | step: 158600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.532007243251428e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.98 | consumed tokens: 81203200.0 | grad norm avg: 6.61 | grad norm last: 6.58 | 
2025-12-27T23:58:53 | step: 158700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.531385876471177e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.91 | consumed tokens: 81254400.0 | grad norm avg: 6.69 | grad norm last: 6.52 | 
2025-12-27T23:58:55 | step: 158800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.530765964882448e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.95 | consumed tokens: 81305600.0 | grad norm avg: 6.66 | grad norm last: 7.64 | 
2025-12-27T23:58:57 | step: 158900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.530145325697958e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.19 | consumed tokens: 81356800.0 | grad norm avg: 7.09 | grad norm last: 6.27 | 
2025-12-27T23:58:59 | step: 159000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.529524686513469e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.88 | consumed tokens: 81408000.0 | grad norm avg: 6.73 | grad norm last: 9.07 | 
2025-12-27T23:59:01 | step: 159100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 9.528903319733217e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.81 | consumed tokens: 81459200.0 | grad norm avg: 7.19 | grad norm last: 6.58 | 
2025-12-27T23:59:03 | step: 159200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.528281952952966e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 5.38 | consumed tokens: 81510400.0 | grad norm avg: 6.95 | grad norm last: 6.34 | 
2025-12-27T23:59:05 | step: 159300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.527659130981192e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.48 | consumed tokens: 81561600.0 | grad norm avg: 6.76 | grad norm last: 6.13 | 
2025-12-27T23:59:07 | step: 159400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.527036309009418e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.59 | consumed tokens: 81612800.0 | grad norm avg: 6.81 | grad norm last: 7.4 | 
2025-12-27T23:59:09 | step: 159500 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.526413487037644e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.09 | consumed tokens: 81664000.0 | grad norm avg: 6.83 | grad norm last: 6.83 | 
2025-12-27T23:59:11 | step: 159600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.52579066506587e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.8 | consumed tokens: 81715200.0 | grad norm avg: 6.8 | grad norm last: 6.64 | 
2025-12-27T23:59:13 | step: 159700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.525166387902573e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.5 | consumed tokens: 81766400.0 | grad norm avg: 6.87 | grad norm last: 7.65 | 
2025-12-27T23:59:15 | step: 159800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.524542110739276e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.25 | consumed tokens: 81817600.0 | grad norm avg: 6.82 | grad norm last: 6.66 | 
2025-12-27T23:59:17 | step: 159900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.523917833575979e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.55 | consumed tokens: 81868800.0 | grad norm avg: 7.24 | grad norm last: 6.6 | 
2025-12-27T23:59:19 | step: 160000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.523293556412682e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.56 | consumed tokens: 81920000.0 | grad norm avg: 6.92 | grad norm last: 8.6 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_160000-seen_tokens_81920000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_160000-seen_tokens_81920000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_160000-seen_tokens_81920000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_160000-seen_tokens_81920000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_160000-seen_tokens_81920000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_160000-seen_tokens_81920000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_160000-seen_tokens_81920000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_160000-seen_tokens_81920000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-27T23:59:21 | step: 160100 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.52266636886634e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.98 | train loss last: 3.41 | consumed tokens: 81971200.0 | grad norm avg: 6.91 | grad norm last: 6.83 | 
2025-12-27T23:59:23 | step: 160200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.522042091703042e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.62 | consumed tokens: 82022400.0 | grad norm avg: 6.9 | grad norm last: 6.58 | 
2025-12-27T23:59:25 | step: 160300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.5214149041567e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 2.89 | consumed tokens: 82073600.0 | grad norm avg: 6.95 | grad norm last: 5.79 | 
2025-12-27T23:59:27 | step: 160400 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.52078917180188e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.86 | consumed tokens: 82124800.0 | grad norm avg: 6.7 | grad norm last: 6.54 | 
2025-12-27T23:59:29 | step: 160500 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.520162711851299e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.62 | consumed tokens: 82176000.0 | grad norm avg: 6.95 | grad norm last: 6.17 | 
2025-12-27T23:59:31 | step: 160600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.519534796709195e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.22 | consumed tokens: 82227200.0 | grad norm avg: 6.81 | grad norm last: 6.13 | 
2025-12-27T23:59:33 | step: 160700 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.518907609162852e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.08 | train loss last: 3.53 | consumed tokens: 82278400.0 | grad norm avg: 7.06 | grad norm last: 7.08 | 
2025-12-27T23:59:35 | step: 160800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.518279694020748e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.0 | consumed tokens: 82329600.0 | grad norm avg: 7.05 | grad norm last: 10.14 | 
2025-12-27T23:59:37 | step: 160900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.517651051282883e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.34 | consumed tokens: 82380800.0 | grad norm avg: 6.89 | grad norm last: 5.59 | 
2025-12-27T23:59:39 | step: 161000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.517022408545017e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.61 | consumed tokens: 82432000.0 | grad norm avg: 6.95 | grad norm last: 5.95 | 
2025-12-27T23:59:41 | step: 161100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 9.51639303821139e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 5.19 | consumed tokens: 82483200.0 | grad norm avg: 6.67 | grad norm last: 11.65 | 
2025-12-27T23:59:43 | step: 161200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.515762940282002e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.81 | consumed tokens: 82534400.0 | grad norm avg: 7.18 | grad norm last: 7.05 | 
2025-12-27T23:59:45 | step: 161300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.515133569948375e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.52 | consumed tokens: 82585600.0 | grad norm avg: 6.79 | grad norm last: 6.01 | 
2025-12-27T23:59:47 | step: 161400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.514504199614748e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.22 | consumed tokens: 82636800.0 | grad norm avg: 6.93 | grad norm last: 9.42 | 
2025-12-27T23:59:49 | step: 161500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.513872646493837e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.25 | consumed tokens: 82688000.0 | grad norm avg: 6.88 | grad norm last: 6.27 | 
2025-12-27T23:59:51 | step: 161600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.513241820968688e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.61 | consumed tokens: 82739200.0 | grad norm avg: 7.18 | grad norm last: 6.35 | 
2025-12-27T23:59:53 | step: 161700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.512610267847776e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.03 | consumed tokens: 82790400.0 | grad norm avg: 6.75 | grad norm last: 6.5 | 
2025-12-27T23:59:55 | step: 161800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.511977987131104e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.42 | consumed tokens: 82841600.0 | grad norm avg: 6.83 | grad norm last: 7.02 | 
2025-12-27T23:59:57 | step: 161900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.51134497881867e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.53 | consumed tokens: 82892800.0 | grad norm avg: 6.79 | grad norm last: 7.22 | 
2025-12-27T23:59:59 | step: 162000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.510713425697759e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.44 | consumed tokens: 82944000.0 | grad norm avg: 7.0 | grad norm last: 11.23 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_162000-seen_tokens_82944000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_162000-seen_tokens_82944000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_162000-seen_tokens_82944000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_162000-seen_tokens_82944000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_162000-seen_tokens_82944000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_162000-seen_tokens_82944000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_162000-seen_tokens_82944000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_162000-seen_tokens_82944000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:00:02 | step: 162100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.510080417385325e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.31 | consumed tokens: 82995200.0 | grad norm avg: 7.1 | grad norm last: 8.24 | 
2025-12-28T00:00:04 | step: 162200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.50944668147713e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.94 | consumed tokens: 83046400.0 | grad norm avg: 6.85 | grad norm last: 6.39 | 
2025-12-28T00:00:06 | step: 162300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.508812945568934e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.34 | consumed tokens: 83097600.0 | grad norm avg: 6.73 | grad norm last: 6.66 | 
2025-12-28T00:00:08 | step: 162400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.508178482064977e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.7 | consumed tokens: 83148800.0 | grad norm avg: 7.04 | grad norm last: 6.41 | 
2025-12-28T00:00:10 | step: 162500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.50754401856102e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.12 | train loss last: 4.69 | consumed tokens: 83200000.0 | grad norm avg: 7.99 | grad norm last: 11.36 | 
2025-12-28T00:00:12 | step: 162600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.506909555057064e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.8 | consumed tokens: 83251200.0 | grad norm avg: 7.09 | grad norm last: 6.71 | 
2025-12-28T00:00:14 | step: 162700 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.506274363957345e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.07 | train loss last: 4.0 | consumed tokens: 83302400.0 | grad norm avg: 7.19 | grad norm last: 6.96 | 
2025-12-28T00:00:16 | step: 162800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.505639172857627e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.34 | consumed tokens: 83353600.0 | grad norm avg: 6.93 | grad norm last: 7.36 | 
2025-12-28T00:00:18 | step: 162900 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.505002526566386e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.84 | consumed tokens: 83404800.0 | grad norm avg: 7.02 | grad norm last: 7.01 | 
2025-12-28T00:00:20 | step: 163000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.504365880275145e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.19 | consumed tokens: 83456000.0 | grad norm avg: 7.02 | grad norm last: 7.93 | 
2025-12-28T00:00:22 | step: 163100 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.503728506388143e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.81 | consumed tokens: 83507200.0 | grad norm avg: 7.05 | grad norm last: 10.24 | 
2025-12-28T00:00:24 | step: 163200 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.50309113250114e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.84 | consumed tokens: 83558400.0 | grad norm avg: 6.87 | grad norm last: 6.34 | 
2025-12-28T00:00:26 | step: 163300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.502453758614138e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.44 | consumed tokens: 83609600.0 | grad norm avg: 6.81 | grad norm last: 7.62 | 
2025-12-28T00:00:28 | step: 163400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.501815657131374e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.44 | consumed tokens: 83660800.0 | grad norm avg: 6.79 | grad norm last: 6.25 | 
2025-12-28T00:00:30 | step: 163500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.50117755564861e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.98 | consumed tokens: 83712000.0 | grad norm avg: 6.88 | grad norm last: 7.21 | 
2025-12-28T00:00:32 | step: 163600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.500538726570085e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.78 | consumed tokens: 83763200.0 | grad norm avg: 7.33 | grad norm last: 16.25 | 
2025-12-28T00:00:34 | step: 163700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.49989989749156e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.78 | consumed tokens: 83814400.0 | grad norm avg: 7.18 | grad norm last: 6.71 | 
2025-12-28T00:00:36 | step: 163800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.499259613221511e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.77 | consumed tokens: 83865600.0 | grad norm avg: 6.79 | grad norm last: 6.41 | 
2025-12-28T00:00:38 | step: 163900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.498620056547225e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 2.7 | consumed tokens: 83916800.0 | grad norm avg: 6.83 | grad norm last: 5.42 | 
2025-12-28T00:00:40 | step: 164000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.497979772277176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.38 | consumed tokens: 83968000.0 | grad norm avg: 6.88 | grad norm last: 6.28 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_164000-seen_tokens_83968000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_164000-seen_tokens_83968000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_164000-seen_tokens_83968000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_164000-seen_tokens_83968000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_164000-seen_tokens_83968000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_164000-seen_tokens_83968000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_164000-seen_tokens_83968000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_164000-seen_tokens_83968000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:00:42 | step: 164100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.497338760411367e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.91 | train loss last: 3.61 | consumed tokens: 84019200.0 | grad norm avg: 6.78 | grad norm last: 6.95 | 
2025-12-28T00:00:44 | step: 164200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.496698476141319e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.27 | consumed tokens: 84070400.0 | grad norm avg: 6.69 | grad norm last: 6.6 | 
2025-12-28T00:00:46 | step: 164300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.496056009083986e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.44 | consumed tokens: 84121600.0 | grad norm avg: 7.02 | grad norm last: 6.37 | 
2025-12-28T00:00:48 | step: 164400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.495413542026654e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.73 | consumed tokens: 84172800.0 | grad norm avg: 6.73 | grad norm last: 7.26 | 
2025-12-28T00:00:50 | step: 164500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.494771802565083e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.03 | consumed tokens: 84224000.0 | grad norm avg: 6.74 | grad norm last: 6.33 | 
2025-12-28T00:00:52 | step: 164600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.49412933550775e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.23 | consumed tokens: 84275200.0 | grad norm avg: 6.83 | grad norm last: 5.17 | 
2025-12-28T00:00:54 | step: 164700 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.493486140854657e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.75 | consumed tokens: 84326400.0 | grad norm avg: 7.08 | grad norm last: 9.35 | 
2025-12-28T00:00:56 | step: 164800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.492842946201563e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.19 | consumed tokens: 84377600.0 | grad norm avg: 6.65 | grad norm last: 6.96 | 
2025-12-28T00:00:58 | step: 164900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.492199023952708e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 5.12 | consumed tokens: 84428800.0 | grad norm avg: 6.92 | grad norm last: 8.85 | 
2025-12-28T00:01:00 | step: 165000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.491554374108091e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.75 | consumed tokens: 84480000.0 | grad norm avg: 6.76 | grad norm last: 6.31 | 
2025-12-28T00:01:02 | step: 165100 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.490910451859236e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.22 | consumed tokens: 84531200.0 | grad norm avg: 6.72 | grad norm last: 7.3 | 
2025-12-28T00:01:04 | step: 165200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.49026652961038e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.95 | consumed tokens: 84582400.0 | grad norm avg: 6.71 | grad norm last: 6.34 | 
2025-12-28T00:01:06 | step: 165300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.489620424574241e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 3.75 | consumed tokens: 84633600.0 | grad norm avg: 7.36 | grad norm last: 6.93 | 
2025-12-28T00:01:08 | step: 165400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.488974319538102e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.78 | consumed tokens: 84684800.0 | grad norm avg: 6.75 | grad norm last: 5.92 | 
2025-12-28T00:01:10 | step: 165500 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.488328214501962e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.09 | consumed tokens: 84736000.0 | grad norm avg: 6.74 | grad norm last: 7.72 | 
2025-12-28T00:01:12 | step: 165600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.487682109465823e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.12 | consumed tokens: 84787200.0 | grad norm avg: 6.98 | grad norm last: 5.96 | 
2025-12-28T00:01:14 | step: 165700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.487036004429683e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.27 | consumed tokens: 84838400.0 | grad norm avg: 6.79 | grad norm last: 7.83 | 
2025-12-28T00:01:16 | step: 165800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 9.48638771660626e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.06 | consumed tokens: 84889600.0 | grad norm avg: 6.86 | grad norm last: 5.89 | 
2025-12-28T00:01:19 | step: 165900 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 9.485739428782836e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.22 | consumed tokens: 84940800.0 | grad norm avg: 6.83 | grad norm last: 6.59 | 
2025-12-28T00:01:21 | step: 166000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.485091868555173e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.44 | consumed tokens: 84992000.0 | grad norm avg: 6.76 | grad norm last: 7.2 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_166000-seen_tokens_84992000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_166000-seen_tokens_84992000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_166000-seen_tokens_84992000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_166000-seen_tokens_84992000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_166000-seen_tokens_84992000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_166000-seen_tokens_84992000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_166000-seen_tokens_84992000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_166000-seen_tokens_84992000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:01:23 | step: 166100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.48444358073175e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.83 | train loss last: 4.16 | consumed tokens: 85043200.0 | grad norm avg: 6.64 | grad norm last: 6.28 | 
2025-12-28T00:01:25 | step: 166200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.483794565312564e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.28 | consumed tokens: 85094400.0 | grad norm avg: 7.04 | grad norm last: 7.13 | 
2025-12-28T00:01:27 | step: 166300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.483145549893379e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.81 | consumed tokens: 85145600.0 | grad norm avg: 7.16 | grad norm last: 5.58 | 
2025-12-28T00:01:29 | step: 166400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.482495806878433e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.98 | consumed tokens: 85196800.0 | grad norm avg: 6.82 | grad norm last: 6.64 | 
2025-12-28T00:01:31 | step: 166500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.481845336267725e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.86 | consumed tokens: 85248000.0 | grad norm avg: 6.56 | grad norm last: 6.56 | 
2025-12-28T00:01:33 | step: 166600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 9.481195593252778e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.62 | consumed tokens: 85299200.0 | grad norm avg: 6.74 | grad norm last: 6.18 | 
2025-12-28T00:01:35 | step: 166700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 9.480545850237831e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.8 | consumed tokens: 85350400.0 | grad norm avg: 7.62 | grad norm last: 6.3 | 
2025-12-28T00:01:37 | step: 166800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.4798939244356e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.91 | consumed tokens: 85401600.0 | grad norm avg: 6.67 | grad norm last: 5.84 | 
2025-12-28T00:01:39 | step: 166900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.479242726229131e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.97 | consumed tokens: 85452800.0 | grad norm avg: 6.8 | grad norm last: 6.06 | 
2025-12-28T00:01:41 | step: 167000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.4785908004269e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.0 | consumed tokens: 85504000.0 | grad norm avg: 6.9 | grad norm last: 5.86 | 
2025-12-28T00:01:43 | step: 167100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.477938147028908e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.78 | consumed tokens: 85555200.0 | grad norm avg: 6.74 | grad norm last: 7.0 | 
2025-12-28T00:01:45 | step: 167200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.477286221226677e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.16 | consumed tokens: 85606400.0 | grad norm avg: 6.69 | grad norm last: 5.13 | 
2025-12-28T00:01:47 | step: 167300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.476632840232924e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.52 | consumed tokens: 85657600.0 | grad norm avg: 6.85 | grad norm last: 5.79 | 
2025-12-28T00:01:49 | step: 167400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.47597945923917e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.5 | consumed tokens: 85708800.0 | grad norm avg: 6.92 | grad norm last: 7.01 | 
2025-12-28T00:01:51 | step: 167500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.475325350649655e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.56 | consumed tokens: 85760000.0 | grad norm avg: 7.07 | grad norm last: 7.81 | 
2025-12-28T00:01:53 | step: 167600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.47467124206014e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.77 | consumed tokens: 85811200.0 | grad norm avg: 6.81 | grad norm last: 6.25 | 
2025-12-28T00:01:55 | step: 167700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.474016405874863e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.72 | consumed tokens: 85862400.0 | grad norm avg: 6.83 | grad norm last: 8.34 | 
2025-12-28T00:01:57 | step: 167800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.47336302488111e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 4.03 | consumed tokens: 85913600.0 | grad norm avg: 6.95 | grad norm last: 6.49 | 
2025-12-28T00:01:59 | step: 167900 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.47270673350431e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.25 | consumed tokens: 85964800.0 | grad norm avg: 6.71 | grad norm last: 7.45 | 
2025-12-28T00:02:01 | step: 168000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.472051169723272e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.59 | consumed tokens: 86016000.0 | grad norm avg: 6.59 | grad norm last: 6.3 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_168000-seen_tokens_86016000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_168000-seen_tokens_86016000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_168000-seen_tokens_86016000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_168000-seen_tokens_86016000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_168000-seen_tokens_86016000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_168000-seen_tokens_86016000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_168000-seen_tokens_86016000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_168000-seen_tokens_86016000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:02:04 | step: 168100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 9.471395605942234e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.93 | train loss last: 3.89 | consumed tokens: 86067200.0 | grad norm avg: 6.95 | grad norm last: 6.58 | 
2025-12-28T00:02:06 | step: 168200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 9.470738586969674e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.77 | consumed tokens: 86118400.0 | grad norm avg: 6.6 | grad norm last: 6.0 | 
2025-12-28T00:02:08 | step: 168300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.470081567997113e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.62 | consumed tokens: 86169600.0 | grad norm avg: 6.62 | grad norm last: 7.57 | 
2025-12-28T00:02:10 | step: 168400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.469423821428791e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.94 | consumed tokens: 86220800.0 | grad norm avg: 6.65 | grad norm last: 6.26 | 
2025-12-28T00:02:12 | step: 168500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.468766074860469e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.64 | consumed tokens: 86272000.0 | grad norm avg: 6.86 | grad norm last: 6.15 | 
2025-12-28T00:02:14 | step: 168600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.468108328292146e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.89 | consumed tokens: 86323200.0 | grad norm avg: 6.8 | grad norm last: 6.92 | 
2025-12-28T00:02:16 | step: 168700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.467450581723824e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.62 | consumed tokens: 86374400.0 | grad norm avg: 6.58 | grad norm last: 5.75 | 
2025-12-28T00:02:18 | step: 168800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.46679210755974e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.0 | consumed tokens: 86425600.0 | grad norm avg: 6.77 | grad norm last: 7.12 | 
2025-12-28T00:02:20 | step: 168900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.466133633395657e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.06 | consumed tokens: 86476800.0 | grad norm avg: 6.86 | grad norm last: 7.4 | 
2025-12-28T00:02:22 | step: 169000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.46547370404005e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.12 | consumed tokens: 86528000.0 | grad norm avg: 6.67 | grad norm last: 5.98 | 
2025-12-28T00:02:24 | step: 169100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.464813774684444e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.75 | consumed tokens: 86579200.0 | grad norm avg: 6.87 | grad norm last: 6.6 | 
2025-12-28T00:02:26 | step: 169200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.464153117733076e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.5 | consumed tokens: 86630400.0 | grad norm avg: 6.79 | grad norm last: 6.51 | 
2025-12-28T00:02:28 | step: 169300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.463492460781708e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.89 | consumed tokens: 86681600.0 | grad norm avg: 6.91 | grad norm last: 6.97 | 
2025-12-28T00:02:30 | step: 169400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.46283180383034e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.8 | consumed tokens: 86732800.0 | grad norm avg: 6.71 | grad norm last: 6.17 | 
2025-12-28T00:02:32 | step: 169500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.462170419283211e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.3 | consumed tokens: 86784000.0 | grad norm avg: 6.74 | grad norm last: 5.43 | 
2025-12-28T00:02:34 | step: 169600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.461507579544559e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.19 | consumed tokens: 86835200.0 | grad norm avg: 6.71 | grad norm last: 6.96 | 
2025-12-28T00:02:36 | step: 169700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.46084619499743e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.28 | consumed tokens: 86886400.0 | grad norm avg: 6.8 | grad norm last: 7.07 | 
2025-12-28T00:02:38 | step: 169800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.4601848104503e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.91 | consumed tokens: 86937600.0 | grad norm avg: 6.69 | grad norm last: 6.88 | 
2025-12-28T00:02:40 | step: 169900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.459521243115887e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.69 | consumed tokens: 86988800.0 | grad norm avg: 6.88 | grad norm last: 9.92 | 
2025-12-28T00:02:42 | step: 170000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.458857675781474e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.23 | consumed tokens: 87040000.0 | grad norm avg: 6.83 | grad norm last: 5.38 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_170000-seen_tokens_87040000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_170000-seen_tokens_87040000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_170000-seen_tokens_87040000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_170000-seen_tokens_87040000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_170000-seen_tokens_87040000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_170000-seen_tokens_87040000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_170000-seen_tokens_87040000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_170000-seen_tokens_87040000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:02:44 | step: 170100 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.45819410844706e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.91 | consumed tokens: 87091200.0 | grad norm avg: 6.46 | grad norm last: 6.58 | 
2025-12-28T00:02:46 | step: 170200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.457530541112646e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.47 | consumed tokens: 87142400.0 | grad norm avg: 7.19 | grad norm last: 6.18 | 
2025-12-28T00:02:48 | step: 170300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.45686551858671e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.89 | consumed tokens: 87193600.0 | grad norm avg: 7.2 | grad norm last: 5.81 | 
2025-12-28T00:02:50 | step: 170400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 9.456200496060774e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.52 | consumed tokens: 87244800.0 | grad norm avg: 6.84 | grad norm last: 6.49 | 
2025-12-28T00:02:52 | step: 170500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.455535473534837e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.22 | consumed tokens: 87296000.0 | grad norm avg: 6.73 | grad norm last: 5.59 | 
2025-12-28T00:02:54 | step: 170600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.454870451008901e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.28 | consumed tokens: 87347200.0 | grad norm avg: 6.91 | grad norm last: 7.01 | 
2025-12-28T00:02:56 | step: 170700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.454203973291442e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.19 | consumed tokens: 87398400.0 | grad norm avg: 7.0 | grad norm last: 6.24 | 
2025-12-28T00:02:58 | step: 170800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.453537495573983e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.38 | consumed tokens: 87449600.0 | grad norm avg: 6.81 | grad norm last: 5.5 | 
2025-12-28T00:03:00 | step: 170900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.452869562665e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.73 | consumed tokens: 87500800.0 | grad norm avg: 6.76 | grad norm last: 6.04 | 
2025-12-28T00:03:02 | step: 171000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.452204540139064e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 2.94 | consumed tokens: 87552000.0 | grad norm avg: 7.11 | grad norm last: 5.95 | 
2025-12-28T00:03:04 | step: 171100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 9.451535879634321e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.72 | consumed tokens: 87603200.0 | grad norm avg: 6.97 | grad norm last: 7.79 | 
2025-12-28T00:03:07 | step: 171200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.450867219129577e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.55 | consumed tokens: 87654400.0 | grad norm avg: 6.96 | grad norm last: 6.57 | 
2025-12-28T00:03:09 | step: 171300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.450200013816357e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.56 | consumed tokens: 87705600.0 | grad norm avg: 7.0 | grad norm last: 6.8 | 
2025-12-28T00:03:11 | step: 171400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.449531353311613e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.25 | consumed tokens: 87756800.0 | grad norm avg: 6.78 | grad norm last: 5.93 | 
2025-12-28T00:03:13 | step: 171500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.448861965211108e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.77 | consumed tokens: 87808000.0 | grad norm avg: 6.77 | grad norm last: 8.47 | 
2025-12-28T00:03:15 | step: 171600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.448192577110603e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.28 | consumed tokens: 87859200.0 | grad norm avg: 6.87 | grad norm last: 9.8 | 
2025-12-28T00:03:17 | step: 171700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.447523189010099e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.0 | consumed tokens: 87910400.0 | grad norm avg: 6.95 | grad norm last: 6.76 | 
2025-12-28T00:03:19 | step: 171800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.446853073313832e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.5 | consumed tokens: 87961600.0 | grad norm avg: 6.59 | grad norm last: 5.88 | 
2025-12-28T00:03:21 | step: 171900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.446181502426043e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.52 | consumed tokens: 88012800.0 | grad norm avg: 6.79 | grad norm last: 5.44 | 
2025-12-28T00:03:23 | step: 172000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.445511386729777e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.36 | consumed tokens: 88064000.0 | grad norm avg: 6.85 | grad norm last: 6.07 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_172000-seen_tokens_88064000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_172000-seen_tokens_88064000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_172000-seen_tokens_88064000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_172000-seen_tokens_88064000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_172000-seen_tokens_88064000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_172000-seen_tokens_88064000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_172000-seen_tokens_88064000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_172000-seen_tokens_88064000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:03:25 | step: 172100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.44484127103351e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.81 | consumed tokens: 88115200.0 | grad norm avg: 6.81 | grad norm last: 9.86 | 
2025-12-28T00:03:27 | step: 172200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.44416897254996e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.91 | consumed tokens: 88166400.0 | grad norm avg: 6.88 | grad norm last: 6.34 | 
2025-12-28T00:03:29 | step: 172300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.44349667406641e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.0 | consumed tokens: 88217600.0 | grad norm avg: 6.65 | grad norm last: 6.33 | 
2025-12-28T00:03:31 | step: 172400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.442824375582859e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.48 | consumed tokens: 88268800.0 | grad norm avg: 6.85 | grad norm last: 6.1 | 
2025-12-28T00:03:33 | step: 172500 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.442152077099308e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.3 | consumed tokens: 88320000.0 | grad norm avg: 6.95 | grad norm last: 5.92 | 
2025-12-28T00:03:35 | step: 172600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.441478323424235e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.34 | consumed tokens: 88371200.0 | grad norm avg: 7.05 | grad norm last: 6.13 | 
2025-12-28T00:03:37 | step: 172700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.440804569749162e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.28 | consumed tokens: 88422400.0 | grad norm avg: 6.79 | grad norm last: 7.32 | 
2025-12-28T00:03:39 | step: 172800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.440130816074088e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.19 | consumed tokens: 88473600.0 | grad norm avg: 6.95 | grad norm last: 6.72 | 
2025-12-28T00:03:41 | step: 172900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.439457062399015e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.47 | consumed tokens: 88524800.0 | grad norm avg: 6.93 | grad norm last: 7.07 | 
2025-12-28T00:03:43 | step: 173000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.438781853532419e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.86 | consumed tokens: 88576000.0 | grad norm avg: 6.94 | grad norm last: 6.1 | 
2025-12-28T00:03:45 | step: 173100 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.438106644665822e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.16 | consumed tokens: 88627200.0 | grad norm avg: 6.77 | grad norm last: 5.61 | 
2025-12-28T00:03:47 | step: 173200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.437431435799226e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.38 | consumed tokens: 88678400.0 | grad norm avg: 6.83 | grad norm last: 7.42 | 
2025-12-28T00:03:49 | step: 173300 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.43675622693263e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 5.53 | consumed tokens: 88729600.0 | grad norm avg: 6.98 | grad norm last: 7.17 | 
2025-12-28T00:03:51 | step: 173400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.43607883527875e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 5.22 | consumed tokens: 88780800.0 | grad norm avg: 6.82 | grad norm last: 12.18 | 
2025-12-28T00:03:53 | step: 173500 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.435401443624869e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.78 | consumed tokens: 88832000.0 | grad norm avg: 7.09 | grad norm last: 6.61 | 
2025-12-28T00:03:55 | step: 173600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.434725507162511e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.62 | consumed tokens: 88883200.0 | grad norm avg: 6.99 | grad norm last: 6.31 | 
2025-12-28T00:03:57 | step: 173700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.434048115508631e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.31 | consumed tokens: 88934400.0 | grad norm avg: 6.92 | grad norm last: 7.08 | 
2025-12-28T00:03:59 | step: 173800 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 9.433369996258989e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.19 | consumed tokens: 88985600.0 | grad norm avg: 6.83 | grad norm last: 7.67 | 
2025-12-28T00:04:01 | step: 173900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 9.43269333220087e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.64 | consumed tokens: 89036800.0 | grad norm avg: 7.07 | grad norm last: 6.42 | 
2025-12-28T00:04:03 | step: 174000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.432013757759705e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.67 | consumed tokens: 89088000.0 | grad norm avg: 7.08 | grad norm last: 6.17 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_174000-seen_tokens_89088000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_174000-seen_tokens_89088000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_174000-seen_tokens_89088000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_174000-seen_tokens_89088000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_174000-seen_tokens_89088000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_174000-seen_tokens_89088000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_174000-seen_tokens_89088000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_174000-seen_tokens_89088000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:04:06 | step: 174100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.431334910914302e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.98 | train loss last: 3.59 | consumed tokens: 89139200.0 | grad norm avg: 7.06 | grad norm last: 6.05 | 
2025-12-28T00:04:08 | step: 174200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 9.430656064068899e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.19 | consumed tokens: 89190400.0 | grad norm avg: 7.04 | grad norm last: 5.61 | 
2025-12-28T00:04:10 | step: 174300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 9.429976489627734e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.31 | consumed tokens: 89241600.0 | grad norm avg: 7.12 | grad norm last: 7.79 | 
2025-12-28T00:04:12 | step: 174400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 9.429295459995046e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.03 | consumed tokens: 89292800.0 | grad norm avg: 7.1 | grad norm last: 7.64 | 
2025-12-28T00:04:14 | step: 174500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 9.428615885553882e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.17 | consumed tokens: 89344000.0 | grad norm avg: 6.97 | grad norm last: 5.65 | 
2025-12-28T00:04:16 | step: 174600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.427934855921194e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 4.47 | consumed tokens: 89395200.0 | grad norm avg: 7.11 | grad norm last: 7.19 | 
2025-12-28T00:04:18 | step: 174700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.427253826288506e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.59 | consumed tokens: 89446400.0 | grad norm avg: 6.81 | grad norm last: 6.12 | 
2025-12-28T00:04:20 | step: 174800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.426571341464296e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.98 | consumed tokens: 89497600.0 | grad norm avg: 6.96 | grad norm last: 7.19 | 
2025-12-28T00:04:22 | step: 174900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.425890311831608e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.19 | consumed tokens: 89548800.0 | grad norm avg: 7.09 | grad norm last: 7.37 | 
2025-12-28T00:04:24 | step: 175000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.42520855460316e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.66 | consumed tokens: 89600000.0 | grad norm avg: 7.06 | grad norm last: 6.09 | 
2025-12-28T00:04:26 | step: 175100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.424525342183188e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.72 | consumed tokens: 89651200.0 | grad norm avg: 6.89 | grad norm last: 6.53 | 
2025-12-28T00:04:28 | step: 175200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.423842857358977e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.59 | consumed tokens: 89702400.0 | grad norm avg: 6.98 | grad norm last: 7.5 | 
2025-12-28T00:04:30 | step: 175300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.423158917343244e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.44 | consumed tokens: 89753600.0 | grad norm avg: 7.38 | grad norm last: 6.51 | 
2025-12-28T00:04:32 | step: 175400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.422475704923272e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.89 | consumed tokens: 89804800.0 | grad norm avg: 7.0 | grad norm last: 6.61 | 
2025-12-28T00:04:34 | step: 175500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.421791037311777e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.11 | consumed tokens: 89856000.0 | grad norm avg: 6.98 | grad norm last: 5.9 | 
2025-12-28T00:04:36 | step: 175600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.421107097296044e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.44 | consumed tokens: 89907200.0 | grad norm avg: 7.04 | grad norm last: 6.61 | 
2025-12-28T00:04:38 | step: 175700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.420421702088788e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.84 | consumed tokens: 89958400.0 | grad norm avg: 7.35 | grad norm last: 6.17 | 
2025-12-28T00:04:40 | step: 175800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.419736306881532e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 5.16 | consumed tokens: 90009600.0 | grad norm avg: 7.2 | grad norm last: 7.73 | 
2025-12-28T00:04:42 | step: 175900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.419050911674276e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.64 | consumed tokens: 90060800.0 | grad norm avg: 7.36 | grad norm last: 6.76 | 
2025-12-28T00:04:44 | step: 176000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.418364061275497e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.16 | consumed tokens: 90112000.0 | grad norm avg: 6.86 | grad norm last: 7.21 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_176000-seen_tokens_90112000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_176000-seen_tokens_90112000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_176000-seen_tokens_90112000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_176000-seen_tokens_90112000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_176000-seen_tokens_90112000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_176000-seen_tokens_90112000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_176000-seen_tokens_90112000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_176000-seen_tokens_90112000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:04:46 | step: 176100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.417678666068241e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.09 | consumed tokens: 90163200.0 | grad norm avg: 7.22 | grad norm last: 7.56 | 
2025-12-28T00:04:48 | step: 176200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.416991815669462e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.69 | consumed tokens: 90214400.0 | grad norm avg: 6.76 | grad norm last: 6.23 | 
2025-12-28T00:04:50 | step: 176300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.41630351007916e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.95 | consumed tokens: 90265600.0 | grad norm avg: 7.0 | grad norm last: 7.36 | 
2025-12-28T00:04:52 | step: 176400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.415616659680381e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.58 | consumed tokens: 90316800.0 | grad norm avg: 7.01 | grad norm last: 5.93 | 
2025-12-28T00:04:54 | step: 176500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.414929081685841e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.47 | consumed tokens: 90368000.0 | grad norm avg: 7.08 | grad norm last: 6.17 | 
2025-12-28T00:04:56 | step: 176600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.414241503691301e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.47 | consumed tokens: 90419200.0 | grad norm avg: 7.26 | grad norm last: 7.12 | 
2025-12-28T00:04:58 | step: 176700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.413551742909476e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.16 | consumed tokens: 90470400.0 | grad norm avg: 7.01 | grad norm last: 7.65 | 
2025-12-28T00:05:00 | step: 176800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 9.412862709723413e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.12 | consumed tokens: 90521600.0 | grad norm avg: 7.14 | grad norm last: 6.53 | 
2025-12-28T00:05:02 | step: 176900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 9.41217367653735e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.05 | consumed tokens: 90572800.0 | grad norm avg: 6.84 | grad norm last: 5.25 | 
2025-12-28T00:05:04 | step: 177000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.411483915755525e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.64 | consumed tokens: 90624000.0 | grad norm avg: 7.08 | grad norm last: 6.66 | 
2025-12-28T00:05:06 | step: 177100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.410793427377939e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.05 | consumed tokens: 90675200.0 | grad norm avg: 7.02 | grad norm last: 6.01 | 
2025-12-28T00:05:08 | step: 177200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.410102939000353e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.89 | consumed tokens: 90726400.0 | grad norm avg: 7.27 | grad norm last: 6.01 | 
2025-12-28T00:05:10 | step: 177300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.409411723027006e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.0 | consumed tokens: 90777600.0 | grad norm avg: 7.16 | grad norm last: 6.55 | 
2025-12-28T00:05:12 | step: 177400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.408720507053658e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.38 | consumed tokens: 90828800.0 | grad norm avg: 6.88 | grad norm last: 6.68 | 
2025-12-28T00:05:14 | step: 177500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 9.408029291080311e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.3 | consumed tokens: 90880000.0 | grad norm avg: 7.01 | grad norm last: 5.61 | 
2025-12-28T00:05:16 | step: 177600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.407338075106964e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.44 | consumed tokens: 90931200.0 | grad norm avg: 7.04 | grad norm last: 6.59 | 
2025-12-28T00:05:19 | step: 177700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.406645403942093e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.44 | consumed tokens: 90982400.0 | grad norm avg: 7.02 | grad norm last: 7.01 | 
2025-12-28T00:05:21 | step: 177800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.405952732777223e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.16 | consumed tokens: 91033600.0 | grad norm avg: 7.1 | grad norm last: 6.58 | 
2025-12-28T00:05:23 | step: 177900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.40525860642083e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.8 | consumed tokens: 91084800.0 | grad norm avg: 7.0 | grad norm last: 6.04 | 
2025-12-28T00:05:25 | step: 178000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.404565207660198e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.22 | consumed tokens: 91136000.0 | grad norm avg: 7.02 | grad norm last: 6.49 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_178000-seen_tokens_91136000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_178000-seen_tokens_91136000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_178000-seen_tokens_91136000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_178000-seen_tokens_91136000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_178000-seen_tokens_91136000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_178000-seen_tokens_91136000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_178000-seen_tokens_91136000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_178000-seen_tokens_91136000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:05:27 | step: 178100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.403870353708044e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.94 | train loss last: 4.12 | consumed tokens: 91187200.0 | grad norm avg: 7.1 | grad norm last: 6.75 | 
2025-12-28T00:05:29 | step: 178200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.403176954947412e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.78 | consumed tokens: 91238400.0 | grad norm avg: 7.28 | grad norm last: 6.64 | 
2025-12-28T00:05:31 | step: 178300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.402482100995257e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.98 | consumed tokens: 91289600.0 | grad norm avg: 6.81 | grad norm last: 6.77 | 
2025-12-28T00:05:33 | step: 178400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.401786519447342e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.06 | consumed tokens: 91340800.0 | grad norm avg: 6.85 | grad norm last: 6.85 | 
2025-12-28T00:05:35 | step: 178500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.401092393090948e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.56 | consumed tokens: 91392000.0 | grad norm avg: 7.27 | grad norm last: 7.7 | 
2025-12-28T00:05:37 | step: 178600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.40039535635151e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.69 | consumed tokens: 91443200.0 | grad norm avg: 6.9 | grad norm last: 7.06 | 
2025-12-28T00:05:39 | step: 178700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.399699774803594e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.69 | consumed tokens: 91494400.0 | grad norm avg: 7.12 | grad norm last: 6.32 | 
2025-12-28T00:05:41 | step: 178800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.399003465659916e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.98 | consumed tokens: 91545600.0 | grad norm avg: 7.12 | grad norm last: 6.62 | 
2025-12-28T00:05:43 | step: 178900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.398305701324716e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.61 | consumed tokens: 91596800.0 | grad norm avg: 6.93 | grad norm last: 11.43 | 
2025-12-28T00:05:45 | step: 179000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.397608664585277e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.45 | consumed tokens: 91648000.0 | grad norm avg: 7.11 | grad norm last: 6.06 | 
2025-12-28T00:05:47 | step: 179100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.396910900250077e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.61 | consumed tokens: 91699200.0 | grad norm avg: 7.13 | grad norm last: 6.24 | 
2025-12-28T00:05:49 | step: 179200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.396213135914877e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.94 | consumed tokens: 91750400.0 | grad norm avg: 6.98 | grad norm last: 6.45 | 
2025-12-28T00:05:51 | step: 179300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.395514643983915e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.66 | consumed tokens: 91801600.0 | grad norm avg: 7.1 | grad norm last: 6.08 | 
2025-12-28T00:05:53 | step: 179400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.394816152052954e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.86 | consumed tokens: 91852800.0 | grad norm avg: 6.94 | grad norm last: 7.12 | 
2025-12-28T00:05:55 | step: 179500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 9.394116932526231e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.5 | consumed tokens: 91904000.0 | grad norm avg: 7.07 | grad norm last: 5.91 | 
2025-12-28T00:05:57 | step: 179600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 9.393416257807985e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.66 | consumed tokens: 91955200.0 | grad norm avg: 7.05 | grad norm last: 6.56 | 
2025-12-28T00:05:59 | step: 179700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.392717038281262e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.44 | consumed tokens: 92006400.0 | grad norm avg: 6.85 | grad norm last: 8.63 | 
2025-12-28T00:06:01 | step: 179800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.392017818754539e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.83 | consumed tokens: 92057600.0 | grad norm avg: 6.99 | grad norm last: 6.19 | 
2025-12-28T00:06:03 | step: 179900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.391316416440532e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.41 | consumed tokens: 92108800.0 | grad norm avg: 7.14 | grad norm last: 6.71 | 
2025-12-28T00:06:05 | step: 180000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.390615014126524e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.73 | consumed tokens: 92160000.0 | grad norm avg: 6.8 | grad norm last: 6.63 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_180000-seen_tokens_92160000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_180000-seen_tokens_92160000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_180000-seen_tokens_92160000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_180000-seen_tokens_92160000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_180000-seen_tokens_92160000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_180000-seen_tokens_92160000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_180000-seen_tokens_92160000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_180000-seen_tokens_92160000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:06:07 | step: 180100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.389913611812517e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.45 | consumed tokens: 92211200.0 | grad norm avg: 7.22 | grad norm last: 5.8 | 
2025-12-28T00:06:09 | step: 180200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.38921220949851e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.47 | consumed tokens: 92262400.0 | grad norm avg: 7.18 | grad norm last: 7.08 | 
2025-12-28T00:06:12 | step: 180300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.38850935199298e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.2 | consumed tokens: 92313600.0 | grad norm avg: 7.11 | grad norm last: 5.47 | 
2025-12-28T00:06:14 | step: 180400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.387807222083211e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.34 | consumed tokens: 92364800.0 | grad norm avg: 7.21 | grad norm last: 6.81 | 
2025-12-28T00:06:16 | step: 180500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.387105092173442e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.09 | consumed tokens: 92416000.0 | grad norm avg: 7.02 | grad norm last: 8.18 | 
2025-12-28T00:06:18 | step: 180600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.386400779476389e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.09 | consumed tokens: 92467200.0 | grad norm avg: 7.0 | grad norm last: 6.91 | 
2025-12-28T00:06:20 | step: 180700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 9.385697194375098e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.33 | consumed tokens: 92518400.0 | grad norm avg: 7.18 | grad norm last: 6.17 | 
2025-12-28T00:06:22 | step: 180800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 9.384993609273806e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.95 | consumed tokens: 92569600.0 | grad norm avg: 7.3 | grad norm last: 6.44 | 
2025-12-28T00:06:24 | step: 180900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 9.384288568980992e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.12 | consumed tokens: 92620800.0 | grad norm avg: 6.97 | grad norm last: 6.61 | 
2025-12-28T00:06:26 | step: 181000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.383584256283939e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.09 | consumed tokens: 92672000.0 | grad norm avg: 7.41 | grad norm last: 6.31 | 
2025-12-28T00:06:28 | step: 181100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.382879215991125e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.2 | consumed tokens: 92723200.0 | grad norm avg: 7.18 | grad norm last: 5.29 | 
2025-12-28T00:06:30 | step: 181200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.382173448102549e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.81 | consumed tokens: 92774400.0 | grad norm avg: 7.18 | grad norm last: 7.34 | 
2025-12-28T00:06:32 | step: 181300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.381467680213973e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.55 | consumed tokens: 92825600.0 | grad norm avg: 7.51 | grad norm last: 6.94 | 
2025-12-28T00:06:34 | step: 181400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.380761184729636e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 2.86 | consumed tokens: 92876800.0 | grad norm avg: 7.35 | grad norm last: 5.67 | 
2025-12-28T00:06:36 | step: 181500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.380054689245299e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.16 | consumed tokens: 92928000.0 | grad norm avg: 7.22 | grad norm last: 10.74 | 
2025-12-28T00:06:38 | step: 181600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.3793474661652e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.25 | consumed tokens: 92979200.0 | grad norm avg: 7.02 | grad norm last: 5.83 | 
2025-12-28T00:06:40 | step: 181700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.378640243085101e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.03 | consumed tokens: 93030400.0 | grad norm avg: 6.91 | grad norm last: 8.68 | 
2025-12-28T00:06:42 | step: 181800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.377932292409241e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.03 | consumed tokens: 93081600.0 | grad norm avg: 7.32 | grad norm last: 7.61 | 
2025-12-28T00:06:44 | step: 181900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.377224341733381e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.91 | consumed tokens: 93132800.0 | grad norm avg: 7.08 | grad norm last: 6.25 | 
2025-12-28T00:06:46 | step: 182000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.37651566346176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.64 | consumed tokens: 93184000.0 | grad norm avg: 7.2 | grad norm last: 6.55 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_182000-seen_tokens_93184000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_182000-seen_tokens_93184000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_182000-seen_tokens_93184000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_182000-seen_tokens_93184000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_182000-seen_tokens_93184000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_182000-seen_tokens_93184000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_182000-seen_tokens_93184000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_182000-seen_tokens_93184000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:06:48 | step: 182100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.375806985190138e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.84 | train loss last: 4.44 | consumed tokens: 93235200.0 | grad norm avg: 6.9 | grad norm last: 7.84 | 
2025-12-28T00:06:50 | step: 182200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.375097579322755e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.28 | consumed tokens: 93286400.0 | grad norm avg: 6.89 | grad norm last: 6.53 | 
2025-12-28T00:06:52 | step: 182300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.374388173455372e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.77 | consumed tokens: 93337600.0 | grad norm avg: 7.03 | grad norm last: 6.51 | 
2025-12-28T00:06:54 | step: 182400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.373678039992228e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.25 | consumed tokens: 93388800.0 | grad norm avg: 7.27 | grad norm last: 9.27 | 
2025-12-28T00:06:56 | step: 182500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.372967178933322e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.31 | consumed tokens: 93440000.0 | grad norm avg: 7.28 | grad norm last: 8.89 | 
2025-12-28T00:06:58 | step: 182600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.372256317874417e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.53 | consumed tokens: 93491200.0 | grad norm avg: 6.97 | grad norm last: 7.87 | 
2025-12-28T00:07:00 | step: 182700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.371546184411272e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.19 | consumed tokens: 93542400.0 | grad norm avg: 7.07 | grad norm last: 8.75 | 
2025-12-28T00:07:02 | step: 182800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.370833868160844e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.34 | consumed tokens: 93593600.0 | grad norm avg: 7.02 | grad norm last: 7.55 | 
2025-12-28T00:07:04 | step: 182900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.370121551910415e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.64 | consumed tokens: 93644800.0 | grad norm avg: 7.04 | grad norm last: 6.83 | 
2025-12-28T00:07:06 | step: 183000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.369409963255748e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.19 | consumed tokens: 93696000.0 | grad norm avg: 7.25 | grad norm last: 6.64 | 
2025-12-28T00:07:08 | step: 183100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.368696919409558e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.53 | consumed tokens: 93747200.0 | grad norm avg: 7.21 | grad norm last: 6.89 | 
2025-12-28T00:07:10 | step: 183200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.36798460315913e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.66 | consumed tokens: 93798400.0 | grad norm avg: 7.04 | grad norm last: 8.33 | 
2025-12-28T00:07:12 | step: 183300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.367270831717178e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 5.44 | consumed tokens: 93849600.0 | grad norm avg: 7.23 | grad norm last: 9.42 | 
2025-12-28T00:07:14 | step: 183400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.366557787870988e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.64 | consumed tokens: 93900800.0 | grad norm avg: 7.18 | grad norm last: 6.72 | 
2025-12-28T00:07:16 | step: 183500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.365843288833275e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.48 | consumed tokens: 93952000.0 | grad norm avg: 7.12 | grad norm last: 7.04 | 
2025-12-28T00:07:18 | step: 183600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.365128789795563e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.16 | consumed tokens: 94003200.0 | grad norm avg: 7.28 | grad norm last: 7.29 | 
2025-12-28T00:07:20 | step: 183700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.364413563162088e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.84 | consumed tokens: 94054400.0 | grad norm avg: 7.27 | grad norm last: 9.26 | 
2025-12-28T00:07:22 | step: 183800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.363698336528614e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.12 | consumed tokens: 94105600.0 | grad norm avg: 6.99 | grad norm last: 6.81 | 
2025-12-28T00:07:24 | step: 183900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 9.362983837490901e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.47 | consumed tokens: 94156800.0 | grad norm avg: 7.08 | grad norm last: 6.6 | 
2025-12-28T00:07:26 | step: 184000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 9.362267883261666e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.36 | consumed tokens: 94208000.0 | grad norm avg: 6.96 | grad norm last: 5.89 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_184000-seen_tokens_94208000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_184000-seen_tokens_94208000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_184000-seen_tokens_94208000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_184000-seen_tokens_94208000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_184000-seen_tokens_94208000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_184000-seen_tokens_94208000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_184000-seen_tokens_94208000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_184000-seen_tokens_94208000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:07:29 | step: 184100 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 9.361550473840907e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.41 | consumed tokens: 94259200.0 | grad norm avg: 7.19 | grad norm last: 6.7 | 
2025-12-28T00:07:31 | step: 184200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.36083379201591e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.61 | consumed tokens: 94310400.0 | grad norm avg: 7.26 | grad norm last: 8.08 | 
2025-12-28T00:07:33 | step: 184300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.360117110190913e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.31 | consumed tokens: 94361600.0 | grad norm avg: 7.16 | grad norm last: 6.39 | 
2025-12-28T00:07:35 | step: 184400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.359399700770155e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.94 | consumed tokens: 94412800.0 | grad norm avg: 7.04 | grad norm last: 6.85 | 
2025-12-28T00:07:37 | step: 184500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.358682291349396e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.55 | consumed tokens: 94464000.0 | grad norm avg: 7.32 | grad norm last: 6.88 | 
2025-12-28T00:07:39 | step: 184600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 9.357963426737115e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.94 | consumed tokens: 94515200.0 | grad norm avg: 7.05 | grad norm last: 11.58 | 
2025-12-28T00:07:41 | step: 184700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.357244562124833e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.31 | consumed tokens: 94566400.0 | grad norm avg: 7.24 | grad norm last: 7.5 | 
2025-12-28T00:07:43 | step: 184800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.356525697512552e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 3.45 | consumed tokens: 94617600.0 | grad norm avg: 7.22 | grad norm last: 6.37 | 
2025-12-28T00:07:45 | step: 184900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.355806832900271e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.34 | consumed tokens: 94668800.0 | grad norm avg: 6.9 | grad norm last: 6.47 | 
2025-12-28T00:07:47 | step: 185000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.355086513096467e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.86 | consumed tokens: 94720000.0 | grad norm avg: 7.16 | grad norm last: 6.9 | 
2025-12-28T00:07:49 | step: 185100 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.354366920888424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.98 | consumed tokens: 94771200.0 | grad norm avg: 7.25 | grad norm last: 6.98 | 
2025-12-28T00:07:51 | step: 185200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.353647328680381e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.42 | consumed tokens: 94822400.0 | grad norm avg: 7.03 | grad norm last: 7.18 | 
2025-12-28T00:07:53 | step: 185300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.352925553685054e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.53 | consumed tokens: 94873600.0 | grad norm avg: 7.26 | grad norm last: 6.46 | 
2025-12-28T00:07:55 | step: 185400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.352204506285489e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.09 | consumed tokens: 94924800.0 | grad norm avg: 7.83 | grad norm last: 6.27 | 
2025-12-28T00:07:57 | step: 185500 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.351482731290162e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.0 | consumed tokens: 94976000.0 | grad norm avg: 7.04 | grad norm last: 6.9 | 
2025-12-28T00:07:59 | step: 185600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.350760956294835e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.44 | consumed tokens: 95027200.0 | grad norm avg: 7.31 | grad norm last: 7.4 | 
2025-12-28T00:08:01 | step: 185700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.350038453703746e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.03 | consumed tokens: 95078400.0 | grad norm avg: 7.07 | grad norm last: 7.74 | 
2025-12-28T00:08:03 | step: 185800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.349316678708419e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.06 | consumed tokens: 95129600.0 | grad norm avg: 7.22 | grad norm last: 7.3 | 
2025-12-28T00:08:05 | step: 185900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.348592720925808e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.91 | consumed tokens: 95180800.0 | grad norm avg: 7.43 | grad norm last: 6.84 | 
2025-12-28T00:08:07 | step: 186000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.347868763143197e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.86 | consumed tokens: 95232000.0 | grad norm avg: 7.07 | grad norm last: 5.82 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_186000-seen_tokens_95232000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_186000-seen_tokens_95232000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_186000-seen_tokens_95232000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_186000-seen_tokens_95232000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_186000-seen_tokens_95232000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_186000-seen_tokens_95232000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_186000-seen_tokens_95232000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_186000-seen_tokens_95232000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:08:10 | step: 186100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.347145532956347e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.92 | train loss last: 3.61 | consumed tokens: 95283200.0 | grad norm avg: 7.07 | grad norm last: 6.44 | 
2025-12-28T00:08:12 | step: 186200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.346421575173736e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.0 | consumed tokens: 95334400.0 | grad norm avg: 7.07 | grad norm last: 7.82 | 
2025-12-28T00:08:14 | step: 186300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.345697617391124e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.16 | consumed tokens: 95385600.0 | grad norm avg: 7.56 | grad norm last: 7.64 | 
2025-12-28T00:08:16 | step: 186400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.34497220441699e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.39 | consumed tokens: 95436800.0 | grad norm avg: 7.01 | grad norm last: 6.82 | 
2025-12-28T00:08:18 | step: 186500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.344247519038618e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.16 | consumed tokens: 95488000.0 | grad norm avg: 7.56 | grad norm last: 7.75 | 
2025-12-28T00:08:20 | step: 186600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.343520650872961e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.97 | consumed tokens: 95539200.0 | grad norm avg: 7.17 | grad norm last: 7.24 | 
2025-12-28T00:08:22 | step: 186700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.342795237898827e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.67 | consumed tokens: 95590400.0 | grad norm avg: 7.29 | grad norm last: 6.93 | 
2025-12-28T00:08:24 | step: 186800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.342069824924693e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.48 | consumed tokens: 95641600.0 | grad norm avg: 7.09 | grad norm last: 7.35 | 
2025-12-28T00:08:26 | step: 186900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.341342229163274e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.34 | consumed tokens: 95692800.0 | grad norm avg: 7.26 | grad norm last: 7.52 | 
2025-12-28T00:08:28 | step: 187000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.340615360997617e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.34 | consumed tokens: 95744000.0 | grad norm avg: 7.21 | grad norm last: 7.97 | 
2025-12-28T00:08:30 | step: 187100 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.339887765236199e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 4.47 | consumed tokens: 95795200.0 | grad norm avg: 7.16 | grad norm last: 8.13 | 
2025-12-28T00:08:32 | step: 187200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.33916016947478e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 5.53 | consumed tokens: 95846400.0 | grad norm avg: 7.22 | grad norm last: 7.76 | 
2025-12-28T00:08:34 | step: 187300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.338431846117601e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.75 | consumed tokens: 95897600.0 | grad norm avg: 7.21 | grad norm last: 8.2 | 
2025-12-28T00:08:36 | step: 187400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.337704250356182e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.23 | consumed tokens: 95948800.0 | grad norm avg: 7.15 | grad norm last: 6.18 | 
2025-12-28T00:08:38 | step: 187500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.33697447180748e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.41 | consumed tokens: 96000000.0 | grad norm avg: 7.23 | grad norm last: 6.25 | 
2025-12-28T00:08:40 | step: 187600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.336244693258777e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.64 | consumed tokens: 96051200.0 | grad norm avg: 7.49 | grad norm last: 5.51 | 
2025-12-28T00:08:42 | step: 187700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.335515642305836e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.06 | consumed tokens: 96102400.0 | grad norm avg: 7.21 | grad norm last: 6.18 | 
2025-12-28T00:08:44 | step: 187800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.334785863757133e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.03 | consumed tokens: 96153600.0 | grad norm avg: 7.42 | grad norm last: 6.89 | 
2025-12-28T00:08:46 | step: 187900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.33405535761267e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.8 | consumed tokens: 96204800.0 | grad norm avg: 7.17 | grad norm last: 6.55 | 
2025-12-28T00:08:48 | step: 188000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.333324123872444e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.58 | consumed tokens: 96256000.0 | grad norm avg: 7.83 | grad norm last: 7.81 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_188000-seen_tokens_96256000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_188000-seen_tokens_96256000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_188000-seen_tokens_96256000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_188000-seen_tokens_96256000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_188000-seen_tokens_96256000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_188000-seen_tokens_96256000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_188000-seen_tokens_96256000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_188000-seen_tokens_96256000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:08:50 | step: 188100 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 9.33259361772798e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.92 | train loss last: 3.14 | consumed tokens: 96307200.0 | grad norm avg: 7.64 | grad norm last: 5.91 | 
2025-12-28T00:08:52 | step: 188200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 9.331861656391993e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.88 | consumed tokens: 96358400.0 | grad norm avg: 7.37 | grad norm last: 7.62 | 
2025-12-28T00:08:54 | step: 188300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.331129695056006e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 2.75 | consumed tokens: 96409600.0 | grad norm avg: 7.34 | grad norm last: 6.22 | 
2025-12-28T00:08:56 | step: 188400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.33039773372002e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.58 | consumed tokens: 96460800.0 | grad norm avg: 7.24 | grad norm last: 6.25 | 
2025-12-28T00:08:58 | step: 188500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.329665772384033e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.5 | consumed tokens: 96512000.0 | grad norm avg: 7.07 | grad norm last: 7.83 | 
2025-12-28T00:09:00 | step: 188600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.328932355856523e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.39 | consumed tokens: 96563200.0 | grad norm avg: 7.73 | grad norm last: 7.43 | 
2025-12-28T00:09:02 | step: 188700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.328198939329013e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.44 | consumed tokens: 96614400.0 | grad norm avg: 7.31 | grad norm last: 6.76 | 
2025-12-28T00:09:04 | step: 188800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.327465522801504e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.64 | consumed tokens: 96665600.0 | grad norm avg: 7.56 | grad norm last: 7.35 | 
2025-12-28T00:09:06 | step: 188900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 9.326730651082471e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.0 | consumed tokens: 96716800.0 | grad norm avg: 7.55 | grad norm last: 6.85 | 
2025-12-28T00:09:08 | step: 189000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 9.3259965069592e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.56 | consumed tokens: 96768000.0 | grad norm avg: 7.15 | grad norm last: 7.26 | 
2025-12-28T00:09:10 | step: 189100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.325260907644406e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.53 | consumed tokens: 96819200.0 | grad norm avg: 7.36 | grad norm last: 7.36 | 
2025-12-28T00:09:12 | step: 189200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 9.324526035925373e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.75 | consumed tokens: 96870400.0 | grad norm avg: 7.35 | grad norm last: 6.61 | 
2025-12-28T00:09:14 | step: 189300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.32379043661058e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.06 | consumed tokens: 96921600.0 | grad norm avg: 7.22 | grad norm last: 6.9 | 
2025-12-28T00:09:16 | step: 189400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 9.323054837295786e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.56 | consumed tokens: 96972800.0 | grad norm avg: 7.39 | grad norm last: 6.36 | 
2025-12-28T00:09:18 | step: 189500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.32231851038523e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 3.31 | consumed tokens: 97024000.0 | grad norm avg: 7.97 | grad norm last: 6.26 | 
2025-12-28T00:09:20 | step: 189600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.321582183474675e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.59 | consumed tokens: 97075200.0 | grad norm avg: 7.56 | grad norm last: 9.69 | 
2025-12-28T00:09:22 | step: 189700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.320845128968358e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 5.22 | consumed tokens: 97126400.0 | grad norm avg: 7.17 | grad norm last: 8.25 | 
2025-12-28T00:09:25 | step: 189800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.320108074462041e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.16 | consumed tokens: 97177600.0 | grad norm avg: 7.27 | grad norm last: 7.82 | 
2025-12-28T00:09:27 | step: 189900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.319369564764202e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.22 | consumed tokens: 97228800.0 | grad norm avg: 7.51 | grad norm last: 8.05 | 
2025-12-28T00:09:29 | step: 190000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.318631055066362e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.22 | consumed tokens: 97280000.0 | grad norm avg: 7.45 | grad norm last: 8.41 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_190000-seen_tokens_97280000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_190000-seen_tokens_97280000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_190000-seen_tokens_97280000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_190000-seen_tokens_97280000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_190000-seen_tokens_97280000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_190000-seen_tokens_97280000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_190000-seen_tokens_97280000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_190000-seen_tokens_97280000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:09:31 | step: 190100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.317893272964284e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.62 | consumed tokens: 97331200.0 | grad norm avg: 7.37 | grad norm last: 6.52 | 
2025-12-28T00:09:33 | step: 190200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.317154035670683e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.94 | consumed tokens: 97382400.0 | grad norm avg: 7.59 | grad norm last: 7.16 | 
2025-12-28T00:09:35 | step: 190300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.316414798377082e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.84 | consumed tokens: 97433600.0 | grad norm avg: 7.34 | grad norm last: 7.2 | 
2025-12-28T00:09:37 | step: 190400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.315675561083481e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.81 | consumed tokens: 97484800.0 | grad norm avg: 7.79 | grad norm last: 6.8 | 
2025-12-28T00:09:39 | step: 190500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 9.314934868598357e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.88 | consumed tokens: 97536000.0 | grad norm avg: 7.53 | grad norm last: 7.14 | 
2025-12-28T00:09:41 | step: 190600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.314194903708994e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.83 | consumed tokens: 97587200.0 | grad norm avg: 7.21 | grad norm last: 6.7 | 
2025-12-28T00:09:43 | step: 190700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.313454938819632e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.36 | consumed tokens: 97638400.0 | grad norm avg: 7.25 | grad norm last: 6.78 | 
2025-12-28T00:09:45 | step: 190800 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.312713518738747e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.28 | consumed tokens: 97689600.0 | grad norm avg: 7.29 | grad norm last: 8.45 | 
2025-12-28T00:09:47 | step: 190900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.311972098657861e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.88 | consumed tokens: 97740800.0 | grad norm avg: 7.26 | grad norm last: 6.73 | 
2025-12-28T00:09:49 | step: 191000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.311229950981215e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.31 | consumed tokens: 97792000.0 | grad norm avg: 7.22 | grad norm last: 9.04 | 
2025-12-28T00:09:51 | step: 191100 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.310487803304568e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.61 | consumed tokens: 97843200.0 | grad norm avg: 7.43 | grad norm last: 6.51 | 
2025-12-28T00:09:53 | step: 191200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.309745655627921e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.09 | consumed tokens: 97894400.0 | grad norm avg: 7.59 | grad norm last: 7.05 | 
2025-12-28T00:09:55 | step: 191300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.309002780355513e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.44 | consumed tokens: 97945600.0 | grad norm avg: 7.15 | grad norm last: 5.94 | 
2025-12-28T00:09:57 | step: 191400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.308258449891582e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 2.88 | consumed tokens: 97996800.0 | grad norm avg: 7.4 | grad norm last: 5.65 | 
2025-12-28T00:09:59 | step: 191500 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.307515574619174e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.38 | consumed tokens: 98048000.0 | grad norm avg: 7.25 | grad norm last: 8.12 | 
2025-12-28T00:10:01 | step: 191600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.306771244155243e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.44 | consumed tokens: 98099200.0 | grad norm avg: 7.34 | grad norm last: 6.52 | 
2025-12-28T00:10:03 | step: 191700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.306027641287073e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.92 | consumed tokens: 98150400.0 | grad norm avg: 7.26 | grad norm last: 6.49 | 
2025-12-28T00:10:05 | step: 191800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.305282583227381e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.03 | consumed tokens: 98201600.0 | grad norm avg: 7.3 | grad norm last: 6.58 | 
2025-12-28T00:10:07 | step: 191900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.304537525167689e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.39 | consumed tokens: 98252800.0 | grad norm avg: 7.4 | grad norm last: 6.36 | 
2025-12-28T00:10:09 | step: 192000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.303792467107996e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.09 | consumed tokens: 98304000.0 | grad norm avg: 7.27 | grad norm last: 7.06 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_192000-seen_tokens_98304000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_192000-seen_tokens_98304000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_192000-seen_tokens_98304000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_192000-seen_tokens_98304000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_192000-seen_tokens_98304000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_192000-seen_tokens_98304000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_192000-seen_tokens_98304000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_192000-seen_tokens_98304000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:10:11 | step: 192100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.303045953856781e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.87 | train loss last: 3.59 | consumed tokens: 98355200.0 | grad norm avg: 7.51 | grad norm last: 6.89 | 
2025-12-28T00:10:13 | step: 192200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.302300168201327e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.91 | consumed tokens: 98406400.0 | grad norm avg: 7.12 | grad norm last: 6.73 | 
2025-12-28T00:10:15 | step: 192300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.301552927354351e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.56 | consumed tokens: 98457600.0 | grad norm avg: 7.12 | grad norm last: 6.44 | 
2025-12-28T00:10:17 | step: 192400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 9.300806414103135e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.91 | consumed tokens: 98508800.0 | grad norm avg: 7.26 | grad norm last: 7.02 | 
2025-12-28T00:10:19 | step: 192500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 9.300059173256159e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.04 | train loss last: 4.0 | consumed tokens: 98560000.0 | grad norm avg: 7.73 | grad norm last: 6.08 | 
2025-12-28T00:10:21 | step: 192600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.299311204813421e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 5.16 | consumed tokens: 98611200.0 | grad norm avg: 7.5 | grad norm last: 13.92 | 
2025-12-28T00:10:23 | step: 192700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.298563236370683e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.53 | consumed tokens: 98662400.0 | grad norm avg: 8.02 | grad norm last: 7.99 | 
2025-12-28T00:10:26 | step: 192800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 9.297815267927945e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.39 | consumed tokens: 98713600.0 | grad norm avg: 7.4 | grad norm last: 8.08 | 
2025-12-28T00:10:28 | step: 192900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 9.297066571889445e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.69 | consumed tokens: 98764800.0 | grad norm avg: 7.51 | grad norm last: 8.19 | 
2025-12-28T00:10:30 | step: 193000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.296317148255184e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.95 | consumed tokens: 98816000.0 | grad norm avg: 7.35 | grad norm last: 7.65 | 
2025-12-28T00:10:32 | step: 193100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.295567724620923e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.8 | consumed tokens: 98867200.0 | grad norm avg: 7.7 | grad norm last: 6.78 | 
2025-12-28T00:10:34 | step: 193200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.294817573390901e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.94 | consumed tokens: 98918400.0 | grad norm avg: 7.92 | grad norm last: 6.9 | 
2025-12-28T00:10:36 | step: 193300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.294067422160879e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.47 | consumed tokens: 98969600.0 | grad norm avg: 7.34 | grad norm last: 8.16 | 
2025-12-28T00:10:38 | step: 193400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.293316543335095e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.78 | consumed tokens: 99020800.0 | grad norm avg: 7.48 | grad norm last: 7.55 | 
2025-12-28T00:10:40 | step: 193500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.292565664509311e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.53 | consumed tokens: 99072000.0 | grad norm avg: 7.48 | grad norm last: 9.01 | 
2025-12-28T00:10:42 | step: 193600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.291814785683528e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.06 | consumed tokens: 99123200.0 | grad norm avg: 7.47 | grad norm last: 6.37 | 
2025-12-28T00:10:44 | step: 193700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.291063179261982e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.16 | consumed tokens: 99174400.0 | grad norm avg: 7.46 | grad norm last: 7.44 | 
2025-12-28T00:10:46 | step: 193800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.290311572840437e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.31 | consumed tokens: 99225600.0 | grad norm avg: 7.43 | grad norm last: 7.23 | 
2025-12-28T00:10:48 | step: 193900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.289558511227369e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.75 | consumed tokens: 99276800.0 | grad norm avg: 7.62 | grad norm last: 6.94 | 
2025-12-28T00:10:50 | step: 194000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.288805449614301e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.16 | consumed tokens: 99328000.0 | grad norm avg: 7.34 | grad norm last: 6.71 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_194000-seen_tokens_99328000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_194000-seen_tokens_99328000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_194000-seen_tokens_99328000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_194000-seen_tokens_99328000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_194000-seen_tokens_99328000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_194000-seen_tokens_99328000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_194000-seen_tokens_99328000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_194000-seen_tokens_99328000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:10:52 | step: 194100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.288053115596995e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.78 | consumed tokens: 99379200.0 | grad norm avg: 7.51 | grad norm last: 6.57 | 
2025-12-28T00:10:54 | step: 194200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.287299326388165e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.83 | consumed tokens: 99430400.0 | grad norm avg: 7.92 | grad norm last: 7.63 | 
2025-12-28T00:10:56 | step: 194300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.286545537179336e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.86 | consumed tokens: 99481600.0 | grad norm avg: 7.59 | grad norm last: 7.93 | 
2025-12-28T00:10:58 | step: 194400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.285790292778984e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.16 | consumed tokens: 99532800.0 | grad norm avg: 7.46 | grad norm last: 9.2 | 
2025-12-28T00:11:00 | step: 194500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.285036503570154e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.38 | consumed tokens: 99584000.0 | grad norm avg: 7.45 | grad norm last: 8.24 | 
2025-12-28T00:11:02 | step: 194600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.284281986765563e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.44 | consumed tokens: 99635200.0 | grad norm avg: 7.63 | grad norm last: 6.84 | 
2025-12-28T00:11:04 | step: 194700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.28352601476945e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.62 | consumed tokens: 99686400.0 | grad norm avg: 7.89 | grad norm last: 7.47 | 
2025-12-28T00:11:06 | step: 194800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.282770770369098e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.0 | consumed tokens: 99737600.0 | grad norm avg: 7.88 | grad norm last: 8.83 | 
2025-12-28T00:11:08 | step: 194900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.282014798372984e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.88 | consumed tokens: 99788800.0 | grad norm avg: 7.77 | grad norm last: 7.54 | 
2025-12-28T00:11:10 | step: 195000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.281258098781109e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.05 | consumed tokens: 99840000.0 | grad norm avg: 7.36 | grad norm last: 5.84 | 
2025-12-28T00:11:12 | step: 195100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.280501399189234e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.16 | consumed tokens: 99891200.0 | grad norm avg: 7.83 | grad norm last: 9.08 | 
2025-12-28T00:11:14 | step: 195200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.279743972001597e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.05 | train loss last: 4.06 | consumed tokens: 99942400.0 | grad norm avg: 8.2 | grad norm last: 7.18 | 
2025-12-28T00:11:16 | step: 195300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.2789858172182e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.22 | consumed tokens: 99993600.0 | grad norm avg: 7.68 | grad norm last: 9.26 | 
2025-12-28T00:11:18 | step: 195400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.278229117626324e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.0 | consumed tokens: 100044800.0 | grad norm avg: 7.7 | grad norm last: 6.95 | 
2025-12-28T00:11:20 | step: 195500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.277470962842926e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.47 | consumed tokens: 100096000.0 | grad norm avg: 7.5 | grad norm last: 8.67 | 
2025-12-28T00:11:22 | step: 195600 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.276712080463767e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.28 | consumed tokens: 100147200.0 | grad norm avg: 7.6 | grad norm last: 9.24 | 
2025-12-28T00:11:24 | step: 195700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.275953198084608e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.34 | consumed tokens: 100198400.0 | grad norm avg: 7.75 | grad norm last: 8.33 | 
2025-12-28T00:11:26 | step: 195800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.275193588109687e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.72 | consumed tokens: 100249600.0 | grad norm avg: 7.68 | grad norm last: 7.22 | 
2025-12-28T00:11:28 | step: 195900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.274433978134766e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.25 | consumed tokens: 100300800.0 | grad norm avg: 7.71 | grad norm last: 6.92 | 
2025-12-28T00:11:30 | step: 196000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.273674368159845e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.8 | consumed tokens: 100352000.0 | grad norm avg: 7.54 | grad norm last: 6.58 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_196000-seen_tokens_100352000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_196000-seen_tokens_100352000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_196000-seen_tokens_100352000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_196000-seen_tokens_100352000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_196000-seen_tokens_100352000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_196000-seen_tokens_100352000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_196000-seen_tokens_100352000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_196000-seen_tokens_100352000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:11:33 | step: 196100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.272914030589163e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.91 | train loss last: 3.12 | consumed tokens: 100403200.0 | grad norm avg: 7.55 | grad norm last: 6.78 | 
2025-12-28T00:11:35 | step: 196200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.272152237826958e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.69 | consumed tokens: 100454400.0 | grad norm avg: 7.3 | grad norm last: 6.39 | 
2025-12-28T00:11:37 | step: 196300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.271391900256276e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 4.53 | consumed tokens: 100505600.0 | grad norm avg: 7.75 | grad norm last: 10.67 | 
2025-12-28T00:11:39 | step: 196400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.270630107494071e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.33 | consumed tokens: 100556800.0 | grad norm avg: 7.53 | grad norm last: 6.67 | 
2025-12-28T00:11:41 | step: 196500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.269869042327628e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.38 | consumed tokens: 100608000.0 | grad norm avg: 7.46 | grad norm last: 6.05 | 
2025-12-28T00:11:43 | step: 196600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.269106521969661e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.73 | consumed tokens: 100659200.0 | grad norm avg: 7.48 | grad norm last: 7.31 | 
2025-12-28T00:11:45 | step: 196700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.268344001611695e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.67 | consumed tokens: 100710400.0 | grad norm avg: 7.54 | grad norm last: 6.62 | 
2025-12-28T00:11:47 | step: 196800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.267581481253728e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.77 | consumed tokens: 100761600.0 | grad norm avg: 7.6 | grad norm last: 6.57 | 
2025-12-28T00:11:49 | step: 196900 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.266817505704239e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.92 | consumed tokens: 100812800.0 | grad norm avg: 7.43 | grad norm last: 6.9 | 
2025-12-28T00:11:51 | step: 197000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.26605353015475e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.98 | consumed tokens: 100864000.0 | grad norm avg: 7.66 | grad norm last: 6.86 | 
2025-12-28T00:11:53 | step: 197100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.26528955460526e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.78 | consumed tokens: 100915200.0 | grad norm avg: 7.35 | grad norm last: 7.19 | 
2025-12-28T00:11:55 | step: 197200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.264525579055771e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 2.89 | consumed tokens: 100966400.0 | grad norm avg: 7.46 | grad norm last: 6.37 | 
2025-12-28T00:11:57 | step: 197300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.26376087591052e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.22 | consumed tokens: 101017600.0 | grad norm avg: 7.66 | grad norm last: 6.2 | 
2025-12-28T00:11:59 | step: 197400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.262995445169508e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.06 | consumed tokens: 101068800.0 | grad norm avg: 7.38 | grad norm last: 5.98 | 
2025-12-28T00:12:01 | step: 197500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 9.262230014428496e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.83 | consumed tokens: 101120000.0 | grad norm avg: 7.48 | grad norm last: 6.64 | 
2025-12-28T00:12:03 | step: 197600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.261463856091723e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.52 | consumed tokens: 101171200.0 | grad norm avg: 8.01 | grad norm last: 6.68 | 
2025-12-28T00:12:05 | step: 197700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.260696970159188e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.09 | consumed tokens: 101222400.0 | grad norm avg: 7.41 | grad norm last: 7.21 | 
2025-12-28T00:12:07 | step: 197800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.259931539418176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.98 | consumed tokens: 101273600.0 | grad norm avg: 7.66 | grad norm last: 6.91 | 
2025-12-28T00:12:09 | step: 197900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.259164653485641e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 5.0 | consumed tokens: 101324800.0 | grad norm avg: 7.79 | grad norm last: 16.73 | 
2025-12-28T00:12:11 | step: 198000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.258397039957345e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.28 | consumed tokens: 101376000.0 | grad norm avg: 7.91 | grad norm last: 7.09 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_198000-seen_tokens_101376000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_198000-seen_tokens_101376000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_198000-seen_tokens_101376000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_198000-seen_tokens_101376000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_198000-seen_tokens_101376000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_198000-seen_tokens_101376000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_198000-seen_tokens_101376000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_198000-seen_tokens_101376000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:12:13 | step: 198100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.257629426429048e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.94 | train loss last: 3.95 | consumed tokens: 101427200.0 | grad norm avg: 7.7 | grad norm last: 7.69 | 
2025-12-28T00:12:15 | step: 198200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 9.25686108530499e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.52 | consumed tokens: 101478400.0 | grad norm avg: 7.61 | grad norm last: 7.4 | 
2025-12-28T00:12:17 | step: 198300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.256092744180933e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.01 | train loss last: 4.0 | consumed tokens: 101529600.0 | grad norm avg: 7.81 | grad norm last: 8.08 | 
2025-12-28T00:12:19 | step: 198400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.255324403056875e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.66 | consumed tokens: 101580800.0 | grad norm avg: 7.85 | grad norm last: 6.58 | 
2025-12-28T00:12:21 | step: 198500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.254555334337056e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.72 | consumed tokens: 101632000.0 | grad norm avg: 7.61 | grad norm last: 7.71 | 
2025-12-28T00:12:23 | step: 198600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.253786265617236e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.75 | consumed tokens: 101683200.0 | grad norm avg: 7.82 | grad norm last: 8.04 | 
2025-12-28T00:12:25 | step: 198700 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.253016469301656e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.06 | consumed tokens: 101734400.0 | grad norm avg: 7.53 | grad norm last: 9.55 | 
2025-12-28T00:12:27 | step: 198800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.252245217794552e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.64 | consumed tokens: 101785600.0 | grad norm avg: 7.51 | grad norm last: 8.13 | 
2025-12-28T00:12:29 | step: 198900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.251475421478972e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.03 | train loss last: 3.55 | consumed tokens: 101836800.0 | grad norm avg: 7.91 | grad norm last: 8.39 | 
2025-12-28T00:12:31 | step: 199000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.250704169971868e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.06 | consumed tokens: 101888000.0 | grad norm avg: 7.6 | grad norm last: 6.81 | 
2025-12-28T00:12:33 | step: 199100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.249932918464765e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.28 | consumed tokens: 101939200.0 | grad norm avg: 7.77 | grad norm last: 6.34 | 
2025-12-28T00:12:35 | step: 199200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.249161666957662e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.62 | consumed tokens: 101990400.0 | grad norm avg: 7.48 | grad norm last: 7.89 | 
2025-12-28T00:12:37 | step: 199300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.248390415450558e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.55 | consumed tokens: 102041600.0 | grad norm avg: 7.79 | grad norm last: 6.56 | 
2025-12-28T00:12:39 | step: 199400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.24761698115617e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.8 | consumed tokens: 102092800.0 | grad norm avg: 7.82 | grad norm last: 8.02 | 
2025-12-28T00:12:41 | step: 199500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.246843546861783e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.88 | consumed tokens: 102144000.0 | grad norm avg: 7.77 | grad norm last: 7.7 | 
2025-12-28T00:12:43 | step: 199600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.246071567758918e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 2.84 | consumed tokens: 102195200.0 | grad norm avg: 7.66 | grad norm last: 5.75 | 
2025-12-28T00:12:45 | step: 199700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.24529813346453e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.31 | consumed tokens: 102246400.0 | grad norm avg: 8.06 | grad norm last: 7.89 | 
2025-12-28T00:12:47 | step: 199800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.244525426765904e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.75 | consumed tokens: 102297600.0 | grad norm avg: 7.76 | grad norm last: 13.58 | 
2025-12-28T00:12:49 | step: 199900 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.243751264875755e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.66 | consumed tokens: 102348800.0 | grad norm avg: 7.64 | grad norm last: 6.29 | 
2025-12-28T00:12:51 | step: 200000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.242975647794083e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.16 | consumed tokens: 102400000.0 | grad norm avg: 7.7 | grad norm last: 6.29 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_200000-seen_tokens_102400000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_200000-seen_tokens_102400000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_200000-seen_tokens_102400000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_200000-seen_tokens_102400000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_200000-seen_tokens_102400000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_200000-seen_tokens_102400000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_200000-seen_tokens_102400000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_200000-seen_tokens_102400000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:12:54 | step: 200100 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.242200758308172e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.88 | train loss last: 3.81 | consumed tokens: 102451200.0 | grad norm avg: 7.58 | grad norm last: 7.07 | 
2025-12-28T00:12:56 | step: 200200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.241425868822262e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.42 | consumed tokens: 102502400.0 | grad norm avg: 7.99 | grad norm last: 6.9 | 
2025-12-28T00:12:58 | step: 200300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.24065025174059e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.53 | consumed tokens: 102553600.0 | grad norm avg: 7.56 | grad norm last: 8.94 | 
2025-12-28T00:13:00 | step: 200400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.239874634658918e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.09 | consumed tokens: 102604800.0 | grad norm avg: 7.85 | grad norm last: 8.6 | 
2025-12-28T00:13:02 | step: 200500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.239097562385723e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.84 | consumed tokens: 102656000.0 | grad norm avg: 7.88 | grad norm last: 8.55 | 
2025-12-28T00:13:04 | step: 200600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.23832121770829e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 2.92 | consumed tokens: 102707200.0 | grad norm avg: 7.68 | grad norm last: 6.17 | 
2025-12-28T00:13:06 | step: 200700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.237544145435095e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.28 | consumed tokens: 102758400.0 | grad norm avg: 7.64 | grad norm last: 8.07 | 
2025-12-28T00:13:08 | step: 200800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.2367670731619e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.12 | consumed tokens: 102809600.0 | grad norm avg: 7.62 | grad norm last: 6.5 | 
2025-12-28T00:13:10 | step: 200900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.235989273292944e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.03 | consumed tokens: 102860800.0 | grad norm avg: 7.75 | grad norm last: 7.71 | 
2025-12-28T00:13:12 | step: 201000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.235210745828226e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.84 | consumed tokens: 102912000.0 | grad norm avg: 7.73 | grad norm last: 8.53 | 
2025-12-28T00:13:14 | step: 201100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.234432218363509e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 5.91 | consumed tokens: 102963200.0 | grad norm avg: 8.08 | grad norm last: 28.97 | 
2025-12-28T00:13:16 | step: 201200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.233653690898791e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.25 | consumed tokens: 103014400.0 | grad norm avg: 7.55 | grad norm last: 10.32 | 
2025-12-28T00:13:18 | step: 201300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.23287370824255e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 2.83 | consumed tokens: 103065600.0 | grad norm avg: 7.92 | grad norm last: 7.33 | 
2025-12-28T00:13:20 | step: 201400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.232095180777833e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.75 | consumed tokens: 103116800.0 | grad norm avg: 7.85 | grad norm last: 6.62 | 
2025-12-28T00:13:22 | step: 201500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.231315198121592e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.88 | consumed tokens: 103168000.0 | grad norm avg: 7.73 | grad norm last: 8.22 | 
2025-12-28T00:13:24 | step: 201600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.230533760273829e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.78 | consumed tokens: 103219200.0 | grad norm avg: 7.98 | grad norm last: 6.97 | 
2025-12-28T00:13:26 | step: 201700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.229753777617589e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.62 | consumed tokens: 103270400.0 | grad norm avg: 7.88 | grad norm last: 6.97 | 
2025-12-28T00:13:28 | step: 201800 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.228973067365587e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.25 | consumed tokens: 103321600.0 | grad norm avg: 7.93 | grad norm last: 11.05 | 
2025-12-28T00:13:30 | step: 201900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.228192357113585e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.5 | consumed tokens: 103372800.0 | grad norm avg: 8.14 | grad norm last: 8.02 | 
2025-12-28T00:13:32 | step: 202000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.22741019167006e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.47 | consumed tokens: 103424000.0 | grad norm avg: 7.61 | grad norm last: 6.76 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_202000-seen_tokens_103424000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_202000-seen_tokens_103424000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_202000-seen_tokens_103424000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_202000-seen_tokens_103424000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_202000-seen_tokens_103424000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_202000-seen_tokens_103424000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_202000-seen_tokens_103424000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_202000-seen_tokens_103424000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:13:34 | step: 202100 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.226628026226535e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.95 | train loss last: 3.95 | consumed tokens: 103475200.0 | grad norm avg: 7.96 | grad norm last: 6.31 | 
2025-12-28T00:13:36 | step: 202200 | train samples/s: 99.2 | train mfu (16-bit): -1.0 | lr mean: 9.225846588378772e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.59 | consumed tokens: 103526400.0 | grad norm avg: 7.98 | grad norm last: 7.94 | 
2025-12-28T00:13:38 | step: 202300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.225062240147963e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.92 | consumed tokens: 103577600.0 | grad norm avg: 7.59 | grad norm last: 7.64 | 
2025-12-28T00:13:40 | step: 202400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 9.2242808023002e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.09 | consumed tokens: 103628800.0 | grad norm avg: 7.86 | grad norm last: 7.31 | 
2025-12-28T00:13:42 | step: 202500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.223496454069391e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.72 | consumed tokens: 103680000.0 | grad norm avg: 7.71 | grad norm last: 8.36 | 
2025-12-28T00:13:44 | step: 202600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.222712833434343e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.33 | consumed tokens: 103731200.0 | grad norm avg: 7.59 | grad norm last: 6.32 | 
2025-12-28T00:13:46 | step: 202700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.221929212799296e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.78 | consumed tokens: 103782400.0 | grad norm avg: 7.68 | grad norm last: 6.9 | 
2025-12-28T00:13:48 | step: 202800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.221144136972725e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.48 | consumed tokens: 103833600.0 | grad norm avg: 8.1 | grad norm last: 6.9 | 
2025-12-28T00:13:50 | step: 202900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.220359061146155e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.61 | consumed tokens: 103884800.0 | grad norm avg: 8.31 | grad norm last: 7.56 | 
2025-12-28T00:13:52 | step: 203000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.219573257723823e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.03 | consumed tokens: 103936000.0 | grad norm avg: 7.58 | grad norm last: 8.19 | 
2025-12-28T00:13:55 | step: 203100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.218787454301491e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.06 | train loss last: 3.53 | consumed tokens: 103987200.0 | grad norm avg: 8.34 | grad norm last: 8.91 | 
2025-12-28T00:13:57 | step: 203200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 9.21800165087916e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.88 | consumed tokens: 104038400.0 | grad norm avg: 8.0 | grad norm last: 7.85 | 
2025-12-28T00:13:59 | step: 203300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.217215847456828e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.95 | consumed tokens: 104089600.0 | grad norm avg: 7.82 | grad norm last: 7.92 | 
2025-12-28T00:14:01 | step: 203400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.216429316438735e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.0 | consumed tokens: 104140800.0 | grad norm avg: 7.73 | grad norm last: 6.14 | 
2025-12-28T00:14:03 | step: 203500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.215642785420641e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.52 | consumed tokens: 104192000.0 | grad norm avg: 7.89 | grad norm last: 6.53 | 
2025-12-28T00:14:05 | step: 203600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.214854799211025e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.06 | consumed tokens: 104243200.0 | grad norm avg: 8.15 | grad norm last: 6.88 | 
2025-12-28T00:14:07 | step: 203700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.214066813001409e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 3.69 | consumed tokens: 104294400.0 | grad norm avg: 7.77 | grad norm last: 7.09 | 
2025-12-28T00:14:09 | step: 203800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.213279554387555e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.23 | consumed tokens: 104345600.0 | grad norm avg: 7.76 | grad norm last: 6.42 | 
2025-12-28T00:14:11 | step: 203900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.212489385390654e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.62 | consumed tokens: 104396800.0 | grad norm avg: 7.85 | grad norm last: 7.82 | 
2025-12-28T00:14:13 | step: 204000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.2117021267768e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.88 | consumed tokens: 104448000.0 | grad norm avg: 8.89 | grad norm last: 13.17 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_204000-seen_tokens_104448000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_204000-seen_tokens_104448000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_204000-seen_tokens_104448000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_204000-seen_tokens_104448000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_204000-seen_tokens_104448000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_204000-seen_tokens_104448000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_204000-seen_tokens_104448000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_204000-seen_tokens_104448000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:14:15 | step: 204100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.210911957779899e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.97 | consumed tokens: 104499200.0 | grad norm avg: 7.93 | grad norm last: 7.96 | 
2025-12-28T00:14:17 | step: 204200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.21012251637876e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.5 | consumed tokens: 104550400.0 | grad norm avg: 7.9 | grad norm last: 7.77 | 
2025-12-28T00:14:19 | step: 204300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.209333074977621e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.59 | consumed tokens: 104601600.0 | grad norm avg: 8.33 | grad norm last: 7.53 | 
2025-12-28T00:14:21 | step: 204400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.20854217838496e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.59 | consumed tokens: 104652800.0 | grad norm avg: 8.28 | grad norm last: 6.83 | 
2025-12-28T00:14:23 | step: 204500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.207751281792298e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 4.22 | consumed tokens: 104704000.0 | grad norm avg: 7.9 | grad norm last: 9.27 | 
2025-12-28T00:14:25 | step: 204600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.206961112795398e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.31 | consumed tokens: 104755200.0 | grad norm avg: 8.06 | grad norm last: 6.73 | 
2025-12-28T00:14:27 | step: 204700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.206169488606974e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.45 | consumed tokens: 104806400.0 | grad norm avg: 8.23 | grad norm last: 7.6 | 
2025-12-28T00:14:29 | step: 204800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.205377864418551e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.09 | consumed tokens: 104857600.0 | grad norm avg: 8.16 | grad norm last: 7.48 | 
2025-12-28T00:14:31 | step: 204900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.204584785038605e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.09 | consumed tokens: 104908800.0 | grad norm avg: 8.03 | grad norm last: 6.99 | 
2025-12-28T00:14:33 | step: 205000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.203793160850182e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.09 | consumed tokens: 104960000.0 | grad norm avg: 7.87 | grad norm last: 9.24 | 
2025-12-28T00:14:35 | step: 205100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.203000809065998e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.28 | consumed tokens: 105011200.0 | grad norm avg: 7.78 | grad norm last: 8.85 | 
2025-12-28T00:14:37 | step: 205200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.202208457281813e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.52 | consumed tokens: 105062400.0 | grad norm avg: 7.91 | grad norm last: 6.84 | 
2025-12-28T00:14:39 | step: 205300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.201413922710344e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.05 | consumed tokens: 105113600.0 | grad norm avg: 7.75 | grad norm last: 6.26 | 
2025-12-28T00:14:41 | step: 205400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.200620115734637e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.73 | consumed tokens: 105164800.0 | grad norm avg: 8.04 | grad norm last: 7.27 | 
2025-12-28T00:14:43 | step: 205500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.19982630875893e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.12 | consumed tokens: 105216000.0 | grad norm avg: 8.17 | grad norm last: 8.0 | 
2025-12-28T00:14:45 | step: 205600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.19903177418746e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.75 | consumed tokens: 105267200.0 | grad norm avg: 8.41 | grad norm last: 9.59 | 
2025-12-28T00:14:47 | step: 205700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.19823651202023e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.75 | consumed tokens: 105318400.0 | grad norm avg: 8.13 | grad norm last: 8.38 | 
2025-12-28T00:14:49 | step: 205800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.197441249853e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.75 | consumed tokens: 105369600.0 | grad norm avg: 7.95 | grad norm last: 7.49 | 
2025-12-28T00:14:51 | step: 205900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.196645260090008e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.25 | consumed tokens: 105420800.0 | grad norm avg: 8.06 | grad norm last: 6.98 | 
2025-12-28T00:14:53 | step: 206000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.195849997922778e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.22 | consumed tokens: 105472000.0 | grad norm avg: 7.94 | grad norm last: 7.43 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_206000-seen_tokens_105472000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_206000-seen_tokens_105472000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_206000-seen_tokens_105472000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_206000-seen_tokens_105472000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_206000-seen_tokens_105472000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_206000-seen_tokens_105472000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_206000-seen_tokens_105472000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_206000-seen_tokens_105472000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:14:56 | step: 206100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.195053280564025e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.92 | train loss last: 3.98 | consumed tokens: 105523200.0 | grad norm avg: 8.12 | grad norm last: 6.8 | 
2025-12-28T00:14:58 | step: 206200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.194257290801033e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.88 | consumed tokens: 105574400.0 | grad norm avg: 7.64 | grad norm last: 8.02 | 
2025-12-28T00:15:00 | step: 206300 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.193459845846519e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.58 | consumed tokens: 105625600.0 | grad norm avg: 8.05 | grad norm last: 6.81 | 
2025-12-28T00:15:02 | step: 206400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.192662400892004e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.58 | consumed tokens: 105676800.0 | grad norm avg: 7.86 | grad norm last: 6.88 | 
2025-12-28T00:15:04 | step: 206500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.19186495593749e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.27 | consumed tokens: 105728000.0 | grad norm avg: 7.74 | grad norm last: 7.95 | 
2025-12-28T00:15:06 | step: 206600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.191067510982975e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.91 | consumed tokens: 105779200.0 | grad norm avg: 7.96 | grad norm last: 6.83 | 
2025-12-28T00:15:08 | step: 206700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.190267883241177e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.47 | consumed tokens: 105830400.0 | grad norm avg: 8.0 | grad norm last: 9.72 | 
2025-12-28T00:15:10 | step: 206800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.189468255499378e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.53 | consumed tokens: 105881600.0 | grad norm avg: 7.82 | grad norm last: 9.18 | 
2025-12-28T00:15:12 | step: 206900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.188670082949102e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.69 | consumed tokens: 105932800.0 | grad norm avg: 7.6 | grad norm last: 6.74 | 
2025-12-28T00:15:14 | step: 207000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.187870455207303e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.03 | consumed tokens: 105984000.0 | grad norm avg: 7.97 | grad norm last: 7.2 | 
2025-12-28T00:15:16 | step: 207100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 9.187070099869743e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 6.19 | consumed tokens: 106035200.0 | grad norm avg: 8.14 | grad norm last: 25.73 | 
2025-12-28T00:15:18 | step: 207200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 9.186271199723706e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.92 | consumed tokens: 106086400.0 | grad norm avg: 7.65 | grad norm last: 7.94 | 
2025-12-28T00:15:20 | step: 207300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.185469389194623e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.78 | consumed tokens: 106137600.0 | grad norm avg: 7.88 | grad norm last: 7.91 | 
2025-12-28T00:15:22 | step: 207400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.184669033857062e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.39 | consumed tokens: 106188800.0 | grad norm avg: 7.8 | grad norm last: 7.42 | 
2025-12-28T00:15:24 | step: 207500 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.183867950923741e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.38 | consumed tokens: 106240000.0 | grad norm avg: 7.81 | grad norm last: 6.91 | 
2025-12-28T00:15:26 | step: 207600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.183065412798896e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.8 | consumed tokens: 106291200.0 | grad norm avg: 7.7 | grad norm last: 6.53 | 
2025-12-28T00:15:28 | step: 207700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.182263602269813e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.66 | consumed tokens: 106342400.0 | grad norm avg: 8.41 | grad norm last: 6.32 | 
2025-12-28T00:15:30 | step: 207800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.18146179174073e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.28 | consumed tokens: 106393600.0 | grad norm avg: 7.89 | grad norm last: 6.28 | 
2025-12-28T00:15:32 | step: 207900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 9.180659981211647e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.59 | consumed tokens: 106444800.0 | grad norm avg: 7.7 | grad norm last: 7.11 | 
2025-12-28T00:15:34 | step: 208000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 9.179856715491042e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.77 | consumed tokens: 106496000.0 | grad norm avg: 8.18 | grad norm last: 7.48 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_208000-seen_tokens_106496000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_208000-seen_tokens_106496000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_208000-seen_tokens_106496000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_208000-seen_tokens_106496000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_208000-seen_tokens_106496000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_208000-seen_tokens_106496000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_208000-seen_tokens_106496000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_208000-seen_tokens_106496000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:15:36 | step: 208100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.179053449770436e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.8 | train loss last: 4.03 | consumed tokens: 106547200.0 | grad norm avg: 8.0 | grad norm last: 9.57 | 
2025-12-28T00:15:38 | step: 208200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.178248728858307e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.09 | consumed tokens: 106598400.0 | grad norm avg: 7.91 | grad norm last: 7.25 | 
2025-12-28T00:15:40 | step: 208300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.17744473554194e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.8 | consumed tokens: 106649600.0 | grad norm avg: 7.5 | grad norm last: 7.51 | 
2025-12-28T00:15:42 | step: 208400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.17663928703405e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.44 | consumed tokens: 106700800.0 | grad norm avg: 7.87 | grad norm last: 6.76 | 
2025-12-28T00:15:44 | step: 208500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.175835293717682e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.8 | consumed tokens: 106752000.0 | grad norm avg: 7.51 | grad norm last: 6.84 | 
2025-12-28T00:15:46 | step: 208600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.175029845209792e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.16 | consumed tokens: 106803200.0 | grad norm avg: 7.66 | grad norm last: 6.97 | 
2025-12-28T00:15:48 | step: 208700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.174223669106141e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 4.56 | consumed tokens: 106854400.0 | grad norm avg: 8.29 | grad norm last: 8.52 | 
2025-12-28T00:15:50 | step: 208800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.173418948194012e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 2.95 | consumed tokens: 106905600.0 | grad norm avg: 7.72 | grad norm last: 6.34 | 
2025-12-28T00:15:52 | step: 208900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.172611316898838e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.78 | consumed tokens: 106956800.0 | grad norm avg: 7.98 | grad norm last: 10.49 | 
2025-12-28T00:15:54 | step: 209000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.171806595986709e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.97 | consumed tokens: 107008000.0 | grad norm avg: 7.72 | grad norm last: 9.76 | 
2025-12-28T00:15:56 | step: 209100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 9.170998964691535e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.09 | consumed tokens: 107059200.0 | grad norm avg: 7.85 | grad norm last: 9.19 | 
2025-12-28T00:15:58 | step: 209200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.17019133339636e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.33 | consumed tokens: 107110400.0 | grad norm avg: 7.6 | grad norm last: 6.05 | 
2025-12-28T00:16:00 | step: 209300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.169383702101186e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.12 | consumed tokens: 107161600.0 | grad norm avg: 7.83 | grad norm last: 7.4 | 
2025-12-28T00:16:02 | step: 209400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.168576070806012e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.06 | consumed tokens: 107212800.0 | grad norm avg: 8.14 | grad norm last: 7.05 | 
2025-12-28T00:16:04 | step: 209500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.167767711915076e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.69 | consumed tokens: 107264000.0 | grad norm avg: 7.97 | grad norm last: 7.75 | 
2025-12-28T00:16:06 | step: 209600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.166958625428379e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.16 | consumed tokens: 107315200.0 | grad norm avg: 7.74 | grad norm last: 8.8 | 
2025-12-28T00:16:08 | step: 209700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.166149538941681e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.19 | consumed tokens: 107366400.0 | grad norm avg: 7.53 | grad norm last: 6.51 | 
2025-12-28T00:16:10 | step: 209800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.165340452454984e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.5 | consumed tokens: 107417600.0 | grad norm avg: 7.78 | grad norm last: 7.8 | 
2025-12-28T00:16:12 | step: 209900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.164530638372526e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.2 | consumed tokens: 107468800.0 | grad norm avg: 7.68 | grad norm last: 6.33 | 
2025-12-28T00:16:14 | step: 210000 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.163720096694306e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.81 | consumed tokens: 107520000.0 | grad norm avg: 8.04 | grad norm last: 6.9 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_210000-seen_tokens_107520000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_210000-seen_tokens_107520000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_210000-seen_tokens_107520000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_210000-seen_tokens_107520000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_210000-seen_tokens_107520000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_210000-seen_tokens_107520000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_210000-seen_tokens_107520000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_210000-seen_tokens_107520000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:16:17 | step: 210100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.162910282611847e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.83 | train loss last: 4.41 | consumed tokens: 107571200.0 | grad norm avg: 7.49 | grad norm last: 7.05 | 
2025-12-28T00:16:19 | step: 210200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.162099013337865e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.56 | consumed tokens: 107622400.0 | grad norm avg: 7.72 | grad norm last: 8.15 | 
2025-12-28T00:16:21 | step: 210300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.161288471659645e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.81 | consumed tokens: 107673600.0 | grad norm avg: 7.61 | grad norm last: 6.6 | 
2025-12-28T00:16:23 | step: 210400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.160476474789903e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.27 | consumed tokens: 107724800.0 | grad norm avg: 7.53 | grad norm last: 6.88 | 
2025-12-28T00:16:25 | step: 210500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.15966447792016e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 2.98 | consumed tokens: 107776000.0 | grad norm avg: 7.45 | grad norm last: 6.33 | 
2025-12-28T00:16:27 | step: 210600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.158852481050417e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.61 | consumed tokens: 107827200.0 | grad norm avg: 7.6 | grad norm last: 6.64 | 
2025-12-28T00:16:29 | step: 210700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.158040484180674e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.44 | consumed tokens: 107878400.0 | grad norm avg: 8.12 | grad norm last: 9.73 | 
2025-12-28T00:16:31 | step: 210800 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.157227032119408e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.69 | consumed tokens: 107929600.0 | grad norm avg: 7.49 | grad norm last: 7.74 | 
2025-12-28T00:16:33 | step: 210900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.156413580058143e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.78 | consumed tokens: 107980800.0 | grad norm avg: 7.62 | grad norm last: 9.24 | 
2025-12-28T00:16:35 | step: 211000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.155600127996877e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.2 | consumed tokens: 108032000.0 | grad norm avg: 7.61 | grad norm last: 6.47 | 
2025-12-28T00:16:37 | step: 211100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.154786675935611e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.73 | consumed tokens: 108083200.0 | grad norm avg: 8.01 | grad norm last: 7.57 | 
2025-12-28T00:16:39 | step: 211200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.153971768682823e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.31 | consumed tokens: 108134400.0 | grad norm avg: 8.03 | grad norm last: 7.97 | 
2025-12-28T00:16:41 | step: 211300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.153156861430034e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.72 | consumed tokens: 108185600.0 | grad norm avg: 7.73 | grad norm last: 6.58 | 
2025-12-28T00:16:43 | step: 211400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.152341954177245e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.58 | consumed tokens: 108236800.0 | grad norm avg: 8.0 | grad norm last: 6.35 | 
2025-12-28T00:16:45 | step: 211500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.151527046924457e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.34 | consumed tokens: 108288000.0 | grad norm avg: 7.8 | grad norm last: 9.94 | 
2025-12-28T00:16:47 | step: 211600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.150710684480146e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.16 | consumed tokens: 108339200.0 | grad norm avg: 8.01 | grad norm last: 7.28 | 
2025-12-28T00:16:49 | step: 211700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.149894322035834e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.47 | consumed tokens: 108390400.0 | grad norm avg: 7.6 | grad norm last: 7.42 | 
2025-12-28T00:16:51 | step: 211800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.149077959591523e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.88 | consumed tokens: 108441600.0 | grad norm avg: 7.64 | grad norm last: 12.81 | 
2025-12-28T00:16:53 | step: 211900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.148261597147211e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.25 | consumed tokens: 108492800.0 | grad norm avg: 7.89 | grad norm last: 6.42 | 
2025-12-28T00:16:55 | step: 212000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.147443779511377e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.89 | consumed tokens: 108544000.0 | grad norm avg: 7.93 | grad norm last: 8.49 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_212000-seen_tokens_108544000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_212000-seen_tokens_108544000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_212000-seen_tokens_108544000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_212000-seen_tokens_108544000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_212000-seen_tokens_108544000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_212000-seen_tokens_108544000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_212000-seen_tokens_108544000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_212000-seen_tokens_108544000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:16:57 | step: 212100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.146626689471304e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.83 | train loss last: 2.94 | consumed tokens: 108595200.0 | grad norm avg: 7.43 | grad norm last: 7.06 | 
2025-12-28T00:16:59 | step: 212200 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.14580887183547e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.23 | consumed tokens: 108646400.0 | grad norm avg: 7.71 | grad norm last: 6.13 | 
2025-12-28T00:17:01 | step: 212300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.144990326603875e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.52 | consumed tokens: 108697600.0 | grad norm avg: 8.0 | grad norm last: 7.0 | 
2025-12-28T00:17:03 | step: 212400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 9.144171053776518e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.47 | consumed tokens: 108748800.0 | grad norm avg: 7.69 | grad norm last: 9.36 | 
2025-12-28T00:17:05 | step: 212500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 9.143353236140683e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.3 | consumed tokens: 108800000.0 | grad norm avg: 7.67 | grad norm last: 6.79 | 
2025-12-28T00:17:07 | step: 212600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.142533963313326e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.61 | consumed tokens: 108851200.0 | grad norm avg: 7.62 | grad norm last: 6.53 | 
2025-12-28T00:17:09 | step: 212700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.141713962890208e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.47 | consumed tokens: 108902400.0 | grad norm avg: 7.52 | grad norm last: 6.55 | 
2025-12-28T00:17:11 | step: 212800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.140893962467089e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.5 | consumed tokens: 108953600.0 | grad norm avg: 7.82 | grad norm last: 6.66 | 
2025-12-28T00:17:13 | step: 212900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.14007323444821e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.86 | consumed tokens: 109004800.0 | grad norm avg: 7.86 | grad norm last: 7.32 | 
2025-12-28T00:17:15 | step: 213000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.13925250642933e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.89 | consumed tokens: 109056000.0 | grad norm avg: 7.58 | grad norm last: 7.46 | 
2025-12-28T00:17:17 | step: 213100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.13843177841045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.75 | consumed tokens: 109107200.0 | grad norm avg: 7.84 | grad norm last: 7.72 | 
2025-12-28T00:17:20 | step: 213200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 9.13761105039157e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.69 | consumed tokens: 109158400.0 | grad norm avg: 7.67 | grad norm last: 7.99 | 
2025-12-28T00:17:22 | step: 213300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.136788867181167e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.22 | consumed tokens: 109209600.0 | grad norm avg: 7.82 | grad norm last: 8.42 | 
2025-12-28T00:17:24 | step: 213400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.135968139162287e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.92 | consumed tokens: 109260800.0 | grad norm avg: 7.73 | grad norm last: 7.69 | 
2025-12-28T00:17:26 | step: 213500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.135144500760362e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.52 | consumed tokens: 109312000.0 | grad norm avg: 7.9 | grad norm last: 7.06 | 
2025-12-28T00:17:28 | step: 213600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.134322317549959e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.09 | consumed tokens: 109363200.0 | grad norm avg: 7.6 | grad norm last: 9.07 | 
2025-12-28T00:17:30 | step: 213700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.133498679148033e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.84 | consumed tokens: 109414400.0 | grad norm avg: 7.83 | grad norm last: 7.64 | 
2025-12-28T00:17:32 | step: 213800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.132675040746108e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 5.41 | consumed tokens: 109465600.0 | grad norm avg: 7.73 | grad norm last: 14.28 | 
2025-12-28T00:17:34 | step: 213900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.131851402344182e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.44 | consumed tokens: 109516800.0 | grad norm avg: 7.49 | grad norm last: 10.13 | 
2025-12-28T00:17:36 | step: 214000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.131027763942257e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 5.03 | consumed tokens: 109568000.0 | grad norm avg: 7.82 | grad norm last: 10.78 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_214000-seen_tokens_109568000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_214000-seen_tokens_109568000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_214000-seen_tokens_109568000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_214000-seen_tokens_109568000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_214000-seen_tokens_109568000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_214000-seen_tokens_109568000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_214000-seen_tokens_109568000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_214000-seen_tokens_109568000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:17:38 | step: 214100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.130202670348808e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.0 | consumed tokens: 109619200.0 | grad norm avg: 8.84 | grad norm last: 7.83 | 
2025-12-28T00:17:40 | step: 214200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.129379031946883e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.56 | consumed tokens: 109670400.0 | grad norm avg: 7.66 | grad norm last: 9.14 | 
2025-12-28T00:17:42 | step: 214300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.128553210757673e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.19 | consumed tokens: 109721600.0 | grad norm avg: 7.74 | grad norm last: 9.4 | 
2025-12-28T00:17:44 | step: 214400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.127727389568463e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.19 | consumed tokens: 109772800.0 | grad norm avg: 7.86 | grad norm last: 10.21 | 
2025-12-28T00:17:46 | step: 214500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.126900840783492e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.38 | consumed tokens: 109824000.0 | grad norm avg: 7.94 | grad norm last: 6.91 | 
2025-12-28T00:17:48 | step: 214600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.12607429199852e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.5 | consumed tokens: 109875200.0 | grad norm avg: 7.7 | grad norm last: 6.45 | 
2025-12-28T00:17:50 | step: 214700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.125247743213549e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.61 | consumed tokens: 109926400.0 | grad norm avg: 7.84 | grad norm last: 6.62 | 
2025-12-28T00:17:52 | step: 214800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.124421194428578e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.06 | consumed tokens: 109977600.0 | grad norm avg: 7.44 | grad norm last: 7.26 | 
2025-12-28T00:17:54 | step: 214900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.123594645643607e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 5.97 | consumed tokens: 110028800.0 | grad norm avg: 7.74 | grad norm last: 11.71 | 
2025-12-28T00:17:56 | step: 215000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.122766641667113e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.8 | consumed tokens: 110080000.0 | grad norm avg: 7.57 | grad norm last: 8.02 | 
2025-12-28T00:17:58 | step: 215100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.121938637690619e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.84 | consumed tokens: 110131200.0 | grad norm avg: 7.96 | grad norm last: 8.1 | 
2025-12-28T00:18:00 | step: 215200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.121110633714125e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 5.06 | consumed tokens: 110182400.0 | grad norm avg: 7.88 | grad norm last: 6.95 | 
2025-12-28T00:18:02 | step: 215300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.120281902141869e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.02 | train loss last: 3.42 | consumed tokens: 110233600.0 | grad norm avg: 8.7 | grad norm last: 8.27 | 
2025-12-28T00:18:04 | step: 215400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.119452442973852e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.41 | consumed tokens: 110284800.0 | grad norm avg: 7.84 | grad norm last: 9.09 | 
2025-12-28T00:18:06 | step: 215500 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.118622983805835e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.19 | consumed tokens: 110336000.0 | grad norm avg: 8.29 | grad norm last: 7.37 | 
2025-12-28T00:18:08 | step: 215600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.117793524637818e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.39 | consumed tokens: 110387200.0 | grad norm avg: 7.81 | grad norm last: 7.39 | 
2025-12-28T00:18:10 | step: 215700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.11696333787404e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.89 | consumed tokens: 110438400.0 | grad norm avg: 7.71 | grad norm last: 7.36 | 
2025-12-28T00:18:12 | step: 215800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.1161324235145e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.41 | consumed tokens: 110489600.0 | grad norm avg: 8.26 | grad norm last: 6.76 | 
2025-12-28T00:18:14 | step: 215900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.115302236750722e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.06 | consumed tokens: 110540800.0 | grad norm avg: 7.59 | grad norm last: 6.8 | 
2025-12-28T00:18:16 | step: 216000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.114472049986944e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.73 | consumed tokens: 110592000.0 | grad norm avg: 8.16 | grad norm last: 8.34 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_216000-seen_tokens_110592000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_216000-seen_tokens_110592000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_216000-seen_tokens_110592000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_216000-seen_tokens_110592000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_216000-seen_tokens_110592000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_216000-seen_tokens_110592000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_216000-seen_tokens_110592000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_216000-seen_tokens_110592000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:18:19 | step: 216100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.113639680435881e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.96 | train loss last: 3.81 | consumed tokens: 110643200.0 | grad norm avg: 8.01 | grad norm last: 7.5 | 
2025-12-28T00:18:21 | step: 216200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.11280803848058e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.09 | consumed tokens: 110694400.0 | grad norm avg: 7.69 | grad norm last: 9.54 | 
2025-12-28T00:18:23 | step: 216300 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.111975668929517e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.78 | consumed tokens: 110745600.0 | grad norm avg: 7.89 | grad norm last: 8.79 | 
2025-12-28T00:18:25 | step: 216400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.111143299378455e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.48 | consumed tokens: 110796800.0 | grad norm avg: 8.03 | grad norm last: 6.48 | 
2025-12-28T00:18:27 | step: 216500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.110310202231631e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.47 | consumed tokens: 110848000.0 | grad norm avg: 7.73 | grad norm last: 7.2 | 
2025-12-28T00:18:29 | step: 216600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.109477832680568e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 5.06 | consumed tokens: 110899200.0 | grad norm avg: 8.08 | grad norm last: 7.29 | 
2025-12-28T00:18:31 | step: 216700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.108643280342221e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.34 | consumed tokens: 110950400.0 | grad norm avg: 7.83 | grad norm last: 6.08 | 
2025-12-28T00:18:33 | step: 216800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.107808728003874e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.75 | consumed tokens: 111001600.0 | grad norm avg: 8.54 | grad norm last: 9.11 | 
2025-12-28T00:18:35 | step: 216900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.10697563085705e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 5.75 | consumed tokens: 111052800.0 | grad norm avg: 7.85 | grad norm last: 7.71 | 
2025-12-28T00:18:37 | step: 217000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.106141078518704e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 5.41 | consumed tokens: 111104000.0 | grad norm avg: 8.29 | grad norm last: 11.85 | 
2025-12-28T00:18:39 | step: 217100 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.105305798584595e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.2 | consumed tokens: 111155200.0 | grad norm avg: 8.14 | grad norm last: 6.71 | 
2025-12-28T00:18:41 | step: 217200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.104470518650487e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.22 | consumed tokens: 111206400.0 | grad norm avg: 7.88 | grad norm last: 7.82 | 
2025-12-28T00:18:43 | step: 217300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.103635238716379e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.5 | consumed tokens: 111257600.0 | grad norm avg: 8.47 | grad norm last: 6.57 | 
2025-12-28T00:18:45 | step: 217400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.102799231186509e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 5.84 | consumed tokens: 111308800.0 | grad norm avg: 8.19 | grad norm last: 29.7 | 
2025-12-28T00:18:47 | step: 217500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 9.10196322365664e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.83 | consumed tokens: 111360000.0 | grad norm avg: 7.94 | grad norm last: 7.86 | 
2025-12-28T00:18:49 | step: 217600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.101125760935247e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.19 | consumed tokens: 111411200.0 | grad norm avg: 8.05 | grad norm last: 7.52 | 
2025-12-28T00:18:51 | step: 217700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.100288298213854e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 2.98 | consumed tokens: 111462400.0 | grad norm avg: 7.82 | grad norm last: 6.66 | 
2025-12-28T00:18:53 | step: 217800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.099451563088223e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.5 | consumed tokens: 111513600.0 | grad norm avg: 7.76 | grad norm last: 7.01 | 
2025-12-28T00:18:55 | step: 217900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.098614100366831e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.78 | consumed tokens: 111564800.0 | grad norm avg: 8.01 | grad norm last: 7.17 | 
2025-12-28T00:18:57 | step: 218000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.097775910049677e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.94 | consumed tokens: 111616000.0 | grad norm avg: 8.15 | grad norm last: 9.8 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_218000-seen_tokens_111616000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_218000-seen_tokens_111616000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_218000-seen_tokens_111616000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_218000-seen_tokens_111616000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_218000-seen_tokens_111616000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_218000-seen_tokens_111616000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_218000-seen_tokens_111616000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_218000-seen_tokens_111616000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:18:59 | step: 218100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 9.096936992136762e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.86 | train loss last: 4.31 | consumed tokens: 111667200.0 | grad norm avg: 8.1 | grad norm last: 8.58 | 
2025-12-28T00:19:01 | step: 218200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 9.096098801819608e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.14 | consumed tokens: 111718400.0 | grad norm avg: 8.68 | grad norm last: 7.24 | 
2025-12-28T00:19:03 | step: 218300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.095259156310931e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.12 | consumed tokens: 111769600.0 | grad norm avg: 8.07 | grad norm last: 7.35 | 
2025-12-28T00:19:05 | step: 218400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.094420238398015e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 2.75 | consumed tokens: 111820800.0 | grad norm avg: 8.09 | grad norm last: 5.9 | 
2025-12-28T00:19:07 | step: 218500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.0935813204851e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.11 | consumed tokens: 111872000.0 | grad norm avg: 7.78 | grad norm last: 6.56 | 
2025-12-28T00:19:09 | step: 218600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.0927402197849e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.67 | consumed tokens: 111923200.0 | grad norm avg: 8.42 | grad norm last: 7.03 | 
2025-12-28T00:19:11 | step: 218700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.091899846680462e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.47 | consumed tokens: 111974400.0 | grad norm avg: 8.07 | grad norm last: 6.56 | 
2025-12-28T00:19:13 | step: 218800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.091058745980263e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.8 | consumed tokens: 112025600.0 | grad norm avg: 8.19 | grad norm last: 7.62 | 
2025-12-28T00:19:15 | step: 218900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.090217645280063e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.95 | consumed tokens: 112076800.0 | grad norm avg: 7.85 | grad norm last: 8.22 | 
2025-12-28T00:19:17 | step: 219000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.089375816984102e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.66 | consumed tokens: 112128000.0 | grad norm avg: 8.22 | grad norm last: 7.0 | 
2025-12-28T00:19:19 | step: 219100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.088534716283903e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.91 | consumed tokens: 112179200.0 | grad norm avg: 8.43 | grad norm last: 10.74 | 
2025-12-28T00:19:21 | step: 219200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.08769216039218e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.09 | consumed tokens: 112230400.0 | grad norm avg: 8.02 | grad norm last: 9.69 | 
2025-12-28T00:19:23 | step: 219300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.086849604500458e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.77 | consumed tokens: 112281600.0 | grad norm avg: 8.34 | grad norm last: 8.09 | 
2025-12-28T00:19:25 | step: 219400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.086006321012974e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.83 | consumed tokens: 112332800.0 | grad norm avg: 8.13 | grad norm last: 6.85 | 
2025-12-28T00:19:27 | step: 219500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.08516303752549e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.19 | consumed tokens: 112384000.0 | grad norm avg: 8.23 | grad norm last: 6.96 | 
2025-12-28T00:19:29 | step: 219600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.084320481633767e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.88 | consumed tokens: 112435200.0 | grad norm avg: 8.18 | grad norm last: 8.48 | 
2025-12-28T00:19:31 | step: 219700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.083476470550522e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.53 | consumed tokens: 112486400.0 | grad norm avg: 8.18 | grad norm last: 8.65 | 
2025-12-28T00:19:33 | step: 219800 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.082632459467277e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.03 | consumed tokens: 112537600.0 | grad norm avg: 8.39 | grad norm last: 6.51 | 
2025-12-28T00:19:35 | step: 219900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.081786993192509e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.38 | consumed tokens: 112588800.0 | grad norm avg: 8.03 | grad norm last: 9.65 | 
2025-12-28T00:19:37 | step: 220000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.080942254513502e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 6.22 | consumed tokens: 112640000.0 | grad norm avg: 8.38 | grad norm last: 28.25 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_220000-seen_tokens_112640000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_220000-seen_tokens_112640000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_220000-seen_tokens_112640000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_220000-seen_tokens_112640000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_220000-seen_tokens_112640000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_220000-seen_tokens_112640000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_220000-seen_tokens_112640000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_220000-seen_tokens_112640000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:19:40 | step: 220100 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.080096060642973e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.85 | train loss last: 3.66 | consumed tokens: 112691200.0 | grad norm avg: 7.99 | grad norm last: 6.68 | 
2025-12-28T00:19:42 | step: 220200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.079251321963966e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.66 | consumed tokens: 112742400.0 | grad norm avg: 8.08 | grad norm last: 8.61 | 
2025-12-28T00:19:44 | step: 220300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.078405128093436e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.7 | consumed tokens: 112793600.0 | grad norm avg: 9.2 | grad norm last: 6.6 | 
2025-12-28T00:19:46 | step: 220400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.077558206627145e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.61 | consumed tokens: 112844800.0 | grad norm avg: 8.08 | grad norm last: 6.4 | 
2025-12-28T00:19:48 | step: 220500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.076712740352377e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.06 | consumed tokens: 112896000.0 | grad norm avg: 8.15 | grad norm last: 10.15 | 
2025-12-28T00:19:50 | step: 220600 | train samples/s: 98.8 | train mfu (16-bit): -1.0 | lr mean: 9.075864363694564e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.34 | consumed tokens: 112947200.0 | grad norm avg: 8.01 | grad norm last: 6.62 | 
2025-12-28T00:19:52 | step: 220700 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 9.075017442228273e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.95 | consumed tokens: 112998400.0 | grad norm avg: 7.99 | grad norm last: 7.76 | 
2025-12-28T00:19:54 | step: 220800 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 9.07416979316622e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 5.03 | consumed tokens: 113049600.0 | grad norm avg: 8.14 | grad norm last: 9.2 | 
2025-12-28T00:19:56 | step: 220900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.073322144104168e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.64 | consumed tokens: 113100800.0 | grad norm avg: 8.31 | grad norm last: 9.27 | 
2025-12-28T00:19:58 | step: 221000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.072473039850593e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.91 | consumed tokens: 113152000.0 | grad norm avg: 7.83 | grad norm last: 9.7 | 
2025-12-28T00:20:00 | step: 221100 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.07162539078854e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.98 | consumed tokens: 113203200.0 | grad norm avg: 8.06 | grad norm last: 7.66 | 
2025-12-28T00:20:02 | step: 221200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.070775558939204e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.66 | consumed tokens: 113254400.0 | grad norm avg: 8.19 | grad norm last: 7.81 | 
2025-12-28T00:20:04 | step: 221300 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.069926454685628e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 2.92 | consumed tokens: 113305600.0 | grad norm avg: 7.91 | grad norm last: 6.42 | 
2025-12-28T00:20:06 | step: 221400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.069076622836292e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.0 | consumed tokens: 113356800.0 | grad norm avg: 8.37 | grad norm last: 10.2 | 
2025-12-28T00:20:08 | step: 221500 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 9.068226063391194e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.19 | consumed tokens: 113408000.0 | grad norm avg: 7.73 | grad norm last: 7.44 | 
2025-12-28T00:20:10 | step: 221600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.067376231541857e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.47 | consumed tokens: 113459200.0 | grad norm avg: 8.25 | grad norm last: 6.85 | 
2025-12-28T00:20:12 | step: 221700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.066524944500998e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.83 | consumed tokens: 113510400.0 | grad norm avg: 8.4 | grad norm last: 11.16 | 
2025-12-28T00:20:14 | step: 221800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.065673657460138e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.88 | consumed tokens: 113561600.0 | grad norm avg: 8.94 | grad norm last: 6.22 | 
2025-12-28T00:20:16 | step: 221900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.064822370419279e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.28 | consumed tokens: 113612800.0 | grad norm avg: 8.03 | grad norm last: 6.61 | 
2025-12-28T00:20:18 | step: 222000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.063971083378419e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.97 | consumed tokens: 113664000.0 | grad norm avg: 8.14 | grad norm last: 7.5 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_222000-seen_tokens_113664000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_222000-seen_tokens_113664000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_222000-seen_tokens_113664000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_222000-seen_tokens_113664000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_222000-seen_tokens_113664000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_222000-seen_tokens_113664000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_222000-seen_tokens_113664000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_222000-seen_tokens_113664000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:20:20 | step: 222100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.063118341146037e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.25 | consumed tokens: 113715200.0 | grad norm avg: 7.83 | grad norm last: 6.53 | 
2025-12-28T00:20:22 | step: 222200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 9.062265598913655e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.03 | consumed tokens: 113766400.0 | grad norm avg: 8.2 | grad norm last: 7.78 | 
2025-12-28T00:20:24 | step: 222300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 9.061412856681272e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.3 | consumed tokens: 113817600.0 | grad norm avg: 7.92 | grad norm last: 8.07 | 
2025-12-28T00:20:26 | step: 222400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.06056011444889e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.95 | consumed tokens: 113868800.0 | grad norm avg: 8.24 | grad norm last: 8.51 | 
2025-12-28T00:20:28 | step: 222500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.059705917024985e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.14 | consumed tokens: 113920000.0 | grad norm avg: 7.77 | grad norm last: 6.6 | 
2025-12-28T00:20:30 | step: 222600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.058852447196841e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.69 | consumed tokens: 113971200.0 | grad norm avg: 8.09 | grad norm last: 6.82 | 
2025-12-28T00:20:33 | step: 222700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.057998977368698e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.31 | consumed tokens: 114022400.0 | grad norm avg: 8.16 | grad norm last: 10.87 | 
2025-12-28T00:20:35 | step: 222800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.05714332475327e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.38 | consumed tokens: 114073600.0 | grad norm avg: 8.06 | grad norm last: 7.82 | 
2025-12-28T00:20:37 | step: 222900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.056288399733603e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.38 | consumed tokens: 114124800.0 | grad norm avg: 8.21 | grad norm last: 7.37 | 
2025-12-28T00:20:39 | step: 223000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 9.055433474713936e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.86 | consumed tokens: 114176000.0 | grad norm avg: 8.05 | grad norm last: 7.26 | 
2025-12-28T00:20:41 | step: 223100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 9.054577822098508e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.75 | consumed tokens: 114227200.0 | grad norm avg: 7.96 | grad norm last: 7.05 | 
2025-12-28T00:20:43 | step: 223200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.053721441887319e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.45 | consumed tokens: 114278400.0 | grad norm avg: 8.27 | grad norm last: 6.48 | 
2025-12-28T00:20:45 | step: 223300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.05286506167613e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.12 | consumed tokens: 114329600.0 | grad norm avg: 8.22 | grad norm last: 6.78 | 
2025-12-28T00:20:47 | step: 223400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.052009409060702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.56 | consumed tokens: 114380800.0 | grad norm avg: 8.02 | grad norm last: 7.11 | 
2025-12-28T00:20:49 | step: 223500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.05115157365799e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.22 | consumed tokens: 114432000.0 | grad norm avg: 8.21 | grad norm last: 6.49 | 
2025-12-28T00:20:51 | step: 223600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.050293738255277e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.89 | consumed tokens: 114483200.0 | grad norm avg: 7.91 | grad norm last: 7.53 | 
2025-12-28T00:20:53 | step: 223700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.049436630448326e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.7 | consumed tokens: 114534400.0 | grad norm avg: 7.97 | grad norm last: 6.35 | 
2025-12-28T00:20:55 | step: 223800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.048578795045614e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.91 | consumed tokens: 114585600.0 | grad norm avg: 8.19 | grad norm last: 13.61 | 
2025-12-28T00:20:57 | step: 223900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.04772023204714e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.84 | consumed tokens: 114636800.0 | grad norm avg: 8.16 | grad norm last: 7.16 | 
2025-12-28T00:20:59 | step: 224000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.046861669048667e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.19 | consumed tokens: 114688000.0 | grad norm avg: 8.28 | grad norm last: 7.6 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_224000-seen_tokens_114688000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_224000-seen_tokens_114688000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_224000-seen_tokens_114688000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_224000-seen_tokens_114688000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_224000-seen_tokens_114688000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_224000-seen_tokens_114688000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_224000-seen_tokens_114688000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_224000-seen_tokens_114688000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:21:01 | step: 224100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.046003106050193e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.23 | consumed tokens: 114739200.0 | grad norm avg: 7.78 | grad norm last: 7.36 | 
2025-12-28T00:21:03 | step: 224200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.045142360264435e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.52 | consumed tokens: 114790400.0 | grad norm avg: 8.04 | grad norm last: 7.15 | 
2025-12-28T00:21:05 | step: 224300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 9.044283797265962e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.5 | consumed tokens: 114841600.0 | grad norm avg: 8.23 | grad norm last: 11.19 | 
2025-12-28T00:21:07 | step: 224400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 9.043423779075965e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.84 | consumed tokens: 114892800.0 | grad norm avg: 7.76 | grad norm last: 7.29 | 
2025-12-28T00:21:09 | step: 224500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 9.042563033290207e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.61 | consumed tokens: 114944000.0 | grad norm avg: 7.92 | grad norm last: 6.47 | 
2025-12-28T00:21:11 | step: 224600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.04170228750445e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.19 | consumed tokens: 114995200.0 | grad norm avg: 7.97 | grad norm last: 6.43 | 
2025-12-28T00:21:13 | step: 224700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.04084081412293e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.83 | consumed tokens: 115046400.0 | grad norm avg: 8.5 | grad norm last: 7.37 | 
2025-12-28T00:21:15 | step: 224800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.039979340741411e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.34 | consumed tokens: 115097600.0 | grad norm avg: 7.93 | grad norm last: 8.53 | 
2025-12-28T00:21:17 | step: 224900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.039117867359892e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 2.72 | consumed tokens: 115148800.0 | grad norm avg: 8.32 | grad norm last: 6.14 | 
2025-12-28T00:21:19 | step: 225000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.038256393978372e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.58 | consumed tokens: 115200000.0 | grad norm avg: 7.98 | grad norm last: 7.96 | 
2025-12-28T00:21:21 | step: 225100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.037394193001091e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.25 | consumed tokens: 115251200.0 | grad norm avg: 7.99 | grad norm last: 7.04 | 
2025-12-28T00:21:23 | step: 225200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.036531992023811e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.94 | consumed tokens: 115302400.0 | grad norm avg: 8.2 | grad norm last: 14.45 | 
2025-12-28T00:21:25 | step: 225300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 9.035668335855007e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.38 | consumed tokens: 115353600.0 | grad norm avg: 8.33 | grad norm last: 7.91 | 
2025-12-28T00:21:27 | step: 225400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.034804679686204e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.75 | consumed tokens: 115404800.0 | grad norm avg: 7.7 | grad norm last: 6.75 | 
2025-12-28T00:21:29 | step: 225500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.033941751113161e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.06 | consumed tokens: 115456000.0 | grad norm avg: 8.31 | grad norm last: 7.7 | 
2025-12-28T00:21:31 | step: 225600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.033075912157074e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.64 | consumed tokens: 115507200.0 | grad norm avg: 8.18 | grad norm last: 7.56 | 
2025-12-28T00:21:33 | step: 225700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.032212983584031e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.09 | consumed tokens: 115558400.0 | grad norm avg: 7.74 | grad norm last: 5.84 | 
2025-12-28T00:21:35 | step: 225800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.031347144627944e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.38 | consumed tokens: 115609600.0 | grad norm avg: 8.19 | grad norm last: 7.44 | 
2025-12-28T00:21:37 | step: 225900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.030482033267617e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.34 | consumed tokens: 115660800.0 | grad norm avg: 7.74 | grad norm last: 12.46 | 
2025-12-28T00:21:39 | step: 226000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.029616921907291e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.72 | consumed tokens: 115712000.0 | grad norm avg: 7.7 | grad norm last: 8.64 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_226000-seen_tokens_115712000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_226000-seen_tokens_115712000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_226000-seen_tokens_115712000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_226000-seen_tokens_115712000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_226000-seen_tokens_115712000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_226000-seen_tokens_115712000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_226000-seen_tokens_115712000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_226000-seen_tokens_115712000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:21:42 | step: 226100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.028751082951203e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.76 | train loss last: 4.31 | consumed tokens: 115763200.0 | grad norm avg: 7.85 | grad norm last: 7.1 | 
2025-12-28T00:21:44 | step: 226200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.027883788803592e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.84 | consumed tokens: 115814400.0 | grad norm avg: 8.19 | grad norm last: 6.74 | 
2025-12-28T00:21:46 | step: 226300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.027017949847504e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.59 | consumed tokens: 115865600.0 | grad norm avg: 7.84 | grad norm last: 6.68 | 
2025-12-28T00:21:48 | step: 226400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.026151383295655e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.09 | consumed tokens: 115916800.0 | grad norm avg: 7.76 | grad norm last: 7.34 | 
2025-12-28T00:21:50 | step: 226500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.025284089148045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.09 | consumed tokens: 115968000.0 | grad norm avg: 7.84 | grad norm last: 6.06 | 
2025-12-28T00:21:52 | step: 226600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.024416795000434e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.22 | consumed tokens: 116019200.0 | grad norm avg: 7.59 | grad norm last: 6.93 | 
2025-12-28T00:21:54 | step: 226700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.023548773257062e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.75 | consumed tokens: 116070400.0 | grad norm avg: 7.93 | grad norm last: 6.98 | 
2025-12-28T00:21:56 | step: 226800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.022680023917928e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.44 | consumed tokens: 116121600.0 | grad norm avg: 7.91 | grad norm last: 8.56 | 
2025-12-28T00:21:58 | step: 226900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 9.021812002174556e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.44 | consumed tokens: 116172800.0 | grad norm avg: 7.49 | grad norm last: 7.18 | 
2025-12-28T00:22:00 | step: 227000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 9.020943980431184e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.45 | consumed tokens: 116224000.0 | grad norm avg: 7.92 | grad norm last: 6.49 | 
2025-12-28T00:22:02 | step: 227100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.020073775900528e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.67 | consumed tokens: 116275200.0 | grad norm avg: 7.71 | grad norm last: 6.2 | 
2025-12-28T00:22:04 | step: 227200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.019204298965633e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.69 | consumed tokens: 116326400.0 | grad norm avg: 7.69 | grad norm last: 7.01 | 
2025-12-28T00:22:06 | step: 227300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.018334822030738e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.92 | consumed tokens: 116377600.0 | grad norm avg: 7.68 | grad norm last: 7.53 | 
2025-12-28T00:22:08 | step: 227400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 9.017464617500082e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.58 | consumed tokens: 116428800.0 | grad norm avg: 7.87 | grad norm last: 8.37 | 
2025-12-28T00:22:10 | step: 227500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 9.016593685373664e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.86 | consumed tokens: 116480000.0 | grad norm avg: 7.87 | grad norm last: 6.87 | 
2025-12-28T00:22:12 | step: 227600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.015722753247246e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.06 | consumed tokens: 116531200.0 | grad norm avg: 7.87 | grad norm last: 7.49 | 
2025-12-28T00:22:14 | step: 227700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.014851093525067e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.28 | consumed tokens: 116582400.0 | grad norm avg: 7.8 | grad norm last: 6.63 | 
2025-12-28T00:22:16 | step: 227800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.013980161398649e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.58 | consumed tokens: 116633600.0 | grad norm avg: 7.79 | grad norm last: 6.45 | 
2025-12-28T00:22:18 | step: 227900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.013107774080709e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.91 | consumed tokens: 116684800.0 | grad norm avg: 8.15 | grad norm last: 9.24 | 
2025-12-28T00:22:20 | step: 228000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.01223611435853e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.56 | consumed tokens: 116736000.0 | grad norm avg: 7.94 | grad norm last: 8.47 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_228000-seen_tokens_116736000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_228000-seen_tokens_116736000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_228000-seen_tokens_116736000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_228000-seen_tokens_116736000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_228000-seen_tokens_116736000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_228000-seen_tokens_116736000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_228000-seen_tokens_116736000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_228000-seen_tokens_116736000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:22:22 | step: 228100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 9.011362999444827e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.17 | consumed tokens: 116787200.0 | grad norm avg: 8.1 | grad norm last: 6.75 | 
2025-12-28T00:22:24 | step: 228200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 9.010490612126887e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.45 | consumed tokens: 116838400.0 | grad norm avg: 7.74 | grad norm last: 7.31 | 
2025-12-28T00:22:26 | step: 228300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.009616769617423e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.62 | consumed tokens: 116889600.0 | grad norm avg: 7.97 | grad norm last: 7.34 | 
2025-12-28T00:22:28 | step: 228400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.008743654703721e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.78 | consumed tokens: 116940800.0 | grad norm avg: 8.17 | grad norm last: 7.03 | 
2025-12-28T00:22:30 | step: 228500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.00787053979002e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.27 | consumed tokens: 116992000.0 | grad norm avg: 7.9 | grad norm last: 6.18 | 
2025-12-28T00:22:32 | step: 228600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.006995242089033e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.81 | consumed tokens: 117043200.0 | grad norm avg: 7.91 | grad norm last: 7.81 | 
2025-12-28T00:22:34 | step: 228700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 9.006119944388047e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.38 | consumed tokens: 117094400.0 | grad norm avg: 7.68 | grad norm last: 6.21 | 
2025-12-28T00:22:36 | step: 228800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 9.005245374282822e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.06 | consumed tokens: 117145600.0 | grad norm avg: 8.06 | grad norm last: 13.9 | 
2025-12-28T00:22:38 | step: 228900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 9.004370076581836e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.81 | consumed tokens: 117196800.0 | grad norm avg: 7.52 | grad norm last: 7.84 | 
2025-12-28T00:22:40 | step: 229000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.00349477888085e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.41 | consumed tokens: 117248000.0 | grad norm avg: 7.94 | grad norm last: 7.59 | 
2025-12-28T00:22:42 | step: 229100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.002618753584102e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.98 | consumed tokens: 117299200.0 | grad norm avg: 8.04 | grad norm last: 7.52 | 
2025-12-28T00:22:44 | step: 229200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 9.001742728287354e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.19 | consumed tokens: 117350400.0 | grad norm avg: 7.81 | grad norm last: 6.19 | 
2025-12-28T00:22:46 | step: 229300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 9.000865975394845e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.75 | consumed tokens: 117401600.0 | grad norm avg: 7.69 | grad norm last: 12.16 | 
2025-12-28T00:22:48 | step: 229400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.999989222502336e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.38 | consumed tokens: 117452800.0 | grad norm avg: 7.83 | grad norm last: 6.89 | 
2025-12-28T00:22:51 | step: 229500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.999111742014065e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.72 | consumed tokens: 117504000.0 | grad norm avg: 7.62 | grad norm last: 6.87 | 
2025-12-28T00:22:53 | step: 229600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.998232806334272e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 2.91 | consumed tokens: 117555200.0 | grad norm avg: 7.95 | grad norm last: 5.95 | 
2025-12-28T00:22:55 | step: 229700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.997356053441763e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.3 | consumed tokens: 117606400.0 | grad norm avg: 7.97 | grad norm last: 6.83 | 
2025-12-28T00:22:57 | step: 229800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.996477845357731e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.75 | consumed tokens: 117657600.0 | grad norm avg: 8.13 | grad norm last: 7.61 | 
2025-12-28T00:22:59 | step: 229900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.995598909677938e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.86 | consumed tokens: 117708800.0 | grad norm avg: 8.36 | grad norm last: 8.14 | 
2025-12-28T00:23:01 | step: 230000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.994719973998144e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.88 | consumed tokens: 117760000.0 | grad norm avg: 8.01 | grad norm last: 7.63 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_230000-seen_tokens_117760000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_230000-seen_tokens_117760000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_230000-seen_tokens_117760000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_230000-seen_tokens_117760000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_230000-seen_tokens_117760000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_230000-seen_tokens_117760000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_230000-seen_tokens_117760000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_230000-seen_tokens_117760000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:23:03 | step: 230100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.99384031072259e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.86 | train loss last: 4.12 | consumed tokens: 117811200.0 | grad norm avg: 8.25 | grad norm last: 7.99 | 
2025-12-28T00:23:05 | step: 230200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.992960647447035e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.09 | consumed tokens: 117862400.0 | grad norm avg: 7.84 | grad norm last: 6.28 | 
2025-12-28T00:23:07 | step: 230300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.992080256575719e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.72 | consumed tokens: 117913600.0 | grad norm avg: 7.86 | grad norm last: 6.69 | 
2025-12-28T00:23:09 | step: 230400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.991200593300164e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.7 | consumed tokens: 117964800.0 | grad norm avg: 7.76 | grad norm last: 7.49 | 
2025-12-28T00:23:11 | step: 230500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.990320930024609e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.72 | consumed tokens: 118016000.0 | grad norm avg: 7.86 | grad norm last: 8.02 | 
2025-12-28T00:23:13 | step: 230600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.98943908396177e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.5 | consumed tokens: 118067200.0 | grad norm avg: 8.16 | grad norm last: 7.08 | 
2025-12-28T00:23:15 | step: 230700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.988557237898931e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.67 | consumed tokens: 118118400.0 | grad norm avg: 8.05 | grad norm last: 7.06 | 
2025-12-28T00:23:17 | step: 230800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.987676119431853e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.38 | consumed tokens: 118169600.0 | grad norm avg: 7.83 | grad norm last: 6.93 | 
2025-12-28T00:23:19 | step: 230900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.986793545773253e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.81 | consumed tokens: 118220800.0 | grad norm avg: 8.26 | grad norm last: 6.92 | 
2025-12-28T00:23:21 | step: 231000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.985911699710414e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.41 | consumed tokens: 118272000.0 | grad norm avg: 7.85 | grad norm last: 8.93 | 
2025-12-28T00:23:23 | step: 231100 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 8.985029853647575e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.0 | consumed tokens: 118323200.0 | grad norm avg: 7.71 | grad norm last: 8.22 | 
2025-12-28T00:23:25 | step: 231200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.984145824797451e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.25 | consumed tokens: 118374400.0 | grad norm avg: 8.31 | grad norm last: 7.74 | 
2025-12-28T00:23:27 | step: 231300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.983261795947328e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.92 | consumed tokens: 118425600.0 | grad norm avg: 7.79 | grad norm last: 7.47 | 
2025-12-28T00:23:29 | step: 231400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.982378494692966e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.88 | consumed tokens: 118476800.0 | grad norm avg: 8.14 | grad norm last: 8.19 | 
2025-12-28T00:23:31 | step: 231500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.981494465842843e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.72 | consumed tokens: 118528000.0 | grad norm avg: 8.06 | grad norm last: 8.16 | 
2025-12-28T00:23:33 | step: 231600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.98061043699272e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.73 | consumed tokens: 118579200.0 | grad norm avg: 7.87 | grad norm last: 7.24 | 
2025-12-28T00:23:35 | step: 231700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.979725680546835e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.88 | consumed tokens: 118630400.0 | grad norm avg: 7.95 | grad norm last: 8.59 | 
2025-12-28T00:23:37 | step: 231800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.978840196505189e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.8 | consumed tokens: 118681600.0 | grad norm avg: 8.24 | grad norm last: 7.17 | 
2025-12-28T00:23:39 | step: 231900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.977955440059304e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.19 | consumed tokens: 118732800.0 | grad norm avg: 8.65 | grad norm last: 7.13 | 
2025-12-28T00:23:41 | step: 232000 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.977068500826135e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.73 | consumed tokens: 118784000.0 | grad norm avg: 8.18 | grad norm last: 7.4 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_232000-seen_tokens_118784000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_232000-seen_tokens_118784000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_232000-seen_tokens_118784000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_232000-seen_tokens_118784000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_232000-seen_tokens_118784000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_232000-seen_tokens_118784000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_232000-seen_tokens_118784000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_232000-seen_tokens_118784000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:23:43 | step: 232100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.97618374438025e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.28 | consumed tokens: 118835200.0 | grad norm avg: 8.06 | grad norm last: 6.85 | 
2025-12-28T00:23:45 | step: 232200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.975297532742843e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.84 | consumed tokens: 118886400.0 | grad norm avg: 8.23 | grad norm last: 7.81 | 
2025-12-28T00:23:47 | step: 232300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.974410593509674e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.48 | consumed tokens: 118937600.0 | grad norm avg: 8.17 | grad norm last: 7.41 | 
2025-12-28T00:23:50 | step: 232400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 8.973523654276505e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.81 | consumed tokens: 118988800.0 | grad norm avg: 8.13 | grad norm last: 8.25 | 
2025-12-28T00:23:52 | step: 232500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.972635987447575e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.75 | consumed tokens: 119040000.0 | grad norm avg: 7.94 | grad norm last: 10.39 | 
2025-12-28T00:23:54 | step: 232600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.971748320618644e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.03 | consumed tokens: 119091200.0 | grad norm avg: 7.87 | grad norm last: 7.66 | 
2025-12-28T00:23:56 | step: 232700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.970859926193953e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.09 | consumed tokens: 119142400.0 | grad norm avg: 8.12 | grad norm last: 7.52 | 
2025-12-28T00:23:58 | step: 232800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.969971531769261e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.41 | consumed tokens: 119193600.0 | grad norm avg: 7.98 | grad norm last: 8.73 | 
2025-12-28T00:24:00 | step: 232900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.969082409748808e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.7 | consumed tokens: 119244800.0 | grad norm avg: 8.3 | grad norm last: 7.99 | 
2025-12-28T00:24:02 | step: 233000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.968194015324116e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.83 | consumed tokens: 119296000.0 | grad norm avg: 8.0 | grad norm last: 6.98 | 
2025-12-28T00:24:04 | step: 233100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 8.967305620899424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 4.28 | consumed tokens: 119347200.0 | grad norm avg: 8.55 | grad norm last: 8.21 | 
2025-12-28T00:24:06 | step: 233200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 8.966415043687448e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.88 | consumed tokens: 119398400.0 | grad norm avg: 7.86 | grad norm last: 7.04 | 
2025-12-28T00:24:08 | step: 233300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.965525194071233e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.66 | consumed tokens: 119449600.0 | grad norm avg: 8.23 | grad norm last: 7.03 | 
2025-12-28T00:24:10 | step: 233400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.964634616859257e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.2 | consumed tokens: 119500800.0 | grad norm avg: 7.76 | grad norm last: 6.56 | 
2025-12-28T00:24:12 | step: 233500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.963744039647281e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.81 | consumed tokens: 119552000.0 | grad norm avg: 8.01 | grad norm last: 6.63 | 
2025-12-28T00:24:14 | step: 233600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.962852734839544e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.91 | consumed tokens: 119603200.0 | grad norm avg: 8.07 | grad norm last: 8.36 | 
2025-12-28T00:24:16 | step: 233700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.961962157627568e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.81 | consumed tokens: 119654400.0 | grad norm avg: 8.16 | grad norm last: 10.68 | 
2025-12-28T00:24:18 | step: 233800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.961069397628307e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.3 | consumed tokens: 119705600.0 | grad norm avg: 7.93 | grad norm last: 7.8 | 
2025-12-28T00:24:20 | step: 233900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.960176637629047e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.47 | consumed tokens: 119756800.0 | grad norm avg: 8.23 | grad norm last: 7.48 | 
2025-12-28T00:24:22 | step: 234000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.95928533282131e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.03 | consumed tokens: 119808000.0 | grad norm avg: 7.94 | grad norm last: 8.14 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_234000-seen_tokens_119808000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_234000-seen_tokens_119808000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_234000-seen_tokens_119808000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_234000-seen_tokens_119808000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_234000-seen_tokens_119808000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_234000-seen_tokens_119808000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_234000-seen_tokens_119808000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_234000-seen_tokens_119808000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:24:24 | step: 234100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.958392572822049e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.66 | consumed tokens: 119859200.0 | grad norm avg: 8.15 | grad norm last: 7.54 | 
2025-12-28T00:24:26 | step: 234200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.957499085227028e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.64 | consumed tokens: 119910400.0 | grad norm avg: 8.41 | grad norm last: 7.15 | 
2025-12-28T00:24:28 | step: 234300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.956607052823529e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.39 | consumed tokens: 119961600.0 | grad norm avg: 8.17 | grad norm last: 6.68 | 
2025-12-28T00:24:30 | step: 234400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 8.955712110036984e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 5.06 | consumed tokens: 120012800.0 | grad norm avg: 8.25 | grad norm last: 12.46 | 
2025-12-28T00:24:32 | step: 234500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.954818622441962e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.78 | consumed tokens: 120064000.0 | grad norm avg: 8.09 | grad norm last: 8.19 | 
2025-12-28T00:24:34 | step: 234600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.953924407251179e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.45 | consumed tokens: 120115200.0 | grad norm avg: 8.04 | grad norm last: 6.67 | 
2025-12-28T00:24:36 | step: 234700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.953028736868873e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.45 | consumed tokens: 120166400.0 | grad norm avg: 8.13 | grad norm last: 6.79 | 
2025-12-28T00:24:38 | step: 234800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.95213452167809e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.16 | consumed tokens: 120217600.0 | grad norm avg: 7.93 | grad norm last: 8.14 | 
2025-12-28T00:24:40 | step: 234900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 8.951238851295784e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.62 | consumed tokens: 120268800.0 | grad norm avg: 8.25 | grad norm last: 6.87 | 
2025-12-28T00:24:42 | step: 235000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.95034390850924e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.08 | consumed tokens: 120320000.0 | grad norm avg: 9.06 | grad norm last: 6.22 | 
2025-12-28T00:24:44 | step: 235100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.949447510531172e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.22 | consumed tokens: 120371200.0 | grad norm avg: 7.74 | grad norm last: 7.17 | 
2025-12-28T00:24:46 | step: 235200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.948551112553105e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.5 | consumed tokens: 120422400.0 | grad norm avg: 8.16 | grad norm last: 6.17 | 
2025-12-28T00:24:48 | step: 235300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.947654714575037e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.31 | consumed tokens: 120473600.0 | grad norm avg: 8.46 | grad norm last: 7.39 | 
2025-12-28T00:24:50 | step: 235400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.946756861405447e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.95 | consumed tokens: 120524800.0 | grad norm avg: 8.28 | grad norm last: 8.18 | 
2025-12-28T00:24:52 | step: 235500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.945859735831618e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.44 | consumed tokens: 120576000.0 | grad norm avg: 7.91 | grad norm last: 7.61 | 
2025-12-28T00:24:54 | step: 235600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.944961155066267e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.92 | consumed tokens: 120627200.0 | grad norm avg: 7.93 | grad norm last: 7.99 | 
2025-12-28T00:24:56 | step: 235700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.944064029492438e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.67 | consumed tokens: 120678400.0 | grad norm avg: 8.05 | grad norm last: 7.92 | 
2025-12-28T00:24:58 | step: 235800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.943165448727086e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.53 | consumed tokens: 120729600.0 | grad norm avg: 7.68 | grad norm last: 8.18 | 
2025-12-28T00:25:00 | step: 235900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.942266140365973e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.41 | consumed tokens: 120780800.0 | grad norm avg: 8.11 | grad norm last: 7.31 | 
2025-12-28T00:25:02 | step: 236000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.941368287196383e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.36 | consumed tokens: 120832000.0 | grad norm avg: 7.98 | grad norm last: 6.73 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_236000-seen_tokens_120832000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_236000-seen_tokens_120832000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_236000-seen_tokens_120832000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_236000-seen_tokens_120832000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_236000-seen_tokens_120832000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_236000-seen_tokens_120832000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_236000-seen_tokens_120832000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_236000-seen_tokens_120832000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:25:05 | step: 236100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.94046897883527e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.9 | train loss last: 3.64 | consumed tokens: 120883200.0 | grad norm avg: 8.32 | grad norm last: 7.9 | 
2025-12-28T00:25:07 | step: 236200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.939569670474157e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.81 | consumed tokens: 120934400.0 | grad norm avg: 8.18 | grad norm last: 7.77 | 
2025-12-28T00:25:09 | step: 236300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.938668906921521e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.88 | consumed tokens: 120985600.0 | grad norm avg: 7.76 | grad norm last: 7.49 | 
2025-12-28T00:25:11 | step: 236400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.937768870964646e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.5 | consumed tokens: 121036800.0 | grad norm avg: 8.0 | grad norm last: 10.0 | 
2025-12-28T00:25:13 | step: 236500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.936868835007772e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.42 | consumed tokens: 121088000.0 | grad norm avg: 7.97 | grad norm last: 7.24 | 
2025-12-28T00:25:15 | step: 236600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.935967343859375e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.5 | consumed tokens: 121139200.0 | grad norm avg: 7.9 | grad norm last: 8.06 | 
2025-12-28T00:25:17 | step: 236700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.935065852710977e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.36 | consumed tokens: 121190400.0 | grad norm avg: 8.19 | grad norm last: 6.34 | 
2025-12-28T00:25:19 | step: 236800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.934163633966818e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.16 | consumed tokens: 121241600.0 | grad norm avg: 8.23 | grad norm last: 9.28 | 
2025-12-28T00:25:21 | step: 236900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.93326141522266e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.8 | consumed tokens: 121292800.0 | grad norm avg: 8.12 | grad norm last: 9.32 | 
2025-12-28T00:25:23 | step: 237000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.932359196478501e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.06 | consumed tokens: 121344000.0 | grad norm avg: 8.14 | grad norm last: 6.77 | 
2025-12-28T00:25:25 | step: 237100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.931456977734342e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 2.91 | consumed tokens: 121395200.0 | grad norm avg: 7.78 | grad norm last: 7.02 | 
2025-12-28T00:25:27 | step: 237200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.930554031394422e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.09 | consumed tokens: 121446400.0 | grad norm avg: 8.04 | grad norm last: 7.2 | 
2025-12-28T00:25:29 | step: 237300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 8.929651085054502e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.58 | consumed tokens: 121497600.0 | grad norm avg: 7.91 | grad norm last: 6.52 | 
2025-12-28T00:25:31 | step: 237400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.92874741111882e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 4.0 | train loss last: 4.34 | consumed tokens: 121548800.0 | grad norm avg: 8.94 | grad norm last: 11.59 | 
2025-12-28T00:25:33 | step: 237500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.927842281991616e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 2.73 | consumed tokens: 121600000.0 | grad norm avg: 7.93 | grad norm last: 6.58 | 
2025-12-28T00:25:35 | step: 237600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.926938608055934e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.69 | consumed tokens: 121651200.0 | grad norm avg: 7.91 | grad norm last: 6.35 | 
2025-12-28T00:25:37 | step: 237700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.926034206524491e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.2 | consumed tokens: 121702400.0 | grad norm avg: 7.78 | grad norm last: 6.79 | 
2025-12-28T00:25:39 | step: 237800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.925129077397287e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.03 | consumed tokens: 121753600.0 | grad norm avg: 7.96 | grad norm last: 7.5 | 
2025-12-28T00:25:41 | step: 237900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.924223948270082e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.61 | consumed tokens: 121804800.0 | grad norm avg: 7.97 | grad norm last: 7.81 | 
2025-12-28T00:25:43 | step: 238000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.923318091547117e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.98 | consumed tokens: 121856000.0 | grad norm avg: 8.01 | grad norm last: 8.07 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_238000-seen_tokens_121856000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_238000-seen_tokens_121856000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_238000-seen_tokens_121856000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_238000-seen_tokens_121856000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_238000-seen_tokens_121856000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_238000-seen_tokens_121856000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_238000-seen_tokens_121856000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_238000-seen_tokens_121856000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:25:45 | step: 238100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 8.92241150722839e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.96 | train loss last: 3.59 | consumed tokens: 121907200.0 | grad norm avg: 8.23 | grad norm last: 6.7 | 
2025-12-28T00:25:47 | step: 238200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.921506378101185e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.73 | consumed tokens: 121958400.0 | grad norm avg: 7.95 | grad norm last: 6.29 | 
2025-12-28T00:25:49 | step: 238300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.920599793782458e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.47 | consumed tokens: 122009600.0 | grad norm avg: 8.06 | grad norm last: 6.93 | 
2025-12-28T00:25:51 | step: 238400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.919692481867969e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.77 | consumed tokens: 122060800.0 | grad norm avg: 7.93 | grad norm last: 6.96 | 
2025-12-28T00:25:53 | step: 238500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.91878516995348e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.22 | consumed tokens: 122112000.0 | grad norm avg: 8.36 | grad norm last: 6.29 | 
2025-12-28T00:25:56 | step: 238600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.91787713044323e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.06 | consumed tokens: 122163200.0 | grad norm avg: 8.51 | grad norm last: 7.57 | 
2025-12-28T00:25:58 | step: 238700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.91696909093298e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.53 | consumed tokens: 122214400.0 | grad norm avg: 7.71 | grad norm last: 7.05 | 
2025-12-28T00:26:00 | step: 238800 | train samples/s: 98.9 | train mfu (16-bit): -1.0 | lr mean: 8.91606105142273e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.53 | consumed tokens: 122265600.0 | grad norm avg: 7.96 | grad norm last: 7.67 | 
2025-12-28T00:26:02 | step: 238900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.91515301191248e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.42 | consumed tokens: 122316800.0 | grad norm avg: 7.74 | grad norm last: 9.07 | 
2025-12-28T00:26:04 | step: 239000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.914244244806468e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.3 | consumed tokens: 122368000.0 | grad norm avg: 8.21 | grad norm last: 6.75 | 
2025-12-28T00:26:06 | step: 239100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.913335477700457e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.25 | consumed tokens: 122419200.0 | grad norm avg: 8.09 | grad norm last: 8.78 | 
2025-12-28T00:26:08 | step: 239200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.912425255402923e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 5.22 | consumed tokens: 122470400.0 | grad norm avg: 7.99 | grad norm last: 14.32 | 
2025-12-28T00:26:10 | step: 239300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.911515033105388e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.69 | consumed tokens: 122521600.0 | grad norm avg: 8.27 | grad norm last: 9.3 | 
2025-12-28T00:26:12 | step: 239400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.910605538403615e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 3.86 | consumed tokens: 122572800.0 | grad norm avg: 8.3 | grad norm last: 7.16 | 
2025-12-28T00:26:14 | step: 239500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.90969458851032e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.98 | consumed tokens: 122624000.0 | grad norm avg: 7.74 | grad norm last: 7.54 | 
2025-12-28T00:26:16 | step: 239600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.908783638617024e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.53 | consumed tokens: 122675200.0 | grad norm avg: 8.23 | grad norm last: 7.4 | 
2025-12-28T00:26:18 | step: 239700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.907872688723728e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.34 | consumed tokens: 122726400.0 | grad norm avg: 7.72 | grad norm last: 6.79 | 
2025-12-28T00:26:20 | step: 239800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.906961738830432e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.2 | consumed tokens: 122777600.0 | grad norm avg: 8.38 | grad norm last: 8.79 | 
2025-12-28T00:26:22 | step: 239900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.906049333745614e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.97 | consumed tokens: 122828800.0 | grad norm avg: 7.83 | grad norm last: 8.78 | 
2025-12-28T00:26:24 | step: 240000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.905136928660795e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.34 | consumed tokens: 122880000.0 | grad norm avg: 7.67 | grad norm last: 6.45 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_240000-seen_tokens_122880000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_240000-seen_tokens_122880000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_240000-seen_tokens_122880000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_240000-seen_tokens_122880000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_240000-seen_tokens_122880000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_240000-seen_tokens_122880000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_240000-seen_tokens_122880000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_240000-seen_tokens_122880000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:26:26 | step: 240100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.904224523575976e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.06 | consumed tokens: 122931200.0 | grad norm avg: 7.75 | grad norm last: 6.58 | 
2025-12-28T00:26:28 | step: 240200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.903312118491158e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.25 | consumed tokens: 122982400.0 | grad norm avg: 7.81 | grad norm last: 6.56 | 
2025-12-28T00:26:30 | step: 240300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.902398258214816e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.94 | consumed tokens: 123033600.0 | grad norm avg: 8.07 | grad norm last: 9.66 | 
2025-12-28T00:26:32 | step: 240400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.901485125534236e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.44 | consumed tokens: 123084800.0 | grad norm avg: 7.72 | grad norm last: 7.07 | 
2025-12-28T00:26:34 | step: 240500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.900571265257895e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.62 | consumed tokens: 123136000.0 | grad norm avg: 7.86 | grad norm last: 6.83 | 
2025-12-28T00:26:36 | step: 240600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.899657404981554e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 2.86 | consumed tokens: 123187200.0 | grad norm avg: 7.76 | grad norm last: 6.38 | 
2025-12-28T00:26:38 | step: 240700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.898742817109451e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 2.92 | consumed tokens: 123238400.0 | grad norm avg: 8.0 | grad norm last: 5.8 | 
2025-12-28T00:26:40 | step: 240800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.897828956833109e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.45 | consumed tokens: 123289600.0 | grad norm avg: 7.63 | grad norm last: 6.98 | 
2025-12-28T00:26:42 | step: 240900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.896912913769484e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.52 | consumed tokens: 123340800.0 | grad norm avg: 8.19 | grad norm last: 7.1 | 
2025-12-28T00:26:44 | step: 241000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.895996870705858e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.84 | consumed tokens: 123392000.0 | grad norm avg: 7.91 | grad norm last: 8.27 | 
2025-12-28T00:26:46 | step: 241100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.895081555237994e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.83 | consumed tokens: 123443200.0 | grad norm avg: 7.74 | grad norm last: 7.83 | 
2025-12-28T00:26:48 | step: 241200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.894165512174368e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.55 | consumed tokens: 123494400.0 | grad norm avg: 7.93 | grad norm last: 7.29 | 
2025-12-28T00:26:50 | step: 241300 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 8.893248741514981e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.5 | consumed tokens: 123545600.0 | grad norm avg: 8.06 | grad norm last: 7.69 | 
2025-12-28T00:26:52 | step: 241400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.892331970855594e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 2.94 | consumed tokens: 123596800.0 | grad norm avg: 7.91 | grad norm last: 7.02 | 
2025-12-28T00:26:54 | step: 241500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.891415200196207e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.61 | consumed tokens: 123648000.0 | grad norm avg: 7.95 | grad norm last: 7.61 | 
2025-12-28T00:26:56 | step: 241600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.890497701941058e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.77 | consumed tokens: 123699200.0 | grad norm avg: 8.14 | grad norm last: 8.18 | 
2025-12-28T00:26:58 | step: 241700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.889580931281671e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.88 | consumed tokens: 123750400.0 | grad norm avg: 8.15 | grad norm last: 7.99 | 
2025-12-28T00:27:00 | step: 241800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.888661977835e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.52 | consumed tokens: 123801600.0 | grad norm avg: 7.63 | grad norm last: 7.43 | 
2025-12-28T00:27:02 | step: 241900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.887743024388328e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.3 | consumed tokens: 123852800.0 | grad norm avg: 8.2 | grad norm last: 7.54 | 
2025-12-28T00:27:04 | step: 242000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.886824798537418e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.92 | consumed tokens: 123904000.0 | grad norm avg: 7.63 | grad norm last: 8.0 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_242000-seen_tokens_123904000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_242000-seen_tokens_123904000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_242000-seen_tokens_123904000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_242000-seen_tokens_123904000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_242000-seen_tokens_123904000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_242000-seen_tokens_123904000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_242000-seen_tokens_123904000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_242000-seen_tokens_123904000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:27:07 | step: 242100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 8.885905845090747e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.31 | consumed tokens: 123955200.0 | grad norm avg: 8.12 | grad norm last: 6.63 | 
2025-12-28T00:27:09 | step: 242200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.884986164048314e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.48 | consumed tokens: 124006400.0 | grad norm avg: 7.93 | grad norm last: 7.35 | 
2025-12-28T00:27:11 | step: 242300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.884066483005881e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.23 | consumed tokens: 124057600.0 | grad norm avg: 7.67 | grad norm last: 6.08 | 
2025-12-28T00:27:13 | step: 242400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.883146801963449e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.16 | consumed tokens: 124108800.0 | grad norm avg: 7.73 | grad norm last: 5.69 | 
2025-12-28T00:27:15 | step: 242500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.882226393325254e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.64 | consumed tokens: 124160000.0 | grad norm avg: 8.06 | grad norm last: 6.68 | 
2025-12-28T00:27:17 | step: 242600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.881305257091299e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.56 | consumed tokens: 124211200.0 | grad norm avg: 7.93 | grad norm last: 6.14 | 
2025-12-28T00:27:19 | step: 242700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.880384848453104e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.09 | consumed tokens: 124262400.0 | grad norm avg: 7.55 | grad norm last: 10.16 | 
2025-12-28T00:27:21 | step: 242800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.87946443981491e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.86 | consumed tokens: 124313600.0 | grad norm avg: 8.23 | grad norm last: 9.22 | 
2025-12-28T00:27:23 | step: 242900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 8.878541848389432e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.38 | consumed tokens: 124364800.0 | grad norm avg: 7.77 | grad norm last: 7.32 | 
2025-12-28T00:27:25 | step: 243000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.877619984559715e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.59 | consumed tokens: 124416000.0 | grad norm avg: 7.98 | grad norm last: 6.26 | 
2025-12-28T00:27:27 | step: 243100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.876697393134236e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.31 | consumed tokens: 124467200.0 | grad norm avg: 8.04 | grad norm last: 8.31 | 
2025-12-28T00:27:29 | step: 243200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.875774801708758e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.97 | consumed tokens: 124518400.0 | grad norm avg: 8.08 | grad norm last: 6.48 | 
2025-12-28T00:27:31 | step: 243300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.87485221028328e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.09 | consumed tokens: 124569600.0 | grad norm avg: 7.87 | grad norm last: 5.84 | 
2025-12-28T00:27:33 | step: 243400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.87392889126204e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.52 | consumed tokens: 124620800.0 | grad norm avg: 7.66 | grad norm last: 7.73 | 
2025-12-28T00:27:35 | step: 243500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.873004844645038e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.72 | consumed tokens: 124672000.0 | grad norm avg: 8.35 | grad norm last: 8.98 | 
2025-12-28T00:27:37 | step: 243600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.872080798028037e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.09 | consumed tokens: 124723200.0 | grad norm avg: 8.02 | grad norm last: 6.5 | 
2025-12-28T00:27:39 | step: 243700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.871156751411036e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.48 | consumed tokens: 124774400.0 | grad norm avg: 7.83 | grad norm last: 7.91 | 
2025-12-28T00:27:41 | step: 243800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.870232704794034e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.66 | consumed tokens: 124825600.0 | grad norm avg: 8.07 | grad norm last: 6.64 | 
2025-12-28T00:27:43 | step: 243900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.86930720298551e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 2.91 | consumed tokens: 124876800.0 | grad norm avg: 8.2 | grad norm last: 6.46 | 
2025-12-28T00:27:45 | step: 244000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.868382428772748e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.25 | consumed tokens: 124928000.0 | grad norm avg: 7.86 | grad norm last: 9.87 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_244000-seen_tokens_124928000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_244000-seen_tokens_124928000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_244000-seen_tokens_124928000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_244000-seen_tokens_124928000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_244000-seen_tokens_124928000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_244000-seen_tokens_124928000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_244000-seen_tokens_124928000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_244000-seen_tokens_124928000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:27:47 | step: 244100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.867456926964223e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.87 | train loss last: 3.53 | consumed tokens: 124979200.0 | grad norm avg: 7.85 | grad norm last: 7.73 | 
2025-12-28T00:27:49 | step: 244200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.866530697559938e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.38 | consumed tokens: 125030400.0 | grad norm avg: 7.91 | grad norm last: 6.9 | 
2025-12-28T00:27:51 | step: 244300 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 8.865605195751414e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.09 | consumed tokens: 125081600.0 | grad norm avg: 7.78 | grad norm last: 8.46 | 
2025-12-28T00:27:53 | step: 244400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.864678238751367e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.06 | consumed tokens: 125132800.0 | grad norm avg: 7.85 | grad norm last: 8.45 | 
2025-12-28T00:27:55 | step: 244500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.86375128175132e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.19 | consumed tokens: 125184000.0 | grad norm avg: 7.84 | grad norm last: 7.97 | 
2025-12-28T00:27:57 | step: 244600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.862824324751273e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.06 | consumed tokens: 125235200.0 | grad norm avg: 8.04 | grad norm last: 6.87 | 
2025-12-28T00:27:59 | step: 244700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.861897367751226e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.12 | consumed tokens: 125286400.0 | grad norm avg: 7.64 | grad norm last: 7.38 | 
2025-12-28T00:28:01 | step: 244800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.860968955559656e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.98 | consumed tokens: 125337600.0 | grad norm avg: 7.85 | grad norm last: 6.94 | 
2025-12-28T00:28:03 | step: 244900 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 8.860040543368086e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.22 | consumed tokens: 125388800.0 | grad norm avg: 7.96 | grad norm last: 7.1 | 
2025-12-28T00:28:05 | step: 245000 | train samples/s: 107.8 | train mfu (16-bit): -1.0 | lr mean: 8.859112131176516e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.81 | consumed tokens: 125440000.0 | grad norm avg: 8.01 | grad norm last: 6.54 | 
2025-12-28T00:28:07 | step: 245100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.858183718984947e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.67 | consumed tokens: 125491200.0 | grad norm avg: 7.84 | grad norm last: 7.16 | 
2025-12-28T00:28:09 | step: 245200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.857253851601854e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.28 | consumed tokens: 125542400.0 | grad norm avg: 7.72 | grad norm last: 8.2 | 
2025-12-28T00:28:12 | step: 245300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.856324711814523e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.31 | consumed tokens: 125593600.0 | grad norm avg: 7.7 | grad norm last: 9.04 | 
2025-12-28T00:28:14 | step: 245400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.855395572027192e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 2.92 | consumed tokens: 125644800.0 | grad norm avg: 7.93 | grad norm last: 8.52 | 
2025-12-28T00:28:16 | step: 245500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.854464977048337e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.03 | consumed tokens: 125696000.0 | grad norm avg: 7.94 | grad norm last: 7.58 | 
2025-12-28T00:28:18 | step: 245600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.853534382069483e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.52 | consumed tokens: 125747200.0 | grad norm avg: 8.03 | grad norm last: 7.8 | 
2025-12-28T00:28:20 | step: 245700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.852603059494868e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 5.59 | consumed tokens: 125798400.0 | grad norm avg: 8.47 | grad norm last: 14.29 | 
2025-12-28T00:28:22 | step: 245800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.851673192111775e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.22 | consumed tokens: 125849600.0 | grad norm avg: 7.57 | grad norm last: 7.07 | 
2025-12-28T00:28:24 | step: 245900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.85074186953716e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.7 | consumed tokens: 125900800.0 | grad norm avg: 7.76 | grad norm last: 7.6 | 
2025-12-28T00:28:26 | step: 246000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.849809091771021e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.77 | consumed tokens: 125952000.0 | grad norm avg: 8.07 | grad norm last: 7.87 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_246000-seen_tokens_125952000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_246000-seen_tokens_125952000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_246000-seen_tokens_125952000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_246000-seen_tokens_125952000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_246000-seen_tokens_125952000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_246000-seen_tokens_125952000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_246000-seen_tokens_125952000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_246000-seen_tokens_125952000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:28:28 | step: 246100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.848877769196406e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.25 | consumed tokens: 126003200.0 | grad norm avg: 8.62 | grad norm last: 9.6 | 
2025-12-28T00:28:30 | step: 246200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.847945719026029e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 6.56 | consumed tokens: 126054400.0 | grad norm avg: 8.42 | grad norm last: 28.28 | 
2025-12-28T00:28:32 | step: 246300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.847013668855652e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.42 | consumed tokens: 126105600.0 | grad norm avg: 8.13 | grad norm last: 6.12 | 
2025-12-28T00:28:34 | step: 246400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.846080163493752e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.69 | consumed tokens: 126156800.0 | grad norm avg: 7.68 | grad norm last: 7.34 | 
2025-12-28T00:28:36 | step: 246500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.845146658131853e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.38 | consumed tokens: 126208000.0 | grad norm avg: 8.24 | grad norm last: 7.45 | 
2025-12-28T00:28:38 | step: 246600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.844213880365714e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.97 | train loss last: 5.28 | consumed tokens: 126259200.0 | grad norm avg: 8.26 | grad norm last: 11.71 | 
2025-12-28T00:28:40 | step: 246700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.843279647408053e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.16 | consumed tokens: 126310400.0 | grad norm avg: 7.8 | grad norm last: 9.58 | 
2025-12-28T00:28:42 | step: 246800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.842345414450392e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.55 | consumed tokens: 126361600.0 | grad norm avg: 7.68 | grad norm last: 8.02 | 
2025-12-28T00:28:44 | step: 246900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.841409726301208e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.94 | consumed tokens: 126412800.0 | grad norm avg: 8.23 | grad norm last: 7.84 | 
2025-12-28T00:28:46 | step: 247000 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 8.840475493343547e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.38 | consumed tokens: 126464000.0 | grad norm avg: 7.71 | grad norm last: 7.55 | 
2025-12-28T00:28:48 | step: 247100 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.839540532790124e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.94 | consumed tokens: 126515200.0 | grad norm avg: 7.92 | grad norm last: 7.65 | 
2025-12-28T00:28:50 | step: 247200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.838604117045179e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.59 | consumed tokens: 126566400.0 | grad norm avg: 8.2 | grad norm last: 9.68 | 
2025-12-28T00:28:52 | step: 247300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.837669156491756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.25 | consumed tokens: 126617600.0 | grad norm avg: 7.95 | grad norm last: 12.73 | 
2025-12-28T00:28:54 | step: 247400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 8.836732740746811e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.36 | consumed tokens: 126668800.0 | grad norm avg: 8.13 | grad norm last: 7.24 | 
2025-12-28T00:28:56 | step: 247500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.835797052597627e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.94 | consumed tokens: 126720000.0 | grad norm avg: 7.56 | grad norm last: 6.93 | 
2025-12-28T00:28:58 | step: 247600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.83485990925692e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.84 | consumed tokens: 126771200.0 | grad norm avg: 7.57 | grad norm last: 7.4 | 
2025-12-28T00:29:00 | step: 247700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.833922765916213e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.86 | consumed tokens: 126822400.0 | grad norm avg: 7.96 | grad norm last: 11.8 | 
2025-12-28T00:29:02 | step: 247800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.832985622575507e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.45 | consumed tokens: 126873600.0 | grad norm avg: 8.15 | grad norm last: 7.04 | 
2025-12-28T00:29:04 | step: 247900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.832047024043277e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.0 | consumed tokens: 126924800.0 | grad norm avg: 7.88 | grad norm last: 7.49 | 
2025-12-28T00:29:06 | step: 248000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.831109153106809e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 5.25 | consumed tokens: 126976000.0 | grad norm avg: 7.91 | grad norm last: 12.92 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_248000-seen_tokens_126976000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_248000-seen_tokens_126976000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_248000-seen_tokens_126976000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_248000-seen_tokens_126976000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_248000-seen_tokens_126976000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_248000-seen_tokens_126976000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_248000-seen_tokens_126976000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_248000-seen_tokens_126976000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:29:09 | step: 248100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 8.830169826978818e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.69 | consumed tokens: 127027200.0 | grad norm avg: 7.88 | grad norm last: 7.96 | 
2025-12-28T00:29:11 | step: 248200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.82923195604235e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.45 | consumed tokens: 127078400.0 | grad norm avg: 7.85 | grad norm last: 6.74 | 
2025-12-28T00:29:13 | step: 248300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.828292629914358e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.84 | consumed tokens: 127129600.0 | grad norm avg: 7.91 | grad norm last: 12.18 | 
2025-12-28T00:29:15 | step: 248400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.827352576190606e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.08 | consumed tokens: 127180800.0 | grad norm avg: 7.92 | grad norm last: 6.32 | 
2025-12-28T00:29:17 | step: 248500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.826413977658376e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.77 | consumed tokens: 127232000.0 | grad norm avg: 8.02 | grad norm last: 7.87 | 
2025-12-28T00:29:19 | step: 248600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.825473923934624e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 5.44 | consumed tokens: 127283200.0 | grad norm avg: 8.18 | grad norm last: 12.53 | 
2025-12-28T00:29:21 | step: 248700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.824533870210871e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.03 | consumed tokens: 127334400.0 | grad norm avg: 8.04 | grad norm last: 7.85 | 
2025-12-28T00:29:23 | step: 248800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.823592361295596e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.67 | consumed tokens: 127385600.0 | grad norm avg: 8.27 | grad norm last: 6.94 | 
2025-12-28T00:29:25 | step: 248900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.822651579976082e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.31 | consumed tokens: 127436800.0 | grad norm avg: 8.02 | grad norm last: 9.22 | 
2025-12-28T00:29:27 | step: 249000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.821710798656568e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.06 | consumed tokens: 127488000.0 | grad norm avg: 7.63 | grad norm last: 6.77 | 
2025-12-28T00:29:29 | step: 249100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.820768562145531e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.97 | consumed tokens: 127539200.0 | grad norm avg: 7.65 | grad norm last: 9.77 | 
2025-12-28T00:29:31 | step: 249200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.819826325634494e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.03 | consumed tokens: 127590400.0 | grad norm avg: 8.18 | grad norm last: 7.87 | 
2025-12-28T00:29:33 | step: 249300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.818884816719219e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.67 | consumed tokens: 127641600.0 | grad norm avg: 8.21 | grad norm last: 6.91 | 
2025-12-28T00:29:35 | step: 249400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.817941852612421e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.03 | consumed tokens: 127692800.0 | grad norm avg: 8.3 | grad norm last: 8.79 | 
2025-12-28T00:29:37 | step: 249500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.816998888505623e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.78 | consumed tokens: 127744000.0 | grad norm avg: 8.13 | grad norm last: 6.49 | 
2025-12-28T00:29:39 | step: 249600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.816055924398825e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.16 | consumed tokens: 127795200.0 | grad norm avg: 7.7 | grad norm last: 7.93 | 
2025-12-28T00:29:41 | step: 249700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.815111505100504e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.39 | consumed tokens: 127846400.0 | grad norm avg: 7.92 | grad norm last: 7.3 | 
2025-12-28T00:29:43 | step: 249800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.814168540993705e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.62 | consumed tokens: 127897600.0 | grad norm avg: 7.64 | grad norm last: 6.92 | 
2025-12-28T00:29:45 | step: 249900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.813224121695384e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.59 | consumed tokens: 127948800.0 | grad norm avg: 8.07 | grad norm last: 9.21 | 
2025-12-28T00:29:47 | step: 250000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.812279702397063e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.33 | consumed tokens: 128000000.0 | grad norm avg: 7.73 | grad norm last: 7.74 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_250000-seen_tokens_128000000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_250000-seen_tokens_128000000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_250000-seen_tokens_128000000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_250000-seen_tokens_128000000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_250000-seen_tokens_128000000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_250000-seen_tokens_128000000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_250000-seen_tokens_128000000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_250000-seen_tokens_128000000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:29:49 | step: 250100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.811335283098742e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.89 | train loss last: 3.56 | consumed tokens: 128051200.0 | grad norm avg: 8.18 | grad norm last: 6.15 | 
2025-12-28T00:29:51 | step: 250200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.81039013620466e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.73 | consumed tokens: 128102400.0 | grad norm avg: 7.56 | grad norm last: 8.2 | 
2025-12-28T00:29:53 | step: 250300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.809444261714816e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.16 | consumed tokens: 128153600.0 | grad norm avg: 8.0 | grad norm last: 6.76 | 
2025-12-28T00:29:55 | step: 250400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.808498387224972e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.25 | consumed tokens: 128204800.0 | grad norm avg: 7.66 | grad norm last: 8.61 | 
2025-12-28T00:29:57 | step: 250500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.807552512735128e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.45 | consumed tokens: 128256000.0 | grad norm avg: 8.2 | grad norm last: 6.59 | 
2025-12-28T00:29:59 | step: 250600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.806605910649523e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.09 | consumed tokens: 128307200.0 | grad norm avg: 7.82 | grad norm last: 7.17 | 
2025-12-28T00:30:01 | step: 250700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.805658580968156e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.03 | consumed tokens: 128358400.0 | grad norm avg: 7.91 | grad norm last: 7.52 | 
2025-12-28T00:30:03 | step: 250800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.804712706478313e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.86 | consumed tokens: 128409600.0 | grad norm avg: 7.85 | grad norm last: 7.88 | 
2025-12-28T00:30:05 | step: 250900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.803765376796946e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.3 | consumed tokens: 128460800.0 | grad norm avg: 7.75 | grad norm last: 8.32 | 
2025-12-28T00:30:07 | step: 251000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.802817319519818e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 5.19 | consumed tokens: 128512000.0 | grad norm avg: 7.81 | grad norm last: 11.85 | 
2025-12-28T00:30:09 | step: 251100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.80186926224269e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.52 | consumed tokens: 128563200.0 | grad norm avg: 7.9 | grad norm last: 7.05 | 
2025-12-28T00:30:11 | step: 251200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.8009204773698e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.3 | consumed tokens: 128614400.0 | grad norm avg: 8.01 | grad norm last: 6.37 | 
2025-12-28T00:30:13 | step: 251300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.799971692496911e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.31 | consumed tokens: 128665600.0 | grad norm avg: 8.9 | grad norm last: 6.46 | 
2025-12-28T00:30:15 | step: 251400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.799022907624021e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.47 | consumed tokens: 128716800.0 | grad norm avg: 7.72 | grad norm last: 8.32 | 
2025-12-28T00:30:17 | step: 251500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.798074122751132e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.67 | consumed tokens: 128768000.0 | grad norm avg: 8.19 | grad norm last: 6.86 | 
2025-12-28T00:30:19 | step: 251600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.797124610282481e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.84 | consumed tokens: 128819200.0 | grad norm avg: 7.91 | grad norm last: 6.85 | 
2025-12-28T00:30:21 | step: 251700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.79617509781383e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.34 | consumed tokens: 128870400.0 | grad norm avg: 7.74 | grad norm last: 8.75 | 
2025-12-28T00:30:23 | step: 251800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.795224857749417e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.8 | consumed tokens: 128921600.0 | grad norm avg: 7.97 | grad norm last: 7.04 | 
2025-12-28T00:30:25 | step: 251900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.794273162493482e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.95 | consumed tokens: 128972800.0 | grad norm avg: 7.65 | grad norm last: 6.92 | 
2025-12-28T00:30:27 | step: 252000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.79332292242907e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.09 | consumed tokens: 129024000.0 | grad norm avg: 7.66 | grad norm last: 7.54 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_252000-seen_tokens_129024000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_252000-seen_tokens_129024000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_252000-seen_tokens_129024000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_252000-seen_tokens_129024000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_252000-seen_tokens_129024000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_252000-seen_tokens_129024000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_252000-seen_tokens_129024000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_252000-seen_tokens_129024000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:30:30 | step: 252100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.792371954768896e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.69 | consumed tokens: 129075200.0 | grad norm avg: 8.05 | grad norm last: 10.45 | 
2025-12-28T00:30:32 | step: 252200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.791420259512961e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.12 | consumed tokens: 129126400.0 | grad norm avg: 7.91 | grad norm last: 7.12 | 
2025-12-28T00:30:34 | step: 252300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.790468564257026e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.5 | consumed tokens: 129177600.0 | grad norm avg: 7.64 | grad norm last: 7.87 | 
2025-12-28T00:30:36 | step: 252400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 8.78951686900109e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.61 | consumed tokens: 129228800.0 | grad norm avg: 8.34 | grad norm last: 7.03 | 
2025-12-28T00:30:38 | step: 252500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.788564446149394e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.98 | consumed tokens: 129280000.0 | grad norm avg: 8.25 | grad norm last: 8.73 | 
2025-12-28T00:30:40 | step: 252600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.787611295701936e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.19 | consumed tokens: 129331200.0 | grad norm avg: 8.34 | grad norm last: 7.64 | 
2025-12-28T00:30:42 | step: 252700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.786658145254478e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.19 | consumed tokens: 129382400.0 | grad norm avg: 8.14 | grad norm last: 8.7 | 
2025-12-28T00:30:44 | step: 252800 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 8.78570499480702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.59 | consumed tokens: 129433600.0 | grad norm avg: 8.06 | grad norm last: 9.83 | 
2025-12-28T00:30:46 | step: 252900 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 8.784750389168039e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.12 | consumed tokens: 129484800.0 | grad norm avg: 8.29 | grad norm last: 7.67 | 
2025-12-28T00:30:48 | step: 253000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.783797238720581e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.58 | consumed tokens: 129536000.0 | grad norm avg: 8.24 | grad norm last: 7.54 | 
2025-12-28T00:30:50 | step: 253100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 8.782843360677361e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.55 | consumed tokens: 129587200.0 | grad norm avg: 8.3 | grad norm last: 7.91 | 
2025-12-28T00:30:52 | step: 253200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.78188875503838e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.28 | consumed tokens: 129638400.0 | grad norm avg: 7.83 | grad norm last: 7.94 | 
2025-12-28T00:30:54 | step: 253300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.780933421803638e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.58 | consumed tokens: 129689600.0 | grad norm avg: 7.97 | grad norm last: 6.77 | 
2025-12-28T00:30:56 | step: 253400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.779977360973135e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.64 | consumed tokens: 129740800.0 | grad norm avg: 7.64 | grad norm last: 8.23 | 
2025-12-28T00:30:58 | step: 253500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.779022755334154e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.22 | consumed tokens: 129792000.0 | grad norm avg: 7.95 | grad norm last: 7.27 | 
2025-12-28T00:31:00 | step: 253600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.77806669450365e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.38 | consumed tokens: 129843200.0 | grad norm avg: 8.18 | grad norm last: 9.04 | 
2025-12-28T00:31:02 | step: 253700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.777110633673146e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.12 | consumed tokens: 129894400.0 | grad norm avg: 8.29 | grad norm last: 6.99 | 
2025-12-28T00:31:04 | step: 253800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.77615311765112e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.55 | consumed tokens: 129945600.0 | grad norm avg: 8.09 | grad norm last: 8.0 | 
2025-12-28T00:31:06 | step: 253900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.775197056820616e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.55 | consumed tokens: 129996800.0 | grad norm avg: 8.55 | grad norm last: 7.27 | 
2025-12-28T00:31:08 | step: 254000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.774240268394351e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.66 | consumed tokens: 130048000.0 | grad norm avg: 8.09 | grad norm last: 7.36 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_254000-seen_tokens_130048000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_254000-seen_tokens_130048000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_254000-seen_tokens_130048000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_254000-seen_tokens_130048000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_254000-seen_tokens_130048000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_254000-seen_tokens_130048000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_254000-seen_tokens_130048000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_254000-seen_tokens_130048000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:31:10 | step: 254100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.773282752372324e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.8 | train loss last: 3.16 | consumed tokens: 130099200.0 | grad norm avg: 8.09 | grad norm last: 8.45 | 
2025-12-28T00:31:12 | step: 254200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.772324508754537e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.41 | consumed tokens: 130150400.0 | grad norm avg: 8.09 | grad norm last: 8.41 | 
2025-12-28T00:31:14 | step: 254300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.77136699273251e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.16 | consumed tokens: 130201600.0 | grad norm avg: 7.96 | grad norm last: 7.48 | 
2025-12-28T00:31:16 | step: 254400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.77040802151896e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.44 | consumed tokens: 130252800.0 | grad norm avg: 8.06 | grad norm last: 7.84 | 
2025-12-28T00:31:19 | step: 254500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.769449050305411e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.09 | consumed tokens: 130304000.0 | grad norm avg: 8.15 | grad norm last: 7.91 | 
2025-12-28T00:31:21 | step: 254600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.768490079091862e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.67 | consumed tokens: 130355200.0 | grad norm avg: 7.96 | grad norm last: 6.96 | 
2025-12-28T00:31:23 | step: 254700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.767531107878312e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.38 | consumed tokens: 130406400.0 | grad norm avg: 7.8 | grad norm last: 10.77 | 
2025-12-28T00:31:25 | step: 254800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.766571409069002e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.69 | consumed tokens: 130457600.0 | grad norm avg: 8.24 | grad norm last: 6.2 | 
2025-12-28T00:31:27 | step: 254900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.76561098266393e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.03 | consumed tokens: 130508800.0 | grad norm avg: 7.79 | grad norm last: 6.67 | 
2025-12-28T00:31:29 | step: 255000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.764651283854619e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.06 | consumed tokens: 130560000.0 | grad norm avg: 8.13 | grad norm last: 6.89 | 
2025-12-28T00:31:31 | step: 255100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.763690129853785e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.31 | consumed tokens: 130611200.0 | grad norm avg: 7.98 | grad norm last: 7.28 | 
2025-12-28T00:31:33 | step: 255200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.762729703448713e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.95 | consumed tokens: 130662400.0 | grad norm avg: 8.29 | grad norm last: 7.22 | 
2025-12-28T00:31:35 | step: 255300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.761768549447879e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.44 | consumed tokens: 130713600.0 | grad norm avg: 8.42 | grad norm last: 7.96 | 
2025-12-28T00:31:37 | step: 255400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.760806667851284e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.39 | consumed tokens: 130764800.0 | grad norm avg: 8.14 | grad norm last: 7.0 | 
2025-12-28T00:31:39 | step: 255500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.759844786254689e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.62 | consumed tokens: 130816000.0 | grad norm avg: 8.23 | grad norm last: 9.27 | 
2025-12-28T00:31:41 | step: 255600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.758882904658094e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.12 | consumed tokens: 130867200.0 | grad norm avg: 8.1 | grad norm last: 10.8 | 
2025-12-28T00:31:43 | step: 255700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.757921023061499e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.92 | consumed tokens: 130918400.0 | grad norm avg: 8.16 | grad norm last: 7.85 | 
2025-12-28T00:31:45 | step: 255800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.756956231081858e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.44 | consumed tokens: 130969600.0 | grad norm avg: 8.02 | grad norm last: 8.99 | 
2025-12-28T00:31:47 | step: 255900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.755994349485263e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.7 | consumed tokens: 131020800.0 | grad norm avg: 8.45 | grad norm last: 8.7 | 
2025-12-28T00:31:49 | step: 256000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.755031012697145e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.86 | consumed tokens: 131072000.0 | grad norm avg: 7.84 | grad norm last: 6.85 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_256000-seen_tokens_131072000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_256000-seen_tokens_131072000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_256000-seen_tokens_131072000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_256000-seen_tokens_131072000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_256000-seen_tokens_131072000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_256000-seen_tokens_131072000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_256000-seen_tokens_131072000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_256000-seen_tokens_131072000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:31:51 | step: 256100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.754067675909027e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.61 | consumed tokens: 131123200.0 | grad norm avg: 8.2 | grad norm last: 7.86 | 
2025-12-28T00:31:53 | step: 256200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.753102883929387e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.0 | consumed tokens: 131174400.0 | grad norm avg: 7.89 | grad norm last: 7.7 | 
2025-12-28T00:31:55 | step: 256300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.752138819545507e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.56 | consumed tokens: 131225600.0 | grad norm avg: 8.19 | grad norm last: 12.44 | 
2025-12-28T00:31:57 | step: 256400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.751174755161628e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.16 | consumed tokens: 131276800.0 | grad norm avg: 8.15 | grad norm last: 8.72 | 
2025-12-28T00:31:59 | step: 256500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.750208507990465e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.47 | consumed tokens: 131328000.0 | grad norm avg: 8.2 | grad norm last: 6.75 | 
2025-12-28T00:32:01 | step: 256600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.749243716010824e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.38 | consumed tokens: 131379200.0 | grad norm avg: 8.0 | grad norm last: 7.46 | 
2025-12-28T00:32:03 | step: 256700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.74827746883966e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.59 | consumed tokens: 131430400.0 | grad norm avg: 8.04 | grad norm last: 23.65 | 
2025-12-28T00:32:05 | step: 256800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.747311221668497e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 5.0 | consumed tokens: 131481600.0 | grad norm avg: 8.12 | grad norm last: 8.42 | 
2025-12-28T00:32:07 | step: 256900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.746344974497333e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.55 | consumed tokens: 131532800.0 | grad norm avg: 7.92 | grad norm last: 6.64 | 
2025-12-28T00:32:09 | step: 257000 | train samples/s: 99.1 | train mfu (16-bit): -1.0 | lr mean: 8.74537872732617e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.53 | consumed tokens: 131584000.0 | grad norm avg: 8.02 | grad norm last: 6.84 | 
2025-12-28T00:32:11 | step: 257100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.744412480155006e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.59 | consumed tokens: 131635200.0 | grad norm avg: 8.08 | grad norm last: 9.0 | 
2025-12-28T00:32:13 | step: 257200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 8.74344477779232e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.12 | consumed tokens: 131686400.0 | grad norm avg: 7.92 | grad norm last: 6.65 | 
2025-12-28T00:32:15 | step: 257300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.742478530621156e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.73 | consumed tokens: 131737600.0 | grad norm avg: 8.14 | grad norm last: 6.88 | 
2025-12-28T00:32:17 | step: 257400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.741509373066947e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.28 | consumed tokens: 131788800.0 | grad norm avg: 8.14 | grad norm last: 7.72 | 
2025-12-28T00:32:19 | step: 257500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.74054167070426e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 6.06 | consumed tokens: 131840000.0 | grad norm avg: 7.98 | grad norm last: 14.39 | 
2025-12-28T00:32:21 | step: 257600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.739573968341574e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.97 | consumed tokens: 131891200.0 | grad norm avg: 8.63 | grad norm last: 7.6 | 
2025-12-28T00:32:24 | step: 257700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.738603355595842e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 5.81 | consumed tokens: 131942400.0 | grad norm avg: 8.17 | grad norm last: 15.94 | 
2025-12-28T00:32:26 | step: 257800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.737635653233156e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.31 | consumed tokens: 131993600.0 | grad norm avg: 8.07 | grad norm last: 7.28 | 
2025-12-28T00:32:28 | step: 257900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 8.736665040487424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.47 | consumed tokens: 132044800.0 | grad norm avg: 8.18 | grad norm last: 7.86 | 
2025-12-28T00:32:30 | step: 258000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 8.735695882933214e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.97 | consumed tokens: 132096000.0 | grad norm avg: 8.01 | grad norm last: 7.82 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_258000-seen_tokens_132096000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_258000-seen_tokens_132096000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_258000-seen_tokens_132096000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_258000-seen_tokens_132096000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_258000-seen_tokens_132096000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_258000-seen_tokens_132096000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_258000-seen_tokens_132096000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_258000-seen_tokens_132096000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:32:32 | step: 258100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.734725997783244e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.87 | train loss last: 3.88 | consumed tokens: 132147200.0 | grad norm avg: 8.38 | grad norm last: 9.36 | 
2025-12-28T00:32:34 | step: 258200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.733756112633273e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.82 | train loss last: 4.16 | consumed tokens: 132198400.0 | grad norm avg: 8.27 | grad norm last: 10.94 | 
2025-12-28T00:32:36 | step: 258300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.732785499887541e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.11 | consumed tokens: 132249600.0 | grad norm avg: 8.1 | grad norm last: 6.76 | 
2025-12-28T00:32:38 | step: 258400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.731814887141809e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.62 | consumed tokens: 132300800.0 | grad norm avg: 8.54 | grad norm last: 10.92 | 
2025-12-28T00:32:40 | step: 258500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.730842819204554e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.0 | consumed tokens: 132352000.0 | grad norm avg: 8.42 | grad norm last: 8.32 | 
2025-12-28T00:32:42 | step: 258600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.72987147886306e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.09 | consumed tokens: 132403200.0 | grad norm avg: 8.01 | grad norm last: 6.4 | 
2025-12-28T00:32:44 | step: 258700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.728899410925806e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.31 | consumed tokens: 132454400.0 | grad norm avg: 8.09 | grad norm last: 7.0 | 
2025-12-28T00:32:46 | step: 258800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.72792734298855e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.61 | consumed tokens: 132505600.0 | grad norm avg: 8.39 | grad norm last: 7.08 | 
2025-12-28T00:32:48 | step: 258900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.726955275051296e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.44 | consumed tokens: 132556800.0 | grad norm avg: 7.96 | grad norm last: 8.46 | 
2025-12-28T00:32:50 | step: 259000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.72598247951828e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.69 | consumed tokens: 132608000.0 | grad norm avg: 8.15 | grad norm last: 7.39 | 
2025-12-28T00:32:52 | step: 259100 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.725008956389502e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.77 | consumed tokens: 132659200.0 | grad norm avg: 8.3 | grad norm last: 7.48 | 
2025-12-28T00:32:54 | step: 259200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.724035433260724e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.92 | consumed tokens: 132710400.0 | grad norm avg: 8.06 | grad norm last: 8.85 | 
2025-12-28T00:32:56 | step: 259300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.723061910131946e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.8 | consumed tokens: 132761600.0 | grad norm avg: 8.25 | grad norm last: 7.36 | 
2025-12-28T00:32:58 | step: 259400 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.722088387003168e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.11 | consumed tokens: 132812800.0 | grad norm avg: 8.11 | grad norm last: 7.16 | 
2025-12-28T00:33:00 | step: 259500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.721113408682868e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.47 | consumed tokens: 132864000.0 | grad norm avg: 8.36 | grad norm last: 10.09 | 
2025-12-28T00:33:02 | step: 259600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.720139157958329e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.7 | consumed tokens: 132915200.0 | grad norm avg: 8.4 | grad norm last: 7.69 | 
2025-12-28T00:33:04 | step: 259700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.719164179638028e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.42 | consumed tokens: 132966400.0 | grad norm avg: 8.47 | grad norm last: 7.09 | 
2025-12-28T00:33:06 | step: 259800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.718188473721966e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.56 | consumed tokens: 133017600.0 | grad norm avg: 8.0 | grad norm last: 6.92 | 
2025-12-28T00:33:08 | step: 259900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.717213495401666e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.89 | consumed tokens: 133068800.0 | grad norm avg: 8.1 | grad norm last: 7.81 | 
2025-12-28T00:33:10 | step: 260000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.716237061889842e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.5 | consumed tokens: 133120000.0 | grad norm avg: 8.84 | grad norm last: 8.17 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_260000-seen_tokens_133120000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_260000-seen_tokens_133120000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_260000-seen_tokens_133120000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_260000-seen_tokens_133120000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_260000-seen_tokens_133120000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_260000-seen_tokens_133120000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_260000-seen_tokens_133120000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_260000-seen_tokens_133120000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:33:13 | step: 260100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.71526135597378e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.84 | train loss last: 3.23 | consumed tokens: 133171200.0 | grad norm avg: 8.05 | grad norm last: 7.0 | 
2025-12-28T00:33:15 | step: 260200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.714284194866195e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.16 | consumed tokens: 133222400.0 | grad norm avg: 8.65 | grad norm last: 6.83 | 
2025-12-28T00:33:17 | step: 260300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.713307761354372e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.81 | consumed tokens: 133273600.0 | grad norm avg: 8.2 | grad norm last: 7.95 | 
2025-12-28T00:33:19 | step: 260400 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 8.712330600246787e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.78 | consumed tokens: 133324800.0 | grad norm avg: 7.93 | grad norm last: 6.61 | 
2025-12-28T00:33:21 | step: 260500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.711353439139202e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.06 | consumed tokens: 133376000.0 | grad norm avg: 8.29 | grad norm last: 7.9 | 
2025-12-28T00:33:23 | step: 260600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.710375550435856e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.77 | consumed tokens: 133427200.0 | grad norm avg: 8.29 | grad norm last: 7.6 | 
2025-12-28T00:33:25 | step: 260700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.70939766173251e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.09 | consumed tokens: 133478400.0 | grad norm avg: 8.17 | grad norm last: 9.42 | 
2025-12-28T00:33:27 | step: 260800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.708419045433402e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.88 | consumed tokens: 133529600.0 | grad norm avg: 8.47 | grad norm last: 8.32 | 
2025-12-28T00:33:29 | step: 260900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.707440429134294e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.38 | consumed tokens: 133580800.0 | grad norm avg: 7.96 | grad norm last: 8.12 | 
2025-12-28T00:33:31 | step: 261000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.706461085239425e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.16 | consumed tokens: 133632000.0 | grad norm avg: 8.22 | grad norm last: 7.23 | 
2025-12-28T00:33:33 | step: 261100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.705481741344556e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.31 | consumed tokens: 133683200.0 | grad norm avg: 8.19 | grad norm last: 8.57 | 
2025-12-28T00:33:35 | step: 261200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.704502397449687e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.89 | consumed tokens: 133734400.0 | grad norm avg: 8.11 | grad norm last: 6.81 | 
2025-12-28T00:33:37 | step: 261300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.703521598363295e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 5.62 | consumed tokens: 133785600.0 | grad norm avg: 8.24 | grad norm last: 9.3 | 
2025-12-28T00:33:39 | step: 261400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.702542254468426e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.23 | consumed tokens: 133836800.0 | grad norm avg: 8.06 | grad norm last: 6.17 | 
2025-12-28T00:33:41 | step: 261500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.701562182977796e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.8 | consumed tokens: 133888000.0 | grad norm avg: 8.26 | grad norm last: 7.97 | 
2025-12-28T00:33:43 | step: 261600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.700580656295642e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.48 | consumed tokens: 133939200.0 | grad norm avg: 7.92 | grad norm last: 6.87 | 
2025-12-28T00:33:45 | step: 261700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.69959985720925e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.72 | consumed tokens: 133990400.0 | grad norm avg: 8.65 | grad norm last: 6.92 | 
2025-12-28T00:33:47 | step: 261800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.698619058122858e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.88 | consumed tokens: 134041600.0 | grad norm avg: 8.66 | grad norm last: 8.09 | 
2025-12-28T00:33:49 | step: 261900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.697636803844944e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.09 | consumed tokens: 134092800.0 | grad norm avg: 8.18 | grad norm last: 6.74 | 
2025-12-28T00:33:51 | step: 262000 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 8.696654549567029e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 5.47 | consumed tokens: 134144000.0 | grad norm avg: 8.12 | grad norm last: 29.96 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_262000-seen_tokens_134144000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_262000-seen_tokens_134144000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_262000-seen_tokens_134144000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_262000-seen_tokens_134144000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_262000-seen_tokens_134144000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_262000-seen_tokens_134144000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_262000-seen_tokens_134144000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_262000-seen_tokens_134144000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:33:53 | step: 262100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.695672295289114e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.78 | train loss last: 3.53 | consumed tokens: 134195200.0 | grad norm avg: 8.22 | grad norm last: 6.97 | 
2025-12-28T00:33:55 | step: 262200 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.6946900410112e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.52 | consumed tokens: 134246400.0 | grad norm avg: 8.5 | grad norm last: 6.87 | 
2025-12-28T00:33:57 | step: 262300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 8.693706331541762e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.48 | consumed tokens: 134297600.0 | grad norm avg: 7.85 | grad norm last: 6.85 | 
2025-12-28T00:33:59 | step: 262400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 8.692723349668086e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.53 | consumed tokens: 134348800.0 | grad norm avg: 7.97 | grad norm last: 7.38 | 
2025-12-28T00:34:01 | step: 262500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.691739640198648e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.31 | consumed tokens: 134400000.0 | grad norm avg: 8.1 | grad norm last: 10.44 | 
2025-12-28T00:34:03 | step: 262600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.69075593072921e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.34 | consumed tokens: 134451200.0 | grad norm avg: 8.37 | grad norm last: 11.49 | 
2025-12-28T00:34:05 | step: 262700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 8.689771493664011e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.84 | consumed tokens: 134502400.0 | grad norm avg: 8.03 | grad norm last: 7.23 | 
2025-12-28T00:34:07 | step: 262800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 8.688787784194574e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.39 | consumed tokens: 134553600.0 | grad norm avg: 7.88 | grad norm last: 7.07 | 
2025-12-28T00:34:09 | step: 262900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.687801891937852e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.69 | consumed tokens: 134604800.0 | grad norm avg: 8.04 | grad norm last: 8.27 | 
2025-12-28T00:34:11 | step: 263000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.686817454872653e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.83 | consumed tokens: 134656000.0 | grad norm avg: 7.96 | grad norm last: 7.24 | 
2025-12-28T00:34:13 | step: 263100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.685831562615931e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.44 | consumed tokens: 134707200.0 | grad norm avg: 8.26 | grad norm last: 9.56 | 
2025-12-28T00:34:15 | step: 263200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.684845670359209e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.97 | consumed tokens: 134758400.0 | grad norm avg: 7.9 | grad norm last: 8.86 | 
2025-12-28T00:34:17 | step: 263300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.683859050506726e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.98 | train loss last: 3.75 | consumed tokens: 134809600.0 | grad norm avg: 8.33 | grad norm last: 7.48 | 
2025-12-28T00:34:19 | step: 263400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.682873885845765e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.7 | consumed tokens: 134860800.0 | grad norm avg: 8.1 | grad norm last: 8.38 | 
2025-12-28T00:34:21 | step: 263500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.68188581080176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 5.22 | consumed tokens: 134912000.0 | grad norm avg: 8.11 | grad norm last: 9.0 | 
2025-12-28T00:34:23 | step: 263600 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.680900646140799e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.16 | consumed tokens: 134963200.0 | grad norm avg: 8.04 | grad norm last: 7.76 | 
2025-12-28T00:34:25 | step: 263700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.679912571096793e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.97 | consumed tokens: 135014400.0 | grad norm avg: 8.16 | grad norm last: 8.75 | 
2025-12-28T00:34:27 | step: 263800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.678925223648548e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.61 | consumed tokens: 135065600.0 | grad norm avg: 8.05 | grad norm last: 7.34 | 
2025-12-28T00:34:29 | step: 263900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.677937876200303e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.67 | consumed tokens: 135116800.0 | grad norm avg: 8.15 | grad norm last: 6.72 | 
2025-12-28T00:34:31 | step: 264000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.676949073560536e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.16 | consumed tokens: 135168000.0 | grad norm avg: 8.11 | grad norm last: 8.13 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_264000-seen_tokens_135168000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_264000-seen_tokens_135168000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_264000-seen_tokens_135168000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_264000-seen_tokens_135168000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_264000-seen_tokens_135168000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_264000-seen_tokens_135168000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_264000-seen_tokens_135168000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_264000-seen_tokens_135168000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:34:34 | step: 264100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.675960270920768e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.79 | train loss last: 3.91 | consumed tokens: 135219200.0 | grad norm avg: 7.93 | grad norm last: 7.54 | 
2025-12-28T00:34:36 | step: 264200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.67497074068524e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.56 | consumed tokens: 135270400.0 | grad norm avg: 8.16 | grad norm last: 9.51 | 
2025-12-28T00:34:38 | step: 264300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.673982665641233e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.33 | consumed tokens: 135321600.0 | grad norm avg: 8.02 | grad norm last: 6.96 | 
2025-12-28T00:34:40 | step: 264400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.672993135405704e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.16 | consumed tokens: 135372800.0 | grad norm avg: 8.18 | grad norm last: 7.93 | 
2025-12-28T00:34:42 | step: 264500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.672003605170175e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.78 | consumed tokens: 135424000.0 | grad norm avg: 8.08 | grad norm last: 6.48 | 
2025-12-28T00:34:44 | step: 264600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.671012619743124e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.55 | consumed tokens: 135475200.0 | grad norm avg: 7.93 | grad norm last: 7.47 | 
2025-12-28T00:34:46 | step: 264700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.670023089507595e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.69 | consumed tokens: 135526400.0 | grad norm avg: 7.82 | grad norm last: 8.77 | 
2025-12-28T00:34:48 | step: 264800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.669032104080543e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.39 | consumed tokens: 135577600.0 | grad norm avg: 8.76 | grad norm last: 7.47 | 
2025-12-28T00:34:50 | step: 264900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.668042573845014e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.38 | consumed tokens: 135628800.0 | grad norm avg: 8.47 | grad norm last: 8.74 | 
2025-12-28T00:34:52 | step: 265000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.66705013322644e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.22 | consumed tokens: 135680000.0 | grad norm avg: 8.14 | grad norm last: 7.48 | 
2025-12-28T00:34:54 | step: 265100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.666058420203626e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.3 | consumed tokens: 135731200.0 | grad norm avg: 8.16 | grad norm last: 7.01 | 
2025-12-28T00:34:56 | step: 265200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.665066707180813e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.47 | consumed tokens: 135782400.0 | grad norm avg: 8.08 | grad norm last: 9.34 | 
2025-12-28T00:34:58 | step: 265300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.664074266562238e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.38 | consumed tokens: 135833600.0 | grad norm avg: 7.91 | grad norm last: 6.48 | 
2025-12-28T00:35:00 | step: 265400 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 8.663083281135187e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.22 | consumed tokens: 135884800.0 | grad norm avg: 8.07 | grad norm last: 6.77 | 
2025-12-28T00:35:02 | step: 265500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.662089385325089e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.47 | consumed tokens: 135936000.0 | grad norm avg: 7.97 | grad norm last: 7.53 | 
2025-12-28T00:35:04 | step: 265600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.661096217110753e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.55 | consumed tokens: 135987200.0 | grad norm avg: 8.04 | grad norm last: 7.62 | 
2025-12-28T00:35:06 | step: 265700 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.660103048896417e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.88 | consumed tokens: 136038400.0 | grad norm avg: 8.02 | grad norm last: 8.51 | 
2025-12-28T00:35:08 | step: 265800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.65910915308632e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.19 | consumed tokens: 136089600.0 | grad norm avg: 7.92 | grad norm last: 8.34 | 
2025-12-28T00:35:10 | step: 265900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.658115257276222e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.31 | consumed tokens: 136140800.0 | grad norm avg: 7.9 | grad norm last: 7.47 | 
2025-12-28T00:35:12 | step: 266000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.657121361466125e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.38 | consumed tokens: 136192000.0 | grad norm avg: 7.73 | grad norm last: 13.02 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_266000-seen_tokens_136192000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_266000-seen_tokens_136192000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_266000-seen_tokens_136192000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_266000-seen_tokens_136192000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_266000-seen_tokens_136192000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_266000-seen_tokens_136192000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_266000-seen_tokens_136192000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_266000-seen_tokens_136192000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:35:14 | step: 266100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.656127465656027e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 5.53 | consumed tokens: 136243200.0 | grad norm avg: 8.39 | grad norm last: 20.65 | 
2025-12-28T00:35:16 | step: 266200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.655132114654407e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 4.5 | consumed tokens: 136294400.0 | grad norm avg: 7.77 | grad norm last: 7.38 | 
2025-12-28T00:35:18 | step: 266300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.654136763652787e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.28 | consumed tokens: 136345600.0 | grad norm avg: 7.8 | grad norm last: 6.36 | 
2025-12-28T00:35:20 | step: 266400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.653141412651166e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.56 | consumed tokens: 136396800.0 | grad norm avg: 8.33 | grad norm last: 7.8 | 
2025-12-28T00:35:22 | step: 266500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.652146061649546e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.88 | consumed tokens: 136448000.0 | grad norm avg: 8.0 | grad norm last: 12.38 | 
2025-12-28T00:35:24 | step: 266600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.651149255456403e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.22 | consumed tokens: 136499200.0 | grad norm avg: 7.66 | grad norm last: 8.3 | 
2025-12-28T00:35:26 | step: 266700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.65015244926326e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.16 | consumed tokens: 136550400.0 | grad norm avg: 7.97 | grad norm last: 6.93 | 
2025-12-28T00:35:28 | step: 266800 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 8.649155643070117e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.14 | consumed tokens: 136601600.0 | grad norm avg: 7.92 | grad norm last: 6.12 | 
2025-12-28T00:35:30 | step: 266900 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.648158836876974e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.92 | consumed tokens: 136652800.0 | grad norm avg: 8.01 | grad norm last: 8.42 | 
2025-12-28T00:35:32 | step: 267000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.647161303088069e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.86 | consumed tokens: 136704000.0 | grad norm avg: 7.95 | grad norm last: 7.05 | 
2025-12-28T00:35:34 | step: 267100 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.646163769299164e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.41 | consumed tokens: 136755200.0 | grad norm avg: 8.17 | grad norm last: 12.77 | 
2025-12-28T00:35:36 | step: 267200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.645166963106021e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.91 | consumed tokens: 136806400.0 | grad norm avg: 8.11 | grad norm last: 7.5 | 
2025-12-28T00:35:38 | step: 267300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 8.644167246529832e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.62 | consumed tokens: 136857600.0 | grad norm avg: 8.35 | grad norm last: 7.45 | 
2025-12-28T00:35:40 | step: 267400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 8.643168985145167e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.94 | consumed tokens: 136908800.0 | grad norm avg: 8.09 | grad norm last: 8.26 | 
2025-12-28T00:35:42 | step: 267500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.6421707237605e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.88 | consumed tokens: 136960000.0 | grad norm avg: 8.19 | grad norm last: 7.62 | 
2025-12-28T00:35:45 | step: 267600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.641171007184312e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.66 | consumed tokens: 137011200.0 | grad norm avg: 8.01 | grad norm last: 7.17 | 
2025-12-28T00:35:47 | step: 267700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.640172745799646e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.91 | consumed tokens: 137062400.0 | grad norm avg: 7.97 | grad norm last: 6.75 | 
2025-12-28T00:35:49 | step: 267800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.639172301627696e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.42 | consumed tokens: 137113600.0 | grad norm avg: 7.95 | grad norm last: 6.71 | 
2025-12-28T00:35:51 | step: 267900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.638171857455745e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.61 | consumed tokens: 137164800.0 | grad norm avg: 7.92 | grad norm last: 7.37 | 
2025-12-28T00:35:53 | step: 268000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.637172140879557e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.69 | consumed tokens: 137216000.0 | grad norm avg: 8.15 | grad norm last: 8.98 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_268000-seen_tokens_137216000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_268000-seen_tokens_137216000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_268000-seen_tokens_137216000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_268000-seen_tokens_137216000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_268000-seen_tokens_137216000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_268000-seen_tokens_137216000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_268000-seen_tokens_137216000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_268000-seen_tokens_137216000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:35:55 | step: 268100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 8.636170969111845e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.83 | train loss last: 3.38 | consumed tokens: 137267200.0 | grad norm avg: 8.16 | grad norm last: 6.6 | 
2025-12-28T00:35:57 | step: 268200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.635170524939895e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.86 | train loss last: 4.03 | consumed tokens: 137318400.0 | grad norm avg: 7.84 | grad norm last: 7.65 | 
2025-12-28T00:35:59 | step: 268300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.634169353172183e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.81 | consumed tokens: 137369600.0 | grad norm avg: 8.17 | grad norm last: 9.8 | 
2025-12-28T00:36:01 | step: 268400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.63316745380871e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.16 | consumed tokens: 137420800.0 | grad norm avg: 8.05 | grad norm last: 6.96 | 
2025-12-28T00:36:03 | step: 268500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.632164826849476e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.5 | consumed tokens: 137472000.0 | grad norm avg: 8.22 | grad norm last: 10.39 | 
2025-12-28T00:36:05 | step: 268600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.631163655081764e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.78 | consumed tokens: 137523200.0 | grad norm avg: 7.92 | grad norm last: 9.26 | 
2025-12-28T00:36:07 | step: 268700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.63016102812253e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.75 | consumed tokens: 137574400.0 | grad norm avg: 8.09 | grad norm last: 7.26 | 
2025-12-28T00:36:09 | step: 268800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.629158401163295e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.44 | consumed tokens: 137625600.0 | grad norm avg: 7.68 | grad norm last: 7.27 | 
2025-12-28T00:36:11 | step: 268900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.628154319012538e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.31 | consumed tokens: 137676800.0 | grad norm avg: 8.09 | grad norm last: 8.02 | 
2025-12-28T00:36:13 | step: 269000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.627151692053303e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.75 | consumed tokens: 137728000.0 | grad norm avg: 8.11 | grad norm last: 7.26 | 
2025-12-28T00:36:15 | step: 269100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.626148337498307e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.31 | consumed tokens: 137779200.0 | grad norm avg: 7.9 | grad norm last: 9.17 | 
2025-12-28T00:36:17 | step: 269200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.62514425534755e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.55 | consumed tokens: 137830400.0 | grad norm avg: 8.18 | grad norm last: 7.05 | 
2025-12-28T00:36:19 | step: 269300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.624140173196793e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.25 | consumed tokens: 137881600.0 | grad norm avg: 8.1 | grad norm last: 8.75 | 
2025-12-28T00:36:21 | step: 269400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.623135363450274e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.64 | consumed tokens: 137932800.0 | grad norm avg: 8.35 | grad norm last: 8.25 | 
2025-12-28T00:36:23 | step: 269500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.622129826107994e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.34 | consumed tokens: 137984000.0 | grad norm avg: 7.94 | grad norm last: 6.47 | 
2025-12-28T00:36:25 | step: 269600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.621125743957236e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.98 | consumed tokens: 138035200.0 | grad norm avg: 8.28 | grad norm last: 7.29 | 
2025-12-28T00:36:27 | step: 269700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.620120206614956e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.0 | consumed tokens: 138086400.0 | grad norm avg: 8.14 | grad norm last: 7.65 | 
2025-12-28T00:36:29 | step: 269800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.619113941676915e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.27 | consumed tokens: 138137600.0 | grad norm avg: 7.95 | grad norm last: 7.12 | 
2025-12-28T00:36:31 | step: 269900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.618107676738873e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.77 | consumed tokens: 138188800.0 | grad norm avg: 8.08 | grad norm last: 6.92 | 
2025-12-28T00:36:33 | step: 270000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.617102139396593e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.67 | consumed tokens: 138240000.0 | grad norm avg: 8.2 | grad norm last: 9.03 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_270000-seen_tokens_138240000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_270000-seen_tokens_138240000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_270000-seen_tokens_138240000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_270000-seen_tokens_138240000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_270000-seen_tokens_138240000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_270000-seen_tokens_138240000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_270000-seen_tokens_138240000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_270000-seen_tokens_138240000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:36:36 | step: 270100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.61609514686279e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.94 | train loss last: 4.0 | consumed tokens: 138291200.0 | grad norm avg: 8.2 | grad norm last: 6.93 | 
2025-12-28T00:36:38 | step: 270200 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 8.615088154328987e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.2 | consumed tokens: 138342400.0 | grad norm avg: 7.8 | grad norm last: 8.06 | 
2025-12-28T00:36:40 | step: 270300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.614081161795184e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.14 | consumed tokens: 138393600.0 | grad norm avg: 8.42 | grad norm last: 6.25 | 
2025-12-28T00:36:42 | step: 270400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.613072714069858e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.34 | consumed tokens: 138444800.0 | grad norm avg: 8.12 | grad norm last: 6.76 | 
2025-12-28T00:36:44 | step: 270500 | train samples/s: 107.7 | train mfu (16-bit): -1.0 | lr mean: 8.612065721536055e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.45 | consumed tokens: 138496000.0 | grad norm avg: 8.33 | grad norm last: 7.5 | 
2025-12-28T00:36:46 | step: 270600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.61105727381073e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.53 | consumed tokens: 138547200.0 | grad norm avg: 8.28 | grad norm last: 7.39 | 
2025-12-28T00:36:48 | step: 270700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.610048826085404e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.48 | consumed tokens: 138598400.0 | grad norm avg: 8.2 | grad norm last: 6.77 | 
2025-12-28T00:36:50 | step: 270800 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.609040378360078e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 3.17 | consumed tokens: 138649600.0 | grad norm avg: 8.39 | grad norm last: 6.57 | 
2025-12-28T00:36:52 | step: 270900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.60803120303899e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.55 | consumed tokens: 138700800.0 | grad norm avg: 8.1 | grad norm last: 7.54 | 
2025-12-28T00:36:54 | step: 271000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.607022027717903e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.17 | consumed tokens: 138752000.0 | grad norm avg: 8.24 | grad norm last: 7.26 | 
2025-12-28T00:36:56 | step: 271100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.606012124801055e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.06 | consumed tokens: 138803200.0 | grad norm avg: 8.17 | grad norm last: 7.56 | 
2025-12-28T00:36:58 | step: 271200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.605002221884206e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.66 | consumed tokens: 138854400.0 | grad norm avg: 8.23 | grad norm last: 7.78 | 
2025-12-28T00:37:00 | step: 271300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.603992318967357e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.41 | consumed tokens: 138905600.0 | grad norm avg: 8.46 | grad norm last: 7.28 | 
2025-12-28T00:37:02 | step: 271400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.602981688454747e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.02 | consumed tokens: 138956800.0 | grad norm avg: 8.28 | grad norm last: 7.59 | 
2025-12-28T00:37:04 | step: 271500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.601971057942137e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.39 | consumed tokens: 139008000.0 | grad norm avg: 8.01 | grad norm last: 7.64 | 
2025-12-28T00:37:06 | step: 271600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.600959699833766e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.91 | consumed tokens: 139059200.0 | grad norm avg: 8.0 | grad norm last: 7.42 | 
2025-12-28T00:37:08 | step: 271700 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.599948341725394e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.0 | consumed tokens: 139110400.0 | grad norm avg: 8.62 | grad norm last: 7.2 | 
2025-12-28T00:37:10 | step: 271800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.598936256021261e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.39 | consumed tokens: 139161600.0 | grad norm avg: 8.61 | grad norm last: 9.05 | 
2025-12-28T00:37:12 | step: 271900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.597924170317128e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.06 | consumed tokens: 139212800.0 | grad norm avg: 8.1 | grad norm last: 9.34 | 
2025-12-28T00:37:14 | step: 272000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.596912812208757e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.42 | consumed tokens: 139264000.0 | grad norm avg: 8.19 | grad norm last: 7.87 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_272000-seen_tokens_139264000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_272000-seen_tokens_139264000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_272000-seen_tokens_139264000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_272000-seen_tokens_139264000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_272000-seen_tokens_139264000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_272000-seen_tokens_139264000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_272000-seen_tokens_139264000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_272000-seen_tokens_139264000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:37:16 | step: 272100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.595899998908862e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.85 | train loss last: 4.25 | consumed tokens: 139315200.0 | grad norm avg: 8.27 | grad norm last: 7.4 | 
2025-12-28T00:37:18 | step: 272200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.594887185608968e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.25 | consumed tokens: 139366400.0 | grad norm avg: 8.66 | grad norm last: 7.25 | 
2025-12-28T00:37:20 | step: 272300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 8.593872917117551e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.84 | consumed tokens: 139417600.0 | grad norm avg: 8.21 | grad norm last: 15.85 | 
2025-12-28T00:37:22 | step: 272400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.592859376221895e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.97 | consumed tokens: 139468800.0 | grad norm avg: 8.68 | grad norm last: 10.56 | 
2025-12-28T00:37:24 | step: 272500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.59184583532624e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.5 | consumed tokens: 139520000.0 | grad norm avg: 8.34 | grad norm last: 8.53 | 
2025-12-28T00:37:26 | step: 272600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.590831566834822e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 2.95 | consumed tokens: 139571200.0 | grad norm avg: 8.53 | grad norm last: 7.98 | 
2025-12-28T00:37:28 | step: 272700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.589817298343405e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.03 | consumed tokens: 139622400.0 | grad norm avg: 8.11 | grad norm last: 8.0 | 
2025-12-28T00:37:30 | step: 272800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.588802302256227e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.5 | consumed tokens: 139673600.0 | grad norm avg: 8.38 | grad norm last: 8.07 | 
2025-12-28T00:37:32 | step: 272900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.587787306169048e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.38 | consumed tokens: 139724800.0 | grad norm avg: 8.74 | grad norm last: 8.04 | 
2025-12-28T00:37:34 | step: 273000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 8.586773037677631e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.97 | consumed tokens: 139776000.0 | grad norm avg: 8.62 | grad norm last: 13.89 | 
2025-12-28T00:37:36 | step: 273100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 8.585755858803168e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.66 | consumed tokens: 139827200.0 | grad norm avg: 8.63 | grad norm last: 10.99 | 
2025-12-28T00:37:38 | step: 273200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.584741590311751e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.67 | consumed tokens: 139878400.0 | grad norm avg: 8.26 | grad norm last: 8.85 | 
2025-12-28T00:37:40 | step: 273300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.583724411437288e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.0 | consumed tokens: 139929600.0 | grad norm avg: 8.45 | grad norm last: 8.48 | 
2025-12-28T00:37:42 | step: 273400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.582707960158587e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.59 | consumed tokens: 139980800.0 | grad norm avg: 8.04 | grad norm last: 11.18 | 
2025-12-28T00:37:44 | step: 273500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.581691508879885e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.03 | consumed tokens: 140032000.0 | grad norm avg: 8.27 | grad norm last: 15.53 | 
2025-12-28T00:37:46 | step: 273600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.580674330005422e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.78 | consumed tokens: 140083200.0 | grad norm avg: 8.24 | grad norm last: 7.7 | 
2025-12-28T00:37:49 | step: 273700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.57965715113096e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.67 | consumed tokens: 140134400.0 | grad norm avg: 8.2 | grad norm last: 8.37 | 
2025-12-28T00:37:51 | step: 273800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.578639244660735e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.28 | consumed tokens: 140185600.0 | grad norm avg: 8.39 | grad norm last: 7.05 | 
2025-12-28T00:37:53 | step: 273900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.577621338190511e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.42 | consumed tokens: 140236800.0 | grad norm avg: 8.65 | grad norm last: 6.66 | 
2025-12-28T00:37:55 | step: 274000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.576602704124525e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.28 | consumed tokens: 140288000.0 | grad norm avg: 8.3 | grad norm last: 7.55 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_274000-seen_tokens_140288000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_274000-seen_tokens_140288000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_274000-seen_tokens_140288000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_274000-seen_tokens_140288000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_274000-seen_tokens_140288000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_274000-seen_tokens_140288000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_274000-seen_tokens_140288000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_274000-seen_tokens_140288000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:37:57 | step: 274100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.57558407005854e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.82 | train loss last: 3.64 | consumed tokens: 140339200.0 | grad norm avg: 8.29 | grad norm last: 7.46 | 
2025-12-28T00:37:59 | step: 274200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.574565435992554e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.92 | consumed tokens: 140390400.0 | grad norm avg: 8.6 | grad norm last: 10.38 | 
2025-12-28T00:38:01 | step: 274300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.573546074330807e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.55 | consumed tokens: 140441600.0 | grad norm avg: 8.12 | grad norm last: 6.82 | 
2025-12-28T00:38:03 | step: 274400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.57252671266906e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.88 | consumed tokens: 140492800.0 | grad norm avg: 8.3 | grad norm last: 7.12 | 
2025-12-28T00:38:05 | step: 274500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.571506623411551e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.7 | consumed tokens: 140544000.0 | grad norm avg: 8.33 | grad norm last: 8.31 | 
2025-12-28T00:38:07 | step: 274600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.570487261749804e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.86 | consumed tokens: 140595200.0 | grad norm avg: 8.1 | grad norm last: 7.2 | 
2025-12-28T00:38:09 | step: 274700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.569466444896534e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.0 | consumed tokens: 140646400.0 | grad norm avg: 8.49 | grad norm last: 8.17 | 
2025-12-28T00:38:11 | step: 274800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.568446355639026e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.39 | consumed tokens: 140697600.0 | grad norm avg: 8.28 | grad norm last: 6.79 | 
2025-12-28T00:38:13 | step: 274900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.567425538785756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.39 | consumed tokens: 140748800.0 | grad norm avg: 8.34 | grad norm last: 9.95 | 
2025-12-28T00:38:15 | step: 275000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.566403994336724e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.12 | consumed tokens: 140800000.0 | grad norm avg: 8.43 | grad norm last: 12.21 | 
2025-12-28T00:38:17 | step: 275100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.565382449887693e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.12 | consumed tokens: 140851200.0 | grad norm avg: 7.91 | grad norm last: 7.38 | 
2025-12-28T00:38:19 | step: 275200 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 8.564360905438662e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.25 | consumed tokens: 140902400.0 | grad norm avg: 8.23 | grad norm last: 8.96 | 
2025-12-28T00:38:21 | step: 275300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.563338633393869e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.99 | train loss last: 3.52 | consumed tokens: 140953600.0 | grad norm avg: 8.67 | grad norm last: 8.33 | 
2025-12-28T00:38:23 | step: 275400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.562315633753315e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.53 | consumed tokens: 141004800.0 | grad norm avg: 8.51 | grad norm last: 9.44 | 
2025-12-28T00:38:25 | step: 275500 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.561293361708522e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.69 | consumed tokens: 141056000.0 | grad norm avg: 8.42 | grad norm last: 6.9 | 
2025-12-28T00:38:27 | step: 275600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.560271089663729e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.25 | consumed tokens: 141107200.0 | grad norm avg: 8.47 | grad norm last: 10.95 | 
2025-12-28T00:38:29 | step: 275700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.559247362427413e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.77 | consumed tokens: 141158400.0 | grad norm avg: 8.2 | grad norm last: 6.8 | 
2025-12-28T00:38:31 | step: 275800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.558223635191098e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.88 | consumed tokens: 141209600.0 | grad norm avg: 8.38 | grad norm last: 7.73 | 
2025-12-28T00:38:33 | step: 275900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.557199180359021e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.06 | consumed tokens: 141260800.0 | grad norm avg: 8.23 | grad norm last: 6.18 | 
2025-12-28T00:38:35 | step: 276000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.556174725526944e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.03 | consumed tokens: 141312000.0 | grad norm avg: 8.45 | grad norm last: 7.37 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_276000-seen_tokens_141312000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_276000-seen_tokens_141312000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_276000-seen_tokens_141312000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_276000-seen_tokens_141312000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_276000-seen_tokens_141312000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_276000-seen_tokens_141312000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_276000-seen_tokens_141312000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_276000-seen_tokens_141312000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:38:38 | step: 276100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.555150270694867e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.77 | train loss last: 4.0 | consumed tokens: 141363200.0 | grad norm avg: 8.37 | grad norm last: 8.04 | 
2025-12-28T00:38:40 | step: 276200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.55412581586279e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.27 | consumed tokens: 141414400.0 | grad norm avg: 8.18 | grad norm last: 7.16 | 
2025-12-28T00:38:42 | step: 276300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.553101361030713e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.14 | consumed tokens: 141465600.0 | grad norm avg: 7.99 | grad norm last: 7.51 | 
2025-12-28T00:38:44 | step: 276400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.552076178602874e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.64 | consumed tokens: 141516800.0 | grad norm avg: 8.09 | grad norm last: 7.05 | 
2025-12-28T00:38:46 | step: 276500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.551050996175036e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.88 | consumed tokens: 141568000.0 | grad norm avg: 8.48 | grad norm last: 9.86 | 
2025-12-28T00:38:48 | step: 276600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.550024358555675e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.58 | consumed tokens: 141619200.0 | grad norm avg: 8.33 | grad norm last: 8.05 | 
2025-12-28T00:38:50 | step: 276700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.548997720936313e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.22 | consumed tokens: 141670400.0 | grad norm avg: 8.82 | grad norm last: 8.28 | 
2025-12-28T00:38:52 | step: 276800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.547971810912713e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.22 | consumed tokens: 141721600.0 | grad norm avg: 8.71 | grad norm last: 7.88 | 
2025-12-28T00:38:54 | step: 276900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.546944445697591e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.8 | consumed tokens: 141772800.0 | grad norm avg: 8.87 | grad norm last: 8.21 | 
2025-12-28T00:38:56 | step: 277000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 8.54591780807823e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.94 | consumed tokens: 141824000.0 | grad norm avg: 8.84 | grad norm last: 11.34 | 
2025-12-28T00:38:58 | step: 277100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 8.544890442863107e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.03 | consumed tokens: 141875200.0 | grad norm avg: 8.29 | grad norm last: 8.13 | 
2025-12-28T00:39:00 | step: 277200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.543862350052223e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 2.98 | consumed tokens: 141926400.0 | grad norm avg: 8.14 | grad norm last: 6.3 | 
2025-12-28T00:39:02 | step: 277300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.5428349848371e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.69 | consumed tokens: 141977600.0 | grad norm avg: 8.59 | grad norm last: 11.82 | 
2025-12-28T00:39:04 | step: 277400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.541806164430454e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.47 | consumed tokens: 142028800.0 | grad norm avg: 7.98 | grad norm last: 7.0 | 
2025-12-28T00:39:06 | step: 277500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.54077807161957e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.75 | consumed tokens: 142080000.0 | grad norm avg: 8.22 | grad norm last: 6.88 | 
2025-12-28T00:39:08 | step: 277600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.539748523617163e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.41 | consumed tokens: 142131200.0 | grad norm avg: 8.51 | grad norm last: 6.81 | 
2025-12-28T00:39:10 | step: 277700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.538719703210518e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.25 | consumed tokens: 142182400.0 | grad norm avg: 8.36 | grad norm last: 8.09 | 
2025-12-28T00:39:12 | step: 277800 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 8.537690155208111e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.56 | consumed tokens: 142233600.0 | grad norm avg: 8.65 | grad norm last: 9.53 | 
2025-12-28T00:39:14 | step: 277900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 8.536660607205704e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 2.83 | consumed tokens: 142284800.0 | grad norm avg: 8.49 | grad norm last: 7.99 | 
2025-12-28T00:39:16 | step: 278000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.535630331607535e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.53 | consumed tokens: 142336000.0 | grad norm avg: 8.35 | grad norm last: 8.01 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_278000-seen_tokens_142336000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_278000-seen_tokens_142336000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_278000-seen_tokens_142336000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_278000-seen_tokens_142336000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_278000-seen_tokens_142336000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_278000-seen_tokens_142336000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_278000-seen_tokens_142336000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_278000-seen_tokens_142336000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:39:18 | step: 278100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.534600056009367e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.81 | train loss last: 3.45 | consumed tokens: 142387200.0 | grad norm avg: 8.59 | grad norm last: 7.97 | 
2025-12-28T00:39:20 | step: 278200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.533569780411199e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.2 | consumed tokens: 142438400.0 | grad norm avg: 8.37 | grad norm last: 7.45 | 
2025-12-28T00:39:22 | step: 278300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.532538777217269e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.53 | consumed tokens: 142489600.0 | grad norm avg: 8.19 | grad norm last: 8.61 | 
2025-12-28T00:39:24 | step: 278400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.531507774023339e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.31 | consumed tokens: 142540800.0 | grad norm avg: 8.57 | grad norm last: 7.82 | 
2025-12-28T00:39:26 | step: 278500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.530476043233648e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.78 | consumed tokens: 142592000.0 | grad norm avg: 8.26 | grad norm last: 8.62 | 
2025-12-28T00:39:29 | step: 278600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.529444312443957e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.42 | consumed tokens: 142643200.0 | grad norm avg: 8.54 | grad norm last: 7.72 | 
2025-12-28T00:39:31 | step: 278700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.528411854058504e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.88 | consumed tokens: 142694400.0 | grad norm avg: 8.29 | grad norm last: 9.91 | 
2025-12-28T00:39:33 | step: 278800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.527379395673051e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.73 | consumed tokens: 142745600.0 | grad norm avg: 8.58 | grad norm last: 9.48 | 
2025-12-28T00:39:35 | step: 278900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.52634766488336e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.83 | consumed tokens: 142796800.0 | grad norm avg: 8.32 | grad norm last: 9.88 | 
2025-12-28T00:39:37 | step: 279000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.525314478902146e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.69 | consumed tokens: 142848000.0 | grad norm avg: 8.07 | grad norm last: 8.7 | 
2025-12-28T00:39:39 | step: 279100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.524281292920932e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.44 | consumed tokens: 142899200.0 | grad norm avg: 8.39 | grad norm last: 8.26 | 
2025-12-28T00:39:41 | step: 279200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.523246651748195e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.14 | consumed tokens: 142950400.0 | grad norm avg: 8.39 | grad norm last: 6.7 | 
2025-12-28T00:39:43 | step: 279300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.522213465766981e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.5 | consumed tokens: 143001600.0 | grad norm avg: 8.66 | grad norm last: 9.76 | 
2025-12-28T00:39:45 | step: 279400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.521179552190006e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 2.88 | consumed tokens: 143052800.0 | grad norm avg: 8.61 | grad norm last: 6.94 | 
2025-12-28T00:39:47 | step: 279500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.520144183421507e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.03 | consumed tokens: 143104000.0 | grad norm avg: 8.26 | grad norm last: 9.35 | 
2025-12-28T00:39:49 | step: 279600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.519110269844532e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.09 | consumed tokens: 143155200.0 | grad norm avg: 8.46 | grad norm last: 8.98 | 
2025-12-28T00:39:51 | step: 279700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.518076356267557e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.03 | consumed tokens: 143206400.0 | grad norm avg: 7.99 | grad norm last: 9.51 | 
2025-12-28T00:39:53 | step: 279800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.517040259903297e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.92 | consumed tokens: 143257600.0 | grad norm avg: 8.68 | grad norm last: 8.6 | 
2025-12-28T00:39:55 | step: 279900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.516004891134799e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.75 | consumed tokens: 143308800.0 | grad norm avg: 8.33 | grad norm last: 7.1 | 
2025-12-28T00:39:57 | step: 280000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.514968794770539e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.0 | consumed tokens: 143360000.0 | grad norm avg: 8.43 | grad norm last: 9.79 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_280000-seen_tokens_143360000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_280000-seen_tokens_143360000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_280000-seen_tokens_143360000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_280000-seen_tokens_143360000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_280000-seen_tokens_143360000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_280000-seen_tokens_143360000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_280000-seen_tokens_143360000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_280000-seen_tokens_143360000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:39:59 | step: 280100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.513932698406279e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.8 | train loss last: 3.62 | consumed tokens: 143411200.0 | grad norm avg: 8.37 | grad norm last: 7.25 | 
2025-12-28T00:40:01 | step: 280200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.51289660204202e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.38 | consumed tokens: 143462400.0 | grad norm avg: 8.4 | grad norm last: 6.9 | 
2025-12-28T00:40:03 | step: 280300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.511859778081998e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.12 | consumed tokens: 143513600.0 | grad norm avg: 8.21 | grad norm last: 8.73 | 
2025-12-28T00:40:05 | step: 280400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.510822226526216e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.89 | consumed tokens: 143564800.0 | grad norm avg: 8.51 | grad norm last: 6.83 | 
2025-12-28T00:40:07 | step: 280500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.509785402566195e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.22 | consumed tokens: 143616000.0 | grad norm avg: 8.5 | grad norm last: 12.82 | 
2025-12-28T00:40:09 | step: 280600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 8.50874712341465e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.94 | consumed tokens: 143667200.0 | grad norm avg: 8.69 | grad norm last: 8.28 | 
2025-12-28T00:40:11 | step: 280700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.507709571858868e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.38 | consumed tokens: 143718400.0 | grad norm avg: 8.81 | grad norm last: 9.29 | 
2025-12-28T00:40:13 | step: 280800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.506671292707324e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.11 | consumed tokens: 143769600.0 | grad norm avg: 8.41 | grad norm last: 6.58 | 
2025-12-28T00:40:15 | step: 280900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.50563301355578e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 2.95 | consumed tokens: 143820800.0 | grad norm avg: 8.48 | grad norm last: 7.24 | 
2025-12-28T00:40:17 | step: 281000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.504595461999997e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.67 | consumed tokens: 143872000.0 | grad norm avg: 8.47 | grad norm last: 8.17 | 
2025-12-28T00:40:19 | step: 281100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.503555000061169e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.36 | consumed tokens: 143923200.0 | grad norm avg: 8.25 | grad norm last: 6.94 | 
2025-12-28T00:40:21 | step: 281200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.502515993313864e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.48 | consumed tokens: 143974400.0 | grad norm avg: 8.86 | grad norm last: 8.43 | 
2025-12-28T00:40:23 | step: 281300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.501476258970797e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.88 | consumed tokens: 144025600.0 | grad norm avg: 9.44 | grad norm last: 9.72 | 
2025-12-28T00:40:25 | step: 281400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.50043652462773e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.53 | consumed tokens: 144076800.0 | grad norm avg: 8.17 | grad norm last: 9.26 | 
2025-12-28T00:40:27 | step: 281500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.499396062688902e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 5.16 | consumed tokens: 144128000.0 | grad norm avg: 8.69 | grad norm last: 14.57 | 
2025-12-28T00:40:29 | step: 281600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.498355600750074e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 5.12 | consumed tokens: 144179200.0 | grad norm avg: 8.44 | grad norm last: 10.75 | 
2025-12-28T00:40:31 | step: 281700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.497315138811246e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.59 | consumed tokens: 144230400.0 | grad norm avg: 8.43 | grad norm last: 11.12 | 
2025-12-28T00:40:33 | step: 281800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.496273221680894e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.92 | consumed tokens: 144281600.0 | grad norm avg: 8.89 | grad norm last: 8.45 | 
2025-12-28T00:40:35 | step: 281900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.495232759742066e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.94 | consumed tokens: 144332800.0 | grad norm avg: 8.64 | grad norm last: 8.72 | 
2025-12-28T00:40:37 | step: 282000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.494190842611715e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 2.52 | consumed tokens: 144384000.0 | grad norm avg: 8.57 | grad norm last: 7.71 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_282000-seen_tokens_144384000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_282000-seen_tokens_144384000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_282000-seen_tokens_144384000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_282000-seen_tokens_144384000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_282000-seen_tokens_144384000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_282000-seen_tokens_144384000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_282000-seen_tokens_144384000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_282000-seen_tokens_144384000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:40:40 | step: 282100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.493148925481364e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.88 | train loss last: 3.91 | consumed tokens: 144435200.0 | grad norm avg: 9.0 | grad norm last: 9.93 | 
2025-12-28T00:40:42 | step: 282200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.492107008351013e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.47 | consumed tokens: 144486400.0 | grad norm avg: 8.15 | grad norm last: 8.32 | 
2025-12-28T00:40:44 | step: 282300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.491063636029139e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.03 | consumed tokens: 144537600.0 | grad norm avg: 8.74 | grad norm last: 9.92 | 
2025-12-28T00:40:46 | step: 282400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.490021718898788e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.53 | consumed tokens: 144588800.0 | grad norm avg: 8.63 | grad norm last: 7.32 | 
2025-12-28T00:40:48 | step: 282500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.488978346576914e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.3 | consumed tokens: 144640000.0 | grad norm avg: 8.62 | grad norm last: 7.3 | 
2025-12-28T00:40:50 | step: 282600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.48793497425504e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.67 | consumed tokens: 144691200.0 | grad norm avg: 8.87 | grad norm last: 7.37 | 
2025-12-28T00:40:52 | step: 282700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.486891601933166e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.94 | consumed tokens: 144742400.0 | grad norm avg: 8.73 | grad norm last: 6.71 | 
2025-12-28T00:40:54 | step: 282800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.485847502015531e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.55 | consumed tokens: 144793600.0 | grad norm avg: 8.32 | grad norm last: 8.04 | 
2025-12-28T00:40:56 | step: 282900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 8.484803402097896e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.98 | consumed tokens: 144844800.0 | grad norm avg: 8.65 | grad norm last: 8.74 | 
2025-12-28T00:40:58 | step: 283000 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 8.483758574584499e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.45 | consumed tokens: 144896000.0 | grad norm avg: 8.84 | grad norm last: 7.43 | 
2025-12-28T00:41:00 | step: 283100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 8.482715202262625e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.31 | consumed tokens: 144947200.0 | grad norm avg: 8.78 | grad norm last: 6.61 | 
2025-12-28T00:41:02 | step: 283200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 8.481668919557706e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.16 | consumed tokens: 144998400.0 | grad norm avg: 8.29 | grad norm last: 6.81 | 
2025-12-28T00:41:04 | step: 283300 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 8.480624092044309e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.62 | consumed tokens: 145049600.0 | grad norm avg: 8.87 | grad norm last: 7.45 | 
2025-12-28T00:41:06 | step: 283400 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 8.479577809339389e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.16 | consumed tokens: 145100800.0 | grad norm avg: 8.36 | grad norm last: 7.59 | 
2025-12-28T00:41:08 | step: 283500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 8.47853152663447e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.58 | consumed tokens: 145152000.0 | grad norm avg: 8.64 | grad norm last: 7.41 | 
2025-12-28T00:41:10 | step: 283600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 8.477485971525311e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.06 | consumed tokens: 145203200.0 | grad norm avg: 8.57 | grad norm last: 9.95 | 
2025-12-28T00:41:12 | step: 283700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.476440416416153e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.59 | consumed tokens: 145254400.0 | grad norm avg: 8.33 | grad norm last: 7.58 | 
2025-12-28T00:41:14 | step: 283800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.475392678519711e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.16 | consumed tokens: 145305600.0 | grad norm avg: 8.72 | grad norm last: 6.93 | 
2025-12-28T00:41:16 | step: 283900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.47434566821903e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.44 | consumed tokens: 145356800.0 | grad norm avg: 8.64 | grad norm last: 6.88 | 
2025-12-28T00:41:18 | step: 284000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.473297930322587e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.22 | consumed tokens: 145408000.0 | grad norm avg: 8.67 | grad norm last: 7.54 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_284000-seen_tokens_145408000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_284000-seen_tokens_145408000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_284000-seen_tokens_145408000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_284000-seen_tokens_145408000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_284000-seen_tokens_145408000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_284000-seen_tokens_145408000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_284000-seen_tokens_145408000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_284000-seen_tokens_145408000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:41:21 | step: 284100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.472250920021906e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.81 | train loss last: 4.53 | consumed tokens: 145459200.0 | grad norm avg: 8.5 | grad norm last: 8.76 | 
2025-12-28T00:41:23 | step: 284200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.471202454529703e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.38 | consumed tokens: 145510400.0 | grad norm avg: 8.56 | grad norm last: 8.62 | 
2025-12-28T00:41:25 | step: 284300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.47015471663326e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.89 | consumed tokens: 145561600.0 | grad norm avg: 8.56 | grad norm last: 8.11 | 
2025-12-28T00:41:27 | step: 284400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.469106251141056e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.92 | consumed tokens: 145612800.0 | grad norm avg: 8.6 | grad norm last: 7.42 | 
2025-12-28T00:41:29 | step: 284500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.468057058053091e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.56 | consumed tokens: 145664000.0 | grad norm avg: 8.08 | grad norm last: 7.42 | 
2025-12-28T00:41:31 | step: 284600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.467007864965126e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.67 | consumed tokens: 145715200.0 | grad norm avg: 8.66 | grad norm last: 8.1 | 
2025-12-28T00:41:33 | step: 284700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.46595867187716e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.25 | consumed tokens: 145766400.0 | grad norm avg: 8.28 | grad norm last: 8.24 | 
2025-12-28T00:41:35 | step: 284800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.464909478789195e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.5 | consumed tokens: 145817600.0 | grad norm avg: 8.23 | grad norm last: 7.47 | 
2025-12-28T00:41:37 | step: 284900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.463858830509707e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.22 | consumed tokens: 145868800.0 | grad norm avg: 8.42 | grad norm last: 8.54 | 
2025-12-28T00:41:39 | step: 285000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.46280890982598e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.44 | consumed tokens: 145920000.0 | grad norm avg: 8.35 | grad norm last: 8.14 | 
2025-12-28T00:41:41 | step: 285100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.461758261546493e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.25 | consumed tokens: 145971200.0 | grad norm avg: 8.76 | grad norm last: 8.4 | 
2025-12-28T00:41:43 | step: 285200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.460707613267004e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.86 | consumed tokens: 146022400.0 | grad norm avg: 8.78 | grad norm last: 8.19 | 
2025-12-28T00:41:45 | step: 285300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.459656237391755e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.69 | consumed tokens: 146073600.0 | grad norm avg: 8.75 | grad norm last: 7.93 | 
2025-12-28T00:41:47 | step: 285400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.458605589112267e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.28 | consumed tokens: 146124800.0 | grad norm avg: 8.3 | grad norm last: 7.53 | 
2025-12-28T00:41:49 | step: 285500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.457553485641256e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.5 | consumed tokens: 146176000.0 | grad norm avg: 8.86 | grad norm last: 8.77 | 
2025-12-28T00:41:51 | step: 285600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.456501382170245e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.06 | consumed tokens: 146227200.0 | grad norm avg: 8.67 | grad norm last: 7.92 | 
2025-12-28T00:41:53 | step: 285700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 8.455449278699234e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.19 | consumed tokens: 146278400.0 | grad norm avg: 8.96 | grad norm last: 9.85 | 
2025-12-28T00:41:55 | step: 285800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.454397175228223e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.95 | consumed tokens: 146329600.0 | grad norm avg: 8.59 | grad norm last: 8.56 | 
2025-12-28T00:41:57 | step: 285900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.453344344161451e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 5.31 | consumed tokens: 146380800.0 | grad norm avg: 8.78 | grad norm last: 7.95 | 
2025-12-28T00:41:59 | step: 286000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.452290785498917e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.53 | consumed tokens: 146432000.0 | grad norm avg: 8.29 | grad norm last: 7.23 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_286000-seen_tokens_146432000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_286000-seen_tokens_146432000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_286000-seen_tokens_146432000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_286000-seen_tokens_146432000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_286000-seen_tokens_146432000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_286000-seen_tokens_146432000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_286000-seen_tokens_146432000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_286000-seen_tokens_146432000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:42:01 | step: 286100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.451237954432145e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 2.89 | consumed tokens: 146483200.0 | grad norm avg: 8.66 | grad norm last: 7.55 | 
2025-12-28T00:42:04 | step: 286200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.45018366817385e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.52 | consumed tokens: 146534400.0 | grad norm avg: 9.14 | grad norm last: 8.67 | 
2025-12-28T00:42:06 | step: 286300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.449130109511316e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.12 | consumed tokens: 146585600.0 | grad norm avg: 8.56 | grad norm last: 7.26 | 
2025-12-28T00:42:08 | step: 286400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.44807582325302e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.19 | consumed tokens: 146636800.0 | grad norm avg: 8.56 | grad norm last: 8.53 | 
2025-12-28T00:42:10 | step: 286500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.447022264590487e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.25 | consumed tokens: 146688000.0 | grad norm avg: 8.68 | grad norm last: 7.45 | 
2025-12-28T00:42:12 | step: 286600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.445966523140669e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.91 | consumed tokens: 146739200.0 | grad norm avg: 8.46 | grad norm last: 9.7 | 
2025-12-28T00:42:14 | step: 286700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.444910781690851e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 2.73 | consumed tokens: 146790400.0 | grad norm avg: 8.73 | grad norm last: 6.31 | 
2025-12-28T00:42:16 | step: 286800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.443856495432556e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.5 | consumed tokens: 146841600.0 | grad norm avg: 8.78 | grad norm last: 8.66 | 
2025-12-28T00:42:18 | step: 286900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.442800753982738e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.0 | consumed tokens: 146892800.0 | grad norm avg: 9.13 | grad norm last: 7.37 | 
2025-12-28T00:42:20 | step: 287000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.441744284937158e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.95 | train loss last: 4.19 | consumed tokens: 146944000.0 | grad norm avg: 8.49 | grad norm last: 10.02 | 
2025-12-28T00:42:22 | step: 287100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.440689271083102e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.56 | consumed tokens: 146995200.0 | grad norm avg: 8.77 | grad norm last: 7.97 | 
2025-12-28T00:42:24 | step: 287200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.439631346846e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.36 | consumed tokens: 147046400.0 | grad norm avg: 8.52 | grad norm last: 7.02 | 
2025-12-28T00:42:26 | step: 287300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.438576332991943e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.17 | consumed tokens: 147097600.0 | grad norm avg: 8.77 | grad norm last: 9.15 | 
2025-12-28T00:42:28 | step: 287400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.43751840875484e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.83 | consumed tokens: 147148800.0 | grad norm avg: 8.84 | grad norm last: 10.09 | 
2025-12-28T00:42:30 | step: 287500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 8.4364612121135e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.44 | consumed tokens: 147200000.0 | grad norm avg: 8.72 | grad norm last: 7.17 | 
2025-12-28T00:42:32 | step: 287600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 8.435404015472159e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.95 | consumed tokens: 147251200.0 | grad norm avg: 8.78 | grad norm last: 8.84 | 
2025-12-28T00:42:34 | step: 287700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 8.434345363639295e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.81 | consumed tokens: 147302400.0 | grad norm avg: 9.18 | grad norm last: 8.34 | 
2025-12-28T00:42:36 | step: 287800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.433286711806431e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.19 | consumed tokens: 147353600.0 | grad norm avg: 8.67 | grad norm last: 9.08 | 
2025-12-28T00:42:38 | step: 287900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 8.432228787569329e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.75 | consumed tokens: 147404800.0 | grad norm avg: 8.65 | grad norm last: 8.14 | 
2025-12-28T00:42:40 | step: 288000 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 8.431170135736465e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.45 | consumed tokens: 147456000.0 | grad norm avg: 8.78 | grad norm last: 8.18 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_288000-seen_tokens_147456000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_288000-seen_tokens_147456000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_288000-seen_tokens_147456000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_288000-seen_tokens_147456000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_288000-seen_tokens_147456000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_288000-seen_tokens_147456000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_288000-seen_tokens_147456000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_288000-seen_tokens_147456000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:42:42 | step: 288100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 8.43011075630784e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.87 | train loss last: 4.72 | consumed tokens: 147507200.0 | grad norm avg: 8.74 | grad norm last: 10.18 | 
2025-12-28T00:42:44 | step: 288200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.429052104474977e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.52 | consumed tokens: 147558400.0 | grad norm avg: 8.81 | grad norm last: 9.32 | 
2025-12-28T00:42:46 | step: 288300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.42799199745059e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.06 | consumed tokens: 147609600.0 | grad norm avg: 8.99 | grad norm last: 7.63 | 
2025-12-28T00:42:48 | step: 288400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.426932618021965e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.69 | consumed tokens: 147660800.0 | grad norm avg: 8.88 | grad norm last: 9.27 | 
2025-12-28T00:42:51 | step: 288500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.425872510997579e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.44 | consumed tokens: 147712000.0 | grad norm avg: 8.87 | grad norm last: 9.7 | 
2025-12-28T00:42:53 | step: 288600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 8.42481167637743e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.88 | consumed tokens: 147763200.0 | grad norm avg: 8.67 | grad norm last: 9.06 | 
2025-12-28T00:42:55 | step: 288700 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 8.423750841757283e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.7 | consumed tokens: 147814400.0 | grad norm avg: 8.82 | grad norm last: 8.62 | 
2025-12-28T00:42:57 | step: 288800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 8.422690007137135e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 5.62 | consumed tokens: 147865600.0 | grad norm avg: 8.76 | grad norm last: 11.78 | 
2025-12-28T00:42:59 | step: 288900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 8.421629172516987e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.75 | consumed tokens: 147916800.0 | grad norm avg: 8.87 | grad norm last: 7.57 | 
2025-12-28T00:43:01 | step: 289000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 8.420567610301077e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.53 | consumed tokens: 147968000.0 | grad norm avg: 8.86 | grad norm last: 7.76 | 
2025-12-28T00:43:03 | step: 289100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 8.419505320489407e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.16 | consumed tokens: 148019200.0 | grad norm avg: 8.42 | grad norm last: 12.88 | 
2025-12-28T00:43:05 | step: 289200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.418443758273497e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.56 | consumed tokens: 148070400.0 | grad norm avg: 8.87 | grad norm last: 7.58 | 
2025-12-28T00:43:07 | step: 289300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.417380740866065e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.3 | consumed tokens: 148121600.0 | grad norm avg: 8.78 | grad norm last: 7.43 | 
2025-12-28T00:43:09 | step: 289400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 8.416318451054394e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.25 | consumed tokens: 148172800.0 | grad norm avg: 8.45 | grad norm last: 7.11 | 
2025-12-28T00:43:11 | step: 289500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.415255433646962e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.77 | consumed tokens: 148224000.0 | grad norm avg: 8.55 | grad norm last: 7.92 | 
2025-12-28T00:43:13 | step: 289600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.414193143835291e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.48 | consumed tokens: 148275200.0 | grad norm avg: 9.26 | grad norm last: 7.64 | 
2025-12-28T00:43:15 | step: 289700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.413128671236336e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.59 | consumed tokens: 148326400.0 | grad norm avg: 9.48 | grad norm last: 7.96 | 
2025-12-28T00:43:17 | step: 289800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.412064198637381e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.06 | consumed tokens: 148377600.0 | grad norm avg: 8.71 | grad norm last: 10.04 | 
2025-12-28T00:43:19 | step: 289900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.411001181229949e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 2.94 | consumed tokens: 148428800.0 | grad norm avg: 9.08 | grad norm last: 9.29 | 
2025-12-28T00:43:21 | step: 290000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.409936708630994e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.12 | consumed tokens: 148480000.0 | grad norm avg: 9.2 | grad norm last: 7.1 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_290000-seen_tokens_148480000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_290000-seen_tokens_148480000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_290000-seen_tokens_148480000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_290000-seen_tokens_148480000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_290000-seen_tokens_148480000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_290000-seen_tokens_148480000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_290000-seen_tokens_148480000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_290000-seen_tokens_148480000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:43:23 | step: 290100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.4088729636278e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.81 | consumed tokens: 148531200.0 | grad norm avg: 8.88 | grad norm last: 8.48 | 
2025-12-28T00:43:25 | step: 290200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.407807763433084e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.25 | consumed tokens: 148582400.0 | grad norm avg: 8.9 | grad norm last: 8.02 | 
2025-12-28T00:43:27 | step: 290300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.406742563238367e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.38 | consumed tokens: 148633600.0 | grad norm avg: 8.67 | grad norm last: 8.21 | 
2025-12-28T00:43:29 | step: 290400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.405677363043651e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.38 | consumed tokens: 148684800.0 | grad norm avg: 8.3 | grad norm last: 7.29 | 
2025-12-28T00:43:31 | step: 290500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.404610707657412e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.69 | consumed tokens: 148736000.0 | grad norm avg: 8.91 | grad norm last: 9.8 | 
2025-12-28T00:43:33 | step: 290600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.403544779866934e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.98 | consumed tokens: 148787200.0 | grad norm avg: 8.92 | grad norm last: 8.1 | 
2025-12-28T00:43:35 | step: 290700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.402477396884933e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.5 | consumed tokens: 148838400.0 | grad norm avg: 8.98 | grad norm last: 7.21 | 
2025-12-28T00:43:38 | step: 290800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 8.401411469094455e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.53 | consumed tokens: 148889600.0 | grad norm avg: 8.62 | grad norm last: 8.1 | 
2025-12-28T00:43:40 | step: 290900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.400345541303977e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.53 | consumed tokens: 148940800.0 | grad norm avg: 8.51 | grad norm last: 8.15 | 
2025-12-28T00:43:42 | step: 291000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.399277430726215e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.47 | consumed tokens: 148992000.0 | grad norm avg: 8.73 | grad norm last: 10.58 | 
2025-12-28T00:43:44 | step: 291100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.398210047744215e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.56 | consumed tokens: 149043200.0 | grad norm avg: 8.58 | grad norm last: 8.01 | 
2025-12-28T00:43:46 | step: 291200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.397142664762214e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.97 | consumed tokens: 149094400.0 | grad norm avg: 8.84 | grad norm last: 8.47 | 
2025-12-28T00:43:48 | step: 291300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.396074554184452e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.2 | consumed tokens: 149145600.0 | grad norm avg: 8.66 | grad norm last: 7.62 | 
2025-12-28T00:43:50 | step: 291400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.39500644360669e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.42 | consumed tokens: 149196800.0 | grad norm avg: 8.39 | grad norm last: 7.13 | 
2025-12-28T00:43:52 | step: 291500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.393937605433166e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.09 | consumed tokens: 149248000.0 | grad norm avg: 8.96 | grad norm last: 7.42 | 
2025-12-28T00:43:54 | step: 291600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.392868767259642e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.0 | consumed tokens: 149299200.0 | grad norm avg: 8.4 | grad norm last: 7.43 | 
2025-12-28T00:43:56 | step: 291700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.39180065668188e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.33 | consumed tokens: 149350400.0 | grad norm avg: 8.88 | grad norm last: 8.39 | 
2025-12-28T00:43:58 | step: 291800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.390730363316834e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.56 | consumed tokens: 149401600.0 | grad norm avg: 9.34 | grad norm last: 6.94 | 
2025-12-28T00:44:00 | step: 291900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.389660069951788e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 2.72 | consumed tokens: 149452800.0 | grad norm avg: 8.94 | grad norm last: 7.44 | 
2025-12-28T00:44:02 | step: 292000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.388591231778264e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.12 | consumed tokens: 149504000.0 | grad norm avg: 8.65 | grad norm last: 7.32 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_292000-seen_tokens_149504000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_292000-seen_tokens_149504000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_292000-seen_tokens_149504000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_292000-seen_tokens_149504000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_292000-seen_tokens_149504000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_292000-seen_tokens_149504000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_292000-seen_tokens_149504000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_292000-seen_tokens_149504000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:44:04 | step: 292100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.387520938413218e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.89 | train loss last: 3.55 | consumed tokens: 149555200.0 | grad norm avg: 8.72 | grad norm last: 8.28 | 
2025-12-28T00:44:06 | step: 292200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.386451372643933e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.09 | consumed tokens: 149606400.0 | grad norm avg: 8.48 | grad norm last: 7.44 | 
2025-12-28T00:44:08 | step: 292300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.385380351683125e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.94 | consumed tokens: 149657600.0 | grad norm avg: 8.78 | grad norm last: 7.91 | 
2025-12-28T00:44:10 | step: 292400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.384309330722317e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.75 | consumed tokens: 149708800.0 | grad norm avg: 8.61 | grad norm last: 7.43 | 
2025-12-28T00:44:12 | step: 292500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.383236854569986e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.42 | consumed tokens: 149760000.0 | grad norm avg: 8.68 | grad norm last: 7.27 | 
2025-12-28T00:44:14 | step: 292600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.382165833609179e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.27 | consumed tokens: 149811200.0 | grad norm avg: 8.63 | grad norm last: 6.73 | 
2025-12-28T00:44:16 | step: 292700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.38109408505261e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.86 | consumed tokens: 149862400.0 | grad norm avg: 8.66 | grad norm last: 7.35 | 
2025-12-28T00:44:18 | step: 292800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 8.380020881304517e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.66 | consumed tokens: 149913600.0 | grad norm avg: 8.69 | grad norm last: 7.58 | 
2025-12-28T00:44:20 | step: 292900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 8.378949132747948e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.75 | consumed tokens: 149964800.0 | grad norm avg: 8.4 | grad norm last: 10.7 | 
2025-12-28T00:44:22 | step: 293000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 8.377877384191379e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.22 | consumed tokens: 150016000.0 | grad norm avg: 8.93 | grad norm last: 10.71 | 
2025-12-28T00:44:24 | step: 293100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.376803452847525e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.86 | consumed tokens: 150067200.0 | grad norm avg: 9.05 | grad norm last: 8.74 | 
2025-12-28T00:44:26 | step: 293200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.375730249099433e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.88 | consumed tokens: 150118400.0 | grad norm avg: 8.8 | grad norm last: 7.65 | 
2025-12-28T00:44:29 | step: 293300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.374657045351341e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.09 | consumed tokens: 150169600.0 | grad norm avg: 8.52 | grad norm last: 7.17 | 
2025-12-28T00:44:31 | step: 293400 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 8.373583114007488e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.89 | consumed tokens: 150220800.0 | grad norm avg: 8.66 | grad norm last: 8.51 | 
2025-12-28T00:44:33 | step: 293500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 8.372509182663634e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.34 | consumed tokens: 150272000.0 | grad norm avg: 8.63 | grad norm last: 8.32 | 
2025-12-28T00:44:35 | step: 293600 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 8.37143452372402e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.22 | consumed tokens: 150323200.0 | grad norm avg: 8.87 | grad norm last: 8.39 | 
2025-12-28T00:44:37 | step: 293700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 8.370359864784405e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.03 | consumed tokens: 150374400.0 | grad norm avg: 8.74 | grad norm last: 10.52 | 
2025-12-28T00:44:39 | step: 293800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 8.369285933440551e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.53 | consumed tokens: 150425600.0 | grad norm avg: 9.0 | grad norm last: 8.06 | 
2025-12-28T00:44:41 | step: 293900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 8.368209819309413e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.64 | consumed tokens: 150476800.0 | grad norm avg: 8.53 | grad norm last: 7.21 | 
2025-12-28T00:44:43 | step: 294000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.367133705178276e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.09 | consumed tokens: 150528000.0 | grad norm avg: 8.74 | grad norm last: 7.92 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_294000-seen_tokens_150528000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_294000-seen_tokens_150528000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_294000-seen_tokens_150528000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_294000-seen_tokens_150528000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_294000-seen_tokens_150528000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_294000-seen_tokens_150528000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_294000-seen_tokens_150528000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_294000-seen_tokens_150528000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:44:45 | step: 294100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.3660583186429e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.83 | train loss last: 3.23 | consumed tokens: 150579200.0 | grad norm avg: 8.6 | grad norm last: 7.36 | 
2025-12-28T00:44:47 | step: 294200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.364982204511762e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.95 | consumed tokens: 150630400.0 | grad norm avg: 9.06 | grad norm last: 8.09 | 
2025-12-28T00:44:49 | step: 294300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 8.363906090380624e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.22 | consumed tokens: 150681600.0 | grad norm avg: 8.78 | grad norm last: 11.48 | 
2025-12-28T00:44:51 | step: 294400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.362830703845248e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 2.94 | consumed tokens: 150732800.0 | grad norm avg: 8.49 | grad norm last: 7.45 | 
2025-12-28T00:44:53 | step: 294500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.361753862118348e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.83 | consumed tokens: 150784000.0 | grad norm avg: 8.51 | grad norm last: 9.04 | 
2025-12-28T00:44:55 | step: 294600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.360675565199926e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.31 | consumed tokens: 150835200.0 | grad norm avg: 9.4 | grad norm last: 6.89 | 
2025-12-28T00:44:57 | step: 294700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.359598723473027e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.83 | consumed tokens: 150886400.0 | grad norm avg: 8.89 | grad norm last: 8.18 | 
2025-12-28T00:44:59 | step: 294800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.358520426554605e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.77 | consumed tokens: 150937600.0 | grad norm avg: 8.94 | grad norm last: 8.2 | 
2025-12-28T00:45:01 | step: 294900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 8.357442129636183e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.48 | consumed tokens: 150988800.0 | grad norm avg: 8.76 | grad norm last: 6.77 | 
2025-12-28T00:45:04 | step: 295000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.356364560313523e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.66 | consumed tokens: 151040000.0 | grad norm avg: 8.96 | grad norm last: 8.91 | 
2025-12-28T00:45:06 | step: 295100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.355286990990862e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 4.06 | consumed tokens: 151091200.0 | grad norm avg: 9.01 | grad norm last: 8.9 | 
2025-12-28T00:45:08 | step: 295200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.354207238880917e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.34 | consumed tokens: 151142400.0 | grad norm avg: 8.73 | grad norm last: 7.54 | 
2025-12-28T00:45:10 | step: 295300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.353128214366734e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.45 | consumed tokens: 151193600.0 | grad norm avg: 9.04 | grad norm last: 7.71 | 
2025-12-28T00:45:12 | step: 295400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.35204918985255e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.39 | consumed tokens: 151244800.0 | grad norm avg: 9.37 | grad norm last: 6.96 | 
2025-12-28T00:45:14 | step: 295500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.350969437742606e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.39 | consumed tokens: 151296000.0 | grad norm avg: 8.49 | grad norm last: 8.48 | 
2025-12-28T00:45:16 | step: 295600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.349889685632661e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.83 | consumed tokens: 151347200.0 | grad norm avg: 8.61 | grad norm last: 6.89 | 
2025-12-28T00:45:18 | step: 295700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.348809205926955e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.31 | consumed tokens: 151398400.0 | grad norm avg: 8.91 | grad norm last: 7.86 | 
2025-12-28T00:45:20 | step: 295800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.347728726221249e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.67 | consumed tokens: 151449600.0 | grad norm avg: 8.99 | grad norm last: 7.46 | 
2025-12-28T00:45:22 | step: 295900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.346648974111304e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.64 | consumed tokens: 151500800.0 | grad norm avg: 8.92 | grad norm last: 8.12 | 
2025-12-28T00:45:24 | step: 296000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.345567039214075e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 5.03 | consumed tokens: 151552000.0 | grad norm avg: 8.93 | grad norm last: 11.87 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_296000-seen_tokens_151552000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_296000-seen_tokens_151552000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_296000-seen_tokens_151552000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_296000-seen_tokens_151552000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_296000-seen_tokens_151552000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_296000-seen_tokens_151552000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_296000-seen_tokens_151552000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_296000-seen_tokens_151552000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:45:26 | step: 296100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.344485104316846e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.88 | consumed tokens: 151603200.0 | grad norm avg: 8.64 | grad norm last: 8.83 | 
2025-12-28T00:45:28 | step: 296200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.343404624611139e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.62 | consumed tokens: 151654400.0 | grad norm avg: 8.43 | grad norm last: 7.6 | 
2025-12-28T00:45:30 | step: 296300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.34232268971391e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.03 | consumed tokens: 151705600.0 | grad norm avg: 8.44 | grad norm last: 7.92 | 
2025-12-28T00:45:32 | step: 296400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 8.341241482412443e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 2.22 | consumed tokens: 151756800.0 | grad norm avg: 8.98 | grad norm last: 5.99 | 
2025-12-28T00:45:34 | step: 296500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.340158819919452e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.28 | consumed tokens: 151808000.0 | grad norm avg: 8.87 | grad norm last: 8.81 | 
2025-12-28T00:45:36 | step: 296600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.339076157426462e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.75 | consumed tokens: 151859200.0 | grad norm avg: 8.97 | grad norm last: 7.41 | 
2025-12-28T00:45:38 | step: 296700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.337993494933471e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.75 | consumed tokens: 151910400.0 | grad norm avg: 9.01 | grad norm last: 9.07 | 
2025-12-28T00:45:40 | step: 296800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.33691083244048e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.41 | consumed tokens: 151961600.0 | grad norm avg: 8.68 | grad norm last: 9.06 | 
2025-12-28T00:45:42 | step: 296900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.335826714755967e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.27 | consumed tokens: 152012800.0 | grad norm avg: 8.61 | grad norm last: 7.61 | 
2025-12-28T00:45:44 | step: 297000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.334742597071454e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.14 | consumed tokens: 152064000.0 | grad norm avg: 8.74 | grad norm last: 10.94 | 
2025-12-28T00:45:46 | step: 297100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.33365847938694e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.31 | consumed tokens: 152115200.0 | grad norm avg: 8.68 | grad norm last: 7.72 | 
2025-12-28T00:45:48 | step: 297200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.332574361702427e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.77 | consumed tokens: 152166400.0 | grad norm avg: 9.36 | grad norm last: 7.42 | 
2025-12-28T00:45:50 | step: 297300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.331490244017914e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.16 | consumed tokens: 152217600.0 | grad norm avg: 8.98 | grad norm last: 11.07 | 
2025-12-28T00:45:52 | step: 297400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.330404671141878e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 5.75 | consumed tokens: 152268800.0 | grad norm avg: 9.1 | grad norm last: 25.96 | 
2025-12-28T00:45:54 | step: 297500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.329320553457364e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.25 | consumed tokens: 152320000.0 | grad norm avg: 8.76 | grad norm last: 7.95 | 
2025-12-28T00:45:57 | step: 297600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.328234980581328e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.42 | consumed tokens: 152371200.0 | grad norm avg: 9.08 | grad norm last: 7.17 | 
2025-12-28T00:45:59 | step: 297700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.327149407705292e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.94 | consumed tokens: 152422400.0 | grad norm avg: 8.92 | grad norm last: 11.96 | 
2025-12-28T00:46:01 | step: 297800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.326062379637733e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.39 | consumed tokens: 152473600.0 | grad norm avg: 8.7 | grad norm last: 7.29 | 
2025-12-28T00:46:03 | step: 297900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.32497826195322e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.75 | consumed tokens: 152524800.0 | grad norm avg: 8.84 | grad norm last: 7.51 | 
2025-12-28T00:46:05 | step: 298000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.323891233885661e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.72 | consumed tokens: 152576000.0 | grad norm avg: 9.13 | grad norm last: 8.56 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_298000-seen_tokens_152576000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_298000-seen_tokens_152576000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_298000-seen_tokens_152576000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_298000-seen_tokens_152576000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_298000-seen_tokens_152576000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_298000-seen_tokens_152576000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_298000-seen_tokens_152576000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_298000-seen_tokens_152576000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:46:07 | step: 298100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.322804205818102e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.82 | train loss last: 3.95 | consumed tokens: 152627200.0 | grad norm avg: 8.5 | grad norm last: 10.29 | 
2025-12-28T00:46:09 | step: 298200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.321717177750543e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.39 | consumed tokens: 152678400.0 | grad norm avg: 8.96 | grad norm last: 7.48 | 
2025-12-28T00:46:11 | step: 298300 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 8.320630149682984e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.53 | consumed tokens: 152729600.0 | grad norm avg: 9.22 | grad norm last: 9.35 | 
2025-12-28T00:46:13 | step: 298400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 8.319542394019663e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.81 | consumed tokens: 152780800.0 | grad norm avg: 8.6 | grad norm last: 12.46 | 
2025-12-28T00:46:15 | step: 298500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 8.318454638356343e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.03 | consumed tokens: 152832000.0 | grad norm avg: 8.39 | grad norm last: 6.87 | 
2025-12-28T00:46:17 | step: 298600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 8.317366155097261e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.16 | consumed tokens: 152883200.0 | grad norm avg: 9.11 | grad norm last: 8.12 | 
2025-12-28T00:46:19 | step: 298700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.316277671838179e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 2.77 | consumed tokens: 152934400.0 | grad norm avg: 9.07 | grad norm last: 7.92 | 
2025-12-28T00:46:21 | step: 298800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.315189188579097e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.3 | consumed tokens: 152985600.0 | grad norm avg: 8.85 | grad norm last: 8.25 | 
2025-12-28T00:46:23 | step: 298900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.314100705320016e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.34 | consumed tokens: 153036800.0 | grad norm avg: 8.84 | grad norm last: 7.45 | 
2025-12-28T00:46:25 | step: 299000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.313012222060934e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.06 | consumed tokens: 153088000.0 | grad norm avg: 8.77 | grad norm last: 6.77 | 
2025-12-28T00:46:27 | step: 299100 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 8.311922283610329e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.98 | consumed tokens: 153139200.0 | grad norm avg: 8.55 | grad norm last: 8.43 | 
2025-12-28T00:46:29 | step: 299200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 8.310833800351247e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.7 | consumed tokens: 153190400.0 | grad norm avg: 9.16 | grad norm last: 8.8 | 
2025-12-28T00:46:31 | step: 299300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 8.309743134304881e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 2.78 | consumed tokens: 153241600.0 | grad norm avg: 8.86 | grad norm last: 7.01 | 
2025-12-28T00:46:33 | step: 299400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 8.308652468258515e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.44 | consumed tokens: 153292800.0 | grad norm avg: 8.78 | grad norm last: 9.01 | 
2025-12-28T00:46:35 | step: 299500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.30756252980791e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.25 | consumed tokens: 153344000.0 | grad norm avg: 8.65 | grad norm last: 8.0 | 
2025-12-28T00:46:38 | step: 299600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 8.306471863761544e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.06 | consumed tokens: 153395200.0 | grad norm avg: 8.54 | grad norm last: 9.36 | 
2025-12-28T00:46:40 | step: 299700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.305380470119417e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.73 | consumed tokens: 153446400.0 | grad norm avg: 8.59 | grad norm last: 8.23 | 
2025-12-28T00:46:42 | step: 299800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 8.304289076477289e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.34 | consumed tokens: 153497600.0 | grad norm avg: 8.97 | grad norm last: 8.0 | 
2025-12-28T00:46:44 | step: 299900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.303197682835162e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.39 | consumed tokens: 153548800.0 | grad norm avg: 8.97 | grad norm last: 7.28 | 
2025-12-28T00:46:46 | step: 300000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.302105561597273e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.53 | consumed tokens: 153600000.0 | grad norm avg: 8.74 | grad norm last: 8.76 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_300000-seen_tokens_153600000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_300000-seen_tokens_153600000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_300000-seen_tokens_153600000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_300000-seen_tokens_153600000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_300000-seen_tokens_153600000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_300000-seen_tokens_153600000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_300000-seen_tokens_153600000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_300000-seen_tokens_153600000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:46:48 | step: 300100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.301014167955145e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.62 | consumed tokens: 153651200.0 | grad norm avg: 8.51 | grad norm last: 7.91 | 
2025-12-28T00:46:50 | step: 300200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.299921319121495e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.34 | consumed tokens: 153702400.0 | grad norm avg: 8.82 | grad norm last: 9.21 | 
2025-12-28T00:46:52 | step: 300300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.298828470287845e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.81 | consumed tokens: 153753600.0 | grad norm avg: 9.46 | grad norm last: 11.03 | 
2025-12-28T00:46:54 | step: 300400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.297735621454194e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.48 | consumed tokens: 153804800.0 | grad norm avg: 8.59 | grad norm last: 7.9 | 
2025-12-28T00:46:56 | step: 300500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.296642772620544e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.58 | consumed tokens: 153856000.0 | grad norm avg: 8.94 | grad norm last: 7.3 | 
2025-12-28T00:46:58 | step: 300600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.295549196191132e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.44 | consumed tokens: 153907200.0 | grad norm avg: 8.69 | grad norm last: 7.57 | 
2025-12-28T00:47:00 | step: 300700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.29445561976172e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.97 | consumed tokens: 153958400.0 | grad norm avg: 8.74 | grad norm last: 7.76 | 
2025-12-28T00:47:02 | step: 300800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.293361315736547e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.09 | consumed tokens: 154009600.0 | grad norm avg: 8.5 | grad norm last: 8.06 | 
2025-12-28T00:47:04 | step: 300900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 8.292267011711374e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.05 | consumed tokens: 154060800.0 | grad norm avg: 8.57 | grad norm last: 7.46 | 
2025-12-28T00:47:06 | step: 301000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.291172707686201e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 2.95 | consumed tokens: 154112000.0 | grad norm avg: 8.74 | grad norm last: 10.48 | 
2025-12-28T00:47:08 | step: 301100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.290078403661028e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.72 | consumed tokens: 154163200.0 | grad norm avg: 8.28 | grad norm last: 8.54 | 
2025-12-28T00:47:10 | step: 301200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 8.288983372040093e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.41 | consumed tokens: 154214400.0 | grad norm avg: 8.74 | grad norm last: 7.86 | 
2025-12-28T00:47:12 | step: 301300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.287888340419158e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.81 | consumed tokens: 154265600.0 | grad norm avg: 8.86 | grad norm last: 9.66 | 
2025-12-28T00:47:14 | step: 301400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 8.286791853606701e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.09 | consumed tokens: 154316800.0 | grad norm avg: 8.81 | grad norm last: 7.98 | 
2025-12-28T00:47:16 | step: 301500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 8.285695366794243e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.97 | consumed tokens: 154368000.0 | grad norm avg: 8.91 | grad norm last: 8.45 | 
2025-12-28T00:47:18 | step: 301600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.284600335173309e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 5.03 | consumed tokens: 154419200.0 | grad norm avg: 8.61 | grad norm last: 12.11 | 
2025-12-28T00:47:20 | step: 301700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.283503848360851e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.09 | consumed tokens: 154470400.0 | grad norm avg: 8.87 | grad norm last: 8.3 | 
2025-12-28T00:47:22 | step: 301800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.282406633952633e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.34 | consumed tokens: 154521600.0 | grad norm avg: 8.79 | grad norm last: 7.64 | 
2025-12-28T00:47:24 | step: 301900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.281310874735937e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.67 | consumed tokens: 154572800.0 | grad norm avg: 8.56 | grad norm last: 7.29 | 
2025-12-28T00:47:27 | step: 302000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.280212205136195e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.75 | consumed tokens: 154624000.0 | grad norm avg: 8.69 | grad norm last: 8.51 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_302000-seen_tokens_154624000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_302000-seen_tokens_154624000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_302000-seen_tokens_154624000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_302000-seen_tokens_154624000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_302000-seen_tokens_154624000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_302000-seen_tokens_154624000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_302000-seen_tokens_154624000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_302000-seen_tokens_154624000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:47:29 | step: 302100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.279116445919499e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.82 | train loss last: 3.41 | consumed tokens: 154675200.0 | grad norm avg: 8.95 | grad norm last: 7.66 | 
2025-12-28T00:47:31 | step: 302200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.278017776319757e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.42 | consumed tokens: 154726400.0 | grad norm avg: 8.74 | grad norm last: 9.21 | 
2025-12-28T00:47:33 | step: 302300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.276919834315777e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.8 | consumed tokens: 154777600.0 | grad norm avg: 8.65 | grad norm last: 7.9 | 
2025-12-28T00:47:35 | step: 302400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.275821892311797e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 5.38 | consumed tokens: 154828800.0 | grad norm avg: 8.89 | grad norm last: 10.42 | 
2025-12-28T00:47:37 | step: 302500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.274723222712055e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.89 | consumed tokens: 154880000.0 | grad norm avg: 8.87 | grad norm last: 9.26 | 
2025-12-28T00:47:39 | step: 302600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.273624553112313e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.41 | consumed tokens: 154931200.0 | grad norm avg: 8.64 | grad norm last: 13.4 | 
2025-12-28T00:47:41 | step: 302700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.27252515591681e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.83 | consumed tokens: 154982400.0 | grad norm avg: 9.08 | grad norm last: 9.49 | 
2025-12-28T00:47:43 | step: 302800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.271425758721307e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.89 | consumed tokens: 155033600.0 | grad norm avg: 9.2 | grad norm last: 7.43 | 
2025-12-28T00:47:45 | step: 302900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.270327089121565e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.12 | consumed tokens: 155084800.0 | grad norm avg: 8.41 | grad norm last: 9.19 | 
2025-12-28T00:47:47 | step: 303000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.269226964330301e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.8 | consumed tokens: 155136000.0 | grad norm avg: 8.95 | grad norm last: 7.32 | 
2025-12-28T00:47:49 | step: 303100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.268126839539036e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.31 | consumed tokens: 155187200.0 | grad norm avg: 8.77 | grad norm last: 6.91 | 
2025-12-28T00:47:51 | step: 303200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.267026714747772e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.81 | consumed tokens: 155238400.0 | grad norm avg: 8.89 | grad norm last: 8.13 | 
2025-12-28T00:47:53 | step: 303300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.265925134764984e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.69 | consumed tokens: 155289600.0 | grad norm avg: 8.76 | grad norm last: 8.15 | 
2025-12-28T00:47:55 | step: 303400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.264824282377958e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.39 | consumed tokens: 155340800.0 | grad norm avg: 9.08 | grad norm last: 7.46 | 
2025-12-28T00:47:57 | step: 303500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.263723429990932e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.45 | consumed tokens: 155392000.0 | grad norm avg: 8.53 | grad norm last: 7.91 | 
2025-12-28T00:47:59 | step: 303600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 8.262621850008145e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.8 | consumed tokens: 155443200.0 | grad norm avg: 8.8 | grad norm last: 7.53 | 
2025-12-28T00:48:01 | step: 303700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 8.261520270025358e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.92 | consumed tokens: 155494400.0 | grad norm avg: 8.85 | grad norm last: 8.25 | 
2025-12-28T00:48:03 | step: 303800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.260417962446809e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.47 | consumed tokens: 155545600.0 | grad norm avg: 8.84 | grad norm last: 7.76 | 
2025-12-28T00:48:05 | step: 303900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.25931565486826e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.66 | consumed tokens: 155596800.0 | grad norm avg: 8.88 | grad norm last: 7.45 | 
2025-12-28T00:48:07 | step: 304000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.258214074885473e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 2.81 | consumed tokens: 155648000.0 | grad norm avg: 9.16 | grad norm last: 7.01 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_304000-seen_tokens_155648000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_304000-seen_tokens_155648000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_304000-seen_tokens_155648000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_304000-seen_tokens_155648000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_304000-seen_tokens_155648000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_304000-seen_tokens_155648000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_304000-seen_tokens_155648000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_304000-seen_tokens_155648000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:48:10 | step: 304100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.25710958451964e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.61 | consumed tokens: 155699200.0 | grad norm avg: 8.76 | grad norm last: 7.77 | 
2025-12-28T00:48:12 | step: 304200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.256008004536852e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.78 | consumed tokens: 155750400.0 | grad norm avg: 8.41 | grad norm last: 8.14 | 
2025-12-28T00:48:14 | step: 304300 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 8.254903514171019e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.69 | consumed tokens: 155801600.0 | grad norm avg: 9.29 | grad norm last: 8.2 | 
2025-12-28T00:48:16 | step: 304400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 8.253800478996709e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.3 | consumed tokens: 155852800.0 | grad norm avg: 8.87 | grad norm last: 6.64 | 
2025-12-28T00:48:18 | step: 304500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.252696716226637e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.22 | consumed tokens: 155904000.0 | grad norm avg: 8.6 | grad norm last: 8.0 | 
2025-12-28T00:48:20 | step: 304600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.251591498265043e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.95 | consumed tokens: 155955200.0 | grad norm avg: 8.73 | grad norm last: 10.22 | 
2025-12-28T00:48:22 | step: 304700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.250488463090733e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.22 | consumed tokens: 156006400.0 | grad norm avg: 8.83 | grad norm last: 9.19 | 
2025-12-28T00:48:24 | step: 304800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.2493839727249e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 5.28 | consumed tokens: 156057600.0 | grad norm avg: 9.02 | grad norm last: 9.5 | 
2025-12-28T00:48:26 | step: 304900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.248278754763305e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 2.95 | consumed tokens: 156108800.0 | grad norm avg: 8.49 | grad norm last: 7.12 | 
2025-12-28T00:48:28 | step: 305000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.247173536801711e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.02 | consumed tokens: 156160000.0 | grad norm avg: 9.22 | grad norm last: 9.35 | 
2025-12-28T00:48:30 | step: 305100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.246067591244355e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.3 | consumed tokens: 156211200.0 | grad norm avg: 9.18 | grad norm last: 6.83 | 
2025-12-28T00:48:32 | step: 305200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.244961645686999e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.78 | consumed tokens: 156262400.0 | grad norm avg: 8.8 | grad norm last: 8.22 | 
2025-12-28T00:48:34 | step: 305300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.243855700129643e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.09 | consumed tokens: 156313600.0 | grad norm avg: 9.05 | grad norm last: 10.37 | 
2025-12-28T00:48:36 | step: 305400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.242749754572287e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.88 | consumed tokens: 156364800.0 | grad norm avg: 9.33 | grad norm last: 9.1 | 
2025-12-28T00:48:38 | step: 305500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.241643809014931e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.31 | consumed tokens: 156416000.0 | grad norm avg: 8.68 | grad norm last: 8.76 | 
2025-12-28T00:48:40 | step: 305600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.240537135861814e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.5 | consumed tokens: 156467200.0 | grad norm avg: 9.11 | grad norm last: 7.58 | 
2025-12-28T00:48:42 | step: 305700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.239430462708697e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.53 | consumed tokens: 156518400.0 | grad norm avg: 9.18 | grad norm last: 8.4 | 
2025-12-28T00:48:44 | step: 305800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.238322334364057e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.09 | consumed tokens: 156569600.0 | grad norm avg: 8.92 | grad norm last: 8.41 | 
2025-12-28T00:48:46 | step: 305900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.237214206019416e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.95 | consumed tokens: 156620800.0 | grad norm avg: 8.86 | grad norm last: 7.77 | 
2025-12-28T00:48:48 | step: 306000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.236107532866299e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.19 | consumed tokens: 156672000.0 | grad norm avg: 8.93 | grad norm last: 9.15 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_306000-seen_tokens_156672000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_306000-seen_tokens_156672000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_306000-seen_tokens_156672000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_306000-seen_tokens_156672000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_306000-seen_tokens_156672000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_306000-seen_tokens_156672000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_306000-seen_tokens_156672000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_306000-seen_tokens_156672000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:48:50 | step: 306100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.234999404521659e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.74 | train loss last: 3.05 | consumed tokens: 156723200.0 | grad norm avg: 8.93 | grad norm last: 8.48 | 
2025-12-28T00:48:52 | step: 306200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.233890548581257e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.33 | consumed tokens: 156774400.0 | grad norm avg: 8.83 | grad norm last: 7.43 | 
2025-12-28T00:48:54 | step: 306300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.232783147832379e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.31 | consumed tokens: 156825600.0 | grad norm avg: 9.16 | grad norm last: 12.5 | 
2025-12-28T00:48:56 | step: 306400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.231672836700454e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.31 | consumed tokens: 156876800.0 | grad norm avg: 8.68 | grad norm last: 8.24 | 
2025-12-28T00:48:58 | step: 306500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.230563980760053e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.22 | consumed tokens: 156928000.0 | grad norm avg: 9.23 | grad norm last: 10.15 | 
2025-12-28T00:49:00 | step: 306600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.229455124819651e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.75 | consumed tokens: 156979200.0 | grad norm avg: 9.13 | grad norm last: 10.98 | 
2025-12-28T00:49:02 | step: 306700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.228345541283488e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.66 | consumed tokens: 157030400.0 | grad norm avg: 8.94 | grad norm last: 7.3 | 
2025-12-28T00:49:04 | step: 306800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.227235957747325e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.03 | consumed tokens: 157081600.0 | grad norm avg: 9.17 | grad norm last: 7.77 | 
2025-12-28T00:49:06 | step: 306900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.22612491901964e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.16 | consumed tokens: 157132800.0 | grad norm avg: 9.48 | grad norm last: 9.02 | 
2025-12-28T00:49:08 | step: 307000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.225013880291954e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 2.5 | consumed tokens: 157184000.0 | grad norm avg: 9.51 | grad norm last: 6.4 | 
2025-12-28T00:49:10 | step: 307100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.223904296755791e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.44 | consumed tokens: 157235200.0 | grad norm avg: 9.34 | grad norm last: 13.81 | 
2025-12-28T00:49:12 | step: 307200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.222793258028105e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.47 | consumed tokens: 157286400.0 | grad norm avg: 9.82 | grad norm last: 8.56 | 
2025-12-28T00:49:14 | step: 307300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.22168294689618e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.22 | consumed tokens: 157337600.0 | grad norm avg: 9.46 | grad norm last: 10.13 | 
2025-12-28T00:49:16 | step: 307400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.220571180572733e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.19 | consumed tokens: 157388800.0 | grad norm avg: 10.07 | grad norm last: 11.48 | 
2025-12-28T00:49:18 | step: 307500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.219459414249286e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.59 | consumed tokens: 157440000.0 | grad norm avg: 9.8 | grad norm last: 10.66 | 
2025-12-28T00:49:20 | step: 307600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.218347647925839e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.0 | consumed tokens: 157491200.0 | grad norm avg: 9.66 | grad norm last: 7.89 | 
2025-12-28T00:49:22 | step: 307700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.217234426410869e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.78 | consumed tokens: 157542400.0 | grad norm avg: 9.57 | grad norm last: 8.38 | 
2025-12-28T00:49:24 | step: 307800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.21612193249166e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.5 | consumed tokens: 157593600.0 | grad norm avg: 9.33 | grad norm last: 8.81 | 
2025-12-28T00:49:27 | step: 307900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.215009438572451e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.83 | consumed tokens: 157644800.0 | grad norm avg: 9.48 | grad norm last: 8.64 | 
2025-12-28T00:49:29 | step: 308000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.213896217057481e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.44 | consumed tokens: 157696000.0 | grad norm avg: 9.36 | grad norm last: 8.51 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_308000-seen_tokens_157696000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_308000-seen_tokens_157696000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_308000-seen_tokens_157696000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_308000-seen_tokens_157696000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_308000-seen_tokens_157696000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_308000-seen_tokens_157696000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_308000-seen_tokens_157696000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_308000-seen_tokens_157696000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:49:31 | step: 308100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.212782995542511e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.36 | consumed tokens: 157747200.0 | grad norm avg: 9.42 | grad norm last: 7.09 | 
2025-12-28T00:49:33 | step: 308200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.21166904643178e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.12 | consumed tokens: 157798400.0 | grad norm avg: 10.24 | grad norm last: 9.53 | 
2025-12-28T00:49:35 | step: 308300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.210555097321048e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.62 | consumed tokens: 157849600.0 | grad norm avg: 9.67 | grad norm last: 10.86 | 
2025-12-28T00:49:37 | step: 308400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.209441875806078e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 2.94 | consumed tokens: 157900800.0 | grad norm avg: 9.5 | grad norm last: 7.43 | 
2025-12-28T00:49:39 | step: 308500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 8.208327199099585e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.42 | consumed tokens: 157952000.0 | grad norm avg: 9.48 | grad norm last: 9.39 | 
2025-12-28T00:49:41 | step: 308600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 8.207212522393093e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.28 | consumed tokens: 158003200.0 | grad norm avg: 9.32 | grad norm last: 7.26 | 
2025-12-28T00:49:43 | step: 308700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.2060978456866e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.45 | consumed tokens: 158054400.0 | grad norm avg: 9.2 | grad norm last: 8.8 | 
2025-12-28T00:49:45 | step: 308800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.204983168980107e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.62 | consumed tokens: 158105600.0 | grad norm avg: 9.16 | grad norm last: 8.35 | 
2025-12-28T00:49:47 | step: 308900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.203867037082091e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.41 | consumed tokens: 158156800.0 | grad norm avg: 9.65 | grad norm last: 8.55 | 
2025-12-28T00:49:49 | step: 309000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.202751632779837e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.47 | consumed tokens: 158208000.0 | grad norm avg: 9.47 | grad norm last: 9.62 | 
2025-12-28T00:49:51 | step: 309100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.201636228477582e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.17 | consumed tokens: 158259200.0 | grad norm avg: 9.63 | grad norm last: 8.32 | 
2025-12-28T00:49:53 | step: 309200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.200519368983805e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.16 | consumed tokens: 158310400.0 | grad norm avg: 9.53 | grad norm last: 7.19 | 
2025-12-28T00:49:55 | step: 309300 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 8.199402509490028e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.58 | consumed tokens: 158361600.0 | grad norm avg: 9.87 | grad norm last: 7.98 | 
2025-12-28T00:49:57 | step: 309400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 8.198286377592012e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.06 | consumed tokens: 158412800.0 | grad norm avg: 9.44 | grad norm last: 11.56 | 
2025-12-28T00:49:59 | step: 309500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.197169518098235e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.7 | consumed tokens: 158464000.0 | grad norm avg: 9.45 | grad norm last: 8.01 | 
2025-12-28T00:50:01 | step: 309600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.196051931008697e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.66 | consumed tokens: 158515200.0 | grad norm avg: 9.86 | grad norm last: 8.2 | 
2025-12-28T00:50:03 | step: 309700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.194934343919158e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.47 | consumed tokens: 158566400.0 | grad norm avg: 9.99 | grad norm last: 9.17 | 
2025-12-28T00:50:05 | step: 309800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.19381675682962e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.22 | consumed tokens: 158617600.0 | grad norm avg: 10.36 | grad norm last: 12.2 | 
2025-12-28T00:50:07 | step: 309900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.192699169740081e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.14 | consumed tokens: 158668800.0 | grad norm avg: 9.63 | grad norm last: 8.62 | 
2025-12-28T00:50:09 | step: 310000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.191580855054781e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.19 | consumed tokens: 158720000.0 | grad norm avg: 9.66 | grad norm last: 7.66 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_310000-seen_tokens_158720000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_310000-seen_tokens_158720000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_310000-seen_tokens_158720000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_310000-seen_tokens_158720000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_310000-seen_tokens_158720000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_310000-seen_tokens_158720000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_310000-seen_tokens_158720000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_310000-seen_tokens_158720000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:50:12 | step: 310100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.19046181277372e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.41 | consumed tokens: 158771200.0 | grad norm avg: 9.5 | grad norm last: 9.39 | 
2025-12-28T00:50:14 | step: 310200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.18934349808842e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.67 | consumed tokens: 158822400.0 | grad norm avg: 9.19 | grad norm last: 7.89 | 
2025-12-28T00:50:16 | step: 310300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.18822518340312e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.17 | consumed tokens: 158873600.0 | grad norm avg: 9.71 | grad norm last: 7.93 | 
2025-12-28T00:50:18 | step: 310400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.187104685930535e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.44 | consumed tokens: 158924800.0 | grad norm avg: 9.68 | grad norm last: 12.79 | 
2025-12-28T00:50:20 | step: 310500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.185985643649474e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.97 | consumed tokens: 158976000.0 | grad norm avg: 9.51 | grad norm last: 9.74 | 
2025-12-28T00:50:22 | step: 310600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.184866601368412e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.62 | consumed tokens: 159027200.0 | grad norm avg: 9.89 | grad norm last: 7.81 | 
2025-12-28T00:50:24 | step: 310700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.183744648704305e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.7 | consumed tokens: 159078400.0 | grad norm avg: 9.92 | grad norm last: 8.64 | 
2025-12-28T00:50:26 | step: 310800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.182625606423244e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.7 | consumed tokens: 159129600.0 | grad norm avg: 10.18 | grad norm last: 9.95 | 
2025-12-28T00:50:28 | step: 310900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.181503653759137e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 2.84 | consumed tokens: 159180800.0 | grad norm avg: 10.07 | grad norm last: 9.48 | 
2025-12-28T00:50:30 | step: 311000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 8.180384611478075e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.28 | consumed tokens: 159232000.0 | grad norm avg: 10.21 | grad norm last: 18.92 | 
2025-12-28T00:50:32 | step: 311100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.179262658813968e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.44 | consumed tokens: 159283200.0 | grad norm avg: 10.15 | grad norm last: 8.86 | 
2025-12-28T00:50:34 | step: 311200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.178141433745623e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.89 | consumed tokens: 159334400.0 | grad norm avg: 9.5 | grad norm last: 8.66 | 
2025-12-28T00:50:36 | step: 311300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.177020208677277e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.66 | consumed tokens: 159385600.0 | grad norm avg: 9.97 | grad norm last: 8.15 | 
2025-12-28T00:50:38 | step: 311400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.17589825601317e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 2.98 | consumed tokens: 159436800.0 | grad norm avg: 9.5 | grad norm last: 6.46 | 
2025-12-28T00:50:40 | step: 311500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.17477484815754e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.97 | consumed tokens: 159488000.0 | grad norm avg: 9.57 | grad norm last: 10.9 | 
2025-12-28T00:50:42 | step: 311600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.173653623089194e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.19 | consumed tokens: 159539200.0 | grad norm avg: 9.89 | grad norm last: 9.68 | 
2025-12-28T00:50:44 | step: 311700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.172530942829326e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.19 | consumed tokens: 159590400.0 | grad norm avg: 9.44 | grad norm last: 11.37 | 
2025-12-28T00:50:46 | step: 311800 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 8.171408990165219e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.84 | consumed tokens: 159641600.0 | grad norm avg: 9.66 | grad norm last: 10.86 | 
2025-12-28T00:50:48 | step: 311900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.170285582309589e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 2.77 | consumed tokens: 159692800.0 | grad norm avg: 9.58 | grad norm last: 6.62 | 
2025-12-28T00:50:50 | step: 312000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.169162174453959e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 5.31 | consumed tokens: 159744000.0 | grad norm avg: 10.14 | grad norm last: 17.13 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_312000-seen_tokens_159744000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_312000-seen_tokens_159744000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_312000-seen_tokens_159744000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_312000-seen_tokens_159744000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_312000-seen_tokens_159744000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_312000-seen_tokens_159744000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_312000-seen_tokens_159744000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_312000-seen_tokens_159744000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:50:52 | step: 312100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.168038766598329e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.19 | consumed tokens: 159795200.0 | grad norm avg: 9.79 | grad norm last: 8.88 | 
2025-12-28T00:50:54 | step: 312200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.166913903551176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.45 | consumed tokens: 159846400.0 | grad norm avg: 10.02 | grad norm last: 7.88 | 
2025-12-28T00:50:56 | step: 312300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.165789768099785e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.69 | consumed tokens: 159897600.0 | grad norm avg: 9.45 | grad norm last: 9.74 | 
2025-12-28T00:50:58 | step: 312400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.164665632648394e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.67 | consumed tokens: 159948800.0 | grad norm avg: 9.46 | grad norm last: 8.16 | 
2025-12-28T00:51:00 | step: 312500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.163540769601241e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.84 | consumed tokens: 160000000.0 | grad norm avg: 9.57 | grad norm last: 12.22 | 
2025-12-28T00:51:02 | step: 312600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.162415906554088e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.09 | consumed tokens: 160051200.0 | grad norm avg: 9.79 | grad norm last: 7.41 | 
2025-12-28T00:51:04 | step: 312700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.161290315911174e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.83 | consumed tokens: 160102400.0 | grad norm avg: 9.45 | grad norm last: 11.39 | 
2025-12-28T00:51:06 | step: 312800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.16016472526826e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.55 | consumed tokens: 160153600.0 | grad norm avg: 9.71 | grad norm last: 9.48 | 
2025-12-28T00:51:08 | step: 312900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.159039862221107e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.61 | consumed tokens: 160204800.0 | grad norm avg: 9.54 | grad norm last: 7.88 | 
2025-12-28T00:51:10 | step: 313000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.157913543982431e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.53 | consumed tokens: 160256000.0 | grad norm avg: 9.67 | grad norm last: 7.19 | 
2025-12-28T00:51:13 | step: 313100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.156787225743756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.69 | consumed tokens: 160307200.0 | grad norm avg: 10.18 | grad norm last: 9.05 | 
2025-12-28T00:51:15 | step: 313200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.15566090750508e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.42 | consumed tokens: 160358400.0 | grad norm avg: 9.46 | grad norm last: 7.59 | 
2025-12-28T00:51:17 | step: 313300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 8.154534589266405e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.5 | consumed tokens: 160409600.0 | grad norm avg: 11.04 | grad norm last: 8.49 | 
2025-12-28T00:51:19 | step: 313400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 8.153406815836206e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.47 | consumed tokens: 160460800.0 | grad norm avg: 9.18 | grad norm last: 9.96 | 
2025-12-28T00:51:21 | step: 313500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.152279770001769e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.3 | consumed tokens: 160512000.0 | grad norm avg: 9.71 | grad norm last: 10.09 | 
2025-12-28T00:51:23 | step: 313600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.151152724167332e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 5.59 | consumed tokens: 160563200.0 | grad norm avg: 9.79 | grad norm last: 14.5 | 
2025-12-28T00:51:25 | step: 313700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.150024223141372e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.83 | consumed tokens: 160614400.0 | grad norm avg: 9.66 | grad norm last: 9.9 | 
2025-12-28T00:51:27 | step: 313800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.148895722115412e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.75 | consumed tokens: 160665600.0 | grad norm avg: 10.03 | grad norm last: 8.75 | 
2025-12-28T00:51:29 | step: 313900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.147767948685214e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.42 | consumed tokens: 160716800.0 | grad norm avg: 9.8 | grad norm last: 7.39 | 
2025-12-28T00:51:31 | step: 314000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.146639447659254e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.03 | consumed tokens: 160768000.0 | grad norm avg: 9.58 | grad norm last: 11.87 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_314000-seen_tokens_160768000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_314000-seen_tokens_160768000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_314000-seen_tokens_160768000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_314000-seen_tokens_160768000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_314000-seen_tokens_160768000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_314000-seen_tokens_160768000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_314000-seen_tokens_160768000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_314000-seen_tokens_160768000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:51:33 | step: 314100 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 8.145510946633294e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.59 | consumed tokens: 160819200.0 | grad norm avg: 9.56 | grad norm last: 9.21 | 
2025-12-28T00:51:35 | step: 314200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 8.144381718011573e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.38 | consumed tokens: 160870400.0 | grad norm avg: 9.69 | grad norm last: 15.03 | 
2025-12-28T00:51:37 | step: 314300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.143252489389852e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.36 | consumed tokens: 160921600.0 | grad norm avg: 9.75 | grad norm last: 8.17 | 
2025-12-28T00:51:39 | step: 314400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.14212326076813e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 2.86 | consumed tokens: 160972800.0 | grad norm avg: 9.86 | grad norm last: 7.53 | 
2025-12-28T00:51:41 | step: 314500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.140993304550648e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.27 | consumed tokens: 161024000.0 | grad norm avg: 9.74 | grad norm last: 7.46 | 
2025-12-28T00:51:43 | step: 314600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.139863348333165e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.97 | consumed tokens: 161075200.0 | grad norm avg: 10.46 | grad norm last: 9.0 | 
2025-12-28T00:51:45 | step: 314700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.138732664519921e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.16 | consumed tokens: 161126400.0 | grad norm avg: 10.03 | grad norm last: 10.78 | 
2025-12-28T00:51:47 | step: 314800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.137602708302438e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.66 | consumed tokens: 161177600.0 | grad norm avg: 9.6 | grad norm last: 8.46 | 
2025-12-28T00:51:49 | step: 314900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.136471296893433e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.38 | consumed tokens: 161228800.0 | grad norm avg: 9.38 | grad norm last: 8.11 | 
2025-12-28T00:51:51 | step: 315000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.135340613080189e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.66 | consumed tokens: 161280000.0 | grad norm avg: 9.77 | grad norm last: 9.12 | 
2025-12-28T00:51:53 | step: 315100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.134209201671183e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.95 | consumed tokens: 161331200.0 | grad norm avg: 9.43 | grad norm last: 9.1 | 
2025-12-28T00:51:55 | step: 315200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.133077790262178e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.5 | consumed tokens: 161382400.0 | grad norm avg: 9.33 | grad norm last: 7.83 | 
2025-12-28T00:51:57 | step: 315300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.13194565125741e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 5.72 | consumed tokens: 161433600.0 | grad norm avg: 9.96 | grad norm last: 26.38 | 
2025-12-28T00:51:59 | step: 315400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.130813512252644e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.53 | consumed tokens: 161484800.0 | grad norm avg: 9.22 | grad norm last: 7.64 | 
2025-12-28T00:52:01 | step: 315500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.129681373247877e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.55 | consumed tokens: 161536000.0 | grad norm avg: 9.33 | grad norm last: 8.29 | 
2025-12-28T00:52:03 | step: 315600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.12854923424311e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.61 | consumed tokens: 161587200.0 | grad norm avg: 9.68 | grad norm last: 7.75 | 
2025-12-28T00:52:05 | step: 315700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.127416367642581e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.16 | consumed tokens: 161638400.0 | grad norm avg: 9.47 | grad norm last: 9.28 | 
2025-12-28T00:52:07 | step: 315800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.126282773446292e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.81 | consumed tokens: 161689600.0 | grad norm avg: 9.75 | grad norm last: 14.43 | 
2025-12-28T00:52:09 | step: 315900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.125149906845763e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.58 | consumed tokens: 161740800.0 | grad norm avg: 9.89 | grad norm last: 10.23 | 
2025-12-28T00:52:11 | step: 316000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.124016312649474e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.81 | consumed tokens: 161792000.0 | grad norm avg: 9.99 | grad norm last: 8.22 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_316000-seen_tokens_161792000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_316000-seen_tokens_161792000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_316000-seen_tokens_161792000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_316000-seen_tokens_161792000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_316000-seen_tokens_161792000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_316000-seen_tokens_161792000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_316000-seen_tokens_161792000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_316000-seen_tokens_161792000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:52:14 | step: 316100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.122881990857422e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.85 | train loss last: 3.48 | consumed tokens: 161843200.0 | grad norm avg: 9.37 | grad norm last: 9.66 | 
2025-12-28T00:52:16 | step: 316200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.121748396661133e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.12 | consumed tokens: 161894400.0 | grad norm avg: 9.76 | grad norm last: 8.42 | 
2025-12-28T00:52:18 | step: 316300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.120614074869081e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.86 | consumed tokens: 161945600.0 | grad norm avg: 9.75 | grad norm last: 10.85 | 
2025-12-28T00:52:20 | step: 316400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.119479025481269e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.25 | consumed tokens: 161996800.0 | grad norm avg: 10.38 | grad norm last: 10.79 | 
2025-12-28T00:52:22 | step: 316500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.118344703689218e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.0 | consumed tokens: 162048000.0 | grad norm avg: 9.79 | grad norm last: 8.7 | 
2025-12-28T00:52:24 | step: 316600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.117208926705644e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.73 | consumed tokens: 162099200.0 | grad norm avg: 9.76 | grad norm last: 8.65 | 
2025-12-28T00:52:26 | step: 316700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.116073877317831e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.03 | consumed tokens: 162150400.0 | grad norm avg: 10.24 | grad norm last: 8.3 | 
2025-12-28T00:52:28 | step: 316800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.114938100334257e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.47 | consumed tokens: 162201600.0 | grad norm avg: 9.76 | grad norm last: 10.41 | 
2025-12-28T00:52:30 | step: 316900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.113802323350683e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.28 | consumed tokens: 162252800.0 | grad norm avg: 9.59 | grad norm last: 12.17 | 
2025-12-28T00:52:32 | step: 317000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.112666546367109e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.12 | consumed tokens: 162304000.0 | grad norm avg: 9.47 | grad norm last: 6.88 | 
2025-12-28T00:52:34 | step: 317100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.111530041787773e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.25 | consumed tokens: 162355200.0 | grad norm avg: 10.08 | grad norm last: 7.88 | 
2025-12-28T00:52:36 | step: 317200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.110393537208438e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.2 | consumed tokens: 162406400.0 | grad norm avg: 9.13 | grad norm last: 14.59 | 
2025-12-28T00:52:38 | step: 317300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.109256305033341e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.8 | consumed tokens: 162457600.0 | grad norm avg: 10.03 | grad norm last: 7.81 | 
2025-12-28T00:52:40 | step: 317400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.108119800454006e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.58 | consumed tokens: 162508800.0 | grad norm avg: 9.98 | grad norm last: 8.69 | 
2025-12-28T00:52:42 | step: 317500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.106981840683147e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.95 | consumed tokens: 162560000.0 | grad norm avg: 9.54 | grad norm last: 9.86 | 
2025-12-28T00:52:44 | step: 317600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 8.10584460850805e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.38 | consumed tokens: 162611200.0 | grad norm avg: 10.25 | grad norm last: 8.74 | 
2025-12-28T00:52:46 | step: 317700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.104706648737192e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.91 | consumed tokens: 162662400.0 | grad norm avg: 10.23 | grad norm last: 9.86 | 
2025-12-28T00:52:48 | step: 317800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 8.103568688966334e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.89 | consumed tokens: 162713600.0 | grad norm avg: 9.75 | grad norm last: 8.28 | 
2025-12-28T00:52:50 | step: 317900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.102430001599714e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.52 | consumed tokens: 162764800.0 | grad norm avg: 10.55 | grad norm last: 13.98 | 
2025-12-28T00:52:52 | step: 318000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.101291314233094e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.31 | consumed tokens: 162816000.0 | grad norm avg: 9.73 | grad norm last: 7.9 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_318000-seen_tokens_162816000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_318000-seen_tokens_162816000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_318000-seen_tokens_162816000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_318000-seen_tokens_162816000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_318000-seen_tokens_162816000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_318000-seen_tokens_162816000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_318000-seen_tokens_162816000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_318000-seen_tokens_162816000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:52:54 | step: 318100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.100152626866475e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 3.94 | consumed tokens: 162867200.0 | grad norm avg: 9.75 | grad norm last: 8.18 | 
2025-12-28T00:52:56 | step: 318200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.099013211904094e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.44 | consumed tokens: 162918400.0 | grad norm avg: 9.58 | grad norm last: 8.48 | 
2025-12-28T00:52:58 | step: 318300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.097874524537474e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.09 | consumed tokens: 162969600.0 | grad norm avg: 9.88 | grad norm last: 16.39 | 
2025-12-28T00:53:00 | step: 318400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.096734381979331e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.31 | consumed tokens: 163020800.0 | grad norm avg: 9.61 | grad norm last: 8.9 | 
2025-12-28T00:53:02 | step: 318500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.09559496701695e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.02 | consumed tokens: 163072000.0 | grad norm avg: 9.84 | grad norm last: 9.37 | 
2025-12-28T00:53:04 | step: 318600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.094454824458808e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 5.0 | consumed tokens: 163123200.0 | grad norm avg: 9.89 | grad norm last: 11.72 | 
2025-12-28T00:53:07 | step: 318700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.093313954304904e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.16 | consumed tokens: 163174400.0 | grad norm avg: 10.29 | grad norm last: 9.79 | 
2025-12-28T00:53:09 | step: 318800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.092173811746761e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.64 | consumed tokens: 163225600.0 | grad norm avg: 9.67 | grad norm last: 9.47 | 
2025-12-28T00:53:11 | step: 318900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 8.091032941592857e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.06 | consumed tokens: 163276800.0 | grad norm avg: 9.73 | grad norm last: 10.39 | 
2025-12-28T00:53:13 | step: 319000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 8.089891343843192e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.52 | consumed tokens: 163328000.0 | grad norm avg: 9.38 | grad norm last: 8.04 | 
2025-12-28T00:53:15 | step: 319100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.088750473689288e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.94 | consumed tokens: 163379200.0 | grad norm avg: 9.72 | grad norm last: 8.46 | 
2025-12-28T00:53:17 | step: 319200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.087608875939623e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.61 | consumed tokens: 163430400.0 | grad norm avg: 9.73 | grad norm last: 9.99 | 
2025-12-28T00:53:19 | step: 319300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.086466550594196e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.2 | consumed tokens: 163481600.0 | grad norm avg: 10.01 | grad norm last: 7.53 | 
2025-12-28T00:53:21 | step: 319400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.08532495284453e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 2.52 | consumed tokens: 163532800.0 | grad norm avg: 9.73 | grad norm last: 8.77 | 
2025-12-28T00:53:23 | step: 319500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.084182627499104e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.19 | consumed tokens: 163584000.0 | grad norm avg: 9.7 | grad norm last: 11.34 | 
2025-12-28T00:53:25 | step: 319600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.083039574557915e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.88 | consumed tokens: 163635200.0 | grad norm avg: 10.33 | grad norm last: 11.16 | 
2025-12-28T00:53:27 | step: 319700 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 8.081897249212489e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.73 | consumed tokens: 163686400.0 | grad norm avg: 9.58 | grad norm last: 8.38 | 
2025-12-28T00:53:29 | step: 319800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 8.0807541962713e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.42 | consumed tokens: 163737600.0 | grad norm avg: 10.05 | grad norm last: 8.57 | 
2025-12-28T00:53:31 | step: 319900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.079610415734351e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.0 | consumed tokens: 163788800.0 | grad norm avg: 9.35 | grad norm last: 6.75 | 
2025-12-28T00:53:33 | step: 320000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.078466635197401e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.17 | consumed tokens: 163840000.0 | grad norm avg: 9.98 | grad norm last: 7.91 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_320000-seen_tokens_163840000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_320000-seen_tokens_163840000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_320000-seen_tokens_163840000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_320000-seen_tokens_163840000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_320000-seen_tokens_163840000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_320000-seen_tokens_163840000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_320000-seen_tokens_163840000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_320000-seen_tokens_163840000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:53:35 | step: 320100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.077322854660451e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.75 | train loss last: 4.69 | consumed tokens: 163891200.0 | grad norm avg: 9.49 | grad norm last: 9.59 | 
2025-12-28T00:53:37 | step: 320200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.076179074123502e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.28 | consumed tokens: 163942400.0 | grad norm avg: 9.72 | grad norm last: 7.69 | 
2025-12-28T00:53:39 | step: 320300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.075034565990791e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.36 | consumed tokens: 163993600.0 | grad norm avg: 9.74 | grad norm last: 8.24 | 
2025-12-28T00:53:41 | step: 320400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.07389005785808e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.78 | consumed tokens: 164044800.0 | grad norm avg: 10.04 | grad norm last: 21.96 | 
2025-12-28T00:53:43 | step: 320500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.072745549725369e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.69 | consumed tokens: 164096000.0 | grad norm avg: 9.72 | grad norm last: 7.86 | 
2025-12-28T00:53:45 | step: 320600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.071600313996896e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.05 | consumed tokens: 164147200.0 | grad norm avg: 10.22 | grad norm last: 9.2 | 
2025-12-28T00:53:47 | step: 320700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.070455078268424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.03 | consumed tokens: 164198400.0 | grad norm avg: 10.1 | grad norm last: 12.38 | 
2025-12-28T00:53:49 | step: 320800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.06930911494419e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.16 | consumed tokens: 164249600.0 | grad norm avg: 9.83 | grad norm last: 18.82 | 
2025-12-28T00:53:51 | step: 320900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.068163151619956e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.31 | consumed tokens: 164300800.0 | grad norm avg: 9.93 | grad norm last: 10.3 | 
2025-12-28T00:53:53 | step: 321000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.067017188295722e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.06 | consumed tokens: 164352000.0 | grad norm avg: 11.03 | grad norm last: 9.04 | 
2025-12-28T00:53:55 | step: 321100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.065871224971488e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.78 | consumed tokens: 164403200.0 | grad norm avg: 10.1 | grad norm last: 12.85 | 
2025-12-28T00:53:57 | step: 321200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.064724534051493e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.75 | consumed tokens: 164454400.0 | grad norm avg: 10.07 | grad norm last: 10.55 | 
2025-12-28T00:53:59 | step: 321300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.063577843131498e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.12 | consumed tokens: 164505600.0 | grad norm avg: 10.17 | grad norm last: 8.06 | 
2025-12-28T00:54:01 | step: 321400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.062430424615741e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.22 | consumed tokens: 164556800.0 | grad norm avg: 9.85 | grad norm last: 9.68 | 
2025-12-28T00:54:03 | step: 321500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 8.061283006099984e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.52 | consumed tokens: 164608000.0 | grad norm avg: 9.8 | grad norm last: 8.05 | 
2025-12-28T00:54:06 | step: 321600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.060135587584227e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.22 | consumed tokens: 164659200.0 | grad norm avg: 10.0 | grad norm last: 8.37 | 
2025-12-28T00:54:08 | step: 321700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.05898816906847e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.19 | consumed tokens: 164710400.0 | grad norm avg: 10.26 | grad norm last: 10.51 | 
2025-12-28T00:54:10 | step: 321800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.057840022956952e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.41 | consumed tokens: 164761600.0 | grad norm avg: 10.02 | grad norm last: 7.89 | 
2025-12-28T00:54:12 | step: 321900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.056691876845434e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.78 | consumed tokens: 164812800.0 | grad norm avg: 10.47 | grad norm last: 7.64 | 
2025-12-28T00:54:14 | step: 322000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.055543003138155e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.41 | consumed tokens: 164864000.0 | grad norm avg: 10.06 | grad norm last: 8.27 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_322000-seen_tokens_164864000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_322000-seen_tokens_164864000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_322000-seen_tokens_164864000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_322000-seen_tokens_164864000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_322000-seen_tokens_164864000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_322000-seen_tokens_164864000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_322000-seen_tokens_164864000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_322000-seen_tokens_164864000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:54:16 | step: 322100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.054394129430875e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.77 | train loss last: 4.09 | consumed tokens: 164915200.0 | grad norm avg: 9.5 | grad norm last: 10.69 | 
2025-12-28T00:54:18 | step: 322200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.053245255723596e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.16 | consumed tokens: 164966400.0 | grad norm avg: 9.98 | grad norm last: 10.78 | 
2025-12-28T00:54:20 | step: 322300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.052096382016316e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.86 | consumed tokens: 165017600.0 | grad norm avg: 9.61 | grad norm last: 8.39 | 
2025-12-28T00:54:22 | step: 322400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.050946780713275e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.92 | consumed tokens: 165068800.0 | grad norm avg: 10.24 | grad norm last: 12.69 | 
2025-12-28T00:54:24 | step: 322500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.049796451814473e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.7 | consumed tokens: 165120000.0 | grad norm avg: 9.93 | grad norm last: 7.6 | 
2025-12-28T00:54:26 | step: 322600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.048646850511432e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.91 | consumed tokens: 165171200.0 | grad norm avg: 9.9 | grad norm last: 8.78 | 
2025-12-28T00:54:28 | step: 322700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.047496521612629e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.47 | consumed tokens: 165222400.0 | grad norm avg: 10.26 | grad norm last: 10.04 | 
2025-12-28T00:54:30 | step: 322800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.046346192713827e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.5 | consumed tokens: 165273600.0 | grad norm avg: 9.82 | grad norm last: 8.69 | 
2025-12-28T00:54:32 | step: 322900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.045195136219263e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.61 | consumed tokens: 165324800.0 | grad norm avg: 9.47 | grad norm last: 9.54 | 
2025-12-28T00:54:34 | step: 323000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.044044079724699e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.25 | consumed tokens: 165376000.0 | grad norm avg: 10.05 | grad norm last: 7.82 | 
2025-12-28T00:54:36 | step: 323100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.042893023230135e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.69 | consumed tokens: 165427200.0 | grad norm avg: 9.96 | grad norm last: 8.29 | 
2025-12-28T00:54:38 | step: 323200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.04174123913981e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.45 | consumed tokens: 165478400.0 | grad norm avg: 10.21 | grad norm last: 8.6 | 
2025-12-28T00:54:40 | step: 323300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.040590182645246e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.09 | consumed tokens: 165529600.0 | grad norm avg: 9.55 | grad norm last: 8.56 | 
2025-12-28T00:54:42 | step: 323400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.03943767095916e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.28 | consumed tokens: 165580800.0 | grad norm avg: 9.31 | grad norm last: 8.41 | 
2025-12-28T00:54:44 | step: 323500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.038285886868834e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.5 | consumed tokens: 165632000.0 | grad norm avg: 10.04 | grad norm last: 7.33 | 
2025-12-28T00:54:46 | step: 323600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.037133375182748e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.31 | consumed tokens: 165683200.0 | grad norm avg: 9.68 | grad norm last: 7.1 | 
2025-12-28T00:54:48 | step: 323700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.035980863496661e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.88 | consumed tokens: 165734400.0 | grad norm avg: 9.86 | grad norm last: 10.67 | 
2025-12-28T00:54:50 | step: 323800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.034827624214813e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.12 | consumed tokens: 165785600.0 | grad norm avg: 9.73 | grad norm last: 10.55 | 
2025-12-28T00:54:52 | step: 323900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 8.033674384932965e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.89 | consumed tokens: 165836800.0 | grad norm avg: 9.89 | grad norm last: 9.88 | 
2025-12-28T00:54:54 | step: 324000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 8.032521145651117e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.69 | consumed tokens: 165888000.0 | grad norm avg: 9.7 | grad norm last: 9.58 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_324000-seen_tokens_165888000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_324000-seen_tokens_165888000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_324000-seen_tokens_165888000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_324000-seen_tokens_165888000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_324000-seen_tokens_165888000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_324000-seen_tokens_165888000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_324000-seen_tokens_165888000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_324000-seen_tokens_165888000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:54:57 | step: 324100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.031367178773507e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.83 | train loss last: 4.81 | consumed tokens: 165939200.0 | grad norm avg: 9.96 | grad norm last: 22.82 | 
2025-12-28T00:54:59 | step: 324200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 8.030213211895898e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.84 | train loss last: 4.03 | consumed tokens: 165990400.0 | grad norm avg: 10.0 | grad norm last: 8.33 | 
2025-12-28T00:55:01 | step: 324300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 8.029059245018288e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.42 | consumed tokens: 166041600.0 | grad norm avg: 9.91 | grad norm last: 9.38 | 
2025-12-28T00:55:03 | step: 324400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.027904550544918e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.09 | consumed tokens: 166092800.0 | grad norm avg: 9.84 | grad norm last: 11.09 | 
2025-12-28T00:55:05 | step: 324500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.026750583667308e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.5 | consumed tokens: 166144000.0 | grad norm avg: 10.22 | grad norm last: 8.76 | 
2025-12-28T00:55:07 | step: 324600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.025595161598176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.31 | consumed tokens: 166195200.0 | grad norm avg: 10.25 | grad norm last: 8.49 | 
2025-12-28T00:55:09 | step: 324700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.024440467124805e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.34 | consumed tokens: 166246400.0 | grad norm avg: 9.77 | grad norm last: 9.03 | 
2025-12-28T00:55:11 | step: 324800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.023285045055673e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 5.59 | consumed tokens: 166297600.0 | grad norm avg: 10.48 | grad norm last: 40.46 | 
2025-12-28T00:55:13 | step: 324900 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 8.022128895390779e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.42 | consumed tokens: 166348800.0 | grad norm avg: 10.37 | grad norm last: 8.37 | 
2025-12-28T00:55:15 | step: 325000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 8.020973473321646e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.19 | consumed tokens: 166400000.0 | grad norm avg: 10.71 | grad norm last: 9.58 | 
2025-12-28T00:55:17 | step: 325100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.019817323656753e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.94 | consumed tokens: 166451200.0 | grad norm avg: 10.04 | grad norm last: 9.99 | 
2025-12-28T00:55:19 | step: 325200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.018661173991859e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.98 | consumed tokens: 166502400.0 | grad norm avg: 9.83 | grad norm last: 9.85 | 
2025-12-28T00:55:21 | step: 325300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.017504296731204e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.06 | consumed tokens: 166553600.0 | grad norm avg: 9.7 | grad norm last: 8.75 | 
2025-12-28T00:55:23 | step: 325400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.016347419470549e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.83 | consumed tokens: 166604800.0 | grad norm avg: 9.87 | grad norm last: 7.4 | 
2025-12-28T00:55:25 | step: 325500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.015190542209893e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.61 | consumed tokens: 166656000.0 | grad norm avg: 10.12 | grad norm last: 10.3 | 
2025-12-28T00:55:27 | step: 325600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.014032937353477e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.08 | consumed tokens: 166707200.0 | grad norm avg: 9.69 | grad norm last: 7.79 | 
2025-12-28T00:55:29 | step: 325700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.01287533249706e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.66 | consumed tokens: 166758400.0 | grad norm avg: 9.52 | grad norm last: 8.27 | 
2025-12-28T00:55:31 | step: 325800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 8.011717727640644e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.22 | consumed tokens: 166809600.0 | grad norm avg: 10.04 | grad norm last: 12.3 | 
2025-12-28T00:55:33 | step: 325900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.010559395188466e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.38 | consumed tokens: 166860800.0 | grad norm avg: 9.65 | grad norm last: 9.63 | 
2025-12-28T00:55:35 | step: 326000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 8.009401790332049e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.56 | consumed tokens: 166912000.0 | grad norm avg: 9.62 | grad norm last: 12.76 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_326000-seen_tokens_166912000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_326000-seen_tokens_166912000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_326000-seen_tokens_166912000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_326000-seen_tokens_166912000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_326000-seen_tokens_166912000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_326000-seen_tokens_166912000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_326000-seen_tokens_166912000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_326000-seen_tokens_166912000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:55:37 | step: 326100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 8.00824273028411e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.81 | train loss last: 3.28 | consumed tokens: 166963200.0 | grad norm avg: 9.69 | grad norm last: 7.22 | 
2025-12-28T00:55:39 | step: 326200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 8.007084397831932e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.48 | consumed tokens: 167014400.0 | grad norm avg: 9.69 | grad norm last: 8.65 | 
2025-12-28T00:55:41 | step: 326300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 8.005925337783992e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.12 | consumed tokens: 167065600.0 | grad norm avg: 10.42 | grad norm last: 10.31 | 
2025-12-28T00:55:43 | step: 326400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.004766277736053e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.75 | consumed tokens: 167116800.0 | grad norm avg: 9.7 | grad norm last: 8.25 | 
2025-12-28T00:55:45 | step: 326500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 8.003606490092352e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.48 | consumed tokens: 167168000.0 | grad norm avg: 9.87 | grad norm last: 8.75 | 
2025-12-28T00:55:47 | step: 326600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.002446702448651e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.89 | consumed tokens: 167219200.0 | grad norm avg: 9.36 | grad norm last: 10.8 | 
2025-12-28T00:55:49 | step: 326700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 8.00128691480495e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.62 | consumed tokens: 167270400.0 | grad norm avg: 9.89 | grad norm last: 14.99 | 
2025-12-28T00:55:51 | step: 326800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 8.000126399565488e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 2.91 | consumed tokens: 167321600.0 | grad norm avg: 9.3 | grad norm last: 8.32 | 
2025-12-28T00:55:54 | step: 326900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.998965884326026e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.97 | consumed tokens: 167372800.0 | grad norm avg: 10.07 | grad norm last: 10.01 | 
2025-12-28T00:55:56 | step: 327000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.997805369086564e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.48 | consumed tokens: 167424000.0 | grad norm avg: 9.91 | grad norm last: 10.07 | 
2025-12-28T00:55:58 | step: 327100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.996644853847101e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.36 | consumed tokens: 167475200.0 | grad norm avg: 9.76 | grad norm last: 7.66 | 
2025-12-28T00:56:00 | step: 327200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.995483611011878e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.44 | consumed tokens: 167526400.0 | grad norm avg: 9.79 | grad norm last: 12.75 | 
2025-12-28T00:56:02 | step: 327300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.994321640580893e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.28 | consumed tokens: 167577600.0 | grad norm avg: 9.28 | grad norm last: 10.46 | 
2025-12-28T00:56:04 | step: 327400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.993160397745669e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.48 | consumed tokens: 167628800.0 | grad norm avg: 9.71 | grad norm last: 9.81 | 
2025-12-28T00:56:06 | step: 327500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.991998427314684e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 2.97 | consumed tokens: 167680000.0 | grad norm avg: 9.89 | grad norm last: 8.73 | 
2025-12-28T00:56:08 | step: 327600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.990836456883699e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.59 | consumed tokens: 167731200.0 | grad norm avg: 9.66 | grad norm last: 9.17 | 
2025-12-28T00:56:10 | step: 327700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.989673758856952e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.58 | consumed tokens: 167782400.0 | grad norm avg: 9.46 | grad norm last: 9.99 | 
2025-12-28T00:56:12 | step: 327800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.988511060830206e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.23 | consumed tokens: 167833600.0 | grad norm avg: 9.95 | grad norm last: 8.06 | 
2025-12-28T00:56:14 | step: 327900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.987348362803459e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.0 | consumed tokens: 167884800.0 | grad norm avg: 9.88 | grad norm last: 13.29 | 
2025-12-28T00:56:16 | step: 328000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.986185664776713e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.34 | consumed tokens: 167936000.0 | grad norm avg: 9.44 | grad norm last: 13.21 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_328000-seen_tokens_167936000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_328000-seen_tokens_167936000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_328000-seen_tokens_167936000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_328000-seen_tokens_167936000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_328000-seen_tokens_167936000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_328000-seen_tokens_167936000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_328000-seen_tokens_167936000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_328000-seen_tokens_167936000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:56:18 | step: 328100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.985022239154205e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.88 | consumed tokens: 167987200.0 | grad norm avg: 9.59 | grad norm last: 12.87 | 
2025-12-28T00:56:20 | step: 328200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.983858813531697e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.06 | consumed tokens: 168038400.0 | grad norm avg: 9.28 | grad norm last: 8.54 | 
2025-12-28T00:56:22 | step: 328300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.982694660313427e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.03 | consumed tokens: 168089600.0 | grad norm avg: 10.33 | grad norm last: 7.81 | 
2025-12-28T00:56:24 | step: 328400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.981530507095158e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.62 | consumed tokens: 168140800.0 | grad norm avg: 9.56 | grad norm last: 9.79 | 
2025-12-28T00:56:26 | step: 328500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.980366353876889e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.55 | consumed tokens: 168192000.0 | grad norm avg: 9.52 | grad norm last: 8.44 | 
2025-12-28T00:56:28 | step: 328600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.97920220065862e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.38 | consumed tokens: 168243200.0 | grad norm avg: 9.64 | grad norm last: 12.11 | 
2025-12-28T00:56:30 | step: 328700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.978037319844589e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.16 | consumed tokens: 168294400.0 | grad norm avg: 9.8 | grad norm last: 9.11 | 
2025-12-28T00:56:32 | step: 328800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.976872439030558e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.25 | consumed tokens: 168345600.0 | grad norm avg: 9.46 | grad norm last: 8.27 | 
2025-12-28T00:56:34 | step: 328900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.975706830620766e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.05 | consumed tokens: 168396800.0 | grad norm avg: 9.24 | grad norm last: 9.79 | 
2025-12-28T00:56:36 | step: 329000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.974541222210974e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.59 | consumed tokens: 168448000.0 | grad norm avg: 9.39 | grad norm last: 8.76 | 
2025-12-28T00:56:38 | step: 329100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.973375613801181e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.0 | consumed tokens: 168499200.0 | grad norm avg: 9.91 | grad norm last: 12.59 | 
2025-12-28T00:56:40 | step: 329200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 7.972210005391389e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.59 | consumed tokens: 168550400.0 | grad norm avg: 9.55 | grad norm last: 9.41 | 
2025-12-28T00:56:42 | step: 329300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 7.971043669385836e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.61 | consumed tokens: 168601600.0 | grad norm avg: 9.48 | grad norm last: 8.97 | 
2025-12-28T00:56:44 | step: 329400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 7.969877333380282e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.72 | consumed tokens: 168652800.0 | grad norm avg: 10.51 | grad norm last: 12.37 | 
2025-12-28T00:56:46 | step: 329500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.968710269778967e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.89 | consumed tokens: 168704000.0 | grad norm avg: 9.85 | grad norm last: 8.95 | 
2025-12-28T00:56:48 | step: 329600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.967543933773413e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.47 | consumed tokens: 168755200.0 | grad norm avg: 9.92 | grad norm last: 8.94 | 
2025-12-28T00:56:50 | step: 329700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.966376870172098e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.03 | consumed tokens: 168806400.0 | grad norm avg: 9.56 | grad norm last: 10.22 | 
2025-12-28T00:56:52 | step: 329800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.965209078975022e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.0 | consumed tokens: 168857600.0 | grad norm avg: 10.01 | grad norm last: 10.7 | 
2025-12-28T00:56:54 | step: 329900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 7.964041287777945e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.94 | consumed tokens: 168908800.0 | grad norm avg: 9.62 | grad norm last: 14.15 | 
2025-12-28T00:56:57 | step: 330000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 7.962873496580869e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.12 | consumed tokens: 168960000.0 | grad norm avg: 9.52 | grad norm last: 10.45 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_330000-seen_tokens_168960000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_330000-seen_tokens_168960000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_330000-seen_tokens_168960000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_330000-seen_tokens_168960000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_330000-seen_tokens_168960000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_330000-seen_tokens_168960000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_330000-seen_tokens_168960000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_330000-seen_tokens_168960000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:56:59 | step: 330100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 7.961705705383793e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 5.12 | consumed tokens: 169011200.0 | grad norm avg: 9.79 | grad norm last: 16.33 | 
2025-12-28T00:57:01 | step: 330200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.960537186590955e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 5.53 | consumed tokens: 169062400.0 | grad norm avg: 9.64 | grad norm last: 14.62 | 
2025-12-28T00:57:03 | step: 330300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 7.959368667798117e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 2.86 | consumed tokens: 169113600.0 | grad norm avg: 9.64 | grad norm last: 6.91 | 
2025-12-28T00:57:05 | step: 330400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.958200149005279e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.58 | consumed tokens: 169164800.0 | grad norm avg: 9.49 | grad norm last: 7.42 | 
2025-12-28T00:57:07 | step: 330500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.95703090261668e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.28 | consumed tokens: 169216000.0 | grad norm avg: 9.49 | grad norm last: 6.94 | 
2025-12-28T00:57:09 | step: 330600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.95586165622808e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 5.97 | consumed tokens: 169267200.0 | grad norm avg: 9.31 | grad norm last: 17.9 | 
2025-12-28T00:57:11 | step: 330700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.954692409839481e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.36 | consumed tokens: 169318400.0 | grad norm avg: 9.73 | grad norm last: 7.47 | 
2025-12-28T00:57:13 | step: 330800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.95352243585512e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.03 | consumed tokens: 169369600.0 | grad norm avg: 9.87 | grad norm last: 11.45 | 
2025-12-28T00:57:15 | step: 330900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 7.95235246187076e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.31 | consumed tokens: 169420800.0 | grad norm avg: 9.45 | grad norm last: 7.78 | 
2025-12-28T00:57:17 | step: 331000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 7.951182487886399e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.45 | consumed tokens: 169472000.0 | grad norm avg: 9.68 | grad norm last: 10.6 | 
2025-12-28T00:57:19 | step: 331100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.950011786306277e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.12 | consumed tokens: 169523200.0 | grad norm avg: 10.45 | grad norm last: 13.15 | 
2025-12-28T00:57:21 | step: 331200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.948841084726155e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.34 | consumed tokens: 169574400.0 | grad norm avg: 9.89 | grad norm last: 8.55 | 
2025-12-28T00:57:23 | step: 331300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 7.947670383146033e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.89 | consumed tokens: 169625600.0 | grad norm avg: 10.33 | grad norm last: 13.59 | 
2025-12-28T00:57:25 | step: 331400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.946498953970149e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.94 | consumed tokens: 169676800.0 | grad norm avg: 9.44 | grad norm last: 9.44 | 
2025-12-28T00:57:27 | step: 331500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.945327524794266e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.91 | consumed tokens: 169728000.0 | grad norm avg: 9.38 | grad norm last: 11.7 | 
2025-12-28T00:57:29 | step: 331600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.944156095618382e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.66 | consumed tokens: 169779200.0 | grad norm avg: 9.71 | grad norm last: 9.37 | 
2025-12-28T00:57:31 | step: 331700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.942983938846737e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.06 | consumed tokens: 169830400.0 | grad norm avg: 9.66 | grad norm last: 12.18 | 
2025-12-28T00:57:33 | step: 331800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.941811782075092e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 2.78 | consumed tokens: 169881600.0 | grad norm avg: 9.67 | grad norm last: 7.3 | 
2025-12-28T00:57:35 | step: 331900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.940639625303447e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 5.12 | consumed tokens: 169932800.0 | grad norm avg: 9.71 | grad norm last: 20.48 | 
2025-12-28T00:57:37 | step: 332000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.939467468531802e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.66 | consumed tokens: 169984000.0 | grad norm avg: 9.56 | grad norm last: 9.03 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_332000-seen_tokens_169984000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_332000-seen_tokens_169984000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_332000-seen_tokens_169984000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_332000-seen_tokens_169984000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_332000-seen_tokens_169984000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_332000-seen_tokens_169984000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_332000-seen_tokens_169984000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_332000-seen_tokens_169984000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:57:40 | step: 332100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.938294584164396e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.75 | train loss last: 3.84 | consumed tokens: 170035200.0 | grad norm avg: 9.97 | grad norm last: 7.8 | 
2025-12-28T00:57:42 | step: 332200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 7.93712169979699e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.06 | consumed tokens: 170086400.0 | grad norm avg: 9.88 | grad norm last: 8.73 | 
2025-12-28T00:57:44 | step: 332300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.935948087833822e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.06 | consumed tokens: 170137600.0 | grad norm avg: 9.99 | grad norm last: 8.68 | 
2025-12-28T00:57:46 | step: 332400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.934774475870654e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.31 | consumed tokens: 170188800.0 | grad norm avg: 9.5 | grad norm last: 9.1 | 
2025-12-28T00:57:48 | step: 332500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.933600863907486e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 5.25 | consumed tokens: 170240000.0 | grad norm avg: 10.13 | grad norm last: 25.99 | 
2025-12-28T00:57:50 | step: 332600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.932427251944318e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.64 | consumed tokens: 170291200.0 | grad norm avg: 9.63 | grad norm last: 9.54 | 
2025-12-28T00:57:52 | step: 332700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.931252912385389e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.69 | consumed tokens: 170342400.0 | grad norm avg: 9.59 | grad norm last: 9.98 | 
2025-12-28T00:57:54 | step: 332800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.93007857282646e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 2.92 | consumed tokens: 170393600.0 | grad norm avg: 9.6 | grad norm last: 7.0 | 
2025-12-28T00:57:56 | step: 332900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.92890350567177e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.8 | consumed tokens: 170444800.0 | grad norm avg: 9.88 | grad norm last: 14.6 | 
2025-12-28T00:57:58 | step: 333000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.927728438517079e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.89 | consumed tokens: 170496000.0 | grad norm avg: 9.55 | grad norm last: 8.03 | 
2025-12-28T00:58:00 | step: 333100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.926553371362388e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.59 | consumed tokens: 170547200.0 | grad norm avg: 9.39 | grad norm last: 12.84 | 
2025-12-28T00:58:02 | step: 333200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.925378304207698e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.73 | consumed tokens: 170598400.0 | grad norm avg: 10.26 | grad norm last: 9.96 | 
2025-12-28T00:58:04 | step: 333300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.924202509457245e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.22 | consumed tokens: 170649600.0 | grad norm avg: 9.41 | grad norm last: 7.75 | 
2025-12-28T00:58:06 | step: 333400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.923026714706793e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.23 | consumed tokens: 170700800.0 | grad norm avg: 9.82 | grad norm last: 9.21 | 
2025-12-28T00:58:08 | step: 333500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.921850919956341e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.69 | consumed tokens: 170752000.0 | grad norm avg: 9.64 | grad norm last: 9.12 | 
2025-12-28T00:58:10 | step: 333600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.920674397610128e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.34 | consumed tokens: 170803200.0 | grad norm avg: 9.67 | grad norm last: 10.13 | 
2025-12-28T00:58:12 | step: 333700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.919497875263914e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 2.97 | consumed tokens: 170854400.0 | grad norm avg: 10.11 | grad norm last: 12.41 | 
2025-12-28T00:58:14 | step: 333800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.918321352917701e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.22 | consumed tokens: 170905600.0 | grad norm avg: 9.35 | grad norm last: 11.28 | 
2025-12-28T00:58:16 | step: 333900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.917144102975726e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.06 | consumed tokens: 170956800.0 | grad norm avg: 9.38 | grad norm last: 12.03 | 
2025-12-28T00:58:18 | step: 334000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.915966853033751e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.53 | consumed tokens: 171008000.0 | grad norm avg: 9.81 | grad norm last: 10.54 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_334000-seen_tokens_171008000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_334000-seen_tokens_171008000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_334000-seen_tokens_171008000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_334000-seen_tokens_171008000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_334000-seen_tokens_171008000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_334000-seen_tokens_171008000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_334000-seen_tokens_171008000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_334000-seen_tokens_171008000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:58:20 | step: 334100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.914789603091776e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.85 | train loss last: 4.28 | consumed tokens: 171059200.0 | grad norm avg: 10.42 | grad norm last: 9.5 | 
2025-12-28T00:58:22 | step: 334200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.91361162555404e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.77 | train loss last: 4.0 | consumed tokens: 171110400.0 | grad norm avg: 9.6 | grad norm last: 10.57 | 
2025-12-28T00:58:24 | step: 334300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.912433648016304e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.0 | consumed tokens: 171161600.0 | grad norm avg: 9.35 | grad norm last: 7.96 | 
2025-12-28T00:58:26 | step: 334400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.911255670478567e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.91 | consumed tokens: 171212800.0 | grad norm avg: 9.63 | grad norm last: 8.11 | 
2025-12-28T00:58:28 | step: 334500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.91007696534507e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.7 | consumed tokens: 171264000.0 | grad norm avg: 9.83 | grad norm last: 8.93 | 
2025-12-28T00:58:30 | step: 334600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.908898987807333e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.08 | consumed tokens: 171315200.0 | grad norm avg: 9.33 | grad norm last: 7.06 | 
2025-12-28T00:58:32 | step: 334700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 7.907719555078074e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.47 | consumed tokens: 171366400.0 | grad norm avg: 9.78 | grad norm last: 9.93 | 
2025-12-28T00:58:34 | step: 334800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 7.906540849944577e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 5.62 | consumed tokens: 171417600.0 | grad norm avg: 9.66 | grad norm last: 8.66 | 
2025-12-28T00:58:37 | step: 334900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 7.905361417215317e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.59 | consumed tokens: 171468800.0 | grad norm avg: 9.33 | grad norm last: 12.44 | 
2025-12-28T00:58:39 | step: 335000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.904181984486058e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.95 | consumed tokens: 171520000.0 | grad norm avg: 9.95 | grad norm last: 9.72 | 
2025-12-28T00:58:41 | step: 335100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.903001824161038e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.98 | consumed tokens: 171571200.0 | grad norm avg: 9.85 | grad norm last: 8.97 | 
2025-12-28T00:58:43 | step: 335200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.901822391431779e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.06 | consumed tokens: 171622400.0 | grad norm avg: 8.98 | grad norm last: 9.35 | 
2025-12-28T00:58:45 | step: 335300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.900642231106758e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.72 | consumed tokens: 171673600.0 | grad norm avg: 9.81 | grad norm last: 7.65 | 
2025-12-28T00:58:47 | step: 335400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.899461343185976e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.75 | consumed tokens: 171724800.0 | grad norm avg: 9.62 | grad norm last: 9.66 | 
2025-12-28T00:58:49 | step: 335500 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 7.898280455265194e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.91 | consumed tokens: 171776000.0 | grad norm avg: 9.3 | grad norm last: 8.1 | 
2025-12-28T00:58:51 | step: 335600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 7.897099567344412e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.94 | consumed tokens: 171827200.0 | grad norm avg: 9.35 | grad norm last: 11.08 | 
2025-12-28T00:58:53 | step: 335700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 7.89591867942363e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.98 | consumed tokens: 171878400.0 | grad norm avg: 9.87 | grad norm last: 10.27 | 
2025-12-28T00:58:55 | step: 335800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.894737063907087e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 2.95 | consumed tokens: 171929600.0 | grad norm avg: 9.56 | grad norm last: 7.76 | 
2025-12-28T00:58:57 | step: 335900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.893555448390543e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.58 | consumed tokens: 171980800.0 | grad norm avg: 9.48 | grad norm last: 9.74 | 
2025-12-28T00:58:59 | step: 336000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.892373832874e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.25 | consumed tokens: 172032000.0 | grad norm avg: 9.19 | grad norm last: 8.78 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_336000-seen_tokens_172032000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_336000-seen_tokens_172032000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_336000-seen_tokens_172032000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_336000-seen_tokens_172032000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_336000-seen_tokens_172032000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_336000-seen_tokens_172032000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_336000-seen_tokens_172032000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_336000-seen_tokens_172032000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:59:01 | step: 336100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.891191489761695e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.74 | train loss last: 2.62 | consumed tokens: 172083200.0 | grad norm avg: 9.12 | grad norm last: 6.73 | 
2025-12-28T00:59:03 | step: 336200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.89000914664939e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.52 | consumed tokens: 172134400.0 | grad norm avg: 9.56 | grad norm last: 9.55 | 
2025-12-28T00:59:05 | step: 336300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 7.888826803537086e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.11 | consumed tokens: 172185600.0 | grad norm avg: 9.35 | grad norm last: 7.54 | 
2025-12-28T00:59:07 | step: 336400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 7.88764373282902e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.12 | consumed tokens: 172236800.0 | grad norm avg: 9.21 | grad norm last: 8.07 | 
2025-12-28T00:59:09 | step: 336500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.886460662120953e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.12 | consumed tokens: 172288000.0 | grad norm avg: 10.31 | grad norm last: 8.88 | 
2025-12-28T00:59:11 | step: 336600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.885277591412887e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.7 | consumed tokens: 172339200.0 | grad norm avg: 9.15 | grad norm last: 9.02 | 
2025-12-28T00:59:13 | step: 336700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.884094520704821e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.09 | consumed tokens: 172390400.0 | grad norm avg: 9.02 | grad norm last: 7.77 | 
2025-12-28T00:59:15 | step: 336800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.882910722400993e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.36 | consumed tokens: 172441600.0 | grad norm avg: 9.7 | grad norm last: 8.5 | 
2025-12-28T00:59:17 | step: 336900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.881726924097165e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.23 | consumed tokens: 172492800.0 | grad norm avg: 8.86 | grad norm last: 7.28 | 
2025-12-28T00:59:19 | step: 337000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.880542398197576e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.81 | consumed tokens: 172544000.0 | grad norm avg: 9.22 | grad norm last: 7.64 | 
2025-12-28T00:59:21 | step: 337100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.879357872297987e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.09 | consumed tokens: 172595200.0 | grad norm avg: 9.26 | grad norm last: 8.14 | 
2025-12-28T00:59:23 | step: 337200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.878173346398398e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.48 | consumed tokens: 172646400.0 | grad norm avg: 9.55 | grad norm last: 8.37 | 
2025-12-28T00:59:25 | step: 337300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.876988820498809e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.58 | consumed tokens: 172697600.0 | grad norm avg: 9.66 | grad norm last: 11.55 | 
2025-12-28T00:59:27 | step: 337400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.875803567003459e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.0 | consumed tokens: 172748800.0 | grad norm avg: 9.45 | grad norm last: 10.27 | 
2025-12-28T00:59:29 | step: 337500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.874618313508108e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.03 | consumed tokens: 172800000.0 | grad norm avg: 9.21 | grad norm last: 8.98 | 
2025-12-28T00:59:31 | step: 337600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.873433060012758e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.16 | consumed tokens: 172851200.0 | grad norm avg: 9.81 | grad norm last: 9.45 | 
2025-12-28T00:59:33 | step: 337700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.872247078921646e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.45 | consumed tokens: 172902400.0 | grad norm avg: 9.26 | grad norm last: 7.41 | 
2025-12-28T00:59:35 | step: 337800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 7.871061097830534e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.38 | consumed tokens: 172953600.0 | grad norm avg: 9.02 | grad norm last: 7.83 | 
2025-12-28T00:59:37 | step: 337900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.869875116739422e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.92 | consumed tokens: 173004800.0 | grad norm avg: 9.45 | grad norm last: 10.12 | 
2025-12-28T00:59:39 | step: 338000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.868688408052549e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.45 | consumed tokens: 173056000.0 | grad norm avg: 9.62 | grad norm last: 7.01 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_338000-seen_tokens_173056000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_338000-seen_tokens_173056000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_338000-seen_tokens_173056000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_338000-seen_tokens_173056000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_338000-seen_tokens_173056000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_338000-seen_tokens_173056000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_338000-seen_tokens_173056000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_338000-seen_tokens_173056000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T00:59:42 | step: 338100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.867501699365675e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.27 | consumed tokens: 173107200.0 | grad norm avg: 9.26 | grad norm last: 8.98 | 
2025-12-28T00:59:44 | step: 338200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.866314990678802e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.25 | consumed tokens: 173158400.0 | grad norm avg: 9.61 | grad norm last: 7.37 | 
2025-12-28T00:59:46 | step: 338300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.865127554396167e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.61 | consumed tokens: 173209600.0 | grad norm avg: 8.96 | grad norm last: 8.88 | 
2025-12-28T00:59:48 | step: 338400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.863940118113533e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.53 | consumed tokens: 173260800.0 | grad norm avg: 9.07 | grad norm last: 7.95 | 
2025-12-28T00:59:50 | step: 338500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.862752681830898e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.94 | consumed tokens: 173312000.0 | grad norm avg: 9.28 | grad norm last: 8.86 | 
2025-12-28T00:59:52 | step: 338600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.861565245548263e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.88 | consumed tokens: 173363200.0 | grad norm avg: 8.77 | grad norm last: 8.55 | 
2025-12-28T00:59:54 | step: 338700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.860377081669867e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 2.78 | consumed tokens: 173414400.0 | grad norm avg: 9.14 | grad norm last: 7.49 | 
2025-12-28T00:59:56 | step: 338800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.859188917791471e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.95 | consumed tokens: 173465600.0 | grad norm avg: 8.98 | grad norm last: 8.38 | 
2025-12-28T00:59:58 | step: 338900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.858000026317313e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.97 | consumed tokens: 173516800.0 | grad norm avg: 8.72 | grad norm last: 8.63 | 
2025-12-28T01:00:00 | step: 339000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.856811862438917e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.5 | consumed tokens: 173568000.0 | grad norm avg: 9.16 | grad norm last: 9.29 | 
2025-12-28T01:00:02 | step: 339100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.85562297096476e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.78 | consumed tokens: 173619200.0 | grad norm avg: 9.14 | grad norm last: 13.38 | 
2025-12-28T01:00:04 | step: 339200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.85443335189484e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.89 | consumed tokens: 173670400.0 | grad norm avg: 9.33 | grad norm last: 8.07 | 
2025-12-28T01:00:06 | step: 339300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.853244460420683e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.8 | consumed tokens: 173721600.0 | grad norm avg: 9.28 | grad norm last: 8.83 | 
2025-12-28T01:00:08 | step: 339400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.852054841350764e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.89 | consumed tokens: 173772800.0 | grad norm avg: 9.32 | grad norm last: 8.07 | 
2025-12-28T01:00:10 | step: 339500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.850864494685084e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.16 | consumed tokens: 173824000.0 | grad norm avg: 9.11 | grad norm last: 12.15 | 
2025-12-28T01:00:12 | step: 339600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.849674875615165e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.56 | consumed tokens: 173875200.0 | grad norm avg: 9.29 | grad norm last: 7.85 | 
2025-12-28T01:00:14 | step: 339700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.848484528949484e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.48 | consumed tokens: 173926400.0 | grad norm avg: 9.06 | grad norm last: 8.73 | 
2025-12-28T01:00:16 | step: 339800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.847293454688042e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.8 | consumed tokens: 173977600.0 | grad norm avg: 9.27 | grad norm last: 9.63 | 
2025-12-28T01:00:18 | step: 339900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 7.846103108022362e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.73 | consumed tokens: 174028800.0 | grad norm avg: 9.31 | grad norm last: 8.74 | 
2025-12-28T01:00:20 | step: 340000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 7.84491203376092e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.27 | consumed tokens: 174080000.0 | grad norm avg: 9.76 | grad norm last: 10.23 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_340000-seen_tokens_174080000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_340000-seen_tokens_174080000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_340000-seen_tokens_174080000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_340000-seen_tokens_174080000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_340000-seen_tokens_174080000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_340000-seen_tokens_174080000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_340000-seen_tokens_174080000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_340000-seen_tokens_174080000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:00:22 | step: 340100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.843720959499478e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 3.53 | consumed tokens: 174131200.0 | grad norm avg: 8.78 | grad norm last: 8.07 | 
2025-12-28T01:00:25 | step: 340200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 7.842529157642275e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.17 | consumed tokens: 174182400.0 | grad norm avg: 9.11 | grad norm last: 6.89 | 
2025-12-28T01:00:27 | step: 340300 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 7.841338083380833e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.12 | consumed tokens: 174233600.0 | grad norm avg: 9.53 | grad norm last: 11.31 | 
2025-12-28T01:00:29 | step: 340400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 7.84014628152363e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.95 | consumed tokens: 174284800.0 | grad norm avg: 8.95 | grad norm last: 9.12 | 
2025-12-28T01:00:31 | step: 340500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.838953752070665e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.52 | consumed tokens: 174336000.0 | grad norm avg: 9.4 | grad norm last: 7.87 | 
2025-12-28T01:00:33 | step: 340600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.837761222617701e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.16 | consumed tokens: 174387200.0 | grad norm avg: 9.39 | grad norm last: 9.7 | 
2025-12-28T01:00:35 | step: 340700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.836568693164736e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.41 | consumed tokens: 174438400.0 | grad norm avg: 9.07 | grad norm last: 7.42 | 
2025-12-28T01:00:37 | step: 340800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.835376163711771e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.56 | consumed tokens: 174489600.0 | grad norm avg: 8.79 | grad norm last: 8.79 | 
2025-12-28T01:00:39 | step: 340900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 7.834182906663045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 2.55 | consumed tokens: 174540800.0 | grad norm avg: 8.9 | grad norm last: 7.3 | 
2025-12-28T01:00:41 | step: 341000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 7.832989649614319e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.91 | consumed tokens: 174592000.0 | grad norm avg: 8.87 | grad norm last: 8.06 | 
2025-12-28T01:00:43 | step: 341100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 7.831796392565593e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.47 | consumed tokens: 174643200.0 | grad norm avg: 9.56 | grad norm last: 9.57 | 
2025-12-28T01:00:45 | step: 341200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 7.830603135516867e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 5.16 | consumed tokens: 174694400.0 | grad norm avg: 9.48 | grad norm last: 17.85 | 
2025-12-28T01:00:47 | step: 341300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.82940915087238e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.28 | consumed tokens: 174745600.0 | grad norm avg: 8.75 | grad norm last: 7.42 | 
2025-12-28T01:00:49 | step: 341400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.828215166227892e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.02 | consumed tokens: 174796800.0 | grad norm avg: 9.54 | grad norm last: 6.64 | 
2025-12-28T01:00:51 | step: 341500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.827020453987643e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.31 | consumed tokens: 174848000.0 | grad norm avg: 8.98 | grad norm last: 13.14 | 
2025-12-28T01:00:53 | step: 341600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.825825741747394e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.44 | consumed tokens: 174899200.0 | grad norm avg: 8.92 | grad norm last: 7.14 | 
2025-12-28T01:00:55 | step: 341700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.824631029507145e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.31 | consumed tokens: 174950400.0 | grad norm avg: 8.83 | grad norm last: 7.71 | 
2025-12-28T01:00:57 | step: 341800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.823436317266896e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 5.12 | consumed tokens: 175001600.0 | grad norm avg: 9.3 | grad norm last: 10.79 | 
2025-12-28T01:00:59 | step: 341900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.822240877430886e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.77 | consumed tokens: 175052800.0 | grad norm avg: 8.96 | grad norm last: 8.31 | 
2025-12-28T01:01:01 | step: 342000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.821045437594876e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.92 | consumed tokens: 175104000.0 | grad norm avg: 9.05 | grad norm last: 9.34 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_342000-seen_tokens_175104000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_342000-seen_tokens_175104000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_342000-seen_tokens_175104000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_342000-seen_tokens_175104000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_342000-seen_tokens_175104000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_342000-seen_tokens_175104000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_342000-seen_tokens_175104000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_342000-seen_tokens_175104000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:01:03 | step: 342100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.819849997758865e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.75 | train loss last: 3.34 | consumed tokens: 175155200.0 | grad norm avg: 9.37 | grad norm last: 7.64 | 
2025-12-28T01:01:05 | step: 342200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.818653830327094e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.0 | consumed tokens: 175206400.0 | grad norm avg: 9.12 | grad norm last: 7.1 | 
2025-12-28T01:01:07 | step: 342300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.817457662895322e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 5.31 | consumed tokens: 175257600.0 | grad norm avg: 9.21 | grad norm last: 13.81 | 
2025-12-28T01:01:09 | step: 342400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.81626149546355e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.25 | consumed tokens: 175308800.0 | grad norm avg: 8.88 | grad norm last: 7.57 | 
2025-12-28T01:01:11 | step: 342500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.815064600436017e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.31 | consumed tokens: 175360000.0 | grad norm avg: 9.49 | grad norm last: 10.33 | 
2025-12-28T01:01:13 | step: 342600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.813867705408484e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.59 | consumed tokens: 175411200.0 | grad norm avg: 9.19 | grad norm last: 7.56 | 
2025-12-28T01:01:15 | step: 342700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.81267081038095e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.7 | consumed tokens: 175462400.0 | grad norm avg: 9.18 | grad norm last: 7.36 | 
2025-12-28T01:01:17 | step: 342800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.811473915353417e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.27 | consumed tokens: 175513600.0 | grad norm avg: 9.01 | grad norm last: 8.69 | 
2025-12-28T01:01:19 | step: 342900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.810276292730123e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.83 | consumed tokens: 175564800.0 | grad norm avg: 9.2 | grad norm last: 9.4 | 
2025-12-28T01:01:21 | step: 343000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 7.809078670106828e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.72 | consumed tokens: 175616000.0 | grad norm avg: 8.59 | grad norm last: 7.81 | 
2025-12-28T01:01:23 | step: 343100 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 7.807881047483534e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 2.95 | consumed tokens: 175667200.0 | grad norm avg: 8.93 | grad norm last: 7.38 | 
2025-12-28T01:01:25 | step: 343200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.806682697264478e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.31 | consumed tokens: 175718400.0 | grad norm avg: 8.69 | grad norm last: 7.29 | 
2025-12-28T01:01:27 | step: 343300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.805484347045422e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.03 | consumed tokens: 175769600.0 | grad norm avg: 9.14 | grad norm last: 11.17 | 
2025-12-28T01:01:29 | step: 343400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.804285996826366e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.31 | consumed tokens: 175820800.0 | grad norm avg: 9.26 | grad norm last: 9.41 | 
2025-12-28T01:01:31 | step: 343500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.803086919011548e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.67 | consumed tokens: 175872000.0 | grad norm avg: 9.2 | grad norm last: 7.83 | 
2025-12-28T01:01:34 | step: 343600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.801887841196731e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.38 | consumed tokens: 175923200.0 | grad norm avg: 8.86 | grad norm last: 7.74 | 
2025-12-28T01:01:36 | step: 343700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.800688763381913e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.31 | consumed tokens: 175974400.0 | grad norm avg: 8.78 | grad norm last: 11.92 | 
2025-12-28T01:01:38 | step: 343800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.799488957971334e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.66 | consumed tokens: 176025600.0 | grad norm avg: 8.76 | grad norm last: 8.02 | 
2025-12-28T01:01:40 | step: 343900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.798289152560756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 5.0 | consumed tokens: 176076800.0 | grad norm avg: 8.86 | grad norm last: 11.35 | 
2025-12-28T01:01:42 | step: 344000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.797089347150177e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.16 | consumed tokens: 176128000.0 | grad norm avg: 8.81 | grad norm last: 7.63 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_344000-seen_tokens_176128000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_344000-seen_tokens_176128000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_344000-seen_tokens_176128000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_344000-seen_tokens_176128000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_344000-seen_tokens_176128000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_344000-seen_tokens_176128000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_344000-seen_tokens_176128000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_344000-seen_tokens_176128000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:01:44 | step: 344100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.795889541739598e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.79 | train loss last: 3.47 | consumed tokens: 176179200.0 | grad norm avg: 9.35 | grad norm last: 9.0 | 
2025-12-28T01:01:46 | step: 344200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.794689008733258e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.83 | train loss last: 3.45 | consumed tokens: 176230400.0 | grad norm avg: 8.98 | grad norm last: 8.17 | 
2025-12-28T01:01:48 | step: 344300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.793488475726917e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.86 | consumed tokens: 176281600.0 | grad norm avg: 9.17 | grad norm last: 9.45 | 
2025-12-28T01:01:50 | step: 344400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.792287942720577e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.06 | consumed tokens: 176332800.0 | grad norm avg: 8.46 | grad norm last: 9.05 | 
2025-12-28T01:01:52 | step: 344500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.791086682118475e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.7 | consumed tokens: 176384000.0 | grad norm avg: 8.69 | grad norm last: 7.78 | 
2025-12-28T01:01:54 | step: 344600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.789885421516374e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.06 | consumed tokens: 176435200.0 | grad norm avg: 9.37 | grad norm last: 10.8 | 
2025-12-28T01:01:56 | step: 344700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.788684160914272e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.56 | consumed tokens: 176486400.0 | grad norm avg: 9.34 | grad norm last: 14.57 | 
2025-12-28T01:01:58 | step: 344800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.787482172716409e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.08 | consumed tokens: 176537600.0 | grad norm avg: 8.79 | grad norm last: 7.95 | 
2025-12-28T01:02:00 | step: 344900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 7.786280912114307e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.08 | consumed tokens: 176588800.0 | grad norm avg: 9.09 | grad norm last: 7.86 | 
2025-12-28T01:02:02 | step: 345000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 7.785078196320683e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.94 | consumed tokens: 176640000.0 | grad norm avg: 8.58 | grad norm last: 10.48 | 
2025-12-28T01:02:04 | step: 345100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.78387620812282e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.05 | consumed tokens: 176691200.0 | grad norm avg: 8.94 | grad norm last: 9.61 | 
2025-12-28T01:02:06 | step: 345200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.782673492329195e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.56 | consumed tokens: 176742400.0 | grad norm avg: 8.95 | grad norm last: 7.97 | 
2025-12-28T01:02:08 | step: 345300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.78147077653557e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.39 | consumed tokens: 176793600.0 | grad norm avg: 8.88 | grad norm last: 7.85 | 
2025-12-28T01:02:10 | step: 345400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.780268060741946e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.62 | consumed tokens: 176844800.0 | grad norm avg: 9.18 | grad norm last: 9.83 | 
2025-12-28T01:02:12 | step: 345500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.77906461735256e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.66 | consumed tokens: 176896000.0 | grad norm avg: 8.98 | grad norm last: 8.07 | 
2025-12-28T01:02:14 | step: 345600 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 7.777861173963174e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.64 | consumed tokens: 176947200.0 | grad norm avg: 9.0 | grad norm last: 7.59 | 
2025-12-28T01:02:16 | step: 345700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 7.776657730573788e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.34 | consumed tokens: 176998400.0 | grad norm avg: 9.0 | grad norm last: 7.75 | 
2025-12-28T01:02:18 | step: 345800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 7.775453559588641e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 5.75 | consumed tokens: 177049600.0 | grad norm avg: 9.08 | grad norm last: 26.78 | 
2025-12-28T01:02:20 | step: 345900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 7.774249388603494e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.03 | consumed tokens: 177100800.0 | grad norm avg: 9.0 | grad norm last: 8.29 | 
2025-12-28T01:02:22 | step: 346000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 7.773045217618346e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.94 | consumed tokens: 177152000.0 | grad norm avg: 8.82 | grad norm last: 10.33 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_346000-seen_tokens_177152000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_346000-seen_tokens_177152000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_346000-seen_tokens_177152000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_346000-seen_tokens_177152000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_346000-seen_tokens_177152000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_346000-seen_tokens_177152000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_346000-seen_tokens_177152000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_346000-seen_tokens_177152000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:02:25 | step: 346100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.771841046633199e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.83 | train loss last: 4.88 | consumed tokens: 177203200.0 | grad norm avg: 8.93 | grad norm last: 10.28 | 
2025-12-28T01:02:27 | step: 346200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.77063614805229e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.84 | consumed tokens: 177254400.0 | grad norm avg: 9.05 | grad norm last: 8.93 | 
2025-12-28T01:02:29 | step: 346300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 7.769431249471381e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.56 | consumed tokens: 177305600.0 | grad norm avg: 8.72 | grad norm last: 8.08 | 
2025-12-28T01:02:31 | step: 346400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 7.768225623294711e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.7 | consumed tokens: 177356800.0 | grad norm avg: 9.18 | grad norm last: 9.31 | 
2025-12-28T01:02:33 | step: 346500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.767020724713802e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.81 | consumed tokens: 177408000.0 | grad norm avg: 9.08 | grad norm last: 8.5 | 
2025-12-28T01:02:35 | step: 346600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.765815098537132e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.7 | consumed tokens: 177459200.0 | grad norm avg: 9.04 | grad norm last: 7.64 | 
2025-12-28T01:02:37 | step: 346700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.764609472360462e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.19 | consumed tokens: 177510400.0 | grad norm avg: 9.12 | grad norm last: 6.96 | 
2025-12-28T01:02:39 | step: 346800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.76340311858803e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.38 | consumed tokens: 177561600.0 | grad norm avg: 8.97 | grad norm last: 7.31 | 
2025-12-28T01:02:41 | step: 346900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.762196764815599e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.77 | consumed tokens: 177612800.0 | grad norm avg: 8.84 | grad norm last: 7.37 | 
2025-12-28T01:02:43 | step: 347000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.760990411043167e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.81 | consumed tokens: 177664000.0 | grad norm avg: 9.46 | grad norm last: 12.4 | 
2025-12-28T01:02:45 | step: 347100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.759783329674974e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.22 | consumed tokens: 177715200.0 | grad norm avg: 8.85 | grad norm last: 7.59 | 
2025-12-28T01:02:47 | step: 347200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.758576975902542e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.69 | consumed tokens: 177766400.0 | grad norm avg: 9.26 | grad norm last: 9.31 | 
2025-12-28T01:02:49 | step: 347300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.75736989453435e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.03 | consumed tokens: 177817600.0 | grad norm avg: 9.21 | grad norm last: 9.21 | 
2025-12-28T01:02:51 | step: 347400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.756162085570395e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.56 | consumed tokens: 177868800.0 | grad norm avg: 9.04 | grad norm last: 7.92 | 
2025-12-28T01:02:53 | step: 347500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 7.754955004202202e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.09 | consumed tokens: 177920000.0 | grad norm avg: 9.03 | grad norm last: 10.21 | 
2025-12-28T01:02:55 | step: 347600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.753747195238248e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.8 | consumed tokens: 177971200.0 | grad norm avg: 8.97 | grad norm last: 8.87 | 
2025-12-28T01:02:57 | step: 347700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.752538658678532e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 5.03 | consumed tokens: 178022400.0 | grad norm avg: 9.28 | grad norm last: 10.39 | 
2025-12-28T01:02:59 | step: 347800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.751330849714577e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.39 | consumed tokens: 178073600.0 | grad norm avg: 8.92 | grad norm last: 7.52 | 
2025-12-28T01:03:01 | step: 347900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.750122313154861e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.75 | consumed tokens: 178124800.0 | grad norm avg: 9.2 | grad norm last: 8.26 | 
2025-12-28T01:03:03 | step: 348000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.748913776595145e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.44 | consumed tokens: 178176000.0 | grad norm avg: 8.76 | grad norm last: 11.17 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_348000-seen_tokens_178176000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_348000-seen_tokens_178176000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_348000-seen_tokens_178176000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_348000-seen_tokens_178176000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_348000-seen_tokens_178176000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_348000-seen_tokens_178176000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_348000-seen_tokens_178176000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_348000-seen_tokens_178176000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:03:05 | step: 348100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.747704512439668e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.83 | train loss last: 3.91 | consumed tokens: 178227200.0 | grad norm avg: 9.49 | grad norm last: 9.03 | 
2025-12-28T01:03:08 | step: 348200 | train samples/s: 98.8 | train mfu (16-bit): -1.0 | lr mean: 7.746495975879952e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.45 | consumed tokens: 178278400.0 | grad norm avg: 9.08 | grad norm last: 8.07 | 
2025-12-28T01:03:10 | step: 348300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.745286711724475e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.53 | consumed tokens: 178329600.0 | grad norm avg: 9.01 | grad norm last: 9.57 | 
2025-12-28T01:03:12 | step: 348400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.744076719973236e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.06 | consumed tokens: 178380800.0 | grad norm avg: 8.88 | grad norm last: 9.32 | 
2025-12-28T01:03:14 | step: 348500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.742867455817759e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.48 | consumed tokens: 178432000.0 | grad norm avg: 9.08 | grad norm last: 8.84 | 
2025-12-28T01:03:16 | step: 348600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.74165746406652e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.06 | consumed tokens: 178483200.0 | grad norm avg: 8.89 | grad norm last: 8.9 | 
2025-12-28T01:03:18 | step: 348700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.74044674471952e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.5 | consumed tokens: 178534400.0 | grad norm avg: 8.89 | grad norm last: 7.19 | 
2025-12-28T01:03:20 | step: 348800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.739236752968282e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 2.8 | consumed tokens: 178585600.0 | grad norm avg: 9.54 | grad norm last: 7.63 | 
2025-12-28T01:03:22 | step: 348900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.738026033621281e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.48 | consumed tokens: 178636800.0 | grad norm avg: 8.98 | grad norm last: 7.36 | 
2025-12-28T01:03:24 | step: 349000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.736815314274281e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.45 | consumed tokens: 178688000.0 | grad norm avg: 9.47 | grad norm last: 8.53 | 
2025-12-28T01:03:26 | step: 349100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.735604594927281e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 5.53 | consumed tokens: 178739200.0 | grad norm avg: 9.28 | grad norm last: 12.09 | 
2025-12-28T01:03:28 | step: 349200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.73439314798452e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.67 | consumed tokens: 178790400.0 | grad norm avg: 9.35 | grad norm last: 7.99 | 
2025-12-28T01:03:30 | step: 349300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.733181701041758e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.97 | consumed tokens: 178841600.0 | grad norm avg: 9.07 | grad norm last: 9.86 | 
2025-12-28T01:03:32 | step: 349400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.731970254098997e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.22 | consumed tokens: 178892800.0 | grad norm avg: 9.02 | grad norm last: 9.68 | 
2025-12-28T01:03:34 | step: 349500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.730758079560474e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.05 | consumed tokens: 178944000.0 | grad norm avg: 9.28 | grad norm last: 7.3 | 
2025-12-28T01:03:36 | step: 349600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.72954590502195e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.83 | consumed tokens: 178995200.0 | grad norm avg: 8.83 | grad norm last: 8.61 | 
2025-12-28T01:03:38 | step: 349700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.728333730483428e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.16 | consumed tokens: 179046400.0 | grad norm avg: 8.97 | grad norm last: 9.79 | 
2025-12-28T01:03:40 | step: 349800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 7.727120828349143e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.17 | consumed tokens: 179097600.0 | grad norm avg: 9.13 | grad norm last: 8.98 | 
2025-12-28T01:03:42 | step: 349900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.72590865381062e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.97 | consumed tokens: 179148800.0 | grad norm avg: 8.88 | grad norm last: 8.15 | 
2025-12-28T01:03:44 | step: 350000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.724695751676336e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.09 | consumed tokens: 179200000.0 | grad norm avg: 9.4 | grad norm last: 9.58 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_350000-seen_tokens_179200000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_350000-seen_tokens_179200000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_350000-seen_tokens_179200000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_350000-seen_tokens_179200000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_350000-seen_tokens_179200000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_350000-seen_tokens_179200000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_350000-seen_tokens_179200000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_350000-seen_tokens_179200000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:03:46 | step: 350100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.72348212194629e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.12 | consumed tokens: 179251200.0 | grad norm avg: 8.81 | grad norm last: 7.87 | 
2025-12-28T01:03:48 | step: 350200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.722269219812006e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.47 | consumed tokens: 179302400.0 | grad norm avg: 9.2 | grad norm last: 11.94 | 
2025-12-28T01:03:50 | step: 350300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.72105559008196e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.14 | consumed tokens: 179353600.0 | grad norm avg: 9.21 | grad norm last: 8.02 | 
2025-12-28T01:03:52 | step: 350400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.719841232756153e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.47 | consumed tokens: 179404800.0 | grad norm avg: 9.85 | grad norm last: 8.59 | 
2025-12-28T01:03:54 | step: 350500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 7.718627603026107e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.42 | consumed tokens: 179456000.0 | grad norm avg: 9.58 | grad norm last: 9.33 | 
2025-12-28T01:03:56 | step: 350600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 7.7174132457003e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.02 | consumed tokens: 179507200.0 | grad norm avg: 9.15 | grad norm last: 8.54 | 
2025-12-28T01:03:58 | step: 350700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 7.716198888374493e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.62 | consumed tokens: 179558400.0 | grad norm avg: 9.06 | grad norm last: 12.04 | 
2025-12-28T01:04:00 | step: 350800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.714983803452924e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.59 | consumed tokens: 179609600.0 | grad norm avg: 9.06 | grad norm last: 7.64 | 
2025-12-28T01:04:02 | step: 350900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.713769446127117e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.08 | consumed tokens: 179660800.0 | grad norm avg: 9.62 | grad norm last: 7.59 | 
2025-12-28T01:04:04 | step: 351000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.712554361205548e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.53 | consumed tokens: 179712000.0 | grad norm avg: 9.13 | grad norm last: 7.84 | 
2025-12-28T01:04:06 | step: 351100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.711338548688218e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.11 | consumed tokens: 179763200.0 | grad norm avg: 8.82 | grad norm last: 7.35 | 
2025-12-28T01:04:08 | step: 351200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 7.71012346376665e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 5.66 | consumed tokens: 179814400.0 | grad norm avg: 9.22 | grad norm last: 24.93 | 
2025-12-28T01:04:10 | step: 351300 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 7.708907651249319e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.42 | consumed tokens: 179865600.0 | grad norm avg: 8.74 | grad norm last: 7.93 | 
2025-12-28T01:04:13 | step: 351400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 7.707691838731989e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.95 | consumed tokens: 179916800.0 | grad norm avg: 9.14 | grad norm last: 9.18 | 
2025-12-28T01:04:15 | step: 351500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 7.706475298618898e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.39 | consumed tokens: 179968000.0 | grad norm avg: 9.12 | grad norm last: 8.15 | 
2025-12-28T01:04:17 | step: 351600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 7.705259486101568e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.75 | consumed tokens: 180019200.0 | grad norm avg: 8.94 | grad norm last: 9.42 | 
2025-12-28T01:04:19 | step: 351700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 7.704042945988476e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.86 | consumed tokens: 180070400.0 | grad norm avg: 9.91 | grad norm last: 8.32 | 
2025-12-28T01:04:21 | step: 351800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 7.702825678279623e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.55 | consumed tokens: 180121600.0 | grad norm avg: 9.15 | grad norm last: 8.56 | 
2025-12-28T01:04:23 | step: 351900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.701609138166532e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.19 | consumed tokens: 180172800.0 | grad norm avg: 8.99 | grad norm last: 10.32 | 
2025-12-28T01:04:25 | step: 352000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.700391870457679e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.41 | consumed tokens: 180224000.0 | grad norm avg: 9.32 | grad norm last: 10.25 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_352000-seen_tokens_180224000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_352000-seen_tokens_180224000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_352000-seen_tokens_180224000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_352000-seen_tokens_180224000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_352000-seen_tokens_180224000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_352000-seen_tokens_180224000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_352000-seen_tokens_180224000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_352000-seen_tokens_180224000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:04:27 | step: 352100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.699174602748826e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.75 | train loss last: 3.8 | consumed tokens: 180275200.0 | grad norm avg: 9.05 | grad norm last: 9.05 | 
2025-12-28T01:04:29 | step: 352200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.697956607444212e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.77 | train loss last: 3.98 | consumed tokens: 180326400.0 | grad norm avg: 9.18 | grad norm last: 8.44 | 
2025-12-28T01:04:31 | step: 352300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.696738612139598e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.25 | consumed tokens: 180377600.0 | grad norm avg: 9.35 | grad norm last: 9.77 | 
2025-12-28T01:04:33 | step: 352400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.695520616834983e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 2.91 | consumed tokens: 180428800.0 | grad norm avg: 9.04 | grad norm last: 10.31 | 
2025-12-28T01:04:35 | step: 352500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.694302621530369e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.41 | consumed tokens: 180480000.0 | grad norm avg: 9.3 | grad norm last: 8.88 | 
2025-12-28T01:04:37 | step: 352600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.693083898629993e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 2.92 | consumed tokens: 180531200.0 | grad norm avg: 9.41 | grad norm last: 8.89 | 
2025-12-28T01:04:39 | step: 352700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.691865175729617e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.31 | consumed tokens: 180582400.0 | grad norm avg: 9.15 | grad norm last: 7.21 | 
2025-12-28T01:04:41 | step: 352800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.690646452829242e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.09 | consumed tokens: 180633600.0 | grad norm avg: 9.5 | grad norm last: 8.79 | 
2025-12-28T01:04:43 | step: 352900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 7.689427002333105e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.88 | consumed tokens: 180684800.0 | grad norm avg: 9.67 | grad norm last: 8.19 | 
2025-12-28T01:04:45 | step: 353000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.688208279432729e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.7 | consumed tokens: 180736000.0 | grad norm avg: 9.12 | grad norm last: 7.13 | 
2025-12-28T01:04:47 | step: 353100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.68698810134083e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.38 | consumed tokens: 180787200.0 | grad norm avg: 9.08 | grad norm last: 10.15 | 
2025-12-28T01:04:49 | step: 353200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.685768650844693e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.94 | consumed tokens: 180838400.0 | grad norm avg: 9.58 | grad norm last: 7.94 | 
2025-12-28T01:04:51 | step: 353300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.684548472752795e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.61 | consumed tokens: 180889600.0 | grad norm avg: 9.27 | grad norm last: 8.12 | 
2025-12-28T01:04:53 | step: 353400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.683328294660896e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.19 | consumed tokens: 180940800.0 | grad norm avg: 9.2 | grad norm last: 7.2 | 
2025-12-28T01:04:55 | step: 353500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.682108116568998e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.28 | consumed tokens: 180992000.0 | grad norm avg: 10.0 | grad norm last: 8.45 | 
2025-12-28T01:04:57 | step: 353600 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 7.680887938477099e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.0 | consumed tokens: 181043200.0 | grad norm avg: 9.59 | grad norm last: 8.42 | 
2025-12-28T01:04:59 | step: 353700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.679667032789439e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.19 | consumed tokens: 181094400.0 | grad norm avg: 9.53 | grad norm last: 10.4 | 
2025-12-28T01:05:01 | step: 353800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.678446127101779e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.69 | consumed tokens: 181145600.0 | grad norm avg: 9.57 | grad norm last: 9.38 | 
2025-12-28T01:05:03 | step: 353900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.677224493818358e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.09 | consumed tokens: 181196800.0 | grad norm avg: 9.67 | grad norm last: 10.68 | 
2025-12-28T01:05:05 | step: 354000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.676003588130698e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.16 | consumed tokens: 181248000.0 | grad norm avg: 9.41 | grad norm last: 8.46 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_354000-seen_tokens_181248000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_354000-seen_tokens_181248000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_354000-seen_tokens_181248000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_354000-seen_tokens_181248000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_354000-seen_tokens_181248000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_354000-seen_tokens_181248000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_354000-seen_tokens_181248000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_354000-seen_tokens_181248000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:05:08 | step: 354100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.674781954847276e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.77 | train loss last: 3.3 | consumed tokens: 181299200.0 | grad norm avg: 8.94 | grad norm last: 7.89 | 
2025-12-28T01:05:10 | step: 354200 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 7.673559593968093e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.91 | consumed tokens: 181350400.0 | grad norm avg: 9.31 | grad norm last: 8.96 | 
2025-12-28T01:05:12 | step: 354300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.672337960684672e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.28 | consumed tokens: 181401600.0 | grad norm avg: 9.11 | grad norm last: 10.12 | 
2025-12-28T01:05:14 | step: 354400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.671115599805489e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.16 | consumed tokens: 181452800.0 | grad norm avg: 9.0 | grad norm last: 8.55 | 
2025-12-28T01:05:16 | step: 354500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.669893238926306e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.17 | consumed tokens: 181504000.0 | grad norm avg: 8.93 | grad norm last: 6.65 | 
2025-12-28T01:05:18 | step: 354600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 7.668670150451362e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.12 | consumed tokens: 181555200.0 | grad norm avg: 9.39 | grad norm last: 8.05 | 
2025-12-28T01:05:20 | step: 354700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.667447789572179e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.36 | consumed tokens: 181606400.0 | grad norm avg: 9.27 | grad norm last: 6.97 | 
2025-12-28T01:05:22 | step: 354800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 7.666224701097235e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.12 | consumed tokens: 181657600.0 | grad norm avg: 9.67 | grad norm last: 10.89 | 
2025-12-28T01:05:24 | step: 354900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.66500088502653e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.38 | consumed tokens: 181708800.0 | grad norm avg: 9.12 | grad norm last: 8.36 | 
2025-12-28T01:05:26 | step: 355000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.663777796551585e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 2.92 | consumed tokens: 181760000.0 | grad norm avg: 8.89 | grad norm last: 7.54 | 
2025-12-28T01:05:28 | step: 355100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.66255398048088e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.25 | consumed tokens: 181811200.0 | grad norm avg: 9.73 | grad norm last: 9.68 | 
2025-12-28T01:05:30 | step: 355200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.661330164410174e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.0 | consumed tokens: 181862400.0 | grad norm avg: 9.87 | grad norm last: 8.75 | 
2025-12-28T01:05:32 | step: 355300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.660105620743707e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.03 | consumed tokens: 181913600.0 | grad norm avg: 8.97 | grad norm last: 8.73 | 
2025-12-28T01:05:34 | step: 355400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.658881804673001e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.27 | consumed tokens: 181964800.0 | grad norm avg: 9.17 | grad norm last: 7.85 | 
2025-12-28T01:05:36 | step: 355500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.657657261006534e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.02 | consumed tokens: 182016000.0 | grad norm avg: 9.63 | grad norm last: 9.49 | 
2025-12-28T01:05:38 | step: 355600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.656431989744306e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.06 | consumed tokens: 182067200.0 | grad norm avg: 9.0 | grad norm last: 10.51 | 
2025-12-28T01:05:40 | step: 355700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.655207446077839e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.22 | consumed tokens: 182118400.0 | grad norm avg: 9.08 | grad norm last: 7.64 | 
2025-12-28T01:05:42 | step: 355800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.65398217481561e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.03 | consumed tokens: 182169600.0 | grad norm avg: 9.46 | grad norm last: 7.26 | 
2025-12-28T01:05:44 | step: 355900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.652756903553382e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.0 | consumed tokens: 182220800.0 | grad norm avg: 9.6 | grad norm last: 8.15 | 
2025-12-28T01:05:46 | step: 356000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.651530904695392e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.2 | consumed tokens: 182272000.0 | grad norm avg: 9.4 | grad norm last: 7.34 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_356000-seen_tokens_182272000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_356000-seen_tokens_182272000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_356000-seen_tokens_182272000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_356000-seen_tokens_182272000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_356000-seen_tokens_182272000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_356000-seen_tokens_182272000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_356000-seen_tokens_182272000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_356000-seen_tokens_182272000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:05:48 | step: 356100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 7.650305633433163e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.73 | consumed tokens: 182323200.0 | grad norm avg: 9.31 | grad norm last: 8.91 | 
2025-12-28T01:05:50 | step: 356200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 7.649079634575173e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.41 | consumed tokens: 182374400.0 | grad norm avg: 9.12 | grad norm last: 7.7 | 
2025-12-28T01:05:52 | step: 356300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.647852908121422e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.89 | consumed tokens: 182425600.0 | grad norm avg: 9.15 | grad norm last: 8.01 | 
2025-12-28T01:05:54 | step: 356400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.646626909263432e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.88 | consumed tokens: 182476800.0 | grad norm avg: 9.32 | grad norm last: 10.06 | 
2025-12-28T01:05:56 | step: 356500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.645400182809681e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.38 | consumed tokens: 182528000.0 | grad norm avg: 9.47 | grad norm last: 7.5 | 
2025-12-28T01:05:58 | step: 356600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.64417345635593e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.67 | consumed tokens: 182579200.0 | grad norm avg: 9.27 | grad norm last: 9.32 | 
2025-12-28T01:06:00 | step: 356700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 7.642946002306417e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.09 | consumed tokens: 182630400.0 | grad norm avg: 9.03 | grad norm last: 7.76 | 
2025-12-28T01:06:02 | step: 356800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 7.641719275852665e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.81 | consumed tokens: 182681600.0 | grad norm avg: 9.02 | grad norm last: 9.13 | 
2025-12-28T01:06:04 | step: 356900 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 7.640491821803153e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.16 | consumed tokens: 182732800.0 | grad norm avg: 9.04 | grad norm last: 9.29 | 
2025-12-28T01:06:07 | step: 357000 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 7.639263640157878e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.75 | consumed tokens: 182784000.0 | grad norm avg: 9.23 | grad norm last: 12.78 | 
2025-12-28T01:06:09 | step: 357100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 7.638036186108366e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.12 | consumed tokens: 182835200.0 | grad norm avg: 8.96 | grad norm last: 7.43 | 
2025-12-28T01:06:11 | step: 357200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.636808004463091e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.88 | consumed tokens: 182886400.0 | grad norm avg: 8.92 | grad norm last: 10.27 | 
2025-12-28T01:06:13 | step: 357300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.635579822817817e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.38 | consumed tokens: 182937600.0 | grad norm avg: 9.09 | grad norm last: 12.98 | 
2025-12-28T01:06:15 | step: 357400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.634351641172543e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.48 | consumed tokens: 182988800.0 | grad norm avg: 9.28 | grad norm last: 7.98 | 
2025-12-28T01:06:17 | step: 357500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.633122731931508e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.28 | consumed tokens: 183040000.0 | grad norm avg: 9.39 | grad norm last: 9.53 | 
2025-12-28T01:06:19 | step: 357600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.631893822690472e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.72 | consumed tokens: 183091200.0 | grad norm avg: 9.5 | grad norm last: 8.83 | 
2025-12-28T01:06:21 | step: 357700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 7.630664913449436e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.66 | consumed tokens: 183142400.0 | grad norm avg: 9.78 | grad norm last: 8.13 | 
2025-12-28T01:06:23 | step: 357800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.62943527661264e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.5 | consumed tokens: 183193600.0 | grad norm avg: 9.1 | grad norm last: 8.55 | 
2025-12-28T01:06:25 | step: 357900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.628205639775842e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.09 | consumed tokens: 183244800.0 | grad norm avg: 9.15 | grad norm last: 8.76 | 
2025-12-28T01:06:27 | step: 358000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.626976002939045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.61 | consumed tokens: 183296000.0 | grad norm avg: 9.13 | grad norm last: 10.93 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_358000-seen_tokens_183296000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_358000-seen_tokens_183296000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_358000-seen_tokens_183296000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_358000-seen_tokens_183296000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_358000-seen_tokens_183296000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_358000-seen_tokens_183296000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_358000-seen_tokens_183296000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_358000-seen_tokens_183296000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:06:29 | step: 358100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.625746366102248e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.82 | train loss last: 3.39 | consumed tokens: 183347200.0 | grad norm avg: 9.05 | grad norm last: 9.09 | 
2025-12-28T01:06:31 | step: 358200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.62451600166969e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.75 | consumed tokens: 183398400.0 | grad norm avg: 9.13 | grad norm last: 13.0 | 
2025-12-28T01:06:33 | step: 358300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.623285637237132e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.36 | consumed tokens: 183449600.0 | grad norm avg: 8.54 | grad norm last: 9.34 | 
2025-12-28T01:06:35 | step: 358400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.622055272804573e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.78 | consumed tokens: 183500800.0 | grad norm avg: 9.29 | grad norm last: 7.5 | 
2025-12-28T01:06:37 | step: 358500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.620824908372015e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.25 | consumed tokens: 183552000.0 | grad norm avg: 9.09 | grad norm last: 8.64 | 
2025-12-28T01:06:39 | step: 358600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.619593816343695e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 2.77 | consumed tokens: 183603200.0 | grad norm avg: 9.16 | grad norm last: 8.2 | 
2025-12-28T01:06:41 | step: 358700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.618362724315375e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.3 | consumed tokens: 183654400.0 | grad norm avg: 8.97 | grad norm last: 7.95 | 
2025-12-28T01:06:43 | step: 358800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.617131632287055e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.53 | consumed tokens: 183705600.0 | grad norm avg: 9.4 | grad norm last: 8.09 | 
2025-12-28T01:06:45 | step: 358900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.615899812662974e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.34 | consumed tokens: 183756800.0 | grad norm avg: 9.53 | grad norm last: 9.57 | 
2025-12-28T01:06:47 | step: 359000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.614667993038893e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.25 | consumed tokens: 183808000.0 | grad norm avg: 9.66 | grad norm last: 8.52 | 
2025-12-28T01:06:49 | step: 359100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.613436173414811e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.91 | consumed tokens: 183859200.0 | grad norm avg: 8.78 | grad norm last: 8.18 | 
2025-12-28T01:06:51 | step: 359200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.612203626194969e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.61 | consumed tokens: 183910400.0 | grad norm avg: 9.08 | grad norm last: 8.62 | 
2025-12-28T01:06:53 | step: 359300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.610971806570888e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.67 | consumed tokens: 183961600.0 | grad norm avg: 9.43 | grad norm last: 8.1 | 
2025-12-28T01:06:55 | step: 359400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.609739259351045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.84 | consumed tokens: 184012800.0 | grad norm avg: 9.6 | grad norm last: 8.62 | 
2025-12-28T01:06:57 | step: 359500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.608505984535441e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.75 | consumed tokens: 184064000.0 | grad norm avg: 9.03 | grad norm last: 11.0 | 
2025-12-28T01:06:59 | step: 359600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.607273437315598e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.34 | consumed tokens: 184115200.0 | grad norm avg: 9.19 | grad norm last: 11.09 | 
2025-12-28T01:07:01 | step: 359700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.606040162499994e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.19 | consumed tokens: 184166400.0 | grad norm avg: 9.19 | grad norm last: 7.81 | 
2025-12-28T01:07:03 | step: 359800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.60480688768439e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.55 | consumed tokens: 184217600.0 | grad norm avg: 8.95 | grad norm last: 7.89 | 
2025-12-28T01:07:05 | step: 359900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.603572885273024e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.5 | consumed tokens: 184268800.0 | grad norm avg: 9.47 | grad norm last: 7.95 | 
2025-12-28T01:07:07 | step: 360000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.60233961045742e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.17 | consumed tokens: 184320000.0 | grad norm avg: 9.06 | grad norm last: 7.6 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_360000-seen_tokens_184320000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_360000-seen_tokens_184320000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_360000-seen_tokens_184320000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_360000-seen_tokens_184320000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_360000-seen_tokens_184320000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_360000-seen_tokens_184320000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_360000-seen_tokens_184320000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_360000-seen_tokens_184320000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:07:10 | step: 360100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.601105608046055e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.79 | train loss last: 4.62 | consumed tokens: 184371200.0 | grad norm avg: 9.28 | grad norm last: 12.66 | 
2025-12-28T01:07:12 | step: 360200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.59987160563469e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.25 | consumed tokens: 184422400.0 | grad norm avg: 9.01 | grad norm last: 13.83 | 
2025-12-28T01:07:14 | step: 360300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.598636875627562e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.88 | consumed tokens: 184473600.0 | grad norm avg: 9.01 | grad norm last: 12.33 | 
2025-12-28T01:07:16 | step: 360400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.597402145620435e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.69 | consumed tokens: 184524800.0 | grad norm avg: 9.76 | grad norm last: 9.3 | 
2025-12-28T01:07:18 | step: 360500 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 7.596167415613309e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.12 | consumed tokens: 184576000.0 | grad norm avg: 9.25 | grad norm last: 7.76 | 
2025-12-28T01:07:20 | step: 360600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.594932685606182e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.42 | consumed tokens: 184627200.0 | grad norm avg: 8.82 | grad norm last: 8.06 | 
2025-12-28T01:07:22 | step: 360700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.593697228003293e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.47 | consumed tokens: 184678400.0 | grad norm avg: 9.2 | grad norm last: 8.43 | 
2025-12-28T01:07:24 | step: 360800 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 7.592461770400405e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.22 | consumed tokens: 184729600.0 | grad norm avg: 8.87 | grad norm last: 8.89 | 
2025-12-28T01:07:26 | step: 360900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.591226312797517e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.12 | consumed tokens: 184780800.0 | grad norm avg: 8.82 | grad norm last: 8.57 | 
2025-12-28T01:07:28 | step: 361000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.589990855194628e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.98 | consumed tokens: 184832000.0 | grad norm avg: 9.5 | grad norm last: 8.8 | 
2025-12-28T01:07:30 | step: 361100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.588754669995978e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.61 | consumed tokens: 184883200.0 | grad norm avg: 9.0 | grad norm last: 8.78 | 
2025-12-28T01:07:32 | step: 361200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.587518484797329e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.84 | consumed tokens: 184934400.0 | grad norm avg: 11.1 | grad norm last: 8.28 | 
2025-12-28T01:07:34 | step: 361300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.586282299598679e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 5.22 | consumed tokens: 184985600.0 | grad norm avg: 9.1 | grad norm last: 10.67 | 
2025-12-28T01:07:36 | step: 361400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.585045386804268e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.78 | consumed tokens: 185036800.0 | grad norm avg: 9.44 | grad norm last: 9.31 | 
2025-12-28T01:07:38 | step: 361500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.583808474009857e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.89 | consumed tokens: 185088000.0 | grad norm avg: 9.18 | grad norm last: 11.96 | 
2025-12-28T01:07:40 | step: 361600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 7.582571561215445e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.06 | consumed tokens: 185139200.0 | grad norm avg: 9.55 | grad norm last: 8.62 | 
2025-12-28T01:07:42 | step: 361700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 7.581334648421034e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.86 | consumed tokens: 185190400.0 | grad norm avg: 8.94 | grad norm last: 9.02 | 
2025-12-28T01:07:44 | step: 361800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 7.580097008030862e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.53 | consumed tokens: 185241600.0 | grad norm avg: 9.11 | grad norm last: 9.87 | 
2025-12-28T01:07:46 | step: 361900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 7.578859367640689e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.69 | consumed tokens: 185292800.0 | grad norm avg: 9.14 | grad norm last: 9.97 | 
2025-12-28T01:07:48 | step: 362000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.577621727250516e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 2.83 | consumed tokens: 185344000.0 | grad norm avg: 8.69 | grad norm last: 7.51 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_362000-seen_tokens_185344000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_362000-seen_tokens_185344000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_362000-seen_tokens_185344000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_362000-seen_tokens_185344000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_362000-seen_tokens_185344000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_362000-seen_tokens_185344000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_362000-seen_tokens_185344000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_362000-seen_tokens_185344000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:07:50 | step: 362100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.576384086860344e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.81 | train loss last: 4.22 | consumed tokens: 185395200.0 | grad norm avg: 9.29 | grad norm last: 10.75 | 
2025-12-28T01:07:52 | step: 362200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.57514571887441e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.74 | train loss last: 2.7 | consumed tokens: 185446400.0 | grad norm avg: 9.08 | grad norm last: 6.81 | 
2025-12-28T01:07:54 | step: 362300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.573907350888476e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.39 | consumed tokens: 185497600.0 | grad norm avg: 9.23 | grad norm last: 8.36 | 
2025-12-28T01:07:56 | step: 362400 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 7.572668982902542e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.38 | consumed tokens: 185548800.0 | grad norm avg: 9.23 | grad norm last: 8.0 | 
2025-12-28T01:07:59 | step: 362500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 7.571429887320846e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.33 | consumed tokens: 185600000.0 | grad norm avg: 9.05 | grad norm last: 7.72 | 
2025-12-28T01:08:01 | step: 362600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 7.570190791739151e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.64 | consumed tokens: 185651200.0 | grad norm avg: 9.26 | grad norm last: 8.07 | 
2025-12-28T01:08:03 | step: 362700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.568951696157455e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 2.98 | consumed tokens: 185702400.0 | grad norm avg: 9.19 | grad norm last: 7.13 | 
2025-12-28T01:08:05 | step: 362800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.56771260057576e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.8 | consumed tokens: 185753600.0 | grad norm avg: 9.16 | grad norm last: 8.67 | 
2025-12-28T01:08:07 | step: 362900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.566472777398303e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.25 | consumed tokens: 185804800.0 | grad norm avg: 9.35 | grad norm last: 12.03 | 
2025-12-28T01:08:09 | step: 363000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.565232954220846e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.77 | consumed tokens: 185856000.0 | grad norm avg: 9.11 | grad norm last: 8.37 | 
2025-12-28T01:08:11 | step: 363100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.56399313104339e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.28 | consumed tokens: 185907200.0 | grad norm avg: 8.98 | grad norm last: 7.49 | 
2025-12-28T01:08:13 | step: 363200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 7.562752580270171e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.58 | consumed tokens: 185958400.0 | grad norm avg: 9.07 | grad norm last: 7.81 | 
2025-12-28T01:08:15 | step: 363300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.561512757092714e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.62 | consumed tokens: 186009600.0 | grad norm avg: 9.33 | grad norm last: 8.07 | 
2025-12-28T01:08:17 | step: 363400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.560272206319496e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.47 | consumed tokens: 186060800.0 | grad norm avg: 9.62 | grad norm last: 12.9 | 
2025-12-28T01:08:19 | step: 363500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.559030927950516e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.47 | consumed tokens: 186112000.0 | grad norm avg: 8.77 | grad norm last: 8.28 | 
2025-12-28T01:08:21 | step: 363600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.557790377177298e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.31 | consumed tokens: 186163200.0 | grad norm avg: 8.92 | grad norm last: 10.38 | 
2025-12-28T01:08:23 | step: 363700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.556549098808318e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.64 | consumed tokens: 186214400.0 | grad norm avg: 9.21 | grad norm last: 9.17 | 
2025-12-28T01:08:25 | step: 363800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.555307820439339e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.23 | consumed tokens: 186265600.0 | grad norm avg: 9.23 | grad norm last: 8.38 | 
2025-12-28T01:08:27 | step: 363900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.554065814474598e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.78 | consumed tokens: 186316800.0 | grad norm avg: 9.61 | grad norm last: 9.86 | 
2025-12-28T01:08:29 | step: 364000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.552824536105618e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.06 | consumed tokens: 186368000.0 | grad norm avg: 9.27 | grad norm last: 9.5 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_364000-seen_tokens_186368000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_364000-seen_tokens_186368000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_364000-seen_tokens_186368000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_364000-seen_tokens_186368000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_364000-seen_tokens_186368000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_364000-seen_tokens_186368000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_364000-seen_tokens_186368000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_364000-seen_tokens_186368000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:08:31 | step: 364100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.551582530140877e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.83 | train loss last: 3.3 | consumed tokens: 186419200.0 | grad norm avg: 9.15 | grad norm last: 7.82 | 
2025-12-28T01:08:33 | step: 364200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.550340524176136e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.72 | consumed tokens: 186470400.0 | grad norm avg: 9.19 | grad norm last: 8.54 | 
2025-12-28T01:08:35 | step: 364300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.549097790615633e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.73 | consumed tokens: 186521600.0 | grad norm avg: 9.07 | grad norm last: 7.71 | 
2025-12-28T01:08:37 | step: 364400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.54785505705513e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.8 | consumed tokens: 186572800.0 | grad norm avg: 9.19 | grad norm last: 7.91 | 
2025-12-28T01:08:39 | step: 364500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.546612323494628e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.41 | consumed tokens: 186624000.0 | grad norm avg: 9.12 | grad norm last: 8.29 | 
2025-12-28T01:08:41 | step: 364600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.545369589934126e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.06 | consumed tokens: 186675200.0 | grad norm avg: 8.99 | grad norm last: 7.92 | 
2025-12-28T01:08:43 | step: 364700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.544126856373623e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.38 | consumed tokens: 186726400.0 | grad norm avg: 8.99 | grad norm last: 10.5 | 
2025-12-28T01:08:45 | step: 364800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.542883395217359e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.58 | consumed tokens: 186777600.0 | grad norm avg: 9.03 | grad norm last: 7.57 | 
2025-12-28T01:08:47 | step: 364900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.541639934061095e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 2.97 | consumed tokens: 186828800.0 | grad norm avg: 8.87 | grad norm last: 8.26 | 
2025-12-28T01:08:49 | step: 365000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.54039574530907e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.23 | consumed tokens: 186880000.0 | grad norm avg: 8.89 | grad norm last: 8.16 | 
2025-12-28T01:08:51 | step: 365100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.539152284152806e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.81 | consumed tokens: 186931200.0 | grad norm avg: 8.82 | grad norm last: 9.73 | 
2025-12-28T01:08:53 | step: 365200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.53790809540078e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.28 | consumed tokens: 186982400.0 | grad norm avg: 9.26 | grad norm last: 7.46 | 
2025-12-28T01:08:55 | step: 365300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.536663179052994e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.09 | consumed tokens: 187033600.0 | grad norm avg: 8.96 | grad norm last: 10.41 | 
2025-12-28T01:08:57 | step: 365400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.535418990300968e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.16 | consumed tokens: 187084800.0 | grad norm avg: 8.96 | grad norm last: 10.14 | 
2025-12-28T01:08:59 | step: 365500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.534174073953182e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.98 | consumed tokens: 187136000.0 | grad norm avg: 8.93 | grad norm last: 8.54 | 
2025-12-28T01:09:01 | step: 365600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.532929157605395e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.16 | consumed tokens: 187187200.0 | grad norm avg: 8.84 | grad norm last: 7.69 | 
2025-12-28T01:09:03 | step: 365700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.531684241257608e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.22 | consumed tokens: 187238400.0 | grad norm avg: 9.12 | grad norm last: 9.33 | 
2025-12-28T01:09:05 | step: 365800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.530439324909821e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.25 | consumed tokens: 187289600.0 | grad norm avg: 8.69 | grad norm last: 8.44 | 
2025-12-28T01:09:07 | step: 365900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.529193680966273e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.48 | consumed tokens: 187340800.0 | grad norm avg: 8.82 | grad norm last: 7.81 | 
2025-12-28T01:09:09 | step: 366000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.527948037022725e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.06 | consumed tokens: 187392000.0 | grad norm avg: 8.78 | grad norm last: 8.24 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_366000-seen_tokens_187392000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_366000-seen_tokens_187392000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_366000-seen_tokens_187392000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_366000-seen_tokens_187392000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_366000-seen_tokens_187392000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_366000-seen_tokens_187392000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_366000-seen_tokens_187392000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_366000-seen_tokens_187392000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:09:12 | step: 366100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.526701665483415e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.47 | consumed tokens: 187443200.0 | grad norm avg: 8.97 | grad norm last: 8.05 | 
2025-12-28T01:09:14 | step: 366200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.525456021539867e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.41 | consumed tokens: 187494400.0 | grad norm avg: 8.82 | grad norm last: 7.21 | 
2025-12-28T01:09:16 | step: 366300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.524209650000557e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.58 | consumed tokens: 187545600.0 | grad norm avg: 8.91 | grad norm last: 7.79 | 
2025-12-28T01:09:18 | step: 366400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.522963278461248e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.61 | consumed tokens: 187596800.0 | grad norm avg: 9.1 | grad norm last: 7.68 | 
2025-12-28T01:09:20 | step: 366500 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 7.521716179326177e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 2.78 | consumed tokens: 187648000.0 | grad norm avg: 8.95 | grad norm last: 8.19 | 
2025-12-28T01:09:22 | step: 366600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 7.520469807786867e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.97 | consumed tokens: 187699200.0 | grad norm avg: 9.02 | grad norm last: 10.27 | 
2025-12-28T01:09:24 | step: 366700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.519222708651796e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.22 | consumed tokens: 187750400.0 | grad norm avg: 9.33 | grad norm last: 7.41 | 
2025-12-28T01:09:26 | step: 366800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.517975609516725e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.3 | consumed tokens: 187801600.0 | grad norm avg: 8.97 | grad norm last: 8.14 | 
2025-12-28T01:09:28 | step: 366900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.516727782785892e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.58 | consumed tokens: 187852800.0 | grad norm avg: 8.76 | grad norm last: 9.31 | 
2025-12-28T01:09:30 | step: 367000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.51547995605506e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.19 | consumed tokens: 187904000.0 | grad norm avg: 9.02 | grad norm last: 12.12 | 
2025-12-28T01:09:32 | step: 367100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.514232129324228e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.33 | consumed tokens: 187955200.0 | grad norm avg: 9.09 | grad norm last: 8.11 | 
2025-12-28T01:09:34 | step: 367200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.512984302593395e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.09 | consumed tokens: 188006400.0 | grad norm avg: 8.94 | grad norm last: 8.91 | 
2025-12-28T01:09:36 | step: 367300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.511736475862563e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.88 | consumed tokens: 188057600.0 | grad norm avg: 9.22 | grad norm last: 18.14 | 
2025-12-28T01:09:38 | step: 367400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.510487921535969e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.66 | consumed tokens: 188108800.0 | grad norm avg: 8.88 | grad norm last: 9.65 | 
2025-12-28T01:09:40 | step: 367500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.509239367209375e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.25 | consumed tokens: 188160000.0 | grad norm avg: 8.64 | grad norm last: 6.95 | 
2025-12-28T01:09:42 | step: 367600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 7.50799008528702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.28 | consumed tokens: 188211200.0 | grad norm avg: 8.97 | grad norm last: 9.3 | 
2025-12-28T01:09:44 | step: 367700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 7.506741530960426e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.7 | consumed tokens: 188262400.0 | grad norm avg: 8.85 | grad norm last: 8.23 | 
2025-12-28T01:09:46 | step: 367800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 7.50549224903807e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.61 | consumed tokens: 188313600.0 | grad norm avg: 8.97 | grad norm last: 8.78 | 
2025-12-28T01:09:48 | step: 367900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.504242967115715e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.92 | consumed tokens: 188364800.0 | grad norm avg: 9.13 | grad norm last: 7.97 | 
2025-12-28T01:09:50 | step: 368000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.50299368519336e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.06 | consumed tokens: 188416000.0 | grad norm avg: 8.81 | grad norm last: 12.38 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_368000-seen_tokens_188416000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_368000-seen_tokens_188416000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_368000-seen_tokens_188416000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_368000-seen_tokens_188416000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_368000-seen_tokens_188416000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_368000-seen_tokens_188416000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_368000-seen_tokens_188416000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_368000-seen_tokens_188416000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:09:53 | step: 368100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.501743675675243e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.38 | consumed tokens: 188467200.0 | grad norm avg: 9.02 | grad norm last: 7.9 | 
2025-12-28T01:09:55 | step: 368200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.500493666157126e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.81 | consumed tokens: 188518400.0 | grad norm avg: 9.45 | grad norm last: 8.4 | 
2025-12-28T01:09:57 | step: 368300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 7.49924365663901e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.78 | consumed tokens: 188569600.0 | grad norm avg: 8.9 | grad norm last: 9.33 | 
2025-12-28T01:09:59 | step: 368400 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 7.497992919525132e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.72 | consumed tokens: 188620800.0 | grad norm avg: 8.54 | grad norm last: 8.6 | 
2025-12-28T01:10:01 | step: 368500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 7.496742910007015e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.52 | consumed tokens: 188672000.0 | grad norm avg: 8.82 | grad norm last: 7.67 | 
2025-12-28T01:10:03 | step: 368600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 7.495492172893137e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.34 | consumed tokens: 188723200.0 | grad norm avg: 8.95 | grad norm last: 8.67 | 
2025-12-28T01:10:05 | step: 368700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 7.494240708183497e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.0 | consumed tokens: 188774400.0 | grad norm avg: 8.58 | grad norm last: 7.36 | 
2025-12-28T01:10:07 | step: 368800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 7.492989971069619e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.55 | consumed tokens: 188825600.0 | grad norm avg: 9.25 | grad norm last: 8.32 | 
2025-12-28T01:10:09 | step: 368900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.49173850635998e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.23 | consumed tokens: 188876800.0 | grad norm avg: 8.99 | grad norm last: 6.9 | 
2025-12-28T01:10:11 | step: 369000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.49048704165034e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.55 | consumed tokens: 188928000.0 | grad norm avg: 9.73 | grad norm last: 9.04 | 
2025-12-28T01:10:13 | step: 369100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.4892355769407e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.53 | consumed tokens: 188979200.0 | grad norm avg: 9.28 | grad norm last: 15.43 | 
2025-12-28T01:10:15 | step: 369200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.4879833846353e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 5.72 | consumed tokens: 189030400.0 | grad norm avg: 9.41 | grad norm last: 17.61 | 
2025-12-28T01:10:17 | step: 369300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.486731192329898e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.94 | consumed tokens: 189081600.0 | grad norm avg: 8.88 | grad norm last: 8.83 | 
2025-12-28T01:10:19 | step: 369400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.485479000024498e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.25 | consumed tokens: 189132800.0 | grad norm avg: 8.88 | grad norm last: 8.26 | 
2025-12-28T01:10:21 | step: 369500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.484226807719097e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.53 | consumed tokens: 189184000.0 | grad norm avg: 8.63 | grad norm last: 7.3 | 
2025-12-28T01:10:23 | step: 369600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.482973887817934e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.22 | consumed tokens: 189235200.0 | grad norm avg: 8.78 | grad norm last: 7.39 | 
2025-12-28T01:10:25 | step: 369700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.481721695512533e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.95 | consumed tokens: 189286400.0 | grad norm avg: 9.14 | grad norm last: 9.12 | 
2025-12-28T01:10:27 | step: 369800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.48046804801561e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.06 | consumed tokens: 189337600.0 | grad norm avg: 8.8 | grad norm last: 9.19 | 
2025-12-28T01:10:29 | step: 369900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.479215128114447e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.94 | train loss last: 4.81 | consumed tokens: 189388800.0 | grad norm avg: 9.65 | grad norm last: 11.3 | 
2025-12-28T01:10:31 | step: 370000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.477961480617523e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.84 | consumed tokens: 189440000.0 | grad norm avg: 9.02 | grad norm last: 7.9 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_370000-seen_tokens_189440000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_370000-seen_tokens_189440000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_370000-seen_tokens_189440000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_370000-seen_tokens_189440000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_370000-seen_tokens_189440000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_370000-seen_tokens_189440000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_370000-seen_tokens_189440000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_370000-seen_tokens_189440000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:10:34 | step: 370100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.4767078331206e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.75 | consumed tokens: 189491200.0 | grad norm avg: 9.04 | grad norm last: 8.96 | 
2025-12-28T01:10:36 | step: 370200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.475454185623676e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.98 | consumed tokens: 189542400.0 | grad norm avg: 9.13 | grad norm last: 9.97 | 
2025-12-28T01:10:38 | step: 370300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.474200538126752e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.45 | consumed tokens: 189593600.0 | grad norm avg: 8.79 | grad norm last: 7.39 | 
2025-12-28T01:10:40 | step: 370400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.472946163034067e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.2 | consumed tokens: 189644800.0 | grad norm avg: 9.25 | grad norm last: 7.87 | 
2025-12-28T01:10:42 | step: 370500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.471691787941381e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.55 | consumed tokens: 189696000.0 | grad norm avg: 9.13 | grad norm last: 8.84 | 
2025-12-28T01:10:44 | step: 370600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.470437412848696e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.7 | consumed tokens: 189747200.0 | grad norm avg: 8.77 | grad norm last: 8.68 | 
2025-12-28T01:10:46 | step: 370700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.469183037756011e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.41 | consumed tokens: 189798400.0 | grad norm avg: 9.11 | grad norm last: 7.93 | 
2025-12-28T01:10:48 | step: 370800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.467927935067564e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.28 | consumed tokens: 189849600.0 | grad norm avg: 8.72 | grad norm last: 8.76 | 
2025-12-28T01:10:50 | step: 370900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.466672832379118e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.17 | consumed tokens: 189900800.0 | grad norm avg: 8.69 | grad norm last: 7.54 | 
2025-12-28T01:10:52 | step: 371000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.465417729690671e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.52 | consumed tokens: 189952000.0 | grad norm avg: 9.13 | grad norm last: 8.66 | 
2025-12-28T01:10:54 | step: 371100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.464161899406463e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.22 | consumed tokens: 190003200.0 | grad norm avg: 9.39 | grad norm last: 7.97 | 
2025-12-28T01:10:56 | step: 371200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.462906069122255e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.31 | consumed tokens: 190054400.0 | grad norm avg: 8.84 | grad norm last: 10.77 | 
2025-12-28T01:10:58 | step: 371300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.461650238838047e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.06 | consumed tokens: 190105600.0 | grad norm avg: 9.28 | grad norm last: 8.81 | 
2025-12-28T01:11:00 | step: 371400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.460394408553839e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.75 | consumed tokens: 190156800.0 | grad norm avg: 8.91 | grad norm last: 12.2 | 
2025-12-28T01:11:02 | step: 371500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.459137850673869e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.42 | consumed tokens: 190208000.0 | grad norm avg: 8.86 | grad norm last: 8.13 | 
2025-12-28T01:11:04 | step: 371600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.457882020389661e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.83 | consumed tokens: 190259200.0 | grad norm avg: 8.91 | grad norm last: 9.24 | 
2025-12-28T01:11:06 | step: 371700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.45662473491393e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 3.56 | consumed tokens: 190310400.0 | grad norm avg: 9.64 | grad norm last: 10.91 | 
2025-12-28T01:11:08 | step: 371800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.455368177033961e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.98 | consumed tokens: 190361600.0 | grad norm avg: 8.62 | grad norm last: 11.68 | 
2025-12-28T01:11:10 | step: 371900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.454111619153991e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.97 | consumed tokens: 190412800.0 | grad norm avg: 9.1 | grad norm last: 9.57 | 
2025-12-28T01:11:12 | step: 372000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.45285433367826e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 5.53 | consumed tokens: 190464000.0 | grad norm avg: 8.89 | grad norm last: 12.21 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_372000-seen_tokens_190464000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_372000-seen_tokens_190464000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_372000-seen_tokens_190464000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_372000-seen_tokens_190464000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_372000-seen_tokens_190464000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_372000-seen_tokens_190464000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_372000-seen_tokens_190464000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_372000-seen_tokens_190464000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:11:14 | step: 372100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.45159704820253e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.75 | train loss last: 3.56 | consumed tokens: 190515200.0 | grad norm avg: 9.02 | grad norm last: 8.33 | 
2025-12-28T01:11:16 | step: 372200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 7.450339035131037e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.83 | consumed tokens: 190566400.0 | grad norm avg: 9.16 | grad norm last: 8.54 | 
2025-12-28T01:11:18 | step: 372300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.449081749655306e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.61 | consumed tokens: 190617600.0 | grad norm avg: 9.05 | grad norm last: 8.39 | 
2025-12-28T01:11:20 | step: 372400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.447823736583814e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.8 | consumed tokens: 190668800.0 | grad norm avg: 9.33 | grad norm last: 8.69 | 
2025-12-28T01:11:22 | step: 372500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.446565723512322e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.83 | consumed tokens: 190720000.0 | grad norm avg: 8.93 | grad norm last: 10.55 | 
2025-12-28T01:11:24 | step: 372600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.445306982845068e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.33 | consumed tokens: 190771200.0 | grad norm avg: 8.66 | grad norm last: 10.43 | 
2025-12-28T01:11:26 | step: 372700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.444048969773576e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.7 | consumed tokens: 190822400.0 | grad norm avg: 8.77 | grad norm last: 8.65 | 
2025-12-28T01:11:28 | step: 372800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.442790229106322e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.02 | consumed tokens: 190873600.0 | grad norm avg: 9.3 | grad norm last: 7.04 | 
2025-12-28T01:11:30 | step: 372900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 7.441530760843307e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 6.12 | consumed tokens: 190924800.0 | grad norm avg: 8.98 | grad norm last: 15.8 | 
2025-12-28T01:11:32 | step: 373000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.440272020176053e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.47 | consumed tokens: 190976000.0 | grad norm avg: 9.22 | grad norm last: 8.69 | 
2025-12-28T01:11:34 | step: 373100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.439012551913038e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.58 | consumed tokens: 191027200.0 | grad norm avg: 8.9 | grad norm last: 8.94 | 
2025-12-28T01:11:36 | step: 373200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.437753083650023e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.03 | consumed tokens: 191078400.0 | grad norm avg: 9.24 | grad norm last: 9.55 | 
2025-12-28T01:11:38 | step: 373300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 7.436493615387008e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.36 | consumed tokens: 191129600.0 | grad norm avg: 9.06 | grad norm last: 9.67 | 
2025-12-28T01:11:40 | step: 373400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 7.435234147123992e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.64 | consumed tokens: 191180800.0 | grad norm avg: 8.89 | grad norm last: 8.37 | 
2025-12-28T01:11:43 | step: 373500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 7.433973951265216e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.67 | consumed tokens: 191232000.0 | grad norm avg: 8.82 | grad norm last: 8.16 | 
2025-12-28T01:11:45 | step: 373600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.432713755406439e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.5 | consumed tokens: 191283200.0 | grad norm avg: 8.91 | grad norm last: 8.19 | 
2025-12-28T01:11:47 | step: 373700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.431453559547663e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.31 | consumed tokens: 191334400.0 | grad norm avg: 8.98 | grad norm last: 8.47 | 
2025-12-28T01:11:49 | step: 373800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.430192636093125e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.5 | consumed tokens: 191385600.0 | grad norm avg: 8.73 | grad norm last: 7.55 | 
2025-12-28T01:11:51 | step: 373900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.428932440234348e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.95 | consumed tokens: 191436800.0 | grad norm avg: 8.86 | grad norm last: 11.21 | 
2025-12-28T01:11:53 | step: 374000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.42767151677981e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.12 | consumed tokens: 191488000.0 | grad norm avg: 9.02 | grad norm last: 11.31 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_374000-seen_tokens_191488000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_374000-seen_tokens_191488000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_374000-seen_tokens_191488000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_374000-seen_tokens_191488000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_374000-seen_tokens_191488000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_374000-seen_tokens_191488000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_374000-seen_tokens_191488000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_374000-seen_tokens_191488000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:11:55 | step: 374100 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 7.426410593325272e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 3.27 | consumed tokens: 191539200.0 | grad norm avg: 8.92 | grad norm last: 7.63 | 
2025-12-28T01:11:57 | step: 374200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 7.425148942274973e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.88 | consumed tokens: 191590400.0 | grad norm avg: 9.22 | grad norm last: 8.26 | 
2025-12-28T01:11:59 | step: 374300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 7.423887291224673e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.73 | consumed tokens: 191641600.0 | grad norm avg: 9.23 | grad norm last: 9.37 | 
2025-12-28T01:12:01 | step: 374400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.422625640174374e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.22 | consumed tokens: 191692800.0 | grad norm avg: 8.98 | grad norm last: 8.12 | 
2025-12-28T01:12:03 | step: 374500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.421363989124075e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 5.56 | consumed tokens: 191744000.0 | grad norm avg: 9.32 | grad norm last: 8.43 | 
2025-12-28T01:12:05 | step: 374600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.420102338073775e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.8 | consumed tokens: 191795200.0 | grad norm avg: 8.71 | grad norm last: 11.19 | 
2025-12-28T01:12:07 | step: 374700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.418839959427714e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.58 | consumed tokens: 191846400.0 | grad norm avg: 8.96 | grad norm last: 8.54 | 
2025-12-28T01:12:09 | step: 374800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 7.417577580781654e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.69 | consumed tokens: 191897600.0 | grad norm avg: 9.0 | grad norm last: 11.57 | 
2025-12-28T01:12:11 | step: 374900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.416315202135593e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.93 | train loss last: 3.66 | consumed tokens: 191948800.0 | grad norm avg: 9.52 | grad norm last: 7.41 | 
2025-12-28T01:12:13 | step: 375000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.41505209589377e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.42 | consumed tokens: 192000000.0 | grad norm avg: 9.25 | grad norm last: 7.85 | 
2025-12-28T01:12:15 | step: 375100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.413788989651948e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 2.73 | consumed tokens: 192051200.0 | grad norm avg: 9.45 | grad norm last: 13.41 | 
2025-12-28T01:12:17 | step: 375200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.412525883410126e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.64 | consumed tokens: 192102400.0 | grad norm avg: 9.3 | grad norm last: 9.3 | 
2025-12-28T01:12:19 | step: 375300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.411262777168304e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.56 | consumed tokens: 192153600.0 | grad norm avg: 9.35 | grad norm last: 8.44 | 
2025-12-28T01:12:21 | step: 375400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.40999894333072e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.09 | consumed tokens: 192204800.0 | grad norm avg: 9.1 | grad norm last: 10.87 | 
2025-12-28T01:12:23 | step: 375500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.408735837088898e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.67 | consumed tokens: 192256000.0 | grad norm avg: 9.03 | grad norm last: 9.75 | 
2025-12-28T01:12:25 | step: 375600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.407472003251314e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.3 | consumed tokens: 192307200.0 | grad norm avg: 8.83 | grad norm last: 7.89 | 
2025-12-28T01:12:27 | step: 375700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.406207441817969e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.44 | consumed tokens: 192358400.0 | grad norm avg: 9.07 | grad norm last: 7.88 | 
2025-12-28T01:12:29 | step: 375800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.404943607980385e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.75 | consumed tokens: 192409600.0 | grad norm avg: 9.28 | grad norm last: 9.43 | 
2025-12-28T01:12:31 | step: 375900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.40367904654704e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.7 | consumed tokens: 192460800.0 | grad norm avg: 9.21 | grad norm last: 8.42 | 
2025-12-28T01:12:33 | step: 376000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.402414485113695e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.03 | consumed tokens: 192512000.0 | grad norm avg: 9.36 | grad norm last: 9.44 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_376000-seen_tokens_192512000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_376000-seen_tokens_192512000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_376000-seen_tokens_192512000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_376000-seen_tokens_192512000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_376000-seen_tokens_192512000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_376000-seen_tokens_192512000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_376000-seen_tokens_192512000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_376000-seen_tokens_192512000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:12:36 | step: 376100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.40114992368035e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.53 | consumed tokens: 192563200.0 | grad norm avg: 8.92 | grad norm last: 8.36 | 
2025-12-28T01:12:38 | step: 376200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.399884634651244e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.53 | consumed tokens: 192614400.0 | grad norm avg: 9.0 | grad norm last: 8.76 | 
2025-12-28T01:12:40 | step: 376300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.398619345622137e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.77 | consumed tokens: 192665600.0 | grad norm avg: 10.91 | grad norm last: 8.06 | 
2025-12-28T01:12:42 | step: 376400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.397354056593031e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.2 | consumed tokens: 192716800.0 | grad norm avg: 8.92 | grad norm last: 7.5 | 
2025-12-28T01:12:44 | step: 376500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.396088767563924e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.41 | consumed tokens: 192768000.0 | grad norm avg: 9.0 | grad norm last: 7.53 | 
2025-12-28T01:12:46 | step: 376600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.394822750939056e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.72 | consumed tokens: 192819200.0 | grad norm avg: 9.1 | grad norm last: 8.72 | 
2025-12-28T01:12:48 | step: 376700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.39355746190995e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.06 | consumed tokens: 192870400.0 | grad norm avg: 9.29 | grad norm last: 9.1 | 
2025-12-28T01:12:50 | step: 376800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.392291445285082e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.52 | consumed tokens: 192921600.0 | grad norm avg: 9.22 | grad norm last: 8.6 | 
2025-12-28T01:12:52 | step: 376900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.391024701064453e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 2.98 | consumed tokens: 192972800.0 | grad norm avg: 9.56 | grad norm last: 7.5 | 
2025-12-28T01:12:54 | step: 377000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.389758684439585e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.94 | consumed tokens: 193024000.0 | grad norm avg: 9.4 | grad norm last: 7.9 | 
2025-12-28T01:12:56 | step: 377100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.388491940218955e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 2.78 | consumed tokens: 193075200.0 | grad norm avg: 9.08 | grad norm last: 7.67 | 
2025-12-28T01:12:58 | step: 377200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 7.387225195998326e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.66 | consumed tokens: 193126400.0 | grad norm avg: 9.11 | grad norm last: 9.55 | 
2025-12-28T01:13:00 | step: 377300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 7.385958451777697e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 2.55 | consumed tokens: 193177600.0 | grad norm avg: 9.12 | grad norm last: 7.79 | 
2025-12-28T01:13:02 | step: 377400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.384690979961306e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.81 | consumed tokens: 193228800.0 | grad norm avg: 9.2 | grad norm last: 9.22 | 
2025-12-28T01:13:04 | step: 377500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.383423508144915e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.91 | consumed tokens: 193280000.0 | grad norm avg: 9.3 | grad norm last: 7.57 | 
2025-12-28T01:13:06 | step: 377600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.382156036328524e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.5 | consumed tokens: 193331200.0 | grad norm avg: 9.21 | grad norm last: 9.05 | 
2025-12-28T01:13:08 | step: 377700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.380888564512134e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.62 | consumed tokens: 193382400.0 | grad norm avg: 9.22 | grad norm last: 9.22 | 
2025-12-28T01:13:10 | step: 377800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.379620365099981e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.12 | consumed tokens: 193433600.0 | grad norm avg: 9.47 | grad norm last: 11.47 | 
2025-12-28T01:13:12 | step: 377900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.37835289328359e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.41 | consumed tokens: 193484800.0 | grad norm avg: 9.14 | grad norm last: 8.81 | 
2025-12-28T01:13:14 | step: 378000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.377083966275677e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.56 | consumed tokens: 193536000.0 | grad norm avg: 9.78 | grad norm last: 21.51 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_378000-seen_tokens_193536000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_378000-seen_tokens_193536000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_378000-seen_tokens_193536000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_378000-seen_tokens_193536000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_378000-seen_tokens_193536000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_378000-seen_tokens_193536000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_378000-seen_tokens_193536000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_378000-seen_tokens_193536000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:13:16 | step: 378100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.375815766863525e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.77 | train loss last: 5.75 | consumed tokens: 193587200.0 | grad norm avg: 9.17 | grad norm last: 12.18 | 
2025-12-28T01:13:18 | step: 378200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.374547567451373e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.38 | consumed tokens: 193638400.0 | grad norm avg: 9.1 | grad norm last: 7.77 | 
2025-12-28T01:13:20 | step: 378300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.373278640443459e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 5.09 | consumed tokens: 193689600.0 | grad norm avg: 9.65 | grad norm last: 10.16 | 
2025-12-28T01:13:22 | step: 378400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.372009713435546e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 5.06 | consumed tokens: 193740800.0 | grad norm avg: 9.3 | grad norm last: 17.32 | 
2025-12-28T01:13:24 | step: 378500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.370740786427632e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.58 | consumed tokens: 193792000.0 | grad norm avg: 9.16 | grad norm last: 8.96 | 
2025-12-28T01:13:26 | step: 378600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.369471131823957e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.03 | consumed tokens: 193843200.0 | grad norm avg: 9.47 | grad norm last: 8.77 | 
2025-12-28T01:13:28 | step: 378700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.368201477220282e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.42 | consumed tokens: 193894400.0 | grad norm avg: 9.7 | grad norm last: 8.23 | 
2025-12-28T01:13:30 | step: 378800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.366931822616607e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.22 | consumed tokens: 193945600.0 | grad norm avg: 9.41 | grad norm last: 7.73 | 
2025-12-28T01:13:32 | step: 378900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.365662168012932e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.09 | consumed tokens: 193996800.0 | grad norm avg: 9.69 | grad norm last: 7.63 | 
2025-12-28T01:13:35 | step: 379000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 7.364391785813496e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 2.94 | consumed tokens: 194048000.0 | grad norm avg: 9.36 | grad norm last: 8.87 | 
2025-12-28T01:13:37 | step: 379100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 7.36312213120982e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.28 | consumed tokens: 194099200.0 | grad norm avg: 9.72 | grad norm last: 7.66 | 
2025-12-28T01:13:39 | step: 379200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 7.361851749010384e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.25 | consumed tokens: 194150400.0 | grad norm avg: 9.78 | grad norm last: 9.15 | 
2025-12-28T01:13:41 | step: 379300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.360580639215186e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.5 | consumed tokens: 194201600.0 | grad norm avg: 9.55 | grad norm last: 12.46 | 
2025-12-28T01:13:43 | step: 379400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.35931025701575e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.83 | consumed tokens: 194252800.0 | grad norm avg: 9.91 | grad norm last: 8.68 | 
2025-12-28T01:13:45 | step: 379500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.358039147220552e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.33 | consumed tokens: 194304000.0 | grad norm avg: 9.37 | grad norm last: 8.02 | 
2025-12-28T01:13:47 | step: 379600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.356768037425354e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.22 | consumed tokens: 194355200.0 | grad norm avg: 9.85 | grad norm last: 7.89 | 
2025-12-28T01:13:49 | step: 379700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.355496927630156e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 4.31 | consumed tokens: 194406400.0 | grad norm avg: 9.89 | grad norm last: 8.28 | 
2025-12-28T01:13:51 | step: 379800 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 7.354225090239197e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.89 | consumed tokens: 194457600.0 | grad norm avg: 10.23 | grad norm last: 12.96 | 
2025-12-28T01:13:53 | step: 379900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 7.352953980443999e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.34 | consumed tokens: 194508800.0 | grad norm avg: 9.57 | grad norm last: 9.35 | 
2025-12-28T01:13:55 | step: 380000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 7.35168214305304e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.75 | consumed tokens: 194560000.0 | grad norm avg: 9.48 | grad norm last: 7.68 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_380000-seen_tokens_194560000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_380000-seen_tokens_194560000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_380000-seen_tokens_194560000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_380000-seen_tokens_194560000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_380000-seen_tokens_194560000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_380000-seen_tokens_194560000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_380000-seen_tokens_194560000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_380000-seen_tokens_194560000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:13:57 | step: 380100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.35041030566208e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.42 | consumed tokens: 194611200.0 | grad norm avg: 9.54 | grad norm last: 8.02 | 
2025-12-28T01:13:59 | step: 380200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.34913774067536e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.09 | consumed tokens: 194662400.0 | grad norm avg: 9.29 | grad norm last: 10.07 | 
2025-12-28T01:14:01 | step: 380300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.347865175688639e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.03 | consumed tokens: 194713600.0 | grad norm avg: 9.41 | grad norm last: 10.75 | 
2025-12-28T01:14:03 | step: 380400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.346592610701919e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.06 | consumed tokens: 194764800.0 | grad norm avg: 9.85 | grad norm last: 8.87 | 
2025-12-28T01:14:05 | step: 380500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 7.345320045715198e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 6.09 | consumed tokens: 194816000.0 | grad norm avg: 9.56 | grad norm last: 28.92 | 
2025-12-28T01:14:07 | step: 380600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.344047480728477e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 2.86 | consumed tokens: 194867200.0 | grad norm avg: 9.89 | grad norm last: 8.68 | 
2025-12-28T01:14:09 | step: 380700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.342774188145995e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.27 | consumed tokens: 194918400.0 | grad norm avg: 9.33 | grad norm last: 7.61 | 
2025-12-28T01:14:11 | step: 380800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.341500895563513e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.08 | consumed tokens: 194969600.0 | grad norm avg: 9.15 | grad norm last: 8.71 | 
2025-12-28T01:14:13 | step: 380900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.340227602981031e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.23 | consumed tokens: 195020800.0 | grad norm avg: 9.46 | grad norm last: 7.86 | 
2025-12-28T01:14:15 | step: 381000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.338954310398549e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.06 | consumed tokens: 195072000.0 | grad norm avg: 9.15 | grad norm last: 7.71 | 
2025-12-28T01:14:17 | step: 381100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.337680290220305e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 5.0 | consumed tokens: 195123200.0 | grad norm avg: 8.98 | grad norm last: 10.94 | 
2025-12-28T01:14:19 | step: 381200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.336406270042062e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.34 | consumed tokens: 195174400.0 | grad norm avg: 9.97 | grad norm last: 12.28 | 
2025-12-28T01:14:21 | step: 381300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.335132249863818e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.59 | consumed tokens: 195225600.0 | grad norm avg: 9.14 | grad norm last: 9.19 | 
2025-12-28T01:14:23 | step: 381400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.333858229685575e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.41 | consumed tokens: 195276800.0 | grad norm avg: 9.78 | grad norm last: 8.94 | 
2025-12-28T01:14:25 | step: 381500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.33258348191157e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.47 | consumed tokens: 195328000.0 | grad norm avg: 9.76 | grad norm last: 14.06 | 
2025-12-28T01:14:27 | step: 381600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.331308734137565e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.66 | consumed tokens: 195379200.0 | grad norm avg: 9.37 | grad norm last: 9.85 | 
2025-12-28T01:14:29 | step: 381700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.33003398636356e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.59 | consumed tokens: 195430400.0 | grad norm avg: 9.29 | grad norm last: 8.45 | 
2025-12-28T01:14:31 | step: 381800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.328759238589555e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.09 | consumed tokens: 195481600.0 | grad norm avg: 9.65 | grad norm last: 8.29 | 
2025-12-28T01:14:34 | step: 381900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.327483763219789e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.75 | consumed tokens: 195532800.0 | grad norm avg: 9.37 | grad norm last: 8.09 | 
2025-12-28T01:14:36 | step: 382000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 7.326208287850022e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.5 | consumed tokens: 195584000.0 | grad norm avg: 9.9 | grad norm last: 10.19 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_382000-seen_tokens_195584000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_382000-seen_tokens_195584000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_382000-seen_tokens_195584000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_382000-seen_tokens_195584000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_382000-seen_tokens_195584000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_382000-seen_tokens_195584000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_382000-seen_tokens_195584000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_382000-seen_tokens_195584000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:14:38 | step: 382100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.324932812480256e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.69 | train loss last: 4.06 | consumed tokens: 195635200.0 | grad norm avg: 9.02 | grad norm last: 11.36 | 
2025-12-28T01:14:40 | step: 382200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.32365733711049e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.92 | consumed tokens: 195686400.0 | grad norm avg: 9.05 | grad norm last: 8.44 | 
2025-12-28T01:14:42 | step: 382300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.322381134144962e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.22 | consumed tokens: 195737600.0 | grad norm avg: 9.3 | grad norm last: 8.35 | 
2025-12-28T01:14:44 | step: 382400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.321104931179434e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.73 | consumed tokens: 195788800.0 | grad norm avg: 8.98 | grad norm last: 7.97 | 
2025-12-28T01:14:46 | step: 382500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 7.319828728213906e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.2 | consumed tokens: 195840000.0 | grad norm avg: 9.3 | grad norm last: 7.86 | 
2025-12-28T01:14:48 | step: 382600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 7.318552525248379e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.06 | consumed tokens: 195891200.0 | grad norm avg: 9.31 | grad norm last: 7.4 | 
2025-12-28T01:14:50 | step: 382700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.317276322282851e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 6.69 | consumed tokens: 195942400.0 | grad norm avg: 9.1 | grad norm last: 24.42 | 
2025-12-28T01:14:52 | step: 382800 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 7.315999391721562e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.53 | consumed tokens: 195993600.0 | grad norm avg: 9.52 | grad norm last: 9.22 | 
2025-12-28T01:14:54 | step: 382900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.314722461160272e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.22 | consumed tokens: 196044800.0 | grad norm avg: 8.96 | grad norm last: 9.66 | 
2025-12-28T01:14:56 | step: 383000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 7.313445530598983e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 5.09 | consumed tokens: 196096000.0 | grad norm avg: 9.83 | grad norm last: 15.37 | 
2025-12-28T01:14:58 | step: 383100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.312167872441933e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.34 | consumed tokens: 196147200.0 | grad norm avg: 9.38 | grad norm last: 10.29 | 
2025-12-28T01:15:00 | step: 383200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.310890214284882e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.67 | consumed tokens: 196198400.0 | grad norm avg: 9.63 | grad norm last: 8.01 | 
2025-12-28T01:15:02 | step: 383300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.309612556127831e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.22 | consumed tokens: 196249600.0 | grad norm avg: 9.01 | grad norm last: 7.96 | 
2025-12-28T01:15:04 | step: 383400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.308334897970781e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.28 | consumed tokens: 196300800.0 | grad norm avg: 9.3 | grad norm last: 9.85 | 
2025-12-28T01:15:06 | step: 383500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.30705723981373e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.47 | consumed tokens: 196352000.0 | grad norm avg: 9.53 | grad norm last: 8.3 | 
2025-12-28T01:15:08 | step: 383600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.305778854060918e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.69 | consumed tokens: 196403200.0 | grad norm avg: 9.63 | grad norm last: 8.54 | 
2025-12-28T01:15:10 | step: 383700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.304500468308106e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.64 | consumed tokens: 196454400.0 | grad norm avg: 9.44 | grad norm last: 8.44 | 
2025-12-28T01:15:12 | step: 383800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.303222082555294e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.53 | consumed tokens: 196505600.0 | grad norm avg: 9.42 | grad norm last: 7.61 | 
2025-12-28T01:15:14 | step: 383900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.301943696802482e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.94 | consumed tokens: 196556800.0 | grad norm avg: 9.14 | grad norm last: 9.39 | 
2025-12-28T01:15:16 | step: 384000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.300664583453909e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.89 | consumed tokens: 196608000.0 | grad norm avg: 9.78 | grad norm last: 9.32 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_384000-seen_tokens_196608000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_384000-seen_tokens_196608000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_384000-seen_tokens_196608000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_384000-seen_tokens_196608000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_384000-seen_tokens_196608000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_384000-seen_tokens_196608000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_384000-seen_tokens_196608000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_384000-seen_tokens_196608000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:15:19 | step: 384100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.299385470105335e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.28 | consumed tokens: 196659200.0 | grad norm avg: 9.75 | grad norm last: 8.75 | 
2025-12-28T01:15:21 | step: 384200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.298106356756762e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.12 | consumed tokens: 196710400.0 | grad norm avg: 8.92 | grad norm last: 10.14 | 
2025-12-28T01:15:23 | step: 384300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.296827243408188e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.28 | consumed tokens: 196761600.0 | grad norm avg: 9.38 | grad norm last: 11.05 | 
2025-12-28T01:15:25 | step: 384400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.295547402463853e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.64 | consumed tokens: 196812800.0 | grad norm avg: 9.45 | grad norm last: 9.71 | 
2025-12-28T01:15:27 | step: 384500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 7.294267561519518e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.75 | consumed tokens: 196864000.0 | grad norm avg: 9.49 | grad norm last: 8.94 | 
2025-12-28T01:15:29 | step: 384600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 7.292987720575184e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.67 | consumed tokens: 196915200.0 | grad norm avg: 9.42 | grad norm last: 8.97 | 
2025-12-28T01:15:31 | step: 384700 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 7.291707879630849e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.86 | consumed tokens: 196966400.0 | grad norm avg: 9.18 | grad norm last: 9.34 | 
2025-12-28T01:15:33 | step: 384800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.290427311090752e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.94 | consumed tokens: 197017600.0 | grad norm avg: 8.86 | grad norm last: 10.89 | 
2025-12-28T01:15:35 | step: 384900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.289147470146418e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.39 | consumed tokens: 197068800.0 | grad norm avg: 9.43 | grad norm last: 9.11 | 
2025-12-28T01:15:37 | step: 385000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.287866901606321e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.5 | consumed tokens: 197120000.0 | grad norm avg: 9.79 | grad norm last: 10.59 | 
2025-12-28T01:15:39 | step: 385100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.286585605470464e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.28 | consumed tokens: 197171200.0 | grad norm avg: 9.79 | grad norm last: 11.69 | 
2025-12-28T01:15:41 | step: 385200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.285305036930367e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.64 | consumed tokens: 197222400.0 | grad norm avg: 9.13 | grad norm last: 10.47 | 
2025-12-28T01:15:43 | step: 385300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 7.28402374079451e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.08 | consumed tokens: 197273600.0 | grad norm avg: 9.1 | grad norm last: 8.92 | 
2025-12-28T01:15:45 | step: 385400 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 7.282742444658652e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.42 | consumed tokens: 197324800.0 | grad norm avg: 9.11 | grad norm last: 8.51 | 
2025-12-28T01:15:47 | step: 385500 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 7.281461148522794e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.33 | consumed tokens: 197376000.0 | grad norm avg: 9.15 | grad norm last: 7.73 | 
2025-12-28T01:15:49 | step: 385600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 7.280179852386937e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.83 | consumed tokens: 197427200.0 | grad norm avg: 9.58 | grad norm last: 11.47 | 
2025-12-28T01:15:51 | step: 385700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.278897828655317e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.5 | consumed tokens: 197478400.0 | grad norm avg: 8.87 | grad norm last: 7.73 | 
2025-12-28T01:15:53 | step: 385800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.277615804923698e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.25 | consumed tokens: 197529600.0 | grad norm avg: 9.28 | grad norm last: 9.43 | 
2025-12-28T01:15:55 | step: 385900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.276333781192079e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.17 | consumed tokens: 197580800.0 | grad norm avg: 9.28 | grad norm last: 7.42 | 
2025-12-28T01:15:57 | step: 386000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.27505175746046e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.14 | consumed tokens: 197632000.0 | grad norm avg: 9.09 | grad norm last: 7.84 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_386000-seen_tokens_197632000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_386000-seen_tokens_197632000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_386000-seen_tokens_197632000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_386000-seen_tokens_197632000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_386000-seen_tokens_197632000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_386000-seen_tokens_197632000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_386000-seen_tokens_197632000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_386000-seen_tokens_197632000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:16:00 | step: 386100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.27376900613308e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.72 | consumed tokens: 197683200.0 | grad norm avg: 9.13 | grad norm last: 7.59 | 
2025-12-28T01:16:02 | step: 386200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.272486254805699e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.62 | consumed tokens: 197734400.0 | grad norm avg: 9.8 | grad norm last: 8.44 | 
2025-12-28T01:16:04 | step: 386300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.271203503478318e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.78 | consumed tokens: 197785600.0 | grad norm avg: 8.89 | grad norm last: 9.08 | 
2025-12-28T01:16:06 | step: 386400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.269920752150938e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.16 | consumed tokens: 197836800.0 | grad norm avg: 9.59 | grad norm last: 9.26 | 
2025-12-28T01:16:08 | step: 386500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.268637273227796e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 2.91 | consumed tokens: 197888000.0 | grad norm avg: 9.19 | grad norm last: 7.84 | 
2025-12-28T01:16:10 | step: 386600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.267354521900415e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.44 | consumed tokens: 197939200.0 | grad norm avg: 8.93 | grad norm last: 10.11 | 
2025-12-28T01:16:12 | step: 386700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.266071042977273e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.06 | consumed tokens: 197990400.0 | grad norm avg: 9.11 | grad norm last: 9.46 | 
2025-12-28T01:16:14 | step: 386800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.26478683645837e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.38 | consumed tokens: 198041600.0 | grad norm avg: 8.97 | grad norm last: 8.56 | 
2025-12-28T01:16:16 | step: 386900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.263503357535228e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 5.78 | consumed tokens: 198092800.0 | grad norm avg: 9.05 | grad norm last: 11.87 | 
2025-12-28T01:16:18 | step: 387000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.262219151016325e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.53 | consumed tokens: 198144000.0 | grad norm avg: 8.99 | grad norm last: 8.64 | 
2025-12-28T01:16:20 | step: 387100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.260934944497421e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.7 | consumed tokens: 198195200.0 | grad norm avg: 9.25 | grad norm last: 9.37 | 
2025-12-28T01:16:22 | step: 387200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.259650737978518e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.5 | consumed tokens: 198246400.0 | grad norm avg: 9.14 | grad norm last: 7.87 | 
2025-12-28T01:16:24 | step: 387300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.258366531459615e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.7 | consumed tokens: 198297600.0 | grad norm avg: 9.44 | grad norm last: 8.2 | 
2025-12-28T01:16:26 | step: 387400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 7.25708159734495e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.95 | consumed tokens: 198348800.0 | grad norm avg: 9.07 | grad norm last: 8.21 | 
2025-12-28T01:16:28 | step: 387500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.255796663230285e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.34 | consumed tokens: 198400000.0 | grad norm avg: 9.78 | grad norm last: 8.08 | 
2025-12-28T01:16:30 | step: 387600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 7.25451172911562e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.0 | consumed tokens: 198451200.0 | grad norm avg: 9.18 | grad norm last: 9.64 | 
2025-12-28T01:16:32 | step: 387700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.253226795000955e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 4.81 | consumed tokens: 198502400.0 | grad norm avg: 9.49 | grad norm last: 10.83 | 
2025-12-28T01:16:34 | step: 387800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.251941133290529e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.34 | consumed tokens: 198553600.0 | grad norm avg: 9.16 | grad norm last: 10.02 | 
2025-12-28T01:16:36 | step: 387900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.250656199175864e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.06 | consumed tokens: 198604800.0 | grad norm avg: 8.97 | grad norm last: 8.61 | 
2025-12-28T01:16:38 | step: 388000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.249370537465438e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 6.03 | consumed tokens: 198656000.0 | grad norm avg: 10.15 | grad norm last: 21.86 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_388000-seen_tokens_198656000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_388000-seen_tokens_198656000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_388000-seen_tokens_198656000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_388000-seen_tokens_198656000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_388000-seen_tokens_198656000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_388000-seen_tokens_198656000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_388000-seen_tokens_198656000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_388000-seen_tokens_198656000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:16:40 | step: 388100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.24808414815925e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 4.0 | consumed tokens: 198707200.0 | grad norm avg: 9.08 | grad norm last: 8.83 | 
2025-12-28T01:16:42 | step: 388200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.246798486448824e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.58 | consumed tokens: 198758400.0 | grad norm avg: 9.01 | grad norm last: 7.68 | 
2025-12-28T01:16:44 | step: 388300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.245512097142637e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.64 | consumed tokens: 198809600.0 | grad norm avg: 9.07 | grad norm last: 9.14 | 
2025-12-28T01:16:46 | step: 388400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.244225707836449e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.59 | consumed tokens: 198860800.0 | grad norm avg: 10.01 | grad norm last: 9.49 | 
2025-12-28T01:16:48 | step: 388500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.242939318530262e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.55 | consumed tokens: 198912000.0 | grad norm avg: 9.08 | grad norm last: 8.01 | 
2025-12-28T01:16:50 | step: 388600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.241652929224074e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.02 | consumed tokens: 198963200.0 | grad norm avg: 9.19 | grad norm last: 7.65 | 
2025-12-28T01:16:52 | step: 388700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.240365812322125e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.97 | consumed tokens: 199014400.0 | grad norm avg: 9.22 | grad norm last: 10.06 | 
2025-12-28T01:16:54 | step: 388800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.239078695420176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.2 | consumed tokens: 199065600.0 | grad norm avg: 9.27 | grad norm last: 7.57 | 
2025-12-28T01:16:56 | step: 388900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.237791578518227e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 5.41 | consumed tokens: 199116800.0 | grad norm avg: 9.65 | grad norm last: 18.86 | 
2025-12-28T01:16:58 | step: 389000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.236504461616278e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.7 | consumed tokens: 199168000.0 | grad norm avg: 9.09 | grad norm last: 8.15 | 
2025-12-28T01:17:00 | step: 389100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.235216617118567e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.03 | consumed tokens: 199219200.0 | grad norm avg: 9.37 | grad norm last: 10.64 | 
2025-12-28T01:17:02 | step: 389200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.233928772620857e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.36 | consumed tokens: 199270400.0 | grad norm avg: 9.25 | grad norm last: 8.78 | 
2025-12-28T01:17:04 | step: 389300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.232640928123146e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.91 | consumed tokens: 199321600.0 | grad norm avg: 9.06 | grad norm last: 8.41 | 
2025-12-28T01:17:06 | step: 389400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.231353083625436e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.22 | consumed tokens: 199372800.0 | grad norm avg: 9.49 | grad norm last: 8.33 | 
2025-12-28T01:17:09 | step: 389500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.230065239127725e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.72 | consumed tokens: 199424000.0 | grad norm avg: 8.93 | grad norm last: 9.64 | 
2025-12-28T01:17:11 | step: 389600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.228776667034253e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.0 | consumed tokens: 199475200.0 | grad norm avg: 9.66 | grad norm last: 8.06 | 
2025-12-28T01:17:13 | step: 389700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.227488094940782e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.83 | consumed tokens: 199526400.0 | grad norm avg: 9.16 | grad norm last: 9.53 | 
2025-12-28T01:17:15 | step: 389800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.22619952284731e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.5 | consumed tokens: 199577600.0 | grad norm avg: 9.57 | grad norm last: 10.19 | 
2025-12-28T01:17:17 | step: 389900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.224910223158076e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.28 | consumed tokens: 199628800.0 | grad norm avg: 9.3 | grad norm last: 7.89 | 
2025-12-28T01:17:19 | step: 390000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.223621651064605e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.52 | consumed tokens: 199680000.0 | grad norm avg: 8.91 | grad norm last: 8.43 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_390000-seen_tokens_199680000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_390000-seen_tokens_199680000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_390000-seen_tokens_199680000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_390000-seen_tokens_199680000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_390000-seen_tokens_199680000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_390000-seen_tokens_199680000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_390000-seen_tokens_199680000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_390000-seen_tokens_199680000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:17:21 | step: 390100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.222332351375371e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.33 | consumed tokens: 199731200.0 | grad norm avg: 9.57 | grad norm last: 8.22 | 
2025-12-28T01:17:23 | step: 390200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.221043051686138e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.5 | consumed tokens: 199782400.0 | grad norm avg: 9.42 | grad norm last: 9.64 | 
2025-12-28T01:17:25 | step: 390300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.219753751996905e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.16 | consumed tokens: 199833600.0 | grad norm avg: 9.2 | grad norm last: 8.39 | 
2025-12-28T01:17:27 | step: 390400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 7.21846372471191e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.86 | consumed tokens: 199884800.0 | grad norm avg: 8.91 | grad norm last: 8.62 | 
2025-12-28T01:17:29 | step: 390500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 7.217173697426915e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.42 | consumed tokens: 199936000.0 | grad norm avg: 9.42 | grad norm last: 9.0 | 
2025-12-28T01:17:31 | step: 390600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 7.21588367014192e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.44 | consumed tokens: 199987200.0 | grad norm avg: 8.96 | grad norm last: 8.19 | 
2025-12-28T01:17:33 | step: 390700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.214593642856926e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.69 | consumed tokens: 200038400.0 | grad norm avg: 9.4 | grad norm last: 8.35 | 
2025-12-28T01:17:35 | step: 390800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.213303615571931e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.88 | consumed tokens: 200089600.0 | grad norm avg: 9.28 | grad norm last: 8.48 | 
2025-12-28T01:17:37 | step: 390900 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 7.212012860691175e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.62 | consumed tokens: 200140800.0 | grad norm avg: 9.62 | grad norm last: 7.51 | 
2025-12-28T01:17:39 | step: 391000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 7.210722105810419e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.25 | consumed tokens: 200192000.0 | grad norm avg: 9.69 | grad norm last: 8.76 | 
2025-12-28T01:17:41 | step: 391100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 7.209431350929663e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.34 | consumed tokens: 200243200.0 | grad norm avg: 9.28 | grad norm last: 8.74 | 
2025-12-28T01:17:43 | step: 391200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.208140596048906e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 2.69 | consumed tokens: 200294400.0 | grad norm avg: 8.81 | grad norm last: 7.66 | 
2025-12-28T01:17:45 | step: 391300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.206849113572389e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.3 | consumed tokens: 200345600.0 | grad norm avg: 9.54 | grad norm last: 7.79 | 
2025-12-28T01:17:47 | step: 391400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.205557631095871e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.62 | consumed tokens: 200396800.0 | grad norm avg: 9.28 | grad norm last: 9.63 | 
2025-12-28T01:17:49 | step: 391500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.204266148619354e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.06 | consumed tokens: 200448000.0 | grad norm avg: 9.46 | grad norm last: 10.47 | 
2025-12-28T01:17:51 | step: 391600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.202974666142836e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.19 | consumed tokens: 200499200.0 | grad norm avg: 9.23 | grad norm last: 9.13 | 
2025-12-28T01:17:53 | step: 391700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 7.201683183666319e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.72 | consumed tokens: 200550400.0 | grad norm avg: 8.97 | grad norm last: 7.83 | 
2025-12-28T01:17:55 | step: 391800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 7.20039097359404e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.5 | consumed tokens: 200601600.0 | grad norm avg: 8.86 | grad norm last: 7.98 | 
2025-12-28T01:17:57 | step: 391900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.199098763521761e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.06 | consumed tokens: 200652800.0 | grad norm avg: 9.08 | grad norm last: 8.46 | 
2025-12-28T01:17:59 | step: 392000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.197806553449482e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.22 | consumed tokens: 200704000.0 | grad norm avg: 9.21 | grad norm last: 8.52 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_392000-seen_tokens_200704000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_392000-seen_tokens_200704000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_392000-seen_tokens_200704000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_392000-seen_tokens_200704000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_392000-seen_tokens_200704000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_392000-seen_tokens_200704000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_392000-seen_tokens_200704000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_392000-seen_tokens_200704000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:18:02 | step: 392100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.196514343377203e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.78 | train loss last: 3.34 | consumed tokens: 200755200.0 | grad norm avg: 8.98 | grad norm last: 7.62 | 
2025-12-28T01:18:04 | step: 392200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.195221405709162e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 2.88 | consumed tokens: 200806400.0 | grad norm avg: 8.78 | grad norm last: 7.78 | 
2025-12-28T01:18:06 | step: 392300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.193928468041122e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 2.83 | consumed tokens: 200857600.0 | grad norm avg: 9.07 | grad norm last: 7.82 | 
2025-12-28T01:18:08 | step: 392400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.192635530373082e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.34 | consumed tokens: 200908800.0 | grad norm avg: 9.38 | grad norm last: 8.68 | 
2025-12-28T01:18:10 | step: 392500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.191342592705041e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.55 | consumed tokens: 200960000.0 | grad norm avg: 9.06 | grad norm last: 8.55 | 
2025-12-28T01:18:12 | step: 392600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.19004892744124e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.5 | consumed tokens: 201011200.0 | grad norm avg: 9.06 | grad norm last: 10.91 | 
2025-12-28T01:18:14 | step: 392700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 7.188755989773199e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.64 | consumed tokens: 201062400.0 | grad norm avg: 9.44 | grad norm last: 9.25 | 
2025-12-28T01:18:16 | step: 392800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 7.187462324509397e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.23 | consumed tokens: 201113600.0 | grad norm avg: 9.27 | grad norm last: 8.16 | 
2025-12-28T01:18:18 | step: 392900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 7.186168659245595e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.38 | consumed tokens: 201164800.0 | grad norm avg: 9.36 | grad norm last: 10.16 | 
2025-12-28T01:18:20 | step: 393000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.184874266386032e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.03 | consumed tokens: 201216000.0 | grad norm avg: 8.93 | grad norm last: 8.82 | 
2025-12-28T01:18:22 | step: 393100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.18358060112223e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.81 | consumed tokens: 201267200.0 | grad norm avg: 9.14 | grad norm last: 8.84 | 
2025-12-28T01:18:24 | step: 393200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.182286208262667e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.92 | consumed tokens: 201318400.0 | grad norm avg: 8.84 | grad norm last: 7.61 | 
2025-12-28T01:18:26 | step: 393300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.180991815403104e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.53 | consumed tokens: 201369600.0 | grad norm avg: 9.15 | grad norm last: 9.08 | 
2025-12-28T01:18:28 | step: 393400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.17969742254354e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 2.69 | consumed tokens: 201420800.0 | grad norm avg: 9.28 | grad norm last: 7.33 | 
2025-12-28T01:18:30 | step: 393500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.178402302088216e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.86 | consumed tokens: 201472000.0 | grad norm avg: 9.27 | grad norm last: 9.11 | 
2025-12-28T01:18:32 | step: 393600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.177107181632891e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.58 | consumed tokens: 201523200.0 | grad norm avg: 9.39 | grad norm last: 8.11 | 
2025-12-28T01:18:34 | step: 393700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.175812788773328e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.61 | consumed tokens: 201574400.0 | grad norm avg: 9.05 | grad norm last: 8.82 | 
2025-12-28T01:18:36 | step: 393800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.174516940722242e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.06 | consumed tokens: 201625600.0 | grad norm avg: 9.75 | grad norm last: 13.11 | 
2025-12-28T01:18:38 | step: 393900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.173221820266917e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 5.5 | consumed tokens: 201676800.0 | grad norm avg: 9.09 | grad norm last: 11.35 | 
2025-12-28T01:18:40 | step: 394000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.171925972215831e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 2.97 | consumed tokens: 201728000.0 | grad norm avg: 9.71 | grad norm last: 8.24 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_394000-seen_tokens_201728000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_394000-seen_tokens_201728000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_394000-seen_tokens_201728000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_394000-seen_tokens_201728000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_394000-seen_tokens_201728000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_394000-seen_tokens_201728000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_394000-seen_tokens_201728000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_394000-seen_tokens_201728000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:18:43 | step: 394100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.170630851760507e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 5.12 | consumed tokens: 201779200.0 | grad norm avg: 9.17 | grad norm last: 10.52 | 
2025-12-28T01:18:45 | step: 394200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.16933500370942e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.34 | consumed tokens: 201830400.0 | grad norm avg: 9.5 | grad norm last: 7.36 | 
2025-12-28T01:18:47 | step: 394300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.168038428062573e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.14 | consumed tokens: 201881600.0 | grad norm avg: 8.93 | grad norm last: 7.63 | 
2025-12-28T01:18:49 | step: 394400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.166742580011487e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.72 | consumed tokens: 201932800.0 | grad norm avg: 9.07 | grad norm last: 7.66 | 
2025-12-28T01:18:51 | step: 394500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.16544600436464e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.89 | consumed tokens: 201984000.0 | grad norm avg: 9.44 | grad norm last: 8.5 | 
2025-12-28T01:18:53 | step: 394600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.164149428717792e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.11 | consumed tokens: 202035200.0 | grad norm avg: 9.43 | grad norm last: 7.3 | 
2025-12-28T01:18:55 | step: 394700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.162852853070945e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.33 | consumed tokens: 202086400.0 | grad norm avg: 9.08 | grad norm last: 13.86 | 
2025-12-28T01:18:57 | step: 394800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.161556277424097e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.78 | consumed tokens: 202137600.0 | grad norm avg: 9.03 | grad norm last: 8.0 | 
2025-12-28T01:18:59 | step: 394900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.160258974181488e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.62 | consumed tokens: 202188800.0 | grad norm avg: 9.21 | grad norm last: 8.1 | 
2025-12-28T01:19:01 | step: 395000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.158961670938879e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.03 | consumed tokens: 202240000.0 | grad norm avg: 9.1 | grad norm last: 8.81 | 
2025-12-28T01:19:03 | step: 395100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.15766436769627e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 5.0 | consumed tokens: 202291200.0 | grad norm avg: 9.01 | grad norm last: 9.54 | 
2025-12-28T01:19:05 | step: 395200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.156367064453661e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.23 | consumed tokens: 202342400.0 | grad norm avg: 9.33 | grad norm last: 10.44 | 
2025-12-28T01:19:07 | step: 395300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.155069761211053e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.52 | consumed tokens: 202393600.0 | grad norm avg: 9.25 | grad norm last: 8.02 | 
2025-12-28T01:19:09 | step: 395400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.153771730372682e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.59 | consumed tokens: 202444800.0 | grad norm avg: 9.39 | grad norm last: 9.24 | 
2025-12-28T01:19:11 | step: 395500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.152473699534312e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.53 | consumed tokens: 202496000.0 | grad norm avg: 8.78 | grad norm last: 8.47 | 
2025-12-28T01:19:13 | step: 395600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.151175668695942e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.45 | consumed tokens: 202547200.0 | grad norm avg: 9.35 | grad norm last: 8.58 | 
2025-12-28T01:19:15 | step: 395700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 7.149877637857571e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.06 | consumed tokens: 202598400.0 | grad norm avg: 9.43 | grad norm last: 11.41 | 
2025-12-28T01:19:17 | step: 395800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 7.14857887942344e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.36 | consumed tokens: 202649600.0 | grad norm avg: 8.9 | grad norm last: 7.93 | 
2025-12-28T01:19:19 | step: 395900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 7.147280120989308e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.56 | consumed tokens: 202700800.0 | grad norm avg: 9.1 | grad norm last: 7.82 | 
2025-12-28T01:19:21 | step: 396000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.145981362555176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.28 | consumed tokens: 202752000.0 | grad norm avg: 8.99 | grad norm last: 7.47 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_396000-seen_tokens_202752000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_396000-seen_tokens_202752000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_396000-seen_tokens_202752000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_396000-seen_tokens_202752000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_396000-seen_tokens_202752000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_396000-seen_tokens_202752000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_396000-seen_tokens_202752000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_396000-seen_tokens_202752000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:19:23 | step: 396100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.144682604121044e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.79 | train loss last: 2.88 | consumed tokens: 202803200.0 | grad norm avg: 9.4 | grad norm last: 7.43 | 
2025-12-28T01:19:25 | step: 396200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.143383845686913e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.52 | consumed tokens: 202854400.0 | grad norm avg: 9.08 | grad norm last: 9.26 | 
2025-12-28T01:19:27 | step: 396300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.14208435965702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.05 | consumed tokens: 202905600.0 | grad norm avg: 9.14 | grad norm last: 7.3 | 
2025-12-28T01:19:29 | step: 396400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 7.140784873627126e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.95 | consumed tokens: 202956800.0 | grad norm avg: 9.22 | grad norm last: 9.14 | 
2025-12-28T01:19:31 | step: 396500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 7.139485387597233e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.3 | consumed tokens: 203008000.0 | grad norm avg: 9.55 | grad norm last: 9.37 | 
2025-12-28T01:19:33 | step: 396600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 7.13818590156734e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.84 | consumed tokens: 203059200.0 | grad norm avg: 9.03 | grad norm last: 8.29 | 
2025-12-28T01:19:35 | step: 396700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 7.136886415537447e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.5 | consumed tokens: 203110400.0 | grad norm avg: 8.95 | grad norm last: 10.25 | 
2025-12-28T01:19:37 | step: 396800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 7.135586201911792e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.86 | consumed tokens: 203161600.0 | grad norm avg: 9.54 | grad norm last: 8.37 | 
2025-12-28T01:19:39 | step: 396900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.134285988286138e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.83 | consumed tokens: 203212800.0 | grad norm avg: 8.97 | grad norm last: 8.02 | 
2025-12-28T01:19:42 | step: 397000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.132985774660483e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.72 | consumed tokens: 203264000.0 | grad norm avg: 8.98 | grad norm last: 8.56 | 
2025-12-28T01:19:44 | step: 397100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.131684833439067e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.55 | consumed tokens: 203315200.0 | grad norm avg: 8.69 | grad norm last: 9.62 | 
2025-12-28T01:19:46 | step: 397200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.130384619813412e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.2 | consumed tokens: 203366400.0 | grad norm avg: 9.11 | grad norm last: 8.2 | 
2025-12-28T01:19:48 | step: 397300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.129083678591996e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.77 | consumed tokens: 203417600.0 | grad norm avg: 8.96 | grad norm last: 7.48 | 
2025-12-28T01:19:50 | step: 397400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.12778273737058e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.73 | consumed tokens: 203468800.0 | grad norm avg: 8.91 | grad norm last: 7.8 | 
2025-12-28T01:19:52 | step: 397500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 7.126481796149164e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.31 | consumed tokens: 203520000.0 | grad norm avg: 9.2 | grad norm last: 8.26 | 
2025-12-28T01:19:54 | step: 397600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 7.125180127331987e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.89 | consumed tokens: 203571200.0 | grad norm avg: 9.17 | grad norm last: 8.38 | 
2025-12-28T01:19:56 | step: 397700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 7.123879186110571e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 2.97 | consumed tokens: 203622400.0 | grad norm avg: 9.25 | grad norm last: 7.87 | 
2025-12-28T01:19:58 | step: 397800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 7.122577517293394e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.73 | consumed tokens: 203673600.0 | grad norm avg: 9.2 | grad norm last: 9.01 | 
2025-12-28T01:20:00 | step: 397900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.121275848476216e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.86 | consumed tokens: 203724800.0 | grad norm avg: 9.26 | grad norm last: 10.62 | 
2025-12-28T01:20:02 | step: 398000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.119973452063277e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.7 | consumed tokens: 203776000.0 | grad norm avg: 9.56 | grad norm last: 8.4 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_398000-seen_tokens_203776000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_398000-seen_tokens_203776000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_398000-seen_tokens_203776000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_398000-seen_tokens_203776000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_398000-seen_tokens_203776000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_398000-seen_tokens_203776000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_398000-seen_tokens_203776000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_398000-seen_tokens_203776000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:20:04 | step: 398100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.1186717832461e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.08 | consumed tokens: 203827200.0 | grad norm avg: 9.37 | grad norm last: 8.1 | 
2025-12-28T01:20:06 | step: 398200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.117369386833161e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.53 | consumed tokens: 203878400.0 | grad norm avg: 9.04 | grad norm last: 7.7 | 
2025-12-28T01:20:08 | step: 398300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 7.116066990420222e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.48 | consumed tokens: 203929600.0 | grad norm avg: 9.32 | grad norm last: 8.64 | 
2025-12-28T01:20:10 | step: 398400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.114764594007283e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.58 | consumed tokens: 203980800.0 | grad norm avg: 9.33 | grad norm last: 7.65 | 
2025-12-28T01:20:12 | step: 398500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.113462197594345e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.28 | consumed tokens: 204032000.0 | grad norm avg: 9.36 | grad norm last: 9.73 | 
2025-12-28T01:20:14 | step: 398600 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.112159073585644e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.11 | consumed tokens: 204083200.0 | grad norm avg: 9.18 | grad norm last: 8.19 | 
2025-12-28T01:20:16 | step: 398700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.110855949576944e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.34 | consumed tokens: 204134400.0 | grad norm avg: 9.02 | grad norm last: 9.23 | 
2025-12-28T01:20:18 | step: 398800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.109552825568244e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.38 | consumed tokens: 204185600.0 | grad norm avg: 9.25 | grad norm last: 9.58 | 
2025-12-28T01:20:20 | step: 398900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.108249701559544e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.41 | consumed tokens: 204236800.0 | grad norm avg: 8.94 | grad norm last: 10.0 | 
2025-12-28T01:20:22 | step: 399000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.106946577550843e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.11 | consumed tokens: 204288000.0 | grad norm avg: 9.05 | grad norm last: 7.8 | 
2025-12-28T01:20:24 | step: 399100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.105642725946382e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.22 | consumed tokens: 204339200.0 | grad norm avg: 9.09 | grad norm last: 8.62 | 
2025-12-28T01:20:26 | step: 399200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.10433887434192e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.34 | consumed tokens: 204390400.0 | grad norm avg: 8.98 | grad norm last: 8.36 | 
2025-12-28T01:20:28 | step: 399300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.103035022737458e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.5 | consumed tokens: 204441600.0 | grad norm avg: 8.93 | grad norm last: 9.75 | 
2025-12-28T01:20:30 | step: 399400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.101731171132997e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.25 | consumed tokens: 204492800.0 | grad norm avg: 9.06 | grad norm last: 9.01 | 
2025-12-28T01:20:32 | step: 399500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.100426591932774e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.34 | consumed tokens: 204544000.0 | grad norm avg: 9.28 | grad norm last: 8.33 | 
2025-12-28T01:20:34 | step: 399600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.099122740328312e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.89 | consumed tokens: 204595200.0 | grad norm avg: 9.16 | grad norm last: 11.55 | 
2025-12-28T01:20:36 | step: 399700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.097818161128089e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 5.31 | consumed tokens: 204646400.0 | grad norm avg: 9.44 | grad norm last: 10.43 | 
2025-12-28T01:20:38 | step: 399800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.096513581927866e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.75 | consumed tokens: 204697600.0 | grad norm avg: 9.19 | grad norm last: 7.89 | 
2025-12-28T01:20:40 | step: 399900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.095208275131881e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.59 | consumed tokens: 204748800.0 | grad norm avg: 9.01 | grad norm last: 11.5 | 
2025-12-28T01:20:42 | step: 400000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.093903695931658e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 2.91 | consumed tokens: 204800000.0 | grad norm avg: 8.83 | grad norm last: 7.71 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_400000-seen_tokens_204800000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_400000-seen_tokens_204800000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_400000-seen_tokens_204800000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_400000-seen_tokens_204800000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_400000-seen_tokens_204800000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_400000-seen_tokens_204800000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_400000-seen_tokens_204800000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_400000-seen_tokens_204800000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:20:45 | step: 400100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.092598389135674e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.8 | train loss last: 3.58 | consumed tokens: 204851200.0 | grad norm avg: 9.25 | grad norm last: 8.04 | 
2025-12-28T01:20:47 | step: 400200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.091293082339689e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.58 | consumed tokens: 204902400.0 | grad norm avg: 8.98 | grad norm last: 9.94 | 
2025-12-28T01:20:49 | step: 400300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.089987775543705e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.59 | consumed tokens: 204953600.0 | grad norm avg: 9.43 | grad norm last: 7.45 | 
2025-12-28T01:20:51 | step: 400400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.088681741151959e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.77 | consumed tokens: 205004800.0 | grad norm avg: 9.04 | grad norm last: 8.63 | 
2025-12-28T01:20:53 | step: 400500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.087376434355974e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.77 | consumed tokens: 205056000.0 | grad norm avg: 9.07 | grad norm last: 9.05 | 
2025-12-28T01:20:55 | step: 400600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.086070399964228e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.67 | consumed tokens: 205107200.0 | grad norm avg: 8.77 | grad norm last: 7.5 | 
2025-12-28T01:20:57 | step: 400700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.084764365572482e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.58 | consumed tokens: 205158400.0 | grad norm avg: 9.14 | grad norm last: 7.56 | 
2025-12-28T01:20:59 | step: 400800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 7.083458331180736e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.27 | consumed tokens: 205209600.0 | grad norm avg: 9.21 | grad norm last: 8.38 | 
2025-12-28T01:21:01 | step: 400900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 7.082151569193229e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.61 | consumed tokens: 205260800.0 | grad norm avg: 9.38 | grad norm last: 8.9 | 
2025-12-28T01:21:03 | step: 401000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 7.080845534801483e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.56 | consumed tokens: 205312000.0 | grad norm avg: 9.35 | grad norm last: 10.78 | 
2025-12-28T01:21:05 | step: 401100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.079538772813976e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.53 | consumed tokens: 205363200.0 | grad norm avg: 8.99 | grad norm last: 7.51 | 
2025-12-28T01:21:07 | step: 401200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.078232010826468e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.06 | consumed tokens: 205414400.0 | grad norm avg: 9.32 | grad norm last: 8.94 | 
2025-12-28T01:21:09 | step: 401300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.076925248838961e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.81 | consumed tokens: 205465600.0 | grad norm avg: 9.56 | grad norm last: 9.72 | 
2025-12-28T01:21:11 | step: 401400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.075617759255692e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.83 | consumed tokens: 205516800.0 | grad norm avg: 9.1 | grad norm last: 9.06 | 
2025-12-28T01:21:13 | step: 401500 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 7.074310269672424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.53 | consumed tokens: 205568000.0 | grad norm avg: 9.21 | grad norm last: 8.55 | 
2025-12-28T01:21:15 | step: 401600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 7.073003507684916e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.84 | consumed tokens: 205619200.0 | grad norm avg: 9.04 | grad norm last: 8.16 | 
2025-12-28T01:21:17 | step: 401700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 7.071695290505886e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.94 | consumed tokens: 205670400.0 | grad norm avg: 9.23 | grad norm last: 13.5 | 
2025-12-28T01:21:19 | step: 401800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.070387800922617e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.91 | consumed tokens: 205721600.0 | grad norm avg: 9.47 | grad norm last: 10.39 | 
2025-12-28T01:21:21 | step: 401900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 7.069080311339349e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.09 | consumed tokens: 205772800.0 | grad norm avg: 9.59 | grad norm last: 8.88 | 
2025-12-28T01:21:23 | step: 402000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 7.067772094160318e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.78 | consumed tokens: 205824000.0 | grad norm avg: 9.45 | grad norm last: 8.76 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_402000-seen_tokens_205824000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_402000-seen_tokens_205824000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_402000-seen_tokens_205824000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_402000-seen_tokens_205824000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_402000-seen_tokens_205824000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_402000-seen_tokens_205824000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_402000-seen_tokens_205824000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_402000-seen_tokens_205824000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:21:26 | step: 402100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.066463876981288e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.75 | train loss last: 3.94 | consumed tokens: 205875200.0 | grad norm avg: 9.17 | grad norm last: 13.43 | 
2025-12-28T01:21:28 | step: 402200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.065155659802258e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.7 | consumed tokens: 205926400.0 | grad norm avg: 8.96 | grad norm last: 9.03 | 
2025-12-28T01:21:30 | step: 402300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.063846715027466e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.36 | consumed tokens: 205977600.0 | grad norm avg: 9.13 | grad norm last: 7.69 | 
2025-12-28T01:21:32 | step: 402400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.062538497848436e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.19 | consumed tokens: 206028800.0 | grad norm avg: 9.24 | grad norm last: 8.58 | 
2025-12-28T01:21:34 | step: 402500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.061229553073645e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.22 | consumed tokens: 206080000.0 | grad norm avg: 9.61 | grad norm last: 8.35 | 
2025-12-28T01:21:36 | step: 402600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 7.059920608298853e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.7 | consumed tokens: 206131200.0 | grad norm avg: 9.49 | grad norm last: 9.04 | 
2025-12-28T01:21:38 | step: 402700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 7.058611663524061e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.84 | consumed tokens: 206182400.0 | grad norm avg: 9.46 | grad norm last: 11.05 | 
2025-12-28T01:21:40 | step: 402800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.05730271874927e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.72 | consumed tokens: 206233600.0 | grad norm avg: 9.7 | grad norm last: 12.61 | 
2025-12-28T01:21:42 | step: 402900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.055993046378717e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.66 | consumed tokens: 206284800.0 | grad norm avg: 10.01 | grad norm last: 8.05 | 
2025-12-28T01:21:44 | step: 403000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.054683374008164e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.8 | consumed tokens: 206336000.0 | grad norm avg: 9.65 | grad norm last: 9.12 | 
2025-12-28T01:21:46 | step: 403100 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 7.053373701637611e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.38 | consumed tokens: 206387200.0 | grad norm avg: 9.45 | grad norm last: 8.64 | 
2025-12-28T01:21:48 | step: 403200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.052064029267058e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.08 | consumed tokens: 206438400.0 | grad norm avg: 9.64 | grad norm last: 7.75 | 
2025-12-28T01:21:50 | step: 403300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.050754356896505e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.67 | consumed tokens: 206489600.0 | grad norm avg: 9.27 | grad norm last: 9.06 | 
2025-12-28T01:21:52 | step: 403400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 7.04944395693019e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.5 | consumed tokens: 206540800.0 | grad norm avg: 9.62 | grad norm last: 8.42 | 
2025-12-28T01:21:54 | step: 403500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.048133556963876e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.42 | consumed tokens: 206592000.0 | grad norm avg: 9.7 | grad norm last: 8.84 | 
2025-12-28T01:21:56 | step: 403600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.046823156997561e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.53 | consumed tokens: 206643200.0 | grad norm avg: 9.72 | grad norm last: 8.65 | 
2025-12-28T01:21:58 | step: 403700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.045512757031247e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.78 | consumed tokens: 206694400.0 | grad norm avg: 9.51 | grad norm last: 9.07 | 
2025-12-28T01:22:00 | step: 403800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.044202357064933e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.62 | consumed tokens: 206745600.0 | grad norm avg: 9.96 | grad norm last: 8.84 | 
2025-12-28T01:22:02 | step: 403900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.042891229502857e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.53 | consumed tokens: 206796800.0 | grad norm avg: 9.21 | grad norm last: 14.62 | 
2025-12-28T01:22:04 | step: 404000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.041580101940781e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.12 | consumed tokens: 206848000.0 | grad norm avg: 9.59 | grad norm last: 10.18 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_404000-seen_tokens_206848000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_404000-seen_tokens_206848000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_404000-seen_tokens_206848000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_404000-seen_tokens_206848000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_404000-seen_tokens_206848000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_404000-seen_tokens_206848000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_404000-seen_tokens_206848000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_404000-seen_tokens_206848000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:22:06 | step: 404100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.040268974378705e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.71 | train loss last: 3.12 | consumed tokens: 206899200.0 | grad norm avg: 9.2 | grad norm last: 7.4 | 
2025-12-28T01:22:08 | step: 404200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.038957846816629e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.64 | consumed tokens: 206950400.0 | grad norm avg: 9.27 | grad norm last: 8.52 | 
2025-12-28T01:22:10 | step: 404300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.037645991658792e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.84 | consumed tokens: 207001600.0 | grad norm avg: 9.46 | grad norm last: 8.91 | 
2025-12-28T01:22:12 | step: 404400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.036334864096716e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.45 | consumed tokens: 207052800.0 | grad norm avg: 9.65 | grad norm last: 8.59 | 
2025-12-28T01:22:14 | step: 404500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.035023008938879e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.81 | consumed tokens: 207104000.0 | grad norm avg: 9.51 | grad norm last: 9.58 | 
2025-12-28T01:22:17 | step: 404600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.033711153781042e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 5.72 | consumed tokens: 207155200.0 | grad norm avg: 9.81 | grad norm last: 10.06 | 
2025-12-28T01:22:19 | step: 404700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.032398571027443e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.58 | consumed tokens: 207206400.0 | grad norm avg: 9.57 | grad norm last: 8.35 | 
2025-12-28T01:22:21 | step: 404800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 7.031086715869606e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.81 | consumed tokens: 207257600.0 | grad norm avg: 9.74 | grad norm last: 8.68 | 
2025-12-28T01:22:23 | step: 404900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.029774133116007e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 5.0 | consumed tokens: 207308800.0 | grad norm avg: 9.43 | grad norm last: 8.81 | 
2025-12-28T01:22:25 | step: 405000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 7.028461550362408e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.86 | consumed tokens: 207360000.0 | grad norm avg: 9.03 | grad norm last: 9.63 | 
2025-12-28T01:22:27 | step: 405100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.02714896760881e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.0 | consumed tokens: 207411200.0 | grad norm avg: 9.11 | grad norm last: 9.51 | 
2025-12-28T01:22:29 | step: 405200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 7.025836384855211e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.92 | consumed tokens: 207462400.0 | grad norm avg: 9.71 | grad norm last: 9.21 | 
2025-12-28T01:22:31 | step: 405300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 7.024523802101612e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.48 | consumed tokens: 207513600.0 | grad norm avg: 8.93 | grad norm last: 7.49 | 
2025-12-28T01:22:33 | step: 405400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 7.023210491752252e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.94 | consumed tokens: 207564800.0 | grad norm avg: 9.42 | grad norm last: 13.42 | 
2025-12-28T01:22:35 | step: 405500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.021897181402892e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.22 | consumed tokens: 207616000.0 | grad norm avg: 9.32 | grad norm last: 9.45 | 
2025-12-28T01:22:37 | step: 405600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.020583871053532e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.22 | consumed tokens: 207667200.0 | grad norm avg: 9.37 | grad norm last: 8.2 | 
2025-12-28T01:22:39 | step: 405700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.019270560704172e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.64 | consumed tokens: 207718400.0 | grad norm avg: 9.44 | grad norm last: 7.94 | 
2025-12-28T01:22:41 | step: 405800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 7.01795652275905e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.55 | consumed tokens: 207769600.0 | grad norm avg: 9.58 | grad norm last: 9.67 | 
2025-12-28T01:22:43 | step: 405900 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 7.01664321240969e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 2.62 | consumed tokens: 207820800.0 | grad norm avg: 9.66 | grad norm last: 7.2 | 
2025-12-28T01:22:45 | step: 406000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 7.015329174464568e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.31 | consumed tokens: 207872000.0 | grad norm avg: 9.32 | grad norm last: 8.52 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_406000-seen_tokens_207872000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_406000-seen_tokens_207872000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_406000-seen_tokens_207872000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_406000-seen_tokens_207872000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_406000-seen_tokens_207872000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_406000-seen_tokens_207872000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_406000-seen_tokens_207872000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_406000-seen_tokens_207872000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:22:47 | step: 406100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 7.014015136519447e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.9 | train loss last: 3.73 | consumed tokens: 207923200.0 | grad norm avg: 9.45 | grad norm last: 12.69 | 
2025-12-28T01:22:49 | step: 406200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.012700370978564e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.64 | consumed tokens: 207974400.0 | grad norm avg: 9.6 | grad norm last: 8.21 | 
2025-12-28T01:22:51 | step: 406300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 7.011386333033442e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.09 | consumed tokens: 208025600.0 | grad norm avg: 9.37 | grad norm last: 9.86 | 
2025-12-28T01:22:53 | step: 406400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.01007156749256e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.12 | consumed tokens: 208076800.0 | grad norm avg: 9.46 | grad norm last: 8.05 | 
2025-12-28T01:22:55 | step: 406500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 7.008756801951677e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.45 | consumed tokens: 208128000.0 | grad norm avg: 10.03 | grad norm last: 7.69 | 
2025-12-28T01:22:57 | step: 406600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 7.007442036410794e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.12 | consumed tokens: 208179200.0 | grad norm avg: 9.41 | grad norm last: 9.28 | 
2025-12-28T01:22:59 | step: 406700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 7.006127270869911e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.14 | consumed tokens: 208230400.0 | grad norm avg: 9.89 | grad norm last: 8.1 | 
2025-12-28T01:23:01 | step: 406800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.004811777733266e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.94 | consumed tokens: 208281600.0 | grad norm avg: 9.91 | grad norm last: 12.3 | 
2025-12-28T01:23:03 | step: 406900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 7.003497012192383e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.17 | consumed tokens: 208332800.0 | grad norm avg: 9.49 | grad norm last: 7.53 | 
2025-12-28T01:23:05 | step: 407000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 7.002181519055739e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.48 | consumed tokens: 208384000.0 | grad norm avg: 9.5 | grad norm last: 9.57 | 
2025-12-28T01:23:07 | step: 407100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 7.000866025919095e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.67 | consumed tokens: 208435200.0 | grad norm avg: 9.51 | grad norm last: 9.23 | 
2025-12-28T01:23:09 | step: 407200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.99955053278245e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.56 | consumed tokens: 208486400.0 | grad norm avg: 9.38 | grad norm last: 12.02 | 
2025-12-28T01:23:11 | step: 407300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.998234312050045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.22 | consumed tokens: 208537600.0 | grad norm avg: 9.23 | grad norm last: 7.62 | 
2025-12-28T01:23:14 | step: 407400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.996918091317639e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.09 | consumed tokens: 208588800.0 | grad norm avg: 9.3 | grad norm last: 8.64 | 
2025-12-28T01:23:16 | step: 407500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.995602598180994e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.69 | consumed tokens: 208640000.0 | grad norm avg: 9.11 | grad norm last: 9.01 | 
2025-12-28T01:23:18 | step: 407600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.994286377448589e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.09 | consumed tokens: 208691200.0 | grad norm avg: 9.08 | grad norm last: 8.76 | 
2025-12-28T01:23:20 | step: 407700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 6.992969429120421e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.7 | consumed tokens: 208742400.0 | grad norm avg: 9.42 | grad norm last: 9.79 | 
2025-12-28T01:23:22 | step: 407800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.991653208388016e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 5.03 | consumed tokens: 208793600.0 | grad norm avg: 9.38 | grad norm last: 16.04 | 
2025-12-28T01:23:24 | step: 407900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.990336260059848e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.31 | consumed tokens: 208844800.0 | grad norm avg: 9.36 | grad norm last: 8.98 | 
2025-12-28T01:23:26 | step: 408000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.989019311731681e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.36 | consumed tokens: 208896000.0 | grad norm avg: 9.29 | grad norm last: 8.18 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_408000-seen_tokens_208896000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_408000-seen_tokens_208896000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_408000-seen_tokens_208896000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_408000-seen_tokens_208896000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_408000-seen_tokens_208896000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_408000-seen_tokens_208896000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_408000-seen_tokens_208896000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_408000-seen_tokens_208896000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:23:28 | step: 408100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.987702363403514e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.58 | consumed tokens: 208947200.0 | grad norm avg: 9.27 | grad norm last: 8.79 | 
2025-12-28T01:23:30 | step: 408200 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 6.986385415075347e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.97 | consumed tokens: 208998400.0 | grad norm avg: 9.52 | grad norm last: 11.16 | 
2025-12-28T01:23:32 | step: 408300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.98506846674718e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.72 | consumed tokens: 209049600.0 | grad norm avg: 9.39 | grad norm last: 8.47 | 
2025-12-28T01:23:34 | step: 408400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.983750790823251e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.14 | consumed tokens: 209100800.0 | grad norm avg: 9.74 | grad norm last: 8.67 | 
2025-12-28T01:23:36 | step: 408500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.982433114899322e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.62 | consumed tokens: 209152000.0 | grad norm avg: 8.82 | grad norm last: 8.65 | 
2025-12-28T01:23:38 | step: 408600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.981115438975394e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.72 | consumed tokens: 209203200.0 | grad norm avg: 9.22 | grad norm last: 7.67 | 
2025-12-28T01:23:40 | step: 408700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.979797763051465e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.84 | consumed tokens: 209254400.0 | grad norm avg: 9.24 | grad norm last: 8.36 | 
2025-12-28T01:23:42 | step: 408800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.978479359531775e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.06 | consumed tokens: 209305600.0 | grad norm avg: 9.09 | grad norm last: 11.19 | 
2025-12-28T01:23:44 | step: 408900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.977161683607846e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.62 | consumed tokens: 209356800.0 | grad norm avg: 9.3 | grad norm last: 8.15 | 
2025-12-28T01:23:46 | step: 409000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.975843280088156e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.75 | consumed tokens: 209408000.0 | grad norm avg: 9.38 | grad norm last: 7.88 | 
2025-12-28T01:23:48 | step: 409100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.974524876568466e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.34 | consumed tokens: 209459200.0 | grad norm avg: 9.32 | grad norm last: 10.9 | 
2025-12-28T01:23:50 | step: 409200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.973206473048776e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.09 | consumed tokens: 209510400.0 | grad norm avg: 9.58 | grad norm last: 8.31 | 
2025-12-28T01:23:52 | step: 409300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.971887341933325e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.19 | consumed tokens: 209561600.0 | grad norm avg: 9.11 | grad norm last: 8.84 | 
2025-12-28T01:23:54 | step: 409400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.970568938413635e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.53 | consumed tokens: 209612800.0 | grad norm avg: 9.2 | grad norm last: 8.37 | 
2025-12-28T01:23:56 | step: 409500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.969249807298183e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.17 | consumed tokens: 209664000.0 | grad norm avg: 8.95 | grad norm last: 7.37 | 
2025-12-28T01:23:58 | step: 409600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.967930676182732e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.34 | consumed tokens: 209715200.0 | grad norm avg: 9.43 | grad norm last: 13.52 | 
2025-12-28T01:24:00 | step: 409700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.96661154506728e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.41 | consumed tokens: 209766400.0 | grad norm avg: 8.98 | grad norm last: 10.2 | 
2025-12-28T01:24:02 | step: 409800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.965291686356068e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.31 | consumed tokens: 209817600.0 | grad norm avg: 9.71 | grad norm last: 9.06 | 
2025-12-28T01:24:04 | step: 409900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.963972555240616e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.34 | consumed tokens: 209868800.0 | grad norm avg: 9.13 | grad norm last: 9.66 | 
2025-12-28T01:24:06 | step: 410000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.962652696529403e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.72 | consumed tokens: 209920000.0 | grad norm avg: 9.68 | grad norm last: 8.05 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_410000-seen_tokens_209920000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_410000-seen_tokens_209920000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_410000-seen_tokens_209920000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_410000-seen_tokens_209920000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_410000-seen_tokens_209920000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_410000-seen_tokens_209920000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_410000-seen_tokens_209920000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_410000-seen_tokens_209920000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:24:09 | step: 410100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 6.96133283781819e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.85 | train loss last: 3.69 | consumed tokens: 209971200.0 | grad norm avg: 9.73 | grad norm last: 8.34 | 
2025-12-28T01:24:11 | step: 410200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.960012979106978e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.81 | train loss last: 4.16 | consumed tokens: 210022400.0 | grad norm avg: 9.78 | grad norm last: 10.88 | 
2025-12-28T01:24:13 | step: 410300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.958693120395765e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.75 | train loss last: 4.72 | consumed tokens: 210073600.0 | grad norm avg: 9.32 | grad norm last: 9.76 | 
2025-12-28T01:24:15 | step: 410400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.95737253408879e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.82 | train loss last: 3.84 | consumed tokens: 210124800.0 | grad norm avg: 9.36 | grad norm last: 9.6 | 
2025-12-28T01:24:17 | step: 410500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.956051947781816e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 3.58 | consumed tokens: 210176000.0 | grad norm avg: 9.04 | grad norm last: 9.25 | 
2025-12-28T01:24:19 | step: 410600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.954732089070603e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.83 | train loss last: 3.52 | consumed tokens: 210227200.0 | grad norm avg: 9.58 | grad norm last: 7.49 | 
2025-12-28T01:24:21 | step: 410700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.953410775167868e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.81 | train loss last: 4.16 | consumed tokens: 210278400.0 | grad norm avg: 9.47 | grad norm last: 10.14 | 
2025-12-28T01:24:23 | step: 410800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 6.952090188860893e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.78 | train loss last: 4.28 | consumed tokens: 210329600.0 | grad norm avg: 9.6 | grad norm last: 11.03 | 
2025-12-28T01:24:25 | step: 410900 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 6.950769602553919e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.76 | train loss last: 3.59 | consumed tokens: 210380800.0 | grad norm avg: 8.99 | grad norm last: 8.35 | 
2025-12-28T01:24:27 | step: 411000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 6.949448288651183e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.79 | train loss last: 3.86 | consumed tokens: 210432000.0 | grad norm avg: 9.49 | grad norm last: 8.26 | 
2025-12-28T01:24:29 | step: 411100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.948126974748448e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.96 | train loss last: 4.09 | consumed tokens: 210483200.0 | grad norm avg: 9.44 | grad norm last: 12.58 | 
2025-12-28T01:24:31 | step: 411200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.946805660845712e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 3.69 | consumed tokens: 210534400.0 | grad norm avg: 9.74 | grad norm last: 8.14 | 
2025-12-28T01:24:33 | step: 411300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.945484346942976e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.89 | train loss last: 3.47 | consumed tokens: 210585600.0 | grad norm avg: 9.8 | grad norm last: 7.98 | 
2025-12-28T01:24:35 | step: 411400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.944162305444479e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.87 | train loss last: 4.44 | consumed tokens: 210636800.0 | grad norm avg: 9.64 | grad norm last: 8.53 | 
2025-12-28T01:24:37 | step: 411500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.942840991541743e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.81 | train loss last: 3.84 | consumed tokens: 210688000.0 | grad norm avg: 9.17 | grad norm last: 9.37 | 
2025-12-28T01:24:39 | step: 411600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.941518950043246e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.69 | train loss last: 4.16 | consumed tokens: 210739200.0 | grad norm avg: 8.99 | grad norm last: 8.49 | 
2025-12-28T01:24:41 | step: 411700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.940196908544749e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.71 | train loss last: 5.09 | consumed tokens: 210790400.0 | grad norm avg: 9.48 | grad norm last: 13.36 | 
2025-12-28T01:24:43 | step: 411800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.938874867046252e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.72 | train loss last: 3.34 | consumed tokens: 210841600.0 | grad norm avg: 9.39 | grad norm last: 7.84 | 
2025-12-28T01:24:45 | step: 411900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.937552097951993e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.72 | train loss last: 3.27 | consumed tokens: 210892800.0 | grad norm avg: 9.05 | grad norm last: 8.37 | 
2025-12-28T01:24:47 | step: 412000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.936230056453496e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.74 | train loss last: 3.38 | consumed tokens: 210944000.0 | grad norm avg: 9.21 | grad norm last: 7.57 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_412000-seen_tokens_210944000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_412000-seen_tokens_210944000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_412000-seen_tokens_210944000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_412000-seen_tokens_210944000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_412000-seen_tokens_210944000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_412000-seen_tokens_210944000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_412000-seen_tokens_210944000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_412000-seen_tokens_210944000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:24:49 | step: 412100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.934907287359238e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 3.72 | train loss last: 4.16 | consumed tokens: 210995200.0 | grad norm avg: 9.22 | grad norm last: 10.86 | 
2025-12-28T01:24:51 | step: 412200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.933584518264979e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.76 | train loss last: 4.19 | consumed tokens: 211046400.0 | grad norm avg: 9.43 | grad norm last: 9.94 | 
2025-12-28T01:24:53 | step: 412300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 6.93226174917072e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.78 | train loss last: 3.8 | consumed tokens: 211097600.0 | grad norm avg: 9.85 | grad norm last: 9.61 | 
2025-12-28T01:24:55 | step: 412400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.9309382524807e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.72 | train loss last: 4.03 | consumed tokens: 211148800.0 | grad norm avg: 9.34 | grad norm last: 8.62 | 
2025-12-28T01:24:57 | step: 412500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.929615483386442e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.77 | train loss last: 3.64 | consumed tokens: 211200000.0 | grad norm avg: 9.13 | grad norm last: 8.38 | 
2025-12-28T01:24:59 | step: 412600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.928291986696422e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.79 | train loss last: 3.11 | consumed tokens: 211251200.0 | grad norm avg: 9.15 | grad norm last: 9.33 | 
2025-12-28T01:25:01 | step: 412700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.926968490006402e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.76 | train loss last: 4.28 | consumed tokens: 211302400.0 | grad norm avg: 9.66 | grad norm last: 16.18 | 
2025-12-28T01:25:04 | step: 412800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.925644993316382e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.83 | train loss last: 3.78 | consumed tokens: 211353600.0 | grad norm avg: 9.41 | grad norm last: 8.31 | 
2025-12-28T01:25:06 | step: 412900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.924321496626362e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 3.03 | consumed tokens: 211404800.0 | grad norm avg: 9.12 | grad norm last: 8.21 | 
2025-12-28T01:25:08 | step: 413000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.922997272340581e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.74 | train loss last: 2.98 | consumed tokens: 211456000.0 | grad norm avg: 9.65 | grad norm last: 8.66 | 
2025-12-28T01:25:10 | step: 413100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.921673775650561e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.69 | train loss last: 3.56 | consumed tokens: 211507200.0 | grad norm avg: 9.52 | grad norm last: 10.11 | 
2025-12-28T01:25:12 | step: 413200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.92034955136478e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.76 | train loss last: 4.22 | consumed tokens: 211558400.0 | grad norm avg: 9.13 | grad norm last: 11.38 | 
2025-12-28T01:25:14 | step: 413300 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 6.919025327078998e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.75 | train loss last: 3.3 | consumed tokens: 211609600.0 | grad norm avg: 9.37 | grad norm last: 9.04 | 
2025-12-28T01:25:16 | step: 413400 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 6.917701102793217e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.84 | train loss last: 3.56 | consumed tokens: 211660800.0 | grad norm avg: 10.25 | grad norm last: 7.79 | 
2025-12-28T01:25:18 | step: 413500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.916376150911674e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.67 | train loss last: 2.94 | consumed tokens: 211712000.0 | grad norm avg: 9.09 | grad norm last: 9.47 | 
2025-12-28T01:25:20 | step: 413600 | train samples/s: 107.6 | train mfu (16-bit): -1.0 | lr mean: 6.915051199030131e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.85 | train loss last: 3.48 | consumed tokens: 211763200.0 | grad norm avg: 9.99 | grad norm last: 8.52 | 
2025-12-28T01:25:22 | step: 413700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 6.91372697474435e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.82 | train loss last: 3.59 | consumed tokens: 211814400.0 | grad norm avg: 9.56 | grad norm last: 10.39 | 
2025-12-28T01:25:24 | step: 413800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.912402022862807e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 3.41 | consumed tokens: 211865600.0 | grad norm avg: 9.34 | grad norm last: 7.95 | 
2025-12-28T01:25:26 | step: 413900 | train samples/s: 107.4 | train mfu (16-bit): -1.0 | lr mean: 6.911077070981264e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.75 | train loss last: 3.98 | consumed tokens: 211916800.0 | grad norm avg: 9.6 | grad norm last: 8.98 | 
2025-12-28T01:25:28 | step: 414000 | train samples/s: 107.5 | train mfu (16-bit): -1.0 | lr mean: 6.90975139150396e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.79 | train loss last: 4.5 | consumed tokens: 211968000.0 | grad norm avg: 8.86 | grad norm last: 11.31 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_414000-seen_tokens_211968000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_414000-seen_tokens_211968000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_414000-seen_tokens_211968000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_414000-seen_tokens_211968000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_414000-seen_tokens_211968000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_414000-seen_tokens_211968000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_414000-seen_tokens_211968000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_414000-seen_tokens_211968000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:25:30 | step: 414100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.908426439622417e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 3.78 | train loss last: 3.38 | consumed tokens: 212019200.0 | grad norm avg: 9.74 | grad norm last: 7.9 | 
2025-12-28T01:25:32 | step: 414200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.907100760145113e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.71 | train loss last: 3.95 | consumed tokens: 212070400.0 | grad norm avg: 9.34 | grad norm last: 9.02 | 
2025-12-28T01:25:34 | step: 414300 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.905775080667809e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.74 | train loss last: 3.2 | consumed tokens: 212121600.0 | grad norm avg: 9.55 | grad norm last: 8.45 | 
2025-12-28T01:25:36 | step: 414400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.904449401190504e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.79 | train loss last: 3.19 | consumed tokens: 212172800.0 | grad norm avg: 8.97 | grad norm last: 7.53 | 
2025-12-28T01:25:38 | step: 414500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.9031237217132e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.76 | train loss last: 3.7 | consumed tokens: 212224000.0 | grad norm avg: 8.99 | grad norm last: 8.95 | 
2025-12-28T01:25:40 | step: 414600 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 6.901797314640135e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 4.75 | consumed tokens: 212275200.0 | grad norm avg: 9.23 | grad norm last: 9.29 | 
2025-12-28T01:25:42 | step: 414700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.90047163516283e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.68 | train loss last: 3.97 | consumed tokens: 212326400.0 | grad norm avg: 9.03 | grad norm last: 13.08 | 
2025-12-28T01:25:44 | step: 414800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.899145228089765e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.76 | train loss last: 3.08 | consumed tokens: 212377600.0 | grad norm avg: 9.43 | grad norm last: 8.73 | 
2025-12-28T01:25:46 | step: 414900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.897818821016699e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 3.7 | consumed tokens: 212428800.0 | grad norm avg: 9.04 | grad norm last: 9.45 | 
2025-12-28T01:25:48 | step: 415000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.896491686347872e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.94 | train loss last: 4.38 | consumed tokens: 212480000.0 | grad norm avg: 9.52 | grad norm last: 11.51 | 
2025-12-28T01:25:50 | step: 415100 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.895165279274806e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.8 | train loss last: 3.78 | consumed tokens: 212531200.0 | grad norm avg: 9.07 | grad norm last: 8.57 | 
2025-12-28T01:25:52 | step: 415200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.89383814460598e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.84 | train loss last: 3.66 | consumed tokens: 212582400.0 | grad norm avg: 9.15 | grad norm last: 8.74 | 
2025-12-28T01:25:54 | step: 415300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.892511737532914e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.72 | train loss last: 4.53 | consumed tokens: 212633600.0 | grad norm avg: 9.09 | grad norm last: 11.86 | 
2025-12-28T01:25:56 | step: 415400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 6.891184602864087e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.7 | train loss last: 3.45 | consumed tokens: 212684800.0 | grad norm avg: 8.9 | grad norm last: 8.13 | 
2025-12-28T01:25:58 | step: 415500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 6.88985746819526e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.7 | train loss last: 3.75 | consumed tokens: 212736000.0 | grad norm avg: 8.96 | grad norm last: 8.56 | 
2025-12-28T01:26:00 | step: 415600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.888529605930671e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.84 | train loss last: 4.34 | consumed tokens: 212787200.0 | grad norm avg: 9.44 | grad norm last: 14.28 | 
2025-12-28T01:26:02 | step: 415700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.887202471261844e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 4.81 | consumed tokens: 212838400.0 | grad norm avg: 9.39 | grad norm last: 14.72 | 
2025-12-28T01:26:04 | step: 415800 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 6.885874608997256e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 4.12 | consumed tokens: 212889600.0 | grad norm avg: 9.08 | grad norm last: 13.72 | 
2025-12-28T01:26:06 | step: 415900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 6.884546746732667e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 3.38 | consumed tokens: 212940800.0 | grad norm avg: 9.24 | grad norm last: 8.35 | 
2025-12-28T01:26:08 | step: 416000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.883218884468079e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.69 | train loss last: 4.53 | consumed tokens: 212992000.0 | grad norm avg: 9.0 | grad norm last: 10.96 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_416000-seen_tokens_212992000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_416000-seen_tokens_212992000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_416000-seen_tokens_212992000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_416000-seen_tokens_212992000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_416000-seen_tokens_212992000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_416000-seen_tokens_212992000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_416000-seen_tokens_212992000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_416000-seen_tokens_212992000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:26:11 | step: 416100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.88189102220349e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 3.76 | train loss last: 3.22 | consumed tokens: 213043200.0 | grad norm avg: 8.72 | grad norm last: 7.78 | 
2025-12-28T01:26:13 | step: 416200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.880563159938902e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.83 | train loss last: 3.92 | consumed tokens: 213094400.0 | grad norm avg: 9.13 | grad norm last: 8.41 | 
2025-12-28T01:26:15 | step: 416300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 6.879234570078552e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.76 | train loss last: 4.41 | consumed tokens: 213145600.0 | grad norm avg: 9.1 | grad norm last: 10.56 | 
2025-12-28T01:26:17 | step: 416400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.877905980218202e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.81 | train loss last: 3.02 | consumed tokens: 213196800.0 | grad norm avg: 9.12 | grad norm last: 7.81 | 
2025-12-28T01:26:19 | step: 416500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.876577390357852e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.72 | train loss last: 3.62 | consumed tokens: 213248000.0 | grad norm avg: 8.94 | grad norm last: 9.9 | 
2025-12-28T01:26:21 | step: 416600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.875248800497502e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.75 | train loss last: 3.97 | consumed tokens: 213299200.0 | grad norm avg: 9.15 | grad norm last: 9.07 | 
2025-12-28T01:26:23 | step: 416700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.873920210637152e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 3.39 | consumed tokens: 213350400.0 | grad norm avg: 8.7 | grad norm last: 7.35 | 
2025-12-28T01:26:25 | step: 416800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.872590893181041e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.72 | train loss last: 3.61 | consumed tokens: 213401600.0 | grad norm avg: 8.97 | grad norm last: 8.22 | 
2025-12-28T01:26:27 | step: 416900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.871262303320691e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.83 | train loss last: 3.7 | consumed tokens: 213452800.0 | grad norm avg: 9.4 | grad norm last: 7.99 | 
2025-12-28T01:26:29 | step: 417000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.86993298586458e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.81 | train loss last: 3.7 | consumed tokens: 213504000.0 | grad norm avg: 9.2 | grad norm last: 9.1 | 
2025-12-28T01:26:31 | step: 417100 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.868603668408468e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.82 | train loss last: 4.44 | consumed tokens: 213555200.0 | grad norm avg: 9.17 | grad norm last: 13.47 | 
2025-12-28T01:26:33 | step: 417200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.867273623356596e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.69 | train loss last: 3.59 | consumed tokens: 213606400.0 | grad norm avg: 9.12 | grad norm last: 8.57 | 
2025-12-28T01:26:35 | step: 417300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.865944305900484e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.79 | train loss last: 4.19 | consumed tokens: 213657600.0 | grad norm avg: 9.19 | grad norm last: 11.07 | 
2025-12-28T01:26:37 | step: 417400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.864614260848612e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.71 | train loss last: 3.62 | consumed tokens: 213708800.0 | grad norm avg: 9.07 | grad norm last: 7.41 | 
2025-12-28T01:26:39 | step: 417500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.8632849433925e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.87 | train loss last: 4.03 | consumed tokens: 213760000.0 | grad norm avg: 9.13 | grad norm last: 8.16 | 
2025-12-28T01:26:41 | step: 417600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.861954898340628e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.71 | train loss last: 4.06 | consumed tokens: 213811200.0 | grad norm avg: 8.88 | grad norm last: 9.37 | 
2025-12-28T01:26:43 | step: 417700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.860624853288755e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.8 | train loss last: 3.41 | consumed tokens: 213862400.0 | grad norm avg: 9.22 | grad norm last: 7.59 | 
2025-12-28T01:26:45 | step: 417800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.85929408064112e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 3.28 | consumed tokens: 213913600.0 | grad norm avg: 8.87 | grad norm last: 8.19 | 
2025-12-28T01:26:47 | step: 417900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.857964035589248e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.92 | train loss last: 3.31 | consumed tokens: 213964800.0 | grad norm avg: 9.5 | grad norm last: 8.57 | 
2025-12-28T01:26:49 | step: 418000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.856633262941614e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.81 | train loss last: 2.97 | consumed tokens: 214016000.0 | grad norm avg: 9.15 | grad norm last: 7.33 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_418000-seen_tokens_214016000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_418000-seen_tokens_214016000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_418000-seen_tokens_214016000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_418000-seen_tokens_214016000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_418000-seen_tokens_214016000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_418000-seen_tokens_214016000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_418000-seen_tokens_214016000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_418000-seen_tokens_214016000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:26:51 | step: 418100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.85530249029398e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.81 | train loss last: 4.03 | consumed tokens: 214067200.0 | grad norm avg: 9.25 | grad norm last: 9.96 | 
2025-12-28T01:26:53 | step: 418200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.853971717646345e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 4.25 | consumed tokens: 214118400.0 | grad norm avg: 9.36 | grad norm last: 8.35 | 
2025-12-28T01:26:55 | step: 418300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.852640944998711e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.8 | train loss last: 3.52 | consumed tokens: 214169600.0 | grad norm avg: 8.95 | grad norm last: 8.79 | 
2025-12-28T01:26:57 | step: 418400 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 6.851310172351077e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.82 | train loss last: 4.12 | consumed tokens: 214220800.0 | grad norm avg: 9.02 | grad norm last: 9.46 | 
2025-12-28T01:26:59 | step: 418500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.849978672107682e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.68 | train loss last: 3.39 | consumed tokens: 214272000.0 | grad norm avg: 8.9 | grad norm last: 7.81 | 
2025-12-28T01:27:01 | step: 418600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.848647171864286e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.8 | train loss last: 3.25 | consumed tokens: 214323200.0 | grad norm avg: 9.12 | grad norm last: 8.56 | 
2025-12-28T01:27:03 | step: 418700 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 6.84731567162089e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.65 | train loss last: 3.45 | consumed tokens: 214374400.0 | grad norm avg: 8.67 | grad norm last: 8.25 | 
2025-12-28T01:27:06 | step: 418800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.845984171377495e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.8 | train loss last: 2.66 | consumed tokens: 214425600.0 | grad norm avg: 9.08 | grad norm last: 7.03 | 
2025-12-28T01:27:08 | step: 418900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.8446526711341e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.75 | train loss last: 3.23 | consumed tokens: 214476800.0 | grad norm avg: 8.67 | grad norm last: 7.62 | 
2025-12-28T01:27:10 | step: 419000 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 6.843321170890704e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 4.16 | consumed tokens: 214528000.0 | grad norm avg: 8.93 | grad norm last: 8.83 | 
2025-12-28T01:27:12 | step: 419100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.841988943051547e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.77 | train loss last: 3.97 | consumed tokens: 214579200.0 | grad norm avg: 8.75 | grad norm last: 8.8 | 
2025-12-28T01:27:14 | step: 419200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.84065671521239e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.78 | train loss last: 3.34 | consumed tokens: 214630400.0 | grad norm avg: 8.99 | grad norm last: 7.85 | 
2025-12-28T01:27:16 | step: 419300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.839324487373233e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.83 | train loss last: 4.41 | consumed tokens: 214681600.0 | grad norm avg: 9.22 | grad norm last: 8.9 | 
2025-12-28T01:27:18 | step: 419400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.837992259534076e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.72 | train loss last: 3.73 | consumed tokens: 214732800.0 | grad norm avg: 8.7 | grad norm last: 7.75 | 
2025-12-28T01:27:20 | step: 419500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.836660031694919e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.77 | train loss last: 3.28 | consumed tokens: 214784000.0 | grad norm avg: 9.04 | grad norm last: 7.38 | 
2025-12-28T01:27:22 | step: 419600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.83532707626e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 3.97 | consumed tokens: 214835200.0 | grad norm avg: 8.72 | grad norm last: 8.51 | 
2025-12-28T01:27:24 | step: 419700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.833994120825082e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.82 | train loss last: 4.0 | consumed tokens: 214886400.0 | grad norm avg: 9.07 | grad norm last: 9.35 | 
2025-12-28T01:27:26 | step: 419800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.832661892985925e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.78 | train loss last: 4.25 | consumed tokens: 214937600.0 | grad norm avg: 8.87 | grad norm last: 9.01 | 
2025-12-28T01:27:28 | step: 419900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.831328937551007e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.82 | train loss last: 3.64 | consumed tokens: 214988800.0 | grad norm avg: 8.88 | grad norm last: 8.36 | 
2025-12-28T01:27:30 | step: 420000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.829995254520327e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.71 | train loss last: 3.8 | consumed tokens: 215040000.0 | grad norm avg: 8.51 | grad norm last: 7.97 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_420000-seen_tokens_215040000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_420000-seen_tokens_215040000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_420000-seen_tokens_215040000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_420000-seen_tokens_215040000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_420000-seen_tokens_215040000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_420000-seen_tokens_215040000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_420000-seen_tokens_215040000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_420000-seen_tokens_215040000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:27:32 | step: 420100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 6.828662299085408e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 3.83 | train loss last: 3.55 | consumed tokens: 215091200.0 | grad norm avg: 9.05 | grad norm last: 9.17 | 
2025-12-28T01:27:34 | step: 420200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 6.827328616054729e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 3.72 | train loss last: 3.73 | consumed tokens: 215142400.0 | grad norm avg: 8.91 | grad norm last: 9.09 | 
2025-12-28T01:27:36 | step: 420300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 6.82599566061981e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 3.76 | train loss last: 3.48 | consumed tokens: 215193600.0 | grad norm avg: 9.01 | grad norm last: 8.48 | 
2025-12-28T01:27:38 | step: 420400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.82466197758913e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 3.65 | train loss last: 3.8 | consumed tokens: 215244800.0 | grad norm avg: 8.66 | grad norm last: 8.1 | 
2025-12-28T01:27:40 | step: 420500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.82332829455845e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 3.74 | train loss last: 3.5 | consumed tokens: 215296000.0 | grad norm avg: 9.06 | grad norm last: 7.81 | 
2025-12-28T01:27:42 | step: 420600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.82199388393201e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 3.86 | train loss last: 3.91 | consumed tokens: 215347200.0 | grad norm avg: 8.92 | grad norm last: 9.42 | 
2025-12-28T01:27:44 | step: 420700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 6.82066020090133e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 3.77 | train loss last: 4.0 | consumed tokens: 215398400.0 | grad norm avg: 8.8 | grad norm last: 8.09 | 
2025-12-28T01:27:46 | step: 420800 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 6.819325790274888e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 3.81 | train loss last: 5.34 | consumed tokens: 215449600.0 | grad norm avg: 8.78 | grad norm last: 10.99 | 
2025-12-28T01:27:48 | step: 420900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 6.817991379648447e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 3.73 | train loss last: 3.84 | consumed tokens: 215500800.0 | grad norm avg: 8.87 | grad norm last: 7.99 | 
2025-12-28T01:27:50 | step: 421000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.816656969022006e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 3.81 | train loss last: 3.72 | consumed tokens: 215552000.0 | grad norm avg: 8.88 | grad norm last: 8.09 | 
2025-12-28T01:27:52 | step: 421100 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 6.815322558395565e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 3.73 | train loss last: 3.5 | consumed tokens: 215603200.0 | grad norm avg: 8.7 | grad norm last: 8.54 | 
2025-12-28T01:27:55 | step: 421200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 6.813988147769123e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.77 | consumed tokens: 215654400.0 | grad norm avg: 8.76 | grad norm last: 7.96 | 
2025-12-28T01:27:57 | step: 421300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.81265300954692e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.27 | consumed tokens: 215705600.0 | grad norm avg: 8.79 | grad norm last: 9.11 | 
2025-12-28T01:27:59 | step: 421400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.81131859892048e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.91 | train loss last: 3.78 | consumed tokens: 215756800.0 | grad norm avg: 9.06 | grad norm last: 8.09 | 
2025-12-28T01:28:01 | step: 421500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.809983460698277e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.41 | consumed tokens: 215808000.0 | grad norm avg: 9.09 | grad norm last: 8.76 | 
2025-12-28T01:28:03 | step: 421600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.808648322476074e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.02 | consumed tokens: 215859200.0 | grad norm avg: 8.89 | grad norm last: 7.58 | 
2025-12-28T01:28:05 | step: 421700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.807313184253871e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.69 | consumed tokens: 215910400.0 | grad norm avg: 8.74 | grad norm last: 7.31 | 
2025-12-28T01:28:07 | step: 421800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.805977318435907e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.06 | consumed tokens: 215961600.0 | grad norm avg: 8.79 | grad norm last: 11.49 | 
2025-12-28T01:28:09 | step: 421900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.804642180213705e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.2 | consumed tokens: 216012800.0 | grad norm avg: 8.64 | grad norm last: 9.05 | 
2025-12-28T01:28:11 | step: 422000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.80330631439574e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.56 | consumed tokens: 216064000.0 | grad norm avg: 8.98 | grad norm last: 7.45 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_422000-seen_tokens_216064000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_422000-seen_tokens_216064000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_422000-seen_tokens_216064000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_422000-seen_tokens_216064000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_422000-seen_tokens_216064000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_422000-seen_tokens_216064000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_422000-seen_tokens_216064000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_422000-seen_tokens_216064000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:28:13 | step: 422100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.801970448577777e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.3 | consumed tokens: 216115200.0 | grad norm avg: 8.5 | grad norm last: 8.07 | 
2025-12-28T01:28:15 | step: 422200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.800634582759812e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.55 | consumed tokens: 216166400.0 | grad norm avg: 8.8 | grad norm last: 8.24 | 
2025-12-28T01:28:17 | step: 422300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.799298716941848e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.69 | consumed tokens: 216217600.0 | grad norm avg: 8.72 | grad norm last: 7.64 | 
2025-12-28T01:28:19 | step: 422400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.797962851123884e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.75 | consumed tokens: 216268800.0 | grad norm avg: 8.69 | grad norm last: 8.05 | 
2025-12-28T01:28:21 | step: 422500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.796626257710159e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.03 | consumed tokens: 216320000.0 | grad norm avg: 8.65 | grad norm last: 8.02 | 
2025-12-28T01:28:23 | step: 422600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.795289664296433e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.22 | consumed tokens: 216371200.0 | grad norm avg: 8.75 | grad norm last: 9.01 | 
2025-12-28T01:28:25 | step: 422700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.793953070882708e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.77 | consumed tokens: 216422400.0 | grad norm avg: 8.66 | grad norm last: 7.91 | 
2025-12-28T01:28:27 | step: 422800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 6.792616477468982e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.19 | consumed tokens: 216473600.0 | grad norm avg: 8.76 | grad norm last: 7.31 | 
2025-12-28T01:28:29 | step: 422900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.791279884055257e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.09 | consumed tokens: 216524800.0 | grad norm avg: 8.71 | grad norm last: 8.35 | 
2025-12-28T01:28:31 | step: 423000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.789943290641531e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 2.94 | consumed tokens: 216576000.0 | grad norm avg: 9.0 | grad norm last: 8.0 | 
2025-12-28T01:28:33 | step: 423100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.788605969632044e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.73 | consumed tokens: 216627200.0 | grad norm avg: 8.74 | grad norm last: 7.64 | 
2025-12-28T01:28:35 | step: 423200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.787268648622558e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.58 | consumed tokens: 216678400.0 | grad norm avg: 9.2 | grad norm last: 8.84 | 
2025-12-28T01:28:37 | step: 423300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.78593132761307e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.44 | consumed tokens: 216729600.0 | grad norm avg: 8.96 | grad norm last: 8.33 | 
2025-12-28T01:28:39 | step: 423400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.784594006603584e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.41 | consumed tokens: 216780800.0 | grad norm avg: 9.08 | grad norm last: 8.09 | 
2025-12-28T01:28:41 | step: 423500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.783256685594097e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.95 | consumed tokens: 216832000.0 | grad norm avg: 8.62 | grad norm last: 12.1 | 
2025-12-28T01:28:43 | step: 423600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.78191936458461e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.91 | consumed tokens: 216883200.0 | grad norm avg: 8.75 | grad norm last: 13.15 | 
2025-12-28T01:28:45 | step: 423700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.780581315979362e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.61 | consumed tokens: 216934400.0 | grad norm avg: 8.79 | grad norm last: 8.54 | 
2025-12-28T01:28:47 | step: 423800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.779243267374113e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.05 | consumed tokens: 216985600.0 | grad norm avg: 9.05 | grad norm last: 8.62 | 
2025-12-28T01:28:49 | step: 423900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.777905218768865e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.45 | consumed tokens: 217036800.0 | grad norm avg: 8.97 | grad norm last: 8.14 | 
2025-12-28T01:28:51 | step: 424000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.776567170163617e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.3 | consumed tokens: 217088000.0 | grad norm avg: 8.85 | grad norm last: 7.89 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_424000-seen_tokens_217088000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_424000-seen_tokens_217088000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_424000-seen_tokens_217088000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_424000-seen_tokens_217088000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_424000-seen_tokens_217088000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_424000-seen_tokens_217088000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_424000-seen_tokens_217088000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_424000-seen_tokens_217088000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:28:54 | step: 424100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.775229121558368e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.76 | train loss last: 3.59 | consumed tokens: 217139200.0 | grad norm avg: 8.97 | grad norm last: 7.8 | 
2025-12-28T01:28:56 | step: 424200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.773890345357358e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.73 | consumed tokens: 217190400.0 | grad norm avg: 9.18 | grad norm last: 8.07 | 
2025-12-28T01:28:58 | step: 424300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.77255229675211e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.38 | consumed tokens: 217241600.0 | grad norm avg: 8.52 | grad norm last: 7.96 | 
2025-12-28T01:29:00 | step: 424400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.7712135205511e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.64 | consumed tokens: 217292800.0 | grad norm avg: 8.86 | grad norm last: 8.28 | 
2025-12-28T01:29:02 | step: 424500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.76987474435009e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.42 | consumed tokens: 217344000.0 | grad norm avg: 8.79 | grad norm last: 7.93 | 
2025-12-28T01:29:04 | step: 424600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.768535968149081e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.78 | consumed tokens: 217395200.0 | grad norm avg: 9.37 | grad norm last: 20.51 | 
2025-12-28T01:29:06 | step: 424700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.767197191948071e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 5.12 | consumed tokens: 217446400.0 | grad norm avg: 8.76 | grad norm last: 8.15 | 
2025-12-28T01:29:08 | step: 424800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.7658576881513e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.66 | consumed tokens: 217497600.0 | grad norm avg: 8.71 | grad norm last: 8.52 | 
2025-12-28T01:29:10 | step: 424900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 6.764518184354529e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.3 | consumed tokens: 217548800.0 | grad norm avg: 8.75 | grad norm last: 8.46 | 
2025-12-28T01:29:12 | step: 425000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 6.763179408153519e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.86 | consumed tokens: 217600000.0 | grad norm avg: 9.02 | grad norm last: 23.6 | 
2025-12-28T01:29:14 | step: 425100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.761839904356748e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.31 | consumed tokens: 217651200.0 | grad norm avg: 9.05 | grad norm last: 8.48 | 
2025-12-28T01:29:16 | step: 425200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.760500400559977e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 2.64 | consumed tokens: 217702400.0 | grad norm avg: 8.78 | grad norm last: 8.72 | 
2025-12-28T01:29:18 | step: 425300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.759160169167444e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 5.94 | consumed tokens: 217753600.0 | grad norm avg: 8.66 | grad norm last: 9.61 | 
2025-12-28T01:29:20 | step: 425400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.757820665370673e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.64 | consumed tokens: 217804800.0 | grad norm avg: 9.25 | grad norm last: 8.97 | 
2025-12-28T01:29:22 | step: 425500 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 6.75648043397814e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.06 | consumed tokens: 217856000.0 | grad norm avg: 9.23 | grad norm last: 10.71 | 
2025-12-28T01:29:24 | step: 425600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 6.755140202585608e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.09 | consumed tokens: 217907200.0 | grad norm avg: 9.1 | grad norm last: 13.17 | 
2025-12-28T01:29:26 | step: 425700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 6.753799971193075e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.64 | consumed tokens: 217958400.0 | grad norm avg: 9.04 | grad norm last: 8.35 | 
2025-12-28T01:29:28 | step: 425800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.752459739800543e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.03 | consumed tokens: 218009600.0 | grad norm avg: 8.92 | grad norm last: 8.68 | 
2025-12-28T01:29:30 | step: 425900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.75111950840801e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.75 | consumed tokens: 218060800.0 | grad norm avg: 9.08 | grad norm last: 9.28 | 
2025-12-28T01:29:32 | step: 426000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.749779277015477e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.95 | consumed tokens: 218112000.0 | grad norm avg: 9.23 | grad norm last: 8.48 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_426000-seen_tokens_218112000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_426000-seen_tokens_218112000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_426000-seen_tokens_218112000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_426000-seen_tokens_218112000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_426000-seen_tokens_218112000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_426000-seen_tokens_218112000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_426000-seen_tokens_218112000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_426000-seen_tokens_218112000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:29:35 | step: 426100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.748438318027183e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.76 | train loss last: 3.42 | consumed tokens: 218163200.0 | grad norm avg: 9.17 | grad norm last: 9.09 | 
2025-12-28T01:29:37 | step: 426200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.74709735903889e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.16 | consumed tokens: 218214400.0 | grad norm avg: 9.18 | grad norm last: 7.43 | 
2025-12-28T01:29:39 | step: 426300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.745756400050595e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.31 | consumed tokens: 218265600.0 | grad norm avg: 8.81 | grad norm last: 9.56 | 
2025-12-28T01:29:41 | step: 426400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.744415441062301e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.03 | consumed tokens: 218316800.0 | grad norm avg: 9.18 | grad norm last: 9.36 | 
2025-12-28T01:29:43 | step: 426500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.743074482074007e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.58 | consumed tokens: 218368000.0 | grad norm avg: 8.95 | grad norm last: 7.75 | 
2025-12-28T01:29:45 | step: 426600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.741732795489952e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.38 | consumed tokens: 218419200.0 | grad norm avg: 9.37 | grad norm last: 8.05 | 
2025-12-28T01:29:47 | step: 426700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.740391836501658e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.91 | consumed tokens: 218470400.0 | grad norm avg: 9.12 | grad norm last: 8.7 | 
2025-12-28T01:29:49 | step: 426800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.739050149917603e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.08 | consumed tokens: 218521600.0 | grad norm avg: 8.91 | grad norm last: 7.32 | 
2025-12-28T01:29:51 | step: 426900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.737708463333547e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.94 | consumed tokens: 218572800.0 | grad norm avg: 8.99 | grad norm last: 8.43 | 
2025-12-28T01:29:53 | step: 427000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.736366776749492e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.39 | consumed tokens: 218624000.0 | grad norm avg: 8.97 | grad norm last: 7.8 | 
2025-12-28T01:29:55 | step: 427100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.735025090165436e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.0 | consumed tokens: 218675200.0 | grad norm avg: 8.99 | grad norm last: 9.39 | 
2025-12-28T01:29:57 | step: 427200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.73368267598562e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.88 | consumed tokens: 218726400.0 | grad norm avg: 8.93 | grad norm last: 9.07 | 
2025-12-28T01:29:59 | step: 427300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.732340989401564e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.91 | consumed tokens: 218777600.0 | grad norm avg: 9.57 | grad norm last: 9.41 | 
2025-12-28T01:30:01 | step: 427400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.730998575221747e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.41 | consumed tokens: 218828800.0 | grad norm avg: 9.4 | grad norm last: 7.99 | 
2025-12-28T01:30:03 | step: 427500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.72965616104193e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.55 | consumed tokens: 218880000.0 | grad norm avg: 8.89 | grad norm last: 8.0 | 
2025-12-28T01:30:05 | step: 427600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.728313746862113e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.56 | consumed tokens: 218931200.0 | grad norm avg: 9.22 | grad norm last: 10.61 | 
2025-12-28T01:30:07 | step: 427700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.726971332682297e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.97 | consumed tokens: 218982400.0 | grad norm avg: 8.79 | grad norm last: 9.41 | 
2025-12-28T01:30:09 | step: 427800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.725628190906718e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.48 | consumed tokens: 219033600.0 | grad norm avg: 9.13 | grad norm last: 7.7 | 
2025-12-28T01:30:11 | step: 427900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.724285776726902e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.64 | consumed tokens: 219084800.0 | grad norm avg: 9.12 | grad norm last: 10.57 | 
2025-12-28T01:30:13 | step: 428000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.722942634951323e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.3 | consumed tokens: 219136000.0 | grad norm avg: 9.48 | grad norm last: 8.95 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_428000-seen_tokens_219136000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_428000-seen_tokens_219136000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_428000-seen_tokens_219136000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_428000-seen_tokens_219136000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_428000-seen_tokens_219136000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_428000-seen_tokens_219136000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_428000-seen_tokens_219136000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_428000-seen_tokens_219136000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:30:15 | step: 428100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.721599493175745e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.58 | consumed tokens: 219187200.0 | grad norm avg: 9.14 | grad norm last: 8.82 | 
2025-12-28T01:30:17 | step: 428200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.720256351400167e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.78 | consumed tokens: 219238400.0 | grad norm avg: 9.1 | grad norm last: 8.62 | 
2025-12-28T01:30:19 | step: 428300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.718913209624588e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.44 | consumed tokens: 219289600.0 | grad norm avg: 9.06 | grad norm last: 8.81 | 
2025-12-28T01:30:21 | step: 428400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.717569340253249e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.78 | consumed tokens: 219340800.0 | grad norm avg: 9.11 | grad norm last: 8.9 | 
2025-12-28T01:30:23 | step: 428500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.71622619847767e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.69 | consumed tokens: 219392000.0 | grad norm avg: 8.76 | grad norm last: 11.26 | 
2025-12-28T01:30:25 | step: 428600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.714882329106331e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.95 | consumed tokens: 219443200.0 | grad norm avg: 9.13 | grad norm last: 10.22 | 
2025-12-28T01:30:27 | step: 428700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.713538459734991e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.97 | consumed tokens: 219494400.0 | grad norm avg: 9.12 | grad norm last: 8.83 | 
2025-12-28T01:30:29 | step: 428800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.712194590363652e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.75 | consumed tokens: 219545600.0 | grad norm avg: 9.64 | grad norm last: 8.4 | 
2025-12-28T01:30:31 | step: 428900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.710850720992312e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.52 | consumed tokens: 219596800.0 | grad norm avg: 8.98 | grad norm last: 8.83 | 
2025-12-28T01:30:33 | step: 429000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.709506851620972e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.17 | consumed tokens: 219648000.0 | grad norm avg: 9.38 | grad norm last: 8.17 | 
2025-12-28T01:30:35 | step: 429100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.708162254653871e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 2.75 | consumed tokens: 219699200.0 | grad norm avg: 8.87 | grad norm last: 8.28 | 
2025-12-28T01:30:37 | step: 429200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.706818385282531e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.56 | consumed tokens: 219750400.0 | grad norm avg: 9.03 | grad norm last: 8.99 | 
2025-12-28T01:30:39 | step: 429300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.70547378831543e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.91 | consumed tokens: 219801600.0 | grad norm avg: 9.5 | grad norm last: 11.26 | 
2025-12-28T01:30:41 | step: 429400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.704129191348329e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.88 | consumed tokens: 219852800.0 | grad norm avg: 9.01 | grad norm last: 10.04 | 
2025-12-28T01:30:43 | step: 429500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.702784594381228e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.42 | consumed tokens: 219904000.0 | grad norm avg: 9.26 | grad norm last: 8.43 | 
2025-12-28T01:30:46 | step: 429600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.701439269818366e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.25 | consumed tokens: 219955200.0 | grad norm avg: 9.76 | grad norm last: 9.91 | 
2025-12-28T01:30:48 | step: 429700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.700094672851264e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.67 | consumed tokens: 220006400.0 | grad norm avg: 9.41 | grad norm last: 12.26 | 
2025-12-28T01:30:50 | step: 429800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 6.698749348288402e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.91 | consumed tokens: 220057600.0 | grad norm avg: 9.19 | grad norm last: 10.5 | 
2025-12-28T01:30:52 | step: 429900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 6.697404751321301e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.12 | consumed tokens: 220108800.0 | grad norm avg: 9.21 | grad norm last: 7.87 | 
2025-12-28T01:30:54 | step: 430000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 6.696059426758438e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.45 | consumed tokens: 220160000.0 | grad norm avg: 8.81 | grad norm last: 7.87 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_430000-seen_tokens_220160000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_430000-seen_tokens_220160000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_430000-seen_tokens_220160000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_430000-seen_tokens_220160000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_430000-seen_tokens_220160000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_430000-seen_tokens_220160000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_430000-seen_tokens_220160000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_430000-seen_tokens_220160000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:30:56 | step: 430100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.694714102195576e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.78 | train loss last: 4.03 | consumed tokens: 220211200.0 | grad norm avg: 9.33 | grad norm last: 7.93 | 
2025-12-28T01:30:58 | step: 430200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.693368050036952e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.34 | consumed tokens: 220262400.0 | grad norm avg: 9.27 | grad norm last: 8.88 | 
2025-12-28T01:31:00 | step: 430300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.69202272547409e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.39 | consumed tokens: 220313600.0 | grad norm avg: 9.16 | grad norm last: 8.13 | 
2025-12-28T01:31:02 | step: 430400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.690676673315465e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.36 | consumed tokens: 220364800.0 | grad norm avg: 9.19 | grad norm last: 7.51 | 
2025-12-28T01:31:04 | step: 430500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 6.689331348752603e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.98 | consumed tokens: 220416000.0 | grad norm avg: 8.99 | grad norm last: 10.61 | 
2025-12-28T01:31:06 | step: 430600 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 6.687985296593979e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.22 | consumed tokens: 220467200.0 | grad norm avg: 9.01 | grad norm last: 9.4 | 
2025-12-28T01:31:08 | step: 430700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 6.686639244435355e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.03 | consumed tokens: 220518400.0 | grad norm avg: 8.92 | grad norm last: 9.62 | 
2025-12-28T01:31:10 | step: 430800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 6.685293192276731e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.97 | consumed tokens: 220569600.0 | grad norm avg: 9.17 | grad norm last: 8.47 | 
2025-12-28T01:31:12 | step: 430900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.683946412522346e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.91 | consumed tokens: 220620800.0 | grad norm avg: 8.96 | grad norm last: 8.88 | 
2025-12-28T01:31:14 | step: 431000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.682600360363722e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.39 | consumed tokens: 220672000.0 | grad norm avg: 9.12 | grad norm last: 8.54 | 
2025-12-28T01:31:16 | step: 431100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.681253580609336e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.09 | consumed tokens: 220723200.0 | grad norm avg: 9.29 | grad norm last: 19.04 | 
2025-12-28T01:31:18 | step: 431200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.679906800854951e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.66 | consumed tokens: 220774400.0 | grad norm avg: 9.09 | grad norm last: 7.93 | 
2025-12-28T01:31:20 | step: 431300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.678560021100566e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.53 | consumed tokens: 220825600.0 | grad norm avg: 8.96 | grad norm last: 8.19 | 
2025-12-28T01:31:22 | step: 431400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.67721324134618e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 2.83 | consumed tokens: 220876800.0 | grad norm avg: 9.52 | grad norm last: 6.65 | 
2025-12-28T01:31:24 | step: 431500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.675866461591795e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.83 | consumed tokens: 220928000.0 | grad norm avg: 9.03 | grad norm last: 9.28 | 
2025-12-28T01:31:26 | step: 431600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.674518954241648e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.94 | consumed tokens: 220979200.0 | grad norm avg: 9.1 | grad norm last: 9.08 | 
2025-12-28T01:31:28 | step: 431700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.673172174487263e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.7 | consumed tokens: 221030400.0 | grad norm avg: 9.13 | grad norm last: 9.61 | 
2025-12-28T01:31:30 | step: 431800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.671824667137116e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.61 | consumed tokens: 221081600.0 | grad norm avg: 8.99 | grad norm last: 8.35 | 
2025-12-28T01:31:32 | step: 431900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.67047715978697e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 2.94 | consumed tokens: 221132800.0 | grad norm avg: 8.86 | grad norm last: 8.4 | 
2025-12-28T01:31:34 | step: 432000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.669129652436823e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.02 | consumed tokens: 221184000.0 | grad norm avg: 9.18 | grad norm last: 7.81 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_432000-seen_tokens_221184000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_432000-seen_tokens_221184000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_432000-seen_tokens_221184000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_432000-seen_tokens_221184000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_432000-seen_tokens_221184000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_432000-seen_tokens_221184000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_432000-seen_tokens_221184000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_432000-seen_tokens_221184000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:31:37 | step: 432100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.667782145086676e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.78 | consumed tokens: 221235200.0 | grad norm avg: 9.38 | grad norm last: 11.74 | 
2025-12-28T01:31:39 | step: 432200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.666434637736529e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.95 | consumed tokens: 221286400.0 | grad norm avg: 9.05 | grad norm last: 9.56 | 
2025-12-28T01:31:41 | step: 432300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 6.665086402790621e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.22 | consumed tokens: 221337600.0 | grad norm avg: 9.49 | grad norm last: 9.66 | 
2025-12-28T01:31:43 | step: 432400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.663738167844713e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.22 | consumed tokens: 221388800.0 | grad norm avg: 8.97 | grad norm last: 9.39 | 
2025-12-28T01:31:45 | step: 432500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.662390660494566e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 5.0 | consumed tokens: 221440000.0 | grad norm avg: 9.15 | grad norm last: 8.64 | 
2025-12-28T01:31:47 | step: 432600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.661042425548658e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.28 | consumed tokens: 221491200.0 | grad norm avg: 8.88 | grad norm last: 8.93 | 
2025-12-28T01:31:49 | step: 432700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.659693463006988e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.42 | consumed tokens: 221542400.0 | grad norm avg: 8.84 | grad norm last: 7.96 | 
2025-12-28T01:31:51 | step: 432800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.65834522806108e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.03 | consumed tokens: 221593600.0 | grad norm avg: 9.51 | grad norm last: 9.0 | 
2025-12-28T01:31:53 | step: 432900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.656996993115172e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.83 | consumed tokens: 221644800.0 | grad norm avg: 8.93 | grad norm last: 9.05 | 
2025-12-28T01:31:55 | step: 433000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.655648030573502e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.84 | consumed tokens: 221696000.0 | grad norm avg: 8.7 | grad norm last: 9.29 | 
2025-12-28T01:31:57 | step: 433100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.654299068031833e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.0 | consumed tokens: 221747200.0 | grad norm avg: 8.97 | grad norm last: 8.03 | 
2025-12-28T01:31:59 | step: 433200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.652950105490163e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.83 | consumed tokens: 221798400.0 | grad norm avg: 8.86 | grad norm last: 8.81 | 
2025-12-28T01:32:01 | step: 433300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.651601142948493e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.73 | consumed tokens: 221849600.0 | grad norm avg: 8.83 | grad norm last: 8.08 | 
2025-12-28T01:32:03 | step: 433400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.650252180406824e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.38 | consumed tokens: 221900800.0 | grad norm avg: 8.83 | grad norm last: 7.38 | 
2025-12-28T01:32:05 | step: 433500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.648903217865154e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 2.97 | consumed tokens: 221952000.0 | grad norm avg: 8.94 | grad norm last: 7.37 | 
2025-12-28T01:32:07 | step: 433600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.647553527727723e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 2.5 | consumed tokens: 222003200.0 | grad norm avg: 8.91 | grad norm last: 7.65 | 
2025-12-28T01:32:09 | step: 433700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.646204565186054e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.48 | consumed tokens: 222054400.0 | grad norm avg: 9.04 | grad norm last: 8.69 | 
2025-12-28T01:32:11 | step: 433800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.644854875048622e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.83 | consumed tokens: 222105600.0 | grad norm avg: 9.06 | grad norm last: 8.47 | 
2025-12-28T01:32:13 | step: 433900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.643505184911191e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 4.12 | consumed tokens: 222156800.0 | grad norm avg: 9.22 | grad norm last: 10.93 | 
2025-12-28T01:32:15 | step: 434000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.64215549477376e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.55 | consumed tokens: 222208000.0 | grad norm avg: 9.36 | grad norm last: 7.74 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_434000-seen_tokens_222208000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_434000-seen_tokens_222208000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_434000-seen_tokens_222208000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_434000-seen_tokens_222208000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_434000-seen_tokens_222208000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_434000-seen_tokens_222208000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_434000-seen_tokens_222208000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_434000-seen_tokens_222208000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:32:18 | step: 434100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.64080580463633e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.78 | train loss last: 3.31 | consumed tokens: 222259200.0 | grad norm avg: 8.86 | grad norm last: 8.12 | 
2025-12-28T01:32:20 | step: 434200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.639455386903137e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.09 | consumed tokens: 222310400.0 | grad norm avg: 9.05 | grad norm last: 18.01 | 
2025-12-28T01:32:22 | step: 434300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.638105696765706e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.84 | consumed tokens: 222361600.0 | grad norm avg: 8.93 | grad norm last: 8.22 | 
2025-12-28T01:32:24 | step: 434400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.636755279032513e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.3 | consumed tokens: 222412800.0 | grad norm avg: 9.07 | grad norm last: 7.88 | 
2025-12-28T01:32:26 | step: 434500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.635404861299321e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.23 | consumed tokens: 222464000.0 | grad norm avg: 9.03 | grad norm last: 8.97 | 
2025-12-28T01:32:28 | step: 434600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.634054443566129e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.8 | consumed tokens: 222515200.0 | grad norm avg: 8.61 | grad norm last: 8.68 | 
2025-12-28T01:32:30 | step: 434700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.632704025832936e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.77 | consumed tokens: 222566400.0 | grad norm avg: 8.68 | grad norm last: 8.2 | 
2025-12-28T01:32:32 | step: 434800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 6.631353608099744e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.41 | consumed tokens: 222617600.0 | grad norm avg: 8.76 | grad norm last: 7.76 | 
2025-12-28T01:32:34 | step: 434900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 6.63000246277079e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.39 | consumed tokens: 222668800.0 | grad norm avg: 8.95 | grad norm last: 8.02 | 
2025-12-28T01:32:36 | step: 435000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.628651317441836e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.42 | consumed tokens: 222720000.0 | grad norm avg: 8.82 | grad norm last: 7.68 | 
2025-12-28T01:32:38 | step: 435100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.627300899708644e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.44 | consumed tokens: 222771200.0 | grad norm avg: 9.0 | grad norm last: 8.06 | 
2025-12-28T01:32:40 | step: 435200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.62594975437969e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.27 | consumed tokens: 222822400.0 | grad norm avg: 9.35 | grad norm last: 11.7 | 
2025-12-28T01:32:42 | step: 435300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.624598609050736e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.22 | consumed tokens: 222873600.0 | grad norm avg: 9.28 | grad norm last: 8.68 | 
2025-12-28T01:32:44 | step: 435400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.62324673612602e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.0 | consumed tokens: 222924800.0 | grad norm avg: 8.94 | grad norm last: 9.94 | 
2025-12-28T01:32:46 | step: 435500 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 6.621895590797067e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.53 | consumed tokens: 222976000.0 | grad norm avg: 8.7 | grad norm last: 7.55 | 
2025-12-28T01:32:48 | step: 435600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 6.620544445468113e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.23 | consumed tokens: 223027200.0 | grad norm avg: 8.74 | grad norm last: 7.82 | 
2025-12-28T01:32:50 | step: 435700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 6.619192572543398e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.45 | consumed tokens: 223078400.0 | grad norm avg: 8.79 | grad norm last: 18.46 | 
2025-12-28T01:32:52 | step: 435800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.617840699618682e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.12 | consumed tokens: 223129600.0 | grad norm avg: 8.89 | grad norm last: 7.24 | 
2025-12-28T01:32:54 | step: 435900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.616488826693967e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.7 | consumed tokens: 223180800.0 | grad norm avg: 8.75 | grad norm last: 7.76 | 
2025-12-28T01:32:56 | step: 436000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.615136953769252e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.19 | consumed tokens: 223232000.0 | grad norm avg: 8.66 | grad norm last: 9.16 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_436000-seen_tokens_223232000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_436000-seen_tokens_223232000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_436000-seen_tokens_223232000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_436000-seen_tokens_223232000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_436000-seen_tokens_223232000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_436000-seen_tokens_223232000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_436000-seen_tokens_223232000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_436000-seen_tokens_223232000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:32:58 | step: 436100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.613785080844536e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.75 | train loss last: 3.73 | consumed tokens: 223283200.0 | grad norm avg: 8.68 | grad norm last: 8.5 | 
2025-12-28T01:33:00 | step: 436200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.61243248032406e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.66 | consumed tokens: 223334400.0 | grad norm avg: 8.73 | grad norm last: 11.55 | 
2025-12-28T01:33:02 | step: 436300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 6.611080607399344e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.67 | consumed tokens: 223385600.0 | grad norm avg: 8.64 | grad norm last: 8.53 | 
2025-12-28T01:33:04 | step: 436400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.609728006878868e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.83 | consumed tokens: 223436800.0 | grad norm avg: 8.63 | grad norm last: 10.06 | 
2025-12-28T01:33:06 | step: 436500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.608375406358391e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.88 | consumed tokens: 223488000.0 | grad norm avg: 8.84 | grad norm last: 8.55 | 
2025-12-28T01:33:08 | step: 436600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.607022805837914e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.59 | consumed tokens: 223539200.0 | grad norm avg: 8.6 | grad norm last: 8.22 | 
2025-12-28T01:33:11 | step: 436700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.605670205317438e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 5.34 | consumed tokens: 223590400.0 | grad norm avg: 8.78 | grad norm last: 13.84 | 
2025-12-28T01:33:13 | step: 436800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.604317604796961e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.91 | consumed tokens: 223641600.0 | grad norm avg: 8.71 | grad norm last: 9.13 | 
2025-12-28T01:33:15 | step: 436900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 6.602965004276484e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.23 | consumed tokens: 223692800.0 | grad norm avg: 8.53 | grad norm last: 8.2 | 
2025-12-28T01:33:17 | step: 437000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.601611676160246e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 2.98 | consumed tokens: 223744000.0 | grad norm avg: 9.03 | grad norm last: 7.3 | 
2025-12-28T01:33:19 | step: 437100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.600258348044008e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.12 | consumed tokens: 223795200.0 | grad norm avg: 8.92 | grad norm last: 9.62 | 
2025-12-28T01:33:21 | step: 437200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.59890501992777e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.83 | consumed tokens: 223846400.0 | grad norm avg: 8.68 | grad norm last: 8.44 | 
2025-12-28T01:33:23 | step: 437300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.597551691811532e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.38 | consumed tokens: 223897600.0 | grad norm avg: 8.7 | grad norm last: 7.84 | 
2025-12-28T01:33:25 | step: 437400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.596198363695294e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.33 | consumed tokens: 223948800.0 | grad norm avg: 8.63 | grad norm last: 7.27 | 
2025-12-28T01:33:27 | step: 437500 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.594845035579056e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.73 | consumed tokens: 224000000.0 | grad norm avg: 8.63 | grad norm last: 7.51 | 
2025-12-28T01:33:29 | step: 437600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.593491707462817e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.34 | consumed tokens: 224051200.0 | grad norm avg: 8.75 | grad norm last: 8.35 | 
2025-12-28T01:33:31 | step: 437700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.592137651750818e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.81 | consumed tokens: 224102400.0 | grad norm avg: 8.89 | grad norm last: 9.92 | 
2025-12-28T01:33:33 | step: 437800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.590783596038818e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.97 | consumed tokens: 224153600.0 | grad norm avg: 8.86 | grad norm last: 9.67 | 
2025-12-28T01:33:35 | step: 437900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.589429540326819e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.58 | consumed tokens: 224204800.0 | grad norm avg: 8.9 | grad norm last: 8.05 | 
2025-12-28T01:33:37 | step: 438000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.588075484614819e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 3.53 | consumed tokens: 224256000.0 | grad norm avg: 9.07 | grad norm last: 8.59 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_438000-seen_tokens_224256000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_438000-seen_tokens_224256000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_438000-seen_tokens_224256000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_438000-seen_tokens_224256000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_438000-seen_tokens_224256000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_438000-seen_tokens_224256000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_438000-seen_tokens_224256000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_438000-seen_tokens_224256000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:33:39 | step: 438100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.58672142890282e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.82 | train loss last: 3.02 | consumed tokens: 224307200.0 | grad norm avg: 8.95 | grad norm last: 7.22 | 
2025-12-28T01:33:41 | step: 438200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.58536737319082e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.84 | train loss last: 3.77 | consumed tokens: 224358400.0 | grad norm avg: 8.83 | grad norm last: 9.07 | 
2025-12-28T01:33:43 | step: 438300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.584013317478821e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.81 | consumed tokens: 224409600.0 | grad norm avg: 8.76 | grad norm last: 12.31 | 
2025-12-28T01:33:45 | step: 438400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.58265853417106e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.97 | consumed tokens: 224460800.0 | grad norm avg: 8.87 | grad norm last: 10.13 | 
2025-12-28T01:33:47 | step: 438500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.581303750863299e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.45 | consumed tokens: 224512000.0 | grad norm avg: 8.95 | grad norm last: 9.08 | 
2025-12-28T01:33:49 | step: 438600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.579948967555538e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.59 | consumed tokens: 224563200.0 | grad norm avg: 8.83 | grad norm last: 9.95 | 
2025-12-28T01:33:51 | step: 438700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.578594184247777e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.5 | consumed tokens: 224614400.0 | grad norm avg: 8.95 | grad norm last: 8.1 | 
2025-12-28T01:33:53 | step: 438800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.577239400940016e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.39 | consumed tokens: 224665600.0 | grad norm avg: 8.72 | grad norm last: 8.19 | 
2025-12-28T01:33:55 | step: 438900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.575884617632255e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.0 | consumed tokens: 224716800.0 | grad norm avg: 8.81 | grad norm last: 8.77 | 
2025-12-28T01:33:57 | step: 439000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.574529106728733e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 2.89 | consumed tokens: 224768000.0 | grad norm avg: 8.7 | grad norm last: 7.42 | 
2025-12-28T01:33:59 | step: 439100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.573174323420972e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.41 | consumed tokens: 224819200.0 | grad norm avg: 8.97 | grad norm last: 7.86 | 
2025-12-28T01:34:01 | step: 439200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.571818812517449e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.91 | consumed tokens: 224870400.0 | grad norm avg: 8.81 | grad norm last: 9.12 | 
2025-12-28T01:34:03 | step: 439300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.570463301613927e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.53 | consumed tokens: 224921600.0 | grad norm avg: 8.64 | grad norm last: 8.43 | 
2025-12-28T01:34:05 | step: 439400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.569107790710405e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.81 | consumed tokens: 224972800.0 | grad norm avg: 8.9 | grad norm last: 7.86 | 
2025-12-28T01:34:08 | step: 439500 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 6.567752279806882e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.88 | consumed tokens: 225024000.0 | grad norm avg: 8.75 | grad norm last: 8.57 | 
2025-12-28T01:34:10 | step: 439600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.56639676890336e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 5.03 | consumed tokens: 225075200.0 | grad norm avg: 8.75 | grad norm last: 10.1 | 
2025-12-28T01:34:12 | step: 439700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.565040530404076e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.06 | consumed tokens: 225126400.0 | grad norm avg: 9.19 | grad norm last: 8.81 | 
2025-12-28T01:34:14 | step: 439800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.563685019500554e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.09 | consumed tokens: 225177600.0 | grad norm avg: 9.23 | grad norm last: 8.22 | 
2025-12-28T01:34:16 | step: 439900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.56232878100127e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.03 | consumed tokens: 225228800.0 | grad norm avg: 8.8 | grad norm last: 7.62 | 
2025-12-28T01:34:18 | step: 440000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.560972542501986e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.47 | consumed tokens: 225280000.0 | grad norm avg: 8.98 | grad norm last: 7.59 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_440000-seen_tokens_225280000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_440000-seen_tokens_225280000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_440000-seen_tokens_225280000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_440000-seen_tokens_225280000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_440000-seen_tokens_225280000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_440000-seen_tokens_225280000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_440000-seen_tokens_225280000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_440000-seen_tokens_225280000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:34:20 | step: 440100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 6.559616304002702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.42 | consumed tokens: 225331200.0 | grad norm avg: 8.85 | grad norm last: 9.4 | 
2025-12-28T01:34:22 | step: 440200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 6.558260065503418e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.22 | consumed tokens: 225382400.0 | grad norm avg: 8.66 | grad norm last: 11.46 | 
2025-12-28T01:34:24 | step: 440300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.556903827004135e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.31 | consumed tokens: 225433600.0 | grad norm avg: 8.77 | grad norm last: 7.7 | 
2025-12-28T01:34:26 | step: 440400 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 6.55554686090909e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 5.28 | consumed tokens: 225484800.0 | grad norm avg: 9.25 | grad norm last: 11.0 | 
2025-12-28T01:34:28 | step: 440500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 6.554190622409806e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.39 | consumed tokens: 225536000.0 | grad norm avg: 9.1 | grad norm last: 8.12 | 
2025-12-28T01:34:30 | step: 440600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 6.55283365631476e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.53 | consumed tokens: 225587200.0 | grad norm avg: 8.76 | grad norm last: 11.8 | 
2025-12-28T01:34:32 | step: 440700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.551476690219715e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.09 | consumed tokens: 225638400.0 | grad norm avg: 8.99 | grad norm last: 11.15 | 
2025-12-28T01:34:34 | step: 440800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.55011972412467e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.56 | consumed tokens: 225689600.0 | grad norm avg: 8.82 | grad norm last: 12.28 | 
2025-12-28T01:34:36 | step: 440900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.548762758029625e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.12 | consumed tokens: 225740800.0 | grad norm avg: 9.19 | grad norm last: 8.91 | 
2025-12-28T01:34:38 | step: 441000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.54740579193458e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 5.38 | consumed tokens: 225792000.0 | grad norm avg: 9.05 | grad norm last: 29.6 | 
2025-12-28T01:34:40 | step: 441100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 6.546048825839534e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 4.38 | consumed tokens: 225843200.0 | grad norm avg: 8.84 | grad norm last: 9.59 | 
2025-12-28T01:34:42 | step: 441200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.544691132148728e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.11 | consumed tokens: 225894400.0 | grad norm avg: 8.78 | grad norm last: 8.94 | 
2025-12-28T01:34:44 | step: 441300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 6.543333438457921e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.94 | consumed tokens: 225945600.0 | grad norm avg: 8.57 | grad norm last: 10.14 | 
2025-12-28T01:34:46 | step: 441400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.541976472362876e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.81 | consumed tokens: 225996800.0 | grad norm avg: 9.0 | grad norm last: 8.14 | 
2025-12-28T01:34:48 | step: 441500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.540618778672069e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 2.98 | consumed tokens: 226048000.0 | grad norm avg: 8.65 | grad norm last: 9.14 | 
2025-12-28T01:34:50 | step: 441600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.539261084981263e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.39 | consumed tokens: 226099200.0 | grad norm avg: 8.78 | grad norm last: 8.12 | 
2025-12-28T01:34:52 | step: 441700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.537902663694695e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 2.45 | consumed tokens: 226150400.0 | grad norm avg: 8.82 | grad norm last: 6.87 | 
2025-12-28T01:34:55 | step: 441800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 6.536544970003888e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.98 | consumed tokens: 226201600.0 | grad norm avg: 8.84 | grad norm last: 9.65 | 
2025-12-28T01:34:57 | step: 441900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 6.535187276313081e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.23 | consumed tokens: 226252800.0 | grad norm avg: 9.07 | grad norm last: 7.37 | 
2025-12-28T01:34:59 | step: 442000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.533828855026513e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.12 | consumed tokens: 226304000.0 | grad norm avg: 8.77 | grad norm last: 8.91 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_442000-seen_tokens_226304000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_442000-seen_tokens_226304000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_442000-seen_tokens_226304000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_442000-seen_tokens_226304000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_442000-seen_tokens_226304000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_442000-seen_tokens_226304000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_442000-seen_tokens_226304000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_442000-seen_tokens_226304000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:35:01 | step: 442100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.532470433739945e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.65 | train loss last: 3.84 | consumed tokens: 226355200.0 | grad norm avg: 8.89 | grad norm last: 8.03 | 
2025-12-28T01:35:03 | step: 442200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.531112012453377e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.28 | consumed tokens: 226406400.0 | grad norm avg: 9.15 | grad norm last: 12.01 | 
2025-12-28T01:35:05 | step: 442300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.529753591166809e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.67 | consumed tokens: 226457600.0 | grad norm avg: 8.87 | grad norm last: 9.7 | 
2025-12-28T01:35:07 | step: 442400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.528395169880241e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.05 | consumed tokens: 226508800.0 | grad norm avg: 8.87 | grad norm last: 8.28 | 
2025-12-28T01:35:09 | step: 442500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.527036748593673e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.61 | consumed tokens: 226560000.0 | grad norm avg: 9.01 | grad norm last: 8.68 | 
2025-12-28T01:35:11 | step: 442600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.525677599711344e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.48 | consumed tokens: 226611200.0 | grad norm avg: 8.92 | grad norm last: 8.82 | 
2025-12-28T01:35:13 | step: 442700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.524319178424776e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.17 | consumed tokens: 226662400.0 | grad norm avg: 9.17 | grad norm last: 7.7 | 
2025-12-28T01:35:15 | step: 442800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.522960029542446e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.09 | consumed tokens: 226713600.0 | grad norm avg: 9.17 | grad norm last: 8.96 | 
2025-12-28T01:35:17 | step: 442900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.521600880660117e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.58 | consumed tokens: 226764800.0 | grad norm avg: 8.58 | grad norm last: 7.97 | 
2025-12-28T01:35:19 | step: 443000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.520241731777787e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.22 | consumed tokens: 226816000.0 | grad norm avg: 8.95 | grad norm last: 8.44 | 
2025-12-28T01:35:21 | step: 443100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.518882582895458e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.86 | consumed tokens: 226867200.0 | grad norm avg: 9.14 | grad norm last: 7.91 | 
2025-12-28T01:35:23 | step: 443200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.517523434013128e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.41 | consumed tokens: 226918400.0 | grad norm avg: 8.86 | grad norm last: 7.71 | 
2025-12-28T01:35:25 | step: 443300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.516163557535037e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.83 | consumed tokens: 226969600.0 | grad norm avg: 9.23 | grad norm last: 8.12 | 
2025-12-28T01:35:27 | step: 443400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.514804408652708e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 4.22 | consumed tokens: 227020800.0 | grad norm avg: 9.02 | grad norm last: 10.16 | 
2025-12-28T01:35:29 | step: 443500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.513444532174617e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.19 | consumed tokens: 227072000.0 | grad norm avg: 8.79 | grad norm last: 9.05 | 
2025-12-28T01:35:31 | step: 443600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.512084655696526e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.25 | consumed tokens: 227123200.0 | grad norm avg: 9.03 | grad norm last: 9.43 | 
2025-12-28T01:35:33 | step: 443700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.510725506814197e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.53 | consumed tokens: 227174400.0 | grad norm avg: 8.87 | grad norm last: 8.27 | 
2025-12-28T01:35:35 | step: 443800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.509364902740344e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.5 | consumed tokens: 227225600.0 | grad norm avg: 9.19 | grad norm last: 8.55 | 
2025-12-28T01:35:37 | step: 443900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.508005026262254e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.42 | consumed tokens: 227276800.0 | grad norm avg: 9.19 | grad norm last: 7.55 | 
2025-12-28T01:35:39 | step: 444000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.506645149784163e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.31 | consumed tokens: 227328000.0 | grad norm avg: 9.09 | grad norm last: 10.83 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_444000-seen_tokens_227328000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_444000-seen_tokens_227328000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_444000-seen_tokens_227328000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_444000-seen_tokens_227328000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_444000-seen_tokens_227328000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_444000-seen_tokens_227328000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_444000-seen_tokens_227328000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_444000-seen_tokens_227328000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:35:42 | step: 444100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.505285273306072e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.85 | train loss last: 2.86 | consumed tokens: 227379200.0 | grad norm avg: 9.11 | grad norm last: 8.95 | 
2025-12-28T01:35:44 | step: 444200 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.50392466923222e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.91 | consumed tokens: 227430400.0 | grad norm avg: 8.91 | grad norm last: 11.27 | 
2025-12-28T01:35:46 | step: 444300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.502564065158367e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.25 | consumed tokens: 227481600.0 | grad norm avg: 9.25 | grad norm last: 11.3 | 
2025-12-28T01:35:48 | step: 444400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.501203461084515e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.67 | consumed tokens: 227532800.0 | grad norm avg: 9.22 | grad norm last: 7.97 | 
2025-12-28T01:35:50 | step: 444500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.499842857010663e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.95 | consumed tokens: 227584000.0 | grad norm avg: 8.95 | grad norm last: 7.8 | 
2025-12-28T01:35:52 | step: 444600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.49848225293681e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.48 | consumed tokens: 227635200.0 | grad norm avg: 8.94 | grad norm last: 9.52 | 
2025-12-28T01:35:54 | step: 444700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.497121648862958e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.53 | consumed tokens: 227686400.0 | grad norm avg: 8.91 | grad norm last: 10.43 | 
2025-12-28T01:35:56 | step: 444800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.495761044789106e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.34 | consumed tokens: 227737600.0 | grad norm avg: 9.56 | grad norm last: 9.72 | 
2025-12-28T01:35:58 | step: 444900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.494399713119492e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.38 | consumed tokens: 227788800.0 | grad norm avg: 8.98 | grad norm last: 8.5 | 
2025-12-28T01:36:00 | step: 445000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.493038381449878e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.84 | consumed tokens: 227840000.0 | grad norm avg: 9.24 | grad norm last: 8.4 | 
2025-12-28T01:36:02 | step: 445100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 6.491677777376026e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.75 | consumed tokens: 227891200.0 | grad norm avg: 9.08 | grad norm last: 8.38 | 
2025-12-28T01:36:04 | step: 445200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 6.490316445706412e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.55 | consumed tokens: 227942400.0 | grad norm avg: 9.08 | grad norm last: 8.79 | 
2025-12-28T01:36:06 | step: 445300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 6.488955114036798e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.31 | consumed tokens: 227993600.0 | grad norm avg: 9.14 | grad norm last: 8.15 | 
2025-12-28T01:36:08 | step: 445400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.487593782367185e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.03 | consumed tokens: 228044800.0 | grad norm avg: 9.48 | grad norm last: 11.48 | 
2025-12-28T01:36:10 | step: 445500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.48623172310181e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.31 | consumed tokens: 228096000.0 | grad norm avg: 9.42 | grad norm last: 10.23 | 
2025-12-28T01:36:12 | step: 445600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.484870391432196e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.06 | consumed tokens: 228147200.0 | grad norm avg: 9.81 | grad norm last: 10.92 | 
2025-12-28T01:36:14 | step: 445700 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 6.483508332166821e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.47 | consumed tokens: 228198400.0 | grad norm avg: 9.16 | grad norm last: 8.74 | 
2025-12-28T01:36:16 | step: 445800 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 6.482147000497207e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.62 | consumed tokens: 228249600.0 | grad norm avg: 9.15 | grad norm last: 10.43 | 
2025-12-28T01:36:18 | step: 445900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 6.480784941231832e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.66 | consumed tokens: 228300800.0 | grad norm avg: 9.77 | grad norm last: 7.77 | 
2025-12-28T01:36:20 | step: 446000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.479422881966457e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.22 | consumed tokens: 228352000.0 | grad norm avg: 9.15 | grad norm last: 9.21 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_446000-seen_tokens_228352000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_446000-seen_tokens_228352000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_446000-seen_tokens_228352000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_446000-seen_tokens_228352000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_446000-seen_tokens_228352000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_446000-seen_tokens_228352000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_446000-seen_tokens_228352000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_446000-seen_tokens_228352000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:36:22 | step: 446100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.478060822701082e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.17 | consumed tokens: 228403200.0 | grad norm avg: 9.45 | grad norm last: 9.29 | 
2025-12-28T01:36:24 | step: 446200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.476698763435706e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.14 | consumed tokens: 228454400.0 | grad norm avg: 9.09 | grad norm last: 9.66 | 
2025-12-28T01:36:26 | step: 446300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.47533597657457e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.03 | consumed tokens: 228505600.0 | grad norm avg: 9.22 | grad norm last: 9.05 | 
2025-12-28T01:36:28 | step: 446400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 6.473973917309195e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.61 | consumed tokens: 228556800.0 | grad norm avg: 9.21 | grad norm last: 10.03 | 
2025-12-28T01:36:31 | step: 446500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 6.472611130448058e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.3 | consumed tokens: 228608000.0 | grad norm avg: 9.61 | grad norm last: 8.32 | 
2025-12-28T01:36:33 | step: 446600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.471248343586922e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.88 | consumed tokens: 228659200.0 | grad norm avg: 9.22 | grad norm last: 8.57 | 
2025-12-28T01:36:35 | step: 446700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.469886284321547e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.62 | consumed tokens: 228710400.0 | grad norm avg: 9.29 | grad norm last: 8.39 | 
2025-12-28T01:36:37 | step: 446800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.46852349746041e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.16 | consumed tokens: 228761600.0 | grad norm avg: 9.2 | grad norm last: 6.99 | 
2025-12-28T01:36:39 | step: 446900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.467159983003512e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.83 | consumed tokens: 228812800.0 | grad norm avg: 9.64 | grad norm last: 8.9 | 
2025-12-28T01:36:41 | step: 447000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 6.465797196142375e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 2.86 | consumed tokens: 228864000.0 | grad norm avg: 9.25 | grad norm last: 8.15 | 
2025-12-28T01:36:43 | step: 447100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.464434409281239e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.73 | consumed tokens: 228915200.0 | grad norm avg: 9.81 | grad norm last: 8.75 | 
2025-12-28T01:36:45 | step: 447200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.463070894824341e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.56 | consumed tokens: 228966400.0 | grad norm avg: 9.31 | grad norm last: 10.27 | 
2025-12-28T01:36:47 | step: 447300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.461708107963204e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.28 | consumed tokens: 229017600.0 | grad norm avg: 9.89 | grad norm last: 8.44 | 
2025-12-28T01:36:49 | step: 447400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.460344593506306e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.22 | consumed tokens: 229068800.0 | grad norm avg: 9.25 | grad norm last: 12.19 | 
2025-12-28T01:36:51 | step: 447500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.458981079049408e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.08 | consumed tokens: 229120000.0 | grad norm avg: 9.21 | grad norm last: 7.6 | 
2025-12-28T01:36:53 | step: 447600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.45761756459251e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.75 | consumed tokens: 229171200.0 | grad norm avg: 9.58 | grad norm last: 9.32 | 
2025-12-28T01:36:55 | step: 447700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.456254050135612e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.38 | consumed tokens: 229222400.0 | grad norm avg: 9.37 | grad norm last: 7.91 | 
2025-12-28T01:36:57 | step: 447800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.454890535678715e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.91 | consumed tokens: 229273600.0 | grad norm avg: 9.63 | grad norm last: 9.17 | 
2025-12-28T01:36:59 | step: 447900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.453526293626055e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 2.73 | consumed tokens: 229324800.0 | grad norm avg: 9.36 | grad norm last: 7.77 | 
2025-12-28T01:37:01 | step: 448000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.452162779169157e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.84 | consumed tokens: 229376000.0 | grad norm avg: 9.1 | grad norm last: 10.76 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_448000-seen_tokens_229376000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_448000-seen_tokens_229376000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_448000-seen_tokens_229376000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_448000-seen_tokens_229376000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_448000-seen_tokens_229376000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_448000-seen_tokens_229376000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_448000-seen_tokens_229376000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_448000-seen_tokens_229376000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:37:03 | step: 448100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.450798537116498e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.85 | train loss last: 3.55 | consumed tokens: 229427200.0 | grad norm avg: 9.42 | grad norm last: 7.56 | 
2025-12-28T01:37:05 | step: 448200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.449434295063838e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.11 | consumed tokens: 229478400.0 | grad norm avg: 9.07 | grad norm last: 8.57 | 
2025-12-28T01:37:07 | step: 448300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.44807078060694e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.7 | consumed tokens: 229529600.0 | grad norm avg: 9.3 | grad norm last: 9.54 | 
2025-12-28T01:37:09 | step: 448400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.446706538554281e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.16 | consumed tokens: 229580800.0 | grad norm avg: 9.44 | grad norm last: 9.87 | 
2025-12-28T01:37:11 | step: 448500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.44534156890586e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.33 | consumed tokens: 229632000.0 | grad norm avg: 9.22 | grad norm last: 7.42 | 
2025-12-28T01:37:13 | step: 448600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.443977326853201e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.47 | consumed tokens: 229683200.0 | grad norm avg: 9.19 | grad norm last: 9.17 | 
2025-12-28T01:37:15 | step: 448700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.442613084800541e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.05 | consumed tokens: 229734400.0 | grad norm avg: 9.02 | grad norm last: 8.21 | 
2025-12-28T01:37:17 | step: 448800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.44124811515212e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.27 | consumed tokens: 229785600.0 | grad norm avg: 9.06 | grad norm last: 9.09 | 
2025-12-28T01:37:19 | step: 448900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.439883873099461e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.58 | consumed tokens: 229836800.0 | grad norm avg: 9.1 | grad norm last: 9.03 | 
2025-12-28T01:37:21 | step: 449000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.43851890345104e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.83 | consumed tokens: 229888000.0 | grad norm avg: 9.3 | grad norm last: 8.87 | 
2025-12-28T01:37:23 | step: 449100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.43715393380262e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.58 | consumed tokens: 229939200.0 | grad norm avg: 9.4 | grad norm last: 8.7 | 
2025-12-28T01:37:25 | step: 449200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.435788964154199e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.72 | consumed tokens: 229990400.0 | grad norm avg: 9.5 | grad norm last: 7.67 | 
2025-12-28T01:37:27 | step: 449300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.434423994505778e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.55 | consumed tokens: 230041600.0 | grad norm avg: 9.37 | grad norm last: 7.68 | 
2025-12-28T01:37:29 | step: 449400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.433059024857357e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.38 | consumed tokens: 230092800.0 | grad norm avg: 9.09 | grad norm last: 8.88 | 
2025-12-28T01:37:31 | step: 449500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.431693327613175e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.11 | consumed tokens: 230144000.0 | grad norm avg: 9.56 | grad norm last: 8.27 | 
2025-12-28T01:37:33 | step: 449600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.430328357964754e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.0 | consumed tokens: 230195200.0 | grad norm avg: 9.19 | grad norm last: 8.85 | 
2025-12-28T01:37:35 | step: 449700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.428962660720572e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.75 | consumed tokens: 230246400.0 | grad norm avg: 9.38 | grad norm last: 10.07 | 
2025-12-28T01:37:38 | step: 449800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.42759696347639e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.56 | consumed tokens: 230297600.0 | grad norm avg: 9.31 | grad norm last: 7.94 | 
2025-12-28T01:37:40 | step: 449900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.426231993827969e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 2.89 | consumed tokens: 230348800.0 | grad norm avg: 9.32 | grad norm last: 7.84 | 
2025-12-28T01:37:42 | step: 450000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.424866296583787e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.12 | consumed tokens: 230400000.0 | grad norm avg: 9.31 | grad norm last: 7.89 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_450000-seen_tokens_230400000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_450000-seen_tokens_230400000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_450000-seen_tokens_230400000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_450000-seen_tokens_230400000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_450000-seen_tokens_230400000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_450000-seen_tokens_230400000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_450000-seen_tokens_230400000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_450000-seen_tokens_230400000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:37:44 | step: 450100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.423499871743843e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.75 | train loss last: 3.05 | consumed tokens: 230451200.0 | grad norm avg: 9.44 | grad norm last: 7.89 | 
2025-12-28T01:37:46 | step: 450200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 6.422134174499661e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.28 | consumed tokens: 230502400.0 | grad norm avg: 8.91 | grad norm last: 8.52 | 
2025-12-28T01:37:48 | step: 450300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.420768477255479e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.03 | consumed tokens: 230553600.0 | grad norm avg: 9.62 | grad norm last: 9.77 | 
2025-12-28T01:37:50 | step: 450400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.419402052415535e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.64 | consumed tokens: 230604800.0 | grad norm avg: 9.3 | grad norm last: 7.77 | 
2025-12-28T01:37:52 | step: 450500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.418036355171353e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.84 | consumed tokens: 230656000.0 | grad norm avg: 9.21 | grad norm last: 13.32 | 
2025-12-28T01:37:54 | step: 450600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.416669930331409e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.06 | consumed tokens: 230707200.0 | grad norm avg: 9.18 | grad norm last: 8.9 | 
2025-12-28T01:37:56 | step: 450700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.415303505491465e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.77 | consumed tokens: 230758400.0 | grad norm avg: 9.05 | grad norm last: 8.54 | 
2025-12-28T01:37:58 | step: 450800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 6.413937080651522e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.58 | consumed tokens: 230809600.0 | grad norm avg: 8.94 | grad norm last: 8.38 | 
2025-12-28T01:38:00 | step: 450900 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 6.412570655811578e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.47 | consumed tokens: 230860800.0 | grad norm avg: 9.04 | grad norm last: 8.38 | 
2025-12-28T01:38:02 | step: 451000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 6.411204230971634e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.42 | consumed tokens: 230912000.0 | grad norm avg: 9.43 | grad norm last: 9.03 | 
2025-12-28T01:38:04 | step: 451100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.409837806131691e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.73 | consumed tokens: 230963200.0 | grad norm avg: 9.29 | grad norm last: 9.64 | 
2025-12-28T01:38:06 | step: 451200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.408470653695986e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.33 | consumed tokens: 231014400.0 | grad norm avg: 9.22 | grad norm last: 8.62 | 
2025-12-28T01:38:08 | step: 451300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.407104228856042e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.47 | consumed tokens: 231065600.0 | grad norm avg: 9.15 | grad norm last: 7.9 | 
2025-12-28T01:38:10 | step: 451400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.405737076420337e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 2.48 | consumed tokens: 231116800.0 | grad norm avg: 8.81 | grad norm last: 6.55 | 
2025-12-28T01:38:12 | step: 451500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 6.404369923984632e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.38 | consumed tokens: 231168000.0 | grad norm avg: 9.79 | grad norm last: 7.67 | 
2025-12-28T01:38:14 | step: 451600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 6.403002771548927e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.44 | consumed tokens: 231219200.0 | grad norm avg: 9.13 | grad norm last: 8.65 | 
2025-12-28T01:38:16 | step: 451700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.401635619113222e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.3 | consumed tokens: 231270400.0 | grad norm avg: 9.28 | grad norm last: 9.93 | 
2025-12-28T01:38:18 | step: 451800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.400268466677517e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.86 | consumed tokens: 231321600.0 | grad norm avg: 9.31 | grad norm last: 9.73 | 
2025-12-28T01:38:20 | step: 451900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.398901314241812e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 5.09 | consumed tokens: 231372800.0 | grad norm avg: 9.22 | grad norm last: 11.8 | 
2025-12-28T01:38:22 | step: 452000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.397533434210345e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.44 | consumed tokens: 231424000.0 | grad norm avg: 9.24 | grad norm last: 7.93 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_452000-seen_tokens_231424000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_452000-seen_tokens_231424000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_452000-seen_tokens_231424000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_452000-seen_tokens_231424000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_452000-seen_tokens_231424000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_452000-seen_tokens_231424000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_452000-seen_tokens_231424000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_452000-seen_tokens_231424000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:38:25 | step: 452100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 6.39616628177464e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.77 | train loss last: 2.72 | consumed tokens: 231475200.0 | grad norm avg: 9.34 | grad norm last: 7.96 | 
2025-12-28T01:38:27 | step: 452200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.394798401743174e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.28 | consumed tokens: 231526400.0 | grad norm avg: 9.22 | grad norm last: 8.78 | 
2025-12-28T01:38:29 | step: 452300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.393430521711707e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.78 | consumed tokens: 231577600.0 | grad norm avg: 9.24 | grad norm last: 8.4 | 
2025-12-28T01:38:31 | step: 452400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.392063369276002e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.61 | consumed tokens: 231628800.0 | grad norm avg: 9.19 | grad norm last: 8.57 | 
2025-12-28T01:38:33 | step: 452500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.390695489244536e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.33 | consumed tokens: 231680000.0 | grad norm avg: 9.29 | grad norm last: 9.78 | 
2025-12-28T01:38:35 | step: 452600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.389326881617308e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.53 | consumed tokens: 231731200.0 | grad norm avg: 9.48 | grad norm last: 8.87 | 
2025-12-28T01:38:37 | step: 452700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.387959001585841e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.77 | consumed tokens: 231782400.0 | grad norm avg: 9.19 | grad norm last: 8.39 | 
2025-12-28T01:38:39 | step: 452800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.386591121554375e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.78 | consumed tokens: 231833600.0 | grad norm avg: 9.24 | grad norm last: 9.87 | 
2025-12-28T01:38:41 | step: 452900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.385222513927147e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.53 | consumed tokens: 231884800.0 | grad norm avg: 9.02 | grad norm last: 8.96 | 
2025-12-28T01:38:43 | step: 453000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.38385463389568e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.28 | consumed tokens: 231936000.0 | grad norm avg: 9.44 | grad norm last: 8.11 | 
2025-12-28T01:38:45 | step: 453100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.382486026268452e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.06 | consumed tokens: 231987200.0 | grad norm avg: 9.61 | grad norm last: 9.51 | 
2025-12-28T01:38:47 | step: 453200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.381117418641225e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.12 | consumed tokens: 232038400.0 | grad norm avg: 8.96 | grad norm last: 8.98 | 
2025-12-28T01:38:49 | step: 453300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.379748811013997e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.5 | consumed tokens: 232089600.0 | grad norm avg: 9.57 | grad norm last: 8.61 | 
2025-12-28T01:38:51 | step: 453400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.378380203386769e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.88 | consumed tokens: 232140800.0 | grad norm avg: 9.4 | grad norm last: 8.28 | 
2025-12-28T01:38:53 | step: 453500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.377011595759541e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.69 | consumed tokens: 232192000.0 | grad norm avg: 9.26 | grad norm last: 10.5 | 
2025-12-28T01:38:55 | step: 453600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.375642988132313e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.5 | consumed tokens: 232243200.0 | grad norm avg: 9.21 | grad norm last: 8.24 | 
2025-12-28T01:38:57 | step: 453700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.374274380505085e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 7.44 | consumed tokens: 232294400.0 | grad norm avg: 9.16 | grad norm last: 17.74 | 
2025-12-28T01:38:59 | step: 453800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.372905045282096e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.03 | consumed tokens: 232345600.0 | grad norm avg: 9.31 | grad norm last: 8.45 | 
2025-12-28T01:39:01 | step: 453900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.371535710059106e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.59 | consumed tokens: 232396800.0 | grad norm avg: 8.93 | grad norm last: 9.86 | 
2025-12-28T01:39:03 | step: 454000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.370167102431878e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 2.91 | consumed tokens: 232448000.0 | grad norm avg: 9.44 | grad norm last: 7.86 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_454000-seen_tokens_232448000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_454000-seen_tokens_232448000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_454000-seen_tokens_232448000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_454000-seen_tokens_232448000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_454000-seen_tokens_232448000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_454000-seen_tokens_232448000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_454000-seen_tokens_232448000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_454000-seen_tokens_232448000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:39:05 | step: 454100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.368797767208889e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.7 | train loss last: 3.8 | consumed tokens: 232499200.0 | grad norm avg: 9.37 | grad norm last: 8.42 | 
2025-12-28T01:39:07 | step: 454200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.3674284319859e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.75 | consumed tokens: 232550400.0 | grad norm avg: 9.11 | grad norm last: 9.4 | 
2025-12-28T01:39:10 | step: 454300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.36605909676291e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.53 | consumed tokens: 232601600.0 | grad norm avg: 9.08 | grad norm last: 8.68 | 
2025-12-28T01:39:12 | step: 454400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.364689761539921e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.67 | consumed tokens: 232652800.0 | grad norm avg: 9.19 | grad norm last: 9.84 | 
2025-12-28T01:39:14 | step: 454500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.36331969872117e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.59 | consumed tokens: 232704000.0 | grad norm avg: 9.64 | grad norm last: 8.44 | 
2025-12-28T01:39:16 | step: 454600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.361950363498181e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.67 | consumed tokens: 232755200.0 | grad norm avg: 9.29 | grad norm last: 8.6 | 
2025-12-28T01:39:18 | step: 454700 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.36058030067943e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.73 | consumed tokens: 232806400.0 | grad norm avg: 9.27 | grad norm last: 8.53 | 
2025-12-28T01:39:20 | step: 454800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.359210965456441e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.14 | consumed tokens: 232857600.0 | grad norm avg: 9.34 | grad norm last: 8.24 | 
2025-12-28T01:39:22 | step: 454900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.35784090263769e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.27 | consumed tokens: 232908800.0 | grad norm avg: 9.2 | grad norm last: 13.04 | 
2025-12-28T01:39:24 | step: 455000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.35647083981894e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.75 | consumed tokens: 232960000.0 | grad norm avg: 9.7 | grad norm last: 8.72 | 
2025-12-28T01:39:26 | step: 455100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 6.355100777000189e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.28 | consumed tokens: 233011200.0 | grad norm avg: 9.51 | grad norm last: 8.61 | 
2025-12-28T01:39:28 | step: 455200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 6.353730714181438e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 5.25 | consumed tokens: 233062400.0 | grad norm avg: 9.5 | grad norm last: 10.31 | 
2025-12-28T01:39:30 | step: 455300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.352360651362687e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 2.69 | consumed tokens: 233113600.0 | grad norm avg: 9.78 | grad norm last: 8.06 | 
2025-12-28T01:39:32 | step: 455400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.350989860948175e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.25 | consumed tokens: 233164800.0 | grad norm avg: 9.23 | grad norm last: 7.94 | 
2025-12-28T01:39:34 | step: 455500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.349619798129424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.0 | consumed tokens: 233216000.0 | grad norm avg: 9.24 | grad norm last: 9.34 | 
2025-12-28T01:39:36 | step: 455600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.348249007714912e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.95 | consumed tokens: 233267200.0 | grad norm avg: 9.74 | grad norm last: 8.16 | 
2025-12-28T01:39:38 | step: 455700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.346878944896162e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.67 | consumed tokens: 233318400.0 | grad norm avg: 9.2 | grad norm last: 9.89 | 
2025-12-28T01:39:40 | step: 455800 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 6.34550815448165e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.06 | consumed tokens: 233369600.0 | grad norm avg: 9.48 | grad norm last: 8.97 | 
2025-12-28T01:39:42 | step: 455900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 6.344137364067137e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 5.34 | consumed tokens: 233420800.0 | grad norm avg: 9.38 | grad norm last: 14.7 | 
2025-12-28T01:39:44 | step: 456000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 6.342766573652625e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.84 | consumed tokens: 233472000.0 | grad norm avg: 9.06 | grad norm last: 9.17 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_456000-seen_tokens_233472000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_456000-seen_tokens_233472000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_456000-seen_tokens_233472000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_456000-seen_tokens_233472000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_456000-seen_tokens_233472000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_456000-seen_tokens_233472000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_456000-seen_tokens_233472000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_456000-seen_tokens_233472000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:39:46 | step: 456100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 6.341395783238113e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.73 | consumed tokens: 233523200.0 | grad norm avg: 9.1 | grad norm last: 9.88 | 
2025-12-28T01:39:48 | step: 456200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.340024992823601e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.09 | consumed tokens: 233574400.0 | grad norm avg: 9.12 | grad norm last: 8.01 | 
2025-12-28T01:39:50 | step: 456300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.338653474813327e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 2.97 | consumed tokens: 233625600.0 | grad norm avg: 9.44 | grad norm last: 7.48 | 
2025-12-28T01:39:52 | step: 456400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.337282684398815e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.41 | consumed tokens: 233676800.0 | grad norm avg: 9.19 | grad norm last: 12.06 | 
2025-12-28T01:39:54 | step: 456500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 6.335911166388541e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.39 | consumed tokens: 233728000.0 | grad norm avg: 9.32 | grad norm last: 8.22 | 
2025-12-28T01:39:56 | step: 456600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 6.334540375974029e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.91 | consumed tokens: 233779200.0 | grad norm avg: 9.31 | grad norm last: 9.04 | 
2025-12-28T01:39:58 | step: 456700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 6.333168857963756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.38 | consumed tokens: 233830400.0 | grad norm avg: 9.13 | grad norm last: 7.47 | 
2025-12-28T01:40:01 | step: 456800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 6.331797339953482e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.3 | consumed tokens: 233881600.0 | grad norm avg: 9.73 | grad norm last: 7.74 | 
2025-12-28T01:40:03 | step: 456900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.330425821943209e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.97 | consumed tokens: 233932800.0 | grad norm avg: 9.49 | grad norm last: 11.12 | 
2025-12-28T01:40:05 | step: 457000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.329054303932935e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 2.39 | consumed tokens: 233984000.0 | grad norm avg: 9.48 | grad norm last: 6.43 | 
2025-12-28T01:40:07 | step: 457100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.327682785922661e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 5.03 | consumed tokens: 234035200.0 | grad norm avg: 9.5 | grad norm last: 18.37 | 
2025-12-28T01:40:09 | step: 457200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.326310540316626e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 5.03 | consumed tokens: 234086400.0 | grad norm avg: 9.41 | grad norm last: 9.8 | 
2025-12-28T01:40:11 | step: 457300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.324939022306353e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.0 | consumed tokens: 234137600.0 | grad norm avg: 9.22 | grad norm last: 9.36 | 
2025-12-28T01:40:13 | step: 457400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.323566776700318e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.62 | consumed tokens: 234188800.0 | grad norm avg: 10.83 | grad norm last: 9.19 | 
2025-12-28T01:40:15 | step: 457500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.322195258690044e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 2.61 | consumed tokens: 234240000.0 | grad norm avg: 9.19 | grad norm last: 8.64 | 
2025-12-28T01:40:17 | step: 457600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.320823013084009e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.33 | consumed tokens: 234291200.0 | grad norm avg: 9.09 | grad norm last: 9.36 | 
2025-12-28T01:40:19 | step: 457700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.319450767477974e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.03 | consumed tokens: 234342400.0 | grad norm avg: 8.93 | grad norm last: 8.23 | 
2025-12-28T01:40:21 | step: 457800 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 6.318078521871939e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.28 | consumed tokens: 234393600.0 | grad norm avg: 9.16 | grad norm last: 10.42 | 
2025-12-28T01:40:23 | step: 457900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.316706276265904e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.94 | consumed tokens: 234444800.0 | grad norm avg: 9.22 | grad norm last: 8.0 | 
2025-12-28T01:40:25 | step: 458000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.315334030659869e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.69 | consumed tokens: 234496000.0 | grad norm avg: 8.87 | grad norm last: 8.78 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_458000-seen_tokens_234496000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_458000-seen_tokens_234496000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_458000-seen_tokens_234496000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_458000-seen_tokens_234496000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_458000-seen_tokens_234496000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_458000-seen_tokens_234496000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_458000-seen_tokens_234496000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_458000-seen_tokens_234496000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:40:27 | step: 458100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.313961057458073e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.53 | consumed tokens: 234547200.0 | grad norm avg: 9.4 | grad norm last: 10.09 | 
2025-12-28T01:40:29 | step: 458200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.312588811852038e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.06 | consumed tokens: 234598400.0 | grad norm avg: 9.11 | grad norm last: 9.33 | 
2025-12-28T01:40:31 | step: 458300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.311216566246003e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.86 | consumed tokens: 234649600.0 | grad norm avg: 9.2 | grad norm last: 9.1 | 
2025-12-28T01:40:33 | step: 458400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.309843593044207e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.59 | consumed tokens: 234700800.0 | grad norm avg: 9.22 | grad norm last: 10.85 | 
2025-12-28T01:40:35 | step: 458500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.30847061984241e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.83 | consumed tokens: 234752000.0 | grad norm avg: 9.16 | grad norm last: 8.84 | 
2025-12-28T01:40:37 | step: 458600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.307097646640614e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 2.97 | consumed tokens: 234803200.0 | grad norm avg: 9.21 | grad norm last: 7.55 | 
2025-12-28T01:40:39 | step: 458700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.305724673438817e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.58 | consumed tokens: 234854400.0 | grad norm avg: 9.25 | grad norm last: 8.98 | 
2025-12-28T01:40:41 | step: 458800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.304351700237021e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.72 | consumed tokens: 234905600.0 | grad norm avg: 9.53 | grad norm last: 8.19 | 
2025-12-28T01:40:43 | step: 458900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.302978727035224e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 2.47 | consumed tokens: 234956800.0 | grad norm avg: 9.13 | grad norm last: 8.05 | 
2025-12-28T01:40:45 | step: 459000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.301605753833428e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.58 | consumed tokens: 235008000.0 | grad norm avg: 9.43 | grad norm last: 10.88 | 
2025-12-28T01:40:47 | step: 459100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.300232780631632e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.67 | consumed tokens: 235059200.0 | grad norm avg: 9.46 | grad norm last: 8.88 | 
2025-12-28T01:40:49 | step: 459200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.298859079834074e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.27 | consumed tokens: 235110400.0 | grad norm avg: 8.99 | grad norm last: 8.17 | 
2025-12-28T01:40:51 | step: 459300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.297485379036516e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.25 | consumed tokens: 235161600.0 | grad norm avg: 9.53 | grad norm last: 11.0 | 
2025-12-28T01:40:53 | step: 459400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.29611240583472e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.91 | consumed tokens: 235212800.0 | grad norm avg: 9.24 | grad norm last: 12.4 | 
2025-12-28T01:40:55 | step: 459500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.294738705037162e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.56 | consumed tokens: 235264000.0 | grad norm avg: 9.03 | grad norm last: 8.21 | 
2025-12-28T01:40:58 | step: 459600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.293365004239604e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.83 | consumed tokens: 235315200.0 | grad norm avg: 9.4 | grad norm last: 8.47 | 
2025-12-28T01:41:00 | step: 459700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.291991303442046e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.39 | consumed tokens: 235366400.0 | grad norm avg: 9.35 | grad norm last: 9.06 | 
2025-12-28T01:41:02 | step: 459800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.290617602644488e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.12 | consumed tokens: 235417600.0 | grad norm avg: 8.99 | grad norm last: 7.94 | 
2025-12-28T01:41:04 | step: 459900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.28924390184693e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.34 | consumed tokens: 235468800.0 | grad norm avg: 9.44 | grad norm last: 7.59 | 
2025-12-28T01:41:06 | step: 460000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.287869473453611e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.53 | consumed tokens: 235520000.0 | grad norm avg: 9.2 | grad norm last: 8.1 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_460000-seen_tokens_235520000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_460000-seen_tokens_235520000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_460000-seen_tokens_235520000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_460000-seen_tokens_235520000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_460000-seen_tokens_235520000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_460000-seen_tokens_235520000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_460000-seen_tokens_235520000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_460000-seen_tokens_235520000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:41:08 | step: 460100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 6.286495772656053e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.92 | train loss last: 5.38 | consumed tokens: 235571200.0 | grad norm avg: 9.93 | grad norm last: 12.38 | 
2025-12-28T01:41:10 | step: 460200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.285121344262734e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.22 | consumed tokens: 235622400.0 | grad norm avg: 9.02 | grad norm last: 9.31 | 
2025-12-28T01:41:12 | step: 460300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.283747643465176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.73 | consumed tokens: 235673600.0 | grad norm avg: 9.36 | grad norm last: 8.68 | 
2025-12-28T01:41:14 | step: 460400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.282373215071857e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.58 | consumed tokens: 235724800.0 | grad norm avg: 9.33 | grad norm last: 8.03 | 
2025-12-28T01:41:16 | step: 460500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.280998786678538e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.59 | consumed tokens: 235776000.0 | grad norm avg: 10.67 | grad norm last: 8.65 | 
2025-12-28T01:41:18 | step: 460600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.279624358285218e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.55 | consumed tokens: 235827200.0 | grad norm avg: 9.29 | grad norm last: 8.97 | 
2025-12-28T01:41:20 | step: 460700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 6.278249929891899e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.38 | consumed tokens: 235878400.0 | grad norm avg: 9.67 | grad norm last: 10.7 | 
2025-12-28T01:41:22 | step: 460800 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 6.27687550149858e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.09 | consumed tokens: 235929600.0 | grad norm avg: 9.33 | grad norm last: 13.08 | 
2025-12-28T01:41:24 | step: 460900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 6.275501073105261e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.28 | consumed tokens: 235980800.0 | grad norm avg: 9.41 | grad norm last: 8.44 | 
2025-12-28T01:41:26 | step: 461000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 6.274126644711941e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.5 | consumed tokens: 236032000.0 | grad norm avg: 9.11 | grad norm last: 14.94 | 
2025-12-28T01:41:28 | step: 461100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.272751488722861e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.2 | consumed tokens: 236083200.0 | grad norm avg: 9.87 | grad norm last: 8.12 | 
2025-12-28T01:41:30 | step: 461200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.271377060329542e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.22 | consumed tokens: 236134400.0 | grad norm avg: 9.49 | grad norm last: 14.03 | 
2025-12-28T01:41:32 | step: 461300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.270001904340461e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.19 | consumed tokens: 236185600.0 | grad norm avg: 9.58 | grad norm last: 9.82 | 
2025-12-28T01:41:34 | step: 461400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 6.26862674835138e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.77 | consumed tokens: 236236800.0 | grad norm avg: 9.52 | grad norm last: 10.36 | 
2025-12-28T01:41:36 | step: 461500 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 6.2672515923623e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.92 | consumed tokens: 236288000.0 | grad norm avg: 9.74 | grad norm last: 10.24 | 
2025-12-28T01:41:38 | step: 461600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 6.265876436373219e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.25 | consumed tokens: 236339200.0 | grad norm avg: 9.55 | grad norm last: 14.99 | 
2025-12-28T01:41:40 | step: 461700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 6.264501280384138e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.53 | consumed tokens: 236390400.0 | grad norm avg: 9.29 | grad norm last: 10.02 | 
2025-12-28T01:41:42 | step: 461800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.263126124395058e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.81 | consumed tokens: 236441600.0 | grad norm avg: 9.38 | grad norm last: 8.0 | 
2025-12-28T01:41:45 | step: 461900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.261750968405977e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.16 | consumed tokens: 236492800.0 | grad norm avg: 9.7 | grad norm last: 7.5 | 
2025-12-28T01:41:47 | step: 462000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.260375084821135e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.25 | consumed tokens: 236544000.0 | grad norm avg: 9.5 | grad norm last: 8.49 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_462000-seen_tokens_236544000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_462000-seen_tokens_236544000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_462000-seen_tokens_236544000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_462000-seen_tokens_236544000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_462000-seen_tokens_236544000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_462000-seen_tokens_236544000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_462000-seen_tokens_236544000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_462000-seen_tokens_236544000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:41:49 | step: 462100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.258999928832054e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.74 | train loss last: 3.48 | consumed tokens: 236595200.0 | grad norm avg: 9.46 | grad norm last: 8.89 | 
2025-12-28T01:41:51 | step: 462200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.257624045247212e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.56 | consumed tokens: 236646400.0 | grad norm avg: 9.16 | grad norm last: 8.79 | 
2025-12-28T01:41:53 | step: 462300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.256248889258131e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.39 | consumed tokens: 236697600.0 | grad norm avg: 9.27 | grad norm last: 9.61 | 
2025-12-28T01:41:55 | step: 462400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.254873005673289e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.98 | consumed tokens: 236748800.0 | grad norm avg: 9.32 | grad norm last: 8.78 | 
2025-12-28T01:41:57 | step: 462500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.253497122088447e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.56 | consumed tokens: 236800000.0 | grad norm avg: 9.43 | grad norm last: 9.88 | 
2025-12-28T01:41:59 | step: 462600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.252121238503605e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.5 | consumed tokens: 236851200.0 | grad norm avg: 9.64 | grad norm last: 10.22 | 
2025-12-28T01:42:01 | step: 462700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.250745354918763e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.88 | consumed tokens: 236902400.0 | grad norm avg: 9.45 | grad norm last: 9.46 | 
2025-12-28T01:42:03 | step: 462800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.249369471333921e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.38 | consumed tokens: 236953600.0 | grad norm avg: 9.36 | grad norm last: 10.99 | 
2025-12-28T01:42:05 | step: 462900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.247993587749079e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.83 | consumed tokens: 237004800.0 | grad norm avg: 9.26 | grad norm last: 8.43 | 
2025-12-28T01:42:07 | step: 463000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.246616976568475e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.88 | consumed tokens: 237056000.0 | grad norm avg: 9.53 | grad norm last: 8.87 | 
2025-12-28T01:42:09 | step: 463100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.245241092983633e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.58 | consumed tokens: 237107200.0 | grad norm avg: 9.06 | grad norm last: 11.27 | 
2025-12-28T01:42:11 | step: 463200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.24386448180303e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.86 | consumed tokens: 237158400.0 | grad norm avg: 11.23 | grad norm last: 8.43 | 
2025-12-28T01:42:13 | step: 463300 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 6.242488598218188e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.61 | consumed tokens: 237209600.0 | grad norm avg: 10.07 | grad norm last: 9.84 | 
2025-12-28T01:42:15 | step: 463400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.241111987037584e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.83 | consumed tokens: 237260800.0 | grad norm avg: 9.6 | grad norm last: 8.88 | 
2025-12-28T01:42:17 | step: 463500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.239735375856981e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 5.16 | consumed tokens: 237312000.0 | grad norm avg: 9.27 | grad norm last: 15.89 | 
2025-12-28T01:42:19 | step: 463600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.238358764676377e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.2 | consumed tokens: 237363200.0 | grad norm avg: 9.24 | grad norm last: 8.33 | 
2025-12-28T01:42:21 | step: 463700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.236982153495774e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.72 | consumed tokens: 237414400.0 | grad norm avg: 9.31 | grad norm last: 10.53 | 
2025-12-28T01:42:23 | step: 463800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.23560554231517e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.23 | consumed tokens: 237465600.0 | grad norm avg: 9.31 | grad norm last: 8.65 | 
2025-12-28T01:42:25 | step: 463900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.234228931134567e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.75 | consumed tokens: 237516800.0 | grad norm avg: 9.43 | grad norm last: 8.68 | 
2025-12-28T01:42:27 | step: 464000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.232851592358202e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.77 | consumed tokens: 237568000.0 | grad norm avg: 9.82 | grad norm last: 8.96 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_464000-seen_tokens_237568000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_464000-seen_tokens_237568000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_464000-seen_tokens_237568000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_464000-seen_tokens_237568000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_464000-seen_tokens_237568000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_464000-seen_tokens_237568000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_464000-seen_tokens_237568000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_464000-seen_tokens_237568000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:42:30 | step: 464100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.231474981177598e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.06 | consumed tokens: 237619200.0 | grad norm avg: 9.67 | grad norm last: 8.06 | 
2025-12-28T01:42:32 | step: 464200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.230097642401233e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.36 | consumed tokens: 237670400.0 | grad norm avg: 9.96 | grad norm last: 8.76 | 
2025-12-28T01:42:34 | step: 464300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.22872103122063e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.41 | consumed tokens: 237721600.0 | grad norm avg: 9.82 | grad norm last: 12.67 | 
2025-12-28T01:42:36 | step: 464400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.227343692444265e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.25 | consumed tokens: 237772800.0 | grad norm avg: 9.9 | grad norm last: 9.33 | 
2025-12-28T01:42:38 | step: 464500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.2259663536679e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.91 | consumed tokens: 237824000.0 | grad norm avg: 9.29 | grad norm last: 14.59 | 
2025-12-28T01:42:40 | step: 464600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.224589014891535e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.0 | consumed tokens: 237875200.0 | grad norm avg: 9.67 | grad norm last: 9.22 | 
2025-12-28T01:42:42 | step: 464700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.22321167611517e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.39 | consumed tokens: 237926400.0 | grad norm avg: 9.87 | grad norm last: 9.3 | 
2025-12-28T01:42:44 | step: 464800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.221834337338805e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.27 | consumed tokens: 237977600.0 | grad norm avg: 9.66 | grad norm last: 7.76 | 
2025-12-28T01:42:46 | step: 464900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.22045699856244e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.5 | consumed tokens: 238028800.0 | grad norm avg: 9.38 | grad norm last: 11.73 | 
2025-12-28T01:42:48 | step: 465000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.219079659786075e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 2.92 | consumed tokens: 238080000.0 | grad norm avg: 9.6 | grad norm last: 8.12 | 
2025-12-28T01:42:50 | step: 465100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.217701593413949e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.8 | consumed tokens: 238131200.0 | grad norm avg: 9.4 | grad norm last: 9.13 | 
2025-12-28T01:42:52 | step: 465200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.216324254637584e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.75 | consumed tokens: 238182400.0 | grad norm avg: 9.8 | grad norm last: 8.31 | 
2025-12-28T01:42:54 | step: 465300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.214946188265458e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.69 | consumed tokens: 238233600.0 | grad norm avg: 9.79 | grad norm last: 8.74 | 
2025-12-28T01:42:56 | step: 465400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 6.213568121893331e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.7 | consumed tokens: 238284800.0 | grad norm avg: 9.45 | grad norm last: 8.83 | 
2025-12-28T01:42:58 | step: 465500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 6.212190783116966e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 2.95 | consumed tokens: 238336000.0 | grad norm avg: 9.53 | grad norm last: 8.14 | 
2025-12-28T01:43:00 | step: 465600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.21081271674484e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.78 | consumed tokens: 238387200.0 | grad norm avg: 9.41 | grad norm last: 8.66 | 
2025-12-28T01:43:02 | step: 465700 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 6.209434650372714e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.84 | consumed tokens: 238438400.0 | grad norm avg: 9.67 | grad norm last: 10.31 | 
2025-12-28T01:43:04 | step: 465800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 6.208056584000587e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.22 | consumed tokens: 238489600.0 | grad norm avg: 9.24 | grad norm last: 9.13 | 
2025-12-28T01:43:06 | step: 465900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 6.206678517628461e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.7 | consumed tokens: 238540800.0 | grad norm avg: 9.64 | grad norm last: 8.33 | 
2025-12-28T01:43:08 | step: 466000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.205299723660573e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.75 | consumed tokens: 238592000.0 | grad norm avg: 9.59 | grad norm last: 8.62 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_466000-seen_tokens_238592000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_466000-seen_tokens_238592000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_466000-seen_tokens_238592000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_466000-seen_tokens_238592000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_466000-seen_tokens_238592000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_466000-seen_tokens_238592000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_466000-seen_tokens_238592000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_466000-seen_tokens_238592000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:43:10 | step: 466100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.203921657288447e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.25 | consumed tokens: 238643200.0 | grad norm avg: 9.73 | grad norm last: 8.84 | 
2025-12-28T01:43:12 | step: 466200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.202543590916321e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.73 | consumed tokens: 238694400.0 | grad norm avg: 9.7 | grad norm last: 9.68 | 
2025-12-28T01:43:14 | step: 466300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.201164796948433e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.94 | consumed tokens: 238745600.0 | grad norm avg: 9.8 | grad norm last: 10.88 | 
2025-12-28T01:43:16 | step: 466400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 6.199786002980545e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.95 | consumed tokens: 238796800.0 | grad norm avg: 9.84 | grad norm last: 8.09 | 
2025-12-28T01:43:18 | step: 466500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 6.198407936608419e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.78 | consumed tokens: 238848000.0 | grad norm avg: 9.91 | grad norm last: 8.36 | 
2025-12-28T01:43:20 | step: 466600 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 6.197029142640531e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.28 | consumed tokens: 238899200.0 | grad norm avg: 9.71 | grad norm last: 9.35 | 
2025-12-28T01:43:23 | step: 466700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 6.195650348672643e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.8 | consumed tokens: 238950400.0 | grad norm avg: 9.42 | grad norm last: 8.85 | 
2025-12-28T01:43:25 | step: 466800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.194271554704756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.0 | consumed tokens: 239001600.0 | grad norm avg: 9.67 | grad norm last: 10.57 | 
2025-12-28T01:43:27 | step: 466900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 6.192892760736868e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.06 | consumed tokens: 239052800.0 | grad norm avg: 9.48 | grad norm last: 8.95 | 
2025-12-28T01:43:29 | step: 467000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.19151396676898e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.61 | consumed tokens: 239104000.0 | grad norm avg: 9.85 | grad norm last: 9.13 | 
2025-12-28T01:43:31 | step: 467100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.190135172801092e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.84 | consumed tokens: 239155200.0 | grad norm avg: 9.73 | grad norm last: 10.72 | 
2025-12-28T01:43:33 | step: 467200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.188755651237443e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.19 | consumed tokens: 239206400.0 | grad norm avg: 9.41 | grad norm last: 12.94 | 
2025-12-28T01:43:35 | step: 467300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.187376857269555e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.39 | consumed tokens: 239257600.0 | grad norm avg: 9.7 | grad norm last: 8.62 | 
2025-12-28T01:43:37 | step: 467400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.185997335705906e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.94 | consumed tokens: 239308800.0 | grad norm avg: 9.76 | grad norm last: 9.07 | 
2025-12-28T01:43:39 | step: 467500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.184618541738018e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 6.47 | consumed tokens: 239360000.0 | grad norm avg: 10.3 | grad norm last: 20.86 | 
2025-12-28T01:43:41 | step: 467600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.183239020174369e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.59 | consumed tokens: 239411200.0 | grad norm avg: 9.89 | grad norm last: 8.12 | 
2025-12-28T01:43:43 | step: 467700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.18185949861072e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.25 | consumed tokens: 239462400.0 | grad norm avg: 9.96 | grad norm last: 10.68 | 
2025-12-28T01:43:45 | step: 467800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.180479977047071e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.56 | consumed tokens: 239513600.0 | grad norm avg: 9.84 | grad norm last: 10.06 | 
2025-12-28T01:43:47 | step: 467900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.179100455483422e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.0 | consumed tokens: 239564800.0 | grad norm avg: 9.44 | grad norm last: 9.3 | 
2025-12-28T01:43:49 | step: 468000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.177720933919773e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.62 | consumed tokens: 239616000.0 | grad norm avg: 9.73 | grad norm last: 8.85 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_468000-seen_tokens_239616000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_468000-seen_tokens_239616000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_468000-seen_tokens_239616000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_468000-seen_tokens_239616000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_468000-seen_tokens_239616000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_468000-seen_tokens_239616000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_468000-seen_tokens_239616000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_468000-seen_tokens_239616000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:43:51 | step: 468100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.176341412356123e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.76 | train loss last: 3.44 | consumed tokens: 239667200.0 | grad norm avg: 9.79 | grad norm last: 8.34 | 
2025-12-28T01:43:53 | step: 468200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.174961890792474e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.03 | consumed tokens: 239718400.0 | grad norm avg: 10.15 | grad norm last: 8.54 | 
2025-12-28T01:43:55 | step: 468300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.173581641633064e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.75 | consumed tokens: 239769600.0 | grad norm avg: 9.33 | grad norm last: 9.33 | 
2025-12-28T01:43:57 | step: 468400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.172202120069414e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 5.25 | consumed tokens: 239820800.0 | grad norm avg: 9.78 | grad norm last: 24.24 | 
2025-12-28T01:43:59 | step: 468500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.170821870910004e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.06 | consumed tokens: 239872000.0 | grad norm avg: 9.95 | grad norm last: 9.83 | 
2025-12-28T01:44:01 | step: 468600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.169442349346355e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.84 | consumed tokens: 239923200.0 | grad norm avg: 9.82 | grad norm last: 9.68 | 
2025-12-28T01:44:03 | step: 468700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.168062100186944e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.75 | consumed tokens: 239974400.0 | grad norm avg: 9.77 | grad norm last: 8.72 | 
2025-12-28T01:44:05 | step: 468800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.166681851027533e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.53 | consumed tokens: 240025600.0 | grad norm avg: 9.4 | grad norm last: 17.28 | 
2025-12-28T01:44:07 | step: 468900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.165301601868123e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.45 | consumed tokens: 240076800.0 | grad norm avg: 9.71 | grad norm last: 11.88 | 
2025-12-28T01:44:09 | step: 469000 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.163921352708712e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.84 | consumed tokens: 240128000.0 | grad norm avg: 9.88 | grad norm last: 8.17 | 
2025-12-28T01:44:11 | step: 469100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.162541103549302e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.06 | consumed tokens: 240179200.0 | grad norm avg: 9.38 | grad norm last: 10.38 | 
2025-12-28T01:44:13 | step: 469200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.161160854389891e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.48 | consumed tokens: 240230400.0 | grad norm avg: 9.65 | grad norm last: 7.86 | 
2025-12-28T01:44:15 | step: 469300 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.15978060523048e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.44 | consumed tokens: 240281600.0 | grad norm avg: 9.85 | grad norm last: 8.72 | 
2025-12-28T01:44:17 | step: 469400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.15840035607107e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.16 | consumed tokens: 240332800.0 | grad norm avg: 9.56 | grad norm last: 9.84 | 
2025-12-28T01:44:19 | step: 469500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.157019379315898e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.73 | consumed tokens: 240384000.0 | grad norm avg: 9.7 | grad norm last: 9.58 | 
2025-12-28T01:44:21 | step: 469600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.155639130156487e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.62 | consumed tokens: 240435200.0 | grad norm avg: 9.65 | grad norm last: 9.18 | 
2025-12-28T01:44:23 | step: 469700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.154258153401315e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.64 | consumed tokens: 240486400.0 | grad norm avg: 9.65 | grad norm last: 8.26 | 
2025-12-28T01:44:25 | step: 469800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.152877904241905e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.0 | consumed tokens: 240537600.0 | grad norm avg: 9.61 | grad norm last: 8.16 | 
2025-12-28T01:44:27 | step: 469900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.151496927486733e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.45 | consumed tokens: 240588800.0 | grad norm avg: 9.32 | grad norm last: 8.91 | 
2025-12-28T01:44:29 | step: 470000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.15011595073156e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.41 | consumed tokens: 240640000.0 | grad norm avg: 9.22 | grad norm last: 12.24 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_470000-seen_tokens_240640000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_470000-seen_tokens_240640000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_470000-seen_tokens_240640000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_470000-seen_tokens_240640000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_470000-seen_tokens_240640000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_470000-seen_tokens_240640000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_470000-seen_tokens_240640000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_470000-seen_tokens_240640000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:44:32 | step: 470100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.148734973976389e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.92 | consumed tokens: 240691200.0 | grad norm avg: 10.03 | grad norm last: 8.24 | 
2025-12-28T01:44:34 | step: 470200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.147353997221217e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.12 | consumed tokens: 240742400.0 | grad norm avg: 10.07 | grad norm last: 8.6 | 
2025-12-28T01:44:36 | step: 470300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.145973020466045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.47 | consumed tokens: 240793600.0 | grad norm avg: 9.59 | grad norm last: 8.4 | 
2025-12-28T01:44:38 | step: 470400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 6.144592043710873e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.47 | consumed tokens: 240844800.0 | grad norm avg: 9.37 | grad norm last: 9.7 | 
2025-12-28T01:44:40 | step: 470500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 6.1432110669557e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.16 | consumed tokens: 240896000.0 | grad norm avg: 9.82 | grad norm last: 8.2 | 
2025-12-28T01:44:42 | step: 470600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 6.141829362604767e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.47 | consumed tokens: 240947200.0 | grad norm avg: 9.52 | grad norm last: 8.4 | 
2025-12-28T01:44:44 | step: 470700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.140448385849595e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.16 | consumed tokens: 240998400.0 | grad norm avg: 9.66 | grad norm last: 8.48 | 
2025-12-28T01:44:46 | step: 470800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.139066681498662e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 5.44 | consumed tokens: 241049600.0 | grad norm avg: 9.52 | grad norm last: 13.61 | 
2025-12-28T01:44:48 | step: 470900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.13768570474349e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 2.94 | consumed tokens: 241100800.0 | grad norm avg: 9.83 | grad norm last: 8.22 | 
2025-12-28T01:44:50 | step: 471000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 6.136304000392556e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.03 | consumed tokens: 241152000.0 | grad norm avg: 10.14 | grad norm last: 10.23 | 
2025-12-28T01:44:52 | step: 471100 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 6.134922296041623e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.5 | consumed tokens: 241203200.0 | grad norm avg: 9.68 | grad norm last: 8.64 | 
2025-12-28T01:44:54 | step: 471200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 6.13354059169069e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.56 | consumed tokens: 241254400.0 | grad norm avg: 9.69 | grad norm last: 10.79 | 
2025-12-28T01:44:56 | step: 471300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 6.132158887339756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.7 | consumed tokens: 241305600.0 | grad norm avg: 9.46 | grad norm last: 11.55 | 
2025-12-28T01:44:58 | step: 471400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.130777182988822e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.78 | consumed tokens: 241356800.0 | grad norm avg: 9.7 | grad norm last: 11.62 | 
2025-12-28T01:45:00 | step: 471500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.129395478637889e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.97 | consumed tokens: 241408000.0 | grad norm avg: 9.72 | grad norm last: 10.48 | 
2025-12-28T01:45:02 | step: 471600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 6.128013774286956e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.03 | consumed tokens: 241459200.0 | grad norm avg: 9.62 | grad norm last: 8.77 | 
2025-12-28T01:45:04 | step: 471700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 6.126632069936022e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.8 | consumed tokens: 241510400.0 | grad norm avg: 9.75 | grad norm last: 9.47 | 
2025-12-28T01:45:06 | step: 471800 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 6.125250365585089e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.47 | consumed tokens: 241561600.0 | grad norm avg: 9.84 | grad norm last: 9.05 | 
2025-12-28T01:45:08 | step: 471900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 6.123867933638394e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 5.97 | consumed tokens: 241612800.0 | grad norm avg: 9.47 | grad norm last: 20.45 | 
2025-12-28T01:45:10 | step: 472000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 6.12248622928746e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.73 | consumed tokens: 241664000.0 | grad norm avg: 9.92 | grad norm last: 8.84 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_472000-seen_tokens_241664000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_472000-seen_tokens_241664000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_472000-seen_tokens_241664000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_472000-seen_tokens_241664000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_472000-seen_tokens_241664000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_472000-seen_tokens_241664000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_472000-seen_tokens_241664000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_472000-seen_tokens_241664000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:45:13 | step: 472100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 6.121103797340766e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.7 | train loss last: 3.33 | consumed tokens: 241715200.0 | grad norm avg: 9.72 | grad norm last: 7.94 | 
2025-12-28T01:45:15 | step: 472200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.119721365394071e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.72 | consumed tokens: 241766400.0 | grad norm avg: 9.66 | grad norm last: 8.12 | 
2025-12-28T01:45:17 | step: 472300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.118339661043137e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.5 | consumed tokens: 241817600.0 | grad norm avg: 9.76 | grad norm last: 10.18 | 
2025-12-28T01:45:19 | step: 472400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.116957229096442e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.95 | consumed tokens: 241868800.0 | grad norm avg: 9.63 | grad norm last: 9.46 | 
2025-12-28T01:45:21 | step: 472500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.115574797149748e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.72 | consumed tokens: 241920000.0 | grad norm avg: 9.51 | grad norm last: 9.71 | 
2025-12-28T01:45:23 | step: 472600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.114192365203053e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.47 | consumed tokens: 241971200.0 | grad norm avg: 9.77 | grad norm last: 13.9 | 
2025-12-28T01:45:25 | step: 472700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.112809933256358e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.75 | consumed tokens: 242022400.0 | grad norm avg: 9.38 | grad norm last: 8.38 | 
2025-12-28T01:45:27 | step: 472800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.111427501309663e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.56 | consumed tokens: 242073600.0 | grad norm avg: 9.84 | grad norm last: 10.45 | 
2025-12-28T01:45:29 | step: 472900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.110044341767207e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 2.84 | consumed tokens: 242124800.0 | grad norm avg: 9.3 | grad norm last: 7.59 | 
2025-12-28T01:45:31 | step: 473000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.108661909820512e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.39 | consumed tokens: 242176000.0 | grad norm avg: 9.63 | grad norm last: 9.58 | 
2025-12-28T01:45:33 | step: 473100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.107279477873817e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.72 | consumed tokens: 242227200.0 | grad norm avg: 9.84 | grad norm last: 8.77 | 
2025-12-28T01:45:35 | step: 473200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.105896318331361e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.06 | consumed tokens: 242278400.0 | grad norm avg: 9.39 | grad norm last: 8.76 | 
2025-12-28T01:45:37 | step: 473300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.104513886384666e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.47 | consumed tokens: 242329600.0 | grad norm avg: 9.38 | grad norm last: 9.28 | 
2025-12-28T01:45:39 | step: 473400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.103130363044329e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.31 | consumed tokens: 242380800.0 | grad norm avg: 9.36 | grad norm last: 8.85 | 
2025-12-28T01:45:41 | step: 473500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.1017475672997534e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.19 | consumed tokens: 242432000.0 | grad norm avg: 9.63 | grad norm last: 8.28 | 
2025-12-28T01:45:43 | step: 473600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.100364771555178e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.0 | consumed tokens: 242483200.0 | grad norm avg: 9.5 | grad norm last: 9.1 | 
2025-12-28T01:45:45 | step: 473700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.0989816120127216e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.16 | consumed tokens: 242534400.0 | grad norm avg: 9.46 | grad norm last: 8.15 | 
2025-12-28T01:45:47 | step: 473800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.097598452470265e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.92 | consumed tokens: 242585600.0 | grad norm avg: 9.53 | grad norm last: 9.15 | 
2025-12-28T01:45:49 | step: 473900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.096215292927809e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.62 | consumed tokens: 242636800.0 | grad norm avg: 9.9 | grad norm last: 8.51 | 
2025-12-28T01:45:51 | step: 474000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.094832133385353e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.91 | consumed tokens: 242688000.0 | grad norm avg: 9.85 | grad norm last: 10.46 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_474000-seen_tokens_242688000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_474000-seen_tokens_242688000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_474000-seen_tokens_242688000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_474000-seen_tokens_242688000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_474000-seen_tokens_242688000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_474000-seen_tokens_242688000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_474000-seen_tokens_242688000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_474000-seen_tokens_242688000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:45:53 | step: 474100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.093448610045016e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.44 | consumed tokens: 242739200.0 | grad norm avg: 9.64 | grad norm last: 11.38 | 
2025-12-28T01:45:55 | step: 474200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.092065086704679e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.84 | consumed tokens: 242790400.0 | grad norm avg: 9.78 | grad norm last: 10.85 | 
2025-12-28T01:45:57 | step: 474300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.0906819271622226e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.3 | consumed tokens: 242841600.0 | grad norm avg: 9.32 | grad norm last: 8.68 | 
2025-12-28T01:45:59 | step: 474400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.0892984038218856e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.75 | consumed tokens: 242892800.0 | grad norm avg: 9.82 | grad norm last: 9.75 | 
2025-12-28T01:46:01 | step: 474500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.0879148804815486e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 6.41 | consumed tokens: 242944000.0 | grad norm avg: 9.45 | grad norm last: 11.7 | 
2025-12-28T01:46:03 | step: 474600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.086531720939092e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.75 | consumed tokens: 242995200.0 | grad norm avg: 9.72 | grad norm last: 9.03 | 
2025-12-28T01:46:06 | step: 474700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.085147106205113e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.52 | consumed tokens: 243046400.0 | grad norm avg: 9.82 | grad norm last: 9.07 | 
2025-12-28T01:46:08 | step: 474800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.083763946662657e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 5.38 | consumed tokens: 243097600.0 | grad norm avg: 9.66 | grad norm last: 14.9 | 
2025-12-28T01:46:10 | step: 474900 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 6.082380059524439e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.09 | consumed tokens: 243148800.0 | grad norm avg: 9.72 | grad norm last: 11.08 | 
2025-12-28T01:46:12 | step: 475000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.0809961723862216e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.56 | consumed tokens: 243200000.0 | grad norm avg: 9.68 | grad norm last: 11.8 | 
2025-12-28T01:46:14 | step: 475100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.079612285248004e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.34 | consumed tokens: 243251200.0 | grad norm avg: 9.42 | grad norm last: 8.52 | 
2025-12-28T01:46:16 | step: 475200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.078228398109786e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.44 | consumed tokens: 243302400.0 | grad norm avg: 9.64 | grad norm last: 8.78 | 
2025-12-28T01:46:18 | step: 475300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.0768445109715685e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.03 | consumed tokens: 243353600.0 | grad norm avg: 10.2 | grad norm last: 11.19 | 
2025-12-28T01:46:20 | step: 475400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 6.075460623833351e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.09 | consumed tokens: 243404800.0 | grad norm avg: 9.79 | grad norm last: 7.55 | 
2025-12-28T01:46:22 | step: 475500 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 6.074076009099372e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.86 | consumed tokens: 243456000.0 | grad norm avg: 9.62 | grad norm last: 13.68 | 
2025-12-28T01:46:24 | step: 475600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 6.072692121961154e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.44 | consumed tokens: 243507200.0 | grad norm avg: 9.79 | grad norm last: 10.78 | 
2025-12-28T01:46:26 | step: 475700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.0713082348229364e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 5.91 | consumed tokens: 243558400.0 | grad norm avg: 9.5 | grad norm last: 10.0 | 
2025-12-28T01:46:28 | step: 475800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.069923620088957e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 5.41 | consumed tokens: 243609600.0 | grad norm avg: 10.2 | grad norm last: 12.49 | 
2025-12-28T01:46:30 | step: 475900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.0685397329507396e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.61 | consumed tokens: 243660800.0 | grad norm avg: 9.65 | grad norm last: 8.71 | 
2025-12-28T01:46:32 | step: 476000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.0671551182167605e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 2.98 | consumed tokens: 243712000.0 | grad norm avg: 9.51 | grad norm last: 8.24 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_476000-seen_tokens_243712000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_476000-seen_tokens_243712000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_476000-seen_tokens_243712000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_476000-seen_tokens_243712000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_476000-seen_tokens_243712000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_476000-seen_tokens_243712000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_476000-seen_tokens_243712000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_476000-seen_tokens_243712000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:46:34 | step: 476100 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 6.065770867280662e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.74 | train loss last: 3.94 | consumed tokens: 243763200.0 | grad norm avg: 9.93 | grad norm last: 11.98 | 
2025-12-28T01:46:36 | step: 476200 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 6.064386616344564e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.3 | consumed tokens: 243814400.0 | grad norm avg: 10.02 | grad norm last: 10.22 | 
2025-12-28T01:46:38 | step: 476300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 6.063001637812704e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.31 | consumed tokens: 243865600.0 | grad norm avg: 9.65 | grad norm last: 7.98 | 
2025-12-28T01:46:40 | step: 476400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.061616659280844e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.42 | consumed tokens: 243916800.0 | grad norm avg: 9.49 | grad norm last: 9.83 | 
2025-12-28T01:46:42 | step: 476500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.0602324083447456e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.06 | consumed tokens: 243968000.0 | grad norm avg: 9.97 | grad norm last: 9.58 | 
2025-12-28T01:46:44 | step: 476600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.058848157408647e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.03 | consumed tokens: 244019200.0 | grad norm avg: 9.97 | grad norm last: 10.36 | 
2025-12-28T01:46:46 | step: 476700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 6.0574631788767874e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.66 | consumed tokens: 244070400.0 | grad norm avg: 9.83 | grad norm last: 10.34 | 
2025-12-28T01:46:49 | step: 476800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 6.0560782003449276e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.69 | consumed tokens: 244121600.0 | grad norm avg: 9.19 | grad norm last: 8.36 | 
2025-12-28T01:46:51 | step: 476900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 6.054692858015187e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 2.97 | consumed tokens: 244172800.0 | grad norm avg: 10.21 | grad norm last: 8.29 | 
2025-12-28T01:46:53 | step: 477000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 6.053308607079089e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.72 | consumed tokens: 244224000.0 | grad norm avg: 9.55 | grad norm last: 10.75 | 
2025-12-28T01:46:55 | step: 477100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 6.051923628547229e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.11 | consumed tokens: 244275200.0 | grad norm avg: 9.9 | grad norm last: 8.26 | 
2025-12-28T01:46:57 | step: 477200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.0505382862174883e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.3 | consumed tokens: 244326400.0 | grad norm avg: 9.58 | grad norm last: 10.18 | 
2025-12-28T01:46:59 | step: 477300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.049153671483509e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.56 | consumed tokens: 244377600.0 | grad norm avg: 10.07 | grad norm last: 15.66 | 
2025-12-28T01:47:01 | step: 477400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 6.047768329153769e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.91 | consumed tokens: 244428800.0 | grad norm avg: 9.83 | grad norm last: 10.11 | 
2025-12-28T01:47:03 | step: 477500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.046382986824028e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.53 | consumed tokens: 244480000.0 | grad norm avg: 10.01 | grad norm last: 10.43 | 
2025-12-28T01:47:05 | step: 477600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.0449980082921684e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.17 | consumed tokens: 244531200.0 | grad norm avg: 9.6 | grad norm last: 8.23 | 
2025-12-28T01:47:07 | step: 477700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.043612665962428e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.66 | consumed tokens: 244582400.0 | grad norm avg: 9.5 | grad norm last: 9.41 | 
2025-12-28T01:47:09 | step: 477800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.042227323632687e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.12 | consumed tokens: 244633600.0 | grad norm avg: 9.69 | grad norm last: 8.01 | 
2025-12-28T01:47:11 | step: 477900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.040841981302947e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.78 | consumed tokens: 244684800.0 | grad norm avg: 9.83 | grad norm last: 8.75 | 
2025-12-28T01:47:13 | step: 478000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.0394562751753256e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.58 | consumed tokens: 244736000.0 | grad norm avg: 9.8 | grad norm last: 8.43 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_478000-seen_tokens_244736000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_478000-seen_tokens_244736000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_478000-seen_tokens_244736000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_478000-seen_tokens_244736000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_478000-seen_tokens_244736000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_478000-seen_tokens_244736000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_478000-seen_tokens_244736000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_478000-seen_tokens_244736000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:47:15 | step: 478100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.038070932845585e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.12 | consumed tokens: 244787200.0 | grad norm avg: 9.72 | grad norm last: 10.05 | 
2025-12-28T01:47:17 | step: 478200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.0366855905158445e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.28 | consumed tokens: 244838400.0 | grad norm avg: 10.0 | grad norm last: 10.23 | 
2025-12-28T01:47:19 | step: 478300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.035300248186104e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.56 | consumed tokens: 244889600.0 | grad norm avg: 9.61 | grad norm last: 11.85 | 
2025-12-28T01:47:21 | step: 478400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.033914178260602e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 2.94 | consumed tokens: 244940800.0 | grad norm avg: 9.85 | grad norm last: 8.25 | 
2025-12-28T01:47:23 | step: 478500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.032528472132981e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.16 | consumed tokens: 244992000.0 | grad norm avg: 9.59 | grad norm last: 8.42 | 
2025-12-28T01:47:25 | step: 478600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.0311427660053596e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.2 | consumed tokens: 245043200.0 | grad norm avg: 9.79 | grad norm last: 8.55 | 
2025-12-28T01:47:27 | step: 478700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 6.0297566960798576e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.28 | consumed tokens: 245094400.0 | grad norm avg: 9.9 | grad norm last: 8.65 | 
2025-12-28T01:47:29 | step: 478800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.0283709899522364e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.7 | consumed tokens: 245145600.0 | grad norm avg: 9.83 | grad norm last: 9.2 | 
2025-12-28T01:47:31 | step: 478900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.026985283824615e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.34 | consumed tokens: 245196800.0 | grad norm avg: 9.36 | grad norm last: 8.31 | 
2025-12-28T01:47:33 | step: 479000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.025599213899113e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.34 | consumed tokens: 245248000.0 | grad norm avg: 9.7 | grad norm last: 9.3 | 
2025-12-28T01:47:35 | step: 479100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.024213143973611e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.84 | consumed tokens: 245299200.0 | grad norm avg: 9.95 | grad norm last: 10.59 | 
2025-12-28T01:47:37 | step: 479200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.0228270740481094e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.09 | consumed tokens: 245350400.0 | grad norm avg: 9.3 | grad norm last: 9.07 | 
2025-12-28T01:47:39 | step: 479300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.0214410041226074e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.16 | consumed tokens: 245401600.0 | grad norm avg: 9.98 | grad norm last: 7.95 | 
2025-12-28T01:47:41 | step: 479400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.0200549341971055e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.67 | consumed tokens: 245452800.0 | grad norm avg: 10.02 | grad norm last: 9.01 | 
2025-12-28T01:47:43 | step: 479500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.0186688642716035e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.0 | consumed tokens: 245504000.0 | grad norm avg: 9.55 | grad norm last: 9.13 | 
2025-12-28T01:47:45 | step: 479600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.017282430548221e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.22 | consumed tokens: 245555200.0 | grad norm avg: 9.51 | grad norm last: 11.8 | 
2025-12-28T01:47:47 | step: 479700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 6.0158967244205996e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.95 | consumed tokens: 245606400.0 | grad norm avg: 9.67 | grad norm last: 10.31 | 
2025-12-28T01:47:50 | step: 479800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.014509926899336e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.14 | consumed tokens: 245657600.0 | grad norm avg: 9.73 | grad norm last: 9.56 | 
2025-12-28T01:47:52 | step: 479900 | train samples/s: 107.3 | train mfu (16-bit): -1.0 | lr mean: 6.0131234931759536e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.56 | consumed tokens: 245708800.0 | grad norm avg: 9.64 | grad norm last: 10.86 | 
2025-12-28T01:47:54 | step: 480000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.011737059452571e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.55 | consumed tokens: 245760000.0 | grad norm avg: 9.32 | grad norm last: 9.09 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_480000-seen_tokens_245760000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_480000-seen_tokens_245760000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_480000-seen_tokens_245760000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_480000-seen_tokens_245760000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_480000-seen_tokens_245760000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_480000-seen_tokens_245760000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_480000-seen_tokens_245760000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_480000-seen_tokens_245760000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:47:56 | step: 480100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.0103502619313076e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.81 | consumed tokens: 245811200.0 | grad norm avg: 9.27 | grad norm last: 9.26 | 
2025-12-28T01:47:58 | step: 480200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 6.008964192005806e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 2.77 | consumed tokens: 245862400.0 | grad norm avg: 9.94 | grad norm last: 7.51 | 
2025-12-28T01:48:00 | step: 480300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 6.007577394484542e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.36 | consumed tokens: 245913600.0 | grad norm avg: 9.98 | grad norm last: 10.36 | 
2025-12-28T01:48:02 | step: 480400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 6.006190596963279e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.31 | consumed tokens: 245964800.0 | grad norm avg: 9.75 | grad norm last: 8.91 | 
2025-12-28T01:48:04 | step: 480500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 6.004804163239896e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.14 | consumed tokens: 246016000.0 | grad norm avg: 9.74 | grad norm last: 9.4 | 
2025-12-28T01:48:06 | step: 480600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 6.003417365718633e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.27 | consumed tokens: 246067200.0 | grad norm avg: 9.6 | grad norm last: 8.37 | 
2025-12-28T01:48:08 | step: 480700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 6.0020305681973696e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.12 | consumed tokens: 246118400.0 | grad norm avg: 9.64 | grad norm last: 9.86 | 
2025-12-28T01:48:10 | step: 480800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 6.000643770676106e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.34 | consumed tokens: 246169600.0 | grad norm avg: 9.91 | grad norm last: 10.45 | 
2025-12-28T01:48:12 | step: 480900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.999256609356962e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.0 | consumed tokens: 246220800.0 | grad norm avg: 9.6 | grad norm last: 8.91 | 
2025-12-28T01:48:14 | step: 481000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.997869811835699e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.55 | consumed tokens: 246272000.0 | grad norm avg: 9.28 | grad norm last: 8.51 | 
2025-12-28T01:48:16 | step: 481100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 5.9964830143144354e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.3 | consumed tokens: 246323200.0 | grad norm avg: 9.53 | grad norm last: 10.1 | 
2025-12-28T01:48:18 | step: 481200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 5.995096216793172e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.41 | consumed tokens: 246374400.0 | grad norm avg: 9.64 | grad norm last: 9.05 | 
2025-12-28T01:48:20 | step: 481300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 5.993708691676147e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.5 | consumed tokens: 246425600.0 | grad norm avg: 9.82 | grad norm last: 11.51 | 
2025-12-28T01:48:22 | step: 481400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 5.992321530357003e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.03 | consumed tokens: 246476800.0 | grad norm avg: 9.63 | grad norm last: 9.71 | 
2025-12-28T01:48:24 | step: 481500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.990934369037859e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.61 | consumed tokens: 246528000.0 | grad norm avg: 9.53 | grad norm last: 8.24 | 
2025-12-28T01:48:26 | step: 481600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.9895468439208344e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 2.98 | consumed tokens: 246579200.0 | grad norm avg: 9.86 | grad norm last: 11.1 | 
2025-12-28T01:48:28 | step: 481700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.988160046399571e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.14 | consumed tokens: 246630400.0 | grad norm avg: 9.81 | grad norm last: 7.87 | 
2025-12-28T01:48:30 | step: 481800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 5.986772521282546e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.0 | consumed tokens: 246681600.0 | grad norm avg: 9.48 | grad norm last: 8.79 | 
2025-12-28T01:48:32 | step: 481900 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 5.9853849961655214e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.77 | consumed tokens: 246732800.0 | grad norm avg: 9.94 | grad norm last: 8.97 | 
2025-12-28T01:48:34 | step: 482000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.9839978348463774e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.59 | consumed tokens: 246784000.0 | grad norm avg: 9.53 | grad norm last: 8.28 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_482000-seen_tokens_246784000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_482000-seen_tokens_246784000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_482000-seen_tokens_246784000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_482000-seen_tokens_246784000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_482000-seen_tokens_246784000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_482000-seen_tokens_246784000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_482000-seen_tokens_246784000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_482000-seen_tokens_246784000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:48:37 | step: 482100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.982610673527233e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.66 | train loss last: 3.5 | consumed tokens: 246835200.0 | grad norm avg: 10.23 | grad norm last: 8.96 | 
2025-12-28T01:48:39 | step: 482200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.981222784612328e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 2.27 | consumed tokens: 246886400.0 | grad norm avg: 9.93 | grad norm last: 8.24 | 
2025-12-28T01:48:41 | step: 482300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.979834895697422e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.12 | consumed tokens: 246937600.0 | grad norm avg: 9.4 | grad norm last: 10.36 | 
2025-12-28T01:48:43 | step: 482400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.978447734378278e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 2.91 | consumed tokens: 246988800.0 | grad norm avg: 9.69 | grad norm last: 8.68 | 
2025-12-28T01:48:45 | step: 482500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.977060573059134e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.38 | consumed tokens: 247040000.0 | grad norm avg: 9.91 | grad norm last: 11.21 | 
2025-12-28T01:48:47 | step: 482600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.975672320346348e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.38 | consumed tokens: 247091200.0 | grad norm avg: 9.61 | grad norm last: 9.46 | 
2025-12-28T01:48:49 | step: 482700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.974284795229323e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.94 | consumed tokens: 247142400.0 | grad norm avg: 9.77 | grad norm last: 9.35 | 
2025-12-28T01:48:51 | step: 482800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.972896542516537e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.81 | consumed tokens: 247193600.0 | grad norm avg: 10.0 | grad norm last: 10.92 | 
2025-12-28T01:48:53 | step: 482900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.971509017399512e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.66 | consumed tokens: 247244800.0 | grad norm avg: 9.83 | grad norm last: 8.06 | 
2025-12-28T01:48:55 | step: 483000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.970121128484607e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.84 | consumed tokens: 247296000.0 | grad norm avg: 9.52 | grad norm last: 9.96 | 
2025-12-28T01:48:57 | step: 483100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.968733239569701e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.44 | consumed tokens: 247347200.0 | grad norm avg: 9.84 | grad norm last: 8.81 | 
2025-12-28T01:48:59 | step: 483200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.9673457144526765e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.28 | consumed tokens: 247398400.0 | grad norm avg: 9.76 | grad norm last: 8.53 | 
2025-12-28T01:49:01 | step: 483300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.96595746173989e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.03 | consumed tokens: 247449600.0 | grad norm avg: 9.74 | grad norm last: 9.62 | 
2025-12-28T01:49:03 | step: 483400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.964569209027104e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.55 | consumed tokens: 247500800.0 | grad norm avg: 9.88 | grad norm last: 8.72 | 
2025-12-28T01:49:05 | step: 483500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.9631813201121986e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.39 | consumed tokens: 247552000.0 | grad norm avg: 9.17 | grad norm last: 8.14 | 
2025-12-28T01:49:07 | step: 483600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.9617930673994124e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 2.94 | consumed tokens: 247603200.0 | grad norm avg: 9.25 | grad norm last: 8.92 | 
2025-12-28T01:49:09 | step: 483700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.960404814686626e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.84 | consumed tokens: 247654400.0 | grad norm avg: 9.56 | grad norm last: 9.24 | 
2025-12-28T01:49:11 | step: 483800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.95901656197384e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.67 | consumed tokens: 247705600.0 | grad norm avg: 9.33 | grad norm last: 9.95 | 
2025-12-28T01:49:13 | step: 483900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.957628309261054e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.3 | consumed tokens: 247756800.0 | grad norm avg: 9.73 | grad norm last: 8.49 | 
2025-12-28T01:49:15 | step: 484000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.9562400565482676e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.59 | consumed tokens: 247808000.0 | grad norm avg: 9.66 | grad norm last: 9.67 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_484000-seen_tokens_247808000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_484000-seen_tokens_247808000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_484000-seen_tokens_247808000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_484000-seen_tokens_247808000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_484000-seen_tokens_247808000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_484000-seen_tokens_247808000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_484000-seen_tokens_247808000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_484000-seen_tokens_247808000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:49:17 | step: 484100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.9548518038354814e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.19 | consumed tokens: 247859200.0 | grad norm avg: 9.33 | grad norm last: 9.12 | 
2025-12-28T01:49:19 | step: 484200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.953463551122695e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.19 | consumed tokens: 247910400.0 | grad norm avg: 9.43 | grad norm last: 9.59 | 
2025-12-28T01:49:22 | step: 484300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.952074934612028e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.92 | consumed tokens: 247961600.0 | grad norm avg: 9.36 | grad norm last: 9.15 | 
2025-12-28T01:49:24 | step: 484400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.950686681899242e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.86 | consumed tokens: 248012800.0 | grad norm avg: 9.74 | grad norm last: 14.33 | 
2025-12-28T01:49:26 | step: 484500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.949298429186456e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 2.59 | consumed tokens: 248064000.0 | grad norm avg: 9.63 | grad norm last: 6.8 | 
2025-12-28T01:49:28 | step: 484600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.947909448877908e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.58 | consumed tokens: 248115200.0 | grad norm avg: 9.46 | grad norm last: 10.63 | 
2025-12-28T01:49:30 | step: 484700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.9465208323672414e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.3 | consumed tokens: 248166400.0 | grad norm avg: 9.52 | grad norm last: 8.11 | 
2025-12-28T01:49:32 | step: 484800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.9451322158565745e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.92 | consumed tokens: 248217600.0 | grad norm avg: 9.47 | grad norm last: 8.71 | 
2025-12-28T01:49:34 | step: 484900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.943743235548027e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.23 | consumed tokens: 248268800.0 | grad norm avg: 9.89 | grad norm last: 8.04 | 
2025-12-28T01:49:36 | step: 485000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.94235461903736e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.67 | consumed tokens: 248320000.0 | grad norm avg: 9.95 | grad norm last: 9.52 | 
2025-12-28T01:49:38 | step: 485100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.940966002526693e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.22 | consumed tokens: 248371200.0 | grad norm avg: 9.71 | grad norm last: 9.47 | 
2025-12-28T01:49:40 | step: 485200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.9395770222181454e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.0 | consumed tokens: 248422400.0 | grad norm avg: 9.61 | grad norm last: 9.77 | 
2025-12-28T01:49:42 | step: 485300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.938188041909598e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.83 | consumed tokens: 248473600.0 | grad norm avg: 9.34 | grad norm last: 8.86 | 
2025-12-28T01:49:44 | step: 485400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.93679906160105e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.44 | consumed tokens: 248524800.0 | grad norm avg: 9.45 | grad norm last: 8.96 | 
2025-12-28T01:49:46 | step: 485500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.9354100812925026e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.19 | consumed tokens: 248576000.0 | grad norm avg: 9.51 | grad norm last: 9.0 | 
2025-12-28T01:49:48 | step: 485600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.934021100983955e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.09 | consumed tokens: 248627200.0 | grad norm avg: 9.46 | grad norm last: 7.91 | 
2025-12-28T01:49:50 | step: 485700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.9326321206754074e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.34 | consumed tokens: 248678400.0 | grad norm avg: 9.84 | grad norm last: 8.86 | 
2025-12-28T01:49:52 | step: 485800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.93124314036686e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.67 | consumed tokens: 248729600.0 | grad norm avg: 10.16 | grad norm last: 11.32 | 
2025-12-28T01:49:54 | step: 485900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.929854160058312e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.97 | consumed tokens: 248780800.0 | grad norm avg: 9.65 | grad norm last: 9.84 | 
2025-12-28T01:49:56 | step: 486000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 5.928464815951884e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.59 | consumed tokens: 248832000.0 | grad norm avg: 9.92 | grad norm last: 10.18 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_486000-seen_tokens_248832000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_486000-seen_tokens_248832000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_486000-seen_tokens_248832000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_486000-seen_tokens_248832000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_486000-seen_tokens_248832000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_486000-seen_tokens_248832000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_486000-seen_tokens_248832000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_486000-seen_tokens_248832000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:49:58 | step: 486100 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 5.9270754718454555e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.66 | train loss last: 4.19 | consumed tokens: 248883200.0 | grad norm avg: 9.86 | grad norm last: 14.14 | 
2025-12-28T01:50:00 | step: 486200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 5.925686491536908e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.19 | consumed tokens: 248934400.0 | grad norm avg: 9.76 | grad norm last: 11.25 | 
2025-12-28T01:50:02 | step: 486300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 5.9242971474304795e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.38 | consumed tokens: 248985600.0 | grad norm avg: 9.53 | grad norm last: 8.84 | 
2025-12-28T01:50:04 | step: 486400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.922907803324051e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.89 | consumed tokens: 249036800.0 | grad norm avg: 10.55 | grad norm last: 10.68 | 
2025-12-28T01:50:06 | step: 486500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.9215188230155036e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.58 | consumed tokens: 249088000.0 | grad norm avg: 9.65 | grad norm last: 8.69 | 
2025-12-28T01:50:08 | step: 486600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.9201291151111946e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.97 | consumed tokens: 249139200.0 | grad norm avg: 9.93 | grad norm last: 8.58 | 
2025-12-28T01:50:10 | step: 486700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 5.9187394072068855e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.41 | consumed tokens: 249190400.0 | grad norm avg: 9.73 | grad norm last: 9.14 | 
2025-12-28T01:50:13 | step: 486800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 5.917350063100457e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.42 | consumed tokens: 249241600.0 | grad norm avg: 9.45 | grad norm last: 8.16 | 
2025-12-28T01:50:15 | step: 486900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.915960355196148e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.28 | consumed tokens: 249292800.0 | grad norm avg: 10.22 | grad norm last: 7.99 | 
2025-12-28T01:50:17 | step: 487000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.91457101108972e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.41 | consumed tokens: 249344000.0 | grad norm avg: 9.92 | grad norm last: 9.71 | 
2025-12-28T01:50:19 | step: 487100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.913181303185411e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.41 | consumed tokens: 249395200.0 | grad norm avg: 9.52 | grad norm last: 11.38 | 
2025-12-28T01:50:21 | step: 487200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.911791595281102e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.38 | consumed tokens: 249446400.0 | grad norm avg: 9.64 | grad norm last: 15.1 | 
2025-12-28T01:50:23 | step: 487300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.910401887376793e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 2.62 | consumed tokens: 249497600.0 | grad norm avg: 9.58 | grad norm last: 7.61 | 
2025-12-28T01:50:25 | step: 487400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.909012179472484e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.14 | consumed tokens: 249548800.0 | grad norm avg: 9.72 | grad norm last: 8.28 | 
2025-12-28T01:50:27 | step: 487500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.9076224715681747e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.34 | consumed tokens: 249600000.0 | grad norm avg: 9.27 | grad norm last: 10.19 | 
2025-12-28T01:50:29 | step: 487600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.9062327636638656e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.3 | consumed tokens: 249651200.0 | grad norm avg: 9.9 | grad norm last: 11.16 | 
2025-12-28T01:50:31 | step: 487700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.904842691961676e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.62 | consumed tokens: 249702400.0 | grad norm avg: 9.77 | grad norm last: 11.3 | 
2025-12-28T01:50:33 | step: 487800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.903452984057367e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.03 | consumed tokens: 249753600.0 | grad norm avg: 9.83 | grad norm last: 9.23 | 
2025-12-28T01:50:35 | step: 487900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.902062912355177e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.09 | consumed tokens: 249804800.0 | grad norm avg: 9.43 | grad norm last: 8.46 | 
2025-12-28T01:50:37 | step: 488000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.900673204450868e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.19 | consumed tokens: 249856000.0 | grad norm avg: 9.3 | grad norm last: 10.57 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_488000-seen_tokens_249856000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_488000-seen_tokens_249856000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_488000-seen_tokens_249856000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_488000-seen_tokens_249856000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_488000-seen_tokens_249856000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_488000-seen_tokens_249856000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_488000-seen_tokens_249856000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_488000-seen_tokens_249856000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:50:39 | step: 488100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.899283496546559e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.77 | consumed tokens: 249907200.0 | grad norm avg: 9.33 | grad norm last: 8.65 | 
2025-12-28T01:50:41 | step: 488200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.8978930610464886e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.11 | consumed tokens: 249958400.0 | grad norm avg: 9.3 | grad norm last: 8.83 | 
2025-12-28T01:50:43 | step: 488300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.896502989344299e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.78 | consumed tokens: 250009600.0 | grad norm avg: 9.48 | grad norm last: 9.17 | 
2025-12-28T01:50:45 | step: 488400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.895112917642109e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.17 | consumed tokens: 250060800.0 | grad norm avg: 9.66 | grad norm last: 8.77 | 
2025-12-28T01:50:47 | step: 488500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.8937224821420386e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.62 | consumed tokens: 250112000.0 | grad norm avg: 10.93 | grad norm last: 8.39 | 
2025-12-28T01:50:49 | step: 488600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.892332410439849e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 2.06 | consumed tokens: 250163200.0 | grad norm avg: 10.3 | grad norm last: 7.09 | 
2025-12-28T01:50:51 | step: 488700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.890942338737659e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.12 | consumed tokens: 250214400.0 | grad norm avg: 9.67 | grad norm last: 9.45 | 
2025-12-28T01:50:53 | step: 488800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.889551903237589e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.78 | consumed tokens: 250265600.0 | grad norm avg: 9.52 | grad norm last: 12.85 | 
2025-12-28T01:50:55 | step: 488900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.888161831535399e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.27 | consumed tokens: 250316800.0 | grad norm avg: 9.47 | grad norm last: 7.97 | 
2025-12-28T01:50:57 | step: 489000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.886771759833209e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.03 | consumed tokens: 250368000.0 | grad norm avg: 9.39 | grad norm last: 11.0 | 
2025-12-28T01:50:59 | step: 489100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.885380960535258e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.5 | consumed tokens: 250419200.0 | grad norm avg: 9.49 | grad norm last: 11.37 | 
2025-12-28T01:51:01 | step: 489200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.883990161237307e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.41 | consumed tokens: 250470400.0 | grad norm avg: 9.52 | grad norm last: 8.47 | 
2025-12-28T01:51:03 | step: 489300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.882600089535117e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.33 | consumed tokens: 250521600.0 | grad norm avg: 9.49 | grad norm last: 9.51 | 
2025-12-28T01:51:05 | step: 489400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.8812100178329274e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.84 | consumed tokens: 250572800.0 | grad norm avg: 9.46 | grad norm last: 12.72 | 
2025-12-28T01:51:07 | step: 489500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.879819218534976e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.47 | consumed tokens: 250624000.0 | grad norm avg: 10.03 | grad norm last: 9.33 | 
2025-12-28T01:51:09 | step: 489600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.878428419237025e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.06 | consumed tokens: 250675200.0 | grad norm avg: 9.67 | grad norm last: 9.15 | 
2025-12-28T01:51:11 | step: 489700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.8770379837369546e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.17 | consumed tokens: 250726400.0 | grad norm avg: 9.3 | grad norm last: 7.79 | 
2025-12-28T01:51:13 | step: 489800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.8756471844390035e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.72 | consumed tokens: 250777600.0 | grad norm avg: 9.58 | grad norm last: 14.21 | 
2025-12-28T01:51:15 | step: 489900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.874257112736814e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.91 | consumed tokens: 250828800.0 | grad norm avg: 9.57 | grad norm last: 9.27 | 
2025-12-28T01:51:18 | step: 490000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.872865949640982e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.58 | consumed tokens: 250880000.0 | grad norm avg: 10.12 | grad norm last: 10.61 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_490000-seen_tokens_250880000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_490000-seen_tokens_250880000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_490000-seen_tokens_250880000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_490000-seen_tokens_250880000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_490000-seen_tokens_250880000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_490000-seen_tokens_250880000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_490000-seen_tokens_250880000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_490000-seen_tokens_250880000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:51:20 | step: 490100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.871475150343031e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.79 | train loss last: 3.09 | consumed tokens: 250931200.0 | grad norm avg: 9.78 | grad norm last: 9.17 | 
2025-12-28T01:51:22 | step: 490200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.8700843510450795e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.25 | consumed tokens: 250982400.0 | grad norm avg: 9.55 | grad norm last: 9.57 | 
2025-12-28T01:51:24 | step: 490300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.8686931879492477e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.19 | consumed tokens: 251033600.0 | grad norm avg: 9.31 | grad norm last: 10.03 | 
2025-12-28T01:51:26 | step: 490400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.867302752449177e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.03 | consumed tokens: 251084800.0 | grad norm avg: 9.67 | grad norm last: 9.63 | 
2025-12-28T01:51:28 | step: 490500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.865911953151226e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.53 | consumed tokens: 251136000.0 | grad norm avg: 9.99 | grad norm last: 13.23 | 
2025-12-28T01:51:30 | step: 490600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.864520790055394e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.81 | consumed tokens: 251187200.0 | grad norm avg: 9.41 | grad norm last: 9.56 | 
2025-12-28T01:51:32 | step: 490700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 5.863129990757443e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.53 | consumed tokens: 251238400.0 | grad norm avg: 9.83 | grad norm last: 11.16 | 
2025-12-28T01:51:34 | step: 490800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.861738827661611e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.75 | consumed tokens: 251289600.0 | grad norm avg: 9.74 | grad norm last: 9.54 | 
2025-12-28T01:51:36 | step: 490900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 5.860348392161541e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.39 | consumed tokens: 251340800.0 | grad norm avg: 9.7 | grad norm last: 9.25 | 
2025-12-28T01:51:38 | step: 491000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.858957229065709e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.16 | consumed tokens: 251392000.0 | grad norm avg: 9.58 | grad norm last: 10.02 | 
2025-12-28T01:51:40 | step: 491100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.857566065969877e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.05 | consumed tokens: 251443200.0 | grad norm avg: 9.35 | grad norm last: 9.13 | 
2025-12-28T01:51:42 | step: 491200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.856174902874045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.33 | consumed tokens: 251494400.0 | grad norm avg: 9.28 | grad norm last: 8.15 | 
2025-12-28T01:51:44 | step: 491300 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 5.854783739778213e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.34 | consumed tokens: 251545600.0 | grad norm avg: 9.79 | grad norm last: 19.0 | 
2025-12-28T01:51:46 | step: 491400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 5.853392576682381e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.25 | consumed tokens: 251596800.0 | grad norm avg: 9.6 | grad norm last: 8.7 | 
2025-12-28T01:51:48 | step: 491500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 5.8520014135865495e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.77 | consumed tokens: 251648000.0 | grad norm avg: 9.67 | grad norm last: 8.45 | 
2025-12-28T01:51:50 | step: 491600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 5.8506102504907176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.45 | consumed tokens: 251699200.0 | grad norm avg: 10.22 | grad norm last: 9.74 | 
2025-12-28T01:51:52 | step: 491700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 5.849218359799124e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.92 | consumed tokens: 251750400.0 | grad norm avg: 9.73 | grad norm last: 9.61 | 
2025-12-28T01:51:54 | step: 491800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.8478271967032924e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.25 | consumed tokens: 251801600.0 | grad norm avg: 9.68 | grad norm last: 10.73 | 
2025-12-28T01:51:56 | step: 491900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.84643566980958e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.7 | consumed tokens: 251852800.0 | grad norm avg: 9.87 | grad norm last: 9.88 | 
2025-12-28T01:51:58 | step: 492000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.845044506713748e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.97 | consumed tokens: 251904000.0 | grad norm avg: 9.87 | grad norm last: 8.6 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_492000-seen_tokens_251904000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_492000-seen_tokens_251904000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_492000-seen_tokens_251904000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_492000-seen_tokens_251904000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_492000-seen_tokens_251904000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_492000-seen_tokens_251904000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_492000-seen_tokens_251904000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_492000-seen_tokens_251904000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:52:01 | step: 492100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.8436529798200354e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 3.44 | consumed tokens: 251955200.0 | grad norm avg: 9.51 | grad norm last: 8.72 | 
2025-12-28T01:52:03 | step: 492200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.842261089128442e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.16 | consumed tokens: 252006400.0 | grad norm avg: 9.86 | grad norm last: 8.66 | 
2025-12-28T01:52:05 | step: 492300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.84086992603261e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.2 | consumed tokens: 252057600.0 | grad norm avg: 9.56 | grad norm last: 8.58 | 
2025-12-28T01:52:07 | step: 492400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.8394783991388977e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.0 | consumed tokens: 252108800.0 | grad norm avg: 10.3 | grad norm last: 8.93 | 
2025-12-28T01:52:09 | step: 492500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.838086872245185e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.03 | consumed tokens: 252160000.0 | grad norm avg: 9.91 | grad norm last: 8.36 | 
2025-12-28T01:52:11 | step: 492600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.836695709149353e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 5.03 | consumed tokens: 252211200.0 | grad norm avg: 9.75 | grad norm last: 12.12 | 
2025-12-28T01:52:13 | step: 492700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.83530381845776e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 5.22 | consumed tokens: 252262400.0 | grad norm avg: 9.55 | grad norm last: 15.69 | 
2025-12-28T01:52:15 | step: 492800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.8339119277661666e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 2.98 | consumed tokens: 252313600.0 | grad norm avg: 9.3 | grad norm last: 7.58 | 
2025-12-28T01:52:17 | step: 492900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.832520037074573e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.61 | consumed tokens: 252364800.0 | grad norm avg: 9.28 | grad norm last: 9.29 | 
2025-12-28T01:52:19 | step: 493000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.831128510180861e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.19 | consumed tokens: 252416000.0 | grad norm avg: 9.66 | grad norm last: 8.87 | 
2025-12-28T01:52:21 | step: 493100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.829736983287148e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.69 | consumed tokens: 252467200.0 | grad norm avg: 9.95 | grad norm last: 10.9 | 
2025-12-28T01:52:23 | step: 493200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.828345092595555e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 2.89 | consumed tokens: 252518400.0 | grad norm avg: 9.74 | grad norm last: 8.12 | 
2025-12-28T01:52:25 | step: 493300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.8269532019039616e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.44 | consumed tokens: 252569600.0 | grad norm avg: 9.84 | grad norm last: 8.23 | 
2025-12-28T01:52:27 | step: 493400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.825561311212368e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.83 | consumed tokens: 252620800.0 | grad norm avg: 9.34 | grad norm last: 8.98 | 
2025-12-28T01:52:29 | step: 493500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.824169420520775e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 2.89 | consumed tokens: 252672000.0 | grad norm avg: 9.35 | grad norm last: 7.76 | 
2025-12-28T01:52:31 | step: 493600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.822777529829182e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.09 | consumed tokens: 252723200.0 | grad norm avg: 9.53 | grad norm last: 8.15 | 
2025-12-28T01:52:33 | step: 493700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.8213856391375884e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 3.58 | consumed tokens: 252774400.0 | grad norm avg: 9.69 | grad norm last: 8.87 | 
2025-12-28T01:52:35 | step: 493800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.819993748445995e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.56 | consumed tokens: 252825600.0 | grad norm avg: 9.16 | grad norm last: 8.71 | 
2025-12-28T01:52:37 | step: 493900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.818601857754402e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.34 | consumed tokens: 252876800.0 | grad norm avg: 9.43 | grad norm last: 11.08 | 
2025-12-28T01:52:39 | step: 494000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.817209603264928e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.91 | consumed tokens: 252928000.0 | grad norm avg: 10.58 | grad norm last: 8.27 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_494000-seen_tokens_252928000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_494000-seen_tokens_252928000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_494000-seen_tokens_252928000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_494000-seen_tokens_252928000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_494000-seen_tokens_252928000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_494000-seen_tokens_252928000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_494000-seen_tokens_252928000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_494000-seen_tokens_252928000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:52:41 | step: 494100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.815817348775454e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.7 | train loss last: 3.47 | consumed tokens: 252979200.0 | grad norm avg: 9.39 | grad norm last: 9.04 | 
2025-12-28T01:52:44 | step: 494200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.8144254580838606e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.09 | consumed tokens: 253030400.0 | grad norm avg: 9.37 | grad norm last: 8.13 | 
2025-12-28T01:52:46 | step: 494300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.8130332035943866e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.27 | consumed tokens: 253081600.0 | grad norm avg: 9.65 | grad norm last: 10.78 | 
2025-12-28T01:52:48 | step: 494400 | train samples/s: 98.6 | train mfu (16-bit): -1.0 | lr mean: 5.8116409491049126e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.06 | consumed tokens: 253132800.0 | grad norm avg: 9.58 | grad norm last: 10.04 | 
2025-12-28T01:52:50 | step: 494500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.810249058413319e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.52 | consumed tokens: 253184000.0 | grad norm avg: 9.75 | grad norm last: 10.99 | 
2025-12-28T01:52:52 | step: 494600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.808856803923845e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.58 | consumed tokens: 253235200.0 | grad norm avg: 9.59 | grad norm last: 8.88 | 
2025-12-28T01:52:54 | step: 494700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.807464549434371e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.88 | consumed tokens: 253286400.0 | grad norm avg: 9.5 | grad norm last: 8.53 | 
2025-12-28T01:52:56 | step: 494800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.806072658742778e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 2.89 | consumed tokens: 253337600.0 | grad norm avg: 9.68 | grad norm last: 8.58 | 
2025-12-28T01:52:58 | step: 494900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.804680040455423e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.08 | consumed tokens: 253388800.0 | grad norm avg: 9.43 | grad norm last: 8.71 | 
2025-12-28T01:53:00 | step: 495000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.8032874221680686e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.62 | consumed tokens: 253440000.0 | grad norm avg: 9.47 | grad norm last: 9.77 | 
2025-12-28T01:53:02 | step: 495100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.8018951676785946e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.58 | consumed tokens: 253491200.0 | grad norm avg: 9.35 | grad norm last: 10.84 | 
2025-12-28T01:53:04 | step: 495200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.8005029131891206e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.81 | consumed tokens: 253542400.0 | grad norm avg: 9.75 | grad norm last: 9.43 | 
2025-12-28T01:53:06 | step: 495300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.799110294901766e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 5.41 | consumed tokens: 253593600.0 | grad norm avg: 9.58 | grad norm last: 13.08 | 
2025-12-28T01:53:08 | step: 495400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.797717676614411e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.34 | consumed tokens: 253644800.0 | grad norm avg: 9.56 | grad norm last: 9.08 | 
2025-12-28T01:53:10 | step: 495500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.796325785922818e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.47 | consumed tokens: 253696000.0 | grad norm avg: 9.44 | grad norm last: 10.64 | 
2025-12-28T01:53:12 | step: 495600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.794932440039702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.33 | consumed tokens: 253747200.0 | grad norm avg: 9.6 | grad norm last: 11.3 | 
2025-12-28T01:53:14 | step: 495700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.7935405493481085e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.19 | consumed tokens: 253798400.0 | grad norm avg: 9.55 | grad norm last: 8.91 | 
2025-12-28T01:53:16 | step: 495800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 5.792147931060754e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.27 | consumed tokens: 253849600.0 | grad norm avg: 9.69 | grad norm last: 9.44 | 
2025-12-28T01:53:18 | step: 495900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.790755312773399e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.95 | consumed tokens: 253900800.0 | grad norm avg: 9.65 | grad norm last: 9.7 | 
2025-12-28T01:53:20 | step: 496000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.7893626944860443e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.47 | consumed tokens: 253952000.0 | grad norm avg: 9.57 | grad norm last: 10.4 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_496000-seen_tokens_253952000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_496000-seen_tokens_253952000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_496000-seen_tokens_253952000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_496000-seen_tokens_253952000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_496000-seen_tokens_253952000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_496000-seen_tokens_253952000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_496000-seen_tokens_253952000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_496000-seen_tokens_253952000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:53:22 | step: 496100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.7879700761986896e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.94 | consumed tokens: 254003200.0 | grad norm avg: 9.57 | grad norm last: 9.74 | 
2025-12-28T01:53:24 | step: 496200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.7865767303155735e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.47 | consumed tokens: 254054400.0 | grad norm avg: 9.51 | grad norm last: 10.21 | 
2025-12-28T01:53:26 | step: 496300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 5.78518483962398e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.62 | consumed tokens: 254105600.0 | grad norm avg: 9.51 | grad norm last: 10.63 | 
2025-12-28T01:53:29 | step: 496400 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 5.783791493740864e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 5.03 | consumed tokens: 254156800.0 | grad norm avg: 9.72 | grad norm last: 15.07 | 
2025-12-28T01:53:31 | step: 496500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 5.7823988754535094e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.39 | consumed tokens: 254208000.0 | grad norm avg: 9.74 | grad norm last: 9.68 | 
2025-12-28T01:53:33 | step: 496600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 5.781006257166155e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.25 | consumed tokens: 254259200.0 | grad norm avg: 9.71 | grad norm last: 9.46 | 
2025-12-28T01:53:35 | step: 496700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.779613275080919e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.48 | consumed tokens: 254310400.0 | grad norm avg: 9.75 | grad norm last: 8.92 | 
2025-12-28T01:53:37 | step: 496800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.7782206567935646e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.58 | consumed tokens: 254361600.0 | grad norm avg: 9.96 | grad norm last: 9.57 | 
2025-12-28T01:53:39 | step: 496900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.776827674708329e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.06 | consumed tokens: 254412800.0 | grad norm avg: 9.75 | grad norm last: 9.25 | 
2025-12-28T01:53:41 | step: 497000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 5.7754350564209744e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.86 | consumed tokens: 254464000.0 | grad norm avg: 9.95 | grad norm last: 10.23 | 
2025-12-28T01:53:43 | step: 497100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 5.774041710537858e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.69 | consumed tokens: 254515200.0 | grad norm avg: 9.77 | grad norm last: 12.44 | 
2025-12-28T01:53:45 | step: 497200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.7726490922505036e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.27 | consumed tokens: 254566400.0 | grad norm avg: 9.86 | grad norm last: 8.68 | 
2025-12-28T01:53:47 | step: 497300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.771256110165268e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.3 | consumed tokens: 254617600.0 | grad norm avg: 10.0 | grad norm last: 8.29 | 
2025-12-28T01:53:49 | step: 497400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.769863128080033e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.62 | consumed tokens: 254668800.0 | grad norm avg: 10.07 | grad norm last: 10.09 | 
2025-12-28T01:53:51 | step: 497500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.7684697821969166e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.16 | consumed tokens: 254720000.0 | grad norm avg: 9.72 | grad norm last: 9.5 | 
2025-12-28T01:53:53 | step: 497600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.767076800111681e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.34 | consumed tokens: 254771200.0 | grad norm avg: 9.98 | grad norm last: 8.27 | 
2025-12-28T01:53:55 | step: 497700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.765683818026446e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.5 | consumed tokens: 254822400.0 | grad norm avg: 9.97 | grad norm last: 10.59 | 
2025-12-28T01:53:57 | step: 497800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.764291199739091e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.16 | consumed tokens: 254873600.0 | grad norm avg: 10.17 | grad norm last: 8.05 | 
2025-12-28T01:53:59 | step: 497900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.762897490058094e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 2.98 | consumed tokens: 254924800.0 | grad norm avg: 9.66 | grad norm last: 8.29 | 
2025-12-28T01:54:01 | step: 498000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.761504507972859e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 5.69 | consumed tokens: 254976000.0 | grad norm avg: 9.65 | grad norm last: 17.73 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_498000-seen_tokens_254976000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_498000-seen_tokens_254976000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_498000-seen_tokens_254976000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_498000-seen_tokens_254976000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_498000-seen_tokens_254976000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_498000-seen_tokens_254976000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_498000-seen_tokens_254976000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_498000-seen_tokens_254976000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:54:03 | step: 498100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.760111162089743e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.75 | consumed tokens: 255027200.0 | grad norm avg: 9.73 | grad norm last: 8.1 | 
2025-12-28T01:54:05 | step: 498200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.758718180004507e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.5 | consumed tokens: 255078400.0 | grad norm avg: 9.76 | grad norm last: 8.17 | 
2025-12-28T01:54:07 | step: 498300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.7573244703235105e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.45 | consumed tokens: 255129600.0 | grad norm avg: 9.99 | grad norm last: 10.04 | 
2025-12-28T01:54:09 | step: 498400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.755931488238275e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.25 | consumed tokens: 255180800.0 | grad norm avg: 10.13 | grad norm last: 18.12 | 
2025-12-28T01:54:11 | step: 498500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.7545385061530396e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.19 | consumed tokens: 255232000.0 | grad norm avg: 9.9 | grad norm last: 11.08 | 
2025-12-28T01:54:13 | step: 498600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.753144796472043e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.16 | consumed tokens: 255283200.0 | grad norm avg: 10.3 | grad norm last: 9.03 | 
2025-12-28T01:54:15 | step: 498700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.7517518143868074e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.09 | consumed tokens: 255334400.0 | grad norm avg: 10.14 | grad norm last: 8.48 | 
2025-12-28T01:54:17 | step: 498800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.750358468503691e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 5.56 | consumed tokens: 255385600.0 | grad norm avg: 9.99 | grad norm last: 12.14 | 
2025-12-28T01:54:19 | step: 498900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.748965122620575e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.36 | consumed tokens: 255436800.0 | grad norm avg: 10.56 | grad norm last: 10.92 | 
2025-12-28T01:54:22 | step: 499000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.747571412939578e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.16 | consumed tokens: 255488000.0 | grad norm avg: 10.27 | grad norm last: 12.03 | 
2025-12-28T01:54:24 | step: 499100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.7461777032585815e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.36 | consumed tokens: 255539200.0 | grad norm avg: 9.87 | grad norm last: 10.43 | 
2025-12-28T01:54:26 | step: 499200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.744784721173346e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 2.81 | consumed tokens: 255590400.0 | grad norm avg: 9.38 | grad norm last: 7.43 | 
2025-12-28T01:54:28 | step: 499300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.743391011492349e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.55 | consumed tokens: 255641600.0 | grad norm avg: 10.5 | grad norm last: 9.51 | 
2025-12-28T01:54:30 | step: 499400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.741997665609233e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.7 | consumed tokens: 255692800.0 | grad norm avg: 9.64 | grad norm last: 11.86 | 
2025-12-28T01:54:32 | step: 499500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.740604319726117e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.55 | consumed tokens: 255744000.0 | grad norm avg: 9.8 | grad norm last: 8.74 | 
2025-12-28T01:54:34 | step: 499600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.7392102462472394e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.5 | consumed tokens: 255795200.0 | grad norm avg: 10.0 | grad norm last: 9.36 | 
2025-12-28T01:54:36 | step: 499700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.737816900364123e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.69 | consumed tokens: 255846400.0 | grad norm avg: 10.67 | grad norm last: 9.87 | 
2025-12-28T01:54:38 | step: 499800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.736423554481007e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.7 | consumed tokens: 255897600.0 | grad norm avg: 9.95 | grad norm last: 9.1 | 
2025-12-28T01:54:40 | step: 499900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.735030208597891e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.42 | consumed tokens: 255948800.0 | grad norm avg: 10.27 | grad norm last: 10.69 | 
2025-12-28T01:54:42 | step: 500000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.7336361351190135e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.81 | consumed tokens: 256000000.0 | grad norm avg: 10.14 | grad norm last: 9.69 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_500000-seen_tokens_256000000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_500000-seen_tokens_256000000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_500000-seen_tokens_256000000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_500000-seen_tokens_256000000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_500000-seen_tokens_256000000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_500000-seen_tokens_256000000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_500000-seen_tokens_256000000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_500000-seen_tokens_256000000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:54:44 | step: 500100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.7322424254380167e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.75 | train loss last: 4.06 | consumed tokens: 256051200.0 | grad norm avg: 10.41 | grad norm last: 9.41 | 
2025-12-28T01:54:46 | step: 500200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.73084871575702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.61 | consumed tokens: 256102400.0 | grad norm avg: 10.67 | grad norm last: 8.71 | 
2025-12-28T01:54:48 | step: 500300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.729455369873904e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.66 | consumed tokens: 256153600.0 | grad norm avg: 10.03 | grad norm last: 8.8 | 
2025-12-28T01:54:50 | step: 500400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.728061660192907e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.42 | consumed tokens: 256204800.0 | grad norm avg: 10.32 | grad norm last: 8.19 | 
2025-12-28T01:54:52 | step: 500500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.726667586714029e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.39 | consumed tokens: 256256000.0 | grad norm avg: 9.71 | grad norm last: 10.08 | 
2025-12-28T01:54:54 | step: 500600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.7252738770330325e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.14 | consumed tokens: 256307200.0 | grad norm avg: 10.03 | grad norm last: 8.39 | 
2025-12-28T01:54:56 | step: 500700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.7238805311499164e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.39 | consumed tokens: 256358400.0 | grad norm avg: 10.15 | grad norm last: 11.6 | 
2025-12-28T01:54:58 | step: 500800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 5.722486457671039e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.97 | consumed tokens: 256409600.0 | grad norm avg: 9.75 | grad norm last: 8.61 | 
2025-12-28T01:55:00 | step: 500900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 5.721092384192161e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.19 | consumed tokens: 256460800.0 | grad norm avg: 9.55 | grad norm last: 8.2 | 
2025-12-28T01:55:02 | step: 501000 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 5.7196986745111644e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.06 | consumed tokens: 256512000.0 | grad norm avg: 10.23 | grad norm last: 14.52 | 
2025-12-28T01:55:04 | step: 501100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.7183049648301676e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.47 | consumed tokens: 256563200.0 | grad norm avg: 10.33 | grad norm last: 10.28 | 
2025-12-28T01:55:06 | step: 501200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.71691089135129e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 2.73 | consumed tokens: 256614400.0 | grad norm avg: 9.88 | grad norm last: 9.28 | 
2025-12-28T01:55:08 | step: 501300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.7155168178724125e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.91 | consumed tokens: 256665600.0 | grad norm avg: 10.06 | grad norm last: 9.74 | 
2025-12-28T01:55:10 | step: 501400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.714122744393535e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.73 | consumed tokens: 256716800.0 | grad norm avg: 9.91 | grad norm last: 10.77 | 
2025-12-28T01:55:12 | step: 501500 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 5.7127286709146574e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.19 | consumed tokens: 256768000.0 | grad norm avg: 10.21 | grad norm last: 11.0 | 
2025-12-28T01:55:14 | step: 501600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 5.711335325031541e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.53 | consumed tokens: 256819200.0 | grad norm avg: 10.2 | grad norm last: 8.83 | 
2025-12-28T01:55:17 | step: 501700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 5.709941251552664e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.38 | consumed tokens: 256870400.0 | grad norm avg: 10.12 | grad norm last: 10.45 | 
2025-12-28T01:55:19 | step: 501800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.708547178073786e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.16 | consumed tokens: 256921600.0 | grad norm avg: 9.56 | grad norm last: 12.39 | 
2025-12-28T01:55:21 | step: 501900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.7071531045949087e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.78 | consumed tokens: 256972800.0 | grad norm avg: 9.92 | grad norm last: 9.21 | 
2025-12-28T01:55:23 | step: 502000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.705759031116031e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.81 | consumed tokens: 257024000.0 | grad norm avg: 9.75 | grad norm last: 10.18 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_502000-seen_tokens_257024000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_502000-seen_tokens_257024000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_502000-seen_tokens_257024000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_502000-seen_tokens_257024000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_502000-seen_tokens_257024000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_502000-seen_tokens_257024000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_502000-seen_tokens_257024000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_502000-seen_tokens_257024000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:55:25 | step: 502100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 5.7043649576371536e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 3.94 | consumed tokens: 257075200.0 | grad norm avg: 9.75 | grad norm last: 10.45 | 
2025-12-28T01:55:27 | step: 502200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.702970884158276e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.09 | consumed tokens: 257126400.0 | grad norm avg: 9.9 | grad norm last: 9.3 | 
2025-12-28T01:55:29 | step: 502300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 5.7015768106793985e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.31 | consumed tokens: 257177600.0 | grad norm avg: 10.12 | grad norm last: 11.42 | 
2025-12-28T01:55:31 | step: 502400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.700182737200521e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.27 | consumed tokens: 257228800.0 | grad norm avg: 9.72 | grad norm last: 8.29 | 
2025-12-28T01:55:33 | step: 502500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.698787936125882e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.61 | consumed tokens: 257280000.0 | grad norm avg: 11.13 | grad norm last: 10.22 | 
2025-12-28T01:55:35 | step: 502600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.6973938626470044e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.91 | consumed tokens: 257331200.0 | grad norm avg: 10.4 | grad norm last: 10.85 | 
2025-12-28T01:55:37 | step: 502700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.695999789168127e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.17 | consumed tokens: 257382400.0 | grad norm avg: 10.27 | grad norm last: 8.7 | 
2025-12-28T01:55:39 | step: 502800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.694605715689249e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.08 | consumed tokens: 257433600.0 | grad norm avg: 9.8 | grad norm last: 9.2 | 
2025-12-28T01:55:41 | step: 502900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.693211642210372e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.52 | consumed tokens: 257484800.0 | grad norm avg: 9.83 | grad norm last: 8.51 | 
2025-12-28T01:55:43 | step: 503000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.691817568731494e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.66 | consumed tokens: 257536000.0 | grad norm avg: 9.71 | grad norm last: 13.24 | 
2025-12-28T01:55:45 | step: 503100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.690423131454736e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.0 | consumed tokens: 257587200.0 | grad norm avg: 9.58 | grad norm last: 10.36 | 
2025-12-28T01:55:47 | step: 503200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.689028694177978e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.8 | consumed tokens: 257638400.0 | grad norm avg: 9.68 | grad norm last: 8.38 | 
2025-12-28T01:55:49 | step: 503300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.6876346206991e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.05 | consumed tokens: 257689600.0 | grad norm avg: 10.08 | grad norm last: 8.07 | 
2025-12-28T01:55:51 | step: 503400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.6862405472202227e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.39 | consumed tokens: 257740800.0 | grad norm avg: 9.53 | grad norm last: 8.1 | 
2025-12-28T01:55:53 | step: 503500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.684845746145584e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.64 | consumed tokens: 257792000.0 | grad norm avg: 9.69 | grad norm last: 8.61 | 
2025-12-28T01:55:55 | step: 503600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.683451672666706e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.48 | consumed tokens: 257843200.0 | grad norm avg: 10.07 | grad norm last: 8.78 | 
2025-12-28T01:55:57 | step: 503700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.682057235389948e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.22 | consumed tokens: 257894400.0 | grad norm avg: 10.58 | grad norm last: 9.04 | 
2025-12-28T01:55:59 | step: 503800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.6806627981131896e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.58 | consumed tokens: 257945600.0 | grad norm avg: 9.87 | grad norm last: 8.77 | 
2025-12-28T01:56:01 | step: 503900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.679267997038551e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.66 | consumed tokens: 257996800.0 | grad norm avg: 10.07 | grad norm last: 9.57 | 
2025-12-28T01:56:03 | step: 504000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.677873923559673e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.53 | consumed tokens: 258048000.0 | grad norm avg: 9.55 | grad norm last: 10.56 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_504000-seen_tokens_258048000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_504000-seen_tokens_258048000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_504000-seen_tokens_258048000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_504000-seen_tokens_258048000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_504000-seen_tokens_258048000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_504000-seen_tokens_258048000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_504000-seen_tokens_258048000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_504000-seen_tokens_258048000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:56:06 | step: 504100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.676479486282915e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.68 | train loss last: 4.28 | consumed tokens: 258099200.0 | grad norm avg: 9.73 | grad norm last: 11.06 | 
2025-12-28T01:56:08 | step: 504200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.6750850490061566e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.42 | consumed tokens: 258150400.0 | grad norm avg: 10.19 | grad norm last: 9.23 | 
2025-12-28T01:56:10 | step: 504300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.673690975527279e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 2.89 | consumed tokens: 258201600.0 | grad norm avg: 10.17 | grad norm last: 8.21 | 
2025-12-28T01:56:12 | step: 504400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.67229617445264e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.25 | consumed tokens: 258252800.0 | grad norm avg: 9.76 | grad norm last: 12.99 | 
2025-12-28T01:56:14 | step: 504500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.670901737175882e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.31 | consumed tokens: 258304000.0 | grad norm avg: 10.23 | grad norm last: 8.94 | 
2025-12-28T01:56:16 | step: 504600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.669506572303362e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.91 | consumed tokens: 258355200.0 | grad norm avg: 9.57 | grad norm last: 10.37 | 
2025-12-28T01:56:18 | step: 504700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.6681124988244846e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.25 | consumed tokens: 258406400.0 | grad norm avg: 10.17 | grad norm last: 8.32 | 
2025-12-28T01:56:20 | step: 504800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.6667180615477264e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.58 | consumed tokens: 258457600.0 | grad norm avg: 9.96 | grad norm last: 8.84 | 
2025-12-28T01:56:22 | step: 504900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.665323624270968e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.83 | consumed tokens: 258508800.0 | grad norm avg: 10.27 | grad norm last: 9.39 | 
2025-12-28T01:56:24 | step: 505000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.663928823196329e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.36 | consumed tokens: 258560000.0 | grad norm avg: 9.79 | grad norm last: 8.1 | 
2025-12-28T01:56:26 | step: 505100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.66253402212169e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.94 | consumed tokens: 258611200.0 | grad norm avg: 10.02 | grad norm last: 9.5 | 
2025-12-28T01:56:28 | step: 505200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.661139221047051e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.55 | consumed tokens: 258662400.0 | grad norm avg: 10.11 | grad norm last: 8.39 | 
2025-12-28T01:56:30 | step: 505300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.659744783770293e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.44 | consumed tokens: 258713600.0 | grad norm avg: 9.75 | grad norm last: 8.98 | 
2025-12-28T01:56:32 | step: 505400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.658350346493535e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.84 | consumed tokens: 258764800.0 | grad norm avg: 10.02 | grad norm last: 9.69 | 
2025-12-28T01:56:34 | step: 505500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.656955545418896e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.39 | consumed tokens: 258816000.0 | grad norm avg: 9.88 | grad norm last: 9.01 | 
2025-12-28T01:56:36 | step: 505600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.655560744344257e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.69 | consumed tokens: 258867200.0 | grad norm avg: 9.97 | grad norm last: 9.58 | 
2025-12-28T01:56:38 | step: 505700 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 5.654165943269618e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.09 | consumed tokens: 258918400.0 | grad norm avg: 9.84 | grad norm last: 8.66 | 
2025-12-28T01:56:40 | step: 505800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 5.6527715059928596e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.55 | consumed tokens: 258969600.0 | grad norm avg: 9.7 | grad norm last: 8.56 | 
2025-12-28T01:56:42 | step: 505900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 5.6513770687161013e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.03 | consumed tokens: 259020800.0 | grad norm avg: 10.16 | grad norm last: 8.86 | 
2025-12-28T01:56:44 | step: 506000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.649981903843582e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.55 | consumed tokens: 259072000.0 | grad norm avg: 10.0 | grad norm last: 9.85 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_506000-seen_tokens_259072000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_506000-seen_tokens_259072000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_506000-seen_tokens_259072000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_506000-seen_tokens_259072000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_506000-seen_tokens_259072000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_506000-seen_tokens_259072000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_506000-seen_tokens_259072000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_506000-seen_tokens_259072000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:56:46 | step: 506100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.648586738971062e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.7 | train loss last: 3.75 | consumed tokens: 259123200.0 | grad norm avg: 9.73 | grad norm last: 8.79 | 
2025-12-28T01:56:48 | step: 506200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.647192301694304e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.67 | consumed tokens: 259174400.0 | grad norm avg: 10.0 | grad norm last: 10.16 | 
2025-12-28T01:56:51 | step: 506300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.6457978644175455e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.75 | consumed tokens: 259225600.0 | grad norm avg: 9.9 | grad norm last: 9.19 | 
2025-12-28T01:56:53 | step: 506400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 5.6444030633429065e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.56 | consumed tokens: 259276800.0 | grad norm avg: 11.05 | grad norm last: 8.39 | 
2025-12-28T01:56:55 | step: 506500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 5.643007534672506e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.72 | consumed tokens: 259328000.0 | grad norm avg: 10.23 | grad norm last: 8.52 | 
2025-12-28T01:56:57 | step: 506600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.641613097395748e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.59 | consumed tokens: 259379200.0 | grad norm avg: 10.05 | grad norm last: 9.94 | 
2025-12-28T01:56:59 | step: 506700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.6402186601189896e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.56 | consumed tokens: 259430400.0 | grad norm avg: 10.14 | grad norm last: 11.07 | 
2025-12-28T01:57:01 | step: 506800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.63882349524647e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.67 | consumed tokens: 259481600.0 | grad norm avg: 10.03 | grad norm last: 8.85 | 
2025-12-28T01:57:03 | step: 506900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.63742833037395e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.48 | consumed tokens: 259532800.0 | grad norm avg: 10.22 | grad norm last: 8.56 | 
2025-12-28T01:57:05 | step: 507000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.636033893097192e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.52 | consumed tokens: 259584000.0 | grad norm avg: 10.7 | grad norm last: 14.13 | 
2025-12-28T01:57:07 | step: 507100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 5.634639455820434e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.73 | consumed tokens: 259635200.0 | grad norm avg: 10.41 | grad norm last: 9.2 | 
2025-12-28T01:57:09 | step: 507200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.6332439271500334e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.53 | consumed tokens: 259686400.0 | grad norm avg: 10.29 | grad norm last: 9.03 | 
2025-12-28T01:57:11 | step: 507300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.6318491260753945e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.67 | consumed tokens: 259737600.0 | grad norm avg: 9.59 | grad norm last: 9.59 | 
2025-12-28T01:57:13 | step: 507400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.6304543250007555e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.47 | consumed tokens: 259788800.0 | grad norm avg: 9.83 | grad norm last: 9.16 | 
2025-12-28T01:57:15 | step: 507500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.629059160128236e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.16 | consumed tokens: 259840000.0 | grad norm avg: 10.21 | grad norm last: 10.9 | 
2025-12-28T01:57:17 | step: 507600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.627663995255716e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.89 | consumed tokens: 259891200.0 | grad norm avg: 9.81 | grad norm last: 10.16 | 
2025-12-28T01:57:19 | step: 507700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.626269194181077e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 2.86 | consumed tokens: 259942400.0 | grad norm avg: 9.99 | grad norm last: 8.45 | 
2025-12-28T01:57:21 | step: 507800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.624874393106438e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.73 | consumed tokens: 259993600.0 | grad norm avg: 9.94 | grad norm last: 9.22 | 
2025-12-28T01:57:23 | step: 507900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.623478864436038e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.23 | consumed tokens: 260044800.0 | grad norm avg: 9.67 | grad norm last: 10.16 | 
2025-12-28T01:57:25 | step: 508000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.6220844271592796e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.7 | consumed tokens: 260096000.0 | grad norm avg: 9.96 | grad norm last: 9.38 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_508000-seen_tokens_260096000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_508000-seen_tokens_260096000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_508000-seen_tokens_260096000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_508000-seen_tokens_260096000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_508000-seen_tokens_260096000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_508000-seen_tokens_260096000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_508000-seen_tokens_260096000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_508000-seen_tokens_260096000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:57:27 | step: 508100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.62068926228676e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.41 | consumed tokens: 260147200.0 | grad norm avg: 9.91 | grad norm last: 10.39 | 
2025-12-28T01:57:29 | step: 508200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.6192937336163595e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.73 | consumed tokens: 260198400.0 | grad norm avg: 10.2 | grad norm last: 8.8 | 
2025-12-28T01:57:31 | step: 508300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.617899296339601e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.7 | consumed tokens: 260249600.0 | grad norm avg: 10.01 | grad norm last: 8.74 | 
2025-12-28T01:57:33 | step: 508400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.6165041314670816e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.7 | consumed tokens: 260300800.0 | grad norm avg: 9.91 | grad norm last: 9.38 | 
2025-12-28T01:57:35 | step: 508500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.615108602796681e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.66 | consumed tokens: 260352000.0 | grad norm avg: 9.73 | grad norm last: 12.26 | 
2025-12-28T01:57:37 | step: 508600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.613714165519923e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.2 | consumed tokens: 260403200.0 | grad norm avg: 9.82 | grad norm last: 8.05 | 
2025-12-28T01:57:39 | step: 508700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.612319000647403e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.31 | consumed tokens: 260454400.0 | grad norm avg: 9.91 | grad norm last: 8.63 | 
2025-12-28T01:57:41 | step: 508800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.610923471977003e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.09 | consumed tokens: 260505600.0 | grad norm avg: 9.92 | grad norm last: 10.6 | 
2025-12-28T01:57:43 | step: 508900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.609528670902364e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.55 | consumed tokens: 260556800.0 | grad norm avg: 9.87 | grad norm last: 16.54 | 
2025-12-28T01:57:46 | step: 509000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.608133506029844e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.09 | consumed tokens: 260608000.0 | grad norm avg: 9.91 | grad norm last: 8.4 | 
2025-12-28T01:57:48 | step: 509100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.6067383411573246e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.8 | consumed tokens: 260659200.0 | grad norm avg: 9.99 | grad norm last: 10.9 | 
2025-12-28T01:57:50 | step: 509200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.6053435400826856e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.53 | consumed tokens: 260710400.0 | grad norm avg: 10.38 | grad norm last: 10.79 | 
2025-12-28T01:57:52 | step: 509300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.603948375210166e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.78 | consumed tokens: 260761600.0 | grad norm avg: 10.07 | grad norm last: 9.6 | 
2025-12-28T01:57:54 | step: 509400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.602553210337646e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.62 | consumed tokens: 260812800.0 | grad norm avg: 10.04 | grad norm last: 11.77 | 
2025-12-28T01:57:56 | step: 509500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.6011584092630073e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.88 | consumed tokens: 260864000.0 | grad norm avg: 9.85 | grad norm last: 9.59 | 
2025-12-28T01:57:58 | step: 509600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.5997621529968455e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.91 | consumed tokens: 260915200.0 | grad norm avg: 10.35 | grad norm last: 9.74 | 
2025-12-28T01:58:00 | step: 509700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.5983673519222066e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.56 | consumed tokens: 260966400.0 | grad norm avg: 10.09 | grad norm last: 9.66 | 
2025-12-28T01:58:02 | step: 509800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.596972187049687e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.27 | consumed tokens: 261017600.0 | grad norm avg: 10.01 | grad norm last: 9.35 | 
2025-12-28T01:58:04 | step: 509900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.595577022177167e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.56 | consumed tokens: 261068800.0 | grad norm avg: 10.02 | grad norm last: 8.62 | 
2025-12-28T01:58:06 | step: 510000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.594182221102528e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.53 | consumed tokens: 261120000.0 | grad norm avg: 10.06 | grad norm last: 8.44 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_510000-seen_tokens_261120000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_510000-seen_tokens_261120000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_510000-seen_tokens_261120000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_510000-seen_tokens_261120000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_510000-seen_tokens_261120000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_510000-seen_tokens_261120000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_510000-seen_tokens_261120000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_510000-seen_tokens_261120000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:58:08 | step: 510100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.592786692432128e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.69 | train loss last: 3.88 | consumed tokens: 261171200.0 | grad norm avg: 9.61 | grad norm last: 9.94 | 
2025-12-28T01:58:10 | step: 510200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.591391527559608e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.75 | consumed tokens: 261222400.0 | grad norm avg: 10.44 | grad norm last: 9.27 | 
2025-12-28T01:58:12 | step: 510300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.5899963626870885e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.8 | consumed tokens: 261273600.0 | grad norm avg: 10.03 | grad norm last: 8.94 | 
2025-12-28T01:58:14 | step: 510400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.588600834016688e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.92 | consumed tokens: 261324800.0 | grad norm avg: 9.88 | grad norm last: 9.71 | 
2025-12-28T01:58:16 | step: 510500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.587206032942049e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.88 | consumed tokens: 261376000.0 | grad norm avg: 9.6 | grad norm last: 11.97 | 
2025-12-28T01:58:18 | step: 510600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.585810504271649e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.73 | consumed tokens: 261427200.0 | grad norm avg: 10.2 | grad norm last: 10.13 | 
2025-12-28T01:58:20 | step: 510700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.5844149756012484e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.89 | train loss last: 3.61 | consumed tokens: 261478400.0 | grad norm avg: 10.38 | grad norm last: 9.4 | 
2025-12-28T01:58:22 | step: 510800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.583019810728729e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.83 | consumed tokens: 261529600.0 | grad norm avg: 9.71 | grad norm last: 9.22 | 
2025-12-28T01:58:24 | step: 510900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.581624645856209e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.92 | consumed tokens: 261580800.0 | grad norm avg: 10.03 | grad norm last: 9.7 | 
2025-12-28T01:58:26 | step: 511000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 5.580229117185809e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.02 | consumed tokens: 261632000.0 | grad norm avg: 9.73 | grad norm last: 8.18 | 
2025-12-28T01:58:28 | step: 511100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 5.578833588515408e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.75 | consumed tokens: 261683200.0 | grad norm avg: 10.18 | grad norm last: 17.08 | 
2025-12-28T01:58:30 | step: 511200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.5774387874407694e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.19 | consumed tokens: 261734400.0 | grad norm avg: 9.92 | grad norm last: 9.86 | 
2025-12-28T01:58:32 | step: 511300 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 5.576043258770369e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.53 | consumed tokens: 261785600.0 | grad norm avg: 10.42 | grad norm last: 10.16 | 
2025-12-28T01:58:34 | step: 511400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 5.574648093897849e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.73 | consumed tokens: 261836800.0 | grad norm avg: 9.89 | grad norm last: 11.02 | 
2025-12-28T01:58:37 | step: 511500 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 5.573252565227449e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.16 | consumed tokens: 261888000.0 | grad norm avg: 10.25 | grad norm last: 8.7 | 
2025-12-28T01:58:39 | step: 511600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.571857400354929e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.97 | consumed tokens: 261939200.0 | grad norm avg: 9.83 | grad norm last: 10.98 | 
2025-12-28T01:58:41 | step: 511700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.570461871684529e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.75 | consumed tokens: 261990400.0 | grad norm avg: 10.6 | grad norm last: 8.84 | 
2025-12-28T01:58:43 | step: 511800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.5690663430141285e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.12 | consumed tokens: 262041600.0 | grad norm avg: 10.51 | grad norm last: 11.08 | 
2025-12-28T01:58:45 | step: 511900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.5676715419394895e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.98 | consumed tokens: 262092800.0 | grad norm avg: 9.79 | grad norm last: 12.38 | 
2025-12-28T01:58:47 | step: 512000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 5.566276013269089e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.88 | consumed tokens: 262144000.0 | grad norm avg: 10.02 | grad norm last: 9.01 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_512000-seen_tokens_262144000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_512000-seen_tokens_262144000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_512000-seen_tokens_262144000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_512000-seen_tokens_262144000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_512000-seen_tokens_262144000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_512000-seen_tokens_262144000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_512000-seen_tokens_262144000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_512000-seen_tokens_262144000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:58:49 | step: 512100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 5.564880484598689e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.72 | train loss last: 3.84 | consumed tokens: 262195200.0 | grad norm avg: 10.24 | grad norm last: 11.59 | 
2025-12-28T01:58:51 | step: 512200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.5634849559282884e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.25 | consumed tokens: 262246400.0 | grad norm avg: 10.24 | grad norm last: 8.28 | 
2025-12-28T01:58:53 | step: 512300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.562089791055769e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.39 | consumed tokens: 262297600.0 | grad norm avg: 9.96 | grad norm last: 8.35 | 
2025-12-28T01:58:55 | step: 512400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.5606942623853683e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.33 | consumed tokens: 262348800.0 | grad norm avg: 10.17 | grad norm last: 9.84 | 
2025-12-28T01:58:57 | step: 512500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.559298733714968e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 5.53 | consumed tokens: 262400000.0 | grad norm avg: 10.37 | grad norm last: 14.85 | 
2025-12-28T01:58:59 | step: 512600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.557903568842448e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.33 | consumed tokens: 262451200.0 | grad norm avg: 9.92 | grad norm last: 8.49 | 
2025-12-28T01:59:01 | step: 512700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.556508040172048e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.75 | consumed tokens: 262502400.0 | grad norm avg: 10.22 | grad norm last: 11.47 | 
2025-12-28T01:59:03 | step: 512800 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 5.5551125115016475e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.47 | consumed tokens: 262553600.0 | grad norm avg: 9.91 | grad norm last: 12.43 | 
2025-12-28T01:59:05 | step: 512900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.553716982831247e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.75 | consumed tokens: 262604800.0 | grad norm avg: 10.24 | grad norm last: 9.31 | 
2025-12-28T01:59:07 | step: 513000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.552322181756608e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.23 | consumed tokens: 262656000.0 | grad norm avg: 10.17 | grad norm last: 8.47 | 
2025-12-28T01:59:09 | step: 513100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.5509259254904464e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.12 | consumed tokens: 262707200.0 | grad norm avg: 10.07 | grad norm last: 9.73 | 
2025-12-28T01:59:11 | step: 513200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.5495311244158074e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.69 | consumed tokens: 262758400.0 | grad norm avg: 10.03 | grad norm last: 10.07 | 
2025-12-28T01:59:13 | step: 513300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.548135595745407e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.25 | consumed tokens: 262809600.0 | grad norm avg: 10.92 | grad norm last: 11.69 | 
2025-12-28T01:59:15 | step: 513400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.546740067075007e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.59 | consumed tokens: 262860800.0 | grad norm avg: 10.13 | grad norm last: 11.89 | 
2025-12-28T01:59:17 | step: 513500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.545344538404606e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.59 | consumed tokens: 262912000.0 | grad norm avg: 10.61 | grad norm last: 9.67 | 
2025-12-28T01:59:19 | step: 513600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.543949009734206e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.3 | consumed tokens: 262963200.0 | grad norm avg: 10.28 | grad norm last: 8.72 | 
2025-12-28T01:59:22 | step: 513700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.542553844861686e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.19 | consumed tokens: 263014400.0 | grad norm avg: 10.5 | grad norm last: 11.6 | 
2025-12-28T01:59:24 | step: 513800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.541158316191286e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.34 | consumed tokens: 263065600.0 | grad norm avg: 10.35 | grad norm last: 12.22 | 
2025-12-28T01:59:26 | step: 513900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.5397627875208855e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.78 | consumed tokens: 263116800.0 | grad norm avg: 10.9 | grad norm last: 11.81 | 
2025-12-28T01:59:28 | step: 514000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.538367258850485e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 2.81 | consumed tokens: 263168000.0 | grad norm avg: 10.78 | grad norm last: 8.58 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_514000-seen_tokens_263168000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_514000-seen_tokens_263168000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_514000-seen_tokens_263168000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_514000-seen_tokens_263168000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_514000-seen_tokens_263168000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_514000-seen_tokens_263168000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_514000-seen_tokens_263168000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_514000-seen_tokens_263168000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T01:59:30 | step: 514100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.536971730180085e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.74 | train loss last: 4.12 | consumed tokens: 263219200.0 | grad norm avg: 10.19 | grad norm last: 18.29 | 
2025-12-28T01:59:32 | step: 514200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.535576201509684e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.06 | consumed tokens: 263270400.0 | grad norm avg: 10.54 | grad norm last: 8.29 | 
2025-12-28T01:59:34 | step: 514300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.534180672839284e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.75 | consumed tokens: 263321600.0 | grad norm avg: 10.45 | grad norm last: 13.66 | 
2025-12-28T01:59:36 | step: 514400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.532785507966764e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.48 | consumed tokens: 263372800.0 | grad norm avg: 10.83 | grad norm last: 8.64 | 
2025-12-28T01:59:38 | step: 514500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.531389979296364e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.47 | consumed tokens: 263424000.0 | grad norm avg: 10.19 | grad norm last: 12.41 | 
2025-12-28T01:59:40 | step: 514600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.5299944506259635e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.16 | consumed tokens: 263475200.0 | grad norm avg: 10.69 | grad norm last: 9.51 | 
2025-12-28T01:59:42 | step: 514700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.528598921955563e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.38 | consumed tokens: 263526400.0 | grad norm avg: 10.62 | grad norm last: 9.86 | 
2025-12-28T01:59:44 | step: 514800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 5.527203393285163e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.3 | consumed tokens: 263577600.0 | grad norm avg: 10.8 | grad norm last: 8.37 | 
2025-12-28T01:59:46 | step: 514900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.5258078646147624e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.94 | consumed tokens: 263628800.0 | grad norm avg: 10.58 | grad norm last: 10.64 | 
2025-12-28T01:59:48 | step: 515000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.524412335944362e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.53 | consumed tokens: 263680000.0 | grad norm avg: 10.37 | grad norm last: 10.64 | 
2025-12-28T01:59:50 | step: 515100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.5230168072739616e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.33 | consumed tokens: 263731200.0 | grad norm avg: 11.13 | grad norm last: 9.42 | 
2025-12-28T01:59:52 | step: 515200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.521621278603561e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.14 | consumed tokens: 263782400.0 | grad norm avg: 10.84 | grad norm last: 9.17 | 
2025-12-28T01:59:54 | step: 515300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.520225749933161e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.98 | consumed tokens: 263833600.0 | grad norm avg: 10.65 | grad norm last: 12.3 | 
2025-12-28T01:59:56 | step: 515400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.5188302212627605e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.91 | consumed tokens: 263884800.0 | grad norm avg: 10.29 | grad norm last: 14.78 | 
2025-12-28T01:59:58 | step: 515500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.51743469259236e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.39 | consumed tokens: 263936000.0 | grad norm avg: 10.83 | grad norm last: 8.99 | 
2025-12-28T02:00:00 | step: 515600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.51603916392196e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.77 | consumed tokens: 263987200.0 | grad norm avg: 10.69 | grad norm last: 9.3 | 
2025-12-28T02:00:02 | step: 515700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.514643635251559e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.58 | consumed tokens: 264038400.0 | grad norm avg: 10.97 | grad norm last: 9.51 | 
2025-12-28T02:00:04 | step: 515800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.513248106581159e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.09 | consumed tokens: 264089600.0 | grad norm avg: 10.66 | grad norm last: 11.23 | 
2025-12-28T02:00:06 | step: 515900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.5118525779107586e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.12 | consumed tokens: 264140800.0 | grad norm avg: 10.67 | grad norm last: 16.69 | 
2025-12-28T02:00:08 | step: 516000 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 5.510457049240358e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.47 | consumed tokens: 264192000.0 | grad norm avg: 10.3 | grad norm last: 16.26 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_516000-seen_tokens_264192000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_516000-seen_tokens_264192000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_516000-seen_tokens_264192000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_516000-seen_tokens_264192000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_516000-seen_tokens_264192000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_516000-seen_tokens_264192000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_516000-seen_tokens_264192000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_516000-seen_tokens_264192000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:00:11 | step: 516100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 5.509061520569958e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.77 | train loss last: 3.97 | consumed tokens: 264243200.0 | grad norm avg: 10.33 | grad norm last: 9.1 | 
2025-12-28T02:00:13 | step: 516200 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 5.5076659918995574e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.06 | consumed tokens: 264294400.0 | grad norm avg: 10.62 | grad norm last: 9.33 | 
2025-12-28T02:00:15 | step: 516300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.5062711908249184e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.09 | consumed tokens: 264345600.0 | grad norm avg: 10.73 | grad norm last: 16.24 | 
2025-12-28T02:00:17 | step: 516400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.5048749345587566e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.83 | consumed tokens: 264396800.0 | grad norm avg: 10.99 | grad norm last: 9.24 | 
2025-12-28T02:00:19 | step: 516500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.503480133484118e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.28 | consumed tokens: 264448000.0 | grad norm avg: 10.46 | grad norm last: 8.9 | 
2025-12-28T02:00:21 | step: 516600 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 5.502083877217956e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.72 | consumed tokens: 264499200.0 | grad norm avg: 10.84 | grad norm last: 9.52 | 
2025-12-28T02:00:23 | step: 516700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 5.500689076143317e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.12 | consumed tokens: 264550400.0 | grad norm avg: 11.27 | grad norm last: 10.32 | 
2025-12-28T02:00:25 | step: 516800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 5.499292819877155e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.8 | consumed tokens: 264601600.0 | grad norm avg: 10.64 | grad norm last: 8.55 | 
2025-12-28T02:00:27 | step: 516900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 5.497898018802516e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.86 | consumed tokens: 264652800.0 | grad norm avg: 10.11 | grad norm last: 9.45 | 
2025-12-28T02:00:29 | step: 517000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.4965017625363544e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.38 | consumed tokens: 264704000.0 | grad norm avg: 10.64 | grad norm last: 15.55 | 
2025-12-28T02:00:31 | step: 517100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.4951069614617154e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 6.22 | consumed tokens: 264755200.0 | grad norm avg: 10.83 | grad norm last: 13.96 | 
2025-12-28T02:00:33 | step: 517200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.4937107051955536e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.22 | consumed tokens: 264806400.0 | grad norm avg: 11.13 | grad norm last: 9.86 | 
2025-12-28T02:00:35 | step: 517300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 5.4923159041209146e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.08 | consumed tokens: 264857600.0 | grad norm avg: 11.21 | grad norm last: 10.1 | 
2025-12-28T02:00:37 | step: 517400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.490919647854753e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.83 | consumed tokens: 264908800.0 | grad norm avg: 11.12 | grad norm last: 10.42 | 
2025-12-28T02:00:39 | step: 517500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.489524846780114e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.27 | consumed tokens: 264960000.0 | grad norm avg: 12.31 | grad norm last: 8.75 | 
2025-12-28T02:00:41 | step: 517600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.488128590513952e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.61 | consumed tokens: 265011200.0 | grad norm avg: 10.97 | grad norm last: 9.64 | 
2025-12-28T02:00:43 | step: 517700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.486733789439313e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.59 | consumed tokens: 265062400.0 | grad norm avg: 11.24 | grad norm last: 8.32 | 
2025-12-28T02:00:45 | step: 517800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.485337533173151e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.03 | consumed tokens: 265113600.0 | grad norm avg: 10.82 | grad norm last: 8.94 | 
2025-12-28T02:00:47 | step: 517900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.4839427320985124e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 2.94 | consumed tokens: 265164800.0 | grad norm avg: 11.05 | grad norm last: 12.41 | 
2025-12-28T02:00:49 | step: 518000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.4825464758323506e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.67 | consumed tokens: 265216000.0 | grad norm avg: 10.27 | grad norm last: 9.16 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_518000-seen_tokens_265216000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_518000-seen_tokens_265216000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_518000-seen_tokens_265216000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_518000-seen_tokens_265216000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_518000-seen_tokens_265216000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_518000-seen_tokens_265216000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_518000-seen_tokens_265216000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_518000-seen_tokens_265216000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:00:52 | step: 518100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.4811516747577116e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.47 | consumed tokens: 265267200.0 | grad norm avg: 10.6 | grad norm last: 10.55 | 
2025-12-28T02:00:54 | step: 518200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.47975541849155e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.12 | consumed tokens: 265318400.0 | grad norm avg: 10.45 | grad norm last: 9.39 | 
2025-12-28T02:00:56 | step: 518300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.478360617416911e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.5 | consumed tokens: 265369600.0 | grad norm avg: 10.65 | grad norm last: 9.38 | 
2025-12-28T02:00:58 | step: 518400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.476964361150749e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.28 | consumed tokens: 265420800.0 | grad norm avg: 10.12 | grad norm last: 12.34 | 
2025-12-28T02:01:00 | step: 518500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.47556956007611e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.72 | consumed tokens: 265472000.0 | grad norm avg: 10.48 | grad norm last: 15.11 | 
2025-12-28T02:01:02 | step: 518600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.474173303809948e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.36 | consumed tokens: 265523200.0 | grad norm avg: 10.59 | grad norm last: 8.34 | 
2025-12-28T02:01:04 | step: 518700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.472778502735309e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.06 | consumed tokens: 265574400.0 | grad norm avg: 10.68 | grad norm last: 8.76 | 
2025-12-28T02:01:06 | step: 518800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.4713822464691475e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.09 | consumed tokens: 265625600.0 | grad norm avg: 10.63 | grad norm last: 8.67 | 
2025-12-28T02:01:08 | step: 518900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.4699874453945085e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.66 | consumed tokens: 265676800.0 | grad norm avg: 11.45 | grad norm last: 9.22 | 
2025-12-28T02:01:10 | step: 519000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.468591189128347e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.16 | consumed tokens: 265728000.0 | grad norm avg: 10.76 | grad norm last: 10.98 | 
2025-12-28T02:01:12 | step: 519100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.467196388053708e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.0 | consumed tokens: 265779200.0 | grad norm avg: 10.61 | grad norm last: 9.24 | 
2025-12-28T02:01:14 | step: 519200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.4658008593833074e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.72 | consumed tokens: 265830400.0 | grad norm avg: 10.3 | grad norm last: 10.53 | 
2025-12-28T02:01:16 | step: 519300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.464405330712907e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.25 | consumed tokens: 265881600.0 | grad norm avg: 11.62 | grad norm last: 8.84 | 
2025-12-28T02:01:18 | step: 519400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.4630098020425066e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.62 | consumed tokens: 265932800.0 | grad norm avg: 10.8 | grad norm last: 8.99 | 
2025-12-28T02:01:20 | step: 519500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.461614273372106e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.89 | consumed tokens: 265984000.0 | grad norm avg: 11.89 | grad norm last: 9.13 | 
2025-12-28T02:01:22 | step: 519600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.460218744701706e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.09 | consumed tokens: 266035200.0 | grad norm avg: 11.02 | grad norm last: 10.81 | 
2025-12-28T02:01:24 | step: 519700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.4588232160313055e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.88 | consumed tokens: 266086400.0 | grad norm avg: 11.06 | grad norm last: 9.71 | 
2025-12-28T02:01:26 | step: 519800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.457428051158786e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.62 | consumed tokens: 266137600.0 | grad norm avg: 11.22 | grad norm last: 10.48 | 
2025-12-28T02:01:28 | step: 519900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.4560325224883854e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.34 | consumed tokens: 266188800.0 | grad norm avg: 10.34 | grad norm last: 10.07 | 
2025-12-28T02:01:30 | step: 520000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.454636993817985e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.3 | consumed tokens: 266240000.0 | grad norm avg: 10.3 | grad norm last: 8.15 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_520000-seen_tokens_266240000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_520000-seen_tokens_266240000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_520000-seen_tokens_266240000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_520000-seen_tokens_266240000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_520000-seen_tokens_266240000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_520000-seen_tokens_266240000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_520000-seen_tokens_266240000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_520000-seen_tokens_266240000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:01:32 | step: 520100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.453241465147585e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.77 | train loss last: 3.78 | consumed tokens: 266291200.0 | grad norm avg: 11.06 | grad norm last: 10.8 | 
2025-12-28T02:01:34 | step: 520200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.451845936477184e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 2.86 | consumed tokens: 266342400.0 | grad norm avg: 10.58 | grad norm last: 8.59 | 
2025-12-28T02:01:36 | step: 520300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.4504507716046646e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.81 | consumed tokens: 266393600.0 | grad norm avg: 10.3 | grad norm last: 11.35 | 
2025-12-28T02:01:38 | step: 520400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.449055242934264e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.81 | consumed tokens: 266444800.0 | grad norm avg: 10.62 | grad norm last: 11.16 | 
2025-12-28T02:01:40 | step: 520500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.447659714263864e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.3 | consumed tokens: 266496000.0 | grad norm avg: 11.08 | grad norm last: 8.48 | 
2025-12-28T02:01:42 | step: 520600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.4462641855934635e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.28 | consumed tokens: 266547200.0 | grad norm avg: 10.3 | grad norm last: 11.3 | 
2025-12-28T02:01:44 | step: 520700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.444868656923063e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.69 | consumed tokens: 266598400.0 | grad norm avg: 10.76 | grad norm last: 16.8 | 
2025-12-28T02:01:46 | step: 520800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.443473855848424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.16 | consumed tokens: 266649600.0 | grad norm avg: 10.73 | grad norm last: 11.88 | 
2025-12-28T02:01:48 | step: 520900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.442077599582262e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.06 | consumed tokens: 266700800.0 | grad norm avg: 10.78 | grad norm last: 10.31 | 
2025-12-28T02:01:50 | step: 521000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.4406827985076234e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.84 | consumed tokens: 266752000.0 | grad norm avg: 10.88 | grad norm last: 11.09 | 
2025-12-28T02:01:52 | step: 521100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.439287269837223e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.38 | consumed tokens: 266803200.0 | grad norm avg: 11.07 | grad norm last: 14.2 | 
2025-12-28T02:01:55 | step: 521200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.4378917411668226e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.0 | consumed tokens: 266854400.0 | grad norm avg: 10.42 | grad norm last: 9.61 | 
2025-12-28T02:01:57 | step: 521300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 5.436496576294303e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.83 | consumed tokens: 266905600.0 | grad norm avg: 10.4 | grad norm last: 13.39 | 
2025-12-28T02:01:59 | step: 521400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.4351010476239026e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.19 | consumed tokens: 266956800.0 | grad norm avg: 10.37 | grad norm last: 12.39 | 
2025-12-28T02:02:01 | step: 521500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.433705882751383e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.03 | consumed tokens: 267008000.0 | grad norm avg: 10.73 | grad norm last: 12.05 | 
2025-12-28T02:02:03 | step: 521600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.4323103540809825e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.09 | consumed tokens: 267059200.0 | grad norm avg: 10.07 | grad norm last: 9.83 | 
2025-12-28T02:02:05 | step: 521700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 5.430914825410582e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.28 | consumed tokens: 267110400.0 | grad norm avg: 10.48 | grad norm last: 11.91 | 
2025-12-28T02:02:07 | step: 521800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.429519296740182e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.84 | consumed tokens: 267161600.0 | grad norm avg: 11.16 | grad norm last: 9.09 | 
2025-12-28T02:02:09 | step: 521900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 5.428124495665543e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.53 | consumed tokens: 267212800.0 | grad norm avg: 10.32 | grad norm last: 10.24 | 
2025-12-28T02:02:11 | step: 522000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 5.4267289669951424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.55 | consumed tokens: 267264000.0 | grad norm avg: 11.13 | grad norm last: 9.88 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_522000-seen_tokens_267264000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_522000-seen_tokens_267264000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_522000-seen_tokens_267264000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_522000-seen_tokens_267264000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_522000-seen_tokens_267264000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_522000-seen_tokens_267264000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_522000-seen_tokens_267264000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_522000-seen_tokens_267264000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:02:13 | step: 522100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.425333438324742e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.95 | consumed tokens: 267315200.0 | grad norm avg: 10.1 | grad norm last: 10.83 | 
2025-12-28T02:02:15 | step: 522200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.4239382734522223e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.38 | consumed tokens: 267366400.0 | grad norm avg: 10.49 | grad norm last: 9.64 | 
2025-12-28T02:02:17 | step: 522300 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 5.422543108579703e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.31 | consumed tokens: 267417600.0 | grad norm avg: 10.62 | grad norm last: 10.46 | 
2025-12-28T02:02:19 | step: 522400 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 5.421147579909302e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.38 | consumed tokens: 267468800.0 | grad norm avg: 10.19 | grad norm last: 10.67 | 
2025-12-28T02:02:21 | step: 522500 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 5.419752051238902e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.41 | consumed tokens: 267520000.0 | grad norm avg: 10.53 | grad norm last: 9.28 | 
2025-12-28T02:02:23 | step: 522600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 5.418357250164263e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.53 | consumed tokens: 267571200.0 | grad norm avg: 10.9 | grad norm last: 8.67 | 
2025-12-28T02:02:25 | step: 522700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.4169617214938626e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.77 | consumed tokens: 267622400.0 | grad norm avg: 10.84 | grad norm last: 9.61 | 
2025-12-28T02:02:27 | step: 522800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.415566556621343e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.75 | consumed tokens: 267673600.0 | grad norm avg: 11.35 | grad norm last: 13.07 | 
2025-12-28T02:02:29 | step: 522900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.4141710279509425e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.64 | consumed tokens: 267724800.0 | grad norm avg: 10.86 | grad norm last: 9.27 | 
2025-12-28T02:02:31 | step: 523000 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 5.412775863078423e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.8 | consumed tokens: 267776000.0 | grad norm avg: 10.75 | grad norm last: 10.54 | 
2025-12-28T02:02:33 | step: 523100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 5.411381062003784e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.67 | consumed tokens: 267827200.0 | grad norm avg: 10.38 | grad norm last: 8.69 | 
2025-12-28T02:02:35 | step: 523200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.4099855333333835e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.72 | consumed tokens: 267878400.0 | grad norm avg: 11.1 | grad norm last: 10.87 | 
2025-12-28T02:02:37 | step: 523300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.408590004662983e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.41 | consumed tokens: 267929600.0 | grad norm avg: 10.86 | grad norm last: 10.78 | 
2025-12-28T02:02:40 | step: 523400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.4071948397904634e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.67 | consumed tokens: 267980800.0 | grad norm avg: 10.12 | grad norm last: 10.17 | 
2025-12-28T02:02:42 | step: 523500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.405799674917944e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.53 | consumed tokens: 268032000.0 | grad norm avg: 11.09 | grad norm last: 12.02 | 
2025-12-28T02:02:44 | step: 523600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.404404873843305e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.06 | consumed tokens: 268083200.0 | grad norm avg: 11.25 | grad norm last: 29.2 | 
2025-12-28T02:02:46 | step: 523700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.4030093451729044e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.88 | consumed tokens: 268134400.0 | grad norm avg: 10.49 | grad norm last: 10.56 | 
2025-12-28T02:02:48 | step: 523800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.401614180300385e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.61 | consumed tokens: 268185600.0 | grad norm avg: 10.54 | grad norm last: 9.52 | 
2025-12-28T02:02:50 | step: 523900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.400219015427865e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.52 | consumed tokens: 268236800.0 | grad norm avg: 10.77 | grad norm last: 9.06 | 
2025-12-28T02:02:52 | step: 524000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.398823486757465e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.44 | consumed tokens: 268288000.0 | grad norm avg: 10.17 | grad norm last: 9.98 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_524000-seen_tokens_268288000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_524000-seen_tokens_268288000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_524000-seen_tokens_268288000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_524000-seen_tokens_268288000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_524000-seen_tokens_268288000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_524000-seen_tokens_268288000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_524000-seen_tokens_268288000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_524000-seen_tokens_268288000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:02:54 | step: 524100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.397428685682826e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.75 | train loss last: 4.09 | consumed tokens: 268339200.0 | grad norm avg: 11.0 | grad norm last: 12.61 | 
2025-12-28T02:02:56 | step: 524200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.396033520810306e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.5 | consumed tokens: 268390400.0 | grad norm avg: 10.47 | grad norm last: 9.16 | 
2025-12-28T02:02:58 | step: 524300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.3946383559377864e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.22 | consumed tokens: 268441600.0 | grad norm avg: 10.37 | grad norm last: 15.32 | 
2025-12-28T02:03:00 | step: 524400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.3932435548631474e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.52 | consumed tokens: 268492800.0 | grad norm avg: 10.62 | grad norm last: 10.38 | 
2025-12-28T02:03:02 | step: 524500 | train samples/s: 90.5 | train mfu (16-bit): -1.0 | lr mean: 5.391848026192747e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.67 | consumed tokens: 268544000.0 | grad norm avg: 10.4 | grad norm last: 9.82 | 
2025-12-28T02:03:04 | step: 524600 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 5.3904528613202274e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.92 | consumed tokens: 268595200.0 | grad norm avg: 10.67 | grad norm last: 12.21 | 
2025-12-28T02:03:06 | step: 524700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 5.389057696447708e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.89 | consumed tokens: 268646400.0 | grad norm avg: 10.72 | grad norm last: 9.96 | 
2025-12-28T02:03:08 | step: 524800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.387662167777307e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.92 | consumed tokens: 268697600.0 | grad norm avg: 10.65 | grad norm last: 11.19 | 
2025-12-28T02:03:11 | step: 524900 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 5.386267730500549e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.0 | consumed tokens: 268748800.0 | grad norm avg: 10.38 | grad norm last: 11.01 | 
2025-12-28T02:03:13 | step: 525000 | train samples/s: 103.2 | train mfu (16-bit): -1.0 | lr mean: 5.3848725656280294e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.05 | consumed tokens: 268800000.0 | grad norm avg: 10.44 | grad norm last: 9.05 | 
2025-12-28T02:03:15 | step: 525100 | train samples/s: 103.2 | train mfu (16-bit): -1.0 | lr mean: 5.383477036957629e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.44 | consumed tokens: 268851200.0 | grad norm avg: 10.42 | grad norm last: 13.93 | 
2025-12-28T02:03:17 | step: 525200 | train samples/s: 103.0 | train mfu (16-bit): -1.0 | lr mean: 5.38208223588299e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.14 | consumed tokens: 268902400.0 | grad norm avg: 10.2 | grad norm last: 8.41 | 
2025-12-28T02:03:19 | step: 525300 | train samples/s: 103.7 | train mfu (16-bit): -1.0 | lr mean: 5.380687434808351e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.0 | consumed tokens: 268953600.0 | grad norm avg: 10.57 | grad norm last: 11.67 | 
2025-12-28T02:03:21 | step: 525400 | train samples/s: 103.5 | train mfu (16-bit): -1.0 | lr mean: 5.379291906137951e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.56 | consumed tokens: 269004800.0 | grad norm avg: 10.67 | grad norm last: 12.54 | 
2025-12-28T02:03:23 | step: 525500 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 5.3778974688611925e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.38 | consumed tokens: 269056000.0 | grad norm avg: 10.42 | grad norm last: 12.71 | 
2025-12-28T02:03:25 | step: 525600 | train samples/s: 103.5 | train mfu (16-bit): -1.0 | lr mean: 5.376502303988673e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.88 | consumed tokens: 269107200.0 | grad norm avg: 10.95 | grad norm last: 9.62 | 
2025-12-28T02:03:27 | step: 525700 | train samples/s: 103.5 | train mfu (16-bit): -1.0 | lr mean: 5.3751067753182724e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.56 | consumed tokens: 269158400.0 | grad norm avg: 10.74 | grad norm last: 9.22 | 
2025-12-28T02:03:29 | step: 525800 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 5.373712338041514e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.0 | consumed tokens: 269209600.0 | grad norm avg: 11.26 | grad norm last: 9.86 | 
2025-12-28T02:03:31 | step: 525900 | train samples/s: 102.9 | train mfu (16-bit): -1.0 | lr mean: 5.3723171731689945e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.89 | consumed tokens: 269260800.0 | grad norm avg: 10.57 | grad norm last: 8.62 | 
2025-12-28T02:03:33 | step: 526000 | train samples/s: 103.4 | train mfu (16-bit): -1.0 | lr mean: 5.3709223720943555e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.22 | consumed tokens: 269312000.0 | grad norm avg: 10.17 | grad norm last: 9.53 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_526000-seen_tokens_269312000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_526000-seen_tokens_269312000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_526000-seen_tokens_269312000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_526000-seen_tokens_269312000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_526000-seen_tokens_269312000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_526000-seen_tokens_269312000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_526000-seen_tokens_269312000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_526000-seen_tokens_269312000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:03:36 | step: 526100 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 5.3695275710197166e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.95 | consumed tokens: 269363200.0 | grad norm avg: 11.01 | grad norm last: 10.57 | 
2025-12-28T02:03:38 | step: 526200 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 5.3681327699450776e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.81 | consumed tokens: 269414400.0 | grad norm avg: 10.19 | grad norm last: 9.74 | 
2025-12-28T02:03:40 | step: 526300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 5.366737605072558e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.33 | consumed tokens: 269465600.0 | grad norm avg: 10.72 | grad norm last: 10.18 | 
2025-12-28T02:03:42 | step: 526400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.365342440200038e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.53 | consumed tokens: 269516800.0 | grad norm avg: 11.06 | grad norm last: 11.02 | 
2025-12-28T02:03:44 | step: 526500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.363947639125399e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.41 | consumed tokens: 269568000.0 | grad norm avg: 10.24 | grad norm last: 12.57 | 
2025-12-28T02:03:46 | step: 526600 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 5.36255283805076e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.16 | consumed tokens: 269619200.0 | grad norm avg: 11.03 | grad norm last: 10.71 | 
2025-12-28T02:03:48 | step: 526700 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 5.3611580369761214e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.84 | consumed tokens: 269670400.0 | grad norm avg: 10.58 | grad norm last: 9.59 | 
2025-12-28T02:03:50 | step: 526800 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 5.3597632359014824e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.03 | consumed tokens: 269721600.0 | grad norm avg: 10.45 | grad norm last: 8.28 | 
2025-12-28T02:03:52 | step: 526900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 5.3583684348268434e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.33 | consumed tokens: 269772800.0 | grad norm avg: 10.06 | grad norm last: 8.93 | 
2025-12-28T02:03:54 | step: 527000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.3569736337522045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.81 | consumed tokens: 269824000.0 | grad norm avg: 10.92 | grad norm last: 10.16 | 
2025-12-28T02:03:56 | step: 527100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 5.3555788326775655e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.42 | consumed tokens: 269875200.0 | grad norm avg: 10.49 | grad norm last: 9.31 | 
2025-12-28T02:03:58 | step: 527200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.3541840316029266e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.77 | consumed tokens: 269926400.0 | grad norm avg: 10.2 | grad norm last: 11.99 | 
2025-12-28T02:04:00 | step: 527300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.3527892305282876e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.0 | consumed tokens: 269977600.0 | grad norm avg: 11.07 | grad norm last: 9.56 | 
2025-12-28T02:04:02 | step: 527400 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 5.3513944294536486e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.78 | consumed tokens: 270028800.0 | grad norm avg: 10.32 | grad norm last: 12.95 | 
2025-12-28T02:04:04 | step: 527500 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 5.34999962837901e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.72 | consumed tokens: 270080000.0 | grad norm avg: 10.54 | grad norm last: 16.3 | 
2025-12-28T02:04:07 | step: 527600 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 5.348604827304371e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.75 | consumed tokens: 270131200.0 | grad norm avg: 10.9 | grad norm last: 8.95 | 
2025-12-28T02:04:09 | step: 527700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 5.347210026229732e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.22 | consumed tokens: 270182400.0 | grad norm avg: 10.56 | grad norm last: 9.16 | 
2025-12-28T02:04:11 | step: 527800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.345815225155093e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 2.98 | consumed tokens: 270233600.0 | grad norm avg: 10.45 | grad norm last: 9.14 | 
2025-12-28T02:04:13 | step: 527900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.3444207878783345e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.28 | consumed tokens: 270284800.0 | grad norm avg: 10.15 | grad norm last: 10.82 | 
2025-12-28T02:04:15 | step: 528000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 5.343025623005815e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.89 | consumed tokens: 270336000.0 | grad norm avg: 10.98 | grad norm last: 11.62 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_528000-seen_tokens_270336000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_528000-seen_tokens_270336000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_528000-seen_tokens_270336000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_528000-seen_tokens_270336000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_528000-seen_tokens_270336000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_528000-seen_tokens_270336000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_528000-seen_tokens_270336000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_528000-seen_tokens_270336000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:04:17 | step: 528100 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 5.3416311857290566e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.56 | consumed tokens: 270387200.0 | grad norm avg: 10.12 | grad norm last: 11.64 | 
2025-12-28T02:04:19 | step: 528200 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 5.3402367484522983e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.83 | consumed tokens: 270438400.0 | grad norm avg: 10.63 | grad norm last: 10.6 | 
2025-12-28T02:04:21 | step: 528300 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 5.3388419473776594e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.78 | consumed tokens: 270489600.0 | grad norm avg: 10.18 | grad norm last: 8.98 | 
2025-12-28T02:04:23 | step: 528400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 5.337447510100901e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.19 | consumed tokens: 270540800.0 | grad norm avg: 10.57 | grad norm last: 8.04 | 
2025-12-28T02:04:25 | step: 528500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 5.3360523452283815e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.11 | consumed tokens: 270592000.0 | grad norm avg: 10.64 | grad norm last: 7.7 | 
2025-12-28T02:04:27 | step: 528600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.334658271749504e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.59 | consumed tokens: 270643200.0 | grad norm avg: 10.59 | grad norm last: 9.63 | 
2025-12-28T02:04:29 | step: 528700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.3332638344727457e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.25 | consumed tokens: 270694400.0 | grad norm avg: 10.34 | grad norm last: 10.14 | 
2025-12-28T02:04:31 | step: 528800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 5.3318693971959874e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.25 | consumed tokens: 270745600.0 | grad norm avg: 10.79 | grad norm last: 9.1 | 
2025-12-28T02:04:33 | step: 528900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 5.3304745961213484e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.25 | consumed tokens: 270796800.0 | grad norm avg: 10.75 | grad norm last: 11.6 | 
2025-12-28T02:04:35 | step: 529000 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 5.32908015884459e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.77 | consumed tokens: 270848000.0 | grad norm avg: 10.54 | grad norm last: 12.33 | 
2025-12-28T02:04:38 | step: 529100 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 5.3276849939720705e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.25 | consumed tokens: 270899200.0 | grad norm avg: 10.45 | grad norm last: 14.87 | 
2025-12-28T02:04:40 | step: 529200 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 5.326290920493193e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.41 | consumed tokens: 270950400.0 | grad norm avg: 10.56 | grad norm last: 8.73 | 
2025-12-28T02:04:42 | step: 529300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 5.324896483216435e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 2.81 | consumed tokens: 271001600.0 | grad norm avg: 10.69 | grad norm last: 9.92 | 
2025-12-28T02:04:44 | step: 529400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.3235020459396765e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.16 | consumed tokens: 271052800.0 | grad norm avg: 10.43 | grad norm last: 9.34 | 
2025-12-28T02:04:46 | step: 529500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.322107972460799e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.19 | consumed tokens: 271104000.0 | grad norm avg: 10.4 | grad norm last: 13.13 | 
2025-12-28T02:04:48 | step: 529600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.32071317138616e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 2.94 | consumed tokens: 271155200.0 | grad norm avg: 10.46 | grad norm last: 8.4 | 
2025-12-28T02:04:50 | step: 529700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.319318734109402e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.28 | consumed tokens: 271206400.0 | grad norm avg: 10.65 | grad norm last: 9.1 | 
2025-12-28T02:04:52 | step: 529800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.3179242968326434e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.75 | consumed tokens: 271257600.0 | grad norm avg: 11.05 | grad norm last: 8.57 | 
2025-12-28T02:04:54 | step: 529900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.316530223353766e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.9 | train loss last: 3.61 | consumed tokens: 271308800.0 | grad norm avg: 11.18 | grad norm last: 8.39 | 
2025-12-28T02:04:56 | step: 530000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.315135422279127e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 2.8 | consumed tokens: 271360000.0 | grad norm avg: 10.51 | grad norm last: 8.17 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_530000-seen_tokens_271360000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_530000-seen_tokens_271360000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_530000-seen_tokens_271360000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_530000-seen_tokens_271360000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_530000-seen_tokens_271360000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_530000-seen_tokens_271360000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_530000-seen_tokens_271360000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_530000-seen_tokens_271360000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:04:58 | step: 530100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 5.3137413488002494e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.69 | train loss last: 3.72 | consumed tokens: 271411200.0 | grad norm avg: 10.39 | grad norm last: 10.15 | 
2025-12-28T02:05:00 | step: 530200 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 5.312346911523491e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.34 | consumed tokens: 271462400.0 | grad norm avg: 10.29 | grad norm last: 11.55 | 
2025-12-28T02:05:02 | step: 530300 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 5.3109528380446136e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.67 | consumed tokens: 271513600.0 | grad norm avg: 10.95 | grad norm last: 9.7 | 
2025-12-28T02:05:04 | step: 530400 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 5.3095584007678553e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.78 | consumed tokens: 271564800.0 | grad norm avg: 10.45 | grad norm last: 13.38 | 
2025-12-28T02:05:06 | step: 530500 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 5.308164327288978e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.88 | consumed tokens: 271616000.0 | grad norm avg: 10.51 | grad norm last: 16.45 | 
2025-12-28T02:05:08 | step: 530600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.3067702538101e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.23 | consumed tokens: 271667200.0 | grad norm avg: 10.54 | grad norm last: 11.7 | 
2025-12-28T02:05:10 | step: 530700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 5.305376180331223e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.34 | consumed tokens: 271718400.0 | grad norm avg: 10.65 | grad norm last: 10.71 | 
2025-12-28T02:05:12 | step: 530800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.303981379256584e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.06 | consumed tokens: 271769600.0 | grad norm avg: 10.72 | grad norm last: 10.31 | 
2025-12-28T02:05:15 | step: 530900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.302587305777706e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.25 | consumed tokens: 271820800.0 | grad norm avg: 11.12 | grad norm last: 9.44 | 
2025-12-28T02:05:17 | step: 531000 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 5.301193232298829e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 5.19 | consumed tokens: 271872000.0 | grad norm avg: 10.74 | grad norm last: 25.45 | 
2025-12-28T02:05:19 | step: 531100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.2997987950220704e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.22 | consumed tokens: 271923200.0 | grad norm avg: 11.15 | grad norm last: 7.95 | 
2025-12-28T02:05:21 | step: 531200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.298404721543193e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.88 | consumed tokens: 271974400.0 | grad norm avg: 10.73 | grad norm last: 9.85 | 
2025-12-28T02:05:23 | step: 531300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.297010648064315e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.47 | consumed tokens: 272025600.0 | grad norm avg: 10.77 | grad norm last: 9.31 | 
2025-12-28T02:05:25 | step: 531400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.295616574585438e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.12 | consumed tokens: 272076800.0 | grad norm avg: 10.28 | grad norm last: 11.95 | 
2025-12-28T02:05:27 | step: 531500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.29422250110656e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.83 | consumed tokens: 272128000.0 | grad norm avg: 10.51 | grad norm last: 10.07 | 
2025-12-28T02:05:29 | step: 531600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.292828427627683e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.92 | consumed tokens: 272179200.0 | grad norm avg: 10.69 | grad norm last: 10.87 | 
2025-12-28T02:05:31 | step: 531700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 5.291434354148805e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.53 | consumed tokens: 272230400.0 | grad norm avg: 10.75 | grad norm last: 9.5 | 
2025-12-28T02:05:33 | step: 531800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.2900402806699276e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.45 | consumed tokens: 272281600.0 | grad norm avg: 11.29 | grad norm last: 8.64 | 
2025-12-28T02:05:35 | step: 531900 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 5.288646570988931e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.31 | consumed tokens: 272332800.0 | grad norm avg: 10.32 | grad norm last: 11.34 | 
2025-12-28T02:05:37 | step: 532000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 5.287252497510053e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.27 | consumed tokens: 272384000.0 | grad norm avg: 10.3 | grad norm last: 9.02 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_532000-seen_tokens_272384000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_532000-seen_tokens_272384000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_532000-seen_tokens_272384000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_532000-seen_tokens_272384000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_532000-seen_tokens_272384000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_532000-seen_tokens_272384000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_532000-seen_tokens_272384000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_532000-seen_tokens_272384000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:05:39 | step: 532100 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 5.285858424031176e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.75 | train loss last: 3.81 | consumed tokens: 272435200.0 | grad norm avg: 10.46 | grad norm last: 9.28 | 
2025-12-28T02:05:41 | step: 532200 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 5.2844650781480595e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.88 | consumed tokens: 272486400.0 | grad norm avg: 11.22 | grad norm last: 10.07 | 
2025-12-28T02:05:44 | step: 532300 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 5.283071004669182e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.47 | consumed tokens: 272537600.0 | grad norm avg: 10.75 | grad norm last: 10.51 | 
2025-12-28T02:05:46 | step: 532400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.2816769311903045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 3.58 | consumed tokens: 272588800.0 | grad norm avg: 11.79 | grad norm last: 9.97 | 
2025-12-28T02:05:48 | step: 532500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.280282857711427e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.81 | consumed tokens: 272640000.0 | grad norm avg: 10.74 | grad norm last: 10.56 | 
2025-12-28T02:05:50 | step: 532600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.27888914803043e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.92 | consumed tokens: 272691200.0 | grad norm avg: 11.06 | grad norm last: 9.17 | 
2025-12-28T02:05:52 | step: 532700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.2774950745515525e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.78 | consumed tokens: 272742400.0 | grad norm avg: 10.88 | grad norm last: 8.67 | 
2025-12-28T02:05:54 | step: 532800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.276101364870556e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.45 | consumed tokens: 272793600.0 | grad norm avg: 10.68 | grad norm last: 11.33 | 
2025-12-28T02:05:56 | step: 532900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.274707291391678e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.12 | consumed tokens: 272844800.0 | grad norm avg: 10.85 | grad norm last: 10.5 | 
2025-12-28T02:05:58 | step: 533000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.273313945508562e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.0 | consumed tokens: 272896000.0 | grad norm avg: 10.58 | grad norm last: 9.49 | 
2025-12-28T02:06:00 | step: 533100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.271920235827565e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.8 | consumed tokens: 272947200.0 | grad norm avg: 10.48 | grad norm last: 10.23 | 
2025-12-28T02:06:02 | step: 533200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.2705265261465684e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.81 | consumed tokens: 272998400.0 | grad norm avg: 10.54 | grad norm last: 13.05 | 
2025-12-28T02:06:04 | step: 533300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.269133180263452e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.25 | consumed tokens: 273049600.0 | grad norm avg: 10.67 | grad norm last: 9.68 | 
2025-12-28T02:06:06 | step: 533400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.267739106784575e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.3 | consumed tokens: 273100800.0 | grad norm avg: 11.0 | grad norm last: 9.48 | 
2025-12-28T02:06:08 | step: 533500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.266345397103578e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.86 | consumed tokens: 273152000.0 | grad norm avg: 10.75 | grad norm last: 9.77 | 
2025-12-28T02:06:10 | step: 533600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.264951687422581e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.06 | consumed tokens: 273203200.0 | grad norm avg: 10.9 | grad norm last: 11.6 | 
2025-12-28T02:06:12 | step: 533700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.2635576139437035e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.41 | consumed tokens: 273254400.0 | grad norm avg: 11.23 | grad norm last: 14.21 | 
2025-12-28T02:06:14 | step: 533800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.262164631858468e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.12 | consumed tokens: 273305600.0 | grad norm avg: 10.67 | grad norm last: 10.0 | 
2025-12-28T02:06:16 | step: 533900 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 5.260770922177471e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.92 | consumed tokens: 273356800.0 | grad norm avg: 10.99 | grad norm last: 9.79 | 
2025-12-28T02:06:18 | step: 534000 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 5.259377576294355e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.45 | consumed tokens: 273408000.0 | grad norm avg: 10.7 | grad norm last: 10.98 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_534000-seen_tokens_273408000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_534000-seen_tokens_273408000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_534000-seen_tokens_273408000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_534000-seen_tokens_273408000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_534000-seen_tokens_273408000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_534000-seen_tokens_273408000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_534000-seen_tokens_273408000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_534000-seen_tokens_273408000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:06:20 | step: 534100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 5.257983866613358e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.71 | train loss last: 4.03 | consumed tokens: 273459200.0 | grad norm avg: 10.41 | grad norm last: 10.94 | 
2025-12-28T02:06:22 | step: 534200 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 5.2565901569323614e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.41 | consumed tokens: 273510400.0 | grad norm avg: 10.41 | grad norm last: 8.9 | 
2025-12-28T02:06:24 | step: 534300 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 5.255196811049245e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.27 | consumed tokens: 273561600.0 | grad norm avg: 10.69 | grad norm last: 10.13 | 
2025-12-28T02:06:27 | step: 534400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 5.253803465166129e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.36 | consumed tokens: 273612800.0 | grad norm avg: 10.85 | grad norm last: 9.62 | 
2025-12-28T02:06:29 | step: 534500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.252410119283013e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.53 | consumed tokens: 273664000.0 | grad norm avg: 10.83 | grad norm last: 11.69 | 
2025-12-28T02:06:31 | step: 534600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.251016773399897e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.61 | consumed tokens: 273715200.0 | grad norm avg: 10.39 | grad norm last: 12.76 | 
2025-12-28T02:06:33 | step: 534700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.249623427516781e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.55 | consumed tokens: 273766400.0 | grad norm avg: 10.13 | grad norm last: 12.51 | 
2025-12-28T02:06:35 | step: 534800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.248230081633665e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.75 | consumed tokens: 273817600.0 | grad norm avg: 10.64 | grad norm last: 19.29 | 
2025-12-28T02:06:37 | step: 534900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.2468367357505485e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.28 | consumed tokens: 273868800.0 | grad norm avg: 10.64 | grad norm last: 9.33 | 
2025-12-28T02:06:39 | step: 535000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.2454433898674324e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.19 | consumed tokens: 273920000.0 | grad norm avg: 10.36 | grad norm last: 9.87 | 
2025-12-28T02:06:41 | step: 535100 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 5.244050043984316e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.31 | consumed tokens: 273971200.0 | grad norm avg: 10.68 | grad norm last: 9.77 | 
2025-12-28T02:06:43 | step: 535200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.2426566981012e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.28 | consumed tokens: 274022400.0 | grad norm avg: 10.81 | grad norm last: 9.86 | 
2025-12-28T02:06:45 | step: 535300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.241263716015965e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.02 | consumed tokens: 274073600.0 | grad norm avg: 10.15 | grad norm last: 11.26 | 
2025-12-28T02:06:47 | step: 535400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.239870006334968e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.75 | consumed tokens: 274124800.0 | grad norm avg: 10.42 | grad norm last: 10.08 | 
2025-12-28T02:06:49 | step: 535500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.2384770242497325e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.19 | consumed tokens: 274176000.0 | grad norm avg: 10.08 | grad norm last: 10.11 | 
2025-12-28T02:06:51 | step: 535600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.237084042164497e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.62 | consumed tokens: 274227200.0 | grad norm avg: 10.65 | grad norm last: 9.33 | 
2025-12-28T02:06:53 | step: 535700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.235690696281381e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.39 | consumed tokens: 274278400.0 | grad norm avg: 10.87 | grad norm last: 9.83 | 
2025-12-28T02:06:55 | step: 535800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.2342977141961455e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.3 | consumed tokens: 274329600.0 | grad norm avg: 10.65 | grad norm last: 9.4 | 
2025-12-28T02:06:57 | step: 535900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.23290473211091e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.45 | consumed tokens: 274380800.0 | grad norm avg: 11.13 | grad norm last: 9.19 | 
2025-12-28T02:06:59 | step: 536000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.231511386227794e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.0 | consumed tokens: 274432000.0 | grad norm avg: 11.36 | grad norm last: 9.73 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_536000-seen_tokens_274432000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_536000-seen_tokens_274432000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_536000-seen_tokens_274432000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_536000-seen_tokens_274432000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_536000-seen_tokens_274432000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_536000-seen_tokens_274432000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_536000-seen_tokens_274432000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_536000-seen_tokens_274432000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:07:01 | step: 536100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.230118767940439e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.23 | consumed tokens: 274483200.0 | grad norm avg: 11.1 | grad norm last: 9.37 | 
2025-12-28T02:07:03 | step: 536200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.228725785855204e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.56 | consumed tokens: 274534400.0 | grad norm avg: 10.41 | grad norm last: 8.77 | 
2025-12-28T02:07:05 | step: 536300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.2273328037699685e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.83 | consumed tokens: 274585600.0 | grad norm avg: 10.43 | grad norm last: 9.76 | 
2025-12-28T02:07:07 | step: 536400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 5.225940185482614e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.73 | consumed tokens: 274636800.0 | grad norm avg: 11.27 | grad norm last: 9.29 | 
2025-12-28T02:07:09 | step: 536500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.2245468395994976e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.8 | consumed tokens: 274688000.0 | grad norm avg: 10.94 | grad norm last: 8.95 | 
2025-12-28T02:07:11 | step: 536600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.223153857514262e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.64 | consumed tokens: 274739200.0 | grad norm avg: 10.74 | grad norm last: 9.58 | 
2025-12-28T02:07:14 | step: 536700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.221760875429027e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.42 | consumed tokens: 274790400.0 | grad norm avg: 10.87 | grad norm last: 9.23 | 
2025-12-28T02:07:16 | step: 536800 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 5.220368257141672e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.28 | consumed tokens: 274841600.0 | grad norm avg: 10.16 | grad norm last: 8.87 | 
2025-12-28T02:07:18 | step: 536900 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 5.2189756388543174e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.06 | consumed tokens: 274892800.0 | grad norm avg: 10.37 | grad norm last: 9.57 | 
2025-12-28T02:07:20 | step: 537000 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 5.217582292971201e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.19 | consumed tokens: 274944000.0 | grad norm avg: 11.02 | grad norm last: 15.94 | 
2025-12-28T02:07:22 | step: 537100 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 5.2161896746838465e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.67 | consumed tokens: 274995200.0 | grad norm avg: 11.27 | grad norm last: 9.52 | 
2025-12-28T02:07:24 | step: 537200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 5.214797056396492e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.17 | consumed tokens: 275046400.0 | grad norm avg: 10.38 | grad norm last: 11.15 | 
2025-12-28T02:07:26 | step: 537300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.213404438109137e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.72 | consumed tokens: 275097600.0 | grad norm avg: 10.75 | grad norm last: 12.73 | 
2025-12-28T02:07:28 | step: 537400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.2120118198217824e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.31 | consumed tokens: 275148800.0 | grad norm avg: 10.57 | grad norm last: 11.44 | 
2025-12-28T02:07:30 | step: 537500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.210619201534428e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.36 | consumed tokens: 275200000.0 | grad norm avg: 10.16 | grad norm last: 9.13 | 
2025-12-28T02:07:32 | step: 537600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.209226583247073e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.31 | consumed tokens: 275251200.0 | grad norm avg: 10.58 | grad norm last: 10.79 | 
2025-12-28T02:07:34 | step: 537700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.207833964959718e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.16 | consumed tokens: 275302400.0 | grad norm avg: 10.84 | grad norm last: 9.15 | 
2025-12-28T02:07:36 | step: 537800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.2064413466723636e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.3 | consumed tokens: 275353600.0 | grad norm avg: 10.29 | grad norm last: 12.99 | 
2025-12-28T02:07:38 | step: 537900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.205048728385009e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 2.45 | consumed tokens: 275404800.0 | grad norm avg: 10.51 | grad norm last: 12.05 | 
2025-12-28T02:07:40 | step: 538000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.203656110097654e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.8 | consumed tokens: 275456000.0 | grad norm avg: 10.48 | grad norm last: 9.82 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_538000-seen_tokens_275456000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_538000-seen_tokens_275456000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_538000-seen_tokens_275456000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_538000-seen_tokens_275456000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_538000-seen_tokens_275456000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_538000-seen_tokens_275456000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_538000-seen_tokens_275456000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_538000-seen_tokens_275456000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:07:42 | step: 538100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.202264219406061e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.78 | train loss last: 4.28 | consumed tokens: 275507200.0 | grad norm avg: 10.42 | grad norm last: 11.05 | 
2025-12-28T02:07:44 | step: 538200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.200870873522945e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.08 | consumed tokens: 275558400.0 | grad norm avg: 11.16 | grad norm last: 8.35 | 
2025-12-28T02:07:46 | step: 538300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.1994789828313515e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.67 | consumed tokens: 275609600.0 | grad norm avg: 10.93 | grad norm last: 10.03 | 
2025-12-28T02:07:48 | step: 538400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.198086364543997e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.75 | consumed tokens: 275660800.0 | grad norm avg: 10.85 | grad norm last: 9.65 | 
2025-12-28T02:07:50 | step: 538500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.196694110054523e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.83 | consumed tokens: 275712000.0 | grad norm avg: 10.38 | grad norm last: 9.25 | 
2025-12-28T02:07:52 | step: 538600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.195301855565049e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.73 | consumed tokens: 275763200.0 | grad norm avg: 10.27 | grad norm last: 12.78 | 
2025-12-28T02:07:54 | step: 538700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.193909237277694e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.06 | consumed tokens: 275814400.0 | grad norm avg: 11.08 | grad norm last: 10.43 | 
2025-12-28T02:07:56 | step: 538800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.192517346586101e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.31 | consumed tokens: 275865600.0 | grad norm avg: 10.56 | grad norm last: 9.75 | 
2025-12-28T02:07:58 | step: 538900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.191125092096627e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.22 | consumed tokens: 275916800.0 | grad norm avg: 10.16 | grad norm last: 9.86 | 
2025-12-28T02:08:01 | step: 539000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.189732837607153e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.73 | consumed tokens: 275968000.0 | grad norm avg: 10.8 | grad norm last: 10.53 | 
2025-12-28T02:08:03 | step: 539100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.1883409469155595e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.81 | consumed tokens: 276019200.0 | grad norm avg: 10.26 | grad norm last: 15.37 | 
2025-12-28T02:08:05 | step: 539200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.186948328628205e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.38 | consumed tokens: 276070400.0 | grad norm avg: 10.96 | grad norm last: 8.71 | 
2025-12-28T02:08:07 | step: 539300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.185556074138731e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.09 | consumed tokens: 276121600.0 | grad norm avg: 10.55 | grad norm last: 12.58 | 
2025-12-28T02:08:09 | step: 539400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.184164547245018e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.44 | consumed tokens: 276172800.0 | grad norm avg: 10.54 | grad norm last: 10.94 | 
2025-12-28T02:08:11 | step: 539500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.1827719289576635e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.94 | consumed tokens: 276224000.0 | grad norm avg: 10.74 | grad norm last: 10.05 | 
2025-12-28T02:08:13 | step: 539600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.18138003826607e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.05 | consumed tokens: 276275200.0 | grad norm avg: 10.98 | grad norm last: 10.68 | 
2025-12-28T02:08:15 | step: 539700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 5.179988147574477e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.16 | consumed tokens: 276326400.0 | grad norm avg: 10.95 | grad norm last: 9.86 | 
2025-12-28T02:08:17 | step: 539800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.178595893085003e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.81 | consumed tokens: 276377600.0 | grad norm avg: 10.5 | grad norm last: 13.15 | 
2025-12-28T02:08:19 | step: 539900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 5.177203638595529e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.66 | consumed tokens: 276428800.0 | grad norm avg: 10.37 | grad norm last: 15.07 | 
2025-12-28T02:08:21 | step: 540000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 5.175812111701816e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.61 | consumed tokens: 276480000.0 | grad norm avg: 10.55 | grad norm last: 12.9 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_540000-seen_tokens_276480000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_540000-seen_tokens_276480000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_540000-seen_tokens_276480000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_540000-seen_tokens_276480000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_540000-seen_tokens_276480000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_540000-seen_tokens_276480000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_540000-seen_tokens_276480000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_540000-seen_tokens_276480000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:08:23 | step: 540100 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 5.174420584808104e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.02 | consumed tokens: 276531200.0 | grad norm avg: 10.32 | grad norm last: 8.53 | 
2025-12-28T02:08:25 | step: 540200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 5.17302833031863e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 5.12 | consumed tokens: 276582400.0 | grad norm avg: 10.75 | grad norm last: 13.27 | 
2025-12-28T02:08:27 | step: 540300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 5.171636075829156e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.47 | consumed tokens: 276633600.0 | grad norm avg: 10.53 | grad norm last: 8.17 | 
2025-12-28T02:08:29 | step: 540400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.170244912733324e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.67 | consumed tokens: 276684800.0 | grad norm avg: 10.7 | grad norm last: 12.11 | 
2025-12-28T02:08:31 | step: 540500 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 5.1688530220417306e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.52 | consumed tokens: 276736000.0 | grad norm avg: 10.55 | grad norm last: 11.08 | 
2025-12-28T02:08:33 | step: 540600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 5.167461858945899e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.44 | consumed tokens: 276787200.0 | grad norm avg: 10.47 | grad norm last: 9.19 | 
2025-12-28T02:08:35 | step: 540700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 5.166069604456425e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.41 | consumed tokens: 276838400.0 | grad norm avg: 10.36 | grad norm last: 9.16 | 
2025-12-28T02:08:37 | step: 540800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 5.164678077562712e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.88 | consumed tokens: 276889600.0 | grad norm avg: 10.52 | grad norm last: 8.96 | 
2025-12-28T02:08:40 | step: 540900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.163286186871119e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.81 | consumed tokens: 276940800.0 | grad norm avg: 10.52 | grad norm last: 9.43 | 
2025-12-28T02:08:42 | step: 541000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.161894659977406e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.14 | consumed tokens: 276992000.0 | grad norm avg: 10.11 | grad norm last: 9.23 | 
2025-12-28T02:08:44 | step: 541100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.160503133083694e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 4.47 | consumed tokens: 277043200.0 | grad norm avg: 10.77 | grad norm last: 15.75 | 
2025-12-28T02:08:46 | step: 541200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.159111969987862e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.62 | consumed tokens: 277094400.0 | grad norm avg: 11.16 | grad norm last: 10.43 | 
2025-12-28T02:08:48 | step: 541300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.1577200792962685e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 5.09 | consumed tokens: 277145600.0 | grad norm avg: 10.69 | grad norm last: 16.1 | 
2025-12-28T02:08:50 | step: 541400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.156328552402556e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.66 | consumed tokens: 277196800.0 | grad norm avg: 10.47 | grad norm last: 9.49 | 
2025-12-28T02:08:52 | step: 541500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.154937389306724e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.09 | consumed tokens: 277248000.0 | grad norm avg: 10.71 | grad norm last: 13.97 | 
2025-12-28T02:08:54 | step: 541600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.1535458624130115e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.72 | consumed tokens: 277299200.0 | grad norm avg: 10.44 | grad norm last: 9.98 | 
2025-12-28T02:08:56 | step: 541700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.152153971721418e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.28 | consumed tokens: 277350400.0 | grad norm avg: 10.52 | grad norm last: 9.91 | 
2025-12-28T02:08:58 | step: 541800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.150762808625586e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.7 | consumed tokens: 277401600.0 | grad norm avg: 10.76 | grad norm last: 10.27 | 
2025-12-28T02:09:00 | step: 541900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.1493716455297545e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.38 | consumed tokens: 277452800.0 | grad norm avg: 10.71 | grad norm last: 9.84 | 
2025-12-28T02:09:02 | step: 542000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.1479804824339226e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.03 | consumed tokens: 277504000.0 | grad norm avg: 10.33 | grad norm last: 11.44 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_542000-seen_tokens_277504000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_542000-seen_tokens_277504000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_542000-seen_tokens_277504000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_542000-seen_tokens_277504000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_542000-seen_tokens_277504000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_542000-seen_tokens_277504000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_542000-seen_tokens_277504000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_542000-seen_tokens_277504000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:09:04 | step: 542100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.146589319338091e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.81 | consumed tokens: 277555200.0 | grad norm avg: 10.72 | grad norm last: 9.78 | 
2025-12-28T02:09:06 | step: 542200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.145198156242259e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.66 | consumed tokens: 277606400.0 | grad norm avg: 10.52 | grad norm last: 8.59 | 
2025-12-28T02:09:08 | step: 542300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.143806993146427e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.58 | consumed tokens: 277657600.0 | grad norm avg: 10.86 | grad norm last: 13.53 | 
2025-12-28T02:09:10 | step: 542400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.142415830050595e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.42 | consumed tokens: 277708800.0 | grad norm avg: 11.55 | grad norm last: 9.16 | 
2025-12-28T02:09:12 | step: 542500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.141024666954763e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.78 | consumed tokens: 277760000.0 | grad norm avg: 10.81 | grad norm last: 10.34 | 
2025-12-28T02:09:14 | step: 542600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.1396335038589314e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.81 | consumed tokens: 277811200.0 | grad norm avg: 10.8 | grad norm last: 9.55 | 
2025-12-28T02:09:16 | step: 542700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 5.1382423407630995e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.41 | consumed tokens: 277862400.0 | grad norm avg: 10.78 | grad norm last: 12.6 | 
2025-12-28T02:09:18 | step: 542800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.1368511776672676e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.03 | consumed tokens: 277913600.0 | grad norm avg: 10.93 | grad norm last: 8.93 | 
2025-12-28T02:09:20 | step: 542900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.135460742167197e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.28 | consumed tokens: 277964800.0 | grad norm avg: 10.69 | grad norm last: 11.06 | 
2025-12-28T02:09:22 | step: 543000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 5.134069942869246e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.62 | consumed tokens: 278016000.0 | grad norm avg: 10.52 | grad norm last: 9.49 | 
2025-12-28T02:09:24 | step: 543100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.132678779773414e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.55 | consumed tokens: 278067200.0 | grad norm avg: 10.84 | grad norm last: 9.26 | 
2025-12-28T02:09:26 | step: 543200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.131287980475463e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.03 | consumed tokens: 278118400.0 | grad norm avg: 10.67 | grad norm last: 9.46 | 
2025-12-28T02:09:28 | step: 543300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.1298975449753925e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.67 | consumed tokens: 278169600.0 | grad norm avg: 10.72 | grad norm last: 9.48 | 
2025-12-28T02:09:30 | step: 543400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.1285063818795606e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.16 | consumed tokens: 278220800.0 | grad norm avg: 10.65 | grad norm last: 10.97 | 
2025-12-28T02:09:32 | step: 543500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.1271155825816095e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.98 | consumed tokens: 278272000.0 | grad norm avg: 10.48 | grad norm last: 11.81 | 
2025-12-28T02:09:34 | step: 543600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.125724783283658e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.12 | consumed tokens: 278323200.0 | grad norm avg: 11.03 | grad norm last: 13.0 | 
2025-12-28T02:09:36 | step: 543700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.124334347783588e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.55 | consumed tokens: 278374400.0 | grad norm avg: 10.37 | grad norm last: 10.2 | 
2025-12-28T02:09:39 | step: 543800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 5.122943548485637e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.41 | consumed tokens: 278425600.0 | grad norm avg: 10.7 | grad norm last: 9.43 | 
2025-12-28T02:09:41 | step: 543900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.121553476783447e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.69 | consumed tokens: 278476800.0 | grad norm avg: 11.35 | grad norm last: 10.12 | 
2025-12-28T02:09:43 | step: 544000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.120162677485496e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 5.16 | consumed tokens: 278528000.0 | grad norm avg: 10.67 | grad norm last: 15.59 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_544000-seen_tokens_278528000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_544000-seen_tokens_278528000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_544000-seen_tokens_278528000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_544000-seen_tokens_278528000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_544000-seen_tokens_278528000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_544000-seen_tokens_278528000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_544000-seen_tokens_278528000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_544000-seen_tokens_278528000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:09:45 | step: 544100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.1187718781875446e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.67 | train loss last: 3.39 | consumed tokens: 278579200.0 | grad norm avg: 10.1 | grad norm last: 8.66 | 
2025-12-28T02:09:47 | step: 544200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.117381442687474e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.5 | consumed tokens: 278630400.0 | grad norm avg: 10.44 | grad norm last: 9.71 | 
2025-12-28T02:09:49 | step: 544300 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 5.115991007187404e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.59 | consumed tokens: 278681600.0 | grad norm avg: 10.43 | grad norm last: 9.94 | 
2025-12-28T02:09:51 | step: 544400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 5.114600571687333e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.81 | consumed tokens: 278732800.0 | grad norm avg: 10.86 | grad norm last: 10.17 | 
2025-12-28T02:09:53 | step: 544500 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 5.113210136187263e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.34 | consumed tokens: 278784000.0 | grad norm avg: 10.38 | grad norm last: 11.53 | 
2025-12-28T02:09:55 | step: 544600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.111820064485073e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.89 | consumed tokens: 278835200.0 | grad norm avg: 10.11 | grad norm last: 9.29 | 
2025-12-28T02:09:57 | step: 544700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 5.1104299927828833e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.8 | consumed tokens: 278886400.0 | grad norm avg: 10.73 | grad norm last: 9.46 | 
2025-12-28T02:09:59 | step: 544800 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 5.109039557282813e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 2.86 | consumed tokens: 278937600.0 | grad norm avg: 10.73 | grad norm last: 8.39 | 
2025-12-28T02:10:01 | step: 544900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 5.1076491217827424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.95 | consumed tokens: 278988800.0 | grad norm avg: 9.98 | grad norm last: 8.73 | 
2025-12-28T02:10:03 | step: 545000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.1062594138784334e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.59 | consumed tokens: 279040000.0 | grad norm avg: 10.48 | grad norm last: 9.06 | 
2025-12-28T02:10:05 | step: 545100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.104868978378363e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.59 | consumed tokens: 279091200.0 | grad norm avg: 10.74 | grad norm last: 9.68 | 
2025-12-28T02:10:07 | step: 545200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.1034785428782925e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.69 | consumed tokens: 279142400.0 | grad norm avg: 10.28 | grad norm last: 9.26 | 
2025-12-28T02:10:09 | step: 545300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.1020888349739835e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.12 | consumed tokens: 279193600.0 | grad norm avg: 10.51 | grad norm last: 11.01 | 
2025-12-28T02:10:11 | step: 545400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.100698399473913e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 4.25 | consumed tokens: 279244800.0 | grad norm avg: 11.16 | grad norm last: 16.96 | 
2025-12-28T02:10:13 | step: 545500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.099308691569604e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.98 | consumed tokens: 279296000.0 | grad norm avg: 10.62 | grad norm last: 12.1 | 
2025-12-28T02:10:15 | step: 545600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.097918619867414e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.75 | consumed tokens: 279347200.0 | grad norm avg: 10.56 | grad norm last: 11.46 | 
2025-12-28T02:10:17 | step: 545700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.0965285481652245e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.73 | consumed tokens: 279398400.0 | grad norm avg: 10.7 | grad norm last: 9.3 | 
2025-12-28T02:10:20 | step: 545800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.0951388402609155e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.03 | consumed tokens: 279449600.0 | grad norm avg: 10.62 | grad norm last: 13.92 | 
2025-12-28T02:10:22 | step: 545900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.0937491323566064e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.36 | consumed tokens: 279500800.0 | grad norm avg: 10.67 | grad norm last: 9.39 | 
2025-12-28T02:10:24 | step: 546000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.0923594244522974e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.66 | consumed tokens: 279552000.0 | grad norm avg: 10.39 | grad norm last: 9.41 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_546000-seen_tokens_279552000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_546000-seen_tokens_279552000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_546000-seen_tokens_279552000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_546000-seen_tokens_279552000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_546000-seen_tokens_279552000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_546000-seen_tokens_279552000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_546000-seen_tokens_279552000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_546000-seen_tokens_279552000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:10:26 | step: 546100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.090968988952227e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.36 | consumed tokens: 279603200.0 | grad norm avg: 10.59 | grad norm last: 10.4 | 
2025-12-28T02:10:28 | step: 546200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.089580008643679e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.67 | consumed tokens: 279654400.0 | grad norm avg: 10.89 | grad norm last: 10.33 | 
2025-12-28T02:10:30 | step: 546300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 5.088189573143609e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.55 | consumed tokens: 279705600.0 | grad norm avg: 10.67 | grad norm last: 9.66 | 
2025-12-28T02:10:32 | step: 546400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.086800592835061e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.55 | consumed tokens: 279756800.0 | grad norm avg: 10.19 | grad norm last: 8.97 | 
2025-12-28T02:10:34 | step: 546500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.085410157334991e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.89 | consumed tokens: 279808000.0 | grad norm avg: 10.46 | grad norm last: 8.14 | 
2025-12-28T02:10:36 | step: 546600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.084021177026443e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.44 | consumed tokens: 279859200.0 | grad norm avg: 10.34 | grad norm last: 11.41 | 
2025-12-28T02:10:38 | step: 546700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.082631469122134e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.09 | consumed tokens: 279910400.0 | grad norm avg: 10.97 | grad norm last: 9.9 | 
2025-12-28T02:10:40 | step: 546800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.081242125015706e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.0 | consumed tokens: 279961600.0 | grad norm avg: 10.78 | grad norm last: 11.0 | 
2025-12-28T02:10:42 | step: 546900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.0798527809092775e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.64 | consumed tokens: 280012800.0 | grad norm avg: 10.28 | grad norm last: 10.41 | 
2025-12-28T02:10:44 | step: 547000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.0784630730049685e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.44 | consumed tokens: 280064000.0 | grad norm avg: 10.57 | grad norm last: 12.5 | 
2025-12-28T02:10:46 | step: 547100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.077074092696421e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.47 | consumed tokens: 280115200.0 | grad norm avg: 10.4 | grad norm last: 9.34 | 
2025-12-28T02:10:48 | step: 547200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.075684384792112e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.14 | consumed tokens: 280166400.0 | grad norm avg: 10.52 | grad norm last: 8.48 | 
2025-12-28T02:10:50 | step: 547300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.074295404483564e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.06 | consumed tokens: 280217600.0 | grad norm avg: 10.53 | grad norm last: 12.74 | 
2025-12-28T02:10:52 | step: 547400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.0729064241750166e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.58 | consumed tokens: 280268800.0 | grad norm avg: 10.76 | grad norm last: 10.06 | 
2025-12-28T02:10:54 | step: 547500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.0715167162707075e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.73 | consumed tokens: 280320000.0 | grad norm avg: 10.58 | grad norm last: 9.69 | 
2025-12-28T02:10:56 | step: 547600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.07012773596216e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.33 | consumed tokens: 280371200.0 | grad norm avg: 10.44 | grad norm last: 8.19 | 
2025-12-28T02:10:58 | step: 547700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 5.068738755653612e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.08 | consumed tokens: 280422400.0 | grad norm avg: 10.24 | grad norm last: 7.72 | 
2025-12-28T02:11:00 | step: 547800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.067349411547184e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.69 | consumed tokens: 280473600.0 | grad norm avg: 10.15 | grad norm last: 9.48 | 
2025-12-28T02:11:02 | step: 547900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.065960067440756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.67 | consumed tokens: 280524800.0 | grad norm avg: 10.3 | grad norm last: 9.87 | 
2025-12-28T02:11:04 | step: 548000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.064571450930089e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.47 | consumed tokens: 280576000.0 | grad norm avg: 10.45 | grad norm last: 9.65 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_548000-seen_tokens_280576000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_548000-seen_tokens_280576000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_548000-seen_tokens_280576000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_548000-seen_tokens_280576000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_548000-seen_tokens_280576000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_548000-seen_tokens_280576000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_548000-seen_tokens_280576000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_548000-seen_tokens_280576000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:11:07 | step: 548100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.063182834419422e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.77 | train loss last: 2.95 | consumed tokens: 280627200.0 | grad norm avg: 10.59 | grad norm last: 8.49 | 
2025-12-28T02:11:09 | step: 548200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.0617934903129935e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.03 | consumed tokens: 280678400.0 | grad norm avg: 10.87 | grad norm last: 11.55 | 
2025-12-28T02:11:11 | step: 548300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.060404146206565e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.03 | consumed tokens: 280729600.0 | grad norm avg: 10.04 | grad norm last: 10.56 | 
2025-12-28T02:11:13 | step: 548400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.059015893493779e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.56 | consumed tokens: 280780800.0 | grad norm avg: 10.5 | grad norm last: 15.94 | 
2025-12-28T02:11:15 | step: 548500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 5.0576269131852314e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.22 | consumed tokens: 280832000.0 | grad norm avg: 10.75 | grad norm last: 10.4 | 
2025-12-28T02:11:17 | step: 548600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 5.056238660472445e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.33 | consumed tokens: 280883200.0 | grad norm avg: 10.52 | grad norm last: 8.66 | 
2025-12-28T02:11:19 | step: 548700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.0548496801638976e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.39 | consumed tokens: 280934400.0 | grad norm avg: 10.01 | grad norm last: 9.15 | 
2025-12-28T02:11:21 | step: 548800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.053461063653231e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.08 | consumed tokens: 280985600.0 | grad norm avg: 10.6 | grad norm last: 10.48 | 
2025-12-28T02:11:23 | step: 548900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 5.052072447142564e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.64 | consumed tokens: 281036800.0 | grad norm avg: 10.44 | grad norm last: 12.62 | 
2025-12-28T02:11:25 | step: 549000 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 5.050683466834016e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.23 | consumed tokens: 281088000.0 | grad norm avg: 10.06 | grad norm last: 8.48 | 
2025-12-28T02:11:27 | step: 549100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 5.04929521412123e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.03 | consumed tokens: 281139200.0 | grad norm avg: 10.32 | grad norm last: 10.17 | 
2025-12-28T02:11:29 | step: 549200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 5.047906597610563e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 6.0 | consumed tokens: 281190400.0 | grad norm avg: 10.3 | grad norm last: 15.68 | 
2025-12-28T02:11:31 | step: 549300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.046518344897777e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.61 | consumed tokens: 281241600.0 | grad norm avg: 10.21 | grad norm last: 21.99 | 
2025-12-28T02:11:33 | step: 549400 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 5.04512972838711e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.41 | consumed tokens: 281292800.0 | grad norm avg: 10.51 | grad norm last: 9.51 | 
2025-12-28T02:11:35 | step: 549500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.043741475674324e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.67 | consumed tokens: 281344000.0 | grad norm avg: 10.41 | grad norm last: 9.19 | 
2025-12-28T02:11:37 | step: 549600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 5.0423532229615375e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.56 | consumed tokens: 281395200.0 | grad norm avg: 10.27 | grad norm last: 9.17 | 
2025-12-28T02:11:39 | step: 549700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 5.0409649702487513e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.62 | consumed tokens: 281446400.0 | grad norm avg: 10.07 | grad norm last: 9.24 | 
2025-12-28T02:11:41 | step: 549800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 5.039576717535965e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.56 | consumed tokens: 281497600.0 | grad norm avg: 10.25 | grad norm last: 10.25 | 
2025-12-28T02:11:43 | step: 549900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.038188464823179e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 2.86 | consumed tokens: 281548800.0 | grad norm avg: 10.6 | grad norm last: 8.8 | 
2025-12-28T02:11:45 | step: 550000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.0368005759082735e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.77 | consumed tokens: 281600000.0 | grad norm avg: 9.77 | grad norm last: 11.41 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_550000-seen_tokens_281600000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_550000-seen_tokens_281600000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_550000-seen_tokens_281600000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_550000-seen_tokens_281600000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_550000-seen_tokens_281600000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_550000-seen_tokens_281600000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_550000-seen_tokens_281600000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_550000-seen_tokens_281600000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:11:48 | step: 550100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.035412323195487e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.65 | train loss last: 3.41 | consumed tokens: 281651200.0 | grad norm avg: 10.06 | grad norm last: 10.27 | 
2025-12-28T02:11:50 | step: 550200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 5.034024434280582e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.83 | consumed tokens: 281702400.0 | grad norm avg: 9.91 | grad norm last: 9.92 | 
2025-12-28T02:11:52 | step: 550300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.0326361815677956e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.16 | consumed tokens: 281753600.0 | grad norm avg: 10.47 | grad norm last: 9.14 | 
2025-12-28T02:11:54 | step: 550400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 5.0312479288550094e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.5 | consumed tokens: 281804800.0 | grad norm avg: 10.48 | grad norm last: 10.5 | 
2025-12-28T02:11:56 | step: 550500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 5.0298604037379846e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.75 | consumed tokens: 281856000.0 | grad norm avg: 10.75 | grad norm last: 8.4 | 
2025-12-28T02:11:58 | step: 550600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 5.028472514823079e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.06 | consumed tokens: 281907200.0 | grad norm avg: 10.41 | grad norm last: 10.45 | 
2025-12-28T02:12:00 | step: 550700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 5.0270846259081736e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.73 | consumed tokens: 281958400.0 | grad norm avg: 10.36 | grad norm last: 9.86 | 
2025-12-28T02:12:02 | step: 550800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.025697100791149e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.28 | consumed tokens: 282009600.0 | grad norm avg: 10.07 | grad norm last: 10.07 | 
2025-12-28T02:12:04 | step: 550900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.0243092118762434e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.88 | consumed tokens: 282060800.0 | grad norm avg: 10.44 | grad norm last: 10.89 | 
2025-12-28T02:12:06 | step: 551000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.022921322961338e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.86 | consumed tokens: 282112000.0 | grad norm avg: 10.18 | grad norm last: 9.47 | 
2025-12-28T02:12:08 | step: 551100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.021533797844313e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.88 | consumed tokens: 282163200.0 | grad norm avg: 10.58 | grad norm last: 10.26 | 
2025-12-28T02:12:10 | step: 551200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 5.020146272727288e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 2.92 | consumed tokens: 282214400.0 | grad norm avg: 10.22 | grad norm last: 8.19 | 
2025-12-28T02:12:12 | step: 551300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.0187587476102635e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.5 | consumed tokens: 282265600.0 | grad norm avg: 10.17 | grad norm last: 9.19 | 
2025-12-28T02:12:14 | step: 551400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.017371222493239e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.39 | consumed tokens: 282316800.0 | grad norm avg: 10.64 | grad norm last: 9.11 | 
2025-12-28T02:12:16 | step: 551500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.015983697376214e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.31 | consumed tokens: 282368000.0 | grad norm avg: 11.09 | grad norm last: 11.01 | 
2025-12-28T02:12:18 | step: 551600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.0145968998549506e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.12 | consumed tokens: 282419200.0 | grad norm avg: 10.02 | grad norm last: 9.38 | 
2025-12-28T02:12:20 | step: 551700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 5.013209010940045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.73 | consumed tokens: 282470400.0 | grad norm avg: 10.75 | grad norm last: 9.4 | 
2025-12-28T02:12:22 | step: 551800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.011821849620901e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.81 | consumed tokens: 282521600.0 | grad norm avg: 10.62 | grad norm last: 10.49 | 
2025-12-28T02:12:24 | step: 551900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.010434324503876e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.44 | consumed tokens: 282572800.0 | grad norm avg: 10.55 | grad norm last: 10.79 | 
2025-12-28T02:12:26 | step: 552000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.009047163184732e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.92 | consumed tokens: 282624000.0 | grad norm avg: 10.85 | grad norm last: 9.76 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_552000-seen_tokens_282624000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_552000-seen_tokens_282624000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_552000-seen_tokens_282624000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_552000-seen_tokens_282624000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_552000-seen_tokens_282624000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_552000-seen_tokens_282624000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_552000-seen_tokens_282624000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_552000-seen_tokens_282624000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:12:29 | step: 552100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.007660001865588e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 3.09 | consumed tokens: 282675200.0 | grad norm avg: 10.53 | grad norm last: 8.34 | 
2025-12-28T02:12:31 | step: 552200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.006273204344325e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.62 | train loss last: 3.08 | consumed tokens: 282726400.0 | grad norm avg: 10.07 | grad norm last: 8.66 | 
2025-12-28T02:12:33 | step: 552300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 5.0048856792273e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.72 | consumed tokens: 282777600.0 | grad norm avg: 10.03 | grad norm last: 10.46 | 
2025-12-28T02:12:35 | step: 552400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 5.0034988817060366e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 2.91 | consumed tokens: 282828800.0 | grad norm avg: 10.29 | grad norm last: 8.82 | 
2025-12-28T02:12:37 | step: 552500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 5.0021117203868926e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.03 | consumed tokens: 282880000.0 | grad norm avg: 10.15 | grad norm last: 9.36 | 
2025-12-28T02:12:39 | step: 552600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 5.000724922865629e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.61 | consumed tokens: 282931200.0 | grad norm avg: 10.74 | grad norm last: 9.24 | 
2025-12-28T02:12:41 | step: 552700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.999338125344366e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.98 | consumed tokens: 282982400.0 | grad norm avg: 11.08 | grad norm last: 10.21 | 
2025-12-28T02:12:43 | step: 552800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.9979513278231025e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.89 | consumed tokens: 283033600.0 | grad norm avg: 10.55 | grad norm last: 9.54 | 
2025-12-28T02:12:45 | step: 552900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.996564530301839e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.5 | consumed tokens: 283084800.0 | grad norm avg: 10.34 | grad norm last: 11.91 | 
2025-12-28T02:12:47 | step: 553000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.995177732780576e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.47 | consumed tokens: 283136000.0 | grad norm avg: 10.41 | grad norm last: 9.96 | 
2025-12-28T02:12:49 | step: 553100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.9937909352593124e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.36 | consumed tokens: 283187200.0 | grad norm avg: 10.61 | grad norm last: 8.62 | 
2025-12-28T02:12:51 | step: 553200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.99240450153593e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.02 | consumed tokens: 283238400.0 | grad norm avg: 10.42 | grad norm last: 10.92 | 
2025-12-28T02:12:53 | step: 553300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.9910177040146664e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.44 | consumed tokens: 283289600.0 | grad norm avg: 10.46 | grad norm last: 11.41 | 
2025-12-28T02:12:55 | step: 553400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.9896316340891644e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.06 | consumed tokens: 283340800.0 | grad norm avg: 10.78 | grad norm last: 9.66 | 
2025-12-28T02:12:57 | step: 553500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.988244836567901e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.25 | consumed tokens: 283392000.0 | grad norm avg: 10.31 | grad norm last: 9.48 | 
2025-12-28T02:12:59 | step: 553600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.9868584028445184e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.48 | consumed tokens: 283443200.0 | grad norm avg: 10.71 | grad norm last: 9.58 | 
2025-12-28T02:13:01 | step: 553700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.985471969121136e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 2.77 | consumed tokens: 283494400.0 | grad norm avg: 10.8 | grad norm last: 8.54 | 
2025-12-28T02:13:03 | step: 553800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.9840851715998724e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.16 | consumed tokens: 283545600.0 | grad norm avg: 10.59 | grad norm last: 12.62 | 
2025-12-28T02:13:05 | step: 553900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.9826991016743705e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.81 | consumed tokens: 283596800.0 | grad norm avg: 10.55 | grad norm last: 15.69 | 
2025-12-28T02:13:07 | step: 554000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.9813130317488685e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.86 | consumed tokens: 283648000.0 | grad norm avg: 10.69 | grad norm last: 10.86 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_554000-seen_tokens_283648000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_554000-seen_tokens_283648000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_554000-seen_tokens_283648000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_554000-seen_tokens_283648000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_554000-seen_tokens_283648000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_554000-seen_tokens_283648000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_554000-seen_tokens_283648000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_554000-seen_tokens_283648000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:13:09 | step: 554100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.979926234227605e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.7 | train loss last: 3.92 | consumed tokens: 283699200.0 | grad norm avg: 10.7 | grad norm last: 10.58 | 
2025-12-28T02:13:11 | step: 554200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.978540528099984e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.06 | consumed tokens: 283750400.0 | grad norm avg: 10.74 | grad norm last: 9.37 | 
2025-12-28T02:13:13 | step: 554300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.977154821972363e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.73 | consumed tokens: 283801600.0 | grad norm avg: 10.37 | grad norm last: 8.91 | 
2025-12-28T02:13:15 | step: 554400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.97576838824898e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.03 | consumed tokens: 283852800.0 | grad norm avg: 10.46 | grad norm last: 11.76 | 
2025-12-28T02:13:18 | step: 554500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.9743819545255974e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.23 | consumed tokens: 283904000.0 | grad norm avg: 11.14 | grad norm last: 11.02 | 
2025-12-28T02:13:20 | step: 554600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.972996612195857e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 2.75 | consumed tokens: 283955200.0 | grad norm avg: 10.97 | grad norm last: 9.28 | 
2025-12-28T02:13:22 | step: 554700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.971610542270355e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 5.06 | consumed tokens: 284006400.0 | grad norm avg: 10.74 | grad norm last: 11.81 | 
2025-12-28T02:13:24 | step: 554800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.9702251999406144e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.48 | consumed tokens: 284057600.0 | grad norm avg: 10.66 | grad norm last: 8.68 | 
2025-12-28T02:13:26 | step: 554900 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.9688391300151125e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.52 | consumed tokens: 284108800.0 | grad norm avg: 10.62 | grad norm last: 9.74 | 
2025-12-28T02:13:28 | step: 555000 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.9674530600896105e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.23 | consumed tokens: 284160000.0 | grad norm avg: 10.96 | grad norm last: 8.31 | 
2025-12-28T02:13:30 | step: 555100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.96606771775987e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.55 | consumed tokens: 284211200.0 | grad norm avg: 10.39 | grad norm last: 8.11 | 
2025-12-28T02:13:32 | step: 555200 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.964681647834368e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.67 | consumed tokens: 284262400.0 | grad norm avg: 10.64 | grad norm last: 9.1 | 
2025-12-28T02:13:34 | step: 555300 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.9632963055046275e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.84 | consumed tokens: 284313600.0 | grad norm avg: 10.85 | grad norm last: 13.95 | 
2025-12-28T02:13:36 | step: 555400 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.961910599377006e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.11 | consumed tokens: 284364800.0 | grad norm avg: 10.6 | grad norm last: 12.16 | 
2025-12-28T02:13:38 | step: 555500 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.960525257047266e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.09 | consumed tokens: 284416000.0 | grad norm avg: 10.86 | grad norm last: 9.46 | 
2025-12-28T02:13:40 | step: 555600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.959139914717525e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.41 | consumed tokens: 284467200.0 | grad norm avg: 11.0 | grad norm last: 11.79 | 
2025-12-28T02:13:42 | step: 555700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.957754572387785e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.8 | consumed tokens: 284518400.0 | grad norm avg: 11.87 | grad norm last: 12.87 | 
2025-12-28T02:13:44 | step: 555800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.956369230058044e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.06 | consumed tokens: 284569600.0 | grad norm avg: 10.93 | grad norm last: 9.32 | 
2025-12-28T02:13:46 | step: 555900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.954983887728304e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.66 | consumed tokens: 284620800.0 | grad norm avg: 10.88 | grad norm last: 13.53 | 
2025-12-28T02:13:48 | step: 556000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.953598545398563e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.16 | consumed tokens: 284672000.0 | grad norm avg: 10.68 | grad norm last: 10.4 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_556000-seen_tokens_284672000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_556000-seen_tokens_284672000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_556000-seen_tokens_284672000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_556000-seen_tokens_284672000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_556000-seen_tokens_284672000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_556000-seen_tokens_284672000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_556000-seen_tokens_284672000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_556000-seen_tokens_284672000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:13:50 | step: 556100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.952213566866703e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.67 | train loss last: 4.47 | consumed tokens: 284723200.0 | grad norm avg: 10.56 | grad norm last: 11.71 | 
2025-12-28T02:13:52 | step: 556200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.950828224536963e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.88 | consumed tokens: 284774400.0 | grad norm avg: 11.02 | grad norm last: 10.25 | 
2025-12-28T02:13:54 | step: 556300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.949442882207222e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.91 | consumed tokens: 284825600.0 | grad norm avg: 11.37 | grad norm last: 12.8 | 
2025-12-28T02:13:56 | step: 556400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.948058267473243e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.28 | consumed tokens: 284876800.0 | grad norm avg: 10.74 | grad norm last: 9.03 | 
2025-12-28T02:13:59 | step: 556500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.9466732889413834e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.2 | consumed tokens: 284928000.0 | grad norm avg: 11.22 | grad norm last: 9.55 | 
2025-12-28T02:14:01 | step: 556600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.9452883104095235e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 2.58 | consumed tokens: 284979200.0 | grad norm avg: 10.87 | grad norm last: 7.76 | 
2025-12-28T02:14:03 | step: 556700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.9439036956755444e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.11 | consumed tokens: 285030400.0 | grad norm avg: 10.97 | grad norm last: 8.76 | 
2025-12-28T02:14:05 | step: 556800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.9425187171436846e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.53 | consumed tokens: 285081600.0 | grad norm avg: 10.97 | grad norm last: 13.41 | 
2025-12-28T02:14:07 | step: 556900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.941133738611825e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.12 | consumed tokens: 285132800.0 | grad norm avg: 10.79 | grad norm last: 13.43 | 
2025-12-28T02:14:09 | step: 557000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.939749123877846e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.28 | consumed tokens: 285184000.0 | grad norm avg: 10.54 | grad norm last: 14.6 | 
2025-12-28T02:14:11 | step: 557100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.9383645091438666e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.83 | consumed tokens: 285235200.0 | grad norm avg: 10.26 | grad norm last: 10.12 | 
2025-12-28T02:14:13 | step: 557200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.9369798944098875e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.59 | consumed tokens: 285286400.0 | grad norm avg: 11.56 | grad norm last: 9.69 | 
2025-12-28T02:14:15 | step: 557300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.9355952796759084e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.72 | consumed tokens: 285337600.0 | grad norm avg: 11.06 | grad norm last: 12.41 | 
2025-12-28T02:14:17 | step: 557400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.93421102873981e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 2.84 | consumed tokens: 285388800.0 | grad norm avg: 10.4 | grad norm last: 9.42 | 
2025-12-28T02:14:19 | step: 557500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.9328267778037116e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.62 | consumed tokens: 285440000.0 | grad norm avg: 11.19 | grad norm last: 9.81 | 
2025-12-28T02:14:21 | step: 557600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.9314421630697325e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.42 | consumed tokens: 285491200.0 | grad norm avg: 10.62 | grad norm last: 9.34 | 
2025-12-28T02:14:23 | step: 557700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.930057912133634e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.97 | consumed tokens: 285542400.0 | grad norm avg: 10.97 | grad norm last: 11.44 | 
2025-12-28T02:14:25 | step: 557800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.928673661197536e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.03 | consumed tokens: 285593600.0 | grad norm avg: 11.1 | grad norm last: 11.01 | 
2025-12-28T02:14:27 | step: 557900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.9272890464635566e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.78 | consumed tokens: 285644800.0 | grad norm avg: 10.92 | grad norm last: 12.43 | 
2025-12-28T02:14:29 | step: 558000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.925905159325339e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.09 | consumed tokens: 285696000.0 | grad norm avg: 10.58 | grad norm last: 10.22 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_558000-seen_tokens_285696000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_558000-seen_tokens_285696000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_558000-seen_tokens_285696000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_558000-seen_tokens_285696000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_558000-seen_tokens_285696000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_558000-seen_tokens_285696000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_558000-seen_tokens_285696000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_558000-seen_tokens_285696000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:14:31 | step: 558100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.924521272187121e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.72 | train loss last: 3.62 | consumed tokens: 285747200.0 | grad norm avg: 11.07 | grad norm last: 10.59 | 
2025-12-28T02:14:33 | step: 558200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.923137021251023e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.44 | consumed tokens: 285798400.0 | grad norm avg: 11.06 | grad norm last: 9.54 | 
2025-12-28T02:14:35 | step: 558300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.921753134112805e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.28 | consumed tokens: 285849600.0 | grad norm avg: 11.09 | grad norm last: 10.88 | 
2025-12-28T02:14:37 | step: 558400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.9203692469745874e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.41 | consumed tokens: 285900800.0 | grad norm avg: 10.69 | grad norm last: 15.11 | 
2025-12-28T02:14:39 | step: 558500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.91898535983637e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.78 | consumed tokens: 285952000.0 | grad norm avg: 10.59 | grad norm last: 10.76 | 
2025-12-28T02:14:41 | step: 558600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.917601472698152e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.28 | consumed tokens: 286003200.0 | grad norm avg: 10.54 | grad norm last: 15.95 | 
2025-12-28T02:14:43 | step: 558700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.916217949357815e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.78 | consumed tokens: 286054400.0 | grad norm avg: 10.81 | grad norm last: 9.3 | 
2025-12-28T02:14:45 | step: 558800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.9148340622195974e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.34 | consumed tokens: 286105600.0 | grad norm avg: 10.66 | grad norm last: 12.15 | 
2025-12-28T02:14:47 | step: 558900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.91345017508138e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.05 | consumed tokens: 286156800.0 | grad norm avg: 10.66 | grad norm last: 10.79 | 
2025-12-28T02:14:49 | step: 559000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.9120670155389234e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.88 | consumed tokens: 286208000.0 | grad norm avg: 11.11 | grad norm last: 12.95 | 
2025-12-28T02:14:51 | step: 559100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.9106834921985865e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 5.16 | consumed tokens: 286259200.0 | grad norm avg: 10.73 | grad norm last: 15.99 | 
2025-12-28T02:14:53 | step: 559200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.9092999688582495e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.27 | consumed tokens: 286310400.0 | grad norm avg: 10.47 | grad norm last: 8.85 | 
2025-12-28T02:14:55 | step: 559300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.907916809315793e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.31 | consumed tokens: 286361600.0 | grad norm avg: 10.69 | grad norm last: 14.01 | 
2025-12-28T02:14:57 | step: 559400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.9065329221775755e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.44 | consumed tokens: 286412800.0 | grad norm avg: 11.21 | grad norm last: 11.45 | 
2025-12-28T02:15:00 | step: 559500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.905149762635119e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.28 | consumed tokens: 286464000.0 | grad norm avg: 11.17 | grad norm last: 11.92 | 
2025-12-28T02:15:02 | step: 559600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.903766603092663e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.03 | consumed tokens: 286515200.0 | grad norm avg: 10.98 | grad norm last: 9.45 | 
2025-12-28T02:15:04 | step: 559700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.902383443550207e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.38 | consumed tokens: 286566400.0 | grad norm avg: 11.2 | grad norm last: 10.4 | 
2025-12-28T02:15:06 | step: 559800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.9010002840077505e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.89 | consumed tokens: 286617600.0 | grad norm avg: 10.8 | grad norm last: 11.58 | 
2025-12-28T02:15:08 | step: 559900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.899617124465294e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.03 | consumed tokens: 286668800.0 | grad norm avg: 11.57 | grad norm last: 10.36 | 
2025-12-28T02:15:10 | step: 560000 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.898233964922838e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 2.86 | consumed tokens: 286720000.0 | grad norm avg: 10.64 | grad norm last: 9.48 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_560000-seen_tokens_286720000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_560000-seen_tokens_286720000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_560000-seen_tokens_286720000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_560000-seen_tokens_286720000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_560000-seen_tokens_286720000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_560000-seen_tokens_286720000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_560000-seen_tokens_286720000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_560000-seen_tokens_286720000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:15:12 | step: 560100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.896851532976143e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 3.84 | consumed tokens: 286771200.0 | grad norm avg: 11.3 | grad norm last: 9.69 | 
2025-12-28T02:15:14 | step: 560200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.895468373433687e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.22 | consumed tokens: 286822400.0 | grad norm avg: 10.9 | grad norm last: 10.72 | 
2025-12-28T02:15:16 | step: 560300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.8940852138912305e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.31 | consumed tokens: 286873600.0 | grad norm avg: 10.97 | grad norm last: 9.26 | 
2025-12-28T02:15:18 | step: 560400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.892702054348774e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.62 | consumed tokens: 286924800.0 | grad norm avg: 11.56 | grad norm last: 8.81 | 
2025-12-28T02:15:20 | step: 560500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.8913196224020794e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.77 | consumed tokens: 286976000.0 | grad norm avg: 11.23 | grad norm last: 10.36 | 
2025-12-28T02:15:22 | step: 560600 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.8899371904553846e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.41 | consumed tokens: 287027200.0 | grad norm avg: 10.76 | grad norm last: 9.73 | 
2025-12-28T02:15:24 | step: 560700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.888554394710809e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.47 | consumed tokens: 287078400.0 | grad norm avg: 11.02 | grad norm last: 12.21 | 
2025-12-28T02:15:26 | step: 560800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.887171962764114e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.45 | consumed tokens: 287129600.0 | grad norm avg: 11.63 | grad norm last: 10.37 | 
2025-12-28T02:15:28 | step: 560900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.885789530817419e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.73 | consumed tokens: 287180800.0 | grad norm avg: 10.52 | grad norm last: 9.5 | 
2025-12-28T02:15:30 | step: 561000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.8844070988707244e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.25 | consumed tokens: 287232000.0 | grad norm avg: 11.01 | grad norm last: 11.56 | 
2025-12-28T02:15:32 | step: 561100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.8830246669240296e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.05 | consumed tokens: 287283200.0 | grad norm avg: 10.71 | grad norm last: 8.46 | 
2025-12-28T02:15:34 | step: 561200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.881642234977335e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.81 | consumed tokens: 287334400.0 | grad norm avg: 11.43 | grad norm last: 9.72 | 
2025-12-28T02:15:36 | step: 561300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.8802601668285206e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.14 | consumed tokens: 287385600.0 | grad norm avg: 10.98 | grad norm last: 9.0 | 
2025-12-28T02:15:38 | step: 561400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.878877734881826e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.81 | consumed tokens: 287436800.0 | grad norm avg: 11.13 | grad norm last: 10.68 | 
2025-12-28T02:15:41 | step: 561500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.877495302935131e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.56 | consumed tokens: 287488000.0 | grad norm avg: 11.01 | grad norm last: 11.7 | 
2025-12-28T02:15:43 | step: 561600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.8761135985841975e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.95 | consumed tokens: 287539200.0 | grad norm avg: 11.12 | grad norm last: 11.75 | 
2025-12-28T02:15:45 | step: 561700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.874731530435383e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.02 | consumed tokens: 287590400.0 | grad norm avg: 10.68 | grad norm last: 10.9 | 
2025-12-28T02:15:47 | step: 561800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.8733501898823306e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.83 | consumed tokens: 287641600.0 | grad norm avg: 10.95 | grad norm last: 9.61 | 
2025-12-28T02:15:49 | step: 561900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.871967757935636e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 2.88 | consumed tokens: 287692800.0 | grad norm avg: 11.05 | grad norm last: 9.83 | 
2025-12-28T02:15:51 | step: 562000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.870586053584702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.78 | consumed tokens: 287744000.0 | grad norm avg: 11.12 | grad norm last: 12.77 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_562000-seen_tokens_287744000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_562000-seen_tokens_287744000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_562000-seen_tokens_287744000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_562000-seen_tokens_287744000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_562000-seen_tokens_287744000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_562000-seen_tokens_287744000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_562000-seen_tokens_287744000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_562000-seen_tokens_287744000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:15:53 | step: 562100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.869204349233769e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.69 | train loss last: 3.89 | consumed tokens: 287795200.0 | grad norm avg: 10.79 | grad norm last: 11.44 | 
2025-12-28T02:15:55 | step: 562200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.8678226448828354e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.61 | train loss last: 3.69 | consumed tokens: 287846400.0 | grad norm avg: 10.59 | grad norm last: 8.85 | 
2025-12-28T02:15:57 | step: 562300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.866440940531902e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.03 | consumed tokens: 287897600.0 | grad norm avg: 11.19 | grad norm last: 10.98 | 
2025-12-28T02:15:59 | step: 562400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.8650592361809686e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.22 | consumed tokens: 287948800.0 | grad norm avg: 11.21 | grad norm last: 11.1 | 
2025-12-28T02:16:01 | step: 562500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.863677895627916e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.88 | consumed tokens: 288000000.0 | grad norm avg: 10.92 | grad norm last: 9.97 | 
2025-12-28T02:16:03 | step: 562600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.862296555074863e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.2 | consumed tokens: 288051200.0 | grad norm avg: 10.99 | grad norm last: 10.62 | 
2025-12-28T02:16:05 | step: 562700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.86091485072393e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.12 | consumed tokens: 288102400.0 | grad norm avg: 11.17 | grad norm last: 17.67 | 
2025-12-28T02:16:07 | step: 562800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.859533510170877e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.66 | consumed tokens: 288153600.0 | grad norm avg: 10.98 | grad norm last: 9.52 | 
2025-12-28T02:16:09 | step: 562900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.858152169617824e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.02 | consumed tokens: 288204800.0 | grad norm avg: 10.87 | grad norm last: 8.94 | 
2025-12-28T02:16:11 | step: 563000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.856770465266891e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.47 | consumed tokens: 288256000.0 | grad norm avg: 11.21 | grad norm last: 9.58 | 
2025-12-28T02:16:13 | step: 563100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.85539021610748e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.58 | consumed tokens: 288307200.0 | grad norm avg: 10.76 | grad norm last: 9.7 | 
2025-12-28T02:16:15 | step: 563200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 4.854008511756547e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.22 | consumed tokens: 288358400.0 | grad norm avg: 10.76 | grad norm last: 9.32 | 
2025-12-28T02:16:17 | step: 563300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 4.852627535001375e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 2.7 | consumed tokens: 288409600.0 | grad norm avg: 11.51 | grad norm last: 8.16 | 
2025-12-28T02:16:19 | step: 563400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.851246558246203e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.22 | consumed tokens: 288460800.0 | grad norm avg: 11.45 | grad norm last: 11.61 | 
2025-12-28T02:16:21 | step: 563500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.849866309086792e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.3 | consumed tokens: 288512000.0 | grad norm avg: 10.77 | grad norm last: 11.43 | 
2025-12-28T02:16:23 | step: 563600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.848484604735859e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.56 | consumed tokens: 288563200.0 | grad norm avg: 10.7 | grad norm last: 10.1 | 
2025-12-28T02:16:25 | step: 563700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.847104355576448e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.66 | consumed tokens: 288614400.0 | grad norm avg: 11.21 | grad norm last: 9.73 | 
2025-12-28T02:16:27 | step: 563800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.845723378821276e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.67 | consumed tokens: 288665600.0 | grad norm avg: 11.01 | grad norm last: 14.51 | 
2025-12-28T02:16:29 | step: 563900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.844342765863985e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.52 | consumed tokens: 288716800.0 | grad norm avg: 11.7 | grad norm last: 9.8 | 
2025-12-28T02:16:31 | step: 564000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.8429621529066935e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.66 | consumed tokens: 288768000.0 | grad norm avg: 11.31 | grad norm last: 9.82 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_564000-seen_tokens_288768000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_564000-seen_tokens_288768000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_564000-seen_tokens_288768000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_564000-seen_tokens_288768000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_564000-seen_tokens_288768000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_564000-seen_tokens_288768000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_564000-seen_tokens_288768000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_564000-seen_tokens_288768000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:16:34 | step: 564100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.8415811761515215e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.71 | train loss last: 3.38 | consumed tokens: 288819200.0 | grad norm avg: 11.52 | grad norm last: 12.15 | 
2025-12-28T02:16:36 | step: 564200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.8402012907899916e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.78 | consumed tokens: 288870400.0 | grad norm avg: 11.09 | grad norm last: 11.38 | 
2025-12-28T02:16:38 | step: 564300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.8388206778327e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.62 | consumed tokens: 288921600.0 | grad norm avg: 11.03 | grad norm last: 9.34 | 
2025-12-28T02:16:40 | step: 564400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.83744042867329e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.56 | consumed tokens: 288972800.0 | grad norm avg: 11.62 | grad norm last: 9.55 | 
2025-12-28T02:16:42 | step: 564500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.836060179513879e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.67 | consumed tokens: 289024000.0 | grad norm avg: 12.02 | grad norm last: 12.12 | 
2025-12-28T02:16:44 | step: 564600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.8346799303544685e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.92 | consumed tokens: 289075200.0 | grad norm avg: 11.01 | grad norm last: 11.93 | 
2025-12-28T02:16:46 | step: 564700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.833299681195058e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.31 | consumed tokens: 289126400.0 | grad norm avg: 11.58 | grad norm last: 9.23 | 
2025-12-28T02:16:48 | step: 564800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.831919795833528e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.52 | consumed tokens: 289177600.0 | grad norm avg: 11.54 | grad norm last: 10.01 | 
2025-12-28T02:16:50 | step: 564900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.830539182876237e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.97 | consumed tokens: 289228800.0 | grad norm avg: 11.31 | grad norm last: 15.0 | 
2025-12-28T02:16:52 | step: 565000 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.8291596613125876e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.94 | consumed tokens: 289280000.0 | grad norm avg: 11.65 | grad norm last: 13.31 | 
2025-12-28T02:16:54 | step: 565100 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.827779775951058e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.73 | consumed tokens: 289331200.0 | grad norm avg: 11.25 | grad norm last: 13.05 | 
2025-12-28T02:16:56 | step: 565200 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.826399890589528e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.91 | consumed tokens: 289382400.0 | grad norm avg: 11.11 | grad norm last: 10.89 | 
2025-12-28T02:16:58 | step: 565300 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.8250203690258786e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.0 | consumed tokens: 289433600.0 | grad norm avg: 10.94 | grad norm last: 9.87 | 
2025-12-28T02:17:00 | step: 565400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.8236408474622294e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.16 | consumed tokens: 289484800.0 | grad norm avg: 11.92 | grad norm last: 10.71 | 
2025-12-28T02:17:02 | step: 565500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.822260598302819e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.19 | consumed tokens: 289536000.0 | grad norm avg: 11.21 | grad norm last: 9.91 | 
2025-12-28T02:17:04 | step: 565600 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.8208810767391697e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.36 | consumed tokens: 289587200.0 | grad norm avg: 10.62 | grad norm last: 9.06 | 
2025-12-28T02:17:06 | step: 565700 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.8195015551755205e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 5.28 | consumed tokens: 289638400.0 | grad norm avg: 11.8 | grad norm last: 21.43 | 
2025-12-28T02:17:08 | step: 565800 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.818122761207633e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.39 | consumed tokens: 289689600.0 | grad norm avg: 11.6 | grad norm last: 9.1 | 
2025-12-28T02:17:10 | step: 565900 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.8167432396439835e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.56 | consumed tokens: 289740800.0 | grad norm avg: 11.24 | grad norm last: 10.76 | 
2025-12-28T02:17:12 | step: 566000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.8153637180803344e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.17 | consumed tokens: 289792000.0 | grad norm avg: 11.83 | grad norm last: 10.22 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_566000-seen_tokens_289792000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_566000-seen_tokens_289792000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_566000-seen_tokens_289792000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_566000-seen_tokens_289792000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_566000-seen_tokens_289792000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_566000-seen_tokens_289792000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_566000-seen_tokens_289792000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_566000-seen_tokens_289792000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:17:15 | step: 566100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.813984196516685e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.7 | train loss last: 3.28 | consumed tokens: 289843200.0 | grad norm avg: 11.04 | grad norm last: 10.66 | 
2025-12-28T02:17:17 | step: 566200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.812605038750917e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.44 | consumed tokens: 289894400.0 | grad norm avg: 11.76 | grad norm last: 8.46 | 
2025-12-28T02:17:19 | step: 566300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.811225880985148e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.98 | consumed tokens: 289945600.0 | grad norm avg: 11.95 | grad norm last: 9.8 | 
2025-12-28T02:17:21 | step: 566400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.8098470870172605e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.5 | consumed tokens: 289996800.0 | grad norm avg: 11.05 | grad norm last: 9.63 | 
2025-12-28T02:17:23 | step: 566500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.808467929251492e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.55 | consumed tokens: 290048000.0 | grad norm avg: 10.91 | grad norm last: 9.82 | 
2025-12-28T02:17:25 | step: 566600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.807089499081485e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.61 | consumed tokens: 290099200.0 | grad norm avg: 11.26 | grad norm last: 8.82 | 
2025-12-28T02:17:27 | step: 566700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.8057103413157165e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.61 | consumed tokens: 290150400.0 | grad norm avg: 11.85 | grad norm last: 11.64 | 
2025-12-28T02:17:29 | step: 566800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.804331183549948e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.84 | consumed tokens: 290201600.0 | grad norm avg: 12.25 | grad norm last: 37.23 | 
2025-12-28T02:17:31 | step: 566900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.802952753379941e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.92 | consumed tokens: 290252800.0 | grad norm avg: 11.87 | grad norm last: 9.91 | 
2025-12-28T02:17:33 | step: 567000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.801574323209934e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.09 | consumed tokens: 290304000.0 | grad norm avg: 11.39 | grad norm last: 11.36 | 
2025-12-28T02:17:35 | step: 567100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.800195529242046e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.11 | consumed tokens: 290355200.0 | grad norm avg: 11.76 | grad norm last: 10.38 | 
2025-12-28T02:17:37 | step: 567200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.798817099072039e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.47 | consumed tokens: 290406400.0 | grad norm avg: 11.93 | grad norm last: 11.29 | 
2025-12-28T02:17:39 | step: 567300 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.797438668902032e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.7 | consumed tokens: 290457600.0 | grad norm avg: 11.33 | grad norm last: 11.92 | 
2025-12-28T02:17:41 | step: 567400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.796059874934144e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.97 | consumed tokens: 290508800.0 | grad norm avg: 11.18 | grad norm last: 9.96 | 
2025-12-28T02:17:43 | step: 567500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.794681808562018e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 5.56 | consumed tokens: 290560000.0 | grad norm avg: 11.8 | grad norm last: 15.09 | 
2025-12-28T02:17:45 | step: 567600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.7933037421898916e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.7 | consumed tokens: 290611200.0 | grad norm avg: 11.56 | grad norm last: 12.22 | 
2025-12-28T02:17:47 | step: 567700 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 4.7919253120198846e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.03 | consumed tokens: 290662400.0 | grad norm avg: 11.34 | grad norm last: 10.41 | 
2025-12-28T02:17:49 | step: 567800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.790547245647758e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.62 | consumed tokens: 290713600.0 | grad norm avg: 11.61 | grad norm last: 9.26 | 
2025-12-28T02:17:51 | step: 567900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.789169179275632e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.84 | consumed tokens: 290764800.0 | grad norm avg: 11.75 | grad norm last: 17.1 | 
2025-12-28T02:17:53 | step: 568000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.787791476701386e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.06 | consumed tokens: 290816000.0 | grad norm avg: 11.42 | grad norm last: 10.33 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_568000-seen_tokens_290816000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_568000-seen_tokens_290816000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_568000-seen_tokens_290816000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_568000-seen_tokens_290816000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_568000-seen_tokens_290816000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_568000-seen_tokens_290816000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_568000-seen_tokens_290816000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_568000-seen_tokens_290816000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:17:56 | step: 568100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.78641341032926e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.31 | consumed tokens: 290867200.0 | grad norm avg: 11.63 | grad norm last: 11.68 | 
2025-12-28T02:17:58 | step: 568200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.7850353439571336e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.23 | consumed tokens: 290918400.0 | grad norm avg: 12.33 | grad norm last: 18.23 | 
2025-12-28T02:18:00 | step: 568300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.783658005180769e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 2.55 | consumed tokens: 290969600.0 | grad norm avg: 11.94 | grad norm last: 8.71 | 
2025-12-28T02:18:02 | step: 568400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.782279938808642e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 5.09 | consumed tokens: 291020800.0 | grad norm avg: 11.58 | grad norm last: 22.8 | 
2025-12-28T02:18:04 | step: 568500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.7809026000322774e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.14 | consumed tokens: 291072000.0 | grad norm avg: 11.49 | grad norm last: 9.69 | 
2025-12-28T02:18:06 | step: 568600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 4.7795252612559125e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.19 | consumed tokens: 291123200.0 | grad norm avg: 11.27 | grad norm last: 10.39 | 
2025-12-28T02:18:08 | step: 568700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.778147558681667e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.81 | consumed tokens: 291174400.0 | grad norm avg: 11.2 | grad norm last: 10.97 | 
2025-12-28T02:18:10 | step: 568800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.776769856107421e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.17 | consumed tokens: 291225600.0 | grad norm avg: 11.43 | grad norm last: 10.44 | 
2025-12-28T02:18:12 | step: 568900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.775392517331056e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.06 | consumed tokens: 291276800.0 | grad norm avg: 11.04 | grad norm last: 11.44 | 
2025-12-28T02:18:14 | step: 569000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.774015906150453e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.44 | consumed tokens: 291328000.0 | grad norm avg: 11.7 | grad norm last: 10.49 | 
2025-12-28T02:18:16 | step: 569100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.772638203576207e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.83 | consumed tokens: 291379200.0 | grad norm avg: 11.92 | grad norm last: 13.72 | 
2025-12-28T02:18:18 | step: 569200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.7712605010019615e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.86 | consumed tokens: 291430400.0 | grad norm avg: 12.34 | grad norm last: 10.29 | 
2025-12-28T02:18:20 | step: 569300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.769883889821358e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.5 | consumed tokens: 291481600.0 | grad norm avg: 12.96 | grad norm last: 10.03 | 
2025-12-28T02:18:22 | step: 569400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.768506914842874e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.97 | consumed tokens: 291532800.0 | grad norm avg: 11.57 | grad norm last: 16.51 | 
2025-12-28T02:18:24 | step: 569500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.7671299398643896e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.62 | consumed tokens: 291584000.0 | grad norm avg: 11.51 | grad norm last: 10.87 | 
2025-12-28T02:18:26 | step: 569600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.765753328683786e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.53 | consumed tokens: 291635200.0 | grad norm avg: 11.4 | grad norm last: 10.87 | 
2025-12-28T02:18:28 | step: 569700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.7643767175031826e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.62 | consumed tokens: 291686400.0 | grad norm avg: 11.68 | grad norm last: 11.69 | 
2025-12-28T02:18:30 | step: 569800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.763000106322579e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 2.84 | consumed tokens: 291737600.0 | grad norm avg: 11.58 | grad norm last: 8.43 | 
2025-12-28T02:18:32 | step: 569900 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.7616234951419756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.84 | consumed tokens: 291788800.0 | grad norm avg: 12.22 | grad norm last: 10.45 | 
2025-12-28T02:18:34 | step: 570000 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.760246883961372e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.94 | consumed tokens: 291840000.0 | grad norm avg: 12.26 | grad norm last: 11.35 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_570000-seen_tokens_291840000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_570000-seen_tokens_291840000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_570000-seen_tokens_291840000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_570000-seen_tokens_291840000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_570000-seen_tokens_291840000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_570000-seen_tokens_291840000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_570000-seen_tokens_291840000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_570000-seen_tokens_291840000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:18:37 | step: 570100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.7588702727807686e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.64 | consumed tokens: 291891200.0 | grad norm avg: 11.95 | grad norm last: 13.07 | 
2025-12-28T02:18:39 | step: 570200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.757493661600165e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.2 | consumed tokens: 291942400.0 | grad norm avg: 11.93 | grad norm last: 9.64 | 
2025-12-28T02:18:41 | step: 570300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.7561170504195616e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.66 | consumed tokens: 291993600.0 | grad norm avg: 11.41 | grad norm last: 10.41 | 
2025-12-28T02:18:43 | step: 570400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.754740803036839e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.23 | consumed tokens: 292044800.0 | grad norm avg: 11.41 | grad norm last: 11.19 | 
2025-12-28T02:18:45 | step: 570500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.753364555654116e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.67 | consumed tokens: 292096000.0 | grad norm avg: 11.48 | grad norm last: 10.56 | 
2025-12-28T02:18:47 | step: 570600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.751988672069274e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.59 | consumed tokens: 292147200.0 | grad norm avg: 12.23 | grad norm last: 9.7 | 
2025-12-28T02:18:49 | step: 570700 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.750612424686551e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.09 | consumed tokens: 292198400.0 | grad norm avg: 11.43 | grad norm last: 10.77 | 
2025-12-28T02:18:51 | step: 570800 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.74923690489959e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.25 | consumed tokens: 292249600.0 | grad norm avg: 11.28 | grad norm last: 9.25 | 
2025-12-28T02:18:53 | step: 570900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.747860657516867e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.97 | consumed tokens: 292300800.0 | grad norm avg: 11.94 | grad norm last: 12.55 | 
2025-12-28T02:18:55 | step: 571000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.746484410134144e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.31 | consumed tokens: 292352000.0 | grad norm avg: 13.0 | grad norm last: 10.85 | 
2025-12-28T02:18:57 | step: 571100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.745108890347183e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.3 | consumed tokens: 292403200.0 | grad norm avg: 12.14 | grad norm last: 9.84 | 
2025-12-28T02:18:59 | step: 571200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.7437333705602214e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.47 | consumed tokens: 292454400.0 | grad norm avg: 12.54 | grad norm last: 10.34 | 
2025-12-28T02:19:01 | step: 571300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.742357486975379e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.27 | consumed tokens: 292505600.0 | grad norm avg: 11.95 | grad norm last: 11.43 | 
2025-12-28T02:19:03 | step: 571400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.740981967188418e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.44 | consumed tokens: 292556800.0 | grad norm avg: 11.71 | grad norm last: 9.12 | 
2025-12-28T02:19:05 | step: 571500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.7396064474014565e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.33 | consumed tokens: 292608000.0 | grad norm avg: 12.78 | grad norm last: 9.77 | 
2025-12-28T02:19:07 | step: 571600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.7382305638166144e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.94 | consumed tokens: 292659200.0 | grad norm avg: 11.72 | grad norm last: 13.48 | 
2025-12-28T02:19:09 | step: 571700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.736856135423295e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.8 | consumed tokens: 292710400.0 | grad norm avg: 12.33 | grad norm last: 13.34 | 
2025-12-28T02:19:11 | step: 571800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.735480251838453e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.5 | consumed tokens: 292761600.0 | grad norm avg: 12.05 | grad norm last: 10.11 | 
2025-12-28T02:19:13 | step: 571900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.7341050958493724e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.91 | consumed tokens: 292812800.0 | grad norm avg: 11.52 | grad norm last: 9.98 | 
2025-12-28T02:19:15 | step: 572000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.732729939860292e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.84 | consumed tokens: 292864000.0 | grad norm avg: 12.42 | grad norm last: 9.82 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_572000-seen_tokens_292864000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_572000-seen_tokens_292864000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_572000-seen_tokens_292864000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_572000-seen_tokens_292864000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_572000-seen_tokens_292864000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_572000-seen_tokens_292864000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_572000-seen_tokens_292864000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_572000-seen_tokens_292864000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:19:18 | step: 572100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.7313555114669725e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.71 | train loss last: 3.94 | consumed tokens: 292915200.0 | grad norm avg: 11.94 | grad norm last: 10.92 | 
2025-12-28T02:19:20 | step: 572200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.7299796278821304e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.8 | consumed tokens: 292966400.0 | grad norm avg: 12.09 | grad norm last: 11.89 | 
2025-12-28T02:19:22 | step: 572300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.728605199488811e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.12 | consumed tokens: 293017600.0 | grad norm avg: 12.0 | grad norm last: 11.07 | 
2025-12-28T02:19:24 | step: 572400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.727230407297611e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.38 | consumed tokens: 293068800.0 | grad norm avg: 11.91 | grad norm last: 10.82 | 
2025-12-28T02:19:26 | step: 572500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.725855615106411e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.28 | consumed tokens: 293120000.0 | grad norm avg: 11.92 | grad norm last: 8.91 | 
2025-12-28T02:19:28 | step: 572600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.724481186713092e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.19 | consumed tokens: 293171200.0 | grad norm avg: 12.07 | grad norm last: 14.16 | 
2025-12-28T02:19:30 | step: 572700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.723106394521892e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.61 | consumed tokens: 293222400.0 | grad norm avg: 12.16 | grad norm last: 10.67 | 
2025-12-28T02:19:32 | step: 572800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.721731602330692e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.58 | consumed tokens: 293273600.0 | grad norm avg: 11.99 | grad norm last: 9.97 | 
2025-12-28T02:19:34 | step: 572900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.720357173937373e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.12 | consumed tokens: 293324800.0 | grad norm avg: 12.04 | grad norm last: 15.22 | 
2025-12-28T02:19:36 | step: 573000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.7189827455440536e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.31 | consumed tokens: 293376000.0 | grad norm avg: 11.59 | grad norm last: 10.22 | 
2025-12-28T02:19:38 | step: 573100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.717608680948615e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.2 | consumed tokens: 293427200.0 | grad norm avg: 11.74 | grad norm last: 10.01 | 
2025-12-28T02:19:40 | step: 573200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.716233888757415e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.97 | consumed tokens: 293478400.0 | grad norm avg: 11.26 | grad norm last: 10.81 | 
2025-12-28T02:19:42 | step: 573300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.714860187959857e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.31 | consumed tokens: 293529600.0 | grad norm avg: 12.29 | grad norm last: 9.29 | 
2025-12-28T02:19:44 | step: 573400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.713486123364419e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.61 | consumed tokens: 293580800.0 | grad norm avg: 12.13 | grad norm last: 9.48 | 
2025-12-28T02:19:46 | step: 573500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.71211205876898e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.67 | consumed tokens: 293632000.0 | grad norm avg: 13.0 | grad norm last: 9.05 | 
2025-12-28T02:19:48 | step: 573600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.7107383579714224e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.75 | consumed tokens: 293683200.0 | grad norm avg: 11.21 | grad norm last: 12.62 | 
2025-12-28T02:19:50 | step: 573700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.7093646571738645e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.83 | consumed tokens: 293734400.0 | grad norm avg: 11.79 | grad norm last: 9.63 | 
2025-12-28T02:19:52 | step: 573800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.707990956376307e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.23 | consumed tokens: 293785600.0 | grad norm avg: 11.58 | grad norm last: 10.7 | 
2025-12-28T02:19:54 | step: 573900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.706617255578749e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.16 | consumed tokens: 293836800.0 | grad norm avg: 11.23 | grad norm last: 12.07 | 
2025-12-28T02:19:56 | step: 574000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.705243554781191e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.47 | consumed tokens: 293888000.0 | grad norm avg: 11.73 | grad norm last: 14.0 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_574000-seen_tokens_293888000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_574000-seen_tokens_293888000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_574000-seen_tokens_293888000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_574000-seen_tokens_293888000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_574000-seen_tokens_293888000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_574000-seen_tokens_293888000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_574000-seen_tokens_293888000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_574000-seen_tokens_293888000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:19:58 | step: 574100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 4.703869853983633e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.75 | train loss last: 3.62 | consumed tokens: 293939200.0 | grad norm avg: 12.49 | grad norm last: 9.78 | 
2025-12-28T02:20:00 | step: 574200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.7024961531860754e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.75 | consumed tokens: 293990400.0 | grad norm avg: 11.29 | grad norm last: 13.94 | 
2025-12-28T02:20:02 | step: 574300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 4.701122816186398e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.47 | consumed tokens: 294041600.0 | grad norm avg: 11.9 | grad norm last: 9.92 | 
2025-12-28T02:20:04 | step: 574400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.699749479186721e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.2 | consumed tokens: 294092800.0 | grad norm avg: 11.25 | grad norm last: 8.94 | 
2025-12-28T02:20:06 | step: 574500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 4.698375778389163e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.44 | consumed tokens: 294144000.0 | grad norm avg: 11.87 | grad norm last: 11.96 | 
2025-12-28T02:20:08 | step: 574600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 4.6970031689852476e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.94 | consumed tokens: 294195200.0 | grad norm avg: 12.27 | grad norm last: 13.43 | 
2025-12-28T02:20:10 | step: 574700 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 4.6956298319855705e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.39 | consumed tokens: 294246400.0 | grad norm avg: 12.24 | grad norm last: 9.93 | 
2025-12-28T02:20:12 | step: 574800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.694256858783774e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.69 | consumed tokens: 294297600.0 | grad norm avg: 11.53 | grad norm last: 12.34 | 
2025-12-28T02:20:15 | step: 574900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.692883885581978e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.33 | consumed tokens: 294348800.0 | grad norm avg: 12.02 | grad norm last: 8.71 | 
2025-12-28T02:20:17 | step: 575000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.691511276178062e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.56 | consumed tokens: 294400000.0 | grad norm avg: 11.67 | grad norm last: 8.31 | 
2025-12-28T02:20:19 | step: 575100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.690138666774146e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.55 | consumed tokens: 294451200.0 | grad norm avg: 11.74 | grad norm last: 8.97 | 
2025-12-28T02:20:21 | step: 575200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.68876569357235e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.88 | consumed tokens: 294502400.0 | grad norm avg: 12.18 | grad norm last: 11.79 | 
2025-12-28T02:20:23 | step: 575300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.687393084168434e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 2.83 | consumed tokens: 294553600.0 | grad norm avg: 11.57 | grad norm last: 8.61 | 
2025-12-28T02:20:25 | step: 575400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.6860204747645184e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.97 | consumed tokens: 294604800.0 | grad norm avg: 11.61 | grad norm last: 10.62 | 
2025-12-28T02:20:27 | step: 575500 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.684647501562722e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.44 | consumed tokens: 294656000.0 | grad norm avg: 12.74 | grad norm last: 15.78 | 
2025-12-28T02:20:29 | step: 575600 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.6832759835524485e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.55 | consumed tokens: 294707200.0 | grad norm avg: 11.07 | grad norm last: 10.12 | 
2025-12-28T02:20:31 | step: 575700 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.681903010350652e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.09 | consumed tokens: 294758400.0 | grad norm avg: 11.22 | grad norm last: 12.31 | 
2025-12-28T02:20:33 | step: 575800 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.6805314923403785e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.12 | consumed tokens: 294809600.0 | grad norm avg: 11.9 | grad norm last: 13.14 | 
2025-12-28T02:20:35 | step: 575900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.679158519138582e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.48 | consumed tokens: 294860800.0 | grad norm avg: 11.14 | grad norm last: 10.53 | 
2025-12-28T02:20:37 | step: 576000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.6777870011283085e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.22 | consumed tokens: 294912000.0 | grad norm avg: 11.16 | grad norm last: 13.68 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_576000-seen_tokens_294912000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_576000-seen_tokens_294912000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_576000-seen_tokens_294912000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_576000-seen_tokens_294912000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_576000-seen_tokens_294912000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_576000-seen_tokens_294912000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_576000-seen_tokens_294912000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_576000-seen_tokens_294912000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:20:39 | step: 576100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.6764147555222735e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.7 | train loss last: 3.8 | consumed tokens: 294963200.0 | grad norm avg: 11.91 | grad norm last: 10.35 | 
2025-12-28T02:20:41 | step: 576200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.675042873714119e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.94 | consumed tokens: 295014400.0 | grad norm avg: 11.94 | grad norm last: 18.66 | 
2025-12-28T02:20:43 | step: 576300 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 4.673670991905965e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.98 | consumed tokens: 295065600.0 | grad norm avg: 11.3 | grad norm last: 11.21 | 
2025-12-28T02:20:45 | step: 576400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.672299473895691e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.22 | consumed tokens: 295116800.0 | grad norm avg: 11.04 | grad norm last: 9.08 | 
2025-12-28T02:20:47 | step: 576500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.670927592087537e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.11 | consumed tokens: 295168000.0 | grad norm avg: 11.85 | grad norm last: 10.42 | 
2025-12-28T02:20:49 | step: 576600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.669556437875144e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.86 | consumed tokens: 295219200.0 | grad norm avg: 11.94 | grad norm last: 12.49 | 
2025-12-28T02:20:52 | step: 576700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.66818455606699e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.8 | consumed tokens: 295270400.0 | grad norm avg: 11.57 | grad norm last: 9.3 | 
2025-12-28T02:20:54 | step: 576800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.6668126742588356e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.41 | consumed tokens: 295321600.0 | grad norm avg: 11.65 | grad norm last: 12.08 | 
2025-12-28T02:20:56 | step: 576900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.6654418838443235e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.23 | consumed tokens: 295372800.0 | grad norm avg: 11.08 | grad norm last: 8.29 | 
2025-12-28T02:20:58 | step: 577000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.66407036583405e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.53 | consumed tokens: 295424000.0 | grad norm avg: 11.8 | grad norm last: 9.74 | 
2025-12-28T02:21:00 | step: 577100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.662699575419538e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.45 | consumed tokens: 295475200.0 | grad norm avg: 10.89 | grad norm last: 9.62 | 
2025-12-28T02:21:02 | step: 577200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.661328057409264e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.05 | consumed tokens: 295526400.0 | grad norm avg: 11.09 | grad norm last: 9.52 | 
2025-12-28T02:21:04 | step: 577300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.659957266994752e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.91 | consumed tokens: 295577600.0 | grad norm avg: 11.21 | grad norm last: 16.43 | 
2025-12-28T02:21:06 | step: 577400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.658586112782359e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.53 | consumed tokens: 295628800.0 | grad norm avg: 11.55 | grad norm last: 10.99 | 
2025-12-28T02:21:08 | step: 577500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.657215322367847e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.09 | consumed tokens: 295680000.0 | grad norm avg: 11.35 | grad norm last: 10.91 | 
2025-12-28T02:21:10 | step: 577600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.655844531953335e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.34 | consumed tokens: 295731200.0 | grad norm avg: 11.95 | grad norm last: 9.26 | 
2025-12-28T02:21:12 | step: 577700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.6544737415388227e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.41 | consumed tokens: 295782400.0 | grad norm avg: 11.24 | grad norm last: 13.82 | 
2025-12-28T02:21:14 | step: 577800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.653103314922191e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 2.95 | consumed tokens: 295833600.0 | grad norm avg: 11.2 | grad norm last: 9.31 | 
2025-12-28T02:21:16 | step: 577900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.651732524507679e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.59 | consumed tokens: 295884800.0 | grad norm avg: 11.36 | grad norm last: 12.62 | 
2025-12-28T02:21:18 | step: 578000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.650362461688928e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.5 | consumed tokens: 295936000.0 | grad norm avg: 11.89 | grad norm last: 14.39 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_578000-seen_tokens_295936000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_578000-seen_tokens_295936000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_578000-seen_tokens_295936000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_578000-seen_tokens_295936000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_578000-seen_tokens_295936000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_578000-seen_tokens_295936000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_578000-seen_tokens_295936000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_578000-seen_tokens_295936000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:21:20 | step: 578100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.648991671274416e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.69 | train loss last: 3.31 | consumed tokens: 295987200.0 | grad norm avg: 10.92 | grad norm last: 9.31 | 
2025-12-28T02:21:22 | step: 578200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.6476216084556654e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.16 | consumed tokens: 296038400.0 | grad norm avg: 11.4 | grad norm last: 11.04 | 
2025-12-28T02:21:24 | step: 578300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.646250818041153e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.11 | consumed tokens: 296089600.0 | grad norm avg: 10.95 | grad norm last: 9.64 | 
2025-12-28T02:21:26 | step: 578400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.644881119020283e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.34 | consumed tokens: 296140800.0 | grad norm avg: 11.33 | grad norm last: 14.49 | 
2025-12-28T02:21:28 | step: 578500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.643511419999413e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.66 | consumed tokens: 296192000.0 | grad norm avg: 11.15 | grad norm last: 9.45 | 
2025-12-28T02:21:30 | step: 578600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.642140993382782e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.86 | train loss last: 4.16 | consumed tokens: 296243200.0 | grad norm avg: 11.56 | grad norm last: 10.5 | 
2025-12-28T02:21:32 | step: 578700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.640771294361912e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.53 | consumed tokens: 296294400.0 | grad norm avg: 10.76 | grad norm last: 11.15 | 
2025-12-28T02:21:34 | step: 578800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.639401231543161e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.77 | consumed tokens: 296345600.0 | grad norm avg: 10.93 | grad norm last: 9.37 | 
2025-12-28T02:21:36 | step: 578900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.638031532522291e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.81 | consumed tokens: 296396800.0 | grad norm avg: 10.89 | grad norm last: 11.97 | 
2025-12-28T02:21:38 | step: 579000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.6366621972993016e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.47 | consumed tokens: 296448000.0 | grad norm avg: 10.75 | grad norm last: 14.63 | 
2025-12-28T02:21:40 | step: 579100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.6352924982784316e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.55 | consumed tokens: 296499200.0 | grad norm avg: 10.59 | grad norm last: 8.71 | 
2025-12-28T02:21:42 | step: 579200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.633923163055442e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.19 | consumed tokens: 296550400.0 | grad norm avg: 11.17 | grad norm last: 10.23 | 
2025-12-28T02:21:44 | step: 579300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.632553827832453e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.22 | consumed tokens: 296601600.0 | grad norm avg: 10.58 | grad norm last: 8.22 | 
2025-12-28T02:21:46 | step: 579400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.631183765013702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.39 | consumed tokens: 296652800.0 | grad norm avg: 11.16 | grad norm last: 9.22 | 
2025-12-28T02:21:48 | step: 579500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.629815157386474e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.55 | consumed tokens: 296704000.0 | grad norm avg: 10.89 | grad norm last: 9.18 | 
2025-12-28T02:21:50 | step: 579600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 4.628445822163485e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.39 | consumed tokens: 296755200.0 | grad norm avg: 11.22 | grad norm last: 10.29 | 
2025-12-28T02:21:53 | step: 579700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.6270768507383764e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.91 | consumed tokens: 296806400.0 | grad norm avg: 11.18 | grad norm last: 9.35 | 
2025-12-28T02:21:55 | step: 579800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.625707879313268e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.44 | consumed tokens: 296857600.0 | grad norm avg: 11.04 | grad norm last: 10.35 | 
2025-12-28T02:21:57 | step: 579900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.6243385440902784e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.27 | consumed tokens: 296908800.0 | grad norm avg: 10.99 | grad norm last: 9.41 | 
2025-12-28T02:21:59 | step: 580000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 4.622970300260931e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.45 | consumed tokens: 296960000.0 | grad norm avg: 11.22 | grad norm last: 9.89 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_580000-seen_tokens_296960000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_580000-seen_tokens_296960000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_580000-seen_tokens_296960000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_580000-seen_tokens_296960000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_580000-seen_tokens_296960000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_580000-seen_tokens_296960000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_580000-seen_tokens_296960000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_580000-seen_tokens_296960000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:22:01 | step: 580100 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.6216013288358226e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.25 | consumed tokens: 297011200.0 | grad norm avg: 10.94 | grad norm last: 12.97 | 
2025-12-28T02:22:03 | step: 580200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.620232721208595e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.36 | consumed tokens: 297062400.0 | grad norm avg: 11.07 | grad norm last: 8.69 | 
2025-12-28T02:22:05 | step: 580300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.618864113581367e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.59 | consumed tokens: 297113600.0 | grad norm avg: 11.09 | grad norm last: 9.09 | 
2025-12-28T02:22:07 | step: 580400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.6174958697520196e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.52 | consumed tokens: 297164800.0 | grad norm avg: 10.99 | grad norm last: 11.95 | 
2025-12-28T02:22:09 | step: 580500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.6161276259226725e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.88 | train loss last: 6.0 | consumed tokens: 297216000.0 | grad norm avg: 12.34 | grad norm last: 13.74 | 
2025-12-28T02:22:11 | step: 580600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.6147590182954445e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 3.16 | consumed tokens: 297267200.0 | grad norm avg: 11.41 | grad norm last: 9.62 | 
2025-12-28T02:22:13 | step: 580700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.6133907744660974e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.81 | consumed tokens: 297318400.0 | grad norm avg: 10.99 | grad norm last: 10.67 | 
2025-12-28T02:22:15 | step: 580800 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.612022894434631e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.84 | consumed tokens: 297369600.0 | grad norm avg: 10.64 | grad norm last: 10.78 | 
2025-12-28T02:22:17 | step: 580900 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.610654650605284e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.7 | consumed tokens: 297420800.0 | grad norm avg: 10.93 | grad norm last: 10.51 | 
2025-12-28T02:22:19 | step: 581000 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.609286770573817e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.36 | consumed tokens: 297472000.0 | grad norm avg: 11.49 | grad norm last: 9.2 | 
2025-12-28T02:22:21 | step: 581100 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.607918890542351e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.34 | consumed tokens: 297523200.0 | grad norm avg: 11.36 | grad norm last: 10.1 | 
2025-12-28T02:22:23 | step: 581200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.606551010510884e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.38 | consumed tokens: 297574400.0 | grad norm avg: 11.26 | grad norm last: 17.85 | 
2025-12-28T02:22:25 | step: 581300 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.6051834942772985e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.88 | consumed tokens: 297625600.0 | grad norm avg: 10.81 | grad norm last: 10.81 | 
2025-12-28T02:22:28 | step: 581400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.603815978043713e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.27 | consumed tokens: 297676800.0 | grad norm avg: 10.7 | grad norm last: 9.77 | 
2025-12-28T02:22:30 | step: 581500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.6024488256080076e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.3 | consumed tokens: 297728000.0 | grad norm avg: 10.63 | grad norm last: 10.12 | 
2025-12-28T02:22:32 | step: 581600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.601080945576541e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 2.94 | consumed tokens: 297779200.0 | grad norm avg: 10.78 | grad norm last: 7.99 | 
2025-12-28T02:22:34 | step: 581700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.5997134293429554e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.55 | consumed tokens: 297830400.0 | grad norm avg: 10.77 | grad norm last: 8.73 | 
2025-12-28T02:22:36 | step: 581800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.5983459131093696e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 4.12 | consumed tokens: 297881600.0 | grad norm avg: 11.39 | grad norm last: 10.23 | 
2025-12-28T02:22:38 | step: 581900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.596979124471545e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.0 | consumed tokens: 297932800.0 | grad norm avg: 10.88 | grad norm last: 11.17 | 
2025-12-28T02:22:40 | step: 582000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.595612335833721e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.67 | consumed tokens: 297984000.0 | grad norm avg: 10.62 | grad norm last: 11.05 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_582000-seen_tokens_297984000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_582000-seen_tokens_297984000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_582000-seen_tokens_297984000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_582000-seen_tokens_297984000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_582000-seen_tokens_297984000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_582000-seen_tokens_297984000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_582000-seen_tokens_297984000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_582000-seen_tokens_297984000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:22:42 | step: 582100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.594244819600135e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.7 | train loss last: 4.19 | consumed tokens: 298035200.0 | grad norm avg: 10.94 | grad norm last: 12.83 | 
2025-12-28T02:22:44 | step: 582200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.592878030962311e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.64 | consumed tokens: 298086400.0 | grad norm avg: 11.0 | grad norm last: 10.55 | 
2025-12-28T02:22:46 | step: 582300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.591511606122367e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.28 | consumed tokens: 298137600.0 | grad norm avg: 10.81 | grad norm last: 13.4 | 
2025-12-28T02:22:48 | step: 582400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.590144453686662e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.41 | consumed tokens: 298188800.0 | grad norm avg: 11.12 | grad norm last: 9.7 | 
2025-12-28T02:22:50 | step: 582500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.588777665048838e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.11 | consumed tokens: 298240000.0 | grad norm avg: 10.56 | grad norm last: 9.78 | 
2025-12-28T02:22:52 | step: 582600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.587411240208894e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.84 | consumed tokens: 298291200.0 | grad norm avg: 11.08 | grad norm last: 10.1 | 
2025-12-28T02:22:54 | step: 582700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.5860448153689504e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.11 | consumed tokens: 298342400.0 | grad norm avg: 10.72 | grad norm last: 8.78 | 
2025-12-28T02:22:56 | step: 582800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.584678390529007e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.09 | consumed tokens: 298393600.0 | grad norm avg: 10.75 | grad norm last: 9.91 | 
2025-12-28T02:22:58 | step: 582900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.583311965689063e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.52 | consumed tokens: 298444800.0 | grad norm avg: 10.89 | grad norm last: 9.58 | 
2025-12-28T02:23:00 | step: 583000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.581945904647e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.06 | consumed tokens: 298496000.0 | grad norm avg: 10.92 | grad norm last: 9.41 | 
2025-12-28T02:23:02 | step: 583100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.5805794798070565e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.27 | consumed tokens: 298547200.0 | grad norm avg: 11.02 | grad norm last: 11.66 | 
2025-12-28T02:23:04 | step: 583200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.579213782562874e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.72 | consumed tokens: 298598400.0 | grad norm avg: 10.44 | grad norm last: 11.36 | 
2025-12-28T02:23:06 | step: 583300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.577847721520811e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 2.89 | consumed tokens: 298649600.0 | grad norm avg: 11.16 | grad norm last: 9.88 | 
2025-12-28T02:23:08 | step: 583400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.5764816604787484e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.55 | consumed tokens: 298700800.0 | grad norm avg: 10.54 | grad norm last: 12.21 | 
2025-12-28T02:23:10 | step: 583500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.575115963234566e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.8 | consumed tokens: 298752000.0 | grad norm avg: 11.19 | grad norm last: 9.96 | 
2025-12-28T02:23:12 | step: 583600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.573750265990384e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.7 | consumed tokens: 298803200.0 | grad norm avg: 11.47 | grad norm last: 10.2 | 
2025-12-28T02:23:14 | step: 583700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.572384568746202e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.42 | consumed tokens: 298854400.0 | grad norm avg: 11.11 | grad norm last: 9.56 | 
2025-12-28T02:23:16 | step: 583800 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.571019599097781e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.03 | consumed tokens: 298905600.0 | grad norm avg: 11.0 | grad norm last: 22.02 | 
2025-12-28T02:23:19 | step: 583900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.5696539018535987e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.11 | consumed tokens: 298956800.0 | grad norm avg: 10.57 | grad norm last: 9.03 | 
2025-12-28T02:23:21 | step: 584000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 4.568288568407297e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.25 | consumed tokens: 299008000.0 | grad norm avg: 11.05 | grad norm last: 10.56 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_584000-seen_tokens_299008000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_584000-seen_tokens_299008000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_584000-seen_tokens_299008000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_584000-seen_tokens_299008000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_584000-seen_tokens_299008000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_584000-seen_tokens_299008000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_584000-seen_tokens_299008000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_584000-seen_tokens_299008000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:23:23 | step: 584100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.5669232349609956e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.06 | consumed tokens: 299059200.0 | grad norm avg: 10.66 | grad norm last: 10.31 | 
2025-12-28T02:23:25 | step: 584200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 4.5655575377168134e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.3 | consumed tokens: 299110400.0 | grad norm avg: 10.72 | grad norm last: 9.39 | 
2025-12-28T02:23:27 | step: 584300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.5641925680683926e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.19 | consumed tokens: 299161600.0 | grad norm avg: 10.55 | grad norm last: 10.47 | 
2025-12-28T02:23:29 | step: 584400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 4.562827598419972e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.42 | consumed tokens: 299212800.0 | grad norm avg: 10.85 | grad norm last: 9.78 | 
2025-12-28T02:23:31 | step: 584500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.561462628771551e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.66 | consumed tokens: 299264000.0 | grad norm avg: 10.54 | grad norm last: 13.13 | 
2025-12-28T02:23:33 | step: 584600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.5600983867188916e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.55 | consumed tokens: 299315200.0 | grad norm avg: 10.7 | grad norm last: 11.29 | 
2025-12-28T02:23:35 | step: 584700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 4.5587337808683515e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.89 | consumed tokens: 299366400.0 | grad norm avg: 10.85 | grad norm last: 10.27 | 
2025-12-28T02:23:37 | step: 584800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.5573691750178114e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.34 | consumed tokens: 299417600.0 | grad norm avg: 11.08 | grad norm last: 10.89 | 
2025-12-28T02:23:39 | step: 584900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.556004932965152e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.19 | consumed tokens: 299468800.0 | grad norm avg: 10.94 | grad norm last: 10.0 | 
2025-12-28T02:23:41 | step: 585000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.554639963316731e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.45 | consumed tokens: 299520000.0 | grad norm avg: 11.54 | grad norm last: 9.85 | 
2025-12-28T02:23:43 | step: 585100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.553275721264072e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.72 | consumed tokens: 299571200.0 | grad norm avg: 11.64 | grad norm last: 14.24 | 
2025-12-28T02:23:45 | step: 585200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.5519114792114124e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.97 | consumed tokens: 299622400.0 | grad norm avg: 10.65 | grad norm last: 9.88 | 
2025-12-28T02:23:47 | step: 585300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.550547237158753e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.03 | consumed tokens: 299673600.0 | grad norm avg: 10.79 | grad norm last: 16.48 | 
2025-12-28T02:23:49 | step: 585400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.549183358903974e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.16 | consumed tokens: 299724800.0 | grad norm avg: 10.98 | grad norm last: 11.44 | 
2025-12-28T02:23:51 | step: 585500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.5478194806491956e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.61 | consumed tokens: 299776000.0 | grad norm avg: 10.98 | grad norm last: 9.83 | 
2025-12-28T02:23:53 | step: 585600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.5464559661922976e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.8 | consumed tokens: 299827200.0 | grad norm avg: 10.89 | grad norm last: 11.63 | 
2025-12-28T02:23:55 | step: 585700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.545091724139638e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.67 | consumed tokens: 299878400.0 | grad norm avg: 10.65 | grad norm last: 10.17 | 
2025-12-28T02:23:57 | step: 585800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.5437278458848596e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.8 | consumed tokens: 299929600.0 | grad norm avg: 10.58 | grad norm last: 10.41 | 
2025-12-28T02:23:59 | step: 585900 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.5423643314279616e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.34 | consumed tokens: 299980800.0 | grad norm avg: 10.98 | grad norm last: 9.23 | 
2025-12-28T02:24:02 | step: 586000 | train samples/s: 96.9 | train mfu (16-bit): -1.0 | lr mean: 4.5410008169710636e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.22 | consumed tokens: 300032000.0 | grad norm avg: 11.05 | grad norm last: 11.29 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_586000-seen_tokens_300032000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_586000-seen_tokens_300032000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_586000-seen_tokens_300032000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_586000-seen_tokens_300032000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_586000-seen_tokens_300032000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_586000-seen_tokens_300032000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_586000-seen_tokens_300032000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_586000-seen_tokens_300032000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:24:04 | step: 586100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.5396373025141656e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.75 | train loss last: 3.97 | consumed tokens: 300083200.0 | grad norm avg: 11.25 | grad norm last: 10.47 | 
2025-12-28T02:24:06 | step: 586200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.5382741518551484e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.91 | consumed tokens: 300134400.0 | grad norm avg: 11.1 | grad norm last: 12.77 | 
2025-12-28T02:24:08 | step: 586300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.5369106373982504e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.22 | consumed tokens: 300185600.0 | grad norm avg: 11.25 | grad norm last: 9.5 | 
2025-12-28T02:24:10 | step: 586400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.535547850537114e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.12 | consumed tokens: 300236800.0 | grad norm avg: 10.96 | grad norm last: 9.51 | 
2025-12-28T02:24:12 | step: 586500 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.5341846998780966e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.55 | consumed tokens: 300288000.0 | grad norm avg: 10.92 | grad norm last: 9.37 | 
2025-12-28T02:24:14 | step: 586600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.532821549219079e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.88 | consumed tokens: 300339200.0 | grad norm avg: 11.42 | grad norm last: 12.23 | 
2025-12-28T02:24:16 | step: 586700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.531458762357943e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.31 | consumed tokens: 300390400.0 | grad norm avg: 10.78 | grad norm last: 18.85 | 
2025-12-28T02:24:18 | step: 586800 | train samples/s: 102.1 | train mfu (16-bit): -1.0 | lr mean: 4.530095975496806e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.03 | consumed tokens: 300441600.0 | grad norm avg: 10.85 | grad norm last: 12.49 | 
2025-12-28T02:24:20 | step: 586900 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.5287335524335504e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.12 | consumed tokens: 300492800.0 | grad norm avg: 11.54 | grad norm last: 11.17 | 
2025-12-28T02:24:22 | step: 587000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.527370401774533e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.58 | consumed tokens: 300544000.0 | grad norm avg: 10.52 | grad norm last: 11.25 | 
2025-12-28T02:24:24 | step: 587100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.526008342509158e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.94 | consumed tokens: 300595200.0 | grad norm avg: 11.66 | grad norm last: 10.95 | 
2025-12-28T02:24:26 | step: 587200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.524645919445902e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.77 | consumed tokens: 300646400.0 | grad norm avg: 10.81 | grad norm last: 11.25 | 
2025-12-28T02:24:28 | step: 587300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.523283496382646e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.73 | consumed tokens: 300697600.0 | grad norm avg: 10.94 | grad norm last: 12.01 | 
2025-12-28T02:24:30 | step: 587400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.521921437117271e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.67 | consumed tokens: 300748800.0 | grad norm avg: 10.58 | grad norm last: 11.57 | 
2025-12-28T02:24:32 | step: 587500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.520559377851896e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.52 | consumed tokens: 300800000.0 | grad norm avg: 10.96 | grad norm last: 11.06 | 
2025-12-28T02:24:34 | step: 587600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.519197318586521e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.38 | consumed tokens: 300851200.0 | grad norm avg: 10.85 | grad norm last: 11.62 | 
2025-12-28T02:24:36 | step: 587700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.517835259321146e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.59 | consumed tokens: 300902400.0 | grad norm avg: 10.85 | grad norm last: 10.95 | 
2025-12-28T02:24:39 | step: 587800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.516473563853651e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.19 | consumed tokens: 300953600.0 | grad norm avg: 10.82 | grad norm last: 11.75 | 
2025-12-28T02:24:41 | step: 587900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.515111868386157e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.33 | consumed tokens: 301004800.0 | grad norm avg: 10.94 | grad norm last: 12.62 | 
2025-12-28T02:24:43 | step: 588000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.513749809120782e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 4.0 | consumed tokens: 301056000.0 | grad norm avg: 10.83 | grad norm last: 11.35 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_588000-seen_tokens_301056000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_588000-seen_tokens_301056000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_588000-seen_tokens_301056000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_588000-seen_tokens_301056000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_588000-seen_tokens_301056000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_588000-seen_tokens_301056000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_588000-seen_tokens_301056000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_588000-seen_tokens_301056000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:24:45 | step: 588100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.512388477451168e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 4.34 | consumed tokens: 301107200.0 | grad norm avg: 11.04 | grad norm last: 13.57 | 
2025-12-28T02:24:47 | step: 588200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.511027145781554e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.0 | consumed tokens: 301158400.0 | grad norm avg: 11.77 | grad norm last: 11.33 | 
2025-12-28T02:24:49 | step: 588300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.5096658141119406e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.69 | consumed tokens: 301209600.0 | grad norm avg: 11.0 | grad norm last: 9.11 | 
2025-12-28T02:24:51 | step: 588400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.508304482442327e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.34 | consumed tokens: 301260800.0 | grad norm avg: 10.83 | grad norm last: 10.43 | 
2025-12-28T02:24:53 | step: 588500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.506943150772713e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.69 | consumed tokens: 301312000.0 | grad norm avg: 11.73 | grad norm last: 9.2 | 
2025-12-28T02:24:55 | step: 588600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.505582546698861e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.12 | consumed tokens: 301363200.0 | grad norm avg: 10.92 | grad norm last: 11.85 | 
2025-12-28T02:24:57 | step: 588700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.504221215029247e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.38 | consumed tokens: 301414400.0 | grad norm avg: 10.82 | grad norm last: 9.0 | 
2025-12-28T02:24:59 | step: 588800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.502860247157514e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.2 | consumed tokens: 301465600.0 | grad norm avg: 11.08 | grad norm last: 10.33 | 
2025-12-28T02:25:01 | step: 588900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.501499643083662e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.38 | consumed tokens: 301516800.0 | grad norm avg: 11.06 | grad norm last: 11.04 | 
2025-12-28T02:25:03 | step: 589000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.5001390390098095e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.5 | consumed tokens: 301568000.0 | grad norm avg: 10.96 | grad norm last: 9.44 | 
2025-12-28T02:25:05 | step: 589100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.498778434935957e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.73 | consumed tokens: 301619200.0 | grad norm avg: 11.47 | grad norm last: 9.12 | 
2025-12-28T02:25:07 | step: 589200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.497417830862105e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.64 | consumed tokens: 301670400.0 | grad norm avg: 10.96 | grad norm last: 9.27 | 
2025-12-28T02:25:09 | step: 589300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.496057590586133e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.38 | consumed tokens: 301721600.0 | grad norm avg: 10.7 | grad norm last: 11.18 | 
2025-12-28T02:25:11 | step: 589400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.494696986512281e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.88 | consumed tokens: 301772800.0 | grad norm avg: 10.71 | grad norm last: 11.26 | 
2025-12-28T02:25:13 | step: 589500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.493336382438429e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.09 | consumed tokens: 301824000.0 | grad norm avg: 10.9 | grad norm last: 14.18 | 
2025-12-28T02:25:15 | step: 589600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.4919768697582185e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.44 | consumed tokens: 301875200.0 | grad norm avg: 10.59 | grad norm last: 9.5 | 
2025-12-28T02:25:17 | step: 589700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.490616629482247e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.12 | consumed tokens: 301926400.0 | grad norm avg: 11.05 | grad norm last: 10.98 | 
2025-12-28T02:25:19 | step: 589800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.489256753004156e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.41 | consumed tokens: 301977600.0 | grad norm avg: 10.7 | grad norm last: 9.28 | 
2025-12-28T02:25:21 | step: 589900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.487896876526065e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.41 | consumed tokens: 302028800.0 | grad norm avg: 11.09 | grad norm last: 9.5 | 
2025-12-28T02:25:23 | step: 590000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.486537363845855e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.95 | consumed tokens: 302080000.0 | grad norm avg: 10.75 | grad norm last: 12.41 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_590000-seen_tokens_302080000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_590000-seen_tokens_302080000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_590000-seen_tokens_302080000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_590000-seen_tokens_302080000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_590000-seen_tokens_302080000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_590000-seen_tokens_302080000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_590000-seen_tokens_302080000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_590000-seen_tokens_302080000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:25:26 | step: 590100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.485177851165645e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.33 | consumed tokens: 302131200.0 | grad norm avg: 11.22 | grad norm last: 13.89 | 
2025-12-28T02:25:28 | step: 590200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 4.4838187022833154e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.84 | consumed tokens: 302182400.0 | grad norm avg: 10.99 | grad norm last: 11.29 | 
2025-12-28T02:25:30 | step: 590300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 4.4824588258052245e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.0 | consumed tokens: 302233600.0 | grad norm avg: 11.11 | grad norm last: 10.35 | 
2025-12-28T02:25:32 | step: 590400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.481099313125014e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.22 | consumed tokens: 302284800.0 | grad norm avg: 10.75 | grad norm last: 8.7 | 
2025-12-28T02:25:34 | step: 590500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.479740164242685e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.72 | consumed tokens: 302336000.0 | grad norm avg: 10.81 | grad norm last: 14.68 | 
2025-12-28T02:25:36 | step: 590600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.4783810153603554e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.59 | consumed tokens: 302387200.0 | grad norm avg: 11.02 | grad norm last: 12.81 | 
2025-12-28T02:25:38 | step: 590700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.477021866478026e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.22 | consumed tokens: 302438400.0 | grad norm avg: 11.06 | grad norm last: 12.45 | 
2025-12-28T02:25:40 | step: 590800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.475663081393577e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.33 | consumed tokens: 302489600.0 | grad norm avg: 11.81 | grad norm last: 9.94 | 
2025-12-28T02:25:42 | step: 590900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.474304660107009e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 2.59 | consumed tokens: 302540800.0 | grad norm avg: 10.8 | grad norm last: 9.58 | 
2025-12-28T02:25:44 | step: 591000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.4729455112246796e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.58 | consumed tokens: 302592000.0 | grad norm avg: 10.93 | grad norm last: 10.22 | 
2025-12-28T02:25:46 | step: 591100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.471586726140231e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.55 | consumed tokens: 302643200.0 | grad norm avg: 10.86 | grad norm last: 9.76 | 
2025-12-28T02:25:48 | step: 591200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.470227941055782e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.91 | consumed tokens: 302694400.0 | grad norm avg: 11.28 | grad norm last: 16.89 | 
2025-12-28T02:25:50 | step: 591300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.468869883567095e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.34 | consumed tokens: 302745600.0 | grad norm avg: 10.81 | grad norm last: 8.97 | 
2025-12-28T02:25:52 | step: 591400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.4675118260784075e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.78 | consumed tokens: 302796800.0 | grad norm avg: 11.25 | grad norm last: 12.22 | 
2025-12-28T02:25:54 | step: 591500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.4661534047918394e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.09 | consumed tokens: 302848000.0 | grad norm avg: 10.71 | grad norm last: 11.86 | 
2025-12-28T02:25:56 | step: 591600 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.4647949835052714e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.72 | consumed tokens: 302899200.0 | grad norm avg: 10.66 | grad norm last: 10.6 | 
2025-12-28T02:25:58 | step: 591700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.463437289814465e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.5 | consumed tokens: 302950400.0 | grad norm avg: 11.11 | grad norm last: 13.29 | 
2025-12-28T02:26:00 | step: 591800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.462078868527897e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.45 | consumed tokens: 303001600.0 | grad norm avg: 10.82 | grad norm last: 9.93 | 
2025-12-28T02:26:02 | step: 591900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.46072117483709e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.62 | consumed tokens: 303052800.0 | grad norm avg: 10.67 | grad norm last: 9.4 | 
2025-12-28T02:26:04 | step: 592000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.4593634811462834e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.41 | consumed tokens: 303104000.0 | grad norm avg: 10.67 | grad norm last: 9.62 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_592000-seen_tokens_303104000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_592000-seen_tokens_303104000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_592000-seen_tokens_303104000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_592000-seen_tokens_303104000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_592000-seen_tokens_303104000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_592000-seen_tokens_303104000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_592000-seen_tokens_303104000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_592000-seen_tokens_303104000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:26:07 | step: 592100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.458005787455477e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.66 | train loss last: 4.03 | consumed tokens: 303155200.0 | grad norm avg: 11.2 | grad norm last: 12.67 | 
2025-12-28T02:26:09 | step: 592200 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 4.45664809376467e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.09 | consumed tokens: 303206400.0 | grad norm avg: 10.97 | grad norm last: 10.71 | 
2025-12-28T02:26:11 | step: 592300 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.455291127669625e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.5 | consumed tokens: 303257600.0 | grad norm avg: 10.83 | grad norm last: 10.14 | 
2025-12-28T02:26:13 | step: 592400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.4539334339788184e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.3 | consumed tokens: 303308800.0 | grad norm avg: 10.56 | grad norm last: 9.67 | 
2025-12-28T02:26:15 | step: 592500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.452576467883773e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.39 | consumed tokens: 303360000.0 | grad norm avg: 10.96 | grad norm last: 11.06 | 
2025-12-28T02:26:17 | step: 592600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.451219501788728e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.17 | consumed tokens: 303411200.0 | grad norm avg: 10.83 | grad norm last: 8.66 | 
2025-12-28T02:26:19 | step: 592700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.449862171895802e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.56 | consumed tokens: 303462400.0 | grad norm avg: 10.71 | grad norm last: 12.23 | 
2025-12-28T02:26:21 | step: 592800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.448504842002876e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.0 | consumed tokens: 303513600.0 | grad norm avg: 11.25 | grad norm last: 10.93 | 
2025-12-28T02:26:23 | step: 592900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.4471482397057116e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.41 | consumed tokens: 303564800.0 | grad norm avg: 10.84 | grad norm last: 18.4 | 
2025-12-28T02:26:25 | step: 593000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.445791637408547e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.61 | consumed tokens: 303616000.0 | grad norm avg: 11.14 | grad norm last: 10.47 | 
2025-12-28T02:26:27 | step: 593100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.444435398909263e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.28 | consumed tokens: 303667200.0 | grad norm avg: 12.06 | grad norm last: 12.01 | 
2025-12-28T02:26:29 | step: 593200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.443078432814218e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.47 | consumed tokens: 303718400.0 | grad norm avg: 11.02 | grad norm last: 10.44 | 
2025-12-28T02:26:31 | step: 593300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.4417218305170536e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.39 | consumed tokens: 303769600.0 | grad norm avg: 10.86 | grad norm last: 10.12 | 
2025-12-28T02:26:33 | step: 593400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.44036559201777e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.56 | consumed tokens: 303820800.0 | grad norm avg: 11.11 | grad norm last: 11.34 | 
2025-12-28T02:26:35 | step: 593500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.439009353518486e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.25 | consumed tokens: 303872000.0 | grad norm avg: 10.6 | grad norm last: 14.6 | 
2025-12-28T02:26:37 | step: 593600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.437653115019202e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.27 | consumed tokens: 303923200.0 | grad norm avg: 11.19 | grad norm last: 9.83 | 
2025-12-28T02:26:39 | step: 593700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.436297240317799e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.81 | consumed tokens: 303974400.0 | grad norm avg: 11.3 | grad norm last: 9.91 | 
2025-12-28T02:26:41 | step: 593800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.434941729414277e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.94 | consumed tokens: 304025600.0 | grad norm avg: 10.74 | grad norm last: 9.47 | 
2025-12-28T02:26:43 | step: 593900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.433585490914993e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.92 | consumed tokens: 304076800.0 | grad norm avg: 10.64 | grad norm last: 10.02 | 
2025-12-28T02:26:45 | step: 594000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.43222961621359e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 5.22 | consumed tokens: 304128000.0 | grad norm avg: 10.83 | grad norm last: 12.0 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_594000-seen_tokens_304128000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_594000-seen_tokens_304128000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_594000-seen_tokens_304128000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_594000-seen_tokens_304128000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_594000-seen_tokens_304128000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_594000-seen_tokens_304128000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_594000-seen_tokens_304128000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_594000-seen_tokens_304128000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:26:48 | step: 594100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.430873741512187e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.45 | consumed tokens: 304179200.0 | grad norm avg: 10.83 | grad norm last: 9.5 | 
2025-12-28T02:26:50 | step: 594200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 4.429518594406545e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.17 | consumed tokens: 304230400.0 | grad norm avg: 10.97 | grad norm last: 9.35 | 
2025-12-28T02:26:52 | step: 594300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.4281634473009035e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.81 | consumed tokens: 304281600.0 | grad norm avg: 11.46 | grad norm last: 10.9 | 
2025-12-28T02:26:54 | step: 594400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.426807936397381e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.42 | consumed tokens: 304332800.0 | grad norm avg: 11.25 | grad norm last: 9.51 | 
2025-12-28T02:26:56 | step: 594500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.4254527892917395e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 6.09 | consumed tokens: 304384000.0 | grad norm avg: 11.12 | grad norm last: 39.84 | 
2025-12-28T02:26:58 | step: 594600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.424097642186098e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.47 | consumed tokens: 304435200.0 | grad norm avg: 11.19 | grad norm last: 13.27 | 
2025-12-28T02:27:00 | step: 594700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.4227421312825754e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.62 | consumed tokens: 304486400.0 | grad norm avg: 10.9 | grad norm last: 10.4 | 
2025-12-28T02:27:02 | step: 594800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.421388075570576e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.17 | consumed tokens: 304537600.0 | grad norm avg: 10.92 | grad norm last: 11.51 | 
2025-12-28T02:27:04 | step: 594900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.4200325646670535e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.45 | consumed tokens: 304588800.0 | grad norm avg: 11.05 | grad norm last: 9.85 | 
2025-12-28T02:27:06 | step: 595000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.418678508955054e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.67 | consumed tokens: 304640000.0 | grad norm avg: 11.02 | grad norm last: 9.0 | 
2025-12-28T02:27:08 | step: 595100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.417323725647293e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.69 | consumed tokens: 304691200.0 | grad norm avg: 11.61 | grad norm last: 9.89 | 
2025-12-28T02:27:10 | step: 595200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.415969306137413e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.17 | consumed tokens: 304742400.0 | grad norm avg: 11.12 | grad norm last: 11.61 | 
2025-12-28T02:27:12 | step: 595300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.4146148866275325e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.47 | consumed tokens: 304793600.0 | grad norm avg: 11.06 | grad norm last: 12.91 | 
2025-12-28T02:27:14 | step: 595400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.4132601033197716e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 2.5 | consumed tokens: 304844800.0 | grad norm avg: 11.27 | grad norm last: 7.87 | 
2025-12-28T02:27:16 | step: 595500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.411906411405653e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.34 | consumed tokens: 304896000.0 | grad norm avg: 10.92 | grad norm last: 10.29 | 
2025-12-28T02:27:18 | step: 595600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.410552719491534e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.59 | consumed tokens: 304947200.0 | grad norm avg: 10.83 | grad norm last: 15.03 | 
2025-12-28T02:27:20 | step: 595700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.409198299981654e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.48 | consumed tokens: 304998400.0 | grad norm avg: 10.77 | grad norm last: 9.61 | 
2025-12-28T02:27:22 | step: 595800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.407844608067535e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 2.75 | consumed tokens: 305049600.0 | grad norm avg: 11.05 | grad norm last: 9.01 | 
2025-12-28T02:27:24 | step: 595900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.406490552355535e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 2.78 | consumed tokens: 305100800.0 | grad norm avg: 10.9 | grad norm last: 8.63 | 
2025-12-28T02:27:26 | step: 596000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.405137224239297e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.8 | consumed tokens: 305152000.0 | grad norm avg: 11.49 | grad norm last: 10.76 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_596000-seen_tokens_305152000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_596000-seen_tokens_305152000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_596000-seen_tokens_305152000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_596000-seen_tokens_305152000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_596000-seen_tokens_305152000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_596000-seen_tokens_305152000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_596000-seen_tokens_305152000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_596000-seen_tokens_305152000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:27:28 | step: 596100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.4037835323251784e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.74 | train loss last: 2.91 | consumed tokens: 305203200.0 | grad norm avg: 11.49 | grad norm last: 9.88 | 
2025-12-28T02:27:30 | step: 596200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.40243020420894e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.59 | consumed tokens: 305254400.0 | grad norm avg: 10.78 | grad norm last: 14.61 | 
2025-12-28T02:27:32 | step: 596300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.401076876092702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.64 | consumed tokens: 305305600.0 | grad norm avg: 11.15 | grad norm last: 9.99 | 
2025-12-28T02:27:34 | step: 596400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.399723547976464e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.22 | consumed tokens: 305356800.0 | grad norm avg: 10.98 | grad norm last: 8.56 | 
2025-12-28T02:27:36 | step: 596500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.3983705836581066e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.05 | consumed tokens: 305408000.0 | grad norm avg: 10.88 | grad norm last: 8.96 | 
2025-12-28T02:27:38 | step: 596600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.3970172555418685e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.3 | consumed tokens: 305459200.0 | grad norm avg: 11.55 | grad norm last: 9.68 | 
2025-12-28T02:27:41 | step: 596700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.395664655021392e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.8 | consumed tokens: 305510400.0 | grad norm avg: 10.95 | grad norm last: 10.02 | 
2025-12-28T02:27:43 | step: 596800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.3943116907030344e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 2.84 | consumed tokens: 305561600.0 | grad norm avg: 11.43 | grad norm last: 8.79 | 
2025-12-28T02:27:45 | step: 596900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.3929594539804384e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.3 | consumed tokens: 305612800.0 | grad norm avg: 10.91 | grad norm last: 8.66 | 
2025-12-28T02:27:47 | step: 597000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.391606489662081e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.28 | consumed tokens: 305664000.0 | grad norm avg: 11.52 | grad norm last: 9.84 | 
2025-12-28T02:27:49 | step: 597100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.3902535253437236e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.3 | consumed tokens: 305715200.0 | grad norm avg: 11.11 | grad norm last: 10.2 | 
2025-12-28T02:27:51 | step: 597200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.388901652419008e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.39 | consumed tokens: 305766400.0 | grad norm avg: 11.31 | grad norm last: 12.79 | 
2025-12-28T02:27:53 | step: 597300 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.387549415696412e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.5 | consumed tokens: 305817600.0 | grad norm avg: 10.74 | grad norm last: 10.04 | 
2025-12-28T02:27:55 | step: 597400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.386197178973816e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.41 | consumed tokens: 305868800.0 | grad norm avg: 10.69 | grad norm last: 10.93 | 
2025-12-28T02:27:57 | step: 597500 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.384845306049101e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.72 | consumed tokens: 305920000.0 | grad norm avg: 11.12 | grad norm last: 11.11 | 
2025-12-28T02:27:59 | step: 597600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.3834927055286244e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.59 | consumed tokens: 305971200.0 | grad norm avg: 11.15 | grad norm last: 10.27 | 
2025-12-28T02:28:01 | step: 597700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.3821415601996705e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.38 | consumed tokens: 306022400.0 | grad norm avg: 11.02 | grad norm last: 9.55 | 
2025-12-28T02:28:03 | step: 597800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.380789687274955e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.39 | consumed tokens: 306073600.0 | grad norm avg: 10.63 | grad norm last: 9.33 | 
2025-12-28T02:28:05 | step: 597900 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.37943781435024e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 5.25 | consumed tokens: 306124800.0 | grad norm avg: 10.86 | grad norm last: 18.62 | 
2025-12-28T02:28:07 | step: 598000 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.3780863052234054e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.41 | consumed tokens: 306176000.0 | grad norm avg: 11.24 | grad norm last: 10.91 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_598000-seen_tokens_306176000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_598000-seen_tokens_306176000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_598000-seen_tokens_306176000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_598000-seen_tokens_306176000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_598000-seen_tokens_306176000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_598000-seen_tokens_306176000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_598000-seen_tokens_306176000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_598000-seen_tokens_306176000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:28:09 | step: 598100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.376734796096571e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.58 | consumed tokens: 306227200.0 | grad norm avg: 10.46 | grad norm last: 8.94 | 
2025-12-28T02:28:11 | step: 598200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.375383650767617e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.14 | consumed tokens: 306278400.0 | grad norm avg: 10.91 | grad norm last: 11.09 | 
2025-12-28T02:28:13 | step: 598300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.374032505438663e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.38 | consumed tokens: 306329600.0 | grad norm avg: 11.14 | grad norm last: 17.78 | 
2025-12-28T02:28:15 | step: 598400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.372681360109709e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.27 | consumed tokens: 306380800.0 | grad norm avg: 11.24 | grad norm last: 9.15 | 
2025-12-28T02:28:17 | step: 598500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.3713302147807553e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.52 | consumed tokens: 306432000.0 | grad norm avg: 10.9 | grad norm last: 10.88 | 
2025-12-28T02:28:19 | step: 598600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.369979797047563e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.03 | consumed tokens: 306483200.0 | grad norm avg: 10.79 | grad norm last: 10.84 | 
2025-12-28T02:28:22 | step: 598700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.36862901551649e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.27 | consumed tokens: 306534400.0 | grad norm avg: 11.09 | grad norm last: 10.28 | 
2025-12-28T02:28:24 | step: 598800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.3672782339854166e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.09 | consumed tokens: 306585600.0 | grad norm avg: 11.38 | grad norm last: 9.65 | 
2025-12-28T02:28:26 | step: 598900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.365927816252224e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.03 | consumed tokens: 306636800.0 | grad norm avg: 11.54 | grad norm last: 11.81 | 
2025-12-28T02:28:28 | step: 599000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.364577398519032e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.67 | consumed tokens: 306688000.0 | grad norm avg: 10.76 | grad norm last: 12.12 | 
2025-12-28T02:28:30 | step: 599100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.363226980785839e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 2.91 | consumed tokens: 306739200.0 | grad norm avg: 11.11 | grad norm last: 9.2 | 
2025-12-28T02:28:32 | step: 599200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.3618769268505275e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.64 | consumed tokens: 306790400.0 | grad norm avg: 11.27 | grad norm last: 11.97 | 
2025-12-28T02:28:34 | step: 599300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.360526509117335e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.06 | consumed tokens: 306841600.0 | grad norm avg: 10.81 | grad norm last: 11.6 | 
2025-12-28T02:28:36 | step: 599400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.3591764551820233e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.86 | consumed tokens: 306892800.0 | grad norm avg: 10.89 | grad norm last: 12.94 | 
2025-12-28T02:28:38 | step: 599500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.357826765044592e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.42 | consumed tokens: 306944000.0 | grad norm avg: 10.74 | grad norm last: 8.68 | 
2025-12-28T02:28:40 | step: 599600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.356477074907161e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.02 | consumed tokens: 306995200.0 | grad norm avg: 10.58 | grad norm last: 9.76 | 
2025-12-28T02:28:42 | step: 599700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.35512738476973e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.98 | consumed tokens: 307046400.0 | grad norm avg: 10.71 | grad norm last: 11.67 | 
2025-12-28T02:28:44 | step: 599800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.353777694632299e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.25 | consumed tokens: 307097600.0 | grad norm avg: 10.78 | grad norm last: 12.53 | 
2025-12-28T02:28:46 | step: 599900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.352428368292749e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.62 | consumed tokens: 307148800.0 | grad norm avg: 10.91 | grad norm last: 10.55 | 
2025-12-28T02:28:48 | step: 600000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.3510790419531986e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.7 | consumed tokens: 307200000.0 | grad norm avg: 10.77 | grad norm last: 8.49 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_600000-seen_tokens_307200000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_600000-seen_tokens_307200000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_600000-seen_tokens_307200000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_600000-seen_tokens_307200000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_600000-seen_tokens_307200000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_600000-seen_tokens_307200000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_600000-seen_tokens_307200000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_600000-seen_tokens_307200000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:28:50 | step: 600100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.3497293518157676e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.63 | train loss last: 3.77 | consumed tokens: 307251200.0 | grad norm avg: 10.59 | grad norm last: 9.63 | 
2025-12-28T02:28:52 | step: 600200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.3483811168698594e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 2.61 | consumed tokens: 307302400.0 | grad norm avg: 10.87 | grad norm last: 9.27 | 
2025-12-28T02:28:54 | step: 600300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.3470314267324284e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.86 | consumed tokens: 307353600.0 | grad norm avg: 10.62 | grad norm last: 10.77 | 
2025-12-28T02:28:56 | step: 600400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.34568319178652e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.58 | consumed tokens: 307404800.0 | grad norm avg: 10.68 | grad norm last: 9.03 | 
2025-12-28T02:28:58 | step: 600500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.3443342292448506e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.45 | consumed tokens: 307456000.0 | grad norm avg: 10.88 | grad norm last: 11.68 | 
2025-12-28T02:29:00 | step: 600600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.342985266703181e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.73 | consumed tokens: 307507200.0 | grad norm avg: 10.84 | grad norm last: 9.94 | 
2025-12-28T02:29:02 | step: 600700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.341637031757273e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.0 | consumed tokens: 307558400.0 | grad norm avg: 11.14 | grad norm last: 10.0 | 
2025-12-28T02:29:04 | step: 600800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.340288069215603e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.08 | consumed tokens: 307609600.0 | grad norm avg: 10.53 | grad norm last: 9.19 | 
2025-12-28T02:29:06 | step: 600900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.338940198067576e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.23 | consumed tokens: 307660800.0 | grad norm avg: 11.08 | grad norm last: 9.49 | 
2025-12-28T02:29:08 | step: 601000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.337592326919548e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.12 | consumed tokens: 307712000.0 | grad norm avg: 10.83 | grad norm last: 9.48 | 
2025-12-28T02:29:10 | step: 601100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.336243728175759e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.5 | consumed tokens: 307763200.0 | grad norm avg: 11.03 | grad norm last: 14.29 | 
2025-12-28T02:29:12 | step: 601200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.334895857027732e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.86 | consumed tokens: 307814400.0 | grad norm avg: 11.18 | grad norm last: 10.71 | 
2025-12-28T02:29:14 | step: 601300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.3335476220818236e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.69 | consumed tokens: 307865600.0 | grad norm avg: 10.88 | grad norm last: 11.04 | 
2025-12-28T02:29:16 | step: 601400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.332200114731677e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.16 | consumed tokens: 307916800.0 | grad norm avg: 10.8 | grad norm last: 12.04 | 
2025-12-28T02:29:18 | step: 601500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.33085260738153e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 2.98 | consumed tokens: 307968000.0 | grad norm avg: 10.59 | grad norm last: 9.27 | 
2025-12-28T02:29:21 | step: 601600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.3295047362335026e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.53 | consumed tokens: 308019200.0 | grad norm avg: 10.68 | grad norm last: 10.22 | 
2025-12-28T02:29:23 | step: 601700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.3281575926812366e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.73 | consumed tokens: 308070400.0 | grad norm avg: 10.56 | grad norm last: 10.88 | 
2025-12-28T02:29:25 | step: 601800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.32681008533109e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.53 | consumed tokens: 308121600.0 | grad norm avg: 10.72 | grad norm last: 10.93 | 
2025-12-28T02:29:27 | step: 601900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.325462577980943e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.06 | consumed tokens: 308172800.0 | grad norm avg: 10.98 | grad norm last: 9.44 | 
2025-12-28T02:29:29 | step: 602000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.324115798226558e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.69 | consumed tokens: 308224000.0 | grad norm avg: 10.6 | grad norm last: 9.25 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_602000-seen_tokens_308224000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_602000-seen_tokens_308224000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_602000-seen_tokens_308224000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_602000-seen_tokens_308224000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_602000-seen_tokens_308224000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_602000-seen_tokens_308224000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_602000-seen_tokens_308224000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_602000-seen_tokens_308224000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:29:31 | step: 602100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.322769018472172e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.25 | consumed tokens: 308275200.0 | grad norm avg: 10.49 | grad norm last: 9.68 | 
2025-12-28T02:29:33 | step: 602200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.321422238717787e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.03 | consumed tokens: 308326400.0 | grad norm avg: 10.51 | grad norm last: 10.69 | 
2025-12-28T02:29:35 | step: 602300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.320075095165521e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.47 | consumed tokens: 308377600.0 | grad norm avg: 10.81 | grad norm last: 9.62 | 
2025-12-28T02:29:37 | step: 602400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.318728679209016e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 2.7 | consumed tokens: 308428800.0 | grad norm avg: 10.63 | grad norm last: 9.86 | 
2025-12-28T02:29:39 | step: 602500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.317381899454631e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.59 | consumed tokens: 308480000.0 | grad norm avg: 10.95 | grad norm last: 9.57 | 
2025-12-28T02:29:41 | step: 602600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.316035483498126e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.33 | consumed tokens: 308531200.0 | grad norm avg: 11.02 | grad norm last: 9.35 | 
2025-12-28T02:29:43 | step: 602700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.314689431339502e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.84 | consumed tokens: 308582400.0 | grad norm avg: 10.8 | grad norm last: 10.16 | 
2025-12-28T02:29:45 | step: 602800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.313343015382998e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.58 | consumed tokens: 308633600.0 | grad norm avg: 10.68 | grad norm last: 9.9 | 
2025-12-28T02:29:47 | step: 602900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.311996963224374e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 2.94 | consumed tokens: 308684800.0 | grad norm avg: 11.07 | grad norm last: 8.75 | 
2025-12-28T02:29:49 | step: 603000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.3106512748636305e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.19 | consumed tokens: 308736000.0 | grad norm avg: 10.65 | grad norm last: 9.63 | 
2025-12-28T02:29:51 | step: 603100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.3093052227050066e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.59 | consumed tokens: 308787200.0 | grad norm avg: 11.41 | grad norm last: 9.75 | 
2025-12-28T02:29:53 | step: 603200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.3079595343442634e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.22 | consumed tokens: 308838400.0 | grad norm avg: 11.02 | grad norm last: 9.82 | 
2025-12-28T02:29:55 | step: 603300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.306614209781401e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.19 | consumed tokens: 308889600.0 | grad norm avg: 10.76 | grad norm last: 12.65 | 
2025-12-28T02:29:57 | step: 603400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.3052685214206576e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.81 | consumed tokens: 308940800.0 | grad norm avg: 11.06 | grad norm last: 11.11 | 
2025-12-28T02:29:59 | step: 603500 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.3039228330599144e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.62 | consumed tokens: 308992000.0 | grad norm avg: 10.3 | grad norm last: 10.93 | 
2025-12-28T02:30:01 | step: 603600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.3025778722949326e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.39 | consumed tokens: 309043200.0 | grad norm avg: 10.57 | grad norm last: 10.09 | 
2025-12-28T02:30:03 | step: 603700 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.301232911529951e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.28 | consumed tokens: 309094400.0 | grad norm avg: 10.65 | grad norm last: 10.98 | 
2025-12-28T02:30:06 | step: 603800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.299887586967088e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.5 | consumed tokens: 309145600.0 | grad norm avg: 10.97 | grad norm last: 9.66 | 
2025-12-28T02:30:08 | step: 603900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.2985426262021065e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.55 | consumed tokens: 309196800.0 | grad norm avg: 10.2 | grad norm last: 10.23 | 
2025-12-28T02:30:10 | step: 604000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.2971980292350054e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.3 | consumed tokens: 309248000.0 | grad norm avg: 10.64 | grad norm last: 9.42 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_604000-seen_tokens_309248000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_604000-seen_tokens_309248000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_604000-seen_tokens_309248000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_604000-seen_tokens_309248000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_604000-seen_tokens_309248000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_604000-seen_tokens_309248000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_604000-seen_tokens_309248000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_604000-seen_tokens_309248000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:30:12 | step: 604100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.2958530684700236e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.06 | consumed tokens: 309299200.0 | grad norm avg: 10.91 | grad norm last: 9.81 | 
2025-12-28T02:30:14 | step: 604200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.2945084715029225e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.53 | consumed tokens: 309350400.0 | grad norm avg: 10.61 | grad norm last: 9.37 | 
2025-12-28T02:30:16 | step: 604300 | train samples/s: 98.1 | train mfu (16-bit): -1.0 | lr mean: 4.293164238333702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.48 | consumed tokens: 309401600.0 | grad norm avg: 10.52 | grad norm last: 9.99 | 
2025-12-28T02:30:18 | step: 604400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.291819641366601e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.83 | consumed tokens: 309452800.0 | grad norm avg: 10.53 | grad norm last: 11.83 | 
2025-12-28T02:30:20 | step: 604500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.2904754081973806e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.62 | consumed tokens: 309504000.0 | grad norm avg: 10.77 | grad norm last: 9.44 | 
2025-12-28T02:30:22 | step: 604600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.289131538826041e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.86 | consumed tokens: 309555200.0 | grad norm avg: 10.88 | grad norm last: 10.74 | 
2025-12-28T02:30:24 | step: 604700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.2877873056568205e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.85 | train loss last: 4.75 | consumed tokens: 309606400.0 | grad norm avg: 11.13 | grad norm last: 12.32 | 
2025-12-28T02:30:26 | step: 604800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.2864430724876e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.78 | consumed tokens: 309657600.0 | grad norm avg: 10.37 | grad norm last: 10.06 | 
2025-12-28T02:30:28 | step: 604900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.285099930712022e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.25 | consumed tokens: 309708800.0 | grad norm avg: 10.48 | grad norm last: 9.31 | 
2025-12-28T02:30:30 | step: 605000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.283756061340682e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.38 | consumed tokens: 309760000.0 | grad norm avg: 10.44 | grad norm last: 9.38 | 
2025-12-28T02:30:32 | step: 605100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.2824121919693425e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.69 | consumed tokens: 309811200.0 | grad norm avg: 10.65 | grad norm last: 18.32 | 
2025-12-28T02:30:34 | step: 605200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.281069050193764e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.48 | consumed tokens: 309862400.0 | grad norm avg: 10.7 | grad norm last: 10.61 | 
2025-12-28T02:30:36 | step: 605300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.279725908418186e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 2.92 | consumed tokens: 309913600.0 | grad norm avg: 10.8 | grad norm last: 8.87 | 
2025-12-28T02:30:38 | step: 605400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.278382766642608e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.72 | consumed tokens: 309964800.0 | grad norm avg: 10.79 | grad norm last: 14.32 | 
2025-12-28T02:30:41 | step: 605500 | train samples/s: 101.0 | train mfu (16-bit): -1.0 | lr mean: 4.2770396248670295e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.3 | consumed tokens: 310016000.0 | grad norm avg: 10.54 | grad norm last: 10.53 | 
2025-12-28T02:30:43 | step: 605600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.2756972106872126e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.19 | consumed tokens: 310067200.0 | grad norm avg: 10.67 | grad norm last: 14.22 | 
2025-12-28T02:30:45 | step: 605700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.2743540689116344e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.77 | consumed tokens: 310118400.0 | grad norm avg: 10.86 | grad norm last: 10.01 | 
2025-12-28T02:30:47 | step: 605800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.273011290933937e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.53 | consumed tokens: 310169600.0 | grad norm avg: 10.61 | grad norm last: 9.84 | 
2025-12-28T02:30:49 | step: 605900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.271668512956239e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.77 | consumed tokens: 310220800.0 | grad norm avg: 10.56 | grad norm last: 10.0 | 
2025-12-28T02:30:51 | step: 606000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.2703260987764224e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.81 | consumed tokens: 310272000.0 | grad norm avg: 10.73 | grad norm last: 11.06 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_606000-seen_tokens_310272000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_606000-seen_tokens_310272000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_606000-seen_tokens_310272000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_606000-seen_tokens_310272000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_606000-seen_tokens_310272000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_606000-seen_tokens_310272000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_606000-seen_tokens_310272000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_606000-seen_tokens_310272000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:30:53 | step: 606100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.2689836845966056e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.47 | consumed tokens: 310323200.0 | grad norm avg: 11.12 | grad norm last: 9.42 | 
2025-12-28T02:30:55 | step: 606200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.2676416342146695e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.23 | consumed tokens: 310374400.0 | grad norm avg: 10.65 | grad norm last: 9.72 | 
2025-12-28T02:30:57 | step: 606300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.266299583832733e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.58 | consumed tokens: 310425600.0 | grad norm avg: 10.21 | grad norm last: 7.97 | 
2025-12-28T02:30:59 | step: 606400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.264957897248678e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.95 | consumed tokens: 310476800.0 | grad norm avg: 10.82 | grad norm last: 17.23 | 
2025-12-28T02:31:01 | step: 606500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.263615483068861e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.59 | consumed tokens: 310528000.0 | grad norm avg: 10.49 | grad norm last: 9.68 | 
2025-12-28T02:31:03 | step: 606600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.2622737964848056e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.17 | consumed tokens: 310579200.0 | grad norm avg: 10.79 | grad norm last: 9.12 | 
2025-12-28T02:31:05 | step: 606700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.26093210990075e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.11 | consumed tokens: 310630400.0 | grad norm avg: 10.16 | grad norm last: 8.57 | 
2025-12-28T02:31:07 | step: 606800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.259591150912456e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.62 | consumed tokens: 310681600.0 | grad norm avg: 10.7 | grad norm last: 9.56 | 
2025-12-28T02:31:09 | step: 606900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.258249464328401e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.34 | consumed tokens: 310732800.0 | grad norm avg: 10.44 | grad norm last: 9.03 | 
2025-12-28T02:31:11 | step: 607000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.2569077777443454e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.41 | consumed tokens: 310784000.0 | grad norm avg: 10.63 | grad norm last: 11.83 | 
2025-12-28T02:31:13 | step: 607100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.2555668187560514e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.03 | consumed tokens: 310835200.0 | grad norm avg: 10.65 | grad norm last: 10.33 | 
2025-12-28T02:31:15 | step: 607200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.2542258597677574e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.0 | consumed tokens: 310886400.0 | grad norm avg: 10.43 | grad norm last: 9.45 | 
2025-12-28T02:31:17 | step: 607300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.2528849007794634e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 3.2 | consumed tokens: 310937600.0 | grad norm avg: 11.12 | grad norm last: 8.5 | 
2025-12-28T02:31:19 | step: 607400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.2515439417911693e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 2.88 | consumed tokens: 310988800.0 | grad norm avg: 10.4 | grad norm last: 9.43 | 
2025-12-28T02:31:21 | step: 607500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.2502029828028753e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.41 | consumed tokens: 311040000.0 | grad norm avg: 10.61 | grad norm last: 10.59 | 
2025-12-28T02:31:23 | step: 607600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.248862751410343e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.44 | consumed tokens: 311091200.0 | grad norm avg: 10.53 | grad norm last: 10.14 | 
2025-12-28T02:31:25 | step: 607700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.2475221562199295e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.23 | consumed tokens: 311142400.0 | grad norm avg: 10.42 | grad norm last: 9.24 | 
2025-12-28T02:31:28 | step: 607800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.246181924827397e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.02 | consumed tokens: 311193600.0 | grad norm avg: 10.33 | grad norm last: 8.52 | 
2025-12-28T02:31:30 | step: 607900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.244841693434864e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.09 | consumed tokens: 311244800.0 | grad norm avg: 10.61 | grad norm last: 8.88 | 
2025-12-28T02:31:32 | step: 608000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.2435018258402124e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.12 | consumed tokens: 311296000.0 | grad norm avg: 10.85 | grad norm last: 12.34 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_608000-seen_tokens_311296000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_608000-seen_tokens_311296000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_608000-seen_tokens_311296000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_608000-seen_tokens_311296000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_608000-seen_tokens_311296000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_608000-seen_tokens_311296000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_608000-seen_tokens_311296000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_608000-seen_tokens_311296000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:31:34 | step: 608100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.24216159444768e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.66 | consumed tokens: 311347200.0 | grad norm avg: 10.37 | grad norm last: 9.47 | 
2025-12-28T02:31:36 | step: 608200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.2408220906509086e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.8 | consumed tokens: 311398400.0 | grad norm avg: 10.83 | grad norm last: 9.1 | 
2025-12-28T02:31:38 | step: 608300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.239482223056257e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.97 | consumed tokens: 311449600.0 | grad norm avg: 10.61 | grad norm last: 10.75 | 
2025-12-28T02:31:40 | step: 608400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.238142355461605e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.92 | consumed tokens: 311500800.0 | grad norm avg: 10.87 | grad norm last: 9.96 | 
2025-12-28T02:31:42 | step: 608500 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.2368032154627144e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.11 | consumed tokens: 311552000.0 | grad norm avg: 10.19 | grad norm last: 9.44 | 
2025-12-28T02:31:44 | step: 608600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.235464075463824e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.34 | consumed tokens: 311603200.0 | grad norm avg: 10.61 | grad norm last: 11.6 | 
2025-12-28T02:31:46 | step: 608700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.234124571667053e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.56 | consumed tokens: 311654400.0 | grad norm avg: 10.42 | grad norm last: 9.54 | 
2025-12-28T02:31:48 | step: 608800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.2327854316681623e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.62 | consumed tokens: 311705600.0 | grad norm avg: 10.58 | grad norm last: 8.86 | 
2025-12-28T02:31:50 | step: 608900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.231446291669272e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.31 | consumed tokens: 311756800.0 | grad norm avg: 10.32 | grad norm last: 9.49 | 
2025-12-28T02:31:52 | step: 609000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.230107515468262e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 2.91 | consumed tokens: 311808000.0 | grad norm avg: 10.45 | grad norm last: 9.39 | 
2025-12-28T02:31:54 | step: 609100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.2287687392672524e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.84 | consumed tokens: 311859200.0 | grad norm avg: 10.32 | grad norm last: 9.8 | 
2025-12-28T02:31:56 | step: 609200 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 4.2274303268641233e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 5.12 | consumed tokens: 311910400.0 | grad norm avg: 10.61 | grad norm last: 15.91 | 
2025-12-28T02:31:58 | step: 609300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.2260915506631136e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.17 | consumed tokens: 311961600.0 | grad norm avg: 11.05 | grad norm last: 8.62 | 
2025-12-28T02:32:00 | step: 609400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.224753865855746e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.78 | consumed tokens: 312012800.0 | grad norm avg: 10.45 | grad norm last: 10.39 | 
2025-12-28T02:32:02 | step: 609500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.223415089654736e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.16 | consumed tokens: 312064000.0 | grad norm avg: 10.52 | grad norm last: 12.15 | 
2025-12-28T02:32:04 | step: 609600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.222077041049488e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.55 | consumed tokens: 312115200.0 | grad norm avg: 11.05 | grad norm last: 9.84 | 
2025-12-28T02:32:06 | step: 609700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.2207389924442396e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.45 | consumed tokens: 312166400.0 | grad norm avg: 11.12 | grad norm last: 8.92 | 
2025-12-28T02:32:09 | step: 609800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.219400943838991e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.47 | consumed tokens: 312217600.0 | grad norm avg: 10.96 | grad norm last: 9.82 | 
2025-12-28T02:32:11 | step: 609900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.2180632590316236e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.88 | consumed tokens: 312268800.0 | grad norm avg: 10.75 | grad norm last: 9.48 | 
2025-12-28T02:32:13 | step: 610000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.216725574224256e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 2.64 | consumed tokens: 312320000.0 | grad norm avg: 10.9 | grad norm last: 10.6 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_610000-seen_tokens_312320000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_610000-seen_tokens_312320000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_610000-seen_tokens_312320000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_610000-seen_tokens_312320000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_610000-seen_tokens_312320000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_610000-seen_tokens_312320000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_610000-seen_tokens_312320000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_610000-seen_tokens_312320000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:32:15 | step: 610100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.215388253214769e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.61 | train loss last: 2.97 | consumed tokens: 312371200.0 | grad norm avg: 10.22 | grad norm last: 8.85 | 
2025-12-28T02:32:17 | step: 610200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.214050204609521e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.91 | consumed tokens: 312422400.0 | grad norm avg: 11.04 | grad norm last: 9.27 | 
2025-12-28T02:32:19 | step: 610300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.212713611195795e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.69 | consumed tokens: 312473600.0 | grad norm avg: 11.01 | grad norm last: 9.66 | 
2025-12-28T02:32:21 | step: 610400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.211376290186308e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.72 | consumed tokens: 312524800.0 | grad norm avg: 10.62 | grad norm last: 11.21 | 
2025-12-28T02:32:23 | step: 610500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.210039332974702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.09 | consumed tokens: 312576000.0 | grad norm avg: 10.65 | grad norm last: 10.39 | 
2025-12-28T02:32:25 | step: 610600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.208702375763096e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.34 | consumed tokens: 312627200.0 | grad norm avg: 10.37 | grad norm last: 10.0 | 
2025-12-28T02:32:27 | step: 610700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.2073657823493704e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.41 | consumed tokens: 312678400.0 | grad norm avg: 10.74 | grad norm last: 11.01 | 
2025-12-28T02:32:29 | step: 610800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.206028825137764e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.58 | consumed tokens: 312729600.0 | grad norm avg: 10.54 | grad norm last: 10.84 | 
2025-12-28T02:32:31 | step: 610900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.2046925955219194e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.38 | consumed tokens: 312780800.0 | grad norm avg: 10.47 | grad norm last: 11.4 | 
2025-12-28T02:32:33 | step: 611000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.203356002108194e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.66 | consumed tokens: 312832000.0 | grad norm avg: 10.69 | grad norm last: 9.85 | 
2025-12-28T02:32:35 | step: 611100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.202019772492349e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.94 | consumed tokens: 312883200.0 | grad norm avg: 10.59 | grad norm last: 24.45 | 
2025-12-28T02:32:37 | step: 611200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.2006835428765044e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.31 | consumed tokens: 312934400.0 | grad norm avg: 10.73 | grad norm last: 9.97 | 
2025-12-28T02:32:39 | step: 611300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.19934767705854e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.19 | consumed tokens: 312985600.0 | grad norm avg: 10.3 | grad norm last: 11.15 | 
2025-12-28T02:32:41 | step: 611400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.198011811240576e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.17 | consumed tokens: 313036800.0 | grad norm avg: 10.85 | grad norm last: 10.4 | 
2025-12-28T02:32:43 | step: 611500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.196675945422612e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.03 | consumed tokens: 313088000.0 | grad norm avg: 10.25 | grad norm last: 10.77 | 
2025-12-28T02:32:45 | step: 611600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.195340443402529e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 2.64 | consumed tokens: 313139200.0 | grad norm avg: 10.72 | grad norm last: 8.87 | 
2025-12-28T02:32:47 | step: 611700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.194004577584565e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.17 | consumed tokens: 313190400.0 | grad norm avg: 10.64 | grad norm last: 9.01 | 
2025-12-28T02:32:49 | step: 611800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.192669803160243e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.75 | consumed tokens: 313241600.0 | grad norm avg: 10.59 | grad norm last: 9.77 | 
2025-12-28T02:32:51 | step: 611900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.1913339373422787e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.58 | consumed tokens: 313292800.0 | grad norm avg: 10.24 | grad norm last: 11.02 | 
2025-12-28T02:32:53 | step: 612000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.189998799120076e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.34 | consumed tokens: 313344000.0 | grad norm avg: 10.44 | grad norm last: 9.75 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_612000-seen_tokens_313344000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_612000-seen_tokens_313344000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_612000-seen_tokens_313344000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_612000-seen_tokens_313344000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_612000-seen_tokens_313344000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_612000-seen_tokens_313344000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_612000-seen_tokens_313344000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_612000-seen_tokens_313344000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:32:56 | step: 612100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.188664024695754e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.92 | consumed tokens: 313395200.0 | grad norm avg: 10.73 | grad norm last: 11.34 | 
2025-12-28T02:32:58 | step: 612200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.187329250271432e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.72 | consumed tokens: 313446400.0 | grad norm avg: 11.09 | grad norm last: 9.41 | 
2025-12-28T02:33:00 | step: 612300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.1859941120492294e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.31 | consumed tokens: 313497600.0 | grad norm avg: 10.44 | grad norm last: 12.27 | 
2025-12-28T02:33:02 | step: 612400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.184659701422788e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.8 | consumed tokens: 313548800.0 | grad norm avg: 10.46 | grad norm last: 10.1 | 
2025-12-28T02:33:04 | step: 612500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.183324926998466e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.45 | consumed tokens: 313600000.0 | grad norm avg: 10.34 | grad norm last: 9.94 | 
2025-12-28T02:33:06 | step: 612600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.181990880169906e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.69 | consumed tokens: 313651200.0 | grad norm avg: 10.82 | grad norm last: 9.79 | 
2025-12-28T02:33:08 | step: 612700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.1806564695434645e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.44 | consumed tokens: 313702400.0 | grad norm avg: 10.77 | grad norm last: 8.82 | 
2025-12-28T02:33:10 | step: 612800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.1793227865127847e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 2.44 | consumed tokens: 313753600.0 | grad norm avg: 10.54 | grad norm last: 8.62 | 
2025-12-28T02:33:12 | step: 612900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.1779883758863434e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.33 | consumed tokens: 313804800.0 | grad norm avg: 10.73 | grad norm last: 9.45 | 
2025-12-28T02:33:14 | step: 613000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.176654329057783e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.12 | consumed tokens: 313856000.0 | grad norm avg: 10.29 | grad norm last: 9.54 | 
2025-12-28T02:33:16 | step: 613100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.175321009824984e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.25 | consumed tokens: 313907200.0 | grad norm avg: 10.54 | grad norm last: 8.95 | 
2025-12-28T02:33:18 | step: 613200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.173986962996423e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.56 | consumed tokens: 313958400.0 | grad norm avg: 10.3 | grad norm last: 11.32 | 
2025-12-28T02:33:20 | step: 613300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.172653643763624e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.0 | consumed tokens: 314009600.0 | grad norm avg: 10.41 | grad norm last: 8.87 | 
2025-12-28T02:33:22 | step: 613400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.171319960732944e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.56 | consumed tokens: 314060800.0 | grad norm avg: 11.02 | grad norm last: 10.46 | 
2025-12-28T02:33:24 | step: 613500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.169987005298026e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.69 | consumed tokens: 314112000.0 | grad norm avg: 10.54 | grad norm last: 9.69 | 
2025-12-28T02:33:26 | step: 613600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.168653686065227e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.3 | consumed tokens: 314163200.0 | grad norm avg: 10.76 | grad norm last: 8.45 | 
2025-12-28T02:33:28 | step: 613700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.1673207306303084e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 2.8 | consumed tokens: 314214400.0 | grad norm avg: 10.37 | grad norm last: 9.18 | 
2025-12-28T02:33:30 | step: 613800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.16598777519539e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.55 | consumed tokens: 314265600.0 | grad norm avg: 10.38 | grad norm last: 9.71 | 
2025-12-28T02:33:32 | step: 613900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.164655183558352e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.64 | consumed tokens: 314316800.0 | grad norm avg: 10.23 | grad norm last: 10.6 | 
2025-12-28T02:33:34 | step: 614000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.163322228123434e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.66 | consumed tokens: 314368000.0 | grad norm avg: 10.22 | grad norm last: 9.45 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_614000-seen_tokens_314368000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_614000-seen_tokens_314368000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_614000-seen_tokens_314368000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_614000-seen_tokens_314368000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_614000-seen_tokens_314368000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_614000-seen_tokens_314368000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_614000-seen_tokens_314368000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_614000-seen_tokens_314368000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:33:37 | step: 614100 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.161990000284277e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.71 | train loss last: 3.8 | consumed tokens: 314419200.0 | grad norm avg: 10.93 | grad norm last: 10.4 | 
2025-12-28T02:33:39 | step: 614200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.16065777244512e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.16 | consumed tokens: 314470400.0 | grad norm avg: 10.61 | grad norm last: 9.65 | 
2025-12-28T02:33:41 | step: 614300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.159325544605963e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.25 | consumed tokens: 314521600.0 | grad norm avg: 10.61 | grad norm last: 11.54 | 
2025-12-28T02:33:43 | step: 614400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.157993316766806e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.64 | consumed tokens: 314572800.0 | grad norm avg: 10.5 | grad norm last: 10.96 | 
2025-12-28T02:33:45 | step: 614500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.15666145272553e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.23 | consumed tokens: 314624000.0 | grad norm avg: 10.76 | grad norm last: 9.24 | 
2025-12-28T02:33:47 | step: 614600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.1553295886842534e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.06 | consumed tokens: 314675200.0 | grad norm avg: 10.83 | grad norm last: 9.59 | 
2025-12-28T02:33:49 | step: 614700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.153998088440858e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.11 | consumed tokens: 314726400.0 | grad norm avg: 10.39 | grad norm last: 9.17 | 
2025-12-28T02:33:51 | step: 614800 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.152666588197462e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.77 | consumed tokens: 314777600.0 | grad norm avg: 10.22 | grad norm last: 9.93 | 
2025-12-28T02:33:53 | step: 614900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 4.151335087954067e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.48 | consumed tokens: 314828800.0 | grad norm avg: 10.31 | grad norm last: 9.53 | 
2025-12-28T02:33:55 | step: 615000 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.150003587710671e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.44 | consumed tokens: 314880000.0 | grad norm avg: 10.51 | grad norm last: 8.89 | 
2025-12-28T02:33:57 | step: 615100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.148672451265156e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.86 | consumed tokens: 314931200.0 | grad norm avg: 10.35 | grad norm last: 9.98 | 
2025-12-28T02:33:59 | step: 615200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.1473413148196414e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.52 | consumed tokens: 314982400.0 | grad norm avg: 10.64 | grad norm last: 9.22 | 
2025-12-28T02:34:01 | step: 615300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.146010542172007e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.88 | consumed tokens: 315033600.0 | grad norm avg: 10.38 | grad norm last: 9.84 | 
2025-12-28T02:34:03 | step: 615400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.144679769524373e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.34 | consumed tokens: 315084800.0 | grad norm avg: 10.79 | grad norm last: 10.2 | 
2025-12-28T02:34:05 | step: 615500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.143348996876739e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.73 | consumed tokens: 315136000.0 | grad norm avg: 10.47 | grad norm last: 9.64 | 
2025-12-28T02:34:07 | step: 615600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.142018224229105e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.66 | consumed tokens: 315187200.0 | grad norm avg: 10.64 | grad norm last: 10.3 | 
2025-12-28T02:34:09 | step: 615700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.140688179177232e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.72 | consumed tokens: 315238400.0 | grad norm avg: 10.83 | grad norm last: 10.76 | 
2025-12-28T02:34:11 | step: 615800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.1393577703274786e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.02 | consumed tokens: 315289600.0 | grad norm avg: 10.87 | grad norm last: 9.15 | 
2025-12-28T02:34:13 | step: 615900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.138027725275606e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.28 | consumed tokens: 315340800.0 | grad norm avg: 10.36 | grad norm last: 9.62 | 
2025-12-28T02:34:15 | step: 616000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.136697680223733e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.53 | consumed tokens: 315392000.0 | grad norm avg: 10.44 | grad norm last: 12.21 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_616000-seen_tokens_315392000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_616000-seen_tokens_315392000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_616000-seen_tokens_315392000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_616000-seen_tokens_315392000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_616000-seen_tokens_315392000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_616000-seen_tokens_315392000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_616000-seen_tokens_315392000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_616000-seen_tokens_315392000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:34:18 | step: 616100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.135367998969741e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.67 | train loss last: 3.67 | consumed tokens: 315443200.0 | grad norm avg: 10.58 | grad norm last: 9.66 | 
2025-12-28T02:34:20 | step: 616200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.1340379539178684e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.77 | consumed tokens: 315494400.0 | grad norm avg: 10.36 | grad norm last: 9.75 | 
2025-12-28T02:34:22 | step: 616300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.132708636461757e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.14 | consumed tokens: 315545600.0 | grad norm avg: 10.73 | grad norm last: 10.86 | 
2025-12-28T02:34:24 | step: 616400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.131378955207765e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.05 | consumed tokens: 315596800.0 | grad norm avg: 10.75 | grad norm last: 10.52 | 
2025-12-28T02:34:26 | step: 616500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.1300500015495345e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.88 | consumed tokens: 315648000.0 | grad norm avg: 10.72 | grad norm last: 11.15 | 
2025-12-28T02:34:28 | step: 616600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.1287203202955425e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.22 | consumed tokens: 315699200.0 | grad norm avg: 10.39 | grad norm last: 9.29 | 
2025-12-28T02:34:30 | step: 616700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.127391366637312e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.48 | consumed tokens: 315750400.0 | grad norm avg: 10.72 | grad norm last: 9.12 | 
2025-12-28T02:34:32 | step: 616800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.126062776776962e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.23 | consumed tokens: 315801600.0 | grad norm avg: 10.3 | grad norm last: 9.89 | 
2025-12-28T02:34:34 | step: 616900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.124733459320851e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.28 | consumed tokens: 315852800.0 | grad norm avg: 10.6 | grad norm last: 19.19 | 
2025-12-28T02:34:36 | step: 617000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.123404869460501e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.47 | consumed tokens: 315904000.0 | grad norm avg: 10.74 | grad norm last: 10.47 | 
2025-12-28T02:34:38 | step: 617100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.122076279600151e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.31 | consumed tokens: 315955200.0 | grad norm avg: 10.85 | grad norm last: 8.59 | 
2025-12-28T02:34:40 | step: 617200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.1207484173355624e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.31 | consumed tokens: 316006400.0 | grad norm avg: 10.31 | grad norm last: 9.78 | 
2025-12-28T02:34:42 | step: 617300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.119419099879451e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.44 | consumed tokens: 316057600.0 | grad norm avg: 10.27 | grad norm last: 9.91 | 
2025-12-28T02:34:44 | step: 617400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 4.118091601412743e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.52 | consumed tokens: 316108800.0 | grad norm avg: 10.41 | grad norm last: 8.98 | 
2025-12-28T02:34:46 | step: 617500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.116763375350274e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.69 | consumed tokens: 316160000.0 | grad norm avg: 10.48 | grad norm last: 12.64 | 
2025-12-28T02:34:48 | step: 617600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.115435513085686e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.77 | consumed tokens: 316211200.0 | grad norm avg: 10.26 | grad norm last: 10.54 | 
2025-12-28T02:34:50 | step: 617700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.114107650821097e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.98 | consumed tokens: 316262400.0 | grad norm avg: 10.6 | grad norm last: 9.32 | 
2025-12-28T02:34:52 | step: 617800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.1127801523543894e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.06 | consumed tokens: 316313600.0 | grad norm avg: 10.57 | grad norm last: 11.26 | 
2025-12-28T02:34:54 | step: 617900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.111452653887682e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.98 | consumed tokens: 316364800.0 | grad norm avg: 10.64 | grad norm last: 11.33 | 
2025-12-28T02:34:56 | step: 618000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.1101255192188546e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.97 | consumed tokens: 316416000.0 | grad norm avg: 10.54 | grad norm last: 18.08 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_618000-seen_tokens_316416000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_618000-seen_tokens_316416000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_618000-seen_tokens_316416000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_618000-seen_tokens_316416000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_618000-seen_tokens_316416000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_618000-seen_tokens_316416000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_618000-seen_tokens_316416000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_618000-seen_tokens_316416000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:34:58 | step: 618100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.1087983845500275e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.61 | train loss last: 2.64 | consumed tokens: 316467200.0 | grad norm avg: 10.42 | grad norm last: 8.64 | 
2025-12-28T02:35:00 | step: 618200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.1074712498812005e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.67 | train loss last: 3.83 | consumed tokens: 316518400.0 | grad norm avg: 10.24 | grad norm last: 11.55 | 
2025-12-28T02:35:03 | step: 618300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.1061441152123734e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.31 | consumed tokens: 316569600.0 | grad norm avg: 10.55 | grad norm last: 10.42 | 
2025-12-28T02:35:05 | step: 618400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.104817344341427e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.58 | consumed tokens: 316620800.0 | grad norm avg: 10.38 | grad norm last: 9.08 | 
2025-12-28T02:35:07 | step: 618500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.103490573470481e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.25 | consumed tokens: 316672000.0 | grad norm avg: 10.55 | grad norm last: 9.36 | 
2025-12-28T02:35:09 | step: 618600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.102163438801654e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.55 | consumed tokens: 316723200.0 | grad norm avg: 11.1 | grad norm last: 9.46 | 
2025-12-28T02:35:11 | step: 618700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.100837395526469e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.83 | consumed tokens: 316774400.0 | grad norm avg: 10.91 | grad norm last: 16.92 | 
2025-12-28T02:35:13 | step: 618800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.099511352251284e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.55 | consumed tokens: 316825600.0 | grad norm avg: 10.5 | grad norm last: 9.47 | 
2025-12-28T02:35:15 | step: 618900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.098184945178218e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.03 | consumed tokens: 316876800.0 | grad norm avg: 10.53 | grad norm last: 11.66 | 
2025-12-28T02:35:17 | step: 619000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.096858901903033e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.69 | consumed tokens: 316928000.0 | grad norm avg: 10.09 | grad norm last: 9.19 | 
2025-12-28T02:35:19 | step: 619100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.095533222425729e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.08 | consumed tokens: 316979200.0 | grad norm avg: 10.68 | grad norm last: 9.07 | 
2025-12-28T02:35:21 | step: 619200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.094207542948425e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.31 | consumed tokens: 317030400.0 | grad norm avg: 10.4 | grad norm last: 10.23 | 
2025-12-28T02:35:23 | step: 619300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.0928818634711206e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.09 | consumed tokens: 317081600.0 | grad norm avg: 10.28 | grad norm last: 8.84 | 
2025-12-28T02:35:25 | step: 619400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.0915561839938164e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.81 | consumed tokens: 317132800.0 | grad norm avg: 10.68 | grad norm last: 9.23 | 
2025-12-28T02:35:27 | step: 619500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.090230868314393e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.02 | consumed tokens: 317184000.0 | grad norm avg: 10.28 | grad norm last: 8.38 | 
2025-12-28T02:35:29 | step: 619600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.08890591643285e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.48 | consumed tokens: 317235200.0 | grad norm avg: 10.66 | grad norm last: 9.64 | 
2025-12-28T02:35:31 | step: 619700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.0875806007534266e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.66 | consumed tokens: 317286400.0 | grad norm avg: 10.24 | grad norm last: 11.86 | 
2025-12-28T02:35:33 | step: 619800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.086255285074003e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.52 | consumed tokens: 317337600.0 | grad norm avg: 10.55 | grad norm last: 9.51 | 
2025-12-28T02:35:35 | step: 619900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.0849310607882217e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.62 | consumed tokens: 317388800.0 | grad norm avg: 10.71 | grad norm last: 9.18 | 
2025-12-28T02:35:37 | step: 620000 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 4.083606108906679e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.03 | consumed tokens: 317440000.0 | grad norm avg: 10.4 | grad norm last: 9.21 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_620000-seen_tokens_317440000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_620000-seen_tokens_317440000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_620000-seen_tokens_317440000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_620000-seen_tokens_317440000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_620000-seen_tokens_317440000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_620000-seen_tokens_317440000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_620000-seen_tokens_317440000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_620000-seen_tokens_317440000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:35:39 | step: 620100 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 4.0822818846208975e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.64 | train loss last: 4.41 | consumed tokens: 317491200.0 | grad norm avg: 10.7 | grad norm last: 16.15 | 
2025-12-28T02:35:41 | step: 620200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.080957660335116e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.61 | consumed tokens: 317542400.0 | grad norm avg: 11.01 | grad norm last: 9.09 | 
2025-12-28T02:35:43 | step: 620300 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.079633436049335e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.25 | consumed tokens: 317593600.0 | grad norm avg: 10.55 | grad norm last: 9.98 | 
2025-12-28T02:35:46 | step: 620400 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.078309211763553e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.22 | consumed tokens: 317644800.0 | grad norm avg: 10.88 | grad norm last: 9.94 | 
2025-12-28T02:35:48 | step: 620500 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.076984987477772e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.19 | consumed tokens: 317696000.0 | grad norm avg: 10.77 | grad norm last: 10.79 | 
2025-12-28T02:35:50 | step: 620600 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.075661126989871e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.5 | consumed tokens: 317747200.0 | grad norm avg: 10.23 | grad norm last: 7.61 | 
2025-12-28T02:35:52 | step: 620700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 4.0743372665019706e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.98 | consumed tokens: 317798400.0 | grad norm avg: 10.52 | grad norm last: 10.28 | 
2025-12-28T02:35:54 | step: 620800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.0730137698119506e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.95 | consumed tokens: 317849600.0 | grad norm avg: 10.23 | grad norm last: 14.38 | 
2025-12-28T02:35:56 | step: 620900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.071691000717692e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.84 | consumed tokens: 317900800.0 | grad norm avg: 10.54 | grad norm last: 9.36 | 
2025-12-28T02:35:58 | step: 621000 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 4.0703671402297914e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.28 | consumed tokens: 317952000.0 | grad norm avg: 10.65 | grad norm last: 10.02 | 
2025-12-28T02:36:00 | step: 621100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.069044007337652e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.45 | consumed tokens: 318003200.0 | grad norm avg: 10.66 | grad norm last: 9.44 | 
2025-12-28T02:36:02 | step: 621200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.067720874445513e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 2.84 | consumed tokens: 318054400.0 | grad norm avg: 10.24 | grad norm last: 8.17 | 
2025-12-28T02:36:04 | step: 621300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 4.0663981053512543e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.22 | consumed tokens: 318105600.0 | grad norm avg: 10.69 | grad norm last: 11.23 | 
2025-12-28T02:36:06 | step: 621400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.065075336256996e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.48 | consumed tokens: 318156800.0 | grad norm avg: 10.33 | grad norm last: 9.11 | 
2025-12-28T02:36:08 | step: 621500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.063752930960618e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 2.73 | consumed tokens: 318208000.0 | grad norm avg: 10.34 | grad norm last: 7.93 | 
2025-12-28T02:36:10 | step: 621600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.0624301618663594e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.66 | consumed tokens: 318259200.0 | grad norm avg: 10.26 | grad norm last: 20.55 | 
2025-12-28T02:36:12 | step: 621700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.061108120367862e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.34 | consumed tokens: 318310400.0 | grad norm avg: 10.55 | grad norm last: 11.33 | 
2025-12-28T02:36:14 | step: 621800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.0597857150714844e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 5.34 | consumed tokens: 318361600.0 | grad norm avg: 10.39 | grad norm last: 13.06 | 
2025-12-28T02:36:16 | step: 621900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.058463673572987e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.06 | consumed tokens: 318412800.0 | grad norm avg: 10.32 | grad norm last: 9.85 | 
2025-12-28T02:36:18 | step: 622000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.05714163207449e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.7 | consumed tokens: 318464000.0 | grad norm avg: 10.37 | grad norm last: 10.62 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_622000-seen_tokens_318464000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_622000-seen_tokens_318464000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_622000-seen_tokens_318464000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_622000-seen_tokens_318464000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_622000-seen_tokens_318464000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_622000-seen_tokens_318464000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_622000-seen_tokens_318464000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_622000-seen_tokens_318464000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:36:20 | step: 622100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.055819954373874e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.63 | train loss last: 4.75 | consumed tokens: 318515200.0 | grad norm avg: 10.38 | grad norm last: 13.19 | 
2025-12-28T02:36:22 | step: 622200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.0544982766732574e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.66 | consumed tokens: 318566400.0 | grad norm avg: 10.28 | grad norm last: 12.68 | 
2025-12-28T02:36:24 | step: 622300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.0531769627705216e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.48 | consumed tokens: 318617600.0 | grad norm avg: 10.64 | grad norm last: 8.94 | 
2025-12-28T02:36:26 | step: 622400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.051855648867786e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.59 | consumed tokens: 318668800.0 | grad norm avg: 10.4 | grad norm last: 11.56 | 
2025-12-28T02:36:29 | step: 622500 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 4.05053433496505e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.0 | consumed tokens: 318720000.0 | grad norm avg: 10.58 | grad norm last: 9.68 | 
2025-12-28T02:36:31 | step: 622600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.049213384860195e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.25 | consumed tokens: 318771200.0 | grad norm avg: 10.43 | grad norm last: 9.7 | 
2025-12-28T02:36:33 | step: 622700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.04789243475534e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.33 | consumed tokens: 318822400.0 | grad norm avg: 10.58 | grad norm last: 9.3 | 
2025-12-28T02:36:35 | step: 622800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.046571484650485e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.53 | consumed tokens: 318873600.0 | grad norm avg: 10.48 | grad norm last: 11.03 | 
2025-12-28T02:36:37 | step: 622900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.045250898343511e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.77 | consumed tokens: 318924800.0 | grad norm avg: 10.28 | grad norm last: 9.9 | 
2025-12-28T02:36:39 | step: 623000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.0439303120365366e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.19 | consumed tokens: 318976000.0 | grad norm avg: 10.19 | grad norm last: 10.24 | 
2025-12-28T02:36:41 | step: 623100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.042610089527443e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.14 | consumed tokens: 319027200.0 | grad norm avg: 9.96 | grad norm last: 8.65 | 
2025-12-28T02:36:43 | step: 623200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.041289503220469e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.91 | consumed tokens: 319078400.0 | grad norm avg: 10.22 | grad norm last: 11.43 | 
2025-12-28T02:36:45 | step: 623300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.039969644509256e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.5 | consumed tokens: 319129600.0 | grad norm avg: 10.51 | grad norm last: 9.02 | 
2025-12-28T02:36:47 | step: 623400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.038649785798043e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.88 | consumed tokens: 319180800.0 | grad norm avg: 10.24 | grad norm last: 11.44 | 
2025-12-28T02:36:49 | step: 623500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.03732992708683e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.5 | consumed tokens: 319232000.0 | grad norm avg: 10.16 | grad norm last: 10.72 | 
2025-12-28T02:36:51 | step: 623600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.036010068375617e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.72 | consumed tokens: 319283200.0 | grad norm avg: 10.88 | grad norm last: 10.85 | 
2025-12-28T02:36:53 | step: 623700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.034690573462285e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.78 | consumed tokens: 319334400.0 | grad norm avg: 10.41 | grad norm last: 10.09 | 
2025-12-28T02:36:55 | step: 623800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 4.033371078548953e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.16 | consumed tokens: 319385600.0 | grad norm avg: 10.51 | grad norm last: 11.43 | 
2025-12-28T02:36:57 | step: 623900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.0320519474335015e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.38 | consumed tokens: 319436800.0 | grad norm avg: 10.52 | grad norm last: 11.11 | 
2025-12-28T02:36:59 | step: 624000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.03073281631805e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.34 | consumed tokens: 319488000.0 | grad norm avg: 10.25 | grad norm last: 9.12 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_624000-seen_tokens_319488000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_624000-seen_tokens_319488000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_624000-seen_tokens_319488000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_624000-seen_tokens_319488000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_624000-seen_tokens_319488000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_624000-seen_tokens_319488000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_624000-seen_tokens_319488000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_624000-seen_tokens_319488000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:37:01 | step: 624100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 4.0294136852025986e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.78 | train loss last: 4.53 | consumed tokens: 319539200.0 | grad norm avg: 10.48 | grad norm last: 16.24 | 
2025-12-28T02:37:03 | step: 624200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.028094917885028e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.47 | consumed tokens: 319590400.0 | grad norm avg: 10.44 | grad norm last: 10.16 | 
2025-12-28T02:37:05 | step: 624300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.026776150567457e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.77 | consumed tokens: 319641600.0 | grad norm avg: 10.58 | grad norm last: 9.93 | 
2025-12-28T02:37:07 | step: 624400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.025457747047767e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 5.78 | consumed tokens: 319692800.0 | grad norm avg: 10.64 | grad norm last: 32.84 | 
2025-12-28T02:37:09 | step: 624500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 4.024139343528077e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 2.86 | consumed tokens: 319744000.0 | grad norm avg: 10.45 | grad norm last: 10.41 | 
2025-12-28T02:37:11 | step: 624600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.022820940008387e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.72 | consumed tokens: 319795200.0 | grad norm avg: 10.48 | grad norm last: 9.97 | 
2025-12-28T02:37:13 | step: 624700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 4.0215029002865776e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.7 | consumed tokens: 319846400.0 | grad norm avg: 10.57 | grad norm last: 10.54 | 
2025-12-28T02:37:15 | step: 624800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.020184860564768e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.5 | consumed tokens: 319897600.0 | grad norm avg: 10.46 | grad norm last: 10.74 | 
2025-12-28T02:37:17 | step: 624900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 4.01886718464084e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.7 | consumed tokens: 319948800.0 | grad norm avg: 10.39 | grad norm last: 11.01 | 
2025-12-28T02:37:20 | step: 625000 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 4.017549508716911e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.62 | consumed tokens: 320000000.0 | grad norm avg: 10.12 | grad norm last: 11.31 | 
2025-12-28T02:37:22 | step: 625100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 4.0162318327929825e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 2.8 | consumed tokens: 320051200.0 | grad norm avg: 10.56 | grad norm last: 8.47 | 
2025-12-28T02:37:24 | step: 625200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 4.0149145206669345e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.45 | consumed tokens: 320102400.0 | grad norm avg: 10.25 | grad norm last: 10.2 | 
2025-12-28T02:37:26 | step: 625300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 4.0135972085408866e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.16 | consumed tokens: 320153600.0 | grad norm avg: 10.15 | grad norm last: 9.36 | 
2025-12-28T02:37:28 | step: 625400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 4.012279896414839e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.27 | consumed tokens: 320204800.0 | grad norm avg: 10.48 | grad norm last: 10.86 | 
2025-12-28T02:37:30 | step: 625500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.0109629480866715e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.81 | consumed tokens: 320256000.0 | grad norm avg: 10.45 | grad norm last: 9.84 | 
2025-12-28T02:37:32 | step: 625600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 4.009646363556385e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 5.25 | consumed tokens: 320307200.0 | grad norm avg: 10.26 | grad norm last: 11.87 | 
2025-12-28T02:37:34 | step: 625700 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 4.008329415228218e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.5 | consumed tokens: 320358400.0 | grad norm avg: 10.3 | grad norm last: 10.34 | 
2025-12-28T02:37:36 | step: 625800 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 4.0070128306979313e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.92 | consumed tokens: 320409600.0 | grad norm avg: 10.23 | grad norm last: 10.01 | 
2025-12-28T02:37:38 | step: 625900 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 4.0056966099655256e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.23 | consumed tokens: 320460800.0 | grad norm avg: 10.4 | grad norm last: 11.04 | 
2025-12-28T02:37:40 | step: 626000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 4.00438038923312e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 2.81 | consumed tokens: 320512000.0 | grad norm avg: 10.3 | grad norm last: 8.56 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_626000-seen_tokens_320512000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_626000-seen_tokens_320512000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_626000-seen_tokens_320512000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_626000-seen_tokens_320512000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_626000-seen_tokens_320512000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_626000-seen_tokens_320512000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_626000-seen_tokens_320512000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_626000-seen_tokens_320512000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:37:42 | step: 626100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.003064168500714e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.62 | train loss last: 5.19 | consumed tokens: 320563200.0 | grad norm avg: 10.5 | grad norm last: 12.38 | 
2025-12-28T02:37:44 | step: 626200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 4.001748311566189e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.53 | consumed tokens: 320614400.0 | grad norm avg: 10.24 | grad norm last: 9.09 | 
2025-12-28T02:37:46 | step: 626300 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 4.000432454631664e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.41 | consumed tokens: 320665600.0 | grad norm avg: 10.47 | grad norm last: 13.2 | 
2025-12-28T02:37:48 | step: 626400 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 3.999116597697139e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.11 | consumed tokens: 320716800.0 | grad norm avg: 10.3 | grad norm last: 8.59 | 
2025-12-28T02:37:50 | step: 626500 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.9978011045604944e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.41 | consumed tokens: 320768000.0 | grad norm avg: 10.26 | grad norm last: 9.84 | 
2025-12-28T02:37:52 | step: 626600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 3.99648561142385e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.72 | consumed tokens: 320819200.0 | grad norm avg: 10.25 | grad norm last: 10.37 | 
2025-12-28T02:37:54 | step: 626700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.9951704820850864e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.88 | consumed tokens: 320870400.0 | grad norm avg: 10.37 | grad norm last: 12.82 | 
2025-12-28T02:37:57 | step: 626800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.993855352746323e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 7.44 | consumed tokens: 320921600.0 | grad norm avg: 10.56 | grad norm last: 22.14 | 
2025-12-28T02:37:59 | step: 626900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.99254058720544e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.66 | consumed tokens: 320972800.0 | grad norm avg: 10.4 | grad norm last: 10.24 | 
2025-12-28T02:38:01 | step: 627000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.991225457866676e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.84 | consumed tokens: 321024000.0 | grad norm avg: 10.6 | grad norm last: 10.61 | 
2025-12-28T02:38:03 | step: 627100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.989911056123674e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.78 | consumed tokens: 321075200.0 | grad norm avg: 10.37 | grad norm last: 10.4 | 
2025-12-28T02:38:05 | step: 627200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.988596290582791e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.92 | consumed tokens: 321126400.0 | grad norm avg: 10.44 | grad norm last: 11.46 | 
2025-12-28T02:38:07 | step: 627300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.987281888839789e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.09 | consumed tokens: 321177600.0 | grad norm avg: 10.46 | grad norm last: 9.47 | 
2025-12-28T02:38:09 | step: 627400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.985967850894667e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.38 | consumed tokens: 321228800.0 | grad norm avg: 10.25 | grad norm last: 9.53 | 
2025-12-28T02:38:11 | step: 627500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.984653812949546e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.06 | consumed tokens: 321280000.0 | grad norm avg: 10.13 | grad norm last: 10.48 | 
2025-12-28T02:38:13 | step: 627600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.983339775004424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.09 | consumed tokens: 321331200.0 | grad norm avg: 10.39 | grad norm last: 9.12 | 
2025-12-28T02:38:15 | step: 627700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.982026100857183e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.53 | consumed tokens: 321382400.0 | grad norm avg: 10.11 | grad norm last: 10.14 | 
2025-12-28T02:38:17 | step: 627800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.9807124267099425e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.45 | consumed tokens: 321433600.0 | grad norm avg: 10.08 | grad norm last: 9.61 | 
2025-12-28T02:38:19 | step: 627900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.979398752562702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.39 | consumed tokens: 321484800.0 | grad norm avg: 10.33 | grad norm last: 9.84 | 
2025-12-28T02:38:21 | step: 628000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.9780854422133416e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.0 | consumed tokens: 321536000.0 | grad norm avg: 10.71 | grad norm last: 9.14 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_628000-seen_tokens_321536000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_628000-seen_tokens_321536000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_628000-seen_tokens_321536000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_628000-seen_tokens_321536000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_628000-seen_tokens_321536000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_628000-seen_tokens_321536000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_628000-seen_tokens_321536000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_628000-seen_tokens_321536000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:38:23 | step: 628100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.9767721318639815e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.69 | train loss last: 2.64 | consumed tokens: 321587200.0 | grad norm avg: 10.42 | grad norm last: 8.61 | 
2025-12-28T02:38:25 | step: 628200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.975459185312502e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.65 | train loss last: 3.08 | consumed tokens: 321638400.0 | grad norm avg: 10.47 | grad norm last: 9.92 | 
2025-12-28T02:38:27 | step: 628300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.974146238761023e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.33 | consumed tokens: 321689600.0 | grad norm avg: 10.4 | grad norm last: 9.21 | 
2025-12-28T02:38:29 | step: 628400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.972833292209543e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.44 | consumed tokens: 321740800.0 | grad norm avg: 10.46 | grad norm last: 10.73 | 
2025-12-28T02:38:31 | step: 628500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.9715207094559446e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.8 | consumed tokens: 321792000.0 | grad norm avg: 10.24 | grad norm last: 9.37 | 
2025-12-28T02:38:33 | step: 628600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.970208126702346e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.73 | consumed tokens: 321843200.0 | grad norm avg: 10.68 | grad norm last: 11.81 | 
2025-12-28T02:38:35 | step: 628700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.968895907746628e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.33 | consumed tokens: 321894400.0 | grad norm avg: 11.52 | grad norm last: 10.52 | 
2025-12-28T02:38:37 | step: 628800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.96758368879091e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 2.98 | consumed tokens: 321945600.0 | grad norm avg: 10.44 | grad norm last: 9.38 | 
2025-12-28T02:38:39 | step: 628900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.966271833633073e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.67 | consumed tokens: 321996800.0 | grad norm avg: 10.51 | grad norm last: 8.8 | 
2025-12-28T02:38:41 | step: 629000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.9649599784752354e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.16 | consumed tokens: 322048000.0 | grad norm avg: 10.68 | grad norm last: 14.63 | 
2025-12-28T02:38:43 | step: 629100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.963648123317398e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.78 | consumed tokens: 322099200.0 | grad norm avg: 10.43 | grad norm last: 9.67 | 
2025-12-28T02:38:45 | step: 629200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.9623366319574416e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.2 | consumed tokens: 322150400.0 | grad norm avg: 10.32 | grad norm last: 9.05 | 
2025-12-28T02:38:47 | step: 629300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.961025140597485e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.03 | consumed tokens: 322201600.0 | grad norm avg: 10.2 | grad norm last: 11.59 | 
2025-12-28T02:38:49 | step: 629400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 3.9597136492375284e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.55 | consumed tokens: 322252800.0 | grad norm avg: 10.72 | grad norm last: 9.84 | 
2025-12-28T02:38:51 | step: 629500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.9584025216754526e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.33 | consumed tokens: 322304000.0 | grad norm avg: 10.26 | grad norm last: 12.06 | 
2025-12-28T02:38:53 | step: 629600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.957091394113377e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 2.92 | consumed tokens: 322355200.0 | grad norm avg: 10.43 | grad norm last: 8.9 | 
2025-12-28T02:38:56 | step: 629700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.9557806303491816e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.33 | consumed tokens: 322406400.0 | grad norm avg: 10.3 | grad norm last: 9.18 | 
2025-12-28T02:38:58 | step: 629800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.9544698665849864e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.44 | consumed tokens: 322457600.0 | grad norm avg: 10.65 | grad norm last: 14.63 | 
2025-12-28T02:39:00 | step: 629900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.953159466618672e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.28 | consumed tokens: 322508800.0 | grad norm avg: 10.07 | grad norm last: 8.93 | 
2025-12-28T02:39:02 | step: 630000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.9518490666523576e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.2 | consumed tokens: 322560000.0 | grad norm avg: 10.3 | grad norm last: 9.33 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_630000-seen_tokens_322560000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_630000-seen_tokens_322560000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_630000-seen_tokens_322560000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_630000-seen_tokens_322560000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_630000-seen_tokens_322560000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_630000-seen_tokens_322560000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_630000-seen_tokens_322560000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_630000-seen_tokens_322560000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:39:04 | step: 630100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.950538666686043e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.68 | train loss last: 4.47 | consumed tokens: 322611200.0 | grad norm avg: 10.38 | grad norm last: 11.73 | 
2025-12-28T02:39:06 | step: 630200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.9492286305176094e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.97 | consumed tokens: 322662400.0 | grad norm avg: 10.81 | grad norm last: 10.44 | 
2025-12-28T02:39:08 | step: 630300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.947918594349176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 2.88 | consumed tokens: 322713600.0 | grad norm avg: 10.6 | grad norm last: 8.4 | 
2025-12-28T02:39:10 | step: 630400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.946608921978623e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.0 | consumed tokens: 322764800.0 | grad norm avg: 10.42 | grad norm last: 10.79 | 
2025-12-28T02:39:12 | step: 630500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.9452992496080697e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.17 | consumed tokens: 322816000.0 | grad norm avg: 10.47 | grad norm last: 10.29 | 
2025-12-28T02:39:14 | step: 630600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.9439895772375166e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.16 | consumed tokens: 322867200.0 | grad norm avg: 10.43 | grad norm last: 10.57 | 
2025-12-28T02:39:16 | step: 630700 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 3.942680268664844e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.62 | consumed tokens: 322918400.0 | grad norm avg: 10.62 | grad norm last: 9.12 | 
2025-12-28T02:39:18 | step: 630800 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 3.941370960092172e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.25 | consumed tokens: 322969600.0 | grad norm avg: 10.4 | grad norm last: 9.45 | 
2025-12-28T02:39:20 | step: 630900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.9400620153173804e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.52 | consumed tokens: 323020800.0 | grad norm avg: 11.4 | grad norm last: 11.46 | 
2025-12-28T02:39:22 | step: 631000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.938753070542589e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.8 | consumed tokens: 323072000.0 | grad norm avg: 10.39 | grad norm last: 11.31 | 
2025-12-28T02:39:24 | step: 631100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.937444489565678e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.92 | consumed tokens: 323123200.0 | grad norm avg: 10.44 | grad norm last: 10.04 | 
2025-12-28T02:39:26 | step: 631200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.9361355447908863e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.66 | consumed tokens: 323174400.0 | grad norm avg: 10.54 | grad norm last: 10.31 | 
2025-12-28T02:39:28 | step: 631300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.934827327611856e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.11 | consumed tokens: 323225600.0 | grad norm avg: 10.42 | grad norm last: 9.46 | 
2025-12-28T02:39:30 | step: 631400 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 3.933518746634945e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.12 | consumed tokens: 323276800.0 | grad norm avg: 10.7 | grad norm last: 14.15 | 
2025-12-28T02:39:32 | step: 631500 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 3.932210893253796e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 5.25 | consumed tokens: 323328000.0 | grad norm avg: 10.19 | grad norm last: 12.6 | 
2025-12-28T02:39:34 | step: 631600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.9309026760747656e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.55 | consumed tokens: 323379200.0 | grad norm avg: 10.77 | grad norm last: 9.98 | 
2025-12-28T02:39:36 | step: 631700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.929594822693616e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.19 | consumed tokens: 323430400.0 | grad norm avg: 10.43 | grad norm last: 10.69 | 
2025-12-28T02:39:38 | step: 631800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.928286969312467e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.22 | consumed tokens: 323481600.0 | grad norm avg: 10.22 | grad norm last: 10.16 | 
2025-12-28T02:39:40 | step: 631900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.926979479729198e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.94 | consumed tokens: 323532800.0 | grad norm avg: 10.25 | grad norm last: 19.65 | 
2025-12-28T02:39:43 | step: 632000 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 3.925671990145929e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.41 | consumed tokens: 323584000.0 | grad norm avg: 10.6 | grad norm last: 9.92 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_632000-seen_tokens_323584000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_632000-seen_tokens_323584000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_632000-seen_tokens_323584000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_632000-seen_tokens_323584000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_632000-seen_tokens_323584000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_632000-seen_tokens_323584000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_632000-seen_tokens_323584000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_632000-seen_tokens_323584000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:39:45 | step: 632100 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 3.924364864360541e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.8 | consumed tokens: 323635200.0 | grad norm avg: 10.56 | grad norm last: 10.1 | 
2025-12-28T02:39:47 | step: 632200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.923057738575153e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.14 | consumed tokens: 323686400.0 | grad norm avg: 10.39 | grad norm last: 8.66 | 
2025-12-28T02:39:49 | step: 632300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.921750976587646e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.38 | consumed tokens: 323737600.0 | grad norm avg: 10.5 | grad norm last: 14.41 | 
2025-12-28T02:39:51 | step: 632400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.9204442146001384e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.48 | consumed tokens: 323788800.0 | grad norm avg: 10.43 | grad norm last: 11.78 | 
2025-12-28T02:39:53 | step: 632500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.919137452612631e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.62 | consumed tokens: 323840000.0 | grad norm avg: 10.22 | grad norm last: 10.19 | 
2025-12-28T02:39:55 | step: 632600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.9178310544230044e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.22 | consumed tokens: 323891200.0 | grad norm avg: 10.48 | grad norm last: 10.15 | 
2025-12-28T02:39:57 | step: 632700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.916524656233378e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.83 | consumed tokens: 323942400.0 | grad norm avg: 10.27 | grad norm last: 9.66 | 
2025-12-28T02:39:59 | step: 632800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.915218258043751e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.92 | consumed tokens: 323993600.0 | grad norm avg: 10.21 | grad norm last: 9.67 | 
2025-12-28T02:40:01 | step: 632900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.913912223652005e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.59 | consumed tokens: 324044800.0 | grad norm avg: 10.55 | grad norm last: 9.82 | 
2025-12-28T02:40:03 | step: 633000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.91260655305814e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.5 | consumed tokens: 324096000.0 | grad norm avg: 11.05 | grad norm last: 9.36 | 
2025-12-28T02:40:05 | step: 633100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.911300518666394e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.62 | consumed tokens: 324147200.0 | grad norm avg: 10.96 | grad norm last: 10.81 | 
2025-12-28T02:40:07 | step: 633200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.9099952118704095e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.03 | consumed tokens: 324198400.0 | grad norm avg: 10.46 | grad norm last: 13.11 | 
2025-12-28T02:40:09 | step: 633300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.908689541276544e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.23 | consumed tokens: 324249600.0 | grad norm avg: 10.68 | grad norm last: 9.12 | 
2025-12-28T02:40:11 | step: 633400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.90738423448056e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.27 | consumed tokens: 324300800.0 | grad norm avg: 10.18 | grad norm last: 9.13 | 
2025-12-28T02:40:13 | step: 633500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.906079291482456e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.05 | consumed tokens: 324352000.0 | grad norm avg: 10.52 | grad norm last: 9.9 | 
2025-12-28T02:40:15 | step: 633600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.904774348484352e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 5.16 | consumed tokens: 324403200.0 | grad norm avg: 10.43 | grad norm last: 20.88 | 
2025-12-28T02:40:17 | step: 633700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.9034694054862484e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.58 | consumed tokens: 324454400.0 | grad norm avg: 10.43 | grad norm last: 9.08 | 
2025-12-28T02:40:19 | step: 633800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.9021648262860253e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.22 | consumed tokens: 324505600.0 | grad norm avg: 10.74 | grad norm last: 9.06 | 
2025-12-28T02:40:21 | step: 633900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.900860247085802e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.72 | consumed tokens: 324556800.0 | grad norm avg: 10.54 | grad norm last: 9.1 | 
2025-12-28T02:40:23 | step: 634000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.89955603168346e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.14 | consumed tokens: 324608000.0 | grad norm avg: 10.9 | grad norm last: 9.97 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_634000-seen_tokens_324608000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_634000-seen_tokens_324608000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_634000-seen_tokens_324608000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_634000-seen_tokens_324608000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_634000-seen_tokens_324608000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_634000-seen_tokens_324608000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_634000-seen_tokens_324608000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_634000-seen_tokens_324608000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:40:26 | step: 634100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.8982518162811175e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.67 | train loss last: 3.16 | consumed tokens: 324659200.0 | grad norm avg: 10.29 | grad norm last: 8.51 | 
2025-12-28T02:40:28 | step: 634200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.896947600878775e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.59 | consumed tokens: 324710400.0 | grad norm avg: 10.63 | grad norm last: 12.48 | 
2025-12-28T02:40:30 | step: 634300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.8956437492743134e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.33 | consumed tokens: 324761600.0 | grad norm avg: 10.49 | grad norm last: 9.0 | 
2025-12-28T02:40:32 | step: 634400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.894339897669852e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.55 | consumed tokens: 324812800.0 | grad norm avg: 10.46 | grad norm last: 8.95 | 
2025-12-28T02:40:34 | step: 634500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.893036409863271e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.06 | consumed tokens: 324864000.0 | grad norm avg: 10.57 | grad norm last: 9.34 | 
2025-12-28T02:40:36 | step: 634600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.89173292205669e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.64 | consumed tokens: 324915200.0 | grad norm avg: 10.7 | grad norm last: 8.58 | 
2025-12-28T02:40:38 | step: 634700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.8904297980479896e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.55 | consumed tokens: 324966400.0 | grad norm avg: 10.77 | grad norm last: 9.69 | 
2025-12-28T02:40:40 | step: 634800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.8891266740392894e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.25 | consumed tokens: 325017600.0 | grad norm avg: 10.46 | grad norm last: 8.91 | 
2025-12-28T02:40:42 | step: 634900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.887823550030589e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.75 | consumed tokens: 325068800.0 | grad norm avg: 10.29 | grad norm last: 12.68 | 
2025-12-28T02:40:44 | step: 635000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.8865207898197696e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.23 | consumed tokens: 325120000.0 | grad norm avg: 10.31 | grad norm last: 9.79 | 
2025-12-28T02:40:46 | step: 635100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.88521802960895e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.81 | consumed tokens: 325171200.0 | grad norm avg: 10.34 | grad norm last: 9.75 | 
2025-12-28T02:40:48 | step: 635200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.883915633196011e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 5.91 | consumed tokens: 325222400.0 | grad norm avg: 10.79 | grad norm last: 17.45 | 
2025-12-28T02:40:50 | step: 635300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.8826132367830724e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.72 | consumed tokens: 325273600.0 | grad norm avg: 10.84 | grad norm last: 12.54 | 
2025-12-28T02:40:52 | step: 635400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.881311204168014e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.91 | consumed tokens: 325324800.0 | grad norm avg: 10.37 | grad norm last: 10.04 | 
2025-12-28T02:40:54 | step: 635500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.880009171552956e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.69 | consumed tokens: 325376000.0 | grad norm avg: 10.57 | grad norm last: 9.55 | 
2025-12-28T02:40:56 | step: 635600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.878707138937898e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.47 | consumed tokens: 325427200.0 | grad norm avg: 10.6 | grad norm last: 11.47 | 
2025-12-28T02:40:58 | step: 635700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.8774054701207206e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.42 | consumed tokens: 325478400.0 | grad norm avg: 10.3 | grad norm last: 11.21 | 
2025-12-28T02:41:00 | step: 635800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.876103801303543e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.25 | consumed tokens: 325529600.0 | grad norm avg: 10.48 | grad norm last: 10.72 | 
2025-12-28T02:41:02 | step: 635900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.8748024962842464e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.25 | consumed tokens: 325580800.0 | grad norm avg: 10.28 | grad norm last: 8.72 | 
2025-12-28T02:41:04 | step: 636000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.87350119126495e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.0 | consumed tokens: 325632000.0 | grad norm avg: 10.36 | grad norm last: 11.66 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_636000-seen_tokens_325632000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_636000-seen_tokens_325632000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_636000-seen_tokens_325632000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_636000-seen_tokens_325632000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_636000-seen_tokens_325632000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_636000-seen_tokens_325632000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_636000-seen_tokens_325632000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_636000-seen_tokens_325632000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:41:07 | step: 636100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.872200250043534e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.62 | train loss last: 3.77 | consumed tokens: 325683200.0 | grad norm avg: 10.54 | grad norm last: 9.53 | 
2025-12-28T02:41:09 | step: 636200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.870899308822118e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.48 | consumed tokens: 325734400.0 | grad norm avg: 10.54 | grad norm last: 11.26 | 
2025-12-28T02:41:11 | step: 636300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.869598367600702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.84 | consumed tokens: 325785600.0 | grad norm avg: 10.82 | grad norm last: 9.28 | 
2025-12-28T02:41:13 | step: 636400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.8682977901771665e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.83 | consumed tokens: 325836800.0 | grad norm avg: 10.72 | grad norm last: 10.2 | 
2025-12-28T02:41:15 | step: 636500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.866997212753631e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.0 | consumed tokens: 325888000.0 | grad norm avg: 10.38 | grad norm last: 11.07 | 
2025-12-28T02:41:17 | step: 636600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.8656969991279766e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.06 | consumed tokens: 325939200.0 | grad norm avg: 10.29 | grad norm last: 10.02 | 
2025-12-28T02:41:19 | step: 636700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.864396785502322e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.27 | consumed tokens: 325990400.0 | grad norm avg: 10.3 | grad norm last: 9.55 | 
2025-12-28T02:41:21 | step: 636800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.863096935674548e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.59 | consumed tokens: 326041600.0 | grad norm avg: 10.34 | grad norm last: 10.47 | 
2025-12-28T02:41:23 | step: 636900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.861797085846774e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.2 | consumed tokens: 326092800.0 | grad norm avg: 10.41 | grad norm last: 10.37 | 
2025-12-28T02:41:25 | step: 637000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.8604972360190004e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 2.92 | consumed tokens: 326144000.0 | grad norm avg: 10.62 | grad norm last: 8.85 | 
2025-12-28T02:41:27 | step: 637100 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 3.859197749989107e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.0 | consumed tokens: 326195200.0 | grad norm avg: 10.39 | grad norm last: 10.29 | 
2025-12-28T02:41:29 | step: 637200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 3.857898263959214e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.61 | consumed tokens: 326246400.0 | grad norm avg: 10.63 | grad norm last: 12.05 | 
2025-12-28T02:41:31 | step: 637300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.8565991417272016e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 2.88 | consumed tokens: 326297600.0 | grad norm avg: 10.25 | grad norm last: 9.68 | 
2025-12-28T02:41:33 | step: 637400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.855300019495189e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.52 | consumed tokens: 326348800.0 | grad norm avg: 10.45 | grad norm last: 10.02 | 
2025-12-28T02:41:35 | step: 637500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.8540012610610574e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.06 | consumed tokens: 326400000.0 | grad norm avg: 10.24 | grad norm last: 10.4 | 
2025-12-28T02:41:37 | step: 637600 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 3.852702502626926e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.47 | consumed tokens: 326451200.0 | grad norm avg: 10.78 | grad norm last: 9.12 | 
2025-12-28T02:41:39 | step: 637700 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 3.851403744192794e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.72 | consumed tokens: 326502400.0 | grad norm avg: 10.34 | grad norm last: 9.96 | 
2025-12-28T02:41:41 | step: 637800 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 3.850105349556543e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.81 | consumed tokens: 326553600.0 | grad norm avg: 10.46 | grad norm last: 10.81 | 
2025-12-28T02:41:43 | step: 637900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 3.8488073187181726e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.12 | consumed tokens: 326604800.0 | grad norm avg: 10.5 | grad norm last: 13.85 | 
2025-12-28T02:41:45 | step: 638000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.8475089240819216e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.52 | consumed tokens: 326656000.0 | grad norm avg: 10.68 | grad norm last: 9.53 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_638000-seen_tokens_326656000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_638000-seen_tokens_326656000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_638000-seen_tokens_326656000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_638000-seen_tokens_326656000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_638000-seen_tokens_326656000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_638000-seen_tokens_326656000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_638000-seen_tokens_326656000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_638000-seen_tokens_326656000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:41:48 | step: 638100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.846211257041432e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.61 | consumed tokens: 326707200.0 | grad norm avg: 10.32 | grad norm last: 9.51 | 
2025-12-28T02:41:50 | step: 638200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.8449132262030616e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.41 | consumed tokens: 326758400.0 | grad norm avg: 10.4 | grad norm last: 10.18 | 
2025-12-28T02:41:52 | step: 638300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.843615559162572e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.03 | consumed tokens: 326809600.0 | grad norm avg: 10.24 | grad norm last: 9.17 | 
2025-12-28T02:41:54 | step: 638400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.842318255919963e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.44 | consumed tokens: 326860800.0 | grad norm avg: 10.93 | grad norm last: 9.72 | 
2025-12-28T02:41:56 | step: 638500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.841020952677354e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.25 | consumed tokens: 326912000.0 | grad norm avg: 10.76 | grad norm last: 10.03 | 
2025-12-28T02:41:58 | step: 638600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.839723649434745e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.59 | consumed tokens: 326963200.0 | grad norm avg: 10.25 | grad norm last: 9.66 | 
2025-12-28T02:42:00 | step: 638700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.838426709990017e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.42 | consumed tokens: 327014400.0 | grad norm avg: 10.54 | grad norm last: 10.02 | 
2025-12-28T02:42:02 | step: 638800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.837129770545289e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 2.47 | consumed tokens: 327065600.0 | grad norm avg: 10.53 | grad norm last: 9.11 | 
2025-12-28T02:42:04 | step: 638900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.8358331948984414e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.64 | consumed tokens: 327116800.0 | grad norm avg: 10.46 | grad norm last: 10.91 | 
2025-12-28T02:42:06 | step: 639000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.834536619251594e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.27 | consumed tokens: 327168000.0 | grad norm avg: 10.6 | grad norm last: 9.05 | 
2025-12-28T02:42:08 | step: 639100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.833240407402627e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.48 | consumed tokens: 327219200.0 | grad norm avg: 10.78 | grad norm last: 11.09 | 
2025-12-28T02:42:10 | step: 639200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.8319441955536604e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.22 | consumed tokens: 327270400.0 | grad norm avg: 10.47 | grad norm last: 9.22 | 
2025-12-28T02:42:12 | step: 639300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.830648347502574e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.12 | consumed tokens: 327321600.0 | grad norm avg: 10.71 | grad norm last: 8.71 | 
2025-12-28T02:42:14 | step: 639400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.829352499451488e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.44 | consumed tokens: 327372800.0 | grad norm avg: 10.44 | grad norm last: 9.9 | 
2025-12-28T02:42:16 | step: 639500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.828056651400402e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.5 | consumed tokens: 327424000.0 | grad norm avg: 10.68 | grad norm last: 9.72 | 
2025-12-28T02:42:18 | step: 639600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.826761167147197e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 2.97 | consumed tokens: 327475200.0 | grad norm avg: 10.77 | grad norm last: 9.7 | 
2025-12-28T02:42:20 | step: 639700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.8254656828939915e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.55 | consumed tokens: 327526400.0 | grad norm avg: 10.42 | grad norm last: 10.6 | 
2025-12-28T02:42:22 | step: 639800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.824170562438667e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.73 | consumed tokens: 327577600.0 | grad norm avg: 10.84 | grad norm last: 10.07 | 
2025-12-28T02:42:24 | step: 639900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.822875441983342e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.41 | consumed tokens: 327628800.0 | grad norm avg: 10.35 | grad norm last: 11.8 | 
2025-12-28T02:42:26 | step: 640000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.8215803215280175e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.72 | consumed tokens: 327680000.0 | grad norm avg: 10.83 | grad norm last: 9.05 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_640000-seen_tokens_327680000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_640000-seen_tokens_327680000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_640000-seen_tokens_327680000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_640000-seen_tokens_327680000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_640000-seen_tokens_327680000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_640000-seen_tokens_327680000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_640000-seen_tokens_327680000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_640000-seen_tokens_327680000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:42:28 | step: 640100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.820285928668454e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.67 | train loss last: 3.12 | consumed tokens: 327731200.0 | grad norm avg: 10.33 | grad norm last: 10.21 | 
2025-12-28T02:42:30 | step: 640200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.8189911720110103e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.38 | consumed tokens: 327782400.0 | grad norm avg: 10.48 | grad norm last: 8.8 | 
2025-12-28T02:42:32 | step: 640300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.817696779151447e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.89 | consumed tokens: 327833600.0 | grad norm avg: 10.03 | grad norm last: 14.14 | 
2025-12-28T02:42:34 | step: 640400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.816402386291884e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 2.95 | consumed tokens: 327884800.0 | grad norm avg: 10.83 | grad norm last: 9.69 | 
2025-12-28T02:42:37 | step: 640500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.8151083572302014e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.06 | consumed tokens: 327936000.0 | grad norm avg: 10.41 | grad norm last: 9.96 | 
2025-12-28T02:42:39 | step: 640600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.813814328168519e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 2.94 | consumed tokens: 327987200.0 | grad norm avg: 10.43 | grad norm last: 9.14 | 
2025-12-28T02:42:41 | step: 640700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.812520662904717e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.02 | consumed tokens: 328038400.0 | grad norm avg: 10.43 | grad norm last: 9.46 | 
2025-12-28T02:42:43 | step: 640800 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.811226997640915e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.12 | consumed tokens: 328089600.0 | grad norm avg: 10.21 | grad norm last: 10.43 | 
2025-12-28T02:42:45 | step: 640900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.809933696174994e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 2.58 | consumed tokens: 328140800.0 | grad norm avg: 10.66 | grad norm last: 9.2 | 
2025-12-28T02:42:47 | step: 641000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.808640394709073e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.5 | consumed tokens: 328192000.0 | grad norm avg: 10.55 | grad norm last: 11.06 | 
2025-12-28T02:42:49 | step: 641100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.807347093243152e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.44 | consumed tokens: 328243200.0 | grad norm avg: 10.59 | grad norm last: 8.67 | 
2025-12-28T02:42:51 | step: 641200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.8060541555751115e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.94 | consumed tokens: 328294400.0 | grad norm avg: 10.52 | grad norm last: 10.86 | 
2025-12-28T02:42:53 | step: 641300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.804761581704952e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.09 | consumed tokens: 328345600.0 | grad norm avg: 10.38 | grad norm last: 9.29 | 
2025-12-28T02:42:55 | step: 641400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.803469007834792e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.92 | consumed tokens: 328396800.0 | grad norm avg: 10.41 | grad norm last: 8.15 | 
2025-12-28T02:42:57 | step: 641500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.8021764339646325e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.19 | consumed tokens: 328448000.0 | grad norm avg: 10.5 | grad norm last: 8.6 | 
2025-12-28T02:42:59 | step: 641600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.8008842238923535e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.03 | consumed tokens: 328499200.0 | grad norm avg: 10.37 | grad norm last: 11.49 | 
2025-12-28T02:43:01 | step: 641700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.7995920138200745e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.17 | consumed tokens: 328550400.0 | grad norm avg: 10.64 | grad norm last: 9.05 | 
2025-12-28T02:43:03 | step: 641800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.7982998037477955e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.22 | consumed tokens: 328601600.0 | grad norm avg: 11.17 | grad norm last: 12.12 | 
2025-12-28T02:43:05 | step: 641900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.797008321271278e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.48 | consumed tokens: 328652800.0 | grad norm avg: 10.63 | grad norm last: 9.55 | 
2025-12-28T02:43:07 | step: 642000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.79571647499688e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.17 | consumed tokens: 328704000.0 | grad norm avg: 10.48 | grad norm last: 10.41 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_642000-seen_tokens_328704000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_642000-seen_tokens_328704000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_642000-seen_tokens_328704000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_642000-seen_tokens_328704000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_642000-seen_tokens_328704000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_642000-seen_tokens_328704000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_642000-seen_tokens_328704000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_642000-seen_tokens_328704000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:43:09 | step: 642100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 3.794424992520362e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.7 | train loss last: 3.25 | consumed tokens: 328755200.0 | grad norm avg: 10.59 | grad norm last: 10.48 | 
2025-12-28T02:43:11 | step: 642200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 3.7931335100438446e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.19 | consumed tokens: 328806400.0 | grad norm avg: 10.69 | grad norm last: 10.15 | 
2025-12-28T02:43:13 | step: 642300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.791842391365208e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.36 | consumed tokens: 328857600.0 | grad norm avg: 10.27 | grad norm last: 9.58 | 
2025-12-28T02:43:16 | step: 642400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.7905516364844516e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.47 | consumed tokens: 328908800.0 | grad norm avg: 10.75 | grad norm last: 9.44 | 
2025-12-28T02:43:18 | step: 642500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.7892608816036955e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.38 | consumed tokens: 328960000.0 | grad norm avg: 10.54 | grad norm last: 9.49 | 
2025-12-28T02:43:20 | step: 642600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.787970126722939e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 2.97 | consumed tokens: 329011200.0 | grad norm avg: 10.6 | grad norm last: 9.37 | 
2025-12-28T02:43:22 | step: 642700 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 3.786679371842183e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 5.0 | consumed tokens: 329062400.0 | grad norm avg: 10.45 | grad norm last: 14.01 | 
2025-12-28T02:43:24 | step: 642800 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 3.7853893445571885e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.25 | consumed tokens: 329113600.0 | grad norm avg: 10.3 | grad norm last: 9.75 | 
2025-12-28T02:43:26 | step: 642900 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 3.784098953474313e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.45 | consumed tokens: 329164800.0 | grad norm avg: 10.43 | grad norm last: 9.76 | 
2025-12-28T02:43:28 | step: 643000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 3.782808926189318e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.52 | consumed tokens: 329216000.0 | grad norm avg: 10.38 | grad norm last: 9.58 | 
2025-12-28T02:43:30 | step: 643100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.781519262702204e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.2 | consumed tokens: 329267200.0 | grad norm avg: 10.26 | grad norm last: 8.78 | 
2025-12-28T02:43:32 | step: 643200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.78022959921509e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.53 | consumed tokens: 329318400.0 | grad norm avg: 10.47 | grad norm last: 14.38 | 
2025-12-28T02:43:34 | step: 643300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.778939935727976e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.31 | consumed tokens: 329369600.0 | grad norm avg: 10.39 | grad norm last: 9.15 | 
2025-12-28T02:43:36 | step: 643400 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 3.777650636038743e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.14 | consumed tokens: 329420800.0 | grad norm avg: 10.99 | grad norm last: 9.41 | 
2025-12-28T02:43:38 | step: 643500 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 3.7763613363495097e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.09 | consumed tokens: 329472000.0 | grad norm avg: 10.43 | grad norm last: 9.63 | 
2025-12-28T02:43:40 | step: 643600 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 3.775072400458157e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.53 | consumed tokens: 329523200.0 | grad norm avg: 10.71 | grad norm last: 9.33 | 
2025-12-28T02:43:42 | step: 643700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 3.7737834645668045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.61 | consumed tokens: 329574400.0 | grad norm avg: 10.52 | grad norm last: 11.13 | 
2025-12-28T02:43:44 | step: 643800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.7724948924733326e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.03 | consumed tokens: 329625600.0 | grad norm avg: 10.37 | grad norm last: 9.25 | 
2025-12-28T02:43:46 | step: 643900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.771206320379861e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.55 | consumed tokens: 329676800.0 | grad norm avg: 10.36 | grad norm last: 10.04 | 
2025-12-28T02:43:48 | step: 644000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.7699181120842695e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.23 | consumed tokens: 329728000.0 | grad norm avg: 10.62 | grad norm last: 9.86 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_644000-seen_tokens_329728000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_644000-seen_tokens_329728000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_644000-seen_tokens_329728000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_644000-seen_tokens_329728000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_644000-seen_tokens_329728000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_644000-seen_tokens_329728000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_644000-seen_tokens_329728000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_644000-seen_tokens_329728000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:43:50 | step: 644100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.7686299037886783e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.7 | train loss last: 3.39 | consumed tokens: 329779200.0 | grad norm avg: 10.56 | grad norm last: 10.35 | 
2025-12-28T02:43:53 | step: 644200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.767341695493087e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.25 | consumed tokens: 329830400.0 | grad norm avg: 10.48 | grad norm last: 9.05 | 
2025-12-28T02:43:55 | step: 644300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.766053850995377e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.55 | consumed tokens: 329881600.0 | grad norm avg: 10.37 | grad norm last: 9.96 | 
2025-12-28T02:43:57 | step: 644400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.764766370295547e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.94 | consumed tokens: 329932800.0 | grad norm avg: 10.42 | grad norm last: 10.72 | 
2025-12-28T02:43:59 | step: 644500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.763478889595717e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.34 | consumed tokens: 329984000.0 | grad norm avg: 10.51 | grad norm last: 9.71 | 
2025-12-28T02:44:01 | step: 644600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.7621914088958874e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.33 | consumed tokens: 330035200.0 | grad norm avg: 10.52 | grad norm last: 11.02 | 
2025-12-28T02:44:03 | step: 644700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.7609042919939384e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.22 | consumed tokens: 330086400.0 | grad norm avg: 10.77 | grad norm last: 14.47 | 
2025-12-28T02:44:05 | step: 644800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.759617175091989e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.47 | consumed tokens: 330137600.0 | grad norm avg: 10.71 | grad norm last: 9.71 | 
2025-12-28T02:44:07 | step: 644900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.758330421987921e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.84 | consumed tokens: 330188800.0 | grad norm avg: 10.58 | grad norm last: 10.7 | 
2025-12-28T02:44:09 | step: 645000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.7570436688838527e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.87 | train loss last: 3.59 | consumed tokens: 330240000.0 | grad norm avg: 10.57 | grad norm last: 9.21 | 
2025-12-28T02:44:11 | step: 645100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.755757279577665e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.98 | consumed tokens: 330291200.0 | grad norm avg: 10.34 | grad norm last: 11.37 | 
2025-12-28T02:44:13 | step: 645200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.7544708902714774e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.16 | consumed tokens: 330342400.0 | grad norm avg: 10.42 | grad norm last: 9.0 | 
2025-12-28T02:44:15 | step: 645300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 3.7531848647631705e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.89 | consumed tokens: 330393600.0 | grad norm avg: 10.8 | grad norm last: 9.99 | 
2025-12-28T02:44:17 | step: 645400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.7518988392548636e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.42 | consumed tokens: 330444800.0 | grad norm avg: 10.55 | grad norm last: 11.01 | 
2025-12-28T02:44:19 | step: 645500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.7506128137465566e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.45 | consumed tokens: 330496000.0 | grad norm avg: 10.87 | grad norm last: 10.5 | 
2025-12-28T02:44:21 | step: 645600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.7493271520361304e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.44 | consumed tokens: 330547200.0 | grad norm avg: 10.7 | grad norm last: 9.39 | 
2025-12-28T02:44:23 | step: 645700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.748041854123585e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.14 | consumed tokens: 330598400.0 | grad norm avg: 10.34 | grad norm last: 9.27 | 
2025-12-28T02:44:25 | step: 645800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.746756192413159e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.92 | consumed tokens: 330649600.0 | grad norm avg: 10.59 | grad norm last: 10.66 | 
2025-12-28T02:44:27 | step: 645900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.745471258298494e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.3 | consumed tokens: 330700800.0 | grad norm avg: 10.56 | grad norm last: 9.32 | 
2025-12-28T02:44:29 | step: 646000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.744186324183829e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.64 | consumed tokens: 330752000.0 | grad norm avg: 10.41 | grad norm last: 10.55 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_646000-seen_tokens_330752000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_646000-seen_tokens_330752000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_646000-seen_tokens_330752000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_646000-seen_tokens_330752000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_646000-seen_tokens_330752000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_646000-seen_tokens_330752000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_646000-seen_tokens_330752000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_646000-seen_tokens_330752000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:44:31 | step: 646100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.742901390069164e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.44 | consumed tokens: 330803200.0 | grad norm avg: 10.36 | grad norm last: 10.69 | 
2025-12-28T02:44:33 | step: 646200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.74161681975238e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.31 | consumed tokens: 330854400.0 | grad norm avg: 10.46 | grad norm last: 11.91 | 
2025-12-28T02:44:35 | step: 646300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.740332249435596e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.78 | consumed tokens: 330905600.0 | grad norm avg: 10.28 | grad norm last: 11.52 | 
2025-12-28T02:44:38 | step: 646400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.739048042916693e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.78 | consumed tokens: 330956800.0 | grad norm avg: 10.45 | grad norm last: 12.01 | 
2025-12-28T02:44:40 | step: 646500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.7377638363977894e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.78 | consumed tokens: 331008000.0 | grad norm avg: 10.53 | grad norm last: 10.02 | 
2025-12-28T02:44:42 | step: 646600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.736479629878886e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.56 | consumed tokens: 331059200.0 | grad norm avg: 10.3 | grad norm last: 11.43 | 
2025-12-28T02:44:44 | step: 646700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.7351957871578634e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.67 | consumed tokens: 331110400.0 | grad norm avg: 10.23 | grad norm last: 10.14 | 
2025-12-28T02:44:46 | step: 646800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.7339123082347214e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.22 | consumed tokens: 331161600.0 | grad norm avg: 10.4 | grad norm last: 10.7 | 
2025-12-28T02:44:48 | step: 646900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.7326288293115795e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.52 | consumed tokens: 331212800.0 | grad norm avg: 10.25 | grad norm last: 8.94 | 
2025-12-28T02:44:50 | step: 647000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.7313453503884375e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.78 | consumed tokens: 331264000.0 | grad norm avg: 11.34 | grad norm last: 12.56 | 
2025-12-28T02:44:52 | step: 647100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.730062235263176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.73 | consumed tokens: 331315200.0 | grad norm avg: 10.72 | grad norm last: 13.3 | 
2025-12-28T02:44:54 | step: 647200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.728779483935796e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.59 | consumed tokens: 331366400.0 | grad norm avg: 10.08 | grad norm last: 9.6 | 
2025-12-28T02:44:56 | step: 647300 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 3.727496732608415e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.03 | consumed tokens: 331417600.0 | grad norm avg: 10.33 | grad norm last: 10.83 | 
2025-12-28T02:44:58 | step: 647400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.7262139812810346e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.45 | consumed tokens: 331468800.0 | grad norm avg: 10.49 | grad norm last: 9.23 | 
2025-12-28T02:45:00 | step: 647500 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 3.724931593751535e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.56 | consumed tokens: 331520000.0 | grad norm avg: 10.83 | grad norm last: 10.52 | 
2025-12-28T02:45:02 | step: 647600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.723649206222035e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.88 | consumed tokens: 331571200.0 | grad norm avg: 10.45 | grad norm last: 11.2 | 
2025-12-28T02:45:04 | step: 647700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.722367182490416e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.88 | consumed tokens: 331622400.0 | grad norm avg: 10.65 | grad norm last: 10.08 | 
2025-12-28T02:45:06 | step: 647800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.721085158758797e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.98 | consumed tokens: 331673600.0 | grad norm avg: 10.37 | grad norm last: 10.58 | 
2025-12-28T02:45:08 | step: 647900 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 3.7198034988250583e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.66 | consumed tokens: 331724800.0 | grad norm avg: 10.27 | grad norm last: 12.16 | 
2025-12-28T02:45:10 | step: 648000 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 3.71852183889132e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 2.66 | consumed tokens: 331776000.0 | grad norm avg: 10.43 | grad norm last: 8.5 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_648000-seen_tokens_331776000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_648000-seen_tokens_331776000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_648000-seen_tokens_331776000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_648000-seen_tokens_331776000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_648000-seen_tokens_331776000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_648000-seen_tokens_331776000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_648000-seen_tokens_331776000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_648000-seen_tokens_331776000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:45:12 | step: 648100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 3.717240542755462e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.63 | train loss last: 3.06 | consumed tokens: 331827200.0 | grad norm avg: 10.48 | grad norm last: 8.86 | 
2025-12-28T02:45:14 | step: 648200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 3.7159592466196045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.88 | consumed tokens: 331878400.0 | grad norm avg: 10.66 | grad norm last: 12.71 | 
2025-12-28T02:45:16 | step: 648300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.714677950483747e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.52 | consumed tokens: 331929600.0 | grad norm avg: 10.34 | grad norm last: 10.42 | 
2025-12-28T02:45:19 | step: 648400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.71339701814577e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.3 | consumed tokens: 331980800.0 | grad norm avg: 10.33 | grad norm last: 10.55 | 
2025-12-28T02:45:21 | step: 648500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.7121164496056736e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.02 | consumed tokens: 332032000.0 | grad norm avg: 10.45 | grad norm last: 9.46 | 
2025-12-28T02:45:23 | step: 648600 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 3.710835881065577e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 5.38 | consumed tokens: 332083200.0 | grad norm avg: 10.32 | grad norm last: 11.59 | 
2025-12-28T02:45:25 | step: 648700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 3.709555312525481e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.39 | consumed tokens: 332134400.0 | grad norm avg: 10.49 | grad norm last: 8.99 | 
2025-12-28T02:45:27 | step: 648800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.7082751077832654e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 2.86 | consumed tokens: 332185600.0 | grad norm avg: 10.43 | grad norm last: 9.15 | 
2025-12-28T02:45:29 | step: 648900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 3.7069952668389305e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.69 | consumed tokens: 332236800.0 | grad norm avg: 10.34 | grad norm last: 12.37 | 
2025-12-28T02:45:31 | step: 649000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.705715425894596e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.19 | consumed tokens: 332288000.0 | grad norm avg: 10.33 | grad norm last: 13.5 | 
2025-12-28T02:45:33 | step: 649100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.704435584950261e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.69 | consumed tokens: 332339200.0 | grad norm avg: 10.42 | grad norm last: 10.58 | 
2025-12-28T02:45:35 | step: 649200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.703156107803807e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 2.83 | consumed tokens: 332390400.0 | grad norm avg: 10.31 | grad norm last: 8.3 | 
2025-12-28T02:45:37 | step: 649300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.7018766306573525e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 2.59 | consumed tokens: 332441600.0 | grad norm avg: 10.28 | grad norm last: 8.56 | 
2025-12-28T02:45:39 | step: 649400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.700597517308779e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.67 | consumed tokens: 332492800.0 | grad norm avg: 10.32 | grad norm last: 10.52 | 
2025-12-28T02:45:41 | step: 649500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.6993184039602056e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.06 | consumed tokens: 332544000.0 | grad norm avg: 10.37 | grad norm last: 11.2 | 
2025-12-28T02:45:43 | step: 649600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.698039654409513e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 5.25 | consumed tokens: 332595200.0 | grad norm avg: 10.28 | grad norm last: 10.84 | 
2025-12-28T02:45:45 | step: 649700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.69676090485882e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.72 | consumed tokens: 332646400.0 | grad norm avg: 9.99 | grad norm last: 10.5 | 
2025-12-28T02:45:47 | step: 649800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.695482519106008e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.12 | consumed tokens: 332697600.0 | grad norm avg: 10.31 | grad norm last: 11.34 | 
2025-12-28T02:45:49 | step: 649900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.694204133353196e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.03 | consumed tokens: 332748800.0 | grad norm avg: 10.4 | grad norm last: 9.88 | 
2025-12-28T02:45:51 | step: 650000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.692926111398265e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.38 | consumed tokens: 332800000.0 | grad norm avg: 10.23 | grad norm last: 14.48 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_650000-seen_tokens_332800000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_650000-seen_tokens_332800000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_650000-seen_tokens_332800000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_650000-seen_tokens_332800000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_650000-seen_tokens_332800000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_650000-seen_tokens_332800000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_650000-seen_tokens_332800000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_650000-seen_tokens_332800000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:45:53 | step: 650100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.6916480894433334e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.5 | consumed tokens: 332851200.0 | grad norm avg: 10.12 | grad norm last: 9.65 | 
2025-12-28T02:45:55 | step: 650200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.690370431286283e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.5 | consumed tokens: 332902400.0 | grad norm avg: 10.41 | grad norm last: 9.28 | 
2025-12-28T02:45:57 | step: 650300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.689092773129232e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.19 | consumed tokens: 332953600.0 | grad norm avg: 10.44 | grad norm last: 15.02 | 
2025-12-28T02:45:59 | step: 650400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.6878151149721816e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.36 | consumed tokens: 333004800.0 | grad norm avg: 10.18 | grad norm last: 9.12 | 
2025-12-28T02:46:01 | step: 650500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.686537820613012e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.22 | consumed tokens: 333056000.0 | grad norm avg: 10.36 | grad norm last: 9.41 | 
2025-12-28T02:46:03 | step: 650600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.6852608900517225e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.91 | consumed tokens: 333107200.0 | grad norm avg: 10.28 | grad norm last: 10.13 | 
2025-12-28T02:46:05 | step: 650700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.683983959490433e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.48 | consumed tokens: 333158400.0 | grad norm avg: 11.26 | grad norm last: 9.3 | 
2025-12-28T02:46:08 | step: 650800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.682707028929144e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.03 | consumed tokens: 333209600.0 | grad norm avg: 10.42 | grad norm last: 10.54 | 
2025-12-28T02:46:10 | step: 650900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.681430462165736e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.19 | consumed tokens: 333260800.0 | grad norm avg: 10.32 | grad norm last: 9.27 | 
2025-12-28T02:46:12 | step: 651000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.680154259200208e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.02 | consumed tokens: 333312000.0 | grad norm avg: 10.32 | grad norm last: 9.31 | 
2025-12-28T02:46:14 | step: 651100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.67887805623468e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.08 | consumed tokens: 333363200.0 | grad norm avg: 10.44 | grad norm last: 11.13 | 
2025-12-28T02:46:16 | step: 651200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.6776018532691523e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.83 | consumed tokens: 333414400.0 | grad norm avg: 10.62 | grad norm last: 9.68 | 
2025-12-28T02:46:18 | step: 651300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.676326014101505e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.31 | consumed tokens: 333465600.0 | grad norm avg: 10.08 | grad norm last: 9.23 | 
2025-12-28T02:46:20 | step: 651400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.675050174933858e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.22 | consumed tokens: 333516800.0 | grad norm avg: 9.9 | grad norm last: 8.42 | 
2025-12-28T02:46:22 | step: 651500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.673774699564092e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.94 | consumed tokens: 333568000.0 | grad norm avg: 10.15 | grad norm last: 9.66 | 
2025-12-28T02:46:24 | step: 651600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.6724992241943255e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.64 | consumed tokens: 333619200.0 | grad norm avg: 10.5 | grad norm last: 10.46 | 
2025-12-28T02:46:26 | step: 651700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.67122411262244e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.67 | consumed tokens: 333670400.0 | grad norm avg: 10.18 | grad norm last: 9.75 | 
2025-12-28T02:46:28 | step: 651800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.669949364848435e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.8 | consumed tokens: 333721600.0 | grad norm avg: 10.18 | grad norm last: 8.6 | 
2025-12-28T02:46:30 | step: 651900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.668674253276549e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.5 | consumed tokens: 333772800.0 | grad norm avg: 10.21 | grad norm last: 12.65 | 
2025-12-28T02:46:32 | step: 652000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.667399869300425e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.62 | consumed tokens: 333824000.0 | grad norm avg: 10.81 | grad norm last: 11.0 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_652000-seen_tokens_333824000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_652000-seen_tokens_333824000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_652000-seen_tokens_333824000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_652000-seen_tokens_333824000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_652000-seen_tokens_333824000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_652000-seen_tokens_333824000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_652000-seen_tokens_333824000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_652000-seen_tokens_333824000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:46:34 | step: 652100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.66612512152642e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.83 | consumed tokens: 333875200.0 | grad norm avg: 10.18 | grad norm last: 9.99 | 
2025-12-28T02:46:36 | step: 652200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.6648511013481766e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.52 | consumed tokens: 333926400.0 | grad norm avg: 10.16 | grad norm last: 9.53 | 
2025-12-28T02:46:38 | step: 652300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.6635767173720524e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.69 | consumed tokens: 333977600.0 | grad norm avg: 10.17 | grad norm last: 9.08 | 
2025-12-28T02:46:40 | step: 652400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.6623030609916896e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.78 | consumed tokens: 334028800.0 | grad norm avg: 10.27 | grad norm last: 9.7 | 
2025-12-28T02:46:42 | step: 652500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.661029040813446e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.97 | consumed tokens: 334080000.0 | grad norm avg: 10.49 | grad norm last: 9.96 | 
2025-12-28T02:46:44 | step: 652600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.659755384433083e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.62 | consumed tokens: 334131200.0 | grad norm avg: 10.07 | grad norm last: 9.15 | 
2025-12-28T02:46:46 | step: 652700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 3.658482091850601e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.03 | consumed tokens: 334182400.0 | grad norm avg: 10.14 | grad norm last: 11.33 | 
2025-12-28T02:46:48 | step: 652800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.657208799268119e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.81 | consumed tokens: 334233600.0 | grad norm avg: 10.37 | grad norm last: 10.13 | 
2025-12-28T02:46:50 | step: 652900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.6559358704835176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.88 | consumed tokens: 334284800.0 | grad norm avg: 10.26 | grad norm last: 9.65 | 
2025-12-28T02:46:52 | step: 653000 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 3.654662941698916e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.0 | consumed tokens: 334336000.0 | grad norm avg: 10.14 | grad norm last: 12.76 | 
2025-12-28T02:46:55 | step: 653100 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 3.6533903767121956e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 2.97 | consumed tokens: 334387200.0 | grad norm avg: 10.07 | grad norm last: 9.33 | 
2025-12-28T02:46:57 | step: 653200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 3.652117811725475e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.91 | consumed tokens: 334438400.0 | grad norm avg: 10.29 | grad norm last: 11.05 | 
2025-12-28T02:46:59 | step: 653300 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 3.650845246738754e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.34 | consumed tokens: 334489600.0 | grad norm avg: 10.6 | grad norm last: 11.04 | 
2025-12-28T02:47:01 | step: 653400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.649573045549914e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 3.81 | consumed tokens: 334540800.0 | grad norm avg: 10.33 | grad norm last: 9.22 | 
2025-12-28T02:47:03 | step: 653500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.648301208158955e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.44 | consumed tokens: 334592000.0 | grad norm avg: 10.64 | grad norm last: 11.79 | 
2025-12-28T02:47:05 | step: 653600 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 3.647029370767996e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.45 | consumed tokens: 334643200.0 | grad norm avg: 10.08 | grad norm last: 8.96 | 
2025-12-28T02:47:07 | step: 653700 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 3.645757897174917e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.25 | consumed tokens: 334694400.0 | grad norm avg: 10.27 | grad norm last: 9.58 | 
2025-12-28T02:47:09 | step: 653800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 3.6444864235818386e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.14 | consumed tokens: 334745600.0 | grad norm avg: 10.66 | grad norm last: 9.12 | 
2025-12-28T02:47:11 | step: 653900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 3.64321494998876e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.2 | consumed tokens: 334796800.0 | grad norm avg: 10.26 | grad norm last: 8.7 | 
2025-12-28T02:47:13 | step: 654000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.641943840193562e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.8 | consumed tokens: 334848000.0 | grad norm avg: 10.28 | grad norm last: 10.36 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_654000-seen_tokens_334848000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_654000-seen_tokens_334848000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_654000-seen_tokens_334848000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_654000-seen_tokens_334848000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_654000-seen_tokens_334848000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_654000-seen_tokens_334848000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_654000-seen_tokens_334848000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_654000-seen_tokens_334848000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:47:15 | step: 654100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.640673094196245e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.69 | train loss last: 3.53 | consumed tokens: 334899200.0 | grad norm avg: 10.33 | grad norm last: 10.14 | 
2025-12-28T02:47:17 | step: 654200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.639402348198928e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 2.94 | consumed tokens: 334950400.0 | grad norm avg: 10.13 | grad norm last: 10.22 | 
2025-12-28T02:47:19 | step: 654300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.638131602201611e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.25 | consumed tokens: 335001600.0 | grad norm avg: 10.11 | grad norm last: 8.7 | 
2025-12-28T02:47:21 | step: 654400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.6368612200021744e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.92 | consumed tokens: 335052800.0 | grad norm avg: 10.41 | grad norm last: 11.4 | 
2025-12-28T02:47:23 | step: 654500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.6355912016006187e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.12 | consumed tokens: 335104000.0 | grad norm avg: 10.12 | grad norm last: 9.25 | 
2025-12-28T02:47:25 | step: 654600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.634321183199063e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.05 | consumed tokens: 335155200.0 | grad norm avg: 10.46 | grad norm last: 9.85 | 
2025-12-28T02:47:27 | step: 654700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.633051164797507e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.0 | consumed tokens: 335206400.0 | grad norm avg: 10.26 | grad norm last: 10.49 | 
2025-12-28T02:47:29 | step: 654800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.631781510193832e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.25 | consumed tokens: 335257600.0 | grad norm avg: 10.36 | grad norm last: 10.1 | 
2025-12-28T02:47:31 | step: 654900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.630512219388038e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.08 | consumed tokens: 335308800.0 | grad norm avg: 10.36 | grad norm last: 9.49 | 
2025-12-28T02:47:33 | step: 655000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.6292429285822436e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.88 | consumed tokens: 335360000.0 | grad norm avg: 10.54 | grad norm last: 11.53 | 
2025-12-28T02:47:36 | step: 655100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.627973637776449e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.0 | consumed tokens: 335411200.0 | grad norm avg: 10.51 | grad norm last: 11.38 | 
2025-12-28T02:47:38 | step: 655200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.626704710768536e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.53 | consumed tokens: 335462400.0 | grad norm avg: 10.29 | grad norm last: 10.59 | 
2025-12-28T02:47:40 | step: 655300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.625435783760622e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.44 | consumed tokens: 335513600.0 | grad norm avg: 10.14 | grad norm last: 12.65 | 
2025-12-28T02:47:42 | step: 655400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.624167220550589e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.08 | consumed tokens: 335564800.0 | grad norm avg: 10.34 | grad norm last: 9.94 | 
2025-12-28T02:47:44 | step: 655500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.622899021138437e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.77 | consumed tokens: 335616000.0 | grad norm avg: 10.33 | grad norm last: 9.61 | 
2025-12-28T02:47:46 | step: 655600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.621630821726285e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.56 | consumed tokens: 335667200.0 | grad norm avg: 10.53 | grad norm last: 12.34 | 
2025-12-28T02:47:48 | step: 655700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.620362622314133e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.38 | consumed tokens: 335718400.0 | grad norm avg: 10.62 | grad norm last: 10.6 | 
2025-12-28T02:47:50 | step: 655800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.619094786699861e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.95 | consumed tokens: 335769600.0 | grad norm avg: 10.25 | grad norm last: 10.5 | 
2025-12-28T02:47:52 | step: 655900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.6178273148834705e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.17 | consumed tokens: 335820800.0 | grad norm avg: 10.31 | grad norm last: 8.6 | 
2025-12-28T02:47:54 | step: 656000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.616559479269199e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.39 | consumed tokens: 335872000.0 | grad norm avg: 10.32 | grad norm last: 8.95 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_656000-seen_tokens_335872000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_656000-seen_tokens_335872000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_656000-seen_tokens_335872000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_656000-seen_tokens_335872000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_656000-seen_tokens_335872000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_656000-seen_tokens_335872000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_656000-seen_tokens_335872000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_656000-seen_tokens_335872000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:47:56 | step: 656100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.615292371250689e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.03 | consumed tokens: 335923200.0 | grad norm avg: 10.34 | grad norm last: 9.27 | 
2025-12-28T02:47:58 | step: 656200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.614025263232179e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.39 | consumed tokens: 335974400.0 | grad norm avg: 10.65 | grad norm last: 10.31 | 
2025-12-28T02:48:00 | step: 656300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.612758155213669e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.11 | consumed tokens: 336025600.0 | grad norm avg: 10.2 | grad norm last: 9.31 | 
2025-12-28T02:48:02 | step: 656400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.6114914109930396e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.44 | consumed tokens: 336076800.0 | grad norm avg: 10.31 | grad norm last: 10.51 | 
2025-12-28T02:48:04 | step: 656500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.61022466677241e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.03 | consumed tokens: 336128000.0 | grad norm avg: 10.03 | grad norm last: 10.15 | 
2025-12-28T02:48:06 | step: 656600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.6089582863496616e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.95 | consumed tokens: 336179200.0 | grad norm avg: 10.5 | grad norm last: 10.5 | 
2025-12-28T02:48:08 | step: 656700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.607692269724794e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 5.84 | consumed tokens: 336230400.0 | grad norm avg: 10.56 | grad norm last: 20.67 | 
2025-12-28T02:48:10 | step: 656800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.606426253099926e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.72 | consumed tokens: 336281600.0 | grad norm avg: 10.26 | grad norm last: 14.49 | 
2025-12-28T02:48:12 | step: 656900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.605160236475058e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.58 | consumed tokens: 336332800.0 | grad norm avg: 10.36 | grad norm last: 9.98 | 
2025-12-28T02:48:14 | step: 657000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.603894583648071e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.41 | consumed tokens: 336384000.0 | grad norm avg: 10.33 | grad norm last: 9.15 | 
2025-12-28T02:48:16 | step: 657100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.6026289308210835e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.47 | consumed tokens: 336435200.0 | grad norm avg: 10.38 | grad norm last: 9.77 | 
2025-12-28T02:48:18 | step: 657200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.601363641791977e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.62 | consumed tokens: 336486400.0 | grad norm avg: 10.31 | grad norm last: 8.7 | 
2025-12-28T02:48:20 | step: 657300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.600098716560751e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.25 | consumed tokens: 336537600.0 | grad norm avg: 10.36 | grad norm last: 11.69 | 
2025-12-28T02:48:22 | step: 657400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.5988337913295254e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.7 | consumed tokens: 336588800.0 | grad norm avg: 10.32 | grad norm last: 10.21 | 
2025-12-28T02:48:24 | step: 657500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.5975688660982996e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.27 | consumed tokens: 336640000.0 | grad norm avg: 10.08 | grad norm last: 9.39 | 
2025-12-28T02:48:26 | step: 657600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.5963043046649545e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.92 | consumed tokens: 336691200.0 | grad norm avg: 10.35 | grad norm last: 9.88 | 
2025-12-28T02:48:28 | step: 657700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.5950397432316095e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.7 | consumed tokens: 336742400.0 | grad norm avg: 10.22 | grad norm last: 10.13 | 
2025-12-28T02:48:31 | step: 657800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 3.593775545596145e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.03 | consumed tokens: 336793600.0 | grad norm avg: 10.43 | grad norm last: 10.45 | 
2025-12-28T02:48:33 | step: 657900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.5925117117585614e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.19 | consumed tokens: 336844800.0 | grad norm avg: 10.31 | grad norm last: 8.79 | 
2025-12-28T02:48:35 | step: 658000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.591247877920978e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.19 | consumed tokens: 336896000.0 | grad norm avg: 10.27 | grad norm last: 10.34 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_658000-seen_tokens_336896000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_658000-seen_tokens_336896000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_658000-seen_tokens_336896000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_658000-seen_tokens_336896000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_658000-seen_tokens_336896000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_658000-seen_tokens_336896000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_658000-seen_tokens_336896000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_658000-seen_tokens_336896000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:48:37 | step: 658100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.589984044083394e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.74 | train loss last: 4.06 | consumed tokens: 336947200.0 | grad norm avg: 10.58 | grad norm last: 10.87 | 
2025-12-28T02:48:39 | step: 658200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.588720574043691e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 2.77 | consumed tokens: 336998400.0 | grad norm avg: 10.38 | grad norm last: 9.49 | 
2025-12-28T02:48:41 | step: 658300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.587457467801869e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.22 | consumed tokens: 337049600.0 | grad norm avg: 10.11 | grad norm last: 10.95 | 
2025-12-28T02:48:43 | step: 658400 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 3.586193997762166e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.19 | consumed tokens: 337100800.0 | grad norm avg: 10.44 | grad norm last: 9.55 | 
2025-12-28T02:48:45 | step: 658500 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 3.5849312553182244e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.0 | consumed tokens: 337152000.0 | grad norm avg: 10.29 | grad norm last: 9.27 | 
2025-12-28T02:48:47 | step: 658600 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 3.583668512874283e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.81 | consumed tokens: 337203200.0 | grad norm avg: 10.5 | grad norm last: 11.23 | 
2025-12-28T02:48:49 | step: 658700 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 3.5824057704303414e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.09 | consumed tokens: 337254400.0 | grad norm avg: 10.7 | grad norm last: 10.22 | 
2025-12-28T02:48:51 | step: 658800 | train samples/s: 97.1 | train mfu (16-bit): -1.0 | lr mean: 3.5811433917842805e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.38 | consumed tokens: 337305600.0 | grad norm avg: 10.27 | grad norm last: 9.69 | 
2025-12-28T02:48:53 | step: 658900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.5798813769361004e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.86 | consumed tokens: 337356800.0 | grad norm avg: 10.16 | grad norm last: 9.71 | 
2025-12-28T02:48:55 | step: 659000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 3.57861936208792e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.02 | consumed tokens: 337408000.0 | grad norm avg: 10.39 | grad norm last: 9.44 | 
2025-12-28T02:48:58 | step: 659100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.57735734723974e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.56 | consumed tokens: 337459200.0 | grad norm avg: 10.12 | grad norm last: 9.11 | 
2025-12-28T02:49:00 | step: 659200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.576095696189441e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.09 | consumed tokens: 337510400.0 | grad norm avg: 10.29 | grad norm last: 8.73 | 
2025-12-28T02:49:02 | step: 659300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.574834408937022e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.16 | consumed tokens: 337561600.0 | grad norm avg: 10.22 | grad norm last: 9.14 | 
2025-12-28T02:49:04 | step: 659400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.5735731216846034e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.58 | consumed tokens: 337612800.0 | grad norm avg: 10.23 | grad norm last: 9.94 | 
2025-12-28T02:49:06 | step: 659500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.572311834432185e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.36 | consumed tokens: 337664000.0 | grad norm avg: 10.52 | grad norm last: 9.92 | 
2025-12-28T02:49:08 | step: 659600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.5710512747755274e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.8 | consumed tokens: 337715200.0 | grad norm avg: 10.3 | grad norm last: 9.67 | 
2025-12-28T02:49:10 | step: 659700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.5697903513209894e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 6.88 | consumed tokens: 337766400.0 | grad norm avg: 10.94 | grad norm last: 15.83 | 
2025-12-28T02:49:12 | step: 659800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.568529791664332e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.48 | consumed tokens: 337817600.0 | grad norm avg: 10.65 | grad norm last: 11.91 | 
2025-12-28T02:49:14 | step: 659900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.5672695958055556e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.2 | consumed tokens: 337868800.0 | grad norm avg: 10.27 | grad norm last: 9.21 | 
2025-12-28T02:49:16 | step: 660000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.566009399946779e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.16 | consumed tokens: 337920000.0 | grad norm avg: 10.35 | grad norm last: 10.02 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_660000-seen_tokens_337920000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_660000-seen_tokens_337920000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_660000-seen_tokens_337920000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_660000-seen_tokens_337920000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_660000-seen_tokens_337920000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_660000-seen_tokens_337920000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_660000-seen_tokens_337920000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_660000-seen_tokens_337920000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:49:18 | step: 660100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.5647492040880024e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.67 | train loss last: 3.02 | consumed tokens: 337971200.0 | grad norm avg: 10.51 | grad norm last: 10.48 | 
2025-12-28T02:49:20 | step: 660200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.563489735824987e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.65 | train loss last: 3.56 | consumed tokens: 338022400.0 | grad norm avg: 10.23 | grad norm last: 9.53 | 
2025-12-28T02:49:22 | step: 660300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.5622299037640914e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.75 | consumed tokens: 338073600.0 | grad norm avg: 10.44 | grad norm last: 9.58 | 
2025-12-28T02:49:24 | step: 660400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.560970435501076e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.72 | consumed tokens: 338124800.0 | grad norm avg: 10.69 | grad norm last: 12.4 | 
2025-12-28T02:49:26 | step: 660500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.559711331035942e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.41 | consumed tokens: 338176000.0 | grad norm avg: 10.41 | grad norm last: 10.86 | 
2025-12-28T02:49:28 | step: 660600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.5584522265708074e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.56 | consumed tokens: 338227200.0 | grad norm avg: 10.29 | grad norm last: 9.57 | 
2025-12-28T02:49:30 | step: 660700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.557193485903554e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.98 | consumed tokens: 338278400.0 | grad norm avg: 10.43 | grad norm last: 9.91 | 
2025-12-28T02:49:32 | step: 660800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.5559347452363e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.23 | consumed tokens: 338329600.0 | grad norm avg: 10.14 | grad norm last: 9.26 | 
2025-12-28T02:49:34 | step: 660900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.554676368366927e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.09 | consumed tokens: 338380800.0 | grad norm avg: 10.53 | grad norm last: 10.54 | 
2025-12-28T02:49:36 | step: 661000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.553417991497554e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.91 | consumed tokens: 338432000.0 | grad norm avg: 10.44 | grad norm last: 10.43 | 
2025-12-28T02:49:38 | step: 661100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.5521599784260616e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.09 | consumed tokens: 338483200.0 | grad norm avg: 10.2 | grad norm last: 9.12 | 
2025-12-28T02:49:40 | step: 661200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.550901965354569e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.27 | consumed tokens: 338534400.0 | grad norm avg: 10.56 | grad norm last: 9.73 | 
2025-12-28T02:49:42 | step: 661300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.5496443160809577e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.03 | consumed tokens: 338585600.0 | grad norm avg: 10.2 | grad norm last: 10.73 | 
2025-12-28T02:49:44 | step: 661400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.548386666807346e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.16 | consumed tokens: 338636800.0 | grad norm avg: 10.53 | grad norm last: 10.54 | 
2025-12-28T02:49:46 | step: 661500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.547129381331615e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.8 | consumed tokens: 338688000.0 | grad norm avg: 10.44 | grad norm last: 10.75 | 
2025-12-28T02:49:49 | step: 661600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.545872095855884e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.12 | consumed tokens: 338739200.0 | grad norm avg: 10.44 | grad norm last: 9.47 | 
2025-12-28T02:49:51 | step: 661700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.544615174178034e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.78 | consumed tokens: 338790400.0 | grad norm avg: 10.38 | grad norm last: 19.07 | 
2025-12-28T02:49:53 | step: 661800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.543358252500184e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.03 | consumed tokens: 338841600.0 | grad norm avg: 10.25 | grad norm last: 9.75 | 
2025-12-28T02:49:55 | step: 661900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.5421016946202144e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.39 | consumed tokens: 338892800.0 | grad norm avg: 10.46 | grad norm last: 9.37 | 
2025-12-28T02:49:57 | step: 662000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.540845136740245e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.38 | consumed tokens: 338944000.0 | grad norm avg: 10.27 | grad norm last: 10.74 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_662000-seen_tokens_338944000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_662000-seen_tokens_338944000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_662000-seen_tokens_338944000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_662000-seen_tokens_338944000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_662000-seen_tokens_338944000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_662000-seen_tokens_338944000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_662000-seen_tokens_338944000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_662000-seen_tokens_338944000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:49:59 | step: 662100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.539588942658156e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.7 | train loss last: 3.81 | consumed tokens: 338995200.0 | grad norm avg: 10.43 | grad norm last: 11.23 | 
2025-12-28T02:50:01 | step: 662200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.538333112373948e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.58 | consumed tokens: 339046400.0 | grad norm avg: 10.7 | grad norm last: 10.51 | 
2025-12-28T02:50:03 | step: 662300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.53707728208974e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.5 | consumed tokens: 339097600.0 | grad norm avg: 10.7 | grad norm last: 10.08 | 
2025-12-28T02:50:05 | step: 662400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.535821451805532e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.47 | consumed tokens: 339148800.0 | grad norm avg: 10.54 | grad norm last: 9.82 | 
2025-12-28T02:50:07 | step: 662500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.5345659853192046e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 2.53 | consumed tokens: 339200000.0 | grad norm avg: 10.69 | grad norm last: 8.0 | 
2025-12-28T02:50:09 | step: 662600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.533310882630758e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.34 | consumed tokens: 339251200.0 | grad norm avg: 10.38 | grad norm last: 9.05 | 
2025-12-28T02:50:11 | step: 662700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.5320557799423113e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 2.94 | consumed tokens: 339302400.0 | grad norm avg: 10.17 | grad norm last: 9.57 | 
2025-12-28T02:50:13 | step: 662800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.530800677253865e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.72 | consumed tokens: 339353600.0 | grad norm avg: 10.56 | grad norm last: 10.36 | 
2025-12-28T02:50:15 | step: 662900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.529545938363299e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 2.94 | consumed tokens: 339404800.0 | grad norm avg: 10.99 | grad norm last: 9.8 | 
2025-12-28T02:50:17 | step: 663000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.5282915632706136e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.89 | consumed tokens: 339456000.0 | grad norm avg: 10.6 | grad norm last: 10.52 | 
2025-12-28T02:50:19 | step: 663100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.527037188177928e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.88 | consumed tokens: 339507200.0 | grad norm avg: 10.39 | grad norm last: 10.49 | 
2025-12-28T02:50:21 | step: 663200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.525782813085243e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.0 | consumed tokens: 339558400.0 | grad norm avg: 10.36 | grad norm last: 11.67 | 
2025-12-28T02:50:23 | step: 663300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.524529165588319e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.42 | consumed tokens: 339609600.0 | grad norm avg: 10.84 | grad norm last: 10.85 | 
2025-12-28T02:50:25 | step: 663400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.523275154293515e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.06 | consumed tokens: 339660800.0 | grad norm avg: 10.33 | grad norm last: 11.04 | 
2025-12-28T02:50:27 | step: 663500 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 3.522021506796591e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.38 | consumed tokens: 339712000.0 | grad norm avg: 10.35 | grad norm last: 11.4 | 
2025-12-28T02:50:29 | step: 663600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 3.520768223097548e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.8 | consumed tokens: 339763200.0 | grad norm avg: 10.3 | grad norm last: 8.18 | 
2025-12-28T02:50:31 | step: 663700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 3.519514939398505e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.52 | consumed tokens: 339814400.0 | grad norm avg: 10.55 | grad norm last: 9.18 | 
2025-12-28T02:50:33 | step: 663800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 3.5182620194973424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.84 | consumed tokens: 339865600.0 | grad norm avg: 10.43 | grad norm last: 10.4 | 
2025-12-28T02:50:36 | step: 663900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.51700909959618e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.03 | consumed tokens: 339916800.0 | grad norm avg: 10.56 | grad norm last: 13.33 | 
2025-12-28T02:50:38 | step: 664000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.5157565434928983e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.95 | consumed tokens: 339968000.0 | grad norm avg: 10.6 | grad norm last: 10.46 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_664000-seen_tokens_339968000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_664000-seen_tokens_339968000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_664000-seen_tokens_339968000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_664000-seen_tokens_339968000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_664000-seen_tokens_339968000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_664000-seen_tokens_339968000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_664000-seen_tokens_339968000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_664000-seen_tokens_339968000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:50:40 | step: 664100 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 3.5145043511874974e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.71 | train loss last: 3.78 | consumed tokens: 340019200.0 | grad norm avg: 10.39 | grad norm last: 9.51 | 
2025-12-28T02:50:42 | step: 664200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 3.513251795084216e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.28 | consumed tokens: 340070400.0 | grad norm avg: 10.44 | grad norm last: 9.95 | 
2025-12-28T02:50:44 | step: 664300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 3.5119999665766954e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.05 | consumed tokens: 340121600.0 | grad norm avg: 10.68 | grad norm last: 9.54 | 
2025-12-28T02:50:46 | step: 664400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 3.510748138069175e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.03 | consumed tokens: 340172800.0 | grad norm avg: 10.61 | grad norm last: 10.39 | 
2025-12-28T02:50:48 | step: 664500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.509496309561655e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.03 | consumed tokens: 340224000.0 | grad norm avg: 10.77 | grad norm last: 9.38 | 
2025-12-28T02:50:50 | step: 664600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.5082448448520154e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.7 | consumed tokens: 340275200.0 | grad norm avg: 10.44 | grad norm last: 9.65 | 
2025-12-28T02:50:52 | step: 664700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.5069937439402565e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.72 | consumed tokens: 340326400.0 | grad norm avg: 10.27 | grad norm last: 12.4 | 
2025-12-28T02:50:54 | step: 664800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.505742643028498e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 2.81 | consumed tokens: 340377600.0 | grad norm avg: 10.36 | grad norm last: 8.93 | 
2025-12-28T02:50:56 | step: 664900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.504491542116739e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.59 | consumed tokens: 340428800.0 | grad norm avg: 10.8 | grad norm last: 9.83 | 
2025-12-28T02:50:58 | step: 665000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.503240805002861e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.0 | consumed tokens: 340480000.0 | grad norm avg: 10.35 | grad norm last: 11.55 | 
2025-12-28T02:51:00 | step: 665100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.501990431686863e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.33 | consumed tokens: 340531200.0 | grad norm avg: 10.3 | grad norm last: 9.09 | 
2025-12-28T02:51:02 | step: 665200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.500740058370866e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.0 | consumed tokens: 340582400.0 | grad norm avg: 10.54 | grad norm last: 11.31 | 
2025-12-28T02:51:04 | step: 665300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.499490048852749e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.33 | consumed tokens: 340633600.0 | grad norm avg: 10.36 | grad norm last: 9.6 | 
2025-12-28T02:51:06 | step: 665400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.4982400393346325e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.03 | consumed tokens: 340684800.0 | grad norm avg: 10.58 | grad norm last: 11.68 | 
2025-12-28T02:51:08 | step: 665500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.496990029816516e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.67 | consumed tokens: 340736000.0 | grad norm avg: 10.61 | grad norm last: 9.8 | 
2025-12-28T02:51:10 | step: 665600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.4957407478941604e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.62 | consumed tokens: 340787200.0 | grad norm avg: 10.69 | grad norm last: 10.97 | 
2025-12-28T02:51:12 | step: 665700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.4944911021739244e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.31 | consumed tokens: 340838400.0 | grad norm avg: 10.84 | grad norm last: 10.5 | 
2025-12-28T02:51:14 | step: 665800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.49324218404945e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.31 | consumed tokens: 340889600.0 | grad norm avg: 11.04 | grad norm last: 9.84 | 
2025-12-28T02:51:16 | step: 665900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.4919929021270946e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.11 | consumed tokens: 340940800.0 | grad norm avg: 10.74 | grad norm last: 9.42 | 
2025-12-28T02:51:18 | step: 666000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.490744347800501e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 2.88 | consumed tokens: 340992000.0 | grad norm avg: 10.53 | grad norm last: 9.83 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_666000-seen_tokens_340992000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_666000-seen_tokens_340992000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_666000-seen_tokens_340992000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_666000-seen_tokens_340992000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_666000-seen_tokens_340992000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_666000-seen_tokens_340992000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_666000-seen_tokens_340992000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_666000-seen_tokens_340992000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:51:21 | step: 666100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.489495793473907e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.0 | consumed tokens: 341043200.0 | grad norm avg: 10.81 | grad norm last: 9.56 | 
2025-12-28T02:51:23 | step: 666200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.488247239147313e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.56 | consumed tokens: 341094400.0 | grad norm avg: 10.64 | grad norm last: 9.81 | 
2025-12-28T02:51:25 | step: 666300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.4869990486186e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 5.03 | consumed tokens: 341145600.0 | grad norm avg: 10.71 | grad norm last: 13.85 | 
2025-12-28T02:51:27 | step: 666400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.485751221887767e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.02 | consumed tokens: 341196800.0 | grad norm avg: 10.49 | grad norm last: 9.09 | 
2025-12-28T02:51:29 | step: 666500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.484503395156935e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.83 | consumed tokens: 341248000.0 | grad norm avg: 10.52 | grad norm last: 9.3 | 
2025-12-28T02:51:31 | step: 666600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.4832555684261024e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.8 | consumed tokens: 341299200.0 | grad norm avg: 10.65 | grad norm last: 9.85 | 
2025-12-28T02:51:33 | step: 666700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.4820081054931507e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.78 | consumed tokens: 341350400.0 | grad norm avg: 10.62 | grad norm last: 14.69 | 
2025-12-28T02:51:35 | step: 666800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.4807610063580796e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.56 | consumed tokens: 341401600.0 | grad norm avg: 10.95 | grad norm last: 11.24 | 
2025-12-28T02:51:37 | step: 666900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.4795139072230086e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.06 | consumed tokens: 341452800.0 | grad norm avg: 10.54 | grad norm last: 10.67 | 
2025-12-28T02:51:39 | step: 667000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.478267171885818e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.52 | consumed tokens: 341504000.0 | grad norm avg: 10.72 | grad norm last: 11.04 | 
2025-12-28T02:51:41 | step: 667100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.477020436548628e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 2.72 | consumed tokens: 341555200.0 | grad norm avg: 10.54 | grad norm last: 9.23 | 
2025-12-28T02:51:43 | step: 667200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.475774065009318e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.28 | consumed tokens: 341606400.0 | grad norm avg: 10.38 | grad norm last: 10.28 | 
2025-12-28T02:51:45 | step: 667300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.474527693470009e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 2.91 | consumed tokens: 341657600.0 | grad norm avg: 10.6 | grad norm last: 9.64 | 
2025-12-28T02:51:47 | step: 667400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.47328168572858e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.14 | consumed tokens: 341708800.0 | grad norm avg: 10.58 | grad norm last: 8.92 | 
2025-12-28T02:51:49 | step: 667500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.472035677987151e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 2.91 | consumed tokens: 341760000.0 | grad norm avg: 10.67 | grad norm last: 10.01 | 
2025-12-28T02:51:51 | step: 667600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.4707900340436026e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.67 | consumed tokens: 341811200.0 | grad norm avg: 10.63 | grad norm last: 9.99 | 
2025-12-28T02:51:53 | step: 667700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.4695443901000544e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.77 | consumed tokens: 341862400.0 | grad norm avg: 10.61 | grad norm last: 9.99 | 
2025-12-28T02:51:55 | step: 667800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.468299109954387e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.22 | consumed tokens: 341913600.0 | grad norm avg: 10.53 | grad norm last: 12.16 | 
2025-12-28T02:51:57 | step: 667900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.4670541936066e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.56 | consumed tokens: 341964800.0 | grad norm avg: 10.56 | grad norm last: 9.36 | 
2025-12-28T02:51:59 | step: 668000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.4658092772588134e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.66 | consumed tokens: 342016000.0 | grad norm avg: 10.76 | grad norm last: 9.94 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_668000-seen_tokens_342016000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_668000-seen_tokens_342016000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_668000-seen_tokens_342016000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_668000-seen_tokens_342016000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_668000-seen_tokens_342016000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_668000-seen_tokens_342016000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_668000-seen_tokens_342016000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_668000-seen_tokens_342016000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:52:02 | step: 668100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 3.4645643609110266e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.62 | train loss last: 3.94 | consumed tokens: 342067200.0 | grad norm avg: 10.46 | grad norm last: 9.93 | 
2025-12-28T02:52:04 | step: 668200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.463320172159001e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.25 | consumed tokens: 342118400.0 | grad norm avg: 10.93 | grad norm last: 9.39 | 
2025-12-28T02:52:06 | step: 668300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.462075619609095e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.25 | consumed tokens: 342169600.0 | grad norm avg: 10.94 | grad norm last: 10.34 | 
2025-12-28T02:52:08 | step: 668400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.46083143085707e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.25 | consumed tokens: 342220800.0 | grad norm avg: 10.69 | grad norm last: 11.04 | 
2025-12-28T02:52:10 | step: 668500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.459587605902925e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.28 | consumed tokens: 342272000.0 | grad norm avg: 10.65 | grad norm last: 13.77 | 
2025-12-28T02:52:12 | step: 668600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.4583437809487805e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.62 | consumed tokens: 342323200.0 | grad norm avg: 10.81 | grad norm last: 11.42 | 
2025-12-28T02:52:14 | step: 668700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 3.4571003197925165e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 2.95 | consumed tokens: 342374400.0 | grad norm avg: 10.54 | grad norm last: 9.64 | 
2025-12-28T02:52:16 | step: 668800 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 3.455857222434133e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.84 | consumed tokens: 342425600.0 | grad norm avg: 10.91 | grad norm last: 12.8 | 
2025-12-28T02:52:18 | step: 668900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.45461412507575e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.27 | consumed tokens: 342476800.0 | grad norm avg: 10.75 | grad norm last: 9.92 | 
2025-12-28T02:52:20 | step: 669000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.453371027717367e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.89 | consumed tokens: 342528000.0 | grad norm avg: 10.72 | grad norm last: 9.87 | 
2025-12-28T02:52:22 | step: 669100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.452128294156864e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 2.91 | consumed tokens: 342579200.0 | grad norm avg: 10.74 | grad norm last: 10.09 | 
2025-12-28T02:52:24 | step: 669200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.450885560596362e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.12 | consumed tokens: 342630400.0 | grad norm avg: 11.08 | grad norm last: 9.66 | 
2025-12-28T02:52:26 | step: 669300 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 3.4496435546316206e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.28 | consumed tokens: 342681600.0 | grad norm avg: 10.82 | grad norm last: 12.64 | 
2025-12-28T02:52:28 | step: 669400 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 3.448401184868999e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.31 | consumed tokens: 342732800.0 | grad norm avg: 10.91 | grad norm last: 11.04 | 
2025-12-28T02:52:30 | step: 669500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 3.447159178904258e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.8 | consumed tokens: 342784000.0 | grad norm avg: 10.8 | grad norm last: 11.74 | 
2025-12-28T02:52:32 | step: 669600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.445917536737397e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.66 | consumed tokens: 342835200.0 | grad norm avg: 10.77 | grad norm last: 10.09 | 
2025-12-28T02:52:34 | step: 669700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.444675894570537e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.42 | consumed tokens: 342886400.0 | grad norm avg: 10.46 | grad norm last: 11.07 | 
2025-12-28T02:52:36 | step: 669800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 3.443434616201557e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.73 | consumed tokens: 342937600.0 | grad norm avg: 10.69 | grad norm last: 10.32 | 
2025-12-28T02:52:38 | step: 669900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.4421933378325775e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 2.66 | consumed tokens: 342988800.0 | grad norm avg: 10.96 | grad norm last: 8.73 | 
2025-12-28T02:52:40 | step: 670000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.4409524232614785e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.66 | consumed tokens: 343040000.0 | grad norm avg: 10.52 | grad norm last: 9.83 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_670000-seen_tokens_343040000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_670000-seen_tokens_343040000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_670000-seen_tokens_343040000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_670000-seen_tokens_343040000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_670000-seen_tokens_343040000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_670000-seen_tokens_343040000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_670000-seen_tokens_343040000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_670000-seen_tokens_343040000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:52:43 | step: 670100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.4397115086903796e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.61 | consumed tokens: 343091200.0 | grad norm avg: 10.59 | grad norm last: 10.97 | 
2025-12-28T02:52:45 | step: 670200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.438470957917161e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.66 | consumed tokens: 343142400.0 | grad norm avg: 10.84 | grad norm last: 11.09 | 
2025-12-28T02:52:47 | step: 670300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.437230770941824e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.61 | consumed tokens: 343193600.0 | grad norm avg: 10.89 | grad norm last: 10.16 | 
2025-12-28T02:52:49 | step: 670400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.435990583966486e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.59 | consumed tokens: 343244800.0 | grad norm avg: 11.12 | grad norm last: 9.79 | 
2025-12-28T02:52:51 | step: 670500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.434750760789029e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.58 | consumed tokens: 343296000.0 | grad norm avg: 10.58 | grad norm last: 9.63 | 
2025-12-28T02:52:53 | step: 670600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.4335109376115724e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.67 | consumed tokens: 343347200.0 | grad norm avg: 10.82 | grad norm last: 11.27 | 
2025-12-28T02:52:55 | step: 670700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.4322711144341156e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.22 | consumed tokens: 343398400.0 | grad norm avg: 10.73 | grad norm last: 11.34 | 
2025-12-28T02:52:57 | step: 670800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.43103201885242e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.28 | consumed tokens: 343449600.0 | grad norm avg: 10.65 | grad norm last: 9.16 | 
2025-12-28T02:52:59 | step: 670900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.429792559472844e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.89 | consumed tokens: 343500800.0 | grad norm avg: 10.74 | grad norm last: 11.2 | 
2025-12-28T02:53:01 | step: 671000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.428553827689029e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.03 | consumed tokens: 343552000.0 | grad norm avg: 10.9 | grad norm last: 10.58 | 
2025-12-28T02:53:03 | step: 671100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.4273150959052145e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.8 | train loss last: 5.53 | consumed tokens: 343603200.0 | grad norm avg: 11.33 | grad norm last: 21.78 | 
2025-12-28T02:53:05 | step: 671200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.4260763641214e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 2.95 | consumed tokens: 343654400.0 | grad norm avg: 10.69 | grad norm last: 9.41 | 
2025-12-28T02:53:07 | step: 671300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.424837996135466e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.86 | consumed tokens: 343705600.0 | grad norm avg: 10.93 | grad norm last: 16.0 | 
2025-12-28T02:53:09 | step: 671400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.423599628149532e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.0 | consumed tokens: 343756800.0 | grad norm avg: 10.84 | grad norm last: 10.68 | 
2025-12-28T02:53:11 | step: 671500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.4223616239614785e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.06 | consumed tokens: 343808000.0 | grad norm avg: 10.73 | grad norm last: 11.36 | 
2025-12-28T02:53:13 | step: 671600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.421123983571306e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.03 | consumed tokens: 343859200.0 | grad norm avg: 10.63 | grad norm last: 9.03 | 
2025-12-28T02:53:15 | step: 671700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.419886343181133e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 2.95 | consumed tokens: 343910400.0 | grad norm avg: 11.41 | grad norm last: 8.82 | 
2025-12-28T02:53:17 | step: 671800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.4186490665888414e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.0 | consumed tokens: 343961600.0 | grad norm avg: 10.75 | grad norm last: 10.5 | 
2025-12-28T02:53:19 | step: 671900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.4174117899965495e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.69 | consumed tokens: 344012800.0 | grad norm avg: 10.65 | grad norm last: 11.15 | 
2025-12-28T02:53:21 | step: 672000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.416174877202138e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 6.16 | consumed tokens: 344064000.0 | grad norm avg: 11.34 | grad norm last: 34.7 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_672000-seen_tokens_344064000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_672000-seen_tokens_344064000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_672000-seen_tokens_344064000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_672000-seen_tokens_344064000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_672000-seen_tokens_344064000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_672000-seen_tokens_344064000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_672000-seen_tokens_344064000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_672000-seen_tokens_344064000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:53:23 | step: 672100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.414937964407727e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 3.88 | consumed tokens: 344115200.0 | grad norm avg: 11.2 | grad norm last: 12.26 | 
2025-12-28T02:53:26 | step: 672200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.4137014154111966e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.83 | consumed tokens: 344166400.0 | grad norm avg: 10.89 | grad norm last: 10.41 | 
2025-12-28T02:53:28 | step: 672300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.412465230212547e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.22 | consumed tokens: 344217600.0 | grad norm avg: 10.55 | grad norm last: 10.45 | 
2025-12-28T02:53:30 | step: 672400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.411229045013897e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.3 | consumed tokens: 344268800.0 | grad norm avg: 10.77 | grad norm last: 10.27 | 
2025-12-28T02:53:32 | step: 672500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.4099928598152474e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.86 | consumed tokens: 344320000.0 | grad norm avg: 10.89 | grad norm last: 10.33 | 
2025-12-28T02:53:34 | step: 672600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.408757038414478e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.11 | consumed tokens: 344371200.0 | grad norm avg: 10.92 | grad norm last: 8.82 | 
2025-12-28T02:53:36 | step: 672700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.40752158081159e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.44 | consumed tokens: 344422400.0 | grad norm avg: 10.84 | grad norm last: 10.71 | 
2025-12-28T02:53:38 | step: 672800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.4062861232087016e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.88 | consumed tokens: 344473600.0 | grad norm avg: 10.76 | grad norm last: 11.48 | 
2025-12-28T02:53:40 | step: 672900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.405051029403694e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.12 | consumed tokens: 344524800.0 | grad norm avg: 10.86 | grad norm last: 10.13 | 
2025-12-28T02:53:42 | step: 673000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.403815935598686e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.59 | consumed tokens: 344576000.0 | grad norm avg: 10.68 | grad norm last: 13.89 | 
2025-12-28T02:53:44 | step: 673100 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 3.4025812055915594e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.03 | consumed tokens: 344627200.0 | grad norm avg: 10.96 | grad norm last: 10.19 | 
2025-12-28T02:53:46 | step: 673200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.401346839382313e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.75 | consumed tokens: 344678400.0 | grad norm avg: 10.74 | grad norm last: 15.02 | 
2025-12-28T02:53:48 | step: 673300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.400112473173067e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.77 | consumed tokens: 344729600.0 | grad norm avg: 11.08 | grad norm last: 11.26 | 
2025-12-28T02:53:50 | step: 673400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.398878106963821e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.03 | consumed tokens: 344780800.0 | grad norm avg: 11.25 | grad norm last: 9.49 | 
2025-12-28T02:53:52 | step: 673500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.397644104552455e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.0 | consumed tokens: 344832000.0 | grad norm avg: 10.87 | grad norm last: 11.65 | 
2025-12-28T02:53:54 | step: 673600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.3964104659389704e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.22 | consumed tokens: 344883200.0 | grad norm avg: 10.76 | grad norm last: 11.02 | 
2025-12-28T02:53:56 | step: 673700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 3.3951768273254856e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.16 | consumed tokens: 344934400.0 | grad norm avg: 10.74 | grad norm last: 11.78 | 
2025-12-28T02:53:58 | step: 673800 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 3.3939435525098816e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.8 | consumed tokens: 344985600.0 | grad norm avg: 10.65 | grad norm last: 10.85 | 
2025-12-28T02:54:00 | step: 673900 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 3.3927102776942775e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.8 | consumed tokens: 345036800.0 | grad norm avg: 10.94 | grad norm last: 10.02 | 
2025-12-28T02:54:02 | step: 674000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.391477366676554e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.56 | consumed tokens: 345088000.0 | grad norm avg: 10.63 | grad norm last: 10.04 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_674000-seen_tokens_345088000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_674000-seen_tokens_345088000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_674000-seen_tokens_345088000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_674000-seen_tokens_345088000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_674000-seen_tokens_345088000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_674000-seen_tokens_345088000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_674000-seen_tokens_345088000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_674000-seen_tokens_345088000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:54:04 | step: 674100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.3902448194567114e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.02 | consumed tokens: 345139200.0 | grad norm avg: 10.76 | grad norm last: 10.79 | 
2025-12-28T02:54:06 | step: 674200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.389012272236869e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 5.03 | consumed tokens: 345190400.0 | grad norm avg: 10.58 | grad norm last: 15.24 | 
2025-12-28T02:54:08 | step: 674300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.387779725017026e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.78 | consumed tokens: 345241600.0 | grad norm avg: 10.69 | grad norm last: 16.41 | 
2025-12-28T02:54:11 | step: 674400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 3.386547541595064e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.77 | consumed tokens: 345292800.0 | grad norm avg: 10.7 | grad norm last: 10.73 | 
2025-12-28T02:54:13 | step: 674500 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 3.385315721970983e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 2.98 | consumed tokens: 345344000.0 | grad norm avg: 10.98 | grad norm last: 9.33 | 
2025-12-28T02:54:15 | step: 674600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.3840839023469016e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.09 | consumed tokens: 345395200.0 | grad norm avg: 10.62 | grad norm last: 9.12 | 
2025-12-28T02:54:17 | step: 674700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.382852446520701e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.62 | consumed tokens: 345446400.0 | grad norm avg: 10.86 | grad norm last: 10.7 | 
2025-12-28T02:54:19 | step: 674800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.3816209906945005e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.62 | consumed tokens: 345497600.0 | grad norm avg: 10.88 | grad norm last: 16.86 | 
2025-12-28T02:54:21 | step: 674900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.380389898666181e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 5.47 | consumed tokens: 345548800.0 | grad norm avg: 11.05 | grad norm last: 15.87 | 
2025-12-28T02:54:23 | step: 675000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.3791591704357415e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.69 | consumed tokens: 345600000.0 | grad norm avg: 11.25 | grad norm last: 10.74 | 
2025-12-28T02:54:25 | step: 675100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.3779284422053024e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.59 | consumed tokens: 345651200.0 | grad norm avg: 11.03 | grad norm last: 12.84 | 
2025-12-28T02:54:27 | step: 675200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.376697713974863e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.98 | consumed tokens: 345702400.0 | grad norm avg: 11.01 | grad norm last: 9.64 | 
2025-12-28T02:54:29 | step: 675300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.3754677133401856e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 6.09 | consumed tokens: 345753600.0 | grad norm avg: 10.85 | grad norm last: 13.42 | 
2025-12-28T02:54:31 | step: 675400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.374237348907627e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.28 | consumed tokens: 345804800.0 | grad norm avg: 10.97 | grad norm last: 10.96 | 
2025-12-28T02:54:33 | step: 675500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.37300771207083e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 2.97 | consumed tokens: 345856000.0 | grad norm avg: 11.3 | grad norm last: 10.11 | 
2025-12-28T02:54:35 | step: 675600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.3717777114361525e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.97 | consumed tokens: 345907200.0 | grad norm avg: 10.6 | grad norm last: 8.45 | 
2025-12-28T02:54:37 | step: 675700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.370548438397236e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.45 | consumed tokens: 345958400.0 | grad norm avg: 10.61 | grad norm last: 10.26 | 
2025-12-28T02:54:39 | step: 675800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.36931916535832e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.34 | consumed tokens: 346009600.0 | grad norm avg: 10.6 | grad norm last: 10.23 | 
2025-12-28T02:54:41 | step: 675900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.3680898923194036e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.47 | consumed tokens: 346060800.0 | grad norm avg: 10.55 | grad norm last: 11.26 | 
2025-12-28T02:54:43 | step: 676000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.366860983078368e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.75 | consumed tokens: 346112000.0 | grad norm avg: 10.92 | grad norm last: 11.42 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_676000-seen_tokens_346112000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_676000-seen_tokens_346112000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_676000-seen_tokens_346112000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_676000-seen_tokens_346112000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_676000-seen_tokens_346112000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_676000-seen_tokens_346112000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_676000-seen_tokens_346112000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_676000-seen_tokens_346112000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:54:45 | step: 676100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.365632437635213e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 3.69 | consumed tokens: 346163200.0 | grad norm avg: 10.95 | grad norm last: 11.49 | 
2025-12-28T02:54:47 | step: 676200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.364403892192058e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.28 | consumed tokens: 346214400.0 | grad norm avg: 10.58 | grad norm last: 11.23 | 
2025-12-28T02:54:49 | step: 676300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.363175710546784e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.78 | consumed tokens: 346265600.0 | grad norm avg: 10.94 | grad norm last: 9.51 | 
2025-12-28T02:54:51 | step: 676400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.36194752890151e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.83 | train loss last: 4.22 | consumed tokens: 346316800.0 | grad norm avg: 11.2 | grad norm last: 11.16 | 
2025-12-28T02:54:53 | step: 676500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.3607197110541165e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.64 | consumed tokens: 346368000.0 | grad norm avg: 10.69 | grad norm last: 10.38 | 
2025-12-28T02:54:55 | step: 676600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.359492257004604e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.56 | consumed tokens: 346419200.0 | grad norm avg: 10.67 | grad norm last: 10.76 | 
2025-12-28T02:54:58 | step: 676700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 3.358264802955091e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.31 | consumed tokens: 346470400.0 | grad norm avg: 10.99 | grad norm last: 10.2 | 
2025-12-28T02:55:00 | step: 676800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.357037712703459e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.72 | consumed tokens: 346521600.0 | grad norm avg: 10.67 | grad norm last: 11.88 | 
2025-12-28T02:55:02 | step: 676900 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 3.355810622451827e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.3 | consumed tokens: 346572800.0 | grad norm avg: 10.72 | grad norm last: 10.48 | 
2025-12-28T02:55:04 | step: 677000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.354583532200195e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.3 | consumed tokens: 346624000.0 | grad norm avg: 10.9 | grad norm last: 9.69 | 
2025-12-28T02:55:06 | step: 677100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.353357169544324e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.34 | consumed tokens: 346675200.0 | grad norm avg: 10.89 | grad norm last: 10.52 | 
2025-12-28T02:55:08 | step: 677200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.352130806888454e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.28 | consumed tokens: 346726400.0 | grad norm avg: 10.8 | grad norm last: 12.34 | 
2025-12-28T02:55:10 | step: 677300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.350904444232583e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.27 | consumed tokens: 346777600.0 | grad norm avg: 10.65 | grad norm last: 9.23 | 
2025-12-28T02:55:12 | step: 677400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.349678445374593e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.56 | consumed tokens: 346828800.0 | grad norm avg: 10.73 | grad norm last: 10.13 | 
2025-12-28T02:55:14 | step: 677500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.348452810314484e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.95 | consumed tokens: 346880000.0 | grad norm avg: 10.73 | grad norm last: 10.32 | 
2025-12-28T02:55:16 | step: 677600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.347227175254375e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.5 | consumed tokens: 346931200.0 | grad norm avg: 10.92 | grad norm last: 10.12 | 
2025-12-28T02:55:18 | step: 677700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.346001903992146e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.81 | consumed tokens: 346982400.0 | grad norm avg: 10.88 | grad norm last: 10.26 | 
2025-12-28T02:55:20 | step: 677800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.344776632729918e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.22 | consumed tokens: 347033600.0 | grad norm avg: 10.87 | grad norm last: 9.69 | 
2025-12-28T02:55:22 | step: 677900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.34355172526557e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.27 | consumed tokens: 347084800.0 | grad norm avg: 11.09 | grad norm last: 10.69 | 
2025-12-28T02:55:24 | step: 678000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.342326817801222e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.41 | consumed tokens: 347136000.0 | grad norm avg: 10.83 | grad norm last: 8.75 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_678000-seen_tokens_347136000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_678000-seen_tokens_347136000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_678000-seen_tokens_347136000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_678000-seen_tokens_347136000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_678000-seen_tokens_347136000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_678000-seen_tokens_347136000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_678000-seen_tokens_347136000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_678000-seen_tokens_347136000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:55:26 | step: 678100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.341102274134755e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.95 | consumed tokens: 347187200.0 | grad norm avg: 10.75 | grad norm last: 11.03 | 
2025-12-28T02:55:28 | step: 678200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 3.339878094266169e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.78 | consumed tokens: 347238400.0 | grad norm avg: 11.0 | grad norm last: 11.06 | 
2025-12-28T02:55:30 | step: 678300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.3386539143975824e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.19 | consumed tokens: 347289600.0 | grad norm avg: 10.73 | grad norm last: 10.1 | 
2025-12-28T02:55:32 | step: 678400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.337430098326877e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.86 | consumed tokens: 347340800.0 | grad norm avg: 10.67 | grad norm last: 10.14 | 
2025-12-28T02:55:34 | step: 678500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.336206282256171e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.55 | consumed tokens: 347392000.0 | grad norm avg: 10.63 | grad norm last: 9.78 | 
2025-12-28T02:55:37 | step: 678600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.334982829983346e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.47 | consumed tokens: 347443200.0 | grad norm avg: 10.74 | grad norm last: 10.54 | 
2025-12-28T02:55:39 | step: 678700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.333759377710521e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 2.8 | consumed tokens: 347494400.0 | grad norm avg: 10.77 | grad norm last: 8.51 | 
2025-12-28T02:55:41 | step: 678800 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 3.332536289235577e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.38 | consumed tokens: 347545600.0 | grad norm avg: 10.65 | grad norm last: 10.89 | 
2025-12-28T02:55:43 | step: 678900 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 3.3313135645585135e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.86 | consumed tokens: 347596800.0 | grad norm avg: 10.97 | grad norm last: 10.07 | 
2025-12-28T02:55:45 | step: 679000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 3.33009083988145e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.89 | consumed tokens: 347648000.0 | grad norm avg: 10.81 | grad norm last: 11.54 | 
2025-12-28T02:55:47 | step: 679100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 3.328868479002267e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.28 | consumed tokens: 347699200.0 | grad norm avg: 10.75 | grad norm last: 12.1 | 
2025-12-28T02:55:49 | step: 679200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.327646118123084e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.61 | consumed tokens: 347750400.0 | grad norm avg: 10.67 | grad norm last: 10.15 | 
2025-12-28T02:55:51 | step: 679300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.326424121041782e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.8 | consumed tokens: 347801600.0 | grad norm avg: 10.76 | grad norm last: 9.61 | 
2025-12-28T02:55:53 | step: 679400 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 3.32520212396048e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.52 | consumed tokens: 347852800.0 | grad norm avg: 10.66 | grad norm last: 9.54 | 
2025-12-28T02:55:55 | step: 679500 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 3.323980490677059e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.75 | consumed tokens: 347904000.0 | grad norm avg: 10.77 | grad norm last: 10.82 | 
2025-12-28T02:55:57 | step: 679600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 3.322759221191518e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.94 | consumed tokens: 347955200.0 | grad norm avg: 10.71 | grad norm last: 10.19 | 
2025-12-28T02:55:59 | step: 679700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.321537951705977e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.62 | consumed tokens: 348006400.0 | grad norm avg: 11.02 | grad norm last: 9.94 | 
2025-12-28T02:56:01 | step: 679800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.3203170460183173e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.45 | consumed tokens: 348057600.0 | grad norm avg: 10.9 | grad norm last: 9.9 | 
2025-12-28T02:56:03 | step: 679900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.3190961403306574e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 2.72 | consumed tokens: 348108800.0 | grad norm avg: 11.16 | grad norm last: 9.8 | 
2025-12-28T02:56:05 | step: 680000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.317875598440878e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.0 | consumed tokens: 348160000.0 | grad norm avg: 10.67 | grad norm last: 14.73 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_680000-seen_tokens_348160000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_680000-seen_tokens_348160000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_680000-seen_tokens_348160000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_680000-seen_tokens_348160000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_680000-seen_tokens_348160000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_680000-seen_tokens_348160000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_680000-seen_tokens_348160000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_680000-seen_tokens_348160000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:56:07 | step: 680100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.3166554203489795e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.64 | train loss last: 4.03 | consumed tokens: 348211200.0 | grad norm avg: 10.64 | grad norm last: 13.82 | 
2025-12-28T02:56:09 | step: 680200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.315435242257081e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.44 | consumed tokens: 348262400.0 | grad norm avg: 10.84 | grad norm last: 9.74 | 
2025-12-28T02:56:11 | step: 680300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.3142150641651824e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.33 | consumed tokens: 348313600.0 | grad norm avg: 10.52 | grad norm last: 9.62 | 
2025-12-28T02:56:14 | step: 680400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.312995613669045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.12 | consumed tokens: 348364800.0 | grad norm avg: 10.92 | grad norm last: 14.98 | 
2025-12-28T02:56:16 | step: 680500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.3117757993750274e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.75 | consumed tokens: 348416000.0 | grad norm avg: 10.66 | grad norm last: 11.94 | 
2025-12-28T02:56:18 | step: 680600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.310556712676771e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.23 | consumed tokens: 348467200.0 | grad norm avg: 10.86 | grad norm last: 11.27 | 
2025-12-28T02:56:20 | step: 680700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.3093376259785146e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 2.73 | consumed tokens: 348518400.0 | grad norm avg: 11.2 | grad norm last: 9.89 | 
2025-12-28T02:56:22 | step: 680800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.308118539280258e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.44 | consumed tokens: 348569600.0 | grad norm avg: 11.03 | grad norm last: 10.74 | 
2025-12-28T02:56:24 | step: 680900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.3068998163798824e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.08 | consumed tokens: 348620800.0 | grad norm avg: 10.61 | grad norm last: 9.31 | 
2025-12-28T02:56:26 | step: 681000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.3056814572773874e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.56 | consumed tokens: 348672000.0 | grad norm avg: 10.59 | grad norm last: 10.16 | 
2025-12-28T02:56:28 | step: 681100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.3044630981748924e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 2.97 | consumed tokens: 348723200.0 | grad norm avg: 10.78 | grad norm last: 11.31 | 
2025-12-28T02:56:30 | step: 681200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.303245102870278e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.44 | consumed tokens: 348774400.0 | grad norm avg: 10.8 | grad norm last: 14.3 | 
2025-12-28T02:56:32 | step: 681300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.3020274713635445e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.09 | consumed tokens: 348825600.0 | grad norm avg: 10.99 | grad norm last: 10.04 | 
2025-12-28T02:56:34 | step: 681400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.300809839856811e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.56 | consumed tokens: 348876800.0 | grad norm avg: 11.06 | grad norm last: 10.2 | 
2025-12-28T02:56:36 | step: 681500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.299592208350077e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.47 | consumed tokens: 348928000.0 | grad norm avg: 10.75 | grad norm last: 10.04 | 
2025-12-28T02:56:38 | step: 681600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.2983749406412244e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.28 | consumed tokens: 348979200.0 | grad norm avg: 10.61 | grad norm last: 9.81 | 
2025-12-28T02:56:40 | step: 681700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.297158036730252e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.89 | consumed tokens: 349030400.0 | grad norm avg: 10.94 | grad norm last: 9.68 | 
2025-12-28T02:56:42 | step: 681800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.29594113281928e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.61 | consumed tokens: 349081600.0 | grad norm avg: 10.47 | grad norm last: 11.19 | 
2025-12-28T02:56:44 | step: 681900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.2947245927061886e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 2.81 | consumed tokens: 349132800.0 | grad norm avg: 10.81 | grad norm last: 10.1 | 
2025-12-28T02:56:46 | step: 682000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.293508416390978e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.61 | consumed tokens: 349184000.0 | grad norm avg: 12.19 | grad norm last: 9.77 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_682000-seen_tokens_349184000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_682000-seen_tokens_349184000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_682000-seen_tokens_349184000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_682000-seen_tokens_349184000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_682000-seen_tokens_349184000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_682000-seen_tokens_349184000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_682000-seen_tokens_349184000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_682000-seen_tokens_349184000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:56:48 | step: 682100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.292292240075767e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 3.59 | consumed tokens: 349235200.0 | grad norm avg: 10.64 | grad norm last: 11.72 | 
2025-12-28T02:56:50 | step: 682200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.291076427558437e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.17 | consumed tokens: 349286400.0 | grad norm avg: 10.66 | grad norm last: 12.03 | 
2025-12-28T02:56:52 | step: 682300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.289860615041107e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.25 | consumed tokens: 349337600.0 | grad norm avg: 10.99 | grad norm last: 9.7 | 
2025-12-28T02:56:54 | step: 682400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.2886451663216576e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.02 | consumed tokens: 349388800.0 | grad norm avg: 10.58 | grad norm last: 10.01 | 
2025-12-28T02:56:56 | step: 682500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.287429717602208e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.42 | consumed tokens: 349440000.0 | grad norm avg: 11.15 | grad norm last: 10.22 | 
2025-12-28T02:56:58 | step: 682600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.2862146326806396e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.2 | consumed tokens: 349491200.0 | grad norm avg: 10.69 | grad norm last: 9.21 | 
2025-12-28T02:57:00 | step: 682700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.284999911556952e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.09 | consumed tokens: 349542400.0 | grad norm avg: 10.91 | grad norm last: 9.74 | 
2025-12-28T02:57:02 | step: 682800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.283785190433264e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.7 | consumed tokens: 349593600.0 | grad norm avg: 11.06 | grad norm last: 9.14 | 
2025-12-28T02:57:04 | step: 682900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.2825708331074566e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.92 | consumed tokens: 349644800.0 | grad norm avg: 10.69 | grad norm last: 10.53 | 
2025-12-28T02:57:07 | step: 683000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.2813564757816494e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.12 | consumed tokens: 349696000.0 | grad norm avg: 10.6 | grad norm last: 10.66 | 
2025-12-28T02:57:09 | step: 683100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.280142482253723e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.47 | consumed tokens: 349747200.0 | grad norm avg: 10.94 | grad norm last: 9.31 | 
2025-12-28T02:57:11 | step: 683200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 3.2789284887257963e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.45 | consumed tokens: 349798400.0 | grad norm avg: 10.72 | grad norm last: 11.77 | 
2025-12-28T02:57:13 | step: 683300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.277715222793631e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.38 | consumed tokens: 349849600.0 | grad norm avg: 10.88 | grad norm last: 10.77 | 
2025-12-28T02:57:15 | step: 683400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.2765015930635855e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.78 | consumed tokens: 349900800.0 | grad norm avg: 10.87 | grad norm last: 11.38 | 
2025-12-28T02:57:17 | step: 683500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.275288690929301e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.88 | consumed tokens: 349952000.0 | grad norm avg: 10.53 | grad norm last: 11.59 | 
2025-12-28T02:57:19 | step: 683600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.274075424997136e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.72 | consumed tokens: 350003200.0 | grad norm avg: 10.88 | grad norm last: 11.54 | 
2025-12-28T02:57:21 | step: 683700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.272862886660732e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 5.41 | consumed tokens: 350054400.0 | grad norm avg: 10.75 | grad norm last: 14.78 | 
2025-12-28T02:57:23 | step: 683800 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 3.2716503483243287e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.67 | consumed tokens: 350105600.0 | grad norm avg: 10.92 | grad norm last: 10.27 | 
2025-12-28T02:57:25 | step: 683900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 3.270438173785806e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.52 | consumed tokens: 350156800.0 | grad norm avg: 10.87 | grad norm last: 9.56 | 
2025-12-28T02:57:27 | step: 684000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 3.269225999247283e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.77 | consumed tokens: 350208000.0 | grad norm avg: 10.79 | grad norm last: 9.78 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_684000-seen_tokens_350208000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_684000-seen_tokens_350208000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_684000-seen_tokens_350208000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_684000-seen_tokens_350208000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_684000-seen_tokens_350208000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_684000-seen_tokens_350208000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_684000-seen_tokens_350208000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_684000-seen_tokens_350208000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:57:29 | step: 684100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.2680141885066405e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.7 | train loss last: 3.47 | consumed tokens: 350259200.0 | grad norm avg: 11.05 | grad norm last: 9.45 | 
2025-12-28T02:57:31 | step: 684200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.266802377765998e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.06 | consumed tokens: 350310400.0 | grad norm avg: 10.79 | grad norm last: 10.05 | 
2025-12-28T02:57:33 | step: 684300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.265590930823237e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.28 | consumed tokens: 350361600.0 | grad norm avg: 10.87 | grad norm last: 10.58 | 
2025-12-28T02:57:35 | step: 684400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.264379847678356e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.45 | consumed tokens: 350412800.0 | grad norm avg: 10.63 | grad norm last: 10.69 | 
2025-12-28T02:57:37 | step: 684500 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 3.263168764533475e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.16 | consumed tokens: 350464000.0 | grad norm avg: 10.97 | grad norm last: 11.3 | 
2025-12-28T02:57:39 | step: 684600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 3.261958045186475e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.66 | consumed tokens: 350515200.0 | grad norm avg: 10.96 | grad norm last: 9.86 | 
2025-12-28T02:57:41 | step: 684700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 3.260747325839475e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.7 | consumed tokens: 350566400.0 | grad norm avg: 10.75 | grad norm last: 9.32 | 
2025-12-28T02:57:43 | step: 684800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.2595369702903554e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.69 | consumed tokens: 350617600.0 | grad norm avg: 10.81 | grad norm last: 11.47 | 
2025-12-28T02:57:45 | step: 684900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.258326614741236e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.81 | consumed tokens: 350668800.0 | grad norm avg: 10.97 | grad norm last: 12.85 | 
2025-12-28T02:57:48 | step: 685000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.257116986787878e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.48 | consumed tokens: 350720000.0 | grad norm avg: 10.67 | grad norm last: 11.42 | 
2025-12-28T02:57:50 | step: 685100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.255906995036639e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.41 | consumed tokens: 350771200.0 | grad norm avg: 10.78 | grad norm last: 10.0 | 
2025-12-28T02:57:52 | step: 685200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.254697730881162e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.58 | consumed tokens: 350822400.0 | grad norm avg: 10.77 | grad norm last: 9.28 | 
2025-12-28T02:57:54 | step: 685300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.253488466725685e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.38 | consumed tokens: 350873600.0 | grad norm avg: 10.97 | grad norm last: 10.24 | 
2025-12-28T02:57:56 | step: 685400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.2522792025702074e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.64 | consumed tokens: 350924800.0 | grad norm avg: 10.68 | grad norm last: 10.17 | 
2025-12-28T02:57:58 | step: 685500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.251070302212611e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.56 | consumed tokens: 350976000.0 | grad norm avg: 10.88 | grad norm last: 10.08 | 
2025-12-28T02:58:00 | step: 685600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.249861765652895e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.53 | consumed tokens: 351027200.0 | grad norm avg: 10.56 | grad norm last: 10.15 | 
2025-12-28T02:58:02 | step: 685700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.248653229093179e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.2 | consumed tokens: 351078400.0 | grad norm avg: 10.73 | grad norm last: 9.83 | 
2025-12-28T02:58:04 | step: 685800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.247445056331344e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.97 | consumed tokens: 351129600.0 | grad norm avg: 10.75 | grad norm last: 9.92 | 
2025-12-28T02:58:06 | step: 685900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.2462372473673895e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.2 | consumed tokens: 351180800.0 | grad norm avg: 10.65 | grad norm last: 10.28 | 
2025-12-28T02:58:08 | step: 686000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.245029438403435e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.72 | consumed tokens: 351232000.0 | grad norm avg: 10.81 | grad norm last: 11.54 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_686000-seen_tokens_351232000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_686000-seen_tokens_351232000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_686000-seen_tokens_351232000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_686000-seen_tokens_351232000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_686000-seen_tokens_351232000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_686000-seen_tokens_351232000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_686000-seen_tokens_351232000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_686000-seen_tokens_351232000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:58:10 | step: 686100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.2438216294394806e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.66 | train loss last: 4.75 | consumed tokens: 351283200.0 | grad norm avg: 10.78 | grad norm last: 11.32 | 
2025-12-28T02:58:12 | step: 686200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.2426145480712876e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.61 | consumed tokens: 351334400.0 | grad norm avg: 10.85 | grad norm last: 12.62 | 
2025-12-28T02:58:14 | step: 686300 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 3.2414074667030945e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.69 | consumed tokens: 351385600.0 | grad norm avg: 10.9 | grad norm last: 10.61 | 
2025-12-28T02:58:16 | step: 686400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 3.2402003853349015e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.33 | consumed tokens: 351436800.0 | grad norm avg: 10.92 | grad norm last: 9.52 | 
2025-12-28T02:58:18 | step: 686500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.238993667764589e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.59 | consumed tokens: 351488000.0 | grad norm avg: 10.71 | grad norm last: 9.15 | 
2025-12-28T02:58:20 | step: 686600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.2377873139921576e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.78 | consumed tokens: 351539200.0 | grad norm avg: 11.11 | grad norm last: 10.34 | 
2025-12-28T02:58:22 | step: 686700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.236580960219726e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 2.91 | consumed tokens: 351590400.0 | grad norm avg: 10.52 | grad norm last: 8.65 | 
2025-12-28T02:58:24 | step: 686800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.235374970245175e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.56 | consumed tokens: 351641600.0 | grad norm avg: 10.9 | grad norm last: 9.75 | 
2025-12-28T02:58:26 | step: 686900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.234168980270624e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.81 | consumed tokens: 351692800.0 | grad norm avg: 11.14 | grad norm last: 10.45 | 
2025-12-28T02:58:28 | step: 687000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.232963354093954e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.69 | consumed tokens: 351744000.0 | grad norm avg: 11.05 | grad norm last: 11.24 | 
2025-12-28T02:58:30 | step: 687100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.2317580917151645e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.25 | consumed tokens: 351795200.0 | grad norm avg: 10.97 | grad norm last: 10.38 | 
2025-12-28T02:58:32 | step: 687200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.230552829336375e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.28 | consumed tokens: 351846400.0 | grad norm avg: 10.61 | grad norm last: 10.28 | 
2025-12-28T02:58:34 | step: 687300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.229347930755466e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.66 | consumed tokens: 351897600.0 | grad norm avg: 10.84 | grad norm last: 11.08 | 
2025-12-28T02:58:37 | step: 687400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.228143395972438e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.28 | consumed tokens: 351948800.0 | grad norm avg: 11.13 | grad norm last: 9.87 | 
2025-12-28T02:58:39 | step: 687500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.22693886118941e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.61 | consumed tokens: 352000000.0 | grad norm avg: 11.27 | grad norm last: 9.47 | 
2025-12-28T02:58:41 | step: 687600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.225734326406382e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.34 | consumed tokens: 352051200.0 | grad norm avg: 10.99 | grad norm last: 11.47 | 
2025-12-28T02:58:43 | step: 687700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.2245305192191154e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.17 | consumed tokens: 352102400.0 | grad norm avg: 11.07 | grad norm last: 10.22 | 
2025-12-28T02:58:45 | step: 687800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.223326348233968e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.19 | consumed tokens: 352153600.0 | grad norm avg: 10.81 | grad norm last: 9.38 | 
2025-12-28T02:58:47 | step: 687900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.222122904844582e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.53 | consumed tokens: 352204800.0 | grad norm avg: 10.77 | grad norm last: 9.45 | 
2025-12-28T02:58:49 | step: 688000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.220919461455196e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.05 | consumed tokens: 352256000.0 | grad norm avg: 10.73 | grad norm last: 9.39 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_688000-seen_tokens_352256000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_688000-seen_tokens_352256000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_688000-seen_tokens_352256000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_688000-seen_tokens_352256000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_688000-seen_tokens_352256000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_688000-seen_tokens_352256000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_688000-seen_tokens_352256000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_688000-seen_tokens_352256000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:58:51 | step: 688100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.219716381863691e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.62 | train loss last: 4.75 | consumed tokens: 352307200.0 | grad norm avg: 10.6 | grad norm last: 10.44 | 
2025-12-28T02:58:53 | step: 688200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.218513302272186e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.42 | consumed tokens: 352358400.0 | grad norm avg: 10.86 | grad norm last: 10.15 | 
2025-12-28T02:58:55 | step: 688300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.217310586478561e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.55 | consumed tokens: 352409600.0 | grad norm avg: 10.97 | grad norm last: 10.27 | 
2025-12-28T02:58:57 | step: 688400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.2161078706849366e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.16 | consumed tokens: 352460800.0 | grad norm avg: 10.84 | grad norm last: 10.18 | 
2025-12-28T02:58:59 | step: 688500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.214905518689193e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.47 | consumed tokens: 352512000.0 | grad norm avg: 10.76 | grad norm last: 10.59 | 
2025-12-28T02:59:01 | step: 688600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.21370353049133e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.09 | consumed tokens: 352563200.0 | grad norm avg: 10.8 | grad norm last: 13.29 | 
2025-12-28T02:59:03 | step: 688700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.2125015422934666e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.19 | consumed tokens: 352614400.0 | grad norm avg: 10.91 | grad norm last: 12.02 | 
2025-12-28T02:59:05 | step: 688800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.211299917893484e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.22 | consumed tokens: 352665600.0 | grad norm avg: 10.72 | grad norm last: 11.69 | 
2025-12-28T02:59:07 | step: 688900 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 3.2100986572913826e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.62 | consumed tokens: 352716800.0 | grad norm avg: 10.84 | grad norm last: 10.15 | 
2025-12-28T02:59:09 | step: 689000 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 3.208897396689281e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.47 | consumed tokens: 352768000.0 | grad norm avg: 11.14 | grad norm last: 12.44 | 
2025-12-28T02:59:11 | step: 689100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 3.20769649988506e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.89 | consumed tokens: 352819200.0 | grad norm avg: 11.22 | grad norm last: 10.06 | 
2025-12-28T02:59:13 | step: 689200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 3.206495603080839e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.83 | consumed tokens: 352870400.0 | grad norm avg: 10.72 | grad norm last: 10.98 | 
2025-12-28T02:59:15 | step: 689300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.2052950700744987e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.53 | consumed tokens: 352921600.0 | grad norm avg: 10.62 | grad norm last: 10.11 | 
2025-12-28T02:59:17 | step: 689400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.2040945370681584e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.81 | train loss last: 5.75 | consumed tokens: 352972800.0 | grad norm avg: 11.28 | grad norm last: 24.41 | 
2025-12-28T02:59:19 | step: 689500 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 3.2028947316575795e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.3 | consumed tokens: 353024000.0 | grad norm avg: 10.86 | grad norm last: 9.7 | 
2025-12-28T02:59:22 | step: 689600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 3.20169456244912e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.38 | consumed tokens: 353075200.0 | grad norm avg: 10.82 | grad norm last: 10.02 | 
2025-12-28T02:59:24 | step: 689700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 3.200495120836422e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.03 | consumed tokens: 353126400.0 | grad norm avg: 10.81 | grad norm last: 10.29 | 
2025-12-28T02:59:26 | step: 689800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 3.199295679223724e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.33 | consumed tokens: 353177600.0 | grad norm avg: 10.66 | grad norm last: 9.36 | 
2025-12-28T02:59:28 | step: 689900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.1980962376110256e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.09 | consumed tokens: 353228800.0 | grad norm avg: 11.1 | grad norm last: 10.56 | 
2025-12-28T02:59:30 | step: 690000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.196897159796208e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.41 | consumed tokens: 353280000.0 | grad norm avg: 10.6 | grad norm last: 10.45 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_690000-seen_tokens_353280000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_690000-seen_tokens_353280000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_690000-seen_tokens_353280000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_690000-seen_tokens_353280000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_690000-seen_tokens_353280000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_690000-seen_tokens_353280000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_690000-seen_tokens_353280000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_690000-seen_tokens_353280000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T02:59:32 | step: 690100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.1956984457792714e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.72 | train loss last: 3.7 | consumed tokens: 353331200.0 | grad norm avg: 11.01 | grad norm last: 10.44 | 
2025-12-28T02:59:34 | step: 690200 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 3.1945000955602154e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.39 | consumed tokens: 353382400.0 | grad norm avg: 10.81 | grad norm last: 10.07 | 
2025-12-28T02:59:36 | step: 690300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.1933017453411594e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.56 | consumed tokens: 353433600.0 | grad norm avg: 10.82 | grad norm last: 13.78 | 
2025-12-28T02:59:38 | step: 690400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.1921033951221034e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.58 | consumed tokens: 353484800.0 | grad norm avg: 10.8 | grad norm last: 9.98 | 
2025-12-28T02:59:40 | step: 690500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.190905408700928e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.58 | consumed tokens: 353536000.0 | grad norm avg: 10.87 | grad norm last: 10.1 | 
2025-12-28T02:59:42 | step: 690600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.1897077860776335e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.97 | consumed tokens: 353587200.0 | grad norm avg: 10.97 | grad norm last: 9.99 | 
2025-12-28T02:59:44 | step: 690700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.1885105272522196e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.8 | consumed tokens: 353638400.0 | grad norm avg: 10.96 | grad norm last: 10.89 | 
2025-12-28T02:59:46 | step: 690800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.187313268426806e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.8 | consumed tokens: 353689600.0 | grad norm avg: 10.78 | grad norm last: 10.52 | 
2025-12-28T02:59:48 | step: 690900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.186116009601392e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.91 | consumed tokens: 353740800.0 | grad norm avg: 11.06 | grad norm last: 11.07 | 
2025-12-28T02:59:50 | step: 691000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.1849194783717394e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.86 | consumed tokens: 353792000.0 | grad norm avg: 10.84 | grad norm last: 11.27 | 
2025-12-28T02:59:52 | step: 691100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.183722947142087e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.5 | consumed tokens: 353843200.0 | grad norm avg: 10.64 | grad norm last: 10.25 | 
2025-12-28T02:59:54 | step: 691200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.1825264159124345e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.73 | consumed tokens: 353894400.0 | grad norm avg: 11.0 | grad norm last: 10.34 | 
2025-12-28T02:59:56 | step: 691300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.181330248480663e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.44 | consumed tokens: 353945600.0 | grad norm avg: 10.72 | grad norm last: 12.94 | 
2025-12-28T02:59:58 | step: 691400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.1801344448467717e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.67 | consumed tokens: 353996800.0 | grad norm avg: 10.94 | grad norm last: 10.18 | 
2025-12-28T03:00:00 | step: 691500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.1789386412128806e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.97 | consumed tokens: 354048000.0 | grad norm avg: 12.01 | grad norm last: 11.64 | 
2025-12-28T03:00:02 | step: 691600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.17774320137687e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.28 | consumed tokens: 354099200.0 | grad norm avg: 11.07 | grad norm last: 10.21 | 
2025-12-28T03:00:04 | step: 691700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.1765481253387406e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.48 | consumed tokens: 354150400.0 | grad norm avg: 10.43 | grad norm last: 10.6 | 
2025-12-28T03:00:07 | step: 691800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.175353049300611e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.69 | consumed tokens: 354201600.0 | grad norm avg: 10.69 | grad norm last: 10.71 | 
2025-12-28T03:00:09 | step: 691900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.174158337060362e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.8 | consumed tokens: 354252800.0 | grad norm avg: 11.12 | grad norm last: 10.98 | 
2025-12-28T03:00:11 | step: 692000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.172963624820113e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.64 | consumed tokens: 354304000.0 | grad norm avg: 10.72 | grad norm last: 10.16 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_692000-seen_tokens_354304000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_692000-seen_tokens_354304000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_692000-seen_tokens_354304000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_692000-seen_tokens_354304000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_692000-seen_tokens_354304000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_692000-seen_tokens_354304000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_692000-seen_tokens_354304000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_692000-seen_tokens_354304000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:00:13 | step: 692100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.171769276377745e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.65 | train loss last: 2.61 | consumed tokens: 354355200.0 | grad norm avg: 10.83 | grad norm last: 8.56 | 
2025-12-28T03:00:15 | step: 692200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.1705752917332575e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.09 | consumed tokens: 354406400.0 | grad norm avg: 11.03 | grad norm last: 10.53 | 
2025-12-28T03:00:17 | step: 692300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.16938130708877e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.41 | consumed tokens: 354457600.0 | grad norm avg: 10.99 | grad norm last: 10.45 | 
2025-12-28T03:00:19 | step: 692400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.168187686242163e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.17 | consumed tokens: 354508800.0 | grad norm avg: 10.77 | grad norm last: 9.94 | 
2025-12-28T03:00:21 | step: 692500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.166994429193437e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.28 | consumed tokens: 354560000.0 | grad norm avg: 10.84 | grad norm last: 12.63 | 
2025-12-28T03:00:23 | step: 692600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.165801172144711e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.38 | consumed tokens: 354611200.0 | grad norm avg: 10.8 | grad norm last: 13.94 | 
2025-12-28T03:00:25 | step: 692700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.164607915095985e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 5.66 | consumed tokens: 354662400.0 | grad norm avg: 10.84 | grad norm last: 15.97 | 
2025-12-28T03:00:27 | step: 692800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.16341538564302e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.95 | consumed tokens: 354713600.0 | grad norm avg: 10.49 | grad norm last: 12.35 | 
2025-12-28T03:00:29 | step: 692900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.1622228561900556e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.98 | consumed tokens: 354764800.0 | grad norm avg: 11.1 | grad norm last: 9.13 | 
2025-12-28T03:00:31 | step: 693000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.161030326737091e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.25 | consumed tokens: 354816000.0 | grad norm avg: 11.21 | grad norm last: 10.73 | 
2025-12-28T03:00:33 | step: 693100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.159838161082007e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.27 | consumed tokens: 354867200.0 | grad norm avg: 11.22 | grad norm last: 12.17 | 
2025-12-28T03:00:35 | step: 693200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.158646359224804e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.86 | consumed tokens: 354918400.0 | grad norm avg: 10.89 | grad norm last: 9.84 | 
2025-12-28T03:00:37 | step: 693300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.157454921165481e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.7 | consumed tokens: 354969600.0 | grad norm avg: 10.71 | grad norm last: 10.36 | 
2025-12-28T03:00:39 | step: 693400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.156263483106159e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.5 | consumed tokens: 355020800.0 | grad norm avg: 10.53 | grad norm last: 9.85 | 
2025-12-28T03:00:41 | step: 693500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.155072045046836e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.81 | consumed tokens: 355072000.0 | grad norm avg: 11.03 | grad norm last: 10.02 | 
2025-12-28T03:00:43 | step: 693600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.153881334583275e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.81 | consumed tokens: 355123200.0 | grad norm avg: 11.3 | grad norm last: 11.77 | 
2025-12-28T03:00:45 | step: 693700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.152690624119714e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.58 | consumed tokens: 355174400.0 | grad norm avg: 10.82 | grad norm last: 10.87 | 
2025-12-28T03:00:47 | step: 693800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 3.151499913656153e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.75 | consumed tokens: 355225600.0 | grad norm avg: 10.91 | grad norm last: 12.56 | 
2025-12-28T03:00:49 | step: 693900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.1503095669904724e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 5.31 | consumed tokens: 355276800.0 | grad norm avg: 11.0 | grad norm last: 12.28 | 
2025-12-28T03:00:51 | step: 694000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.149119584122673e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.98 | consumed tokens: 355328000.0 | grad norm avg: 11.12 | grad norm last: 9.74 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_694000-seen_tokens_355328000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_694000-seen_tokens_355328000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_694000-seen_tokens_355328000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_694000-seen_tokens_355328000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_694000-seen_tokens_355328000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_694000-seen_tokens_355328000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_694000-seen_tokens_355328000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_694000-seen_tokens_355328000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:00:54 | step: 694100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.147929965052754e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.12 | consumed tokens: 355379200.0 | grad norm avg: 11.17 | grad norm last: 10.55 | 
2025-12-28T03:00:56 | step: 694200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.146740345982835e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.75 | consumed tokens: 355430400.0 | grad norm avg: 10.8 | grad norm last: 9.48 | 
2025-12-28T03:00:58 | step: 694300 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 3.145550726912916e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.22 | consumed tokens: 355481600.0 | grad norm avg: 11.15 | grad norm last: 9.42 | 
2025-12-28T03:01:00 | step: 694400 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 3.1443614716408774e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.5 | consumed tokens: 355532800.0 | grad norm avg: 10.69 | grad norm last: 9.81 | 
2025-12-28T03:01:02 | step: 694500 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 3.14317258016672e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.48 | consumed tokens: 355584000.0 | grad norm avg: 10.65 | grad norm last: 10.48 | 
2025-12-28T03:01:04 | step: 694600 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 3.141984052490443e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.3 | consumed tokens: 355635200.0 | grad norm avg: 10.95 | grad norm last: 10.45 | 
2025-12-28T03:01:06 | step: 694700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 3.140795524814166e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.0 | consumed tokens: 355686400.0 | grad norm avg: 10.8 | grad norm last: 12.16 | 
2025-12-28T03:01:08 | step: 694800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.13960736093577e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.59 | consumed tokens: 355737600.0 | grad norm avg: 11.02 | grad norm last: 9.36 | 
2025-12-28T03:01:10 | step: 694900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.138419197057374e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.31 | consumed tokens: 355788800.0 | grad norm avg: 11.15 | grad norm last: 11.6 | 
2025-12-28T03:01:12 | step: 695000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.1372313969768584e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.88 | consumed tokens: 355840000.0 | grad norm avg: 10.88 | grad norm last: 10.15 | 
2025-12-28T03:01:14 | step: 695100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.1360439606942236e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.56 | consumed tokens: 355891200.0 | grad norm avg: 10.65 | grad norm last: 9.33 | 
2025-12-28T03:01:16 | step: 695200 | train samples/s: 97.5 | train mfu (16-bit): -1.0 | lr mean: 3.134856524411589e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.58 | consumed tokens: 355942400.0 | grad norm avg: 11.39 | grad norm last: 10.2 | 
2025-12-28T03:01:18 | step: 695300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.133669451926835e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 2.92 | consumed tokens: 355993600.0 | grad norm avg: 11.04 | grad norm last: 9.63 | 
2025-12-28T03:01:20 | step: 695400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.132482379442081e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.73 | consumed tokens: 356044800.0 | grad norm avg: 11.24 | grad norm last: 10.9 | 
2025-12-28T03:01:22 | step: 695500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.131296034553088e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.39 | consumed tokens: 356096000.0 | grad norm avg: 10.72 | grad norm last: 10.42 | 
2025-12-28T03:01:24 | step: 695600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.130109325866215e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.31 | consumed tokens: 356147200.0 | grad norm avg: 11.24 | grad norm last: 13.62 | 
2025-12-28T03:01:27 | step: 695700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.128923344775103e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.36 | consumed tokens: 356198400.0 | grad norm avg: 10.8 | grad norm last: 9.54 | 
2025-12-28T03:01:29 | step: 695800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.127737363683991e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.94 | consumed tokens: 356249600.0 | grad norm avg: 11.06 | grad norm last: 11.89 | 
2025-12-28T03:01:31 | step: 695900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.126551382592879e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.02 | consumed tokens: 356300800.0 | grad norm avg: 10.73 | grad norm last: 9.07 | 
2025-12-28T03:01:33 | step: 696000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.125366129097529e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.66 | consumed tokens: 356352000.0 | grad norm avg: 10.85 | grad norm last: 10.89 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_696000-seen_tokens_356352000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_696000-seen_tokens_356352000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_696000-seen_tokens_356352000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_696000-seen_tokens_356352000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_696000-seen_tokens_356352000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_696000-seen_tokens_356352000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_696000-seen_tokens_356352000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_696000-seen_tokens_356352000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:01:35 | step: 696100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.124180875602178e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.34 | consumed tokens: 356403200.0 | grad norm avg: 10.92 | grad norm last: 9.86 | 
2025-12-28T03:01:37 | step: 696200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.122995622106828e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 4.06 | consumed tokens: 356454400.0 | grad norm avg: 11.16 | grad norm last: 10.57 | 
2025-12-28T03:01:39 | step: 696300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.121810732409358e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.94 | consumed tokens: 356505600.0 | grad norm avg: 11.24 | grad norm last: 11.6 | 
2025-12-28T03:01:41 | step: 696400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.120626206509769e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.31 | consumed tokens: 356556800.0 | grad norm avg: 10.81 | grad norm last: 10.72 | 
2025-12-28T03:01:43 | step: 696500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.11944168061018e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.58 | consumed tokens: 356608000.0 | grad norm avg: 10.99 | grad norm last: 12.15 | 
2025-12-28T03:01:45 | step: 696600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.1182575185084715e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.48 | consumed tokens: 356659200.0 | grad norm avg: 10.85 | grad norm last: 10.28 | 
2025-12-28T03:01:47 | step: 696700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.117073720204644e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.73 | consumed tokens: 356710400.0 | grad norm avg: 11.18 | grad norm last: 11.86 | 
2025-12-28T03:01:49 | step: 696800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.115889921900816e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.14 | consumed tokens: 356761600.0 | grad norm avg: 10.97 | grad norm last: 11.06 | 
2025-12-28T03:01:51 | step: 696900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.114706487394869e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.67 | consumed tokens: 356812800.0 | grad norm avg: 10.87 | grad norm last: 10.85 | 
2025-12-28T03:01:53 | step: 697000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.113523416686803e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.53 | consumed tokens: 356864000.0 | grad norm avg: 11.0 | grad norm last: 13.28 | 
2025-12-28T03:01:55 | step: 697100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.112340345978737e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.64 | consumed tokens: 356915200.0 | grad norm avg: 11.26 | grad norm last: 10.08 | 
2025-12-28T03:01:57 | step: 697200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.1111576390685514e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.09 | consumed tokens: 356966400.0 | grad norm avg: 11.59 | grad norm last: 12.35 | 
2025-12-28T03:01:59 | step: 697300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.109974932158366e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.19 | consumed tokens: 357017600.0 | grad norm avg: 10.88 | grad norm last: 11.24 | 
2025-12-28T03:02:01 | step: 697400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.108792589046061e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 5.69 | consumed tokens: 357068800.0 | grad norm avg: 11.33 | grad norm last: 11.91 | 
2025-12-28T03:02:03 | step: 697500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.107610609731637e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.7 | consumed tokens: 357120000.0 | grad norm avg: 10.87 | grad norm last: 14.35 | 
2025-12-28T03:02:05 | step: 697600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.1064289942150936e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.94 | consumed tokens: 357171200.0 | grad norm avg: 10.9 | grad norm last: 11.55 | 
2025-12-28T03:02:07 | step: 697700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.10524737869855e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 5.91 | consumed tokens: 357222400.0 | grad norm avg: 10.84 | grad norm last: 12.34 | 
2025-12-28T03:02:09 | step: 697800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.104065763182007e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.89 | consumed tokens: 357273600.0 | grad norm avg: 10.92 | grad norm last: 10.58 | 
2025-12-28T03:02:11 | step: 697900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.102884511463344e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.83 | consumed tokens: 357324800.0 | grad norm avg: 11.07 | grad norm last: 13.24 | 
2025-12-28T03:02:13 | step: 698000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.101703623542562e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.33 | consumed tokens: 357376000.0 | grad norm avg: 11.08 | grad norm last: 8.95 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_698000-seen_tokens_357376000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_698000-seen_tokens_357376000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_698000-seen_tokens_357376000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_698000-seen_tokens_357376000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_698000-seen_tokens_357376000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_698000-seen_tokens_357376000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_698000-seen_tokens_357376000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_698000-seen_tokens_357376000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:02:16 | step: 698100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.100523099419661e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.71 | train loss last: 4.12 | consumed tokens: 357427200.0 | grad norm avg: 10.98 | grad norm last: 11.37 | 
2025-12-28T03:02:18 | step: 698200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.0993425752967596e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.61 | consumed tokens: 357478400.0 | grad norm avg: 11.15 | grad norm last: 12.47 | 
2025-12-28T03:02:20 | step: 698300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.098162414971739e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.05 | consumed tokens: 357529600.0 | grad norm avg: 10.89 | grad norm last: 9.21 | 
2025-12-28T03:02:22 | step: 698400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.0969822546467185e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.66 | consumed tokens: 357580800.0 | grad norm avg: 10.98 | grad norm last: 11.4 | 
2025-12-28T03:02:24 | step: 698500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.0958024581195787e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.31 | consumed tokens: 357632000.0 | grad norm avg: 10.87 | grad norm last: 10.17 | 
2025-12-28T03:02:26 | step: 698600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.0946230253903195e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.0 | consumed tokens: 357683200.0 | grad norm avg: 11.11 | grad norm last: 13.08 | 
2025-12-28T03:02:28 | step: 698700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.0934435926610604e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.36 | consumed tokens: 357734400.0 | grad norm avg: 10.94 | grad norm last: 10.48 | 
2025-12-28T03:02:30 | step: 698800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.092264523729682e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.23 | consumed tokens: 357785600.0 | grad norm avg: 11.25 | grad norm last: 11.18 | 
2025-12-28T03:02:32 | step: 698900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.091085818596184e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.25 | consumed tokens: 357836800.0 | grad norm avg: 10.93 | grad norm last: 10.72 | 
2025-12-28T03:02:34 | step: 699000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.0899071134626865e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.28 | consumed tokens: 357888000.0 | grad norm avg: 11.3 | grad norm last: 9.92 | 
2025-12-28T03:02:36 | step: 699100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.0887287721270695e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.88 | consumed tokens: 357939200.0 | grad norm avg: 11.01 | grad norm last: 14.45 | 
2025-12-28T03:02:38 | step: 699200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.0875504307914525e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.66 | consumed tokens: 357990400.0 | grad norm avg: 10.93 | grad norm last: 11.9 | 
2025-12-28T03:02:40 | step: 699300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.086372817051597e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.72 | consumed tokens: 358041600.0 | grad norm avg: 11.2 | grad norm last: 10.97 | 
2025-12-28T03:02:42 | step: 699400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 3.0851948395138606e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.17 | consumed tokens: 358092800.0 | grad norm avg: 10.99 | grad norm last: 10.75 | 
2025-12-28T03:02:44 | step: 699500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 3.084017589571886e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.69 | consumed tokens: 358144000.0 | grad norm avg: 11.23 | grad norm last: 11.05 | 
2025-12-28T03:02:46 | step: 699600 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 3.082840339629911e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.84 | consumed tokens: 358195200.0 | grad norm avg: 11.0 | grad norm last: 10.4 | 
2025-12-28T03:02:48 | step: 699700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.081663453485817e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.55 | consumed tokens: 358246400.0 | grad norm avg: 11.1 | grad norm last: 10.56 | 
2025-12-28T03:02:50 | step: 699800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.0804865673417225e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.97 | consumed tokens: 358297600.0 | grad norm avg: 10.92 | grad norm last: 13.06 | 
2025-12-28T03:02:52 | step: 699900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.079310044995509e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.97 | consumed tokens: 358348800.0 | grad norm avg: 10.96 | grad norm last: 9.85 | 
2025-12-28T03:02:54 | step: 700000 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 3.0781335226492956e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.03 | consumed tokens: 358400000.0 | grad norm avg: 10.97 | grad norm last: 8.91 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_700000-seen_tokens_358400000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_700000-seen_tokens_358400000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_700000-seen_tokens_358400000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_700000-seen_tokens_358400000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_700000-seen_tokens_358400000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_700000-seen_tokens_358400000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_700000-seen_tokens_358400000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_700000-seen_tokens_358400000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:02:57 | step: 700100 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 3.0769577278988436e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.64 | train loss last: 3.02 | consumed tokens: 358451200.0 | grad norm avg: 11.23 | grad norm last: 9.95 | 
2025-12-28T03:02:59 | step: 700200 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 3.0757819331483915e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.0 | consumed tokens: 358502400.0 | grad norm avg: 11.03 | grad norm last: 10.27 | 
2025-12-28T03:03:01 | step: 700300 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 3.0746061383979395e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.19 | consumed tokens: 358553600.0 | grad norm avg: 11.35 | grad norm last: 10.51 | 
2025-12-28T03:03:03 | step: 700400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.073430707445368e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 2.91 | consumed tokens: 358604800.0 | grad norm avg: 11.12 | grad norm last: 9.32 | 
2025-12-28T03:03:05 | step: 700500 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 3.0722556402906775e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.06 | consumed tokens: 358656000.0 | grad norm avg: 10.87 | grad norm last: 13.37 | 
2025-12-28T03:03:07 | step: 700600 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 3.0710809369338676e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 5.53 | consumed tokens: 358707200.0 | grad norm avg: 10.81 | grad norm last: 11.54 | 
2025-12-28T03:03:09 | step: 700700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 3.069906233577058e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.84 | consumed tokens: 358758400.0 | grad norm avg: 10.73 | grad norm last: 10.03 | 
2025-12-28T03:03:11 | step: 700800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 3.0687318940181285e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.66 | consumed tokens: 358809600.0 | grad norm avg: 10.74 | grad norm last: 12.99 | 
2025-12-28T03:03:13 | step: 700900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.067557554459199e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.25 | consumed tokens: 358860800.0 | grad norm avg: 11.39 | grad norm last: 10.43 | 
2025-12-28T03:03:15 | step: 701000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.066383578698151e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.98 | consumed tokens: 358912000.0 | grad norm avg: 10.98 | grad norm last: 10.63 | 
2025-12-28T03:03:17 | step: 701100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.065209966734983e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.59 | consumed tokens: 358963200.0 | grad norm avg: 10.8 | grad norm last: 11.39 | 
2025-12-28T03:03:19 | step: 701200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.064036354771815e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.31 | consumed tokens: 359014400.0 | grad norm avg: 11.15 | grad norm last: 10.82 | 
2025-12-28T03:03:21 | step: 701300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.062863106606528e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.0 | consumed tokens: 359065600.0 | grad norm avg: 10.66 | grad norm last: 10.39 | 
2025-12-28T03:03:23 | step: 701400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.061690222239122e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.55 | consumed tokens: 359116800.0 | grad norm avg: 11.13 | grad norm last: 10.93 | 
2025-12-28T03:03:25 | step: 701500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.0605173378717154e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.83 | consumed tokens: 359168000.0 | grad norm avg: 11.23 | grad norm last: 9.29 | 
2025-12-28T03:03:27 | step: 701600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.05934481730219e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.34 | consumed tokens: 359219200.0 | grad norm avg: 11.03 | grad norm last: 10.4 | 
2025-12-28T03:03:29 | step: 701700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.058172296732664e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.45 | consumed tokens: 359270400.0 | grad norm avg: 10.75 | grad norm last: 10.18 | 
2025-12-28T03:03:31 | step: 701800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.057000139961019e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.02 | consumed tokens: 359321600.0 | grad norm avg: 10.81 | grad norm last: 9.89 | 
2025-12-28T03:03:33 | step: 701900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.055828346987255e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.44 | consumed tokens: 359372800.0 | grad norm avg: 10.88 | grad norm last: 9.76 | 
2025-12-28T03:03:35 | step: 702000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.0546569178113714e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.78 | consumed tokens: 359424000.0 | grad norm avg: 11.16 | grad norm last: 11.75 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_702000-seen_tokens_359424000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_702000-seen_tokens_359424000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_702000-seen_tokens_359424000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_702000-seen_tokens_359424000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_702000-seen_tokens_359424000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_702000-seen_tokens_359424000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_702000-seen_tokens_359424000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_702000-seen_tokens_359424000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:03:38 | step: 702100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.053485488635488e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.71 | train loss last: 3.33 | consumed tokens: 359475200.0 | grad norm avg: 11.12 | grad norm last: 10.03 | 
2025-12-28T03:03:40 | step: 702200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.052314423257485e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.08 | consumed tokens: 359526400.0 | grad norm avg: 11.13 | grad norm last: 9.54 | 
2025-12-28T03:03:42 | step: 702300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.051143175980542e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.33 | consumed tokens: 359577600.0 | grad norm avg: 10.93 | grad norm last: 9.39 | 
2025-12-28T03:03:44 | step: 702400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.0499728381983005e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.88 | consumed tokens: 359628800.0 | grad norm avg: 11.14 | grad norm last: 10.47 | 
2025-12-28T03:03:46 | step: 702500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.0488023185171187e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.38 | consumed tokens: 359680000.0 | grad norm avg: 10.82 | grad norm last: 10.66 | 
2025-12-28T03:03:48 | step: 702600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.0476321626338176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.7 | consumed tokens: 359731200.0 | grad norm avg: 10.75 | grad norm last: 10.8 | 
2025-12-28T03:03:50 | step: 702700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 3.046462188649457e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.45 | consumed tokens: 359782400.0 | grad norm avg: 11.08 | grad norm last: 9.61 | 
2025-12-28T03:03:52 | step: 702800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.0452923965640366e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.0 | consumed tokens: 359833600.0 | grad norm avg: 11.08 | grad norm last: 10.59 | 
2025-12-28T03:03:54 | step: 702900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.044122968276497e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.03 | consumed tokens: 359884800.0 | grad norm avg: 11.1 | grad norm last: 11.64 | 
2025-12-28T03:03:56 | step: 703000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.042953358090017e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 5.75 | consumed tokens: 359936000.0 | grad norm avg: 11.07 | grad norm last: 14.3 | 
2025-12-28T03:03:58 | step: 703100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.0417846573982388e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.14 | consumed tokens: 359987200.0 | grad norm avg: 10.86 | grad norm last: 9.39 | 
2025-12-28T03:04:00 | step: 703200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.0406159567064606e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.66 | consumed tokens: 360038400.0 | grad norm avg: 10.92 | grad norm last: 9.98 | 
2025-12-28T03:04:02 | step: 703300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.0394474379136227e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.47 | consumed tokens: 360089600.0 | grad norm avg: 11.18 | grad norm last: 12.04 | 
2025-12-28T03:04:04 | step: 703400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.038278919120785e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.0 | consumed tokens: 360140800.0 | grad norm avg: 11.31 | grad norm last: 12.11 | 
2025-12-28T03:04:06 | step: 703500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.0371107641258277e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.91 | consumed tokens: 360192000.0 | grad norm avg: 11.16 | grad norm last: 10.99 | 
2025-12-28T03:04:08 | step: 703600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 3.0359429729287513e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.56 | consumed tokens: 360243200.0 | grad norm avg: 10.76 | grad norm last: 11.12 | 
2025-12-28T03:04:10 | step: 703700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 3.0347751817316748e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.09 | consumed tokens: 360294400.0 | grad norm avg: 10.94 | grad norm last: 10.3 | 
2025-12-28T03:04:12 | step: 703800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.0336081181303598e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.19 | consumed tokens: 360345600.0 | grad norm avg: 11.34 | grad norm last: 11.14 | 
2025-12-28T03:04:14 | step: 703900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.0324408726301044e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.58 | consumed tokens: 360396800.0 | grad norm avg: 11.1 | grad norm last: 9.52 | 
2025-12-28T03:04:16 | step: 704000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.0312739909277298e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.94 | consumed tokens: 360448000.0 | grad norm avg: 10.89 | grad norm last: 11.13 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_704000-seen_tokens_360448000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_704000-seen_tokens_360448000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_704000-seen_tokens_360448000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_704000-seen_tokens_360448000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_704000-seen_tokens_360448000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_704000-seen_tokens_360448000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_704000-seen_tokens_360448000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_704000-seen_tokens_360448000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:04:18 | step: 704100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 3.0301074730232358e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.75 | consumed tokens: 360499200.0 | grad norm avg: 11.02 | grad norm last: 10.35 | 
2025-12-28T03:04:21 | step: 704200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 3.028940955118742e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.77 | consumed tokens: 360550400.0 | grad norm avg: 11.0 | grad norm last: 10.32 | 
2025-12-28T03:04:23 | step: 704300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 3.0277748010121286e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.06 | consumed tokens: 360601600.0 | grad norm avg: 10.66 | grad norm last: 9.96 | 
2025-12-28T03:04:25 | step: 704400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.0266086469055153e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 2.95 | consumed tokens: 360652800.0 | grad norm avg: 11.05 | grad norm last: 11.36 | 
2025-12-28T03:04:27 | step: 704500 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 3.025443038495723e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.73 | consumed tokens: 360704000.0 | grad norm avg: 11.1 | grad norm last: 10.23 | 
2025-12-28T03:04:29 | step: 704600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 3.024277430085931e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.69 | consumed tokens: 360755200.0 | grad norm avg: 10.97 | grad norm last: 10.96 | 
2025-12-28T03:04:31 | step: 704700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 3.0231125492719002e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.16 | consumed tokens: 360806400.0 | grad norm avg: 10.86 | grad norm last: 10.63 | 
2025-12-28T03:04:33 | step: 704800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 3.021947486558929e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.75 | consumed tokens: 360857600.0 | grad norm avg: 11.14 | grad norm last: 18.54 | 
2025-12-28T03:04:35 | step: 704900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.0207827876438387e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.03 | consumed tokens: 360908800.0 | grad norm avg: 10.78 | grad norm last: 8.91 | 
2025-12-28T03:04:37 | step: 705000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.0196182706276886e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.16 | consumed tokens: 360960000.0 | grad norm avg: 10.9 | grad norm last: 10.86 | 
2025-12-28T03:04:39 | step: 705100 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 3.0184537536115386e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.42 | consumed tokens: 361011200.0 | grad norm avg: 10.79 | grad norm last: 10.86 | 
2025-12-28T03:04:41 | step: 705200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 3.01728996419115e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.59 | consumed tokens: 361062400.0 | grad norm avg: 11.2 | grad norm last: 9.76 | 
2025-12-28T03:04:43 | step: 705300 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 3.0161261747707613e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.33 | consumed tokens: 361113600.0 | grad norm avg: 11.21 | grad norm last: 10.85 | 
2025-12-28T03:04:45 | step: 705400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 3.014962567249313e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.61 | consumed tokens: 361164800.0 | grad norm avg: 11.49 | grad norm last: 12.56 | 
2025-12-28T03:04:47 | step: 705500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 3.013799141626805e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.44 | consumed tokens: 361216000.0 | grad norm avg: 10.92 | grad norm last: 10.5 | 
2025-12-28T03:04:49 | step: 705600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.0126358979032375e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.38 | consumed tokens: 361267200.0 | grad norm avg: 10.63 | grad norm last: 11.46 | 
2025-12-28T03:04:51 | step: 705700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 3.011473199876491e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.3 | consumed tokens: 361318400.0 | grad norm avg: 11.35 | grad norm last: 10.21 | 
2025-12-28T03:04:53 | step: 705800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.0103105018497445e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.39 | consumed tokens: 361369600.0 | grad norm avg: 10.98 | grad norm last: 10.39 | 
2025-12-28T03:04:55 | step: 705900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 3.009148349519819e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.7 | consumed tokens: 361420800.0 | grad norm avg: 10.85 | grad norm last: 10.74 | 
2025-12-28T03:04:57 | step: 706000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 3.0079861971898936e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.33 | consumed tokens: 361472000.0 | grad norm avg: 11.16 | grad norm last: 10.38 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_706000-seen_tokens_361472000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_706000-seen_tokens_361472000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_706000-seen_tokens_361472000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_706000-seen_tokens_361472000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_706000-seen_tokens_361472000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_706000-seen_tokens_361472000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_706000-seen_tokens_361472000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_706000-seen_tokens_361472000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:05:00 | step: 706100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 3.006824408657849e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 3.44 | consumed tokens: 361523200.0 | grad norm avg: 10.89 | grad norm last: 9.99 | 
2025-12-28T03:05:02 | step: 706200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 3.005662620125804e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.62 | consumed tokens: 361574400.0 | grad norm avg: 10.82 | grad norm last: 10.79 | 
2025-12-28T03:05:04 | step: 706300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.0045013772905804e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.97 | consumed tokens: 361625600.0 | grad norm avg: 11.16 | grad norm last: 14.32 | 
2025-12-28T03:05:06 | step: 706400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 3.0033401344553567e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.97 | consumed tokens: 361676800.0 | grad norm avg: 11.06 | grad norm last: 10.57 | 
2025-12-28T03:05:08 | step: 706500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.0021792554180138e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.67 | consumed tokens: 361728000.0 | grad norm avg: 10.96 | grad norm last: 10.15 | 
2025-12-28T03:05:10 | step: 706600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 3.0010187401785515e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 2.97 | consumed tokens: 361779200.0 | grad norm avg: 11.09 | grad norm last: 9.33 | 
2025-12-28T03:05:12 | step: 706700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.9998578611412086e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.77 | consumed tokens: 361830400.0 | grad norm avg: 10.97 | grad norm last: 10.5 | 
2025-12-28T03:05:14 | step: 706800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.9986978915985674e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.98 | consumed tokens: 361881600.0 | grad norm avg: 10.88 | grad norm last: 11.86 | 
2025-12-28T03:05:16 | step: 706900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.9975379220559262e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.98 | consumed tokens: 361932800.0 | grad norm avg: 11.06 | grad norm last: 10.3 | 
2025-12-28T03:05:18 | step: 707000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.9963781344122253e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.75 | consumed tokens: 361984000.0 | grad norm avg: 10.88 | grad norm last: 10.41 | 
2025-12-28T03:05:20 | step: 707100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.9952187105664052e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.02 | consumed tokens: 362035200.0 | grad norm avg: 11.03 | grad norm last: 9.22 | 
2025-12-28T03:05:22 | step: 707200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.9940594686195254e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.12 | consumed tokens: 362086400.0 | grad norm avg: 10.74 | grad norm last: 9.68 | 
2025-12-28T03:05:24 | step: 707300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.992900408571586e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.56 | consumed tokens: 362137600.0 | grad norm avg: 11.04 | grad norm last: 13.15 | 
2025-12-28T03:05:26 | step: 707400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.9917418942204677e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.95 | consumed tokens: 362188800.0 | grad norm avg: 11.28 | grad norm last: 11.62 | 
2025-12-28T03:05:28 | step: 707500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.990583197970409e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.86 | consumed tokens: 362240000.0 | grad norm avg: 11.04 | grad norm last: 10.62 | 
2025-12-28T03:05:30 | step: 707600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.989424865518231e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.48 | consumed tokens: 362291200.0 | grad norm avg: 11.06 | grad norm last: 9.8 | 
2025-12-28T03:05:32 | step: 707700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.9882668968639337e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.47 | consumed tokens: 362342400.0 | grad norm avg: 10.79 | grad norm last: 10.41 | 
2025-12-28T03:05:34 | step: 707800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.9871089282096364e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 2.95 | consumed tokens: 362393600.0 | grad norm avg: 11.1 | grad norm last: 8.73 | 
2025-12-28T03:05:36 | step: 707900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.9859516871511005e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.34 | consumed tokens: 362444800.0 | grad norm avg: 11.38 | grad norm last: 9.95 | 
2025-12-28T03:05:38 | step: 708000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.9847942641936243e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.84 | consumed tokens: 362496000.0 | grad norm avg: 10.83 | grad norm last: 10.09 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_708000-seen_tokens_362496000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_708000-seen_tokens_362496000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_708000-seen_tokens_362496000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_708000-seen_tokens_362496000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_708000-seen_tokens_362496000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_708000-seen_tokens_362496000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_708000-seen_tokens_362496000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_708000-seen_tokens_362496000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:05:40 | step: 708100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.9836372050340287e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.36 | consumed tokens: 362547200.0 | grad norm avg: 11.01 | grad norm last: 12.22 | 
2025-12-28T03:05:42 | step: 708200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 2.9824803277733736e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 2.34 | consumed tokens: 362598400.0 | grad norm avg: 11.14 | grad norm last: 8.47 | 
2025-12-28T03:05:44 | step: 708300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 2.981323814310599e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.42 | consumed tokens: 362649600.0 | grad norm avg: 11.07 | grad norm last: 9.98 | 
2025-12-28T03:05:46 | step: 708400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.980167482746765e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.14 | consumed tokens: 362700800.0 | grad norm avg: 10.95 | grad norm last: 11.75 | 
2025-12-28T03:05:48 | step: 708500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.9790113330818713e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.7 | consumed tokens: 362752000.0 | grad norm avg: 11.47 | grad norm last: 11.03 | 
2025-12-28T03:05:50 | step: 708600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.977855365315918e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.88 | consumed tokens: 362803200.0 | grad norm avg: 11.22 | grad norm last: 11.14 | 
2025-12-28T03:05:53 | step: 708700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 2.9766999432467856e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.3 | consumed tokens: 362854400.0 | grad norm avg: 11.08 | grad norm last: 11.02 | 
2025-12-28T03:05:55 | step: 708800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.9755445211776532e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.39 | consumed tokens: 362905600.0 | grad norm avg: 10.81 | grad norm last: 10.11 | 
2025-12-28T03:05:57 | step: 708900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.9743894629064016e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.3 | consumed tokens: 362956800.0 | grad norm avg: 10.82 | grad norm last: 10.55 | 
2025-12-28T03:05:59 | step: 709000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.9732347684330307e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.08 | consumed tokens: 363008000.0 | grad norm avg: 10.74 | grad norm last: 9.54 | 
2025-12-28T03:06:01 | step: 709100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.972079710161779e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.16 | consumed tokens: 363059200.0 | grad norm avg: 11.03 | grad norm last: 10.46 | 
2025-12-28T03:06:03 | step: 709200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.9709255613852292e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.3 | consumed tokens: 363110400.0 | grad norm avg: 10.95 | grad norm last: 13.25 | 
2025-12-28T03:06:05 | step: 709300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.9697714126086794e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.48 | consumed tokens: 363161600.0 | grad norm avg: 11.08 | grad norm last: 10.32 | 
2025-12-28T03:06:07 | step: 709400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.96861744573107e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.19 | consumed tokens: 363212800.0 | grad norm avg: 11.13 | grad norm last: 9.91 | 
2025-12-28T03:06:09 | step: 709500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.967463842651341e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.77 | consumed tokens: 363264000.0 | grad norm avg: 10.83 | grad norm last: 10.21 | 
2025-12-28T03:06:11 | step: 709600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.9663104214705527e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.67 | consumed tokens: 363315200.0 | grad norm avg: 11.1 | grad norm last: 10.74 | 
2025-12-28T03:06:13 | step: 709700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.9651571821887046e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.91 | consumed tokens: 363366400.0 | grad norm avg: 11.19 | grad norm last: 10.87 | 
2025-12-28T03:06:15 | step: 709800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.9640044886036776e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.64 | consumed tokens: 363417600.0 | grad norm avg: 11.17 | grad norm last: 10.83 | 
2025-12-28T03:06:17 | step: 709900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.9628516131197102e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.41 | consumed tokens: 363468800.0 | grad norm avg: 11.38 | grad norm last: 10.01 | 
2025-12-28T03:06:19 | step: 710000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.9616991014336236e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.23 | consumed tokens: 363520000.0 | grad norm avg: 11.07 | grad norm last: 10.25 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_710000-seen_tokens_363520000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_710000-seen_tokens_363520000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_710000-seen_tokens_363520000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_710000-seen_tokens_363520000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_710000-seen_tokens_363520000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_710000-seen_tokens_363520000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_710000-seen_tokens_363520000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_710000-seen_tokens_363520000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:06:21 | step: 710100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.9605469535454176e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.63 | train loss last: 4.19 | consumed tokens: 363571200.0 | grad norm avg: 11.34 | grad norm last: 12.77 | 
2025-12-28T03:06:23 | step: 710200 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 2.9593948056572117e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.02 | consumed tokens: 363622400.0 | grad norm avg: 10.77 | grad norm last: 10.51 | 
2025-12-28T03:06:25 | step: 710300 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 2.958243385364767e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.39 | consumed tokens: 363673600.0 | grad norm avg: 10.83 | grad norm last: 10.35 | 
2025-12-28T03:06:27 | step: 710400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.9570917831733823e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.45 | consumed tokens: 363724800.0 | grad norm avg: 11.45 | grad norm last: 10.23 | 
2025-12-28T03:06:29 | step: 710500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.955940544779878e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.56 | consumed tokens: 363776000.0 | grad norm avg: 10.98 | grad norm last: 10.26 | 
2025-12-28T03:06:32 | step: 710600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.9547894882853143e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.48 | consumed tokens: 363827200.0 | grad norm avg: 11.22 | grad norm last: 12.61 | 
2025-12-28T03:06:34 | step: 710700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.9536387955886312e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.47 | consumed tokens: 363878400.0 | grad norm avg: 11.06 | grad norm last: 14.63 | 
2025-12-28T03:06:36 | step: 710800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.9524882847908884e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.56 | consumed tokens: 363929600.0 | grad norm avg: 11.12 | grad norm last: 10.63 | 
2025-12-28T03:06:38 | step: 710900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.951337955892086e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.95 | consumed tokens: 363980800.0 | grad norm avg: 11.08 | grad norm last: 9.19 | 
2025-12-28T03:06:40 | step: 711000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.950187808892224e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.25 | consumed tokens: 364032000.0 | grad norm avg: 11.5 | grad norm last: 10.18 | 
2025-12-28T03:06:42 | step: 711100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.949038207589183e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.22 | consumed tokens: 364083200.0 | grad norm avg: 10.96 | grad norm last: 13.45 | 
2025-12-28T03:06:44 | step: 711200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.947888606286142e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.31 | consumed tokens: 364134400.0 | grad norm avg: 10.88 | grad norm last: 14.22 | 
2025-12-28T03:06:46 | step: 711300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.946739550679922e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.17 | consumed tokens: 364185600.0 | grad norm avg: 11.08 | grad norm last: 9.82 | 
2025-12-28T03:06:48 | step: 711400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.9455904950737022e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.03 | consumed tokens: 364236800.0 | grad norm avg: 10.96 | grad norm last: 10.86 | 
2025-12-28T03:06:50 | step: 711500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.9444416213664226e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.73 | consumed tokens: 364288000.0 | grad norm avg: 11.24 | grad norm last: 11.0 | 
2025-12-28T03:06:52 | step: 711600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.9432931114570238e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.48 | consumed tokens: 364339200.0 | grad norm avg: 11.28 | grad norm last: 11.5 | 
2025-12-28T03:06:54 | step: 711700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.9421449653455056e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.53 | consumed tokens: 364390400.0 | grad norm avg: 11.34 | grad norm last: 11.43 | 
2025-12-28T03:06:56 | step: 711800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.9409968192339875e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.69 | consumed tokens: 364441600.0 | grad norm avg: 11.49 | grad norm last: 14.89 | 
2025-12-28T03:06:58 | step: 711900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.93984903692035e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.19 | consumed tokens: 364492800.0 | grad norm avg: 11.42 | grad norm last: 10.25 | 
2025-12-28T03:07:00 | step: 712000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.9387016184045933e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.61 | consumed tokens: 364544000.0 | grad norm avg: 11.2 | grad norm last: 10.85 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_712000-seen_tokens_364544000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_712000-seen_tokens_364544000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_712000-seen_tokens_364544000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_712000-seen_tokens_364544000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_712000-seen_tokens_364544000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_712000-seen_tokens_364544000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_712000-seen_tokens_364544000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_712000-seen_tokens_364544000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:07:02 | step: 712100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.9375541998888366e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.34 | consumed tokens: 364595200.0 | grad norm avg: 11.22 | grad norm last: 10.2 | 
2025-12-28T03:07:04 | step: 712200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.9364071451709606e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.23 | consumed tokens: 364646400.0 | grad norm avg: 11.22 | grad norm last: 10.44 | 
2025-12-28T03:07:06 | step: 712300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.9352604542509653e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.73 | consumed tokens: 364697600.0 | grad norm avg: 11.16 | grad norm last: 11.13 | 
2025-12-28T03:07:08 | step: 712400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.93411376333097e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.05 | consumed tokens: 364748800.0 | grad norm avg: 11.02 | grad norm last: 10.57 | 
2025-12-28T03:07:10 | step: 712500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.9329674362088554e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.55 | consumed tokens: 364800000.0 | grad norm avg: 11.35 | grad norm last: 9.76 | 
2025-12-28T03:07:12 | step: 712600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.9318214728846215e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.36 | consumed tokens: 364851200.0 | grad norm avg: 11.08 | grad norm last: 10.25 | 
2025-12-28T03:07:14 | step: 712700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 2.930675691459328e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.69 | consumed tokens: 364902400.0 | grad norm avg: 10.76 | grad norm last: 10.3 | 
2025-12-28T03:07:16 | step: 712800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.9295299100340344e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 5.91 | consumed tokens: 364953600.0 | grad norm avg: 11.15 | grad norm last: 16.21 | 
2025-12-28T03:07:18 | step: 712900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.928384674305562e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.03 | consumed tokens: 365004800.0 | grad norm avg: 11.13 | grad norm last: 9.74 | 
2025-12-28T03:07:20 | step: 713000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.9272394385770895e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.62 | consumed tokens: 365056000.0 | grad norm avg: 11.13 | grad norm last: 13.41 | 
2025-12-28T03:07:22 | step: 713100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.926094748545438e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.09 | consumed tokens: 365107200.0 | grad norm avg: 11.73 | grad norm last: 10.36 | 
2025-12-28T03:07:25 | step: 713200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.924950240412727e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.25 | consumed tokens: 365158400.0 | grad norm avg: 11.24 | grad norm last: 10.63 | 
2025-12-28T03:07:27 | step: 713300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.9238059141789563e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.97 | consumed tokens: 365209600.0 | grad norm avg: 11.03 | grad norm last: 13.44 | 
2025-12-28T03:07:29 | step: 713400 | train samples/s: 98.3 | train mfu (16-bit): -1.0 | lr mean: 2.922661769844126e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.22 | consumed tokens: 365260800.0 | grad norm avg: 10.85 | grad norm last: 10.35 | 
2025-12-28T03:07:31 | step: 713500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.9215179893071763e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.16 | consumed tokens: 365312000.0 | grad norm avg: 11.06 | grad norm last: 10.0 | 
2025-12-28T03:07:33 | step: 713600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.920374390669167e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.55 | consumed tokens: 365363200.0 | grad norm avg: 11.01 | grad norm last: 11.1 | 
2025-12-28T03:07:35 | step: 713700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.9192311558290385e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.5 | consumed tokens: 365414400.0 | grad norm avg: 11.26 | grad norm last: 22.72 | 
2025-12-28T03:07:37 | step: 713800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.9180877390899695e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.7 | consumed tokens: 365465600.0 | grad norm avg: 11.49 | grad norm last: 12.34 | 
2025-12-28T03:07:39 | step: 713900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.916945049946662e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.41 | consumed tokens: 365516800.0 | grad norm avg: 10.91 | grad norm last: 9.64 | 
2025-12-28T03:07:41 | step: 714000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.9158027246012352e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.0 | consumed tokens: 365568000.0 | grad norm avg: 11.28 | grad norm last: 12.58 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_714000-seen_tokens_365568000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_714000-seen_tokens_365568000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_714000-seen_tokens_365568000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_714000-seen_tokens_365568000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_714000-seen_tokens_365568000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_714000-seen_tokens_365568000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_714000-seen_tokens_365568000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_714000-seen_tokens_365568000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:07:43 | step: 714100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.9146603992558084e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.56 | train loss last: 3.28 | consumed tokens: 365619200.0 | grad norm avg: 10.87 | grad norm last: 9.5 | 
2025-12-28T03:07:45 | step: 714200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.9135180739103816e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.69 | train loss last: 3.42 | consumed tokens: 365670400.0 | grad norm avg: 11.29 | grad norm last: 11.34 | 
2025-12-28T03:07:47 | step: 714300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.9123761123628356e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.62 | consumed tokens: 365721600.0 | grad norm avg: 11.01 | grad norm last: 10.65 | 
2025-12-28T03:07:49 | step: 714400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.9112345146131702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.12 | consumed tokens: 365772800.0 | grad norm avg: 11.0 | grad norm last: 11.02 | 
2025-12-28T03:07:51 | step: 714500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.9100932806613855e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 5.28 | consumed tokens: 365824000.0 | grad norm avg: 11.23 | grad norm last: 13.07 | 
2025-12-28T03:07:53 | step: 714600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.908952046709601e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.81 | consumed tokens: 365875200.0 | grad norm avg: 10.83 | grad norm last: 10.56 | 
2025-12-28T03:07:55 | step: 714700 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 2.907811176555697e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.12 | consumed tokens: 365926400.0 | grad norm avg: 10.86 | grad norm last: 10.48 | 
2025-12-28T03:07:57 | step: 714800 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 2.9066706701996736e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.25 | consumed tokens: 365977600.0 | grad norm avg: 11.17 | grad norm last: 12.13 | 
2025-12-28T03:07:59 | step: 714900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 2.905530527641531e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.48 | consumed tokens: 366028800.0 | grad norm avg: 11.0 | grad norm last: 10.13 | 
2025-12-28T03:08:02 | step: 715000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.9043900212855078e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.67 | consumed tokens: 366080000.0 | grad norm avg: 10.88 | grad norm last: 10.0 | 
2025-12-28T03:08:04 | step: 715100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.9032504244241863e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.34 | consumed tokens: 366131200.0 | grad norm avg: 11.05 | grad norm last: 10.47 | 
2025-12-28T03:08:06 | step: 715200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.902110827562865e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.58 | consumed tokens: 366182400.0 | grad norm avg: 11.16 | grad norm last: 11.34 | 
2025-12-28T03:08:08 | step: 715300 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.9009714126004837e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.47 | consumed tokens: 366233600.0 | grad norm avg: 11.25 | grad norm last: 10.74 | 
2025-12-28T03:08:10 | step: 715400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 2.8998323614359833e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.64 | consumed tokens: 366284800.0 | grad norm avg: 10.6 | grad norm last: 12.59 | 
2025-12-28T03:08:12 | step: 715500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.8986934921704233e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.5 | consumed tokens: 366336000.0 | grad norm avg: 10.92 | grad norm last: 10.72 | 
2025-12-28T03:08:14 | step: 715600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.8975548048038036e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.53 | consumed tokens: 366387200.0 | grad norm avg: 10.94 | grad norm last: 10.62 | 
2025-12-28T03:08:16 | step: 715700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.896416663134005e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.03 | consumed tokens: 366438400.0 | grad norm avg: 11.24 | grad norm last: 10.83 | 
2025-12-28T03:08:18 | step: 715800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.895278339565266e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 2.92 | consumed tokens: 366489600.0 | grad norm avg: 11.58 | grad norm last: 9.09 | 
2025-12-28T03:08:20 | step: 715900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.8941407435922883e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.2 | consumed tokens: 366540800.0 | grad norm avg: 11.26 | grad norm last: 10.4 | 
2025-12-28T03:08:22 | step: 716000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.8930029657203704e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.48 | consumed tokens: 366592000.0 | grad norm avg: 10.79 | grad norm last: 10.14 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_716000-seen_tokens_366592000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_716000-seen_tokens_366592000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_716000-seen_tokens_366592000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_716000-seen_tokens_366592000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_716000-seen_tokens_366592000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_716000-seen_tokens_366592000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_716000-seen_tokens_366592000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_716000-seen_tokens_366592000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:08:24 | step: 716100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.8918655516463332e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 3.36 | consumed tokens: 366643200.0 | grad norm avg: 11.48 | grad norm last: 9.66 | 
2025-12-28T03:08:26 | step: 716200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.8907285013701767e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.8 | consumed tokens: 366694400.0 | grad norm avg: 11.38 | grad norm last: 12.04 | 
2025-12-28T03:08:28 | step: 716300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.889591814891901e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.56 | consumed tokens: 366745600.0 | grad norm avg: 11.02 | grad norm last: 10.78 | 
2025-12-28T03:08:30 | step: 716400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.8884549465146847e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.55 | consumed tokens: 366796800.0 | grad norm avg: 11.42 | grad norm last: 9.53 | 
2025-12-28T03:08:32 | step: 716500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.88731880573323e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.77 | consumed tokens: 366848000.0 | grad norm avg: 11.07 | grad norm last: 10.43 | 
2025-12-28T03:08:34 | step: 716600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.886182483052835e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.77 | consumed tokens: 366899200.0 | grad norm avg: 10.83 | grad norm last: 10.85 | 
2025-12-28T03:08:36 | step: 716700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.885046706069261e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.44 | consumed tokens: 366950400.0 | grad norm avg: 11.02 | grad norm last: 10.96 | 
2025-12-28T03:08:38 | step: 716800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.883911110984627e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.75 | consumed tokens: 367001600.0 | grad norm avg: 11.04 | grad norm last: 10.1 | 
2025-12-28T03:08:40 | step: 716900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.882775697798934e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.81 | consumed tokens: 367052800.0 | grad norm avg: 11.26 | grad norm last: 11.36 | 
2025-12-28T03:08:43 | step: 717000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.8816406484111212e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.28 | consumed tokens: 367104000.0 | grad norm avg: 11.1 | grad norm last: 13.59 | 
2025-12-28T03:08:45 | step: 717100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.880505780922249e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.77 | consumed tokens: 367155200.0 | grad norm avg: 10.83 | grad norm last: 9.83 | 
2025-12-28T03:08:47 | step: 717200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.8793712772312574e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.44 | consumed tokens: 367206400.0 | grad norm avg: 11.02 | grad norm last: 10.95 | 
2025-12-28T03:08:49 | step: 717300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.8782369554392062e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.66 | consumed tokens: 367257600.0 | grad norm avg: 11.13 | grad norm last: 14.94 | 
2025-12-28T03:08:51 | step: 717400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.8771028155460954e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.22 | consumed tokens: 367308800.0 | grad norm avg: 10.95 | grad norm last: 11.92 | 
2025-12-28T03:08:53 | step: 717500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.8759690394508652e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.66 | consumed tokens: 367360000.0 | grad norm avg: 10.92 | grad norm last: 10.97 | 
2025-12-28T03:08:55 | step: 717600 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.8748354452545755e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.42 | consumed tokens: 367411200.0 | grad norm avg: 11.02 | grad norm last: 11.14 | 
2025-12-28T03:08:57 | step: 717700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.873702032957226e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.16 | consumed tokens: 367462400.0 | grad norm avg: 11.37 | grad norm last: 13.32 | 
2025-12-28T03:08:59 | step: 717800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.8725689844577573e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.64 | consumed tokens: 367513600.0 | grad norm avg: 10.76 | grad norm last: 10.11 | 
2025-12-28T03:09:01 | step: 717900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.871436117857229e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.22 | consumed tokens: 367564800.0 | grad norm avg: 10.93 | grad norm last: 12.12 | 
2025-12-28T03:09:03 | step: 718000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.8703036150545813e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 2.94 | consumed tokens: 367616000.0 | grad norm avg: 10.78 | grad norm last: 9.95 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_718000-seen_tokens_367616000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_718000-seen_tokens_367616000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_718000-seen_tokens_367616000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_718000-seen_tokens_367616000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_718000-seen_tokens_367616000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_718000-seen_tokens_367616000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_718000-seen_tokens_367616000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_718000-seen_tokens_367616000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:09:05 | step: 718100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.869171294150874e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.8 | consumed tokens: 367667200.0 | grad norm avg: 11.36 | grad norm last: 10.88 | 
2025-12-28T03:09:07 | step: 718200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.868039155146107e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.73 | consumed tokens: 367718400.0 | grad norm avg: 10.98 | grad norm last: 10.7 | 
2025-12-28T03:09:09 | step: 718300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.8669071980402805e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.03 | consumed tokens: 367769600.0 | grad norm avg: 10.83 | grad norm last: 10.69 | 
2025-12-28T03:09:11 | step: 718400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.865775786631275e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.53 | consumed tokens: 367820800.0 | grad norm avg: 11.64 | grad norm last: 11.26 | 
2025-12-28T03:09:13 | step: 718500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.8646443752222694e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.8 | consumed tokens: 367872000.0 | grad norm avg: 11.4 | grad norm last: 12.85 | 
2025-12-28T03:09:15 | step: 718600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.863513509510085e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.81 | consumed tokens: 367923200.0 | grad norm avg: 11.24 | grad norm last: 10.33 | 
2025-12-28T03:09:17 | step: 718700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.8623826437979005e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.03 | consumed tokens: 367974400.0 | grad norm avg: 11.06 | grad norm last: 9.61 | 
2025-12-28T03:09:19 | step: 718800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.8612521418835968e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.22 | consumed tokens: 368025600.0 | grad norm avg: 10.82 | grad norm last: 9.07 | 
2025-12-28T03:09:21 | step: 718900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.860121639969293e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.44 | consumed tokens: 368076800.0 | grad norm avg: 11.71 | grad norm last: 10.72 | 
2025-12-28T03:09:23 | step: 719000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.858992047549691e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.22 | consumed tokens: 368128000.0 | grad norm avg: 10.85 | grad norm last: 9.0 | 
2025-12-28T03:09:25 | step: 719100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.8578620913322084e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.92 | consumed tokens: 368179200.0 | grad norm avg: 11.11 | grad norm last: 10.71 | 
2025-12-28T03:09:27 | step: 719200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.8567324989126064e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.25 | consumed tokens: 368230400.0 | grad norm avg: 10.96 | grad norm last: 16.5 | 
2025-12-28T03:09:29 | step: 719300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.855603270290885e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.61 | consumed tokens: 368281600.0 | grad norm avg: 11.24 | grad norm last: 10.52 | 
2025-12-28T03:09:31 | step: 719400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.854474041669164e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.39 | consumed tokens: 368332800.0 | grad norm avg: 10.98 | grad norm last: 9.79 | 
2025-12-28T03:09:33 | step: 719500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.8533453587442636e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.59 | consumed tokens: 368384000.0 | grad norm avg: 11.01 | grad norm last: 13.99 | 
2025-12-28T03:09:36 | step: 719600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.8522168577183038e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.02 | consumed tokens: 368435200.0 | grad norm avg: 10.93 | grad norm last: 9.83 | 
2025-12-28T03:09:38 | step: 719700 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 2.851088902389165e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.41 | consumed tokens: 368486400.0 | grad norm avg: 11.0 | grad norm last: 11.19 | 
2025-12-28T03:09:40 | step: 719800 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 2.8499605832621455e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.55 | consumed tokens: 368537600.0 | grad norm avg: 11.11 | grad norm last: 9.52 | 
2025-12-28T03:09:42 | step: 719900 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 2.8488329917308874e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.31 | consumed tokens: 368588800.0 | grad norm avg: 11.27 | grad norm last: 12.54 | 
2025-12-28T03:09:44 | step: 720000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.8477055820985697e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 2.7 | consumed tokens: 368640000.0 | grad norm avg: 10.89 | grad norm last: 9.05 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_720000-seen_tokens_368640000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_720000-seen_tokens_368640000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_720000-seen_tokens_368640000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_720000-seen_tokens_368640000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_720000-seen_tokens_368640000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_720000-seen_tokens_368640000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_720000-seen_tokens_368640000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_720000-seen_tokens_368640000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:09:46 | step: 720100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.846578172466252e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.55 | train loss last: 3.16 | consumed tokens: 368691200.0 | grad norm avg: 10.8 | grad norm last: 10.56 | 
2025-12-28T03:09:48 | step: 720200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.845451126631815e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.62 | consumed tokens: 368742400.0 | grad norm avg: 11.01 | grad norm last: 11.33 | 
2025-12-28T03:09:50 | step: 720300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.8443244445952587e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.94 | consumed tokens: 368793600.0 | grad norm avg: 11.0 | grad norm last: 9.36 | 
2025-12-28T03:09:52 | step: 720400 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.8431977625587024e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.22 | consumed tokens: 368844800.0 | grad norm avg: 10.8 | grad norm last: 10.63 | 
2025-12-28T03:09:54 | step: 720500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.8420718081179075e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.75 | consumed tokens: 368896000.0 | grad norm avg: 11.01 | grad norm last: 10.7 | 
2025-12-28T03:09:56 | step: 720600 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.8409458536771126e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.42 | consumed tokens: 368947200.0 | grad norm avg: 11.25 | grad norm last: 10.16 | 
2025-12-28T03:09:58 | step: 720700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.839820081135258e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.3 | consumed tokens: 368998400.0 | grad norm avg: 10.9 | grad norm last: 9.9 | 
2025-12-28T03:10:00 | step: 720800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.8386946723912843e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.53 | consumed tokens: 369049600.0 | grad norm avg: 10.97 | grad norm last: 15.57 | 
2025-12-28T03:10:02 | step: 720900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.8375694455462508e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.72 | consumed tokens: 369100800.0 | grad norm avg: 11.52 | grad norm last: 11.11 | 
2025-12-28T03:10:04 | step: 721000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.836444582499098e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.69 | consumed tokens: 369152000.0 | grad norm avg: 11.21 | grad norm last: 10.83 | 
2025-12-28T03:10:06 | step: 721100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.8353199013508856e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.34 | consumed tokens: 369203200.0 | grad norm avg: 10.8 | grad norm last: 10.24 | 
2025-12-28T03:10:08 | step: 721200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.834195584000554e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.44 | consumed tokens: 369254400.0 | grad norm avg: 11.43 | grad norm last: 10.14 | 
2025-12-28T03:10:11 | step: 721300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.833071084751282e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.61 | consumed tokens: 369305600.0 | grad norm avg: 11.0 | grad norm last: 10.35 | 
2025-12-28T03:10:13 | step: 721400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.8319473130977713e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.98 | consumed tokens: 369356800.0 | grad norm avg: 11.03 | grad norm last: 9.74 | 
2025-12-28T03:10:15 | step: 721500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.8308239052421413e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.62 | consumed tokens: 369408000.0 | grad norm avg: 11.16 | grad norm last: 12.13 | 
2025-12-28T03:10:17 | step: 721600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.8297004973865114e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.47 | consumed tokens: 369459200.0 | grad norm avg: 11.08 | grad norm last: 10.7 | 
2025-12-28T03:10:19 | step: 721700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.8285770895308815e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.36 | consumed tokens: 369510400.0 | grad norm avg: 11.14 | grad norm last: 9.36 | 
2025-12-28T03:10:21 | step: 721800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.8274540454731323e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.14 | consumed tokens: 369561600.0 | grad norm avg: 11.05 | grad norm last: 10.51 | 
2025-12-28T03:10:23 | step: 721900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.8263317290111445e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.91 | consumed tokens: 369612800.0 | grad norm avg: 10.98 | grad norm last: 11.69 | 
2025-12-28T03:10:25 | step: 722000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.8252092306502163e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.3 | consumed tokens: 369664000.0 | grad norm avg: 10.91 | grad norm last: 9.87 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_722000-seen_tokens_369664000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_722000-seen_tokens_369664000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_722000-seen_tokens_369664000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_722000-seen_tokens_369664000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_722000-seen_tokens_369664000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_722000-seen_tokens_369664000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_722000-seen_tokens_369664000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_722000-seen_tokens_369664000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:10:27 | step: 722100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.824087096087169e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.61 | consumed tokens: 369715200.0 | grad norm avg: 11.26 | grad norm last: 10.08 | 
2025-12-28T03:10:29 | step: 722200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.8229653253220022e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.92 | consumed tokens: 369766400.0 | grad norm avg: 11.17 | grad norm last: 10.36 | 
2025-12-28T03:10:31 | step: 722300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.821843918354716e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.48 | consumed tokens: 369817600.0 | grad norm avg: 11.24 | grad norm last: 11.47 | 
2025-12-28T03:10:33 | step: 722400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.8207223294884898e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.55 | consumed tokens: 369868800.0 | grad norm avg: 11.57 | grad norm last: 11.3 | 
2025-12-28T03:10:35 | step: 722500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.8196014682180248e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.0 | consumed tokens: 369920000.0 | grad norm avg: 11.23 | grad norm last: 12.31 | 
2025-12-28T03:10:37 | step: 722600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.8184804250486195e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.19 | consumed tokens: 369971200.0 | grad norm avg: 11.13 | grad norm last: 11.02 | 
2025-12-28T03:10:39 | step: 722700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.8173599275760353e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.86 | consumed tokens: 370022400.0 | grad norm avg: 11.59 | grad norm last: 11.16 | 
2025-12-28T03:10:41 | step: 722800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.8162396120023914e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.19 | consumed tokens: 370073600.0 | grad norm avg: 11.58 | grad norm last: 13.26 | 
2025-12-28T03:10:43 | step: 722900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.8151194783276878e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.92 | consumed tokens: 370124800.0 | grad norm avg: 11.0 | grad norm last: 10.94 | 
2025-12-28T03:10:45 | step: 723000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.813999708450865e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.03 | consumed tokens: 370176000.0 | grad norm avg: 10.95 | grad norm last: 12.27 | 
2025-12-28T03:10:47 | step: 723100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.812880302371923e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.75 | consumed tokens: 370227200.0 | grad norm avg: 11.29 | grad norm last: 11.7 | 
2025-12-28T03:10:49 | step: 723200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.8117608962929808e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.78 | consumed tokens: 370278400.0 | grad norm avg: 11.59 | grad norm last: 11.24 | 
2025-12-28T03:10:51 | step: 723300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.8106418540119193e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.34 | consumed tokens: 370329600.0 | grad norm avg: 10.93 | grad norm last: 9.93 | 
2025-12-28T03:10:53 | step: 723400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 2.8095231755287386e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.28 | consumed tokens: 370380800.0 | grad norm avg: 11.03 | grad norm last: 10.82 | 
2025-12-28T03:10:55 | step: 723500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.8084046789444983e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.98 | consumed tokens: 370432000.0 | grad norm avg: 11.52 | grad norm last: 10.74 | 
2025-12-28T03:10:57 | step: 723600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 2.8072863642591983e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.14 | consumed tokens: 370483200.0 | grad norm avg: 11.89 | grad norm last: 9.67 | 
2025-12-28T03:10:59 | step: 723700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.8061685952707194e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.33 | consumed tokens: 370534400.0 | grad norm avg: 11.12 | grad norm last: 10.12 | 
2025-12-28T03:11:01 | step: 723800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.8050506443833e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.91 | consumed tokens: 370585600.0 | grad norm avg: 11.44 | grad norm last: 11.74 | 
2025-12-28T03:11:03 | step: 723900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.8039334210916422e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.44 | consumed tokens: 370636800.0 | grad norm avg: 11.07 | grad norm last: 10.57 | 
2025-12-28T03:11:05 | step: 724000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.802816015901044e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.8 | consumed tokens: 370688000.0 | grad norm avg: 11.27 | grad norm last: 11.03 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_724000-seen_tokens_370688000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_724000-seen_tokens_370688000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_724000-seen_tokens_370688000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_724000-seen_tokens_370688000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_724000-seen_tokens_370688000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_724000-seen_tokens_370688000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_724000-seen_tokens_370688000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_724000-seen_tokens_370688000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:11:08 | step: 724100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.801699156407267e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.67 | train loss last: 2.98 | consumed tokens: 370739200.0 | grad norm avg: 11.29 | grad norm last: 9.21 | 
2025-12-28T03:11:10 | step: 724200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.80058247881243e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.48 | consumed tokens: 370790400.0 | grad norm avg: 11.26 | grad norm last: 11.46 | 
2025-12-28T03:11:12 | step: 724300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.7994659831165336e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.0 | consumed tokens: 370841600.0 | grad norm avg: 11.35 | grad norm last: 20.01 | 
2025-12-28T03:11:14 | step: 724400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.798349851218518e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.75 | consumed tokens: 370892800.0 | grad norm avg: 11.1 | grad norm last: 12.18 | 
2025-12-28T03:11:16 | step: 724500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.7972339012194425e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.66 | consumed tokens: 370944000.0 | grad norm avg: 11.23 | grad norm last: 11.44 | 
2025-12-28T03:11:18 | step: 724600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.7961183150182478e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.66 | consumed tokens: 370995200.0 | grad norm avg: 11.24 | grad norm last: 11.45 | 
2025-12-28T03:11:20 | step: 724700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.7950029107159935e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.92 | consumed tokens: 371046400.0 | grad norm avg: 11.49 | grad norm last: 12.05 | 
2025-12-28T03:11:22 | step: 724800 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.7938876883126795e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.53 | consumed tokens: 371097600.0 | grad norm avg: 11.35 | grad norm last: 10.93 | 
2025-12-28T03:11:24 | step: 724900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.7927728297072463e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.53 | consumed tokens: 371148800.0 | grad norm avg: 11.2 | grad norm last: 10.66 | 
2025-12-28T03:11:26 | step: 725000 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.7916583348996937e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.5 | consumed tokens: 371200000.0 | grad norm avg: 11.18 | grad norm last: 10.51 | 
2025-12-28T03:11:28 | step: 725100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.790544203890022e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 2.75 | consumed tokens: 371251200.0 | grad norm avg: 11.75 | grad norm last: 10.09 | 
2025-12-28T03:11:30 | step: 725200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.7894298909814097e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.0 | consumed tokens: 371302400.0 | grad norm avg: 11.14 | grad norm last: 12.27 | 
2025-12-28T03:11:32 | step: 725300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.788316305668559e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.55 | consumed tokens: 371353600.0 | grad norm avg: 11.05 | grad norm last: 11.49 | 
2025-12-28T03:11:34 | step: 725400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.7872025384567678e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.33 | consumed tokens: 371404800.0 | grad norm avg: 11.36 | grad norm last: 10.41 | 
2025-12-28T03:11:36 | step: 725500 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 2.7860891350428574e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.36 | consumed tokens: 371456000.0 | grad norm avg: 11.0 | grad norm last: 9.96 | 
2025-12-28T03:11:38 | step: 725600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.7849760954268277e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 2.78 | consumed tokens: 371507200.0 | grad norm avg: 11.41 | grad norm last: 8.97 | 
2025-12-28T03:11:40 | step: 725700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.7838634196086787e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.5 | consumed tokens: 371558400.0 | grad norm avg: 11.22 | grad norm last: 11.18 | 
2025-12-28T03:11:43 | step: 725800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.7827505618915893e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 4.59 | consumed tokens: 371609600.0 | grad norm avg: 11.51 | grad norm last: 10.5 | 
2025-12-28T03:11:45 | step: 725900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.7816386136692017e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.06 | consumed tokens: 371660800.0 | grad norm avg: 10.97 | grad norm last: 11.1 | 
2025-12-28T03:11:47 | step: 726000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.780526665446814e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.75 | consumed tokens: 371712000.0 | grad norm avg: 11.12 | grad norm last: 11.21 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_726000-seen_tokens_371712000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_726000-seen_tokens_371712000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_726000-seen_tokens_371712000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_726000-seen_tokens_371712000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_726000-seen_tokens_371712000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_726000-seen_tokens_371712000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_726000-seen_tokens_371712000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_726000-seen_tokens_371712000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:11:49 | step: 726100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.779414899123367e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.09 | consumed tokens: 371763200.0 | grad norm avg: 11.27 | grad norm last: 10.75 | 
2025-12-28T03:11:51 | step: 726200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.77830331469886e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.81 | consumed tokens: 371814400.0 | grad norm avg: 11.12 | grad norm last: 10.32 | 
2025-12-28T03:11:53 | step: 726300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.777192094072234e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 2.5 | consumed tokens: 371865600.0 | grad norm avg: 11.04 | grad norm last: 9.32 | 
2025-12-28T03:11:55 | step: 726400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.7760812372434884e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.16 | consumed tokens: 371916800.0 | grad norm avg: 11.2 | grad norm last: 12.71 | 
2025-12-28T03:11:57 | step: 726500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.7749707442126237e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.84 | consumed tokens: 371968000.0 | grad norm avg: 11.29 | grad norm last: 11.78 | 
2025-12-28T03:11:59 | step: 726600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.7738600692828186e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 2.56 | consumed tokens: 372019200.0 | grad norm avg: 11.07 | grad norm last: 9.27 | 
2025-12-28T03:12:01 | step: 726700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.772750121948775e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.75 | consumed tokens: 372070400.0 | grad norm avg: 11.41 | grad norm last: 10.33 | 
2025-12-28T03:12:03 | step: 726800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.771639992715791e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.84 | consumed tokens: 372121600.0 | grad norm avg: 11.44 | grad norm last: 11.95 | 
2025-12-28T03:12:05 | step: 726900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.770530409179628e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.25 | consumed tokens: 372172800.0 | grad norm avg: 11.24 | grad norm last: 9.16 | 
2025-12-28T03:12:07 | step: 727000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.7694210075424053e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.81 | consumed tokens: 372224000.0 | grad norm avg: 11.21 | grad norm last: 12.29 | 
2025-12-28T03:12:09 | step: 727100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.7683119697030634e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.94 | consumed tokens: 372275200.0 | grad norm avg: 11.13 | grad norm last: 10.97 | 
2025-12-28T03:12:11 | step: 727200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.7672031137626618e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.84 | consumed tokens: 372326400.0 | grad norm avg: 11.11 | grad norm last: 12.11 | 
2025-12-28T03:12:13 | step: 727300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.7660944397212006e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.44 | consumed tokens: 372377600.0 | grad norm avg: 10.95 | grad norm last: 9.69 | 
2025-12-28T03:12:15 | step: 727400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.76498612947762e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.86 | consumed tokens: 372428800.0 | grad norm avg: 11.26 | grad norm last: 10.21 | 
2025-12-28T03:12:17 | step: 727500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.76387800113298e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.81 | consumed tokens: 372480000.0 | grad norm avg: 11.48 | grad norm last: 11.93 | 
2025-12-28T03:12:19 | step: 727600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.762770418485161e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.06 | consumed tokens: 372531200.0 | grad norm avg: 11.26 | grad norm last: 11.55 | 
2025-12-28T03:12:21 | step: 727700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.7616626539384015e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.5 | consumed tokens: 372582400.0 | grad norm avg: 10.95 | grad norm last: 10.04 | 
2025-12-28T03:12:23 | step: 727800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.7605556169874035e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.69 | consumed tokens: 372633600.0 | grad norm avg: 11.47 | grad norm last: 10.24 | 
2025-12-28T03:12:25 | step: 727900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.759448398137465e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.61 | consumed tokens: 372684800.0 | grad norm avg: 11.15 | grad norm last: 11.33 | 
2025-12-28T03:12:27 | step: 728000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.7583417249843478e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.94 | consumed tokens: 372736000.0 | grad norm avg: 11.16 | grad norm last: 11.2 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_728000-seen_tokens_372736000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_728000-seen_tokens_372736000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_728000-seen_tokens_372736000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_728000-seen_tokens_372736000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_728000-seen_tokens_372736000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_728000-seen_tokens_372736000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_728000-seen_tokens_372736000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_728000-seen_tokens_372736000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:12:30 | step: 728100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.757235233730171e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.69 | consumed tokens: 372787200.0 | grad norm avg: 11.3 | grad norm last: 10.42 | 
2025-12-28T03:12:32 | step: 728200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.7561289243749343e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.83 | consumed tokens: 372838400.0 | grad norm avg: 11.39 | grad norm last: 12.24 | 
2025-12-28T03:12:34 | step: 728300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.7550229788175784e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.83 | consumed tokens: 372889600.0 | grad norm avg: 11.33 | grad norm last: 11.22 | 
2025-12-28T03:12:36 | step: 728400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.7539173970581032e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 2.66 | consumed tokens: 372940800.0 | grad norm avg: 11.19 | grad norm last: 11.69 | 
2025-12-28T03:12:38 | step: 728500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.7528119971975684e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.59 | consumed tokens: 372992000.0 | grad norm avg: 11.12 | grad norm last: 11.48 | 
2025-12-28T03:12:40 | step: 728600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.751706779235974e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.0 | consumed tokens: 373043200.0 | grad norm avg: 11.37 | grad norm last: 10.03 | 
2025-12-28T03:12:42 | step: 728700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.7506021069712006e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.53 | consumed tokens: 373094400.0 | grad norm avg: 11.14 | grad norm last: 14.46 | 
2025-12-28T03:12:44 | step: 728800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.7494972528074868e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.83 | consumed tokens: 373145600.0 | grad norm avg: 11.34 | grad norm last: 11.81 | 
2025-12-28T03:12:46 | step: 728900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.7483931262395345e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.06 | consumed tokens: 373196800.0 | grad norm avg: 11.22 | grad norm last: 9.35 | 
2025-12-28T03:12:48 | step: 729000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.7472888177726418e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.38 | consumed tokens: 373248000.0 | grad norm avg: 11.22 | grad norm last: 12.2 | 
2025-12-28T03:12:50 | step: 729100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.7461848731036298e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 4.94 | consumed tokens: 373299200.0 | grad norm avg: 10.93 | grad norm last: 11.7 | 
2025-12-28T03:12:52 | step: 729200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.7450812922324985e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.09 | consumed tokens: 373350400.0 | grad norm avg: 11.25 | grad norm last: 9.68 | 
2025-12-28T03:12:54 | step: 729300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.743978075159248e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.89 | consumed tokens: 373401600.0 | grad norm avg: 11.18 | grad norm last: 10.6 | 
2025-12-28T03:12:56 | step: 729400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.7428750399849378e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.03 | consumed tokens: 373452800.0 | grad norm avg: 11.13 | grad norm last: 10.03 | 
2025-12-28T03:12:58 | step: 729500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.741772186709568e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.64 | consumed tokens: 373504000.0 | grad norm avg: 11.24 | grad norm last: 12.75 | 
2025-12-28T03:13:00 | step: 729600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.7406696972320788e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.44 | consumed tokens: 373555200.0 | grad norm avg: 11.1 | grad norm last: 13.66 | 
2025-12-28T03:13:02 | step: 729700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.73956738965353e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.52 | consumed tokens: 373606400.0 | grad norm avg: 11.67 | grad norm last: 10.59 | 
2025-12-28T03:13:04 | step: 729800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.738465445872862e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.83 | consumed tokens: 373657600.0 | grad norm avg: 11.49 | grad norm last: 10.28 | 
2025-12-28T03:13:06 | step: 729900 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 2.737363683991134e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.05 | consumed tokens: 373708800.0 | grad norm avg: 11.41 | grad norm last: 9.34 | 
2025-12-28T03:13:08 | step: 730000 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.736262285907287e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.34 | consumed tokens: 373760000.0 | grad norm avg: 11.35 | grad norm last: 10.18 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_730000-seen_tokens_373760000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_730000-seen_tokens_373760000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_730000-seen_tokens_373760000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_730000-seen_tokens_373760000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_730000-seen_tokens_373760000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_730000-seen_tokens_373760000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_730000-seen_tokens_373760000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_730000-seen_tokens_373760000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:13:11 | step: 730100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.7351610697223805e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.61 | train loss last: 3.2 | consumed tokens: 373811200.0 | grad norm avg: 11.45 | grad norm last: 10.08 | 
2025-12-28T03:13:13 | step: 730200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.7340602173353545e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.2 | consumed tokens: 373862400.0 | grad norm avg: 10.97 | grad norm last: 10.12 | 
2025-12-28T03:13:15 | step: 730300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.732959546847269e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.23 | consumed tokens: 373913600.0 | grad norm avg: 11.19 | grad norm last: 10.31 | 
2025-12-28T03:13:17 | step: 730400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.731859240157064e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.53 | consumed tokens: 373964800.0 | grad norm avg: 11.18 | grad norm last: 11.75 | 
2025-12-28T03:13:19 | step: 730500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.7307591153657995e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.59 | consumed tokens: 374016000.0 | grad norm avg: 11.21 | grad norm last: 11.39 | 
2025-12-28T03:13:21 | step: 730600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.7296591724734753e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.69 | consumed tokens: 374067200.0 | grad norm avg: 11.48 | grad norm last: 11.16 | 
2025-12-28T03:13:23 | step: 730700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.728559593379032e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.92 | consumed tokens: 374118400.0 | grad norm avg: 11.09 | grad norm last: 9.97 | 
2025-12-28T03:13:25 | step: 730800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.7274601961835288e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.64 | consumed tokens: 374169600.0 | grad norm avg: 11.2 | grad norm last: 10.95 | 
2025-12-28T03:13:27 | step: 730900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.7263611627859063e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.42 | consumed tokens: 374220800.0 | grad norm avg: 11.2 | grad norm last: 9.88 | 
2025-12-28T03:13:29 | step: 731000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.7252624931861646e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.25 | consumed tokens: 374272000.0 | grad norm avg: 11.36 | grad norm last: 9.93 | 
2025-12-28T03:13:31 | step: 731100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.7241641873843037e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.59 | consumed tokens: 374323200.0 | grad norm avg: 11.28 | grad norm last: 9.92 | 
2025-12-28T03:13:33 | step: 731200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.7230656996835023e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.09 | consumed tokens: 374374400.0 | grad norm avg: 11.14 | grad norm last: 10.53 | 
2025-12-28T03:13:35 | step: 731300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.721967757679522e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.61 | consumed tokens: 374425600.0 | grad norm avg: 11.24 | grad norm last: 11.64 | 
2025-12-28T03:13:37 | step: 731400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.720869997574482e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.34 | consumed tokens: 374476800.0 | grad norm avg: 11.21 | grad norm last: 9.8 | 
2025-12-28T03:13:39 | step: 731500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.7197724193683825e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.33 | consumed tokens: 374528000.0 | grad norm avg: 11.03 | grad norm last: 10.57 | 
2025-12-28T03:13:41 | step: 731600 | train samples/s: 98.2 | train mfu (16-bit): -1.0 | lr mean: 2.718675386859104e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.12 | consumed tokens: 374579200.0 | grad norm avg: 11.27 | grad norm last: 10.32 | 
2025-12-28T03:13:43 | step: 731700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.7175783543498255e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.53 | consumed tokens: 374630400.0 | grad norm avg: 11.11 | grad norm last: 12.91 | 
2025-12-28T03:13:45 | step: 731800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.7164816856384277e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.73 | consumed tokens: 374681600.0 | grad norm avg: 11.24 | grad norm last: 11.12 | 
2025-12-28T03:13:48 | step: 731900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.7153853807249106e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.11 | consumed tokens: 374732800.0 | grad norm avg: 10.93 | grad norm last: 10.74 | 
2025-12-28T03:13:50 | step: 732000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.714289257710334e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.27 | consumed tokens: 374784000.0 | grad norm avg: 11.07 | grad norm last: 10.12 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_732000-seen_tokens_374784000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_732000-seen_tokens_374784000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_732000-seen_tokens_374784000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_732000-seen_tokens_374784000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_732000-seen_tokens_374784000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_732000-seen_tokens_374784000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_732000-seen_tokens_374784000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_732000-seen_tokens_374784000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:13:52 | step: 732100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.713193498493638e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.71 | train loss last: 4.34 | consumed tokens: 374835200.0 | grad norm avg: 11.2 | grad norm last: 11.79 | 
2025-12-28T03:13:54 | step: 732200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.712097739276942e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.06 | consumed tokens: 374886400.0 | grad norm avg: 11.53 | grad norm last: 9.81 | 
2025-12-28T03:13:56 | step: 732300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.7110023438581266e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.3 | consumed tokens: 374937600.0 | grad norm avg: 11.26 | grad norm last: 11.21 | 
2025-12-28T03:13:58 | step: 732400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.7099076760350727e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.84 | train loss last: 3.17 | consumed tokens: 374988800.0 | grad norm avg: 11.64 | grad norm last: 11.38 | 
2025-12-28T03:14:00 | step: 732500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.708812644414138e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.56 | consumed tokens: 375040000.0 | grad norm avg: 11.29 | grad norm last: 11.31 | 
2025-12-28T03:14:02 | step: 732600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.707717976591084e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.22 | consumed tokens: 375091200.0 | grad norm avg: 11.41 | grad norm last: 11.29 | 
2025-12-28T03:14:04 | step: 732700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.706623672565911e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.66 | consumed tokens: 375142400.0 | grad norm avg: 11.3 | grad norm last: 10.26 | 
2025-12-28T03:14:06 | step: 732800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.705529914237559e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.58 | consumed tokens: 375193600.0 | grad norm avg: 11.26 | grad norm last: 10.97 | 
2025-12-28T03:14:08 | step: 732900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.704436337808147e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.44 | consumed tokens: 375244800.0 | grad norm avg: 11.23 | grad norm last: 16.21 | 
2025-12-28T03:14:10 | step: 733000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.7033427613787353e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 5.34 | consumed tokens: 375296000.0 | grad norm avg: 11.71 | grad norm last: 15.8 | 
2025-12-28T03:14:12 | step: 733100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.7022497306461446e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.12 | consumed tokens: 375347200.0 | grad norm avg: 11.39 | grad norm last: 11.91 | 
2025-12-28T03:14:14 | step: 733200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.7011565180146135e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.41 | consumed tokens: 375398400.0 | grad norm avg: 11.41 | grad norm last: 12.08 | 
2025-12-28T03:14:16 | step: 733300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.7000642148777843e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.78 | consumed tokens: 375449600.0 | grad norm avg: 11.27 | grad norm last: 10.95 | 
2025-12-28T03:14:18 | step: 733400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.698971911740955e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.44 | consumed tokens: 375500800.0 | grad norm avg: 11.09 | grad norm last: 10.9 | 
2025-12-28T03:14:20 | step: 733500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.697879790503066e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.8 | consumed tokens: 375552000.0 | grad norm avg: 11.07 | grad norm last: 12.27 | 
2025-12-28T03:14:22 | step: 733600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.6967878511641175e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.25 | consumed tokens: 375603200.0 | grad norm avg: 11.75 | grad norm last: 10.65 | 
2025-12-28T03:14:24 | step: 733700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.6956962756230496e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.17 | consumed tokens: 375654400.0 | grad norm avg: 11.11 | grad norm last: 10.72 | 
2025-12-28T03:14:26 | step: 733800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.6946050638798624e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.53 | consumed tokens: 375705600.0 | grad norm avg: 11.46 | grad norm last: 9.43 | 
2025-12-28T03:14:28 | step: 733900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.6935138521366753e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.58 | consumed tokens: 375756800.0 | grad norm avg: 11.31 | grad norm last: 11.06 | 
2025-12-28T03:14:30 | step: 734000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.69242354988819e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.62 | consumed tokens: 375808000.0 | grad norm avg: 11.2 | grad norm last: 11.86 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_734000-seen_tokens_375808000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_734000-seen_tokens_375808000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_734000-seen_tokens_375808000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_734000-seen_tokens_375808000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_734000-seen_tokens_375808000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_734000-seen_tokens_375808000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_734000-seen_tokens_375808000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_734000-seen_tokens_375808000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:14:33 | step: 734100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.6913328838418238e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.64 | train loss last: 3.58 | consumed tokens: 375859200.0 | grad norm avg: 11.45 | grad norm last: 10.31 | 
2025-12-28T03:14:35 | step: 734200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.6902425815933384e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.5 | consumed tokens: 375910400.0 | grad norm avg: 11.14 | grad norm last: 10.82 | 
2025-12-28T03:14:37 | step: 734300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.6891526431427337e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.55 | consumed tokens: 375961600.0 | grad norm avg: 13.38 | grad norm last: 13.39 | 
2025-12-28T03:14:39 | step: 734400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.6880630684900098e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.12 | consumed tokens: 376012800.0 | grad norm avg: 11.63 | grad norm last: 13.82 | 
2025-12-28T03:14:41 | step: 734500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.6869738576351665e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.72 | consumed tokens: 376064000.0 | grad norm avg: 11.46 | grad norm last: 11.55 | 
2025-12-28T03:14:43 | step: 734600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.6858846467803232e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.8 | consumed tokens: 376115200.0 | grad norm avg: 11.14 | grad norm last: 10.71 | 
2025-12-28T03:14:45 | step: 734700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.6847957997233607e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.28 | consumed tokens: 376166400.0 | grad norm avg: 11.23 | grad norm last: 10.5 | 
2025-12-28T03:14:47 | step: 734800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.6837071345653385e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.42 | consumed tokens: 376217600.0 | grad norm avg: 11.51 | grad norm last: 9.93 | 
2025-12-28T03:14:49 | step: 734900 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.682618833205197e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.2 | consumed tokens: 376268800.0 | grad norm avg: 11.0 | grad norm last: 9.72 | 
2025-12-28T03:14:51 | step: 735000 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 2.6815308956429362e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.41 | consumed tokens: 376320000.0 | grad norm avg: 11.39 | grad norm last: 10.65 | 
2025-12-28T03:14:53 | step: 735100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.6804431399796158e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.75 | consumed tokens: 376371200.0 | grad norm avg: 11.46 | grad norm last: 12.91 | 
2025-12-28T03:14:55 | step: 735200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.6793555662152357e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.06 | consumed tokens: 376422400.0 | grad norm avg: 11.57 | grad norm last: 11.36 | 
2025-12-28T03:14:57 | step: 735300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.6782683562487364e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 2.52 | consumed tokens: 376473600.0 | grad norm avg: 11.5 | grad norm last: 10.55 | 
2025-12-28T03:14:59 | step: 735400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.6771813281811774e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.19 | consumed tokens: 376524800.0 | grad norm avg: 11.35 | grad norm last: 11.39 | 
2025-12-28T03:15:01 | step: 735500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.6760948458104394e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.16 | consumed tokens: 376576000.0 | grad norm avg: 11.59 | grad norm last: 11.59 | 
2025-12-28T03:15:03 | step: 735600 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 2.675008181540761e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.38 | consumed tokens: 376627200.0 | grad norm avg: 12.08 | grad norm last: 10.26 | 
2025-12-28T03:15:05 | step: 735700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.6739222448668443e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.33 | consumed tokens: 376678400.0 | grad norm avg: 11.61 | grad norm last: 11.3 | 
2025-12-28T03:15:07 | step: 735800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.6728363081929274e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.42 | consumed tokens: 376729600.0 | grad norm avg: 11.88 | grad norm last: 9.93 | 
2025-12-28T03:15:09 | step: 735900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.6717507353168912e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 2.98 | consumed tokens: 376780800.0 | grad norm avg: 11.46 | grad norm last: 10.95 | 
2025-12-28T03:15:11 | step: 736000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.6706655262387358e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.22 | consumed tokens: 376832000.0 | grad norm avg: 11.2 | grad norm last: 10.23 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_736000-seen_tokens_376832000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_736000-seen_tokens_376832000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_736000-seen_tokens_376832000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_736000-seen_tokens_376832000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_736000-seen_tokens_376832000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_736000-seen_tokens_376832000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_736000-seen_tokens_376832000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_736000-seen_tokens_376832000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:15:14 | step: 736100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.6695803171605803e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.19 | consumed tokens: 376883200.0 | grad norm avg: 11.38 | grad norm last: 12.69 | 
2025-12-28T03:15:16 | step: 736200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.6684958356781863e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.5 | consumed tokens: 376934400.0 | grad norm avg: 11.95 | grad norm last: 12.32 | 
2025-12-28T03:15:18 | step: 736300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.667411172296852e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.59 | consumed tokens: 376985600.0 | grad norm avg: 11.32 | grad norm last: 12.66 | 
2025-12-28T03:15:20 | step: 736400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.6663268727133982e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.33 | consumed tokens: 377036800.0 | grad norm avg: 11.28 | grad norm last: 10.79 | 
2025-12-28T03:15:22 | step: 736500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.6652429369278252e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.0 | consumed tokens: 377088000.0 | grad norm avg: 11.01 | grad norm last: 12.19 | 
2025-12-28T03:15:24 | step: 736600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.664159364940133e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.55 | consumed tokens: 377139200.0 | grad norm avg: 11.19 | grad norm last: 11.04 | 
2025-12-28T03:15:26 | step: 736700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.6630756110535003e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.5 | consumed tokens: 377190400.0 | grad norm avg: 11.47 | grad norm last: 13.04 | 
2025-12-28T03:15:28 | step: 736800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.6619927666615695e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.3 | consumed tokens: 377241600.0 | grad norm avg: 11.5 | grad norm last: 10.94 | 
2025-12-28T03:15:30 | step: 736900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.6609099222696386e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.7 | consumed tokens: 377292800.0 | grad norm avg: 11.48 | grad norm last: 12.56 | 
2025-12-28T03:15:32 | step: 737000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.659827259776648e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.25 | consumed tokens: 377344000.0 | grad norm avg: 11.13 | grad norm last: 10.89 | 
2025-12-28T03:15:34 | step: 737100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.6587449610815383e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.58 | consumed tokens: 377395200.0 | grad norm avg: 11.51 | grad norm last: 11.02 | 
2025-12-28T03:15:36 | step: 737200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.657662844285369e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.66 | consumed tokens: 377446400.0 | grad norm avg: 11.32 | grad norm last: 11.45 | 
2025-12-28T03:15:38 | step: 737300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.6565810912870802e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.05 | consumed tokens: 377497600.0 | grad norm avg: 11.35 | grad norm last: 10.07 | 
2025-12-28T03:15:40 | step: 737400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.655499520187732e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.67 | consumed tokens: 377548800.0 | grad norm avg: 11.6 | grad norm last: 11.18 | 
2025-12-28T03:15:42 | step: 737500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.6544183128862642e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.67 | consumed tokens: 377600000.0 | grad norm avg: 11.18 | grad norm last: 11.98 | 
2025-12-28T03:15:44 | step: 737600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.6533374693826772e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.5 | consumed tokens: 377651200.0 | grad norm avg: 11.38 | grad norm last: 15.88 | 
2025-12-28T03:15:46 | step: 737700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.6522568077780306e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.25 | consumed tokens: 377702400.0 | grad norm avg: 11.69 | grad norm last: 10.66 | 
2025-12-28T03:15:48 | step: 737800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.6511763280723244e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.17 | consumed tokens: 377753600.0 | grad norm avg: 11.93 | grad norm last: 9.73 | 
2025-12-28T03:15:50 | step: 737900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.6500963940634392e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.06 | consumed tokens: 377804800.0 | grad norm avg: 11.71 | grad norm last: 9.83 | 
2025-12-28T03:15:52 | step: 738000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.6490162781556137e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.72 | consumed tokens: 377856000.0 | grad norm avg: 11.7 | grad norm last: 11.54 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_738000-seen_tokens_377856000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_738000-seen_tokens_377856000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_738000-seen_tokens_377856000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_738000-seen_tokens_377856000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_738000-seen_tokens_377856000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_738000-seen_tokens_377856000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_738000-seen_tokens_377856000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_738000-seen_tokens_377856000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:15:55 | step: 738100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.6479368898435496e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 3.72 | consumed tokens: 377907200.0 | grad norm avg: 11.2 | grad norm last: 11.26 | 
2025-12-28T03:15:57 | step: 738200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.6468575015314855e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.73 | train loss last: 3.55 | consumed tokens: 377958400.0 | grad norm avg: 11.61 | grad norm last: 11.42 | 
2025-12-28T03:15:59 | step: 738300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.645778477017302e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.78 | consumed tokens: 378009600.0 | grad norm avg: 11.88 | grad norm last: 11.36 | 
2025-12-28T03:16:01 | step: 738400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.6446994525031187e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.7 | consumed tokens: 378060800.0 | grad norm avg: 11.26 | grad norm last: 10.28 | 
2025-12-28T03:16:03 | step: 738500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.6436211555846967e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.58 | consumed tokens: 378112000.0 | grad norm avg: 12.18 | grad norm last: 11.01 | 
2025-12-28T03:16:05 | step: 738600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.6425428586662747e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.34 | consumed tokens: 378163200.0 | grad norm avg: 11.48 | grad norm last: 10.64 | 
2025-12-28T03:16:07 | step: 738700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.6414651074446738e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.22 | consumed tokens: 378214400.0 | grad norm avg: 11.58 | grad norm last: 11.62 | 
2025-12-28T03:16:09 | step: 738800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.640387356223073e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.53 | consumed tokens: 378265600.0 | grad norm avg: 11.43 | grad norm last: 13.83 | 
2025-12-28T03:16:11 | step: 738900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.6393099687993526e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 2.69 | consumed tokens: 378316800.0 | grad norm avg: 11.67 | grad norm last: 11.14 | 
2025-12-28T03:16:13 | step: 739000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.638232945173513e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.08 | consumed tokens: 378368000.0 | grad norm avg: 11.62 | grad norm last: 10.49 | 
2025-12-28T03:16:15 | step: 739100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.637156103446614e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.56 | consumed tokens: 378419200.0 | grad norm avg: 11.44 | grad norm last: 10.31 | 
2025-12-28T03:16:17 | step: 739200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.6360794436186552e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.42 | consumed tokens: 378470400.0 | grad norm avg: 11.45 | grad norm last: 9.79 | 
2025-12-28T03:16:19 | step: 739300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.635003147588577e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.03 | consumed tokens: 378521600.0 | grad norm avg: 11.35 | grad norm last: 13.37 | 
2025-12-28T03:16:21 | step: 739400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.6339272153563797e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.31 | consumed tokens: 378572800.0 | grad norm avg: 11.26 | grad norm last: 14.36 | 
2025-12-28T03:16:23 | step: 739500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.6328512831241824e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.48 | consumed tokens: 378624000.0 | grad norm avg: 11.65 | grad norm last: 10.75 | 
2025-12-28T03:16:25 | step: 739600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.631775896588806e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.81 | consumed tokens: 378675200.0 | grad norm avg: 11.31 | grad norm last: 12.74 | 
2025-12-28T03:16:27 | step: 739700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.6307008738513105e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.75 | consumed tokens: 378726400.0 | grad norm avg: 11.29 | grad norm last: 10.7 | 
2025-12-28T03:16:29 | step: 739800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.6296262149116956e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.33 | consumed tokens: 378777600.0 | grad norm avg: 11.3 | grad norm last: 10.24 | 
2025-12-28T03:16:31 | step: 739900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.6285511921742e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.31 | consumed tokens: 378828800.0 | grad norm avg: 11.82 | grad norm last: 15.72 | 
2025-12-28T03:16:33 | step: 740000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 2.6274768970324658e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.16 | consumed tokens: 378880000.0 | grad norm avg: 11.52 | grad norm last: 10.36 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_740000-seen_tokens_378880000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_740000-seen_tokens_378880000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_740000-seen_tokens_378880000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_740000-seen_tokens_378880000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_740000-seen_tokens_378880000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_740000-seen_tokens_378880000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_740000-seen_tokens_378880000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_740000-seen_tokens_378880000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:16:35 | step: 740100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.6264029656886123e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.65 | train loss last: 3.55 | consumed tokens: 378931200.0 | grad norm avg: 11.53 | grad norm last: 10.52 | 
2025-12-28T03:16:37 | step: 740200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 2.625329034344759e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 2.95 | consumed tokens: 378982400.0 | grad norm avg: 11.68 | grad norm last: 10.62 | 
2025-12-28T03:16:40 | step: 740300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.624255466798786e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.62 | consumed tokens: 379033600.0 | grad norm avg: 11.42 | grad norm last: 9.93 | 
2025-12-28T03:16:42 | step: 740400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.623182263050694e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 2.83 | consumed tokens: 379084800.0 | grad norm avg: 12.08 | grad norm last: 8.78 | 
2025-12-28T03:16:44 | step: 740500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.6221094231004827e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.05 | consumed tokens: 379136000.0 | grad norm avg: 11.13 | grad norm last: 10.28 | 
2025-12-28T03:16:46 | step: 740600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.6210365831502713e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.12 | consumed tokens: 379187200.0 | grad norm avg: 11.69 | grad norm last: 11.15 | 
2025-12-28T03:16:48 | step: 740700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.6199641069979407e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.91 | consumed tokens: 379238400.0 | grad norm avg: 11.31 | grad norm last: 11.89 | 
2025-12-28T03:16:50 | step: 740800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.618892176542431e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.22 | consumed tokens: 379289600.0 | grad norm avg: 11.15 | grad norm last: 9.6 | 
2025-12-28T03:16:52 | step: 740900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.6178202460869215e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.52 | consumed tokens: 379340800.0 | grad norm avg: 11.82 | grad norm last: 10.15 | 
2025-12-28T03:16:54 | step: 741000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.6167486794292927e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 5.09 | consumed tokens: 379392000.0 | grad norm avg: 11.3 | grad norm last: 12.38 | 
2025-12-28T03:16:56 | step: 741100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.6156771127716638e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.86 | consumed tokens: 379443200.0 | grad norm avg: 11.34 | grad norm last: 11.7 | 
2025-12-28T03:16:58 | step: 741200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.614606091810856e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.73 | consumed tokens: 379494400.0 | grad norm avg: 11.3 | grad norm last: 11.29 | 
2025-12-28T03:17:00 | step: 741300 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 2.6135356165468693e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.66 | consumed tokens: 379545600.0 | grad norm avg: 12.55 | grad norm last: 12.92 | 
2025-12-28T03:17:02 | step: 741400 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.6124651412828825e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.56 | consumed tokens: 379596800.0 | grad norm avg: 11.62 | grad norm last: 10.37 | 
2025-12-28T03:17:04 | step: 741500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.611394847917836e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.86 | consumed tokens: 379648000.0 | grad norm avg: 11.6 | grad norm last: 10.71 | 
2025-12-28T03:17:06 | step: 741600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.6103249183506705e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 2.3 | consumed tokens: 379699200.0 | grad norm avg: 11.55 | grad norm last: 9.23 | 
2025-12-28T03:17:08 | step: 741700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.6092553525813855e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.92 | consumed tokens: 379750400.0 | grad norm avg: 11.95 | grad norm last: 11.49 | 
2025-12-28T03:17:10 | step: 741800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.6081857868121006e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.98 | consumed tokens: 379801600.0 | grad norm avg: 11.81 | grad norm last: 12.62 | 
2025-12-28T03:17:12 | step: 741900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.607116948638577e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.47 | consumed tokens: 379852800.0 | grad norm avg: 11.55 | grad norm last: 12.76 | 
2025-12-28T03:17:14 | step: 742000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.6060481104650535e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.34 | consumed tokens: 379904000.0 | grad norm avg: 11.4 | grad norm last: 9.8 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_742000-seen_tokens_379904000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_742000-seen_tokens_379904000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_742000-seen_tokens_379904000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_742000-seen_tokens_379904000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_742000-seen_tokens_379904000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_742000-seen_tokens_379904000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_742000-seen_tokens_379904000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_742000-seen_tokens_379904000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:17:17 | step: 742100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.6049796360894106e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.61 | train loss last: 3.23 | consumed tokens: 379955200.0 | grad norm avg: 11.51 | grad norm last: 9.78 | 
2025-12-28T03:17:19 | step: 742200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.6039115255116485e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.05 | consumed tokens: 380006400.0 | grad norm avg: 11.32 | grad norm last: 10.77 | 
2025-12-28T03:17:21 | step: 742300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.6028434149338864e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.53 | consumed tokens: 380057600.0 | grad norm avg: 11.46 | grad norm last: 15.83 | 
2025-12-28T03:17:23 | step: 742400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.601775668154005e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.19 | consumed tokens: 380108800.0 | grad norm avg: 11.77 | grad norm last: 12.79 | 
2025-12-28T03:17:25 | step: 742500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.6007082851720043e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.08 | consumed tokens: 380160000.0 | grad norm avg: 11.86 | grad norm last: 9.94 | 
2025-12-28T03:17:27 | step: 742600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.5996409021900035e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 2.77 | consumed tokens: 380211200.0 | grad norm avg: 11.85 | grad norm last: 10.3 | 
2025-12-28T03:17:29 | step: 742700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.5985742468037643e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.34 | consumed tokens: 380262400.0 | grad norm avg: 11.68 | grad norm last: 10.16 | 
2025-12-28T03:17:31 | step: 742800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.597507591417525e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.19 | consumed tokens: 380313600.0 | grad norm avg: 11.72 | grad norm last: 11.56 | 
2025-12-28T03:17:33 | step: 742900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.5964412998291664e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.86 | consumed tokens: 380364800.0 | grad norm avg: 11.55 | grad norm last: 10.28 | 
2025-12-28T03:17:35 | step: 743000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.5953753720386885e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.41 | consumed tokens: 380416000.0 | grad norm avg: 11.5 | grad norm last: 12.14 | 
2025-12-28T03:17:37 | step: 743100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.594309626147151e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.86 | consumed tokens: 380467200.0 | grad norm avg: 11.33 | grad norm last: 11.36 | 
2025-12-28T03:17:39 | step: 743200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.5932438802556135e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.03 | consumed tokens: 380518400.0 | grad norm avg: 11.72 | grad norm last: 10.49 | 
2025-12-28T03:17:41 | step: 743300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.592178680060897e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.38 | consumed tokens: 380569600.0 | grad norm avg: 11.56 | grad norm last: 13.8 | 
2025-12-28T03:17:43 | step: 743400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.5911140255630016e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.52 | consumed tokens: 380620800.0 | grad norm avg: 11.46 | grad norm last: 14.31 | 
2025-12-28T03:17:45 | step: 743500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.5900493710651062e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.72 | consumed tokens: 380672000.0 | grad norm avg: 11.08 | grad norm last: 10.88 | 
2025-12-28T03:17:47 | step: 743600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.5889850803650916e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.41 | consumed tokens: 380723200.0 | grad norm avg: 11.4 | grad norm last: 11.22 | 
2025-12-28T03:17:49 | step: 743700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.587920789665077e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.47 | consumed tokens: 380774400.0 | grad norm avg: 11.36 | grad norm last: 10.5 | 
2025-12-28T03:17:51 | step: 743800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.5868570446618833e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.34 | consumed tokens: 380825600.0 | grad norm avg: 11.79 | grad norm last: 11.06 | 
2025-12-28T03:17:53 | step: 743900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.5857936634565704e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.64 | consumed tokens: 380876800.0 | grad norm avg: 11.3 | grad norm last: 10.11 | 
2025-12-28T03:17:55 | step: 744000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.584730646049138e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.67 | consumed tokens: 380928000.0 | grad norm avg: 11.67 | grad norm last: 10.88 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_744000-seen_tokens_380928000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_744000-seen_tokens_380928000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_744000-seen_tokens_380928000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_744000-seen_tokens_380928000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_744000-seen_tokens_380928000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_744000-seen_tokens_380928000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_744000-seen_tokens_380928000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_744000-seen_tokens_380928000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:17:57 | step: 744100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.583667628641706e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.65 | train loss last: 3.94 | consumed tokens: 380979200.0 | grad norm avg: 11.74 | grad norm last: 10.8 | 
2025-12-28T03:17:59 | step: 744200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.5826049750321545e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.94 | consumed tokens: 381030400.0 | grad norm avg: 11.72 | grad norm last: 12.47 | 
2025-12-28T03:18:01 | step: 744300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.5815425033215433e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.39 | consumed tokens: 381081600.0 | grad norm avg: 11.72 | grad norm last: 10.96 | 
2025-12-28T03:18:03 | step: 744400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.580480395408813e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.73 | consumed tokens: 381132800.0 | grad norm avg: 11.53 | grad norm last: 11.05 | 
2025-12-28T03:18:05 | step: 744500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.5794186512939632e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 2.75 | consumed tokens: 381184000.0 | grad norm avg: 11.55 | grad norm last: 14.26 | 
2025-12-28T03:18:08 | step: 744600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.578357089078054e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.19 | consumed tokens: 381235200.0 | grad norm avg: 11.43 | grad norm last: 12.65 | 
2025-12-28T03:18:10 | step: 744700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.5772960725589655e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.23 | consumed tokens: 381286400.0 | grad norm avg: 11.89 | grad norm last: 10.04 | 
2025-12-28T03:18:12 | step: 744800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.576234874140937e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.2 | consumed tokens: 381337600.0 | grad norm avg: 11.57 | grad norm last: 9.97 | 
2025-12-28T03:18:14 | step: 744900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.5751744033186696e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.03 | consumed tokens: 381388800.0 | grad norm avg: 11.46 | grad norm last: 12.12 | 
2025-12-28T03:18:16 | step: 745000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.574113750597462e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.48 | consumed tokens: 381440000.0 | grad norm avg: 11.63 | grad norm last: 10.96 | 
2025-12-28T03:18:18 | step: 745100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.5730536435730755e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.42 | consumed tokens: 381491200.0 | grad norm avg: 11.51 | grad norm last: 10.14 | 
2025-12-28T03:18:20 | step: 745200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.5719937184476294e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.66 | consumed tokens: 381542400.0 | grad norm avg: 11.69 | grad norm last: 11.35 | 
2025-12-28T03:18:22 | step: 745300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.570934157120064e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.22 | consumed tokens: 381593600.0 | grad norm avg: 11.78 | grad norm last: 9.96 | 
2025-12-28T03:18:24 | step: 745400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.569874959590379e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.44 | consumed tokens: 381644800.0 | grad norm avg: 11.49 | grad norm last: 10.26 | 
2025-12-28T03:18:26 | step: 745500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.5688159439596348e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 2.86 | consumed tokens: 381696000.0 | grad norm avg: 11.51 | grad norm last: 11.57 | 
2025-12-28T03:18:28 | step: 745600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.567757292126771e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.0 | consumed tokens: 381747200.0 | grad norm avg: 11.48 | grad norm last: 10.21 | 
2025-12-28T03:18:30 | step: 745700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.5666988221928477e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.52 | consumed tokens: 381798400.0 | grad norm avg: 11.5 | grad norm last: 10.55 | 
2025-12-28T03:18:32 | step: 745800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.5656403522589244e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.81 | consumed tokens: 381849600.0 | grad norm avg: 11.6 | grad norm last: 12.98 | 
2025-12-28T03:18:34 | step: 745900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.564582428021822e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.31 | consumed tokens: 381900800.0 | grad norm avg: 11.27 | grad norm last: 9.98 | 
2025-12-28T03:18:36 | step: 746000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.563525049481541e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.47 | consumed tokens: 381952000.0 | grad norm avg: 11.44 | grad norm last: 9.79 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_746000-seen_tokens_381952000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_746000-seen_tokens_381952000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_746000-seen_tokens_381952000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_746000-seen_tokens_381952000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_746000-seen_tokens_381952000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_746000-seen_tokens_381952000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_746000-seen_tokens_381952000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_746000-seen_tokens_381952000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:18:38 | step: 746100 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 2.5624678528402e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 5.03 | consumed tokens: 382003200.0 | grad norm avg: 11.8 | grad norm last: 22.03 | 
2025-12-28T03:18:40 | step: 746200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.5614108380977996e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.45 | consumed tokens: 382054400.0 | grad norm avg: 11.93 | grad norm last: 10.68 | 
2025-12-28T03:18:42 | step: 746300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.5603540052543394e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.19 | consumed tokens: 382105600.0 | grad norm avg: 11.67 | grad norm last: 11.7 | 
2025-12-28T03:18:44 | step: 746400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.55929753620876e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.88 | consumed tokens: 382156800.0 | grad norm avg: 11.55 | grad norm last: 9.98 | 
2025-12-28T03:18:46 | step: 746500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.5582414309610613e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.12 | consumed tokens: 382208000.0 | grad norm avg: 12.45 | grad norm last: 14.82 | 
2025-12-28T03:18:48 | step: 746600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.557185507612303e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.77 | consumed tokens: 382259200.0 | grad norm avg: 11.56 | grad norm last: 10.53 | 
2025-12-28T03:18:50 | step: 746700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.556129766162485e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.16 | consumed tokens: 382310400.0 | grad norm avg: 11.69 | grad norm last: 13.2 | 
2025-12-28T03:18:53 | step: 746800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.555074570409488e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.92 | consumed tokens: 382361600.0 | grad norm avg: 11.63 | grad norm last: 12.91 | 
2025-12-28T03:18:55 | step: 746900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 2.5540195565554313e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.77 | consumed tokens: 382412800.0 | grad norm avg: 11.43 | grad norm last: 9.71 | 
2025-12-28T03:18:57 | step: 747000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.552964724600315e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.53 | consumed tokens: 382464000.0 | grad norm avg: 11.47 | grad norm last: 10.46 | 
2025-12-28T03:18:59 | step: 747100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.5519102564430796e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.25 | consumed tokens: 382515200.0 | grad norm avg: 11.23 | grad norm last: 10.1 | 
2025-12-28T03:19:01 | step: 747200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.5508559701847844e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.84 | consumed tokens: 382566400.0 | grad norm avg: 11.97 | grad norm last: 11.03 | 
2025-12-28T03:19:03 | step: 747300 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 2.54980204772437e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.41 | consumed tokens: 382617600.0 | grad norm avg: 11.74 | grad norm last: 11.8 | 
2025-12-28T03:19:05 | step: 747400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.548748489061836e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.22 | consumed tokens: 382668800.0 | grad norm avg: 11.58 | grad norm last: 10.33 | 
2025-12-28T03:19:07 | step: 747500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.5476949303993024e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.39 | consumed tokens: 382720000.0 | grad norm avg: 11.4 | grad norm last: 15.99 | 
2025-12-28T03:19:09 | step: 747600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.54664209933253e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.0 | consumed tokens: 382771200.0 | grad norm avg: 11.94 | grad norm last: 12.46 | 
2025-12-28T03:19:11 | step: 747700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.5455892682657577e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 3.3 | consumed tokens: 382822400.0 | grad norm avg: 11.63 | grad norm last: 10.79 | 
2025-12-28T03:19:13 | step: 747800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.544536800996866e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.94 | consumed tokens: 382873600.0 | grad norm avg: 11.49 | grad norm last: 12.02 | 
2025-12-28T03:19:15 | step: 747900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.543484697525855e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.83 | consumed tokens: 382924800.0 | grad norm avg: 11.97 | grad norm last: 10.78 | 
2025-12-28T03:19:17 | step: 748000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.5424325940548442e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.7 | consumed tokens: 382976000.0 | grad norm avg: 11.97 | grad norm last: 11.98 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_748000-seen_tokens_382976000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_748000-seen_tokens_382976000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_748000-seen_tokens_382976000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_748000-seen_tokens_382976000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_748000-seen_tokens_382976000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_748000-seen_tokens_382976000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_748000-seen_tokens_382976000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_748000-seen_tokens_382976000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:19:19 | step: 748100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.541380854381714e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.66 | train loss last: 4.5 | consumed tokens: 383027200.0 | grad norm avg: 11.41 | grad norm last: 14.5 | 
2025-12-28T03:19:21 | step: 748200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.5403298423043452e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.6 | train loss last: 3.14 | consumed tokens: 383078400.0 | grad norm avg: 11.77 | grad norm last: 10.3 | 
2025-12-28T03:19:23 | step: 748300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.539278648328036e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.64 | consumed tokens: 383129600.0 | grad norm avg: 11.68 | grad norm last: 12.32 | 
2025-12-28T03:19:25 | step: 748400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.5382278181496076e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.81 | consumed tokens: 383180800.0 | grad norm avg: 11.53 | grad norm last: 12.13 | 
2025-12-28T03:19:27 | step: 748500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.53717735176906e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.31 | consumed tokens: 383232000.0 | grad norm avg: 11.59 | grad norm last: 10.58 | 
2025-12-28T03:19:29 | step: 748600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.536127249186393e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.14 | consumed tokens: 383283200.0 | grad norm avg: 11.95 | grad norm last: 11.0 | 
2025-12-28T03:19:31 | step: 748700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.5350769647047855e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.42 | consumed tokens: 383334400.0 | grad norm avg: 11.81 | grad norm last: 10.94 | 
2025-12-28T03:19:33 | step: 748800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.5340274078189395e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.11 | consumed tokens: 383385600.0 | grad norm avg: 11.17 | grad norm last: 10.51 | 
2025-12-28T03:19:36 | step: 748900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.5329782147309743e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.55 | consumed tokens: 383436800.0 | grad norm avg: 11.89 | grad norm last: 10.04 | 
2025-12-28T03:19:38 | step: 749000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.531929021643009e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.17 | consumed tokens: 383488000.0 | grad norm avg: 11.36 | grad norm last: 10.74 | 
2025-12-28T03:19:40 | step: 749100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.5308801923529245e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.81 | consumed tokens: 383539200.0 | grad norm avg: 11.54 | grad norm last: 12.01 | 
2025-12-28T03:19:42 | step: 749200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.5298317268607207e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.45 | consumed tokens: 383590400.0 | grad norm avg: 11.75 | grad norm last: 10.82 | 
2025-12-28T03:19:44 | step: 749300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.528783261368517e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.27 | consumed tokens: 383641600.0 | grad norm avg: 11.52 | grad norm last: 10.79 | 
2025-12-28T03:19:46 | step: 749400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.5277355234720744e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.11 | consumed tokens: 383692800.0 | grad norm avg: 11.62 | grad norm last: 10.29 | 
2025-12-28T03:19:48 | step: 749500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.526687785575632e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.03 | consumed tokens: 383744000.0 | grad norm avg: 11.43 | grad norm last: 9.66 | 
2025-12-28T03:19:50 | step: 749600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.5256405933760107e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.78 | consumed tokens: 383795200.0 | grad norm avg: 11.95 | grad norm last: 10.84 | 
2025-12-28T03:19:52 | step: 749700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.5245934011763893e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.91 | consumed tokens: 383846400.0 | grad norm avg: 11.6 | grad norm last: 10.81 | 
2025-12-28T03:19:54 | step: 749800 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 2.523546754673589e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.95 | consumed tokens: 383897600.0 | grad norm avg: 12.01 | grad norm last: 12.05 | 
2025-12-28T03:19:56 | step: 749900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.5225001081707887e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.75 | consumed tokens: 383948800.0 | grad norm avg: 11.36 | grad norm last: 11.84 | 
2025-12-28T03:19:58 | step: 750000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.5214540073648095e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.05 | consumed tokens: 384000000.0 | grad norm avg: 11.69 | grad norm last: 9.57 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_750000-seen_tokens_384000000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_750000-seen_tokens_384000000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_750000-seen_tokens_384000000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_750000-seen_tokens_384000000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_750000-seen_tokens_384000000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_750000-seen_tokens_384000000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_750000-seen_tokens_384000000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_750000-seen_tokens_384000000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:20:00 | step: 750100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.520408270356711e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.91 | consumed tokens: 384051200.0 | grad norm avg: 11.43 | grad norm last: 11.61 | 
2025-12-28T03:20:02 | step: 750200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.519362351449672e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.41 | consumed tokens: 384102400.0 | grad norm avg: 11.49 | grad norm last: 11.37 | 
2025-12-28T03:20:04 | step: 750300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.5183171601383947e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.72 | consumed tokens: 384153600.0 | grad norm avg: 11.41 | grad norm last: 10.59 | 
2025-12-28T03:20:06 | step: 750400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.5172719688271172e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.14 | consumed tokens: 384204800.0 | grad norm avg: 11.98 | grad norm last: 11.83 | 
2025-12-28T03:20:08 | step: 750500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.5162271413137205e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.7 | consumed tokens: 384256000.0 | grad norm avg: 11.85 | grad norm last: 10.49 | 
2025-12-28T03:20:10 | step: 750600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.5151826775982045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.48 | consumed tokens: 384307200.0 | grad norm avg: 11.48 | grad norm last: 13.1 | 
2025-12-28T03:20:12 | step: 750700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.5141382138826884e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.06 | consumed tokens: 384358400.0 | grad norm avg: 11.53 | grad norm last: 10.9 | 
2025-12-28T03:20:14 | step: 750800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.5130944777629338e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 5.75 | consumed tokens: 384409600.0 | grad norm avg: 11.85 | grad norm last: 32.24 | 
2025-12-28T03:20:16 | step: 750900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.51205110544106e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.12 | consumed tokens: 384460800.0 | grad norm avg: 12.05 | grad norm last: 11.06 | 
2025-12-28T03:20:19 | step: 751000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.511007733119186e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.17 | consumed tokens: 384512000.0 | grad norm avg: 11.48 | grad norm last: 10.39 | 
2025-12-28T03:20:21 | step: 751100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.5099645426962525e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.31 | consumed tokens: 384563200.0 | grad norm avg: 11.79 | grad norm last: 9.93 | 
2025-12-28T03:20:23 | step: 751200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.5089217160711996e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.7 | consumed tokens: 384614400.0 | grad norm avg: 11.67 | grad norm last: 10.47 | 
2025-12-28T03:20:25 | step: 751300 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.5078792532440275e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.55 | consumed tokens: 384665600.0 | grad norm avg: 11.61 | grad norm last: 10.53 | 
2025-12-28T03:20:27 | step: 751400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.506837154214736e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 2.91 | consumed tokens: 384716800.0 | grad norm avg: 12.07 | grad norm last: 11.15 | 
2025-12-28T03:20:29 | step: 751500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.505795237084385e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.09 | consumed tokens: 384768000.0 | grad norm avg: 11.57 | grad norm last: 11.14 | 
2025-12-28T03:20:31 | step: 751600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.5047535018529743e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.98 | consumed tokens: 384819200.0 | grad norm avg: 11.57 | grad norm last: 11.81 | 
2025-12-28T03:20:33 | step: 751700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.5037121304194443e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.72 | consumed tokens: 384870400.0 | grad norm avg: 11.52 | grad norm last: 12.73 | 
2025-12-28T03:20:35 | step: 751800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 2.502671122783795e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.34 | consumed tokens: 384921600.0 | grad norm avg: 11.53 | grad norm last: 10.57 | 
2025-12-28T03:20:37 | step: 751900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.5016304789460264e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.45 | consumed tokens: 384972800.0 | grad norm avg: 11.31 | grad norm last: 11.82 | 
2025-12-28T03:20:39 | step: 752000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.5005900170071982e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.16 | consumed tokens: 385024000.0 | grad norm avg: 11.47 | grad norm last: 12.66 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_752000-seen_tokens_385024000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_752000-seen_tokens_385024000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_752000-seen_tokens_385024000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_752000-seen_tokens_385024000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_752000-seen_tokens_385024000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_752000-seen_tokens_385024000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_752000-seen_tokens_385024000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_752000-seen_tokens_385024000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:20:41 | step: 752100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.4995497369673103e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.66 | train loss last: 3.56 | consumed tokens: 385075200.0 | grad norm avg: 11.8 | grad norm last: 11.46 | 
2025-12-28T03:20:43 | step: 752200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.498509820725303e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.33 | consumed tokens: 385126400.0 | grad norm avg: 11.55 | grad norm last: 10.23 | 
2025-12-28T03:20:45 | step: 752300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.4974702682811767e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 2.91 | consumed tokens: 385177600.0 | grad norm avg: 11.43 | grad norm last: 10.62 | 
2025-12-28T03:20:47 | step: 752400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.496431079634931e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.67 | consumed tokens: 385228800.0 | grad norm avg: 11.67 | grad norm last: 11.54 | 
2025-12-28T03:20:49 | step: 752500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.4953920728876255e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.42 | consumed tokens: 385280000.0 | grad norm avg: 11.53 | grad norm last: 11.53 | 
2025-12-28T03:20:51 | step: 752600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.49435306614032e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.73 | consumed tokens: 385331200.0 | grad norm avg: 11.47 | grad norm last: 10.14 | 
2025-12-28T03:20:54 | step: 752700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.4933144231908955e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.75 | consumed tokens: 385382400.0 | grad norm avg: 11.64 | grad norm last: 10.02 | 
2025-12-28T03:20:56 | step: 752800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.4922765078372322e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.59 | consumed tokens: 385433600.0 | grad norm avg: 11.5 | grad norm last: 11.65 | 
2025-12-28T03:20:58 | step: 752900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.491238592483569e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.73 | consumed tokens: 385484800.0 | grad norm avg: 11.45 | grad norm last: 12.03 | 
2025-12-28T03:21:00 | step: 753000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.4902010409277864e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.61 | consumed tokens: 385536000.0 | grad norm avg: 11.65 | grad norm last: 12.61 | 
2025-12-28T03:21:02 | step: 753100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.4891638531698845e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.09 | consumed tokens: 385587200.0 | grad norm avg: 11.64 | grad norm last: 12.09 | 
2025-12-28T03:21:04 | step: 753200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.4881266654119827e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.25 | consumed tokens: 385638400.0 | grad norm avg: 11.87 | grad norm last: 11.14 | 
2025-12-28T03:21:06 | step: 753300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.4870902052498423e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.39 | consumed tokens: 385689600.0 | grad norm avg: 11.22 | grad norm last: 10.96 | 
2025-12-28T03:21:08 | step: 753400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.4860535631887615e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.38 | consumed tokens: 385740800.0 | grad norm avg: 11.38 | grad norm last: 12.49 | 
2025-12-28T03:21:10 | step: 753500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.4850174668245018e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.34 | consumed tokens: 385792000.0 | grad norm avg: 11.48 | grad norm last: 13.58 | 
2025-12-28T03:21:12 | step: 753600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.4839815523591824e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.42 | consumed tokens: 385843200.0 | grad norm avg: 11.68 | grad norm last: 11.76 | 
2025-12-28T03:21:14 | step: 753700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 2.4829460016917437e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.55 | consumed tokens: 385894400.0 | grad norm avg: 11.44 | grad norm last: 10.33 | 
2025-12-28T03:21:16 | step: 753800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.4819108148221858e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.03 | consumed tokens: 385945600.0 | grad norm avg: 11.43 | grad norm last: 10.83 | 
2025-12-28T03:21:18 | step: 753900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.4808758098515682e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.05 | consumed tokens: 385996800.0 | grad norm avg: 11.71 | grad norm last: 10.18 | 
2025-12-28T03:21:20 | step: 754000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.4798411686788313e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.0 | consumed tokens: 386048000.0 | grad norm avg: 11.72 | grad norm last: 10.9 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_754000-seen_tokens_386048000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_754000-seen_tokens_386048000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_754000-seen_tokens_386048000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_754000-seen_tokens_386048000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_754000-seen_tokens_386048000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_754000-seen_tokens_386048000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_754000-seen_tokens_386048000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_754000-seen_tokens_386048000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:21:22 | step: 754100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.4788067094050348e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.67 | train loss last: 3.34 | consumed tokens: 386099200.0 | grad norm avg: 11.46 | grad norm last: 10.92 | 
2025-12-28T03:21:24 | step: 754200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.477772613929119e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.3 | consumed tokens: 386150400.0 | grad norm avg: 11.69 | grad norm last: 11.09 | 
2025-12-28T03:21:26 | step: 754300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.476738882251084e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.42 | consumed tokens: 386201600.0 | grad norm avg: 11.72 | grad norm last: 11.87 | 
2025-12-28T03:21:28 | step: 754400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.4757051505730487e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.97 | consumed tokens: 386252800.0 | grad norm avg: 11.34 | grad norm last: 16.54 | 
2025-12-28T03:21:30 | step: 754500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.4746719645918347e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.55 | consumed tokens: 386304000.0 | grad norm avg: 11.35 | grad norm last: 12.99 | 
2025-12-28T03:21:32 | step: 754600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.4736391424085014e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.09 | consumed tokens: 386355200.0 | grad norm avg: 11.58 | grad norm last: 10.76 | 
2025-12-28T03:21:34 | step: 754700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.4726066840230487e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.33 | consumed tokens: 386406400.0 | grad norm avg: 11.5 | grad norm last: 11.2 | 
2025-12-28T03:21:36 | step: 754800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.471574225637596e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.17 | consumed tokens: 386457600.0 | grad norm avg: 11.8 | grad norm last: 10.47 | 
2025-12-28T03:21:38 | step: 754900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.4705421310500242e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.34 | consumed tokens: 386508800.0 | grad norm avg: 11.22 | grad norm last: 10.62 | 
2025-12-28T03:21:40 | step: 755000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.469510400260333e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.97 | consumed tokens: 386560000.0 | grad norm avg: 11.41 | grad norm last: 13.33 | 
2025-12-28T03:21:42 | step: 755100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.4684786694706418e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.28 | consumed tokens: 386611200.0 | grad norm avg: 11.6 | grad norm last: 14.13 | 
2025-12-28T03:21:44 | step: 755200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.467447666276712e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.95 | consumed tokens: 386662400.0 | grad norm avg: 11.48 | grad norm last: 11.94 | 
2025-12-28T03:21:46 | step: 755300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.4664166630827822e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.77 | consumed tokens: 386713600.0 | grad norm avg: 11.33 | grad norm last: 10.17 | 
2025-12-28T03:21:49 | step: 755400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.4653862055856735e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.5 | consumed tokens: 386764800.0 | grad norm avg: 11.67 | grad norm last: 11.33 | 
2025-12-28T03:21:51 | step: 755500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.4643557480885647e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.47 | consumed tokens: 386816000.0 | grad norm avg: 11.42 | grad norm last: 12.85 | 
2025-12-28T03:21:53 | step: 755600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.463325836288277e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.14 | consumed tokens: 386867200.0 | grad norm avg: 12.02 | grad norm last: 11.52 | 
2025-12-28T03:21:55 | step: 755700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.4622961063869298e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.58 | consumed tokens: 386918400.0 | grad norm avg: 11.47 | grad norm last: 11.23 | 
2025-12-28T03:21:57 | step: 755800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.4612665583845228e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.41 | consumed tokens: 386969600.0 | grad norm avg: 11.63 | grad norm last: 11.5 | 
2025-12-28T03:21:59 | step: 755900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.460237556078937e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.59 | consumed tokens: 387020800.0 | grad norm avg: 12.09 | grad norm last: 13.2 | 
2025-12-28T03:22:01 | step: 756000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.4592087356722914e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.53 | consumed tokens: 387072000.0 | grad norm avg: 11.61 | grad norm last: 10.62 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_756000-seen_tokens_387072000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_756000-seen_tokens_387072000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_756000-seen_tokens_387072000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_756000-seen_tokens_387072000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_756000-seen_tokens_387072000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_756000-seen_tokens_387072000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_756000-seen_tokens_387072000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_756000-seen_tokens_387072000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:22:03 | step: 756100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.4581800971645862e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.41 | consumed tokens: 387123200.0 | grad norm avg: 11.38 | grad norm last: 9.83 | 
2025-12-28T03:22:05 | step: 756200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 2.4571518224547617e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 2.7 | consumed tokens: 387174400.0 | grad norm avg: 11.6 | grad norm last: 10.04 | 
2025-12-28T03:22:07 | step: 756300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.4561237296438776e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 2.22 | consumed tokens: 387225600.0 | grad norm avg: 11.52 | grad norm last: 9.91 | 
2025-12-28T03:22:09 | step: 756400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.455096364428755e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 2.84 | consumed tokens: 387276800.0 | grad norm avg: 11.79 | grad norm last: 13.73 | 
2025-12-28T03:22:11 | step: 756500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.4540689992136322e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.98 | consumed tokens: 387328000.0 | grad norm avg: 11.74 | grad norm last: 14.93 | 
2025-12-28T03:22:13 | step: 756600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.4530416339985095e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.36 | consumed tokens: 387379200.0 | grad norm avg: 11.51 | grad norm last: 11.26 | 
2025-12-28T03:22:15 | step: 756700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.4520146325812675e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.45 | consumed tokens: 387430400.0 | grad norm avg: 11.68 | grad norm last: 10.44 | 
2025-12-28T03:22:17 | step: 756800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.450988358759787e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.09 | consumed tokens: 387481600.0 | grad norm avg: 11.56 | grad norm last: 10.9 | 
2025-12-28T03:22:19 | step: 756900 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.4499620849383064e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 2.88 | consumed tokens: 387532800.0 | grad norm avg: 11.6 | grad norm last: 9.46 | 
2025-12-28T03:22:21 | step: 757000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.4489361749147065e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.25 | consumed tokens: 387584000.0 | grad norm avg: 11.8 | grad norm last: 10.83 | 
2025-12-28T03:22:23 | step: 757100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.4479106286889873e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.27 | consumed tokens: 387635200.0 | grad norm avg: 11.53 | grad norm last: 10.02 | 
2025-12-28T03:22:25 | step: 757200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.4468850824632682e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.31 | consumed tokens: 387686400.0 | grad norm avg: 11.81 | grad norm last: 11.69 | 
2025-12-28T03:22:27 | step: 757300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.4458602638333105e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 2.81 | consumed tokens: 387737600.0 | grad norm avg: 11.37 | grad norm last: 9.98 | 
2025-12-28T03:22:29 | step: 757400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.4448354452033527e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.53 | consumed tokens: 387788800.0 | grad norm avg: 11.73 | grad norm last: 12.37 | 
2025-12-28T03:22:31 | step: 757500 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 2.4438109903712757e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.91 | consumed tokens: 387840000.0 | grad norm avg: 11.44 | grad norm last: 12.52 | 
2025-12-28T03:22:34 | step: 757600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.4427868993370794e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.78 | consumed tokens: 387891200.0 | grad norm avg: 11.68 | grad norm last: 11.68 | 
2025-12-28T03:22:36 | step: 757700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.441762808302883e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.44 | consumed tokens: 387942400.0 | grad norm avg: 12.01 | grad norm last: 10.68 | 
2025-12-28T03:22:38 | step: 757800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 2.440739444864448e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 2.95 | consumed tokens: 387993600.0 | grad norm avg: 11.52 | grad norm last: 9.74 | 
2025-12-28T03:22:40 | step: 757900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.4397160814260133e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.42 | consumed tokens: 388044800.0 | grad norm avg: 11.57 | grad norm last: 11.55 | 
2025-12-28T03:22:42 | step: 758000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.438693081785459e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.0 | consumed tokens: 388096000.0 | grad norm avg: 11.65 | grad norm last: 10.52 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_758000-seen_tokens_388096000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_758000-seen_tokens_388096000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_758000-seen_tokens_388096000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_758000-seen_tokens_388096000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_758000-seen_tokens_388096000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_758000-seen_tokens_388096000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_758000-seen_tokens_388096000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_758000-seen_tokens_388096000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:22:44 | step: 758100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.4376704459427856e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.61 | train loss last: 3.3 | consumed tokens: 388147200.0 | grad norm avg: 11.45 | grad norm last: 12.14 | 
2025-12-28T03:22:46 | step: 758200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.436647810100112e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.92 | consumed tokens: 388198400.0 | grad norm avg: 11.38 | grad norm last: 13.68 | 
2025-12-28T03:22:48 | step: 758300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.4356259018532e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.91 | consumed tokens: 388249600.0 | grad norm avg: 11.85 | grad norm last: 11.22 | 
2025-12-28T03:22:50 | step: 758400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.434603993606288e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.61 | consumed tokens: 388300800.0 | grad norm avg: 11.67 | grad norm last: 11.79 | 
2025-12-28T03:22:52 | step: 758500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.4335828129551373e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.25 | consumed tokens: 388352000.0 | grad norm avg: 11.89 | grad norm last: 9.66 | 
2025-12-28T03:22:54 | step: 758600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.432561268506106e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.22 | consumed tokens: 388403200.0 | grad norm avg: 11.55 | grad norm last: 14.29 | 
2025-12-28T03:22:56 | step: 758700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.431540451652836e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.86 | consumed tokens: 388454400.0 | grad norm avg: 11.73 | grad norm last: 11.64 | 
2025-12-28T03:22:58 | step: 758800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.4305198166985065e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.16 | consumed tokens: 388505600.0 | grad norm avg: 11.98 | grad norm last: 14.89 | 
2025-12-28T03:23:00 | step: 758900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.4294995455420576e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.88 | consumed tokens: 388556800.0 | grad norm avg: 11.37 | grad norm last: 16.23 | 
2025-12-28T03:23:02 | step: 759000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.428479456284549e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.25 | consumed tokens: 388608000.0 | grad norm avg: 11.61 | grad norm last: 11.37 | 
2025-12-28T03:23:04 | step: 759100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.4274597308249213e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.25 | consumed tokens: 388659200.0 | grad norm avg: 11.49 | grad norm last: 10.96 | 
2025-12-28T03:23:06 | step: 759200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.4264401872642338e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.45 | consumed tokens: 388710400.0 | grad norm avg: 11.95 | grad norm last: 11.07 | 
2025-12-28T03:23:08 | step: 759300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.425421007501427e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.06 | consumed tokens: 388761600.0 | grad norm avg: 11.79 | grad norm last: 13.83 | 
2025-12-28T03:23:10 | step: 759400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.424402191536501e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.67 | consumed tokens: 388812800.0 | grad norm avg: 11.31 | grad norm last: 11.25 | 
2025-12-28T03:23:12 | step: 759500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.4233835574705154e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.33 | consumed tokens: 388864000.0 | grad norm avg: 11.81 | grad norm last: 11.74 | 
2025-12-28T03:23:15 | step: 759600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.4223654691013508e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.41 | consumed tokens: 388915200.0 | grad norm avg: 11.25 | grad norm last: 11.08 | 
2025-12-28T03:23:17 | step: 759700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.4213475626311265e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.25 | consumed tokens: 388966400.0 | grad norm avg: 11.85 | grad norm last: 10.57 | 
2025-12-28T03:23:19 | step: 759800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.4203296561609022e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 2.84 | consumed tokens: 389017600.0 | grad norm avg: 11.66 | grad norm last: 10.75 | 
2025-12-28T03:23:21 | step: 759900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.4193121134885587e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.84 | consumed tokens: 389068800.0 | grad norm avg: 11.56 | grad norm last: 11.08 | 
2025-12-28T03:23:23 | step: 760000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.4182952984119765e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.31 | consumed tokens: 389120000.0 | grad norm avg: 11.5 | grad norm last: 11.57 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_760000-seen_tokens_389120000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_760000-seen_tokens_389120000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_760000-seen_tokens_389120000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_760000-seen_tokens_389120000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_760000-seen_tokens_389120000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_760000-seen_tokens_389120000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_760000-seen_tokens_389120000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_760000-seen_tokens_389120000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:23:25 | step: 760100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.4172784833353944e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.62 | train loss last: 4.5 | consumed tokens: 389171200.0 | grad norm avg: 11.84 | grad norm last: 22.17 | 
2025-12-28T03:23:27 | step: 760200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.416262032056693e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.06 | consumed tokens: 389222400.0 | grad norm avg: 11.68 | grad norm last: 9.9 | 
2025-12-28T03:23:29 | step: 760300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.4152459445758723e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.83 | consumed tokens: 389273600.0 | grad norm avg: 11.6 | grad norm last: 10.23 | 
2025-12-28T03:23:31 | step: 760400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.4142298570950516e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.39 | consumed tokens: 389324800.0 | grad norm avg: 11.47 | grad norm last: 10.41 | 
2025-12-28T03:23:33 | step: 760500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.4132144972099923e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.16 | consumed tokens: 389376000.0 | grad norm avg: 11.79 | grad norm last: 10.86 | 
2025-12-28T03:23:35 | step: 760600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.4121989554259926e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.92 | consumed tokens: 389427200.0 | grad norm avg: 11.44 | grad norm last: 10.99 | 
2025-12-28T03:23:37 | step: 760700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.411183959338814e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 4.25 | consumed tokens: 389478400.0 | grad norm avg: 11.66 | grad norm last: 11.14 | 
2025-12-28T03:23:39 | step: 760800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.4101691451505758e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 2.88 | consumed tokens: 389529600.0 | grad norm avg: 11.54 | grad norm last: 9.93 | 
2025-12-28T03:23:41 | step: 760900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.4091548766591586e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.92 | consumed tokens: 389580800.0 | grad norm avg: 11.68 | grad norm last: 10.29 | 
2025-12-28T03:23:43 | step: 761000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.4081406081677414e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.19 | consumed tokens: 389632000.0 | grad norm avg: 11.5 | grad norm last: 9.97 | 
2025-12-28T03:23:45 | step: 761100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.4071270672720857e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.89 | consumed tokens: 389683200.0 | grad norm avg: 11.37 | grad norm last: 10.91 | 
2025-12-28T03:23:47 | step: 761200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.40611352637643e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.25 | consumed tokens: 389734400.0 | grad norm avg: 11.61 | grad norm last: 10.19 | 
2025-12-28T03:23:49 | step: 761300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.405100349278655e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.38 | consumed tokens: 389785600.0 | grad norm avg: 11.59 | grad norm last: 12.37 | 
2025-12-28T03:23:51 | step: 761400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.4040875359787606e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.28 | consumed tokens: 389836800.0 | grad norm avg: 11.49 | grad norm last: 11.02 | 
2025-12-28T03:23:53 | step: 761500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.4030747226788662e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.72 | consumed tokens: 389888000.0 | grad norm avg: 11.69 | grad norm last: 15.35 | 
2025-12-28T03:23:55 | step: 761600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.4020622731768526e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.38 | consumed tokens: 389939200.0 | grad norm avg: 11.48 | grad norm last: 12.22 | 
2025-12-28T03:23:57 | step: 761700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.4010505512706004e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.08 | consumed tokens: 389990400.0 | grad norm avg: 11.51 | grad norm last: 9.85 | 
2025-12-28T03:23:59 | step: 761800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.400038647465408e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.81 | consumed tokens: 390041600.0 | grad norm avg: 11.46 | grad norm last: 10.43 | 
2025-12-28T03:24:01 | step: 761900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.399027107458096e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.75 | consumed tokens: 390092800.0 | grad norm avg: 11.64 | grad norm last: 11.08 | 
2025-12-28T03:24:03 | step: 762000 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 2.3980161131476052e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.12 | consumed tokens: 390144000.0 | grad norm avg: 11.79 | grad norm last: 10.03 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_762000-seen_tokens_390144000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_762000-seen_tokens_390144000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_762000-seen_tokens_390144000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_762000-seen_tokens_390144000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_762000-seen_tokens_390144000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_762000-seen_tokens_390144000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_762000-seen_tokens_390144000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_762000-seen_tokens_390144000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:24:06 | step: 762100 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 2.3970051188371144e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.71 | train loss last: 4.78 | consumed tokens: 390195200.0 | grad norm avg: 11.71 | grad norm last: 14.76 | 
2025-12-28T03:24:08 | step: 762200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.3959946702234447e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.86 | consumed tokens: 390246400.0 | grad norm avg: 11.54 | grad norm last: 12.63 | 
2025-12-28T03:24:10 | step: 762300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.394984221609775e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.09 | consumed tokens: 390297600.0 | grad norm avg: 11.73 | grad norm last: 11.63 | 
2025-12-28T03:24:12 | step: 762400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.3939743186929263e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.02 | consumed tokens: 390348800.0 | grad norm avg: 11.48 | grad norm last: 11.63 | 
2025-12-28T03:24:14 | step: 762500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.3929647795739584e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.83 | consumed tokens: 390400000.0 | grad norm avg: 11.4 | grad norm last: 15.69 | 
2025-12-28T03:24:16 | step: 762600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.391955604252871e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.16 | consumed tokens: 390451200.0 | grad norm avg: 11.87 | grad norm last: 10.65 | 
2025-12-28T03:24:18 | step: 762700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.390946428931784e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.03 | consumed tokens: 390502400.0 | grad norm avg: 12.38 | grad norm last: 10.71 | 
2025-12-28T03:24:20 | step: 762800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.3899376174085774e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 2.8 | consumed tokens: 390553600.0 | grad norm avg: 11.57 | grad norm last: 10.53 | 
2025-12-28T03:24:22 | step: 762900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.3889291696832515e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.03 | consumed tokens: 390604800.0 | grad norm avg: 11.65 | grad norm last: 9.76 | 
2025-12-28T03:24:24 | step: 763000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.3879210857558064e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.02 | consumed tokens: 390656000.0 | grad norm avg: 11.44 | grad norm last: 11.21 | 
2025-12-28T03:24:26 | step: 763100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.386913365626242e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.75 | consumed tokens: 390707200.0 | grad norm avg: 11.69 | grad norm last: 12.63 | 
2025-12-28T03:24:28 | step: 763200 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 2.3859056454966776e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.52 | consumed tokens: 390758400.0 | grad norm avg: 11.41 | grad norm last: 11.2 | 
2025-12-28T03:24:30 | step: 763300 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.384898289164994e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.94 | consumed tokens: 390809600.0 | grad norm avg: 11.4 | grad norm last: 11.88 | 
2025-12-28T03:24:32 | step: 763400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.383891296631191e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.22 | consumed tokens: 390860800.0 | grad norm avg: 11.74 | grad norm last: 11.03 | 
2025-12-28T03:24:34 | step: 763500 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.382884849794209e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.73 | consumed tokens: 390912000.0 | grad norm avg: 11.49 | grad norm last: 10.22 | 
2025-12-28T03:24:36 | step: 763600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.3818785848561674e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.97 | consumed tokens: 390963200.0 | grad norm avg: 11.6 | grad norm last: 9.33 | 
2025-12-28T03:24:38 | step: 763700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.3808725018170662e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.47 | consumed tokens: 391014400.0 | grad norm avg: 11.29 | grad norm last: 10.9 | 
2025-12-28T03:24:41 | step: 763800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.3798667825758457e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.62 | consumed tokens: 391065600.0 | grad norm avg: 11.42 | grad norm last: 10.36 | 
2025-12-28T03:24:43 | step: 763900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.3788612452335656e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.38 | consumed tokens: 391116800.0 | grad norm avg: 11.87 | grad norm last: 14.12 | 
2025-12-28T03:24:45 | step: 764000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.3778562535881065e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.5 | consumed tokens: 391168000.0 | grad norm avg: 11.4 | grad norm last: 11.17 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_764000-seen_tokens_391168000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_764000-seen_tokens_391168000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_764000-seen_tokens_391168000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_764000-seen_tokens_391168000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_764000-seen_tokens_391168000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_764000-seen_tokens_391168000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_764000-seen_tokens_391168000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_764000-seen_tokens_391168000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:24:47 | step: 764100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.376851080043707e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.61 | train loss last: 3.94 | consumed tokens: 391219200.0 | grad norm avg: 11.61 | grad norm last: 11.11 | 
2025-12-28T03:24:49 | step: 764200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.3758468159940094e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.86 | consumed tokens: 391270400.0 | grad norm avg: 11.84 | grad norm last: 11.43 | 
2025-12-28T03:24:51 | step: 764300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.3748425519443117e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.08 | consumed tokens: 391321600.0 | grad norm avg: 11.15 | grad norm last: 10.54 | 
2025-12-28T03:24:53 | step: 764400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.3738384697935544e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 2.88 | consumed tokens: 391372800.0 | grad norm avg: 11.84 | grad norm last: 9.45 | 
2025-12-28T03:24:55 | step: 764500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.3728347514406778e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.22 | consumed tokens: 391424000.0 | grad norm avg: 11.74 | grad norm last: 11.95 | 
2025-12-28T03:24:57 | step: 764600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.3718317606835626e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.25 | consumed tokens: 391475200.0 | grad norm avg: 11.89 | grad norm last: 10.51 | 
2025-12-28T03:24:59 | step: 764700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.3708284061285667e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 2.78 | consumed tokens: 391526400.0 | grad norm avg: 11.6 | grad norm last: 9.9 | 
2025-12-28T03:25:01 | step: 764800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.3698257791693322e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.83 | consumed tokens: 391577600.0 | grad norm avg: 11.5 | grad norm last: 12.3 | 
2025-12-28T03:25:03 | step: 764900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.368823334109038e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.22 | consumed tokens: 391628800.0 | grad norm avg: 11.31 | grad norm last: 10.51 | 
2025-12-28T03:25:05 | step: 765000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.3678212528466247e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.83 | consumed tokens: 391680000.0 | grad norm avg: 11.51 | grad norm last: 11.52 | 
2025-12-28T03:25:07 | step: 765100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.3668193534831516e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.45 | consumed tokens: 391731200.0 | grad norm avg: 11.34 | grad norm last: 10.78 | 
2025-12-28T03:25:09 | step: 765200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.3658178179175593e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.27 | consumed tokens: 391782400.0 | grad norm avg: 11.91 | grad norm last: 11.24 | 
2025-12-28T03:25:11 | step: 765300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 2.3648164642509073e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.27 | consumed tokens: 391833600.0 | grad norm avg: 11.45 | grad norm last: 10.77 | 
2025-12-28T03:25:13 | step: 765400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.363815474382136e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.22 | consumed tokens: 391884800.0 | grad norm avg: 11.26 | grad norm last: 13.79 | 
2025-12-28T03:25:15 | step: 765500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.3628150302101858e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.16 | consumed tokens: 391936000.0 | grad norm avg: 11.12 | grad norm last: 11.17 | 
2025-12-28T03:25:17 | step: 765600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.3618145860382356e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.25 | consumed tokens: 391987200.0 | grad norm avg: 11.52 | grad norm last: 10.42 | 
2025-12-28T03:25:19 | step: 765700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.3608146875631064e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.11 | consumed tokens: 392038400.0 | grad norm avg: 11.21 | grad norm last: 10.37 | 
2025-12-28T03:25:21 | step: 765800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 2.3598147890879773e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.02 | consumed tokens: 392089600.0 | grad norm avg: 11.78 | grad norm last: 9.01 | 
2025-12-28T03:25:23 | step: 765900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.358815436309669e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.48 | consumed tokens: 392140800.0 | grad norm avg: 11.69 | grad norm last: 11.16 | 
2025-12-28T03:25:25 | step: 766000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.3578162654303014e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.38 | consumed tokens: 392192000.0 | grad norm avg: 11.72 | grad norm last: 10.05 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_766000-seen_tokens_392192000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_766000-seen_tokens_392192000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_766000-seen_tokens_392192000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_766000-seen_tokens_392192000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_766000-seen_tokens_392192000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_766000-seen_tokens_392192000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_766000-seen_tokens_392192000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_766000-seen_tokens_392192000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:25:28 | step: 766100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.3568174583488144e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.72 | consumed tokens: 392243200.0 | grad norm avg: 11.36 | grad norm last: 12.32 | 
2025-12-28T03:25:30 | step: 766200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.355819015065208e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.0 | consumed tokens: 392294400.0 | grad norm avg: 11.55 | grad norm last: 12.48 | 
2025-12-28T03:25:32 | step: 766300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.354820753680542e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.12 | consumed tokens: 392345600.0 | grad norm avg: 11.2 | grad norm last: 10.08 | 
2025-12-28T03:25:34 | step: 766400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.3538226741948165e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.03 | consumed tokens: 392396800.0 | grad norm avg: 11.6 | grad norm last: 13.42 | 
2025-12-28T03:25:36 | step: 766500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.352825140405912e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.33 | consumed tokens: 392448000.0 | grad norm avg: 11.93 | grad norm last: 11.75 | 
2025-12-28T03:25:38 | step: 766600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.351827970414888e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.45 | consumed tokens: 392499200.0 | grad norm avg: 11.74 | grad norm last: 10.41 | 
2025-12-28T03:25:40 | step: 766700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.3508308004238643e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.97 | consumed tokens: 392550400.0 | grad norm avg: 11.62 | grad norm last: 11.54 | 
2025-12-28T03:25:42 | step: 766800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.349833994230721e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.33 | consumed tokens: 392601600.0 | grad norm avg: 11.65 | grad norm last: 11.46 | 
2025-12-28T03:25:44 | step: 766900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.348837733734399e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.47 | consumed tokens: 392652800.0 | grad norm avg: 11.66 | grad norm last: 14.92 | 
2025-12-28T03:25:46 | step: 767000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.3478416551370174e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.58 | consumed tokens: 392704000.0 | grad norm avg: 11.54 | grad norm last: 10.78 | 
2025-12-28T03:25:48 | step: 767100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.3468461222364567e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.8 | consumed tokens: 392755200.0 | grad norm avg: 11.42 | grad norm last: 12.45 | 
2025-12-28T03:25:50 | step: 767200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.3458504074369557e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.66 | consumed tokens: 392806400.0 | grad norm avg: 11.65 | grad norm last: 10.94 | 
2025-12-28T03:25:52 | step: 767300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.344855420233216e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.84 | consumed tokens: 392857600.0 | grad norm avg: 11.52 | grad norm last: 10.62 | 
2025-12-28T03:25:54 | step: 767400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.3438602511305362e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.12 | consumed tokens: 392908800.0 | grad norm avg: 11.52 | grad norm last: 10.36 | 
2025-12-28T03:25:56 | step: 767500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.3428658096236177e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.73 | consumed tokens: 392960000.0 | grad norm avg: 11.53 | grad norm last: 11.08 | 
2025-12-28T03:25:58 | step: 767600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.3418715500156395e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.8 | consumed tokens: 393011200.0 | grad norm avg: 11.7 | grad norm last: 11.87 | 
2025-12-28T03:26:00 | step: 767700 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 2.3408772904076613e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.42 | consumed tokens: 393062400.0 | grad norm avg: 11.69 | grad norm last: 10.41 | 
2025-12-28T03:26:02 | step: 767800 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.3398837583954446e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.31 | consumed tokens: 393113600.0 | grad norm avg: 11.48 | grad norm last: 12.58 | 
2025-12-28T03:26:04 | step: 767900 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.3388905901811086e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.73 | consumed tokens: 393164800.0 | grad norm avg: 11.43 | grad norm last: 11.74 | 
2025-12-28T03:26:07 | step: 768000 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 2.3378974219667725e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.59 | consumed tokens: 393216000.0 | grad norm avg: 11.79 | grad norm last: 12.09 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_768000-seen_tokens_393216000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_768000-seen_tokens_393216000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_768000-seen_tokens_393216000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_768000-seen_tokens_393216000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_768000-seen_tokens_393216000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_768000-seen_tokens_393216000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_768000-seen_tokens_393216000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_768000-seen_tokens_393216000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:26:09 | step: 768100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.3369046175503172e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.05 | consumed tokens: 393267200.0 | grad norm avg: 11.97 | grad norm last: 10.23 | 
2025-12-28T03:26:11 | step: 768200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.3359121769317426e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.28 | consumed tokens: 393318400.0 | grad norm avg: 11.54 | grad norm last: 9.96 | 
2025-12-28T03:26:13 | step: 768300 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 2.3349201001110487e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.47 | consumed tokens: 393369600.0 | grad norm avg: 11.82 | grad norm last: 11.19 | 
2025-12-28T03:26:15 | step: 768400 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.3339283870882355e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.56 | consumed tokens: 393420800.0 | grad norm avg: 11.59 | grad norm last: 12.81 | 
2025-12-28T03:26:17 | step: 768500 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.3329366740654223e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.92 | consumed tokens: 393472000.0 | grad norm avg: 11.44 | grad norm last: 10.4 | 
2025-12-28T03:26:19 | step: 768600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.3319453248404898e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 4.47 | consumed tokens: 393523200.0 | grad norm avg: 11.36 | grad norm last: 15.63 | 
2025-12-28T03:26:21 | step: 768700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.330954339413438e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.5 | consumed tokens: 393574400.0 | grad norm avg: 11.23 | grad norm last: 10.3 | 
2025-12-28T03:26:23 | step: 768800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.3299638996832073e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 2.59 | consumed tokens: 393625600.0 | grad norm avg: 11.84 | grad norm last: 8.94 | 
2025-12-28T03:26:25 | step: 768900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.3289734599529766e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.16 | consumed tokens: 393676800.0 | grad norm avg: 11.21 | grad norm last: 12.31 | 
2025-12-28T03:26:27 | step: 769000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.327983565919567e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.97 | consumed tokens: 393728000.0 | grad norm avg: 11.69 | grad norm last: 11.22 | 
2025-12-28T03:26:29 | step: 769100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.3269938537850976e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.19 | consumed tokens: 393779200.0 | grad norm avg: 11.6 | grad norm last: 11.24 | 
2025-12-28T03:26:31 | step: 769200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.3260043235495687e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.12 | consumed tokens: 393830400.0 | grad norm avg: 11.66 | grad norm last: 13.23 | 
2025-12-28T03:26:33 | step: 769300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.3250153390108608e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.84 | consumed tokens: 393881600.0 | grad norm avg: 11.83 | grad norm last: 13.37 | 
2025-12-28T03:26:35 | step: 769400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.3240265363710932e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.02 | consumed tokens: 393932800.0 | grad norm avg: 11.28 | grad norm last: 10.27 | 
2025-12-28T03:26:37 | step: 769500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.323037915630266e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.41 | consumed tokens: 393984000.0 | grad norm avg: 11.42 | grad norm last: 13.58 | 
2025-12-28T03:26:39 | step: 769600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.32204984058626e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.45 | consumed tokens: 394035200.0 | grad norm avg: 11.46 | grad norm last: 11.51 | 
2025-12-28T03:26:41 | step: 769700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.3210619474411942e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.53 | consumed tokens: 394086400.0 | grad norm avg: 11.28 | grad norm last: 10.47 | 
2025-12-28T03:26:43 | step: 769800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.320074418094009e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 5.0 | consumed tokens: 394137600.0 | grad norm avg: 11.48 | grad norm last: 14.28 | 
2025-12-28T03:26:45 | step: 769900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.3190870706457645e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.34 | consumed tokens: 394188800.0 | grad norm avg: 11.68 | grad norm last: 13.04 | 
2025-12-28T03:26:47 | step: 770000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.318100268894341e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.75 | consumed tokens: 394240000.0 | grad norm avg: 11.76 | grad norm last: 11.62 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_770000-seen_tokens_394240000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_770000-seen_tokens_394240000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_770000-seen_tokens_394240000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_770000-seen_tokens_394240000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_770000-seen_tokens_394240000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_770000-seen_tokens_394240000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_770000-seen_tokens_394240000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_770000-seen_tokens_394240000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:26:50 | step: 770100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.3171136490418576e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.22 | consumed tokens: 394291200.0 | grad norm avg: 11.22 | grad norm last: 10.18 | 
2025-12-28T03:26:52 | step: 770200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.3161270291893743e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 2.83 | consumed tokens: 394342400.0 | grad norm avg: 11.89 | grad norm last: 11.03 | 
2025-12-28T03:26:54 | step: 770300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.3151411369326524e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.73 | consumed tokens: 394393600.0 | grad norm avg: 11.37 | grad norm last: 12.56 | 
2025-12-28T03:26:56 | step: 770400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.3141552446759306e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.2 | consumed tokens: 394444800.0 | grad norm avg: 11.47 | grad norm last: 10.51 | 
2025-12-28T03:26:58 | step: 770500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.31317008001497e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.23 | consumed tokens: 394496000.0 | grad norm avg: 11.48 | grad norm last: 11.61 | 
2025-12-28T03:27:00 | step: 770600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.3121849153540097e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.23 | consumed tokens: 394547200.0 | grad norm avg: 11.7 | grad norm last: 10.87 | 
2025-12-28T03:27:02 | step: 770700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.3111999325919896e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.09 | consumed tokens: 394598400.0 | grad norm avg: 11.66 | grad norm last: 10.45 | 
2025-12-28T03:27:04 | step: 770800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.3102154955267906e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.11 | consumed tokens: 394649600.0 | grad norm avg: 11.33 | grad norm last: 10.06 | 
2025-12-28T03:27:06 | step: 770900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.309231240360532e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.28 | consumed tokens: 394700800.0 | grad norm avg: 11.75 | grad norm last: 11.13 | 
2025-12-28T03:27:08 | step: 771000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.308247348992154e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.09 | consumed tokens: 394752000.0 | grad norm avg: 11.59 | grad norm last: 13.65 | 
2025-12-28T03:27:10 | step: 771100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.3072636395227164e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 2.86 | consumed tokens: 394803200.0 | grad norm avg: 11.77 | grad norm last: 9.77 | 
2025-12-28T03:27:12 | step: 771200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.3062804757501e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.41 | consumed tokens: 394854400.0 | grad norm avg: 11.51 | grad norm last: 12.72 | 
2025-12-28T03:27:14 | step: 771300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.3052974938764237e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.84 | consumed tokens: 394905600.0 | grad norm avg: 11.6 | grad norm last: 13.55 | 
2025-12-28T03:27:16 | step: 771400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 2.3043148758006282e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.77 | consumed tokens: 394956800.0 | grad norm avg: 11.31 | grad norm last: 10.66 | 
2025-12-28T03:27:18 | step: 771500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.303332439623773e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 2.86 | consumed tokens: 395008000.0 | grad norm avg: 11.59 | grad norm last: 10.34 | 
2025-12-28T03:27:20 | step: 771600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.3023503672447987e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.2 | consumed tokens: 395059200.0 | grad norm avg: 11.83 | grad norm last: 10.88 | 
2025-12-28T03:27:22 | step: 771700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 2.301368658663705e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.34 | consumed tokens: 395110400.0 | grad norm avg: 11.7 | grad norm last: 11.04 | 
2025-12-28T03:27:24 | step: 771800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 2.3003871319815516e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.09 | consumed tokens: 395161600.0 | grad norm avg: 11.78 | grad norm last: 11.21 | 
2025-12-28T03:27:26 | step: 771900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.2994057871983387e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 4.34 | consumed tokens: 395212800.0 | grad norm avg: 12.05 | grad norm last: 14.1 | 
2025-12-28T03:27:28 | step: 772000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.2984249881119467e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.89 | consumed tokens: 395264000.0 | grad norm avg: 11.67 | grad norm last: 11.42 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_772000-seen_tokens_395264000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_772000-seen_tokens_395264000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_772000-seen_tokens_395264000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_772000-seen_tokens_395264000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_772000-seen_tokens_395264000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_772000-seen_tokens_395264000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_772000-seen_tokens_395264000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_772000-seen_tokens_395264000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:27:31 | step: 772100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.297444734722376e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.75 | train loss last: 4.19 | consumed tokens: 395315200.0 | grad norm avg: 11.94 | grad norm last: 11.96 | 
2025-12-28T03:27:33 | step: 772200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.296464481332805e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.7 | consumed tokens: 395366400.0 | grad norm avg: 11.84 | grad norm last: 10.68 | 
2025-12-28T03:27:35 | step: 772300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.295484591741115e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.64 | consumed tokens: 395417600.0 | grad norm avg: 11.79 | grad norm last: 10.4 | 
2025-12-28T03:27:37 | step: 772400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.2945050659473054e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.81 | consumed tokens: 395468800.0 | grad norm avg: 11.61 | grad norm last: 12.1 | 
2025-12-28T03:27:39 | step: 772500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.2935257220524363e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.48 | consumed tokens: 395520000.0 | grad norm avg: 11.36 | grad norm last: 15.83 | 
2025-12-28T03:27:41 | step: 772600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.292546741955448e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.25 | consumed tokens: 395571200.0 | grad norm avg: 11.68 | grad norm last: 11.62 | 
2025-12-28T03:27:43 | step: 772700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.2915681256563403e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.58 | consumed tokens: 395622400.0 | grad norm avg: 11.49 | grad norm last: 11.9 | 
2025-12-28T03:27:45 | step: 772800 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.2905898731551133e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.7 | consumed tokens: 395673600.0 | grad norm avg: 11.68 | grad norm last: 11.72 | 
2025-12-28T03:27:47 | step: 772900 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 2.2896116206538863e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.31 | consumed tokens: 395724800.0 | grad norm avg: 11.62 | grad norm last: 10.4 | 
2025-12-28T03:27:49 | step: 773000 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 2.2886340957484208e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.22 | consumed tokens: 395776000.0 | grad norm avg: 11.83 | grad norm last: 17.55 | 
2025-12-28T03:27:51 | step: 773100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.2876565708429553e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.44 | consumed tokens: 395827200.0 | grad norm avg: 11.93 | grad norm last: 12.65 | 
2025-12-28T03:27:53 | step: 773200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.2866794097353704e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.28 | consumed tokens: 395878400.0 | grad norm avg: 12.29 | grad norm last: 14.11 | 
2025-12-28T03:27:55 | step: 773300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.2857026124256663e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.94 | consumed tokens: 395929600.0 | grad norm avg: 11.47 | grad norm last: 12.8 | 
2025-12-28T03:27:57 | step: 773400 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 2.2847258151159622e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.02 | consumed tokens: 395980800.0 | grad norm avg: 11.82 | grad norm last: 10.61 | 
2025-12-28T03:27:59 | step: 773500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.2837499273009598e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.75 | consumed tokens: 396032000.0 | grad norm avg: 11.74 | grad norm last: 12.14 | 
2025-12-28T03:28:01 | step: 773600 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.2827740394859575e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.41 | consumed tokens: 396083200.0 | grad norm avg: 11.38 | grad norm last: 11.17 | 
2025-12-28T03:28:03 | step: 773700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.2817983335698955e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 2.64 | consumed tokens: 396134400.0 | grad norm avg: 11.42 | grad norm last: 10.14 | 
2025-12-28T03:28:05 | step: 773800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.2808229914517142e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.64 | consumed tokens: 396185600.0 | grad norm avg: 11.5 | grad norm last: 10.87 | 
2025-12-28T03:28:07 | step: 773900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.2798480131314136e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.3 | consumed tokens: 396236800.0 | grad norm avg: 11.79 | grad norm last: 10.63 | 
2025-12-28T03:28:09 | step: 774000 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.278873580507934e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.66 | consumed tokens: 396288000.0 | grad norm avg: 11.6 | grad norm last: 12.78 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_774000-seen_tokens_396288000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_774000-seen_tokens_396288000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_774000-seen_tokens_396288000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_774000-seen_tokens_396288000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_774000-seen_tokens_396288000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_774000-seen_tokens_396288000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_774000-seen_tokens_396288000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_774000-seen_tokens_396288000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:28:12 | step: 774100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.2778991478844546e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.95 | consumed tokens: 396339200.0 | grad norm avg: 11.61 | grad norm last: 11.73 | 
2025-12-28T03:28:14 | step: 774200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.2769250790588558e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.91 | consumed tokens: 396390400.0 | grad norm avg: 11.5 | grad norm last: 13.52 | 
2025-12-28T03:28:16 | step: 774300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.2759513740311377e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.8 | consumed tokens: 396441600.0 | grad norm avg: 11.75 | grad norm last: 11.23 | 
2025-12-28T03:28:18 | step: 774400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.2749780328013003e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.2 | consumed tokens: 396492800.0 | grad norm avg: 11.42 | grad norm last: 10.17 | 
2025-12-28T03:28:20 | step: 774500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.2740050553693436e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.52 | consumed tokens: 396544000.0 | grad norm avg: 11.31 | grad norm last: 11.03 | 
2025-12-28T03:28:22 | step: 774600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.2730318960384466e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.88 | consumed tokens: 396595200.0 | grad norm avg: 11.6 | grad norm last: 11.2 | 
2025-12-28T03:28:24 | step: 774700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.2720596462022513e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.28 | consumed tokens: 396646400.0 | grad norm avg: 11.65 | grad norm last: 11.71 | 
2025-12-28T03:28:26 | step: 774800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.271087396366056e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.33 | consumed tokens: 396697600.0 | grad norm avg: 11.38 | grad norm last: 10.48 | 
2025-12-28T03:28:28 | step: 774900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.270115692226682e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.38 | consumed tokens: 396748800.0 | grad norm avg: 11.6 | grad norm last: 11.23 | 
2025-12-28T03:28:30 | step: 775000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.2691439880873077e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.86 | consumed tokens: 396800000.0 | grad norm avg: 11.58 | grad norm last: 10.46 | 
2025-12-28T03:28:32 | step: 775100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.2681728296447545e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 2.95 | consumed tokens: 396851200.0 | grad norm avg: 11.68 | grad norm last: 9.29 | 
2025-12-28T03:28:34 | step: 775200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.267202035000082e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.31 | consumed tokens: 396902400.0 | grad norm avg: 11.4 | grad norm last: 14.56 | 
2025-12-28T03:28:36 | step: 775300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.26623142225435e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.33 | consumed tokens: 396953600.0 | grad norm avg: 11.54 | grad norm last: 11.65 | 
2025-12-28T03:28:38 | step: 775400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.2652609914075583e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.06 | consumed tokens: 397004800.0 | grad norm avg: 11.63 | grad norm last: 13.04 | 
2025-12-28T03:28:40 | step: 775500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.2642909243586473e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.38 | consumed tokens: 397056000.0 | grad norm avg: 11.42 | grad norm last: 10.25 | 
2025-12-28T03:28:42 | step: 775600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.263321221107617e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.72 | consumed tokens: 397107200.0 | grad norm avg: 11.6 | grad norm last: 12.51 | 
2025-12-28T03:28:44 | step: 775700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.2623518816544674e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.08 | consumed tokens: 397158400.0 | grad norm avg: 11.91 | grad norm last: 9.31 | 
2025-12-28T03:28:46 | step: 775800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.2613829059991986e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.09 | consumed tokens: 397209600.0 | grad norm avg: 12.04 | grad norm last: 13.0 | 
2025-12-28T03:28:48 | step: 775900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.2604139303439297e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.92 | consumed tokens: 397260800.0 | grad norm avg: 11.64 | grad norm last: 12.74 | 
2025-12-28T03:28:50 | step: 776000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.2594458641833626e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.09 | consumed tokens: 397312000.0 | grad norm avg: 11.63 | grad norm last: 11.19 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_776000-seen_tokens_397312000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_776000-seen_tokens_397312000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_776000-seen_tokens_397312000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_776000-seen_tokens_397312000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_776000-seen_tokens_397312000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_776000-seen_tokens_397312000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_776000-seen_tokens_397312000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_776000-seen_tokens_397312000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:28:52 | step: 776100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.258477616123855e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.2 | consumed tokens: 397363200.0 | grad norm avg: 11.69 | grad norm last: 10.88 | 
2025-12-28T03:28:55 | step: 776200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.2575097318622284e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.36 | consumed tokens: 397414400.0 | grad norm avg: 11.57 | grad norm last: 12.94 | 
2025-12-28T03:28:57 | step: 776300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.2565422113984823e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.42 | consumed tokens: 397465600.0 | grad norm avg: 11.42 | grad norm last: 11.93 | 
2025-12-28T03:28:59 | step: 776400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.255575054732617e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.58 | consumed tokens: 397516800.0 | grad norm avg: 11.85 | grad norm last: 13.79 | 
2025-12-28T03:29:01 | step: 776500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.2546082618646324e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.52 | consumed tokens: 397568000.0 | grad norm avg: 11.78 | grad norm last: 10.63 | 
2025-12-28T03:29:03 | step: 776600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 2.2536414689966477e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.08 | consumed tokens: 397619200.0 | grad norm avg: 11.69 | grad norm last: 11.22 | 
2025-12-28T03:29:05 | step: 776700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.2526752218254842e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.16 | consumed tokens: 397670400.0 | grad norm avg: 11.42 | grad norm last: 10.86 | 
2025-12-28T03:29:07 | step: 776800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.2517095203511417e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.56 | consumed tokens: 397721600.0 | grad norm avg: 11.7 | grad norm last: 10.35 | 
2025-12-28T03:29:09 | step: 776900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.2507438188767992e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.56 | consumed tokens: 397772800.0 | grad norm avg: 11.92 | grad norm last: 12.12 | 
2025-12-28T03:29:11 | step: 777000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.2497784812003374e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.5 | consumed tokens: 397824000.0 | grad norm avg: 11.5 | grad norm last: 12.52 | 
2025-12-28T03:29:13 | step: 777100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.2488135073217563e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.08 | consumed tokens: 397875200.0 | grad norm avg: 11.49 | grad norm last: 11.88 | 
2025-12-28T03:29:15 | step: 777200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.2478487153421156e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.14 | consumed tokens: 397926400.0 | grad norm avg: 11.37 | grad norm last: 10.43 | 
2025-12-28T03:29:17 | step: 777300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.2468846509582363e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 2.86 | consumed tokens: 397977600.0 | grad norm avg: 12.0 | grad norm last: 10.48 | 
2025-12-28T03:29:19 | step: 777400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.2459202227764763e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.52 | consumed tokens: 398028800.0 | grad norm avg: 11.69 | grad norm last: 12.67 | 
2025-12-28T03:29:21 | step: 777500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.2449565221904777e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.52 | consumed tokens: 398080000.0 | grad norm avg: 11.58 | grad norm last: 10.65 | 
2025-12-28T03:29:23 | step: 777600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.2439931854023598e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.75 | consumed tokens: 398131200.0 | grad norm avg: 11.45 | grad norm last: 11.77 | 
2025-12-28T03:29:25 | step: 777700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.2430300305131823e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 2.88 | consumed tokens: 398182400.0 | grad norm avg: 11.58 | grad norm last: 11.37 | 
2025-12-28T03:29:27 | step: 777800 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 2.2420672394218855e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.72 | consumed tokens: 398233600.0 | grad norm avg: 11.8 | grad norm last: 12.63 | 
2025-12-28T03:29:29 | step: 777900 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 2.2411048121284693e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.55 | consumed tokens: 398284800.0 | grad norm avg: 11.41 | grad norm last: 10.08 | 
2025-12-28T03:29:31 | step: 778000 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 2.240142748632934e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.36 | consumed tokens: 398336000.0 | grad norm avg: 11.52 | grad norm last: 10.77 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_778000-seen_tokens_398336000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_778000-seen_tokens_398336000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_778000-seen_tokens_398336000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_778000-seen_tokens_398336000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_778000-seen_tokens_398336000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_778000-seen_tokens_398336000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_778000-seen_tokens_398336000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_778000-seen_tokens_398336000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:29:33 | step: 778100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.239180867036339e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 3.91 | consumed tokens: 398387200.0 | grad norm avg: 11.46 | grad norm last: 11.92 | 
2025-12-28T03:29:35 | step: 778200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.2382191673386842e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.16 | consumed tokens: 398438400.0 | grad norm avg: 11.75 | grad norm last: 10.95 | 
2025-12-28T03:29:38 | step: 778300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.2372578314389102e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.38 | consumed tokens: 398489600.0 | grad norm avg: 12.1 | grad norm last: 11.55 | 
2025-12-28T03:29:40 | step: 778400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.236296859337017e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.3 | consumed tokens: 398540800.0 | grad norm avg: 11.53 | grad norm last: 11.69 | 
2025-12-28T03:29:42 | step: 778500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.2353362510330044e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.23 | consumed tokens: 398592000.0 | grad norm avg: 11.68 | grad norm last: 10.74 | 
2025-12-28T03:29:44 | step: 778600 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.2343760065268725e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.05 | consumed tokens: 398643200.0 | grad norm avg: 11.43 | grad norm last: 10.31 | 
2025-12-28T03:29:46 | step: 778700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.2334157620207407e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.98 | consumed tokens: 398694400.0 | grad norm avg: 11.71 | grad norm last: 11.08 | 
2025-12-28T03:29:48 | step: 778800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.2324564270093106e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.89 | consumed tokens: 398745600.0 | grad norm avg: 11.67 | grad norm last: 12.96 | 
2025-12-28T03:29:50 | step: 778900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.23149691009894e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.2 | consumed tokens: 398796800.0 | grad norm avg: 11.32 | grad norm last: 9.8 | 
2025-12-28T03:29:52 | step: 779000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.2305379388853908e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.75 | consumed tokens: 398848000.0 | grad norm avg: 11.79 | grad norm last: 11.51 | 
2025-12-28T03:29:54 | step: 779100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.2295791495707817e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.72 | consumed tokens: 398899200.0 | grad norm avg: 11.71 | grad norm last: 11.93 | 
2025-12-28T03:29:56 | step: 779200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.2286207240540534e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.28 | consumed tokens: 398950400.0 | grad norm avg: 11.96 | grad norm last: 10.45 | 
2025-12-28T03:29:58 | step: 779300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.2276626623352058e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.41 | consumed tokens: 399001600.0 | grad norm avg: 11.79 | grad norm last: 10.82 | 
2025-12-28T03:30:00 | step: 779400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.226704964414239e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.03 | consumed tokens: 399052800.0 | grad norm avg: 11.8 | grad norm last: 11.32 | 
2025-12-28T03:30:02 | step: 779500 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.2257474483922124e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.88 | consumed tokens: 399104000.0 | grad norm avg: 11.74 | grad norm last: 10.21 | 
2025-12-28T03:30:04 | step: 779600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.224790478067007e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.75 | consumed tokens: 399155200.0 | grad norm avg: 11.95 | grad norm last: 11.36 | 
2025-12-28T03:30:06 | step: 779700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.223833325842861e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.47 | consumed tokens: 399206400.0 | grad norm avg: 11.53 | grad norm last: 11.51 | 
2025-12-28T03:30:08 | step: 779800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.2228769012144767e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.84 | consumed tokens: 399257600.0 | grad norm avg: 11.81 | grad norm last: 11.91 | 
2025-12-28T03:30:10 | step: 779900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.221920840383973e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 4.34 | consumed tokens: 399308800.0 | grad norm avg: 12.15 | grad norm last: 12.91 | 
2025-12-28T03:30:12 | step: 780000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.2209647795534693e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.8 | consumed tokens: 399360000.0 | grad norm avg: 12.07 | grad norm last: 11.14 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_780000-seen_tokens_399360000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_780000-seen_tokens_399360000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_780000-seen_tokens_399360000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_780000-seen_tokens_399360000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_780000-seen_tokens_399360000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_780000-seen_tokens_399360000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_780000-seen_tokens_399360000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_780000-seen_tokens_399360000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:30:14 | step: 780100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.2200090825208463e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.44 | consumed tokens: 399411200.0 | grad norm avg: 11.53 | grad norm last: 10.33 | 
2025-12-28T03:30:16 | step: 780200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.2190541130839847e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.19 | consumed tokens: 399462400.0 | grad norm avg: 11.84 | grad norm last: 20.36 | 
2025-12-28T03:30:18 | step: 780300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.2180989617481828e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.08 | consumed tokens: 399513600.0 | grad norm avg: 11.82 | grad norm last: 10.96 | 
2025-12-28T03:30:21 | step: 780400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.217144356109202e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.25 | consumed tokens: 399564800.0 | grad norm avg: 11.39 | grad norm last: 10.06 | 
2025-12-28T03:30:23 | step: 780500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.216190296167042e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.58 | consumed tokens: 399616000.0 | grad norm avg: 11.83 | grad norm last: 10.83 | 
2025-12-28T03:30:25 | step: 780600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.215236054325942e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.75 | consumed tokens: 399667200.0 | grad norm avg: 12.46 | grad norm last: 12.71 | 
2025-12-28T03:30:27 | step: 780700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.2142825400806032e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.08 | consumed tokens: 399718400.0 | grad norm avg: 11.65 | grad norm last: 9.69 | 
2025-12-28T03:30:29 | step: 780800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.2133290258352645e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.33 | consumed tokens: 399769600.0 | grad norm avg: 12.0 | grad norm last: 11.2 | 
2025-12-28T03:30:31 | step: 780900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.2123758753878064e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.16 | consumed tokens: 399820800.0 | grad norm avg: 11.98 | grad norm last: 11.02 | 
2025-12-28T03:30:33 | step: 781000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.211423088738229e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.83 | consumed tokens: 399872000.0 | grad norm avg: 11.7 | grad norm last: 9.91 | 
2025-12-28T03:30:35 | step: 781100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.2104706658865325e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.16 | consumed tokens: 399923200.0 | grad norm avg: 11.69 | grad norm last: 10.09 | 
2025-12-28T03:30:37 | step: 781200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.2095186068327166e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.2 | consumed tokens: 399974400.0 | grad norm avg: 11.63 | grad norm last: 9.48 | 
2025-12-28T03:30:39 | step: 781300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.2085669115767814e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.47 | consumed tokens: 400025600.0 | grad norm avg: 11.91 | grad norm last: 14.5 | 
2025-12-28T03:30:41 | step: 781400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.2076152163208462e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.03 | consumed tokens: 400076800.0 | grad norm avg: 11.57 | grad norm last: 11.15 | 
2025-12-28T03:30:43 | step: 781500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.2066642486606725e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.92 | consumed tokens: 400128000.0 | grad norm avg: 12.01 | grad norm last: 12.42 | 
2025-12-28T03:30:45 | step: 781600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 2.2057132810004987e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.66 | consumed tokens: 400179200.0 | grad norm avg: 12.0 | grad norm last: 10.54 | 
2025-12-28T03:30:47 | step: 781700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.204762859037146e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.12 | consumed tokens: 400230400.0 | grad norm avg: 11.88 | grad norm last: 12.11 | 
2025-12-28T03:30:49 | step: 781800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 2.2038126189727336e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.91 | consumed tokens: 400281600.0 | grad norm avg: 11.68 | grad norm last: 11.36 | 
2025-12-28T03:30:51 | step: 781900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.2028625608072616e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.44 | consumed tokens: 400332800.0 | grad norm avg: 11.79 | grad norm last: 10.69 | 
2025-12-28T03:30:53 | step: 782000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 2.2019134121364914e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.59 | consumed tokens: 400384000.0 | grad norm avg: 11.61 | grad norm last: 11.17 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_782000-seen_tokens_400384000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_782000-seen_tokens_400384000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_782000-seen_tokens_400384000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_782000-seen_tokens_400384000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_782000-seen_tokens_400384000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_782000-seen_tokens_400384000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_782000-seen_tokens_400384000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_782000-seen_tokens_400384000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:30:55 | step: 782100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.2009638996678405e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.54 | train loss last: 3.5 | consumed tokens: 400435200.0 | grad norm avg: 11.59 | grad norm last: 11.67 | 
2025-12-28T03:30:57 | step: 782200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.2000147509970702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.28 | consumed tokens: 400486400.0 | grad norm avg: 11.82 | grad norm last: 12.29 | 
2025-12-28T03:30:59 | step: 782300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.1990663299220614e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.7 | consumed tokens: 400537600.0 | grad norm avg: 11.6 | grad norm last: 11.67 | 
2025-12-28T03:31:01 | step: 782400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.1981182726449333e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.72 | consumed tokens: 400588800.0 | grad norm avg: 11.82 | grad norm last: 12.92 | 
2025-12-28T03:31:03 | step: 782500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.1971698515699245e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.81 | consumed tokens: 400640000.0 | grad norm avg: 11.43 | grad norm last: 12.54 | 
2025-12-28T03:31:05 | step: 782600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.1962223399896175e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.09 | consumed tokens: 400691200.0 | grad norm avg: 12.28 | grad norm last: 12.35 | 
2025-12-28T03:31:07 | step: 782700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.1952750103082508e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.36 | consumed tokens: 400742400.0 | grad norm avg: 12.07 | grad norm last: 11.17 | 
2025-12-28T03:31:09 | step: 782800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 2.1943278625258245e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.17 | consumed tokens: 400793600.0 | grad norm avg: 11.79 | grad norm last: 10.36 | 
2025-12-28T03:31:12 | step: 782900 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 2.1933812604402192e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.62 | consumed tokens: 400844800.0 | grad norm avg: 11.83 | grad norm last: 12.62 | 
2025-12-28T03:31:14 | step: 783000 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 2.192434658354614e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 2.72 | consumed tokens: 400896000.0 | grad norm avg: 11.77 | grad norm last: 9.6 | 
2025-12-28T03:31:16 | step: 783100 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.19148878386477e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.19 | consumed tokens: 400947200.0 | grad norm avg: 11.88 | grad norm last: 16.9 | 
2025-12-28T03:31:18 | step: 783200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.1905429093749262e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.53 | consumed tokens: 400998400.0 | grad norm avg: 11.96 | grad norm last: 11.67 | 
2025-12-28T03:31:20 | step: 783300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.1895975805819035e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.61 | consumed tokens: 401049600.0 | grad norm avg: 12.16 | grad norm last: 13.44 | 
2025-12-28T03:31:22 | step: 783400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.188652433687821e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.47 | consumed tokens: 401100800.0 | grad norm avg: 11.87 | grad norm last: 13.72 | 
2025-12-28T03:31:24 | step: 783500 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.1877078324905597e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.06 | consumed tokens: 401152000.0 | grad norm avg: 11.68 | grad norm last: 11.39 | 
2025-12-28T03:31:26 | step: 783600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.1867634131922387e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.36 | consumed tokens: 401203200.0 | grad norm avg: 11.69 | grad norm last: 10.71 | 
2025-12-28T03:31:28 | step: 783700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.1858189938939176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.97 | consumed tokens: 401254400.0 | grad norm avg: 11.7 | grad norm last: 11.96 | 
2025-12-28T03:31:30 | step: 783800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.1848749383934774e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.12 | consumed tokens: 401305600.0 | grad norm avg: 11.93 | grad norm last: 9.62 | 
2025-12-28T03:31:32 | step: 783900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.1839316104887985e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.25 | consumed tokens: 401356800.0 | grad norm avg: 11.66 | grad norm last: 10.71 | 
2025-12-28T03:31:34 | step: 784000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.1829886463820003e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.39 | consumed tokens: 401408000.0 | grad norm avg: 11.89 | grad norm last: 10.79 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_784000-seen_tokens_401408000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_784000-seen_tokens_401408000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_784000-seen_tokens_401408000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_784000-seen_tokens_401408000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_784000-seen_tokens_401408000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_784000-seen_tokens_401408000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_784000-seen_tokens_401408000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_784000-seen_tokens_401408000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:31:36 | step: 784100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.182045682275202e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.92 | consumed tokens: 401459200.0 | grad norm avg: 11.44 | grad norm last: 10.56 | 
2025-12-28T03:31:38 | step: 784200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.1811030819662847e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.16 | consumed tokens: 401510400.0 | grad norm avg: 12.16 | grad norm last: 11.41 | 
2025-12-28T03:31:40 | step: 784300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.1801606635563076e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.97 | consumed tokens: 401561600.0 | grad norm avg: 12.03 | grad norm last: 13.45 | 
2025-12-28T03:31:42 | step: 784400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.179218608944211e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.62 | consumed tokens: 401612800.0 | grad norm avg: 11.79 | grad norm last: 10.65 | 
2025-12-28T03:31:44 | step: 784500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.1782771000289358e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.08 | consumed tokens: 401664000.0 | grad norm avg: 12.12 | grad norm last: 11.8 | 
2025-12-28T03:31:46 | step: 784600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.1773359549115412e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.28 | consumed tokens: 401715200.0 | grad norm avg: 11.78 | grad norm last: 12.07 | 
2025-12-28T03:31:49 | step: 784700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.1763951735920273e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 2.95 | consumed tokens: 401766400.0 | grad norm avg: 11.67 | grad norm last: 10.24 | 
2025-12-28T03:31:51 | step: 784800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.1754540284746327e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.77 | consumed tokens: 401817600.0 | grad norm avg: 11.4 | grad norm last: 12.5 | 
2025-12-28T03:31:53 | step: 784900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.17451397475088e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.44 | consumed tokens: 401868800.0 | grad norm avg: 11.79 | grad norm last: 12.36 | 
2025-12-28T03:31:55 | step: 785000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.1735739210271277e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.53 | consumed tokens: 401920000.0 | grad norm avg: 11.89 | grad norm last: 10.92 | 
2025-12-28T03:31:57 | step: 785100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.172634231101256e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.0 | consumed tokens: 401971200.0 | grad norm avg: 12.03 | grad norm last: 13.15 | 
2025-12-28T03:31:59 | step: 785200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.1716949049732648e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.27 | consumed tokens: 402022400.0 | grad norm avg: 11.52 | grad norm last: 10.95 | 
2025-12-28T03:32:01 | step: 785300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.170755760744214e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.03 | consumed tokens: 402073600.0 | grad norm avg: 12.41 | grad norm last: 10.59 | 
2025-12-28T03:32:03 | step: 785400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.169816980313044e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.66 | consumed tokens: 402124800.0 | grad norm avg: 11.62 | grad norm last: 11.13 | 
2025-12-28T03:32:05 | step: 785500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.1688785636797547e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.11 | consumed tokens: 402176000.0 | grad norm avg: 12.24 | grad norm last: 10.88 | 
2025-12-28T03:32:07 | step: 785600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.167940510844346e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.06 | consumed tokens: 402227200.0 | grad norm avg: 12.16 | grad norm last: 10.42 | 
2025-12-28T03:32:09 | step: 785700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.1670028218068182e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.52 | consumed tokens: 402278400.0 | grad norm avg: 12.18 | grad norm last: 10.47 | 
2025-12-28T03:32:11 | step: 785800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.1660651327692904e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.61 | consumed tokens: 402329600.0 | grad norm avg: 11.94 | grad norm last: 11.05 | 
2025-12-28T03:32:13 | step: 785900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.1651279894285835e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.0 | consumed tokens: 402380800.0 | grad norm avg: 11.88 | grad norm last: 11.3 | 
2025-12-28T03:32:15 | step: 786000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.1641913917846978e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.33 | consumed tokens: 402432000.0 | grad norm avg: 11.79 | grad norm last: 11.52 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_786000-seen_tokens_402432000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_786000-seen_tokens_402432000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_786000-seen_tokens_402432000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_786000-seen_tokens_402432000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_786000-seen_tokens_402432000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_786000-seen_tokens_402432000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_786000-seen_tokens_402432000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_786000-seen_tokens_402432000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:32:17 | step: 786100 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 2.163254794140812e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.63 | train loss last: 3.98 | consumed tokens: 402483200.0 | grad norm avg: 11.74 | grad norm last: 12.05 | 
2025-12-28T03:32:19 | step: 786200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.1623187421937473e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.11 | consumed tokens: 402534400.0 | grad norm avg: 11.82 | grad norm last: 10.86 | 
2025-12-28T03:32:21 | step: 786300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.161382872145623e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.3 | consumed tokens: 402585600.0 | grad norm avg: 12.06 | grad norm last: 11.45 | 
2025-12-28T03:32:23 | step: 786400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.1604473658953793e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.12 | consumed tokens: 402636800.0 | grad norm avg: 12.17 | grad norm last: 11.02 | 
2025-12-28T03:32:25 | step: 786500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.159512041544076e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.59 | consumed tokens: 402688000.0 | grad norm avg: 11.88 | grad norm last: 11.05 | 
2025-12-28T03:32:27 | step: 786600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.158577262889594e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.58 | consumed tokens: 402739200.0 | grad norm avg: 11.94 | grad norm last: 11.14 | 
2025-12-28T03:32:29 | step: 786700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.1576424842351116e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.0 | consumed tokens: 402790400.0 | grad norm avg: 11.78 | grad norm last: 13.74 | 
2025-12-28T03:32:32 | step: 786800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.1567082512774505e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.31 | consumed tokens: 402841600.0 | grad norm avg: 11.65 | grad norm last: 11.16 | 
2025-12-28T03:32:34 | step: 786900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.15577438211767e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.62 | consumed tokens: 402892800.0 | grad norm avg: 12.05 | grad norm last: 10.75 | 
2025-12-28T03:32:36 | step: 787000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.1548408767557703e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.92 | consumed tokens: 402944000.0 | grad norm avg: 11.95 | grad norm last: 11.99 | 
2025-12-28T03:32:38 | step: 787100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.153907553292811e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.81 | consumed tokens: 402995200.0 | grad norm avg: 11.98 | grad norm last: 11.2 | 
2025-12-28T03:32:40 | step: 787200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.1529745936277322e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.75 | consumed tokens: 403046400.0 | grad norm avg: 11.76 | grad norm last: 12.14 | 
2025-12-28T03:32:42 | step: 787300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.1520419977605343e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.16 | consumed tokens: 403097600.0 | grad norm avg: 11.74 | grad norm last: 11.82 | 
2025-12-28T03:32:44 | step: 787400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.151109765691217e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.03 | consumed tokens: 403148800.0 | grad norm avg: 12.75 | grad norm last: 10.51 | 
2025-12-28T03:32:46 | step: 787500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.15017771552084e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.06 | consumed tokens: 403200000.0 | grad norm avg: 11.72 | grad norm last: 11.8 | 
2025-12-28T03:32:48 | step: 787600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.149246029148344e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.44 | consumed tokens: 403251200.0 | grad norm avg: 12.1 | grad norm last: 11.6 | 
2025-12-28T03:32:50 | step: 787700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.1483147065737285e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.59 | consumed tokens: 403302400.0 | grad norm avg: 11.71 | grad norm last: 11.73 | 
2025-12-28T03:32:52 | step: 787800 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.147383383999113e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.23 | consumed tokens: 403353600.0 | grad norm avg: 12.06 | grad norm last: 10.63 | 
2025-12-28T03:32:54 | step: 787900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.1464531528181396e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.44 | consumed tokens: 403404800.0 | grad norm avg: 11.79 | grad norm last: 9.8 | 
2025-12-28T03:32:56 | step: 788000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.1455225578392856e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.66 | consumed tokens: 403456000.0 | grad norm avg: 11.86 | grad norm last: 13.47 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_788000-seen_tokens_403456000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_788000-seen_tokens_403456000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_788000-seen_tokens_403456000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_788000-seen_tokens_403456000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_788000-seen_tokens_403456000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_788000-seen_tokens_403456000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_788000-seen_tokens_403456000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_788000-seen_tokens_403456000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:32:58 | step: 788100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.1445923266583122e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.66 | consumed tokens: 403507200.0 | grad norm avg: 11.7 | grad norm last: 11.56 | 
2025-12-28T03:33:00 | step: 788200 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 2.1436624592752196e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.69 | consumed tokens: 403558400.0 | grad norm avg: 12.04 | grad norm last: 12.42 | 
2025-12-28T03:33:02 | step: 788300 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 2.1427333194878884e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.27 | consumed tokens: 403609600.0 | grad norm avg: 11.64 | grad norm last: 10.91 | 
2025-12-28T03:33:04 | step: 788400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.141804179700557e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.58 | consumed tokens: 403660800.0 | grad norm avg: 12.02 | grad norm last: 10.59 | 
2025-12-28T03:33:06 | step: 788500 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 2.1408754037111066e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.42 | consumed tokens: 403712000.0 | grad norm avg: 12.04 | grad norm last: 12.99 | 
2025-12-28T03:33:08 | step: 788600 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 2.1399469915195368e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.72 | consumed tokens: 403763200.0 | grad norm avg: 12.16 | grad norm last: 10.34 | 
2025-12-28T03:33:11 | step: 788700 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 2.1390189431258477e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.59 | consumed tokens: 403814400.0 | grad norm avg: 12.12 | grad norm last: 12.1 | 
2025-12-28T03:33:13 | step: 788800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.138091076631099e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.67 | consumed tokens: 403865600.0 | grad norm avg: 11.92 | grad norm last: 11.62 | 
2025-12-28T03:33:15 | step: 788900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.137163573934231e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.06 | consumed tokens: 403916800.0 | grad norm avg: 11.82 | grad norm last: 10.07 | 
2025-12-28T03:33:17 | step: 789000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.1362364350352436e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.55 | consumed tokens: 403968000.0 | grad norm avg: 11.81 | grad norm last: 10.94 | 
2025-12-28T03:33:19 | step: 789100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.135309659934137e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.91 | consumed tokens: 404019200.0 | grad norm avg: 11.75 | grad norm last: 12.02 | 
2025-12-28T03:33:21 | step: 789200 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 2.1343830667319708e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.78 | consumed tokens: 404070400.0 | grad norm avg: 11.94 | grad norm last: 12.16 | 
2025-12-28T03:33:23 | step: 789300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.1334570192266256e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.52 | consumed tokens: 404121600.0 | grad norm avg: 11.78 | grad norm last: 11.01 | 
2025-12-28T03:33:25 | step: 789400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.132531335519161e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.55 | consumed tokens: 404172800.0 | grad norm avg: 12.14 | grad norm last: 11.4 | 
2025-12-28T03:33:27 | step: 789500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.131605833710637e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.92 | consumed tokens: 404224000.0 | grad norm avg: 11.76 | grad norm last: 11.1 | 
2025-12-28T03:33:29 | step: 789600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.1306803319021128e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.8 | consumed tokens: 404275200.0 | grad norm avg: 11.93 | grad norm last: 13.47 | 
2025-12-28T03:33:31 | step: 789700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.12975555768935e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.09 | consumed tokens: 404326400.0 | grad norm avg: 11.79 | grad norm last: 11.56 | 
2025-12-28T03:33:33 | step: 789800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.1288309653755277e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.47 | consumed tokens: 404377600.0 | grad norm avg: 11.7 | grad norm last: 10.68 | 
2025-12-28T03:33:35 | step: 789900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.127906736859586e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.03 | consumed tokens: 404428800.0 | grad norm avg: 11.9 | grad norm last: 12.92 | 
2025-12-28T03:33:37 | step: 790000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.1269826902425848e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.36 | consumed tokens: 404480000.0 | grad norm avg: 12.29 | grad norm last: 11.22 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_790000-seen_tokens_404480000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_790000-seen_tokens_404480000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_790000-seen_tokens_404480000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_790000-seen_tokens_404480000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_790000-seen_tokens_404480000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_790000-seen_tokens_404480000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_790000-seen_tokens_404480000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_790000-seen_tokens_404480000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:33:39 | step: 790100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.1260590074234642e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.44 | consumed tokens: 404531200.0 | grad norm avg: 11.77 | grad norm last: 13.29 | 
2025-12-28T03:33:41 | step: 790200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.125136052200105e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.89 | consumed tokens: 404582400.0 | grad norm avg: 11.88 | grad norm last: 10.4 | 
2025-12-28T03:33:43 | step: 790300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.1242129150778055e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 2.73 | consumed tokens: 404633600.0 | grad norm avg: 11.97 | grad norm last: 13.95 | 
2025-12-28T03:33:45 | step: 790400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.123290323652327e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 6.31 | consumed tokens: 404684800.0 | grad norm avg: 11.72 | grad norm last: 19.12 | 
2025-12-28T03:33:47 | step: 790500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.1223682779236697e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.14 | consumed tokens: 404736000.0 | grad norm avg: 11.93 | grad norm last: 9.87 | 
2025-12-28T03:33:49 | step: 790600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.121446050296072e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.94 | consumed tokens: 404787200.0 | grad norm avg: 11.75 | grad norm last: 9.75 | 
2025-12-28T03:33:51 | step: 790700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.1205245502642356e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 2.72 | consumed tokens: 404838400.0 | grad norm avg: 11.83 | grad norm last: 10.07 | 
2025-12-28T03:33:54 | step: 790800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.11960341403028e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 2.88 | consumed tokens: 404889600.0 | grad norm avg: 11.6 | grad norm last: 10.17 | 
2025-12-28T03:33:56 | step: 790900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.1186822777963243e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.78 | consumed tokens: 404940800.0 | grad norm avg: 11.88 | grad norm last: 12.85 | 
2025-12-28T03:33:58 | step: 791000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.1177615053602494e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.78 | consumed tokens: 404992000.0 | grad norm avg: 11.91 | grad norm last: 9.5 | 
2025-12-28T03:34:00 | step: 791100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.1168410967220552e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 4.09 | consumed tokens: 405043200.0 | grad norm avg: 11.66 | grad norm last: 13.6 | 
2025-12-28T03:34:02 | step: 791200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.1159210518817417e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.84 | consumed tokens: 405094400.0 | grad norm avg: 11.91 | grad norm last: 11.98 | 
2025-12-28T03:34:04 | step: 791300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.115001370839309e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.19 | consumed tokens: 405145600.0 | grad norm avg: 12.04 | grad norm last: 13.67 | 
2025-12-28T03:34:06 | step: 791400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.114082053594757e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.61 | consumed tokens: 405196800.0 | grad norm avg: 11.83 | grad norm last: 12.38 | 
2025-12-28T03:34:08 | step: 791500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.1131631001480855e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.55 | consumed tokens: 405248000.0 | grad norm avg: 12.09 | grad norm last: 11.8 | 
2025-12-28T03:34:10 | step: 791600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.112244510499295e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.03 | consumed tokens: 405299200.0 | grad norm avg: 12.2 | grad norm last: 13.01 | 
2025-12-28T03:34:12 | step: 791700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.1113259208505042e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.19 | consumed tokens: 405350400.0 | grad norm avg: 12.1 | grad norm last: 13.15 | 
2025-12-28T03:34:14 | step: 791800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.110408058797475e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 2.81 | consumed tokens: 405401600.0 | grad norm avg: 11.81 | grad norm last: 10.2 | 
2025-12-28T03:34:16 | step: 791900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.1094901967444457e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.84 | consumed tokens: 405452800.0 | grad norm avg: 12.34 | grad norm last: 12.81 | 
2025-12-28T03:34:18 | step: 792000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.1085726984892972e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.5 | consumed tokens: 405504000.0 | grad norm avg: 12.03 | grad norm last: 14.28 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_792000-seen_tokens_405504000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_792000-seen_tokens_405504000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_792000-seen_tokens_405504000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_792000-seen_tokens_405504000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_792000-seen_tokens_405504000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_792000-seen_tokens_405504000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_792000-seen_tokens_405504000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_792000-seen_tokens_405504000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:34:20 | step: 792100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.1076557459309697e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.56 | train loss last: 4.22 | consumed tokens: 405555200.0 | grad norm avg: 11.99 | grad norm last: 12.29 | 
2025-12-28T03:34:22 | step: 792200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.1067389752715826e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.56 | consumed tokens: 405606400.0 | grad norm avg: 12.51 | grad norm last: 10.53 | 
2025-12-28T03:34:24 | step: 792300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.1058227503090166e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.28 | consumed tokens: 405657600.0 | grad norm avg: 12.11 | grad norm last: 11.11 | 
2025-12-28T03:34:26 | step: 792400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.10490634344751e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.69 | consumed tokens: 405708800.0 | grad norm avg: 11.92 | grad norm last: 11.25 | 
2025-12-28T03:34:28 | step: 792500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.103990664181765e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.55 | consumed tokens: 405760000.0 | grad norm avg: 11.75 | grad norm last: 11.49 | 
2025-12-28T03:34:30 | step: 792600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.103075348713901e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.92 | consumed tokens: 405811200.0 | grad norm avg: 12.07 | grad norm last: 10.79 | 
2025-12-28T03:34:32 | step: 792700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.1021600332460366e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.16 | consumed tokens: 405862400.0 | grad norm avg: 12.15 | grad norm last: 10.7 | 
2025-12-28T03:34:34 | step: 792800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.101245081576053e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.5 | consumed tokens: 405913600.0 | grad norm avg: 12.42 | grad norm last: 12.37 | 
2025-12-28T03:34:36 | step: 792900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 2.100330857501831e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.77 | consumed tokens: 405964800.0 | grad norm avg: 12.12 | grad norm last: 11.27 | 
2025-12-28T03:34:38 | step: 793000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.0994166334276088e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.23 | consumed tokens: 406016000.0 | grad norm avg: 12.24 | grad norm last: 14.57 | 
2025-12-28T03:34:40 | step: 793100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.0985027731512673e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.55 | consumed tokens: 406067200.0 | grad norm avg: 12.15 | grad norm last: 12.59 | 
2025-12-28T03:34:42 | step: 793200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.0975892766728066e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.66 | consumed tokens: 406118400.0 | grad norm avg: 11.97 | grad norm last: 13.42 | 
2025-12-28T03:34:44 | step: 793300 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.0966761439922266e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.69 | consumed tokens: 406169600.0 | grad norm avg: 12.4 | grad norm last: 11.72 | 
2025-12-28T03:34:46 | step: 793400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 2.0957633751095273e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.98 | consumed tokens: 406220800.0 | grad norm avg: 12.24 | grad norm last: 13.8 | 
2025-12-28T03:34:49 | step: 793500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.0948507881257683e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.62 | consumed tokens: 406272000.0 | grad norm avg: 12.01 | grad norm last: 11.51 | 
2025-12-28T03:34:51 | step: 793600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.09393856493989e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.59 | consumed tokens: 406323200.0 | grad norm avg: 12.2 | grad norm last: 11.17 | 
2025-12-28T03:34:53 | step: 793700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.093026887450833e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 2.88 | consumed tokens: 406374400.0 | grad norm avg: 11.87 | grad norm last: 9.97 | 
2025-12-28T03:34:55 | step: 793800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.0921152099617757e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.12 | consumed tokens: 406425600.0 | grad norm avg: 12.22 | grad norm last: 10.95 | 
2025-12-28T03:34:57 | step: 793900 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 2.0912040781695396e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 5.75 | consumed tokens: 406476800.0 | grad norm avg: 12.16 | grad norm last: 18.48 | 
2025-12-28T03:34:59 | step: 794000 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.0902931282762438e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.84 | consumed tokens: 406528000.0 | grad norm avg: 12.25 | grad norm last: 11.88 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_794000-seen_tokens_406528000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_794000-seen_tokens_406528000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_794000-seen_tokens_406528000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_794000-seen_tokens_406528000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_794000-seen_tokens_406528000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_794000-seen_tokens_406528000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_794000-seen_tokens_406528000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_794000-seen_tokens_406528000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:35:01 | step: 794100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.089382724079769e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.69 | consumed tokens: 406579200.0 | grad norm avg: 11.88 | grad norm last: 11.49 | 
2025-12-28T03:35:03 | step: 794200 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 2.0884725017822348e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 4.06 | consumed tokens: 406630400.0 | grad norm avg: 12.23 | grad norm last: 13.05 | 
2025-12-28T03:35:05 | step: 794300 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 2.087562643282581e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.19 | consumed tokens: 406681600.0 | grad norm avg: 11.99 | grad norm last: 10.32 | 
2025-12-28T03:35:07 | step: 794400 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.086652966681868e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.66 | consumed tokens: 406732800.0 | grad norm avg: 12.57 | grad norm last: 11.72 | 
2025-12-28T03:35:09 | step: 794500 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.085744017676916e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.27 | consumed tokens: 406784000.0 | grad norm avg: 11.83 | grad norm last: 12.07 | 
2025-12-28T03:35:11 | step: 794600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.0848348867730238e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.72 | consumed tokens: 406835200.0 | grad norm avg: 11.74 | grad norm last: 11.66 | 
2025-12-28T03:35:13 | step: 794700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.083926483464893e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.14 | consumed tokens: 406886400.0 | grad norm avg: 11.87 | grad norm last: 10.59 | 
2025-12-28T03:35:15 | step: 794800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.083018080156762e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.73 | consumed tokens: 406937600.0 | grad norm avg: 12.13 | grad norm last: 12.18 | 
2025-12-28T03:35:17 | step: 794900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.0821104044443928e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.17 | consumed tokens: 406988800.0 | grad norm avg: 12.41 | grad norm last: 12.05 | 
2025-12-28T03:35:19 | step: 795000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.081202546833083e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.45 | consumed tokens: 407040000.0 | grad norm avg: 11.95 | grad norm last: 11.01 | 
2025-12-28T03:35:22 | step: 795100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.0802954168175347e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.09 | consumed tokens: 407091200.0 | grad norm avg: 12.34 | grad norm last: 12.35 | 
2025-12-28T03:35:24 | step: 795200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.0793884687009268e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.25 | consumed tokens: 407142400.0 | grad norm avg: 11.82 | grad norm last: 10.43 | 
2025-12-28T03:35:26 | step: 795300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.0784818843821995e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.34 | consumed tokens: 407193600.0 | grad norm avg: 12.09 | grad norm last: 10.65 | 
2025-12-28T03:35:28 | step: 795400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.0775754819624126e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.75 | consumed tokens: 407244800.0 | grad norm avg: 11.92 | grad norm last: 11.75 | 
2025-12-28T03:35:30 | step: 795500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.0766696252394468e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.67 | consumed tokens: 407296000.0 | grad norm avg: 11.72 | grad norm last: 11.2 | 
2025-12-28T03:35:32 | step: 795600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.0757639504154213e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.84 | consumed tokens: 407347200.0 | grad norm avg: 12.44 | grad norm last: 16.26 | 
2025-12-28T03:35:34 | step: 795700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.0748586393892765e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.42 | consumed tokens: 407398400.0 | grad norm avg: 12.05 | grad norm last: 11.2 | 
2025-12-28T03:35:36 | step: 795800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.0739536921610124e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.95 | consumed tokens: 407449600.0 | grad norm avg: 12.27 | grad norm last: 15.39 | 
2025-12-28T03:35:38 | step: 795900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.073049108730629e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.11 | consumed tokens: 407500800.0 | grad norm avg: 12.36 | grad norm last: 11.97 | 
2025-12-28T03:35:40 | step: 796000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.0721448890981264e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.59 | consumed tokens: 407552000.0 | grad norm avg: 11.95 | grad norm last: 11.56 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_796000-seen_tokens_407552000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_796000-seen_tokens_407552000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_796000-seen_tokens_407552000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_796000-seen_tokens_407552000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_796000-seen_tokens_407552000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_796000-seen_tokens_407552000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_796000-seen_tokens_407552000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_796000-seen_tokens_407552000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:35:42 | step: 796100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.071240851364564e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.55 | train loss last: 3.19 | consumed tokens: 407603200.0 | grad norm avg: 12.08 | grad norm last: 12.56 | 
2025-12-28T03:35:44 | step: 796200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.0703371774288826e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.91 | consumed tokens: 407654400.0 | grad norm avg: 12.25 | grad norm last: 13.08 | 
2025-12-28T03:35:46 | step: 796300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.0694338672910817e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.38 | consumed tokens: 407705600.0 | grad norm avg: 11.95 | grad norm last: 13.27 | 
2025-12-28T03:35:48 | step: 796400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.0685309209511615e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.59 | consumed tokens: 407756800.0 | grad norm avg: 11.99 | grad norm last: 11.5 | 
2025-12-28T03:35:50 | step: 796500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.067628338409122e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.53 | consumed tokens: 407808000.0 | grad norm avg: 12.6 | grad norm last: 11.53 | 
2025-12-28T03:35:52 | step: 796600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.0667261196649633e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.88 | consumed tokens: 407859200.0 | grad norm avg: 12.26 | grad norm last: 16.81 | 
2025-12-28T03:35:54 | step: 796700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.065824082819745e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.09 | consumed tokens: 407910400.0 | grad norm avg: 12.32 | grad norm last: 12.39 | 
2025-12-28T03:35:56 | step: 796800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.0649224097724073e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.82 | train loss last: 3.97 | consumed tokens: 407961600.0 | grad norm avg: 12.68 | grad norm last: 13.98 | 
2025-12-28T03:35:58 | step: 796900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.0640211005229503e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.5 | consumed tokens: 408012800.0 | grad norm avg: 11.95 | grad norm last: 15.34 | 
2025-12-28T03:36:00 | step: 797000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.063120155071374e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.84 | consumed tokens: 408064000.0 | grad norm avg: 11.92 | grad norm last: 18.38 | 
2025-12-28T03:36:02 | step: 797100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.062219391518738e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.47 | consumed tokens: 408115200.0 | grad norm avg: 12.0 | grad norm last: 11.55 | 
2025-12-28T03:36:04 | step: 797200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.061318991763983e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.17 | consumed tokens: 408166400.0 | grad norm avg: 12.13 | grad norm last: 10.74 | 
2025-12-28T03:36:06 | step: 797300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.060419319604989e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.61 | consumed tokens: 408217600.0 | grad norm avg: 11.9 | grad norm last: 12.83 | 
2025-12-28T03:36:08 | step: 797400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.059519465547055e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.16 | consumed tokens: 408268800.0 | grad norm avg: 12.04 | grad norm last: 12.89 | 
2025-12-28T03:36:10 | step: 797500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 2.0586199752870016e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.03 | consumed tokens: 408320000.0 | grad norm avg: 12.09 | grad norm last: 11.7 | 
2025-12-28T03:36:13 | step: 797600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.0577210307237692e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.72 | consumed tokens: 408371200.0 | grad norm avg: 12.69 | grad norm last: 26.5 | 
2025-12-28T03:36:15 | step: 797700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.0568224499584176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.47 | consumed tokens: 408422400.0 | grad norm avg: 12.21 | grad norm last: 11.11 | 
2025-12-28T03:36:17 | step: 797800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.0559242329909466e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.86 | consumed tokens: 408473600.0 | grad norm avg: 12.0 | grad norm last: 15.49 | 
2025-12-28T03:36:19 | step: 797900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.0550260160234757e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.03 | consumed tokens: 408524800.0 | grad norm avg: 12.39 | grad norm last: 10.94 | 
2025-12-28T03:36:21 | step: 798000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.054128526651766e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.16 | consumed tokens: 408576000.0 | grad norm avg: 12.18 | grad norm last: 12.06 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_798000-seen_tokens_408576000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_798000-seen_tokens_408576000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_798000-seen_tokens_408576000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_798000-seen_tokens_408576000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_798000-seen_tokens_408576000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_798000-seen_tokens_408576000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_798000-seen_tokens_408576000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_798000-seen_tokens_408576000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:36:23 | step: 798100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.0532310372800566e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.75 | train loss last: 3.2 | consumed tokens: 408627200.0 | grad norm avg: 12.44 | grad norm last: 10.04 | 
2025-12-28T03:36:25 | step: 798200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.0523339117062278e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.61 | consumed tokens: 408678400.0 | grad norm avg: 12.25 | grad norm last: 11.93 | 
2025-12-28T03:36:27 | step: 798300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 2.05143733182922e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.88 | consumed tokens: 408729600.0 | grad norm avg: 12.38 | grad norm last: 10.78 | 
2025-12-28T03:36:29 | step: 798400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.0505409338511527e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.03 | consumed tokens: 408780800.0 | grad norm avg: 12.08 | grad norm last: 10.56 | 
2025-12-28T03:36:31 | step: 798500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.0496450815699063e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.44 | consumed tokens: 408832000.0 | grad norm avg: 12.0 | grad norm last: 11.71 | 
2025-12-28T03:36:33 | step: 798600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.0487490473897196e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.17 | consumed tokens: 408883200.0 | grad norm avg: 12.44 | grad norm last: 10.66 | 
2025-12-28T03:36:35 | step: 798700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.0478537408052944e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.03 | consumed tokens: 408934400.0 | grad norm avg: 12.04 | grad norm last: 11.76 | 
2025-12-28T03:36:37 | step: 798800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.0469587980187498e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.34 | consumed tokens: 408985600.0 | grad norm avg: 12.67 | grad norm last: 13.52 | 
2025-12-28T03:36:39 | step: 798900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.0460640371311456e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.39 | consumed tokens: 409036800.0 | grad norm avg: 11.84 | grad norm last: 13.03 | 
2025-12-28T03:36:41 | step: 799000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.0451698219403625e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.84 | consumed tokens: 409088000.0 | grad norm avg: 12.23 | grad norm last: 13.21 | 
2025-12-28T03:36:43 | step: 799100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.0442757886485197e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.61 | consumed tokens: 409139200.0 | grad norm avg: 12.14 | grad norm last: 12.29 | 
2025-12-28T03:36:45 | step: 799200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.0433819372556172e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.31 | consumed tokens: 409190400.0 | grad norm avg: 12.06 | grad norm last: 10.82 | 
2025-12-28T03:36:47 | step: 799300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.042488631559536e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.2 | consumed tokens: 409241600.0 | grad norm avg: 12.15 | grad norm last: 11.97 | 
2025-12-28T03:36:49 | step: 799400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 2.0415956896613352e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.97 | consumed tokens: 409292800.0 | grad norm avg: 12.35 | grad norm last: 13.78 | 
2025-12-28T03:36:51 | step: 799500 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.040702929662075e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 2.78 | consumed tokens: 409344000.0 | grad norm avg: 12.68 | grad norm last: 10.99 | 
2025-12-28T03:36:53 | step: 799600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.0398105334606953e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.27 | consumed tokens: 409395200.0 | grad norm avg: 12.27 | grad norm last: 11.2 | 
2025-12-28T03:36:56 | step: 799700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.0389185010571964e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.66 | consumed tokens: 409446400.0 | grad norm avg: 12.19 | grad norm last: 11.88 | 
2025-12-28T03:36:58 | step: 799800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.0380268324515782e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.7 | consumed tokens: 409497600.0 | grad norm avg: 12.03 | grad norm last: 11.71 | 
2025-12-28T03:37:00 | step: 799900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.03713516384596e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.58 | consumed tokens: 409548800.0 | grad norm avg: 12.61 | grad norm last: 11.7 | 
2025-12-28T03:37:02 | step: 800000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.0362444047350436e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.5 | consumed tokens: 409600000.0 | grad norm avg: 12.44 | grad norm last: 11.84 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_800000-seen_tokens_409600000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_800000-seen_tokens_409600000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_800000-seen_tokens_409600000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_800000-seen_tokens_409600000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_800000-seen_tokens_409600000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_800000-seen_tokens_409600000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_800000-seen_tokens_409600000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_800000-seen_tokens_409600000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:37:04 | step: 800100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.0353536456241272e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 3.64 | consumed tokens: 409651200.0 | grad norm avg: 12.29 | grad norm last: 12.28 | 
2025-12-28T03:37:06 | step: 800200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 2.0344632503110915e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.88 | consumed tokens: 409702400.0 | grad norm avg: 12.16 | grad norm last: 12.35 | 
2025-12-28T03:37:08 | step: 800300 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 2.0335732187959366e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.02 | consumed tokens: 409753600.0 | grad norm avg: 12.4 | grad norm last: 10.47 | 
2025-12-28T03:37:10 | step: 800400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.0326835510786623e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.06 | consumed tokens: 409804800.0 | grad norm avg: 13.08 | grad norm last: 11.38 | 
2025-12-28T03:37:12 | step: 800500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 2.0317942471592687e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.53 | consumed tokens: 409856000.0 | grad norm avg: 12.52 | grad norm last: 13.14 | 
2025-12-28T03:37:14 | step: 800600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.0309051251388155e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.56 | consumed tokens: 409907200.0 | grad norm avg: 12.34 | grad norm last: 11.9 | 
2025-12-28T03:37:16 | step: 800700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.030016366916243e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.81 | consumed tokens: 409958400.0 | grad norm avg: 12.02 | grad norm last: 12.06 | 
2025-12-28T03:37:18 | step: 800800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.0291281543904915e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.09 | consumed tokens: 410009600.0 | grad norm avg: 12.4 | grad norm last: 11.36 | 
2025-12-28T03:37:20 | step: 800900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.02823994186474e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.8 | consumed tokens: 410060800.0 | grad norm avg: 12.15 | grad norm last: 11.5 | 
2025-12-28T03:37:22 | step: 801000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.0273522750358097e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.42 | consumed tokens: 410112000.0 | grad norm avg: 12.2 | grad norm last: 10.97 | 
2025-12-28T03:37:24 | step: 801100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.02646497200476e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.64 | consumed tokens: 410163200.0 | grad norm avg: 12.13 | grad norm last: 11.06 | 
2025-12-28T03:37:26 | step: 801200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.0255778508726507e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.5 | consumed tokens: 410214400.0 | grad norm avg: 12.71 | grad norm last: 13.79 | 
2025-12-28T03:37:28 | step: 801300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.0246912754373625e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.5 | consumed tokens: 410265600.0 | grad norm avg: 12.31 | grad norm last: 11.7 | 
2025-12-28T03:37:30 | step: 801400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.0238048819010146e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.47 | consumed tokens: 410316800.0 | grad norm avg: 12.04 | grad norm last: 11.71 | 
2025-12-28T03:37:32 | step: 801500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.0229188521625474e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.31 | consumed tokens: 410368000.0 | grad norm avg: 12.41 | grad norm last: 12.04 | 
2025-12-28T03:37:34 | step: 801600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 2.022033186221961e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.84 | consumed tokens: 410419200.0 | grad norm avg: 12.48 | grad norm last: 11.72 | 
2025-12-28T03:37:37 | step: 801700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 2.0211477021803148e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.62 | consumed tokens: 410470400.0 | grad norm avg: 11.95 | grad norm last: 11.56 | 
2025-12-28T03:37:39 | step: 801800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.0202627638354897e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.28 | consumed tokens: 410521600.0 | grad norm avg: 12.57 | grad norm last: 19.16 | 
2025-12-28T03:37:41 | step: 801900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.019378007389605e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.66 | consumed tokens: 410572800.0 | grad norm avg: 12.23 | grad norm last: 10.56 | 
2025-12-28T03:37:43 | step: 802000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.018493614741601e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.28 | consumed tokens: 410624000.0 | grad norm avg: 12.14 | grad norm last: 10.86 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_802000-seen_tokens_410624000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_802000-seen_tokens_410624000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_802000-seen_tokens_410624000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_802000-seen_tokens_410624000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_802000-seen_tokens_410624000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_802000-seen_tokens_410624000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_802000-seen_tokens_410624000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_802000-seen_tokens_410624000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:37:45 | step: 802100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.0176095858914778e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.69 | train loss last: 3.81 | consumed tokens: 410675200.0 | grad norm avg: 12.33 | grad norm last: 13.77 | 
2025-12-28T03:37:47 | step: 802200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.0167259208392352e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.92 | consumed tokens: 410726400.0 | grad norm avg: 12.19 | grad norm last: 11.11 | 
2025-12-28T03:37:49 | step: 802300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.0158426195848733e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.64 | consumed tokens: 410777600.0 | grad norm avg: 11.98 | grad norm last: 10.88 | 
2025-12-28T03:37:51 | step: 802400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.0149595002294518e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.25 | consumed tokens: 410828800.0 | grad norm avg: 12.44 | grad norm last: 11.16 | 
2025-12-28T03:37:53 | step: 802500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.0140769265708514e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.22 | consumed tokens: 410880000.0 | grad norm avg: 12.67 | grad norm last: 12.91 | 
2025-12-28T03:37:55 | step: 802600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.0131945348111913e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.36 | consumed tokens: 410931200.0 | grad norm avg: 12.12 | grad norm last: 11.86 | 
2025-12-28T03:37:57 | step: 802700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.012312506849412e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.05 | consumed tokens: 410982400.0 | grad norm avg: 12.51 | grad norm last: 10.79 | 
2025-12-28T03:37:59 | step: 802800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.0114308426855132e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.59 | consumed tokens: 411033600.0 | grad norm avg: 12.38 | grad norm last: 12.3 | 
2025-12-28T03:38:01 | step: 802900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 2.0105495423194952e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.64 | consumed tokens: 411084800.0 | grad norm avg: 12.14 | grad norm last: 12.04 | 
2025-12-28T03:38:03 | step: 803000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 2.0096684238524176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.77 | consumed tokens: 411136000.0 | grad norm avg: 12.21 | grad norm last: 12.05 | 
2025-12-28T03:38:05 | step: 803100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 2.008787851082161e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.33 | consumed tokens: 411187200.0 | grad norm avg: 12.36 | grad norm last: 11.94 | 
2025-12-28T03:38:07 | step: 803200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 2.007907460210845e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.12 | consumed tokens: 411238400.0 | grad norm avg: 12.16 | grad norm last: 12.09 | 
2025-12-28T03:38:09 | step: 803300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.0070274331374094e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.48 | consumed tokens: 411289600.0 | grad norm avg: 12.08 | grad norm last: 13.59 | 
2025-12-28T03:38:11 | step: 803400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.0061477698618546e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.22 | consumed tokens: 411340800.0 | grad norm avg: 12.19 | grad norm last: 13.28 | 
2025-12-28T03:38:13 | step: 803500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 2.0052684703841805e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.19 | consumed tokens: 411392000.0 | grad norm avg: 11.92 | grad norm last: 12.84 | 
2025-12-28T03:38:15 | step: 803600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 2.0043895347043872e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.05 | consumed tokens: 411443200.0 | grad norm avg: 12.17 | grad norm last: 10.74 | 
2025-12-28T03:38:17 | step: 803700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 2.0035107809235342e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.97 | consumed tokens: 411494400.0 | grad norm avg: 11.93 | grad norm last: 17.28 | 
2025-12-28T03:38:19 | step: 803800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.0026325728395022e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.92 | consumed tokens: 411545600.0 | grad norm avg: 12.02 | grad norm last: 13.29 | 
2025-12-28T03:38:21 | step: 803900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 2.0017545466544107e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.12 | consumed tokens: 411596800.0 | grad norm avg: 12.24 | grad norm last: 11.3 | 
2025-12-28T03:38:23 | step: 804000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 2.0008768842671998e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 2.36 | consumed tokens: 411648000.0 | grad norm avg: 12.11 | grad norm last: 9.32 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_804000-seen_tokens_411648000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_804000-seen_tokens_411648000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_804000-seen_tokens_411648000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_804000-seen_tokens_411648000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_804000-seen_tokens_411648000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_804000-seen_tokens_411648000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_804000-seen_tokens_411648000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_804000-seen_tokens_411648000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:38:26 | step: 804100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.9999995856778696e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.64 | train loss last: 3.42 | consumed tokens: 411699200.0 | grad norm avg: 12.11 | grad norm last: 11.96 | 
2025-12-28T03:38:28 | step: 804200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.99912265088642e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.78 | train loss last: 4.0 | consumed tokens: 411750400.0 | grad norm avg: 12.47 | grad norm last: 12.34 | 
2025-12-28T03:38:30 | step: 804300 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.998245897993911e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.09 | consumed tokens: 411801600.0 | grad norm avg: 12.3 | grad norm last: 13.68 | 
2025-12-28T03:38:32 | step: 804400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.997369690798223e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.8 | consumed tokens: 411852800.0 | grad norm avg: 12.1 | grad norm last: 11.23 | 
2025-12-28T03:38:34 | step: 804500 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.9964936655014753e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.39 | consumed tokens: 411904000.0 | grad norm avg: 12.28 | grad norm last: 10.5 | 
2025-12-28T03:38:36 | step: 804600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.9956180040026084e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.53 | consumed tokens: 411955200.0 | grad norm avg: 12.15 | grad norm last: 10.86 | 
2025-12-28T03:38:38 | step: 804700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.994742706301622e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.31 | consumed tokens: 412006400.0 | grad norm avg: 12.07 | grad norm last: 13.8 | 
2025-12-28T03:38:40 | step: 804800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.9938677723985165e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.72 | consumed tokens: 412057600.0 | grad norm avg: 12.03 | grad norm last: 11.49 | 
2025-12-28T03:38:42 | step: 804900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.9929932022932917e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.23 | consumed tokens: 412108800.0 | grad norm avg: 11.89 | grad norm last: 15.7 | 
2025-12-28T03:38:44 | step: 805000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.9921189959859475e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.86 | consumed tokens: 412160000.0 | grad norm avg: 11.96 | grad norm last: 12.67 | 
2025-12-28T03:38:46 | step: 805100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.9912449715775438e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.75 | consumed tokens: 412211200.0 | grad norm avg: 11.92 | grad norm last: 11.5 | 
2025-12-28T03:38:48 | step: 805200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.990371492865961e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.11 | consumed tokens: 412262400.0 | grad norm avg: 12.03 | grad norm last: 10.64 | 
2025-12-28T03:38:50 | step: 805300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.9894981960533187e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.3 | consumed tokens: 412313600.0 | grad norm avg: 12.48 | grad norm last: 11.11 | 
2025-12-28T03:38:52 | step: 805400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.988625263038557e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.88 | consumed tokens: 412364800.0 | grad norm avg: 12.12 | grad norm last: 11.46 | 
2025-12-28T03:38:55 | step: 805500 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.987752693821676e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.0 | consumed tokens: 412416000.0 | grad norm avg: 12.18 | grad norm last: 16.98 | 
2025-12-28T03:38:57 | step: 805600 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.9868803065037355e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.89 | consumed tokens: 412467200.0 | grad norm avg: 11.91 | grad norm last: 10.9 | 
2025-12-28T03:38:59 | step: 805700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.986008464882616e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.91 | consumed tokens: 412518400.0 | grad norm avg: 12.05 | grad norm last: 10.89 | 
2025-12-28T03:39:01 | step: 805800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.9851368051604368e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.8 | consumed tokens: 412569600.0 | grad norm avg: 11.95 | grad norm last: 11.41 | 
2025-12-28T03:39:03 | step: 805900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.9842656911350787e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.69 | consumed tokens: 412620800.0 | grad norm avg: 12.4 | grad norm last: 12.19 | 
2025-12-28T03:39:05 | step: 806000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.983394759008661e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.22 | consumed tokens: 412672000.0 | grad norm avg: 12.28 | grad norm last: 12.24 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_806000-seen_tokens_412672000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_806000-seen_tokens_412672000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_806000-seen_tokens_412672000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_806000-seen_tokens_412672000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_806000-seen_tokens_412672000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_806000-seen_tokens_412672000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_806000-seen_tokens_412672000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_806000-seen_tokens_412672000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:39:07 | step: 806100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.982524190680124e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.92 | consumed tokens: 412723200.0 | grad norm avg: 12.11 | grad norm last: 11.13 | 
2025-12-28T03:39:09 | step: 806200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.9816539861494675e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.45 | consumed tokens: 412774400.0 | grad norm avg: 12.03 | grad norm last: 12.53 | 
2025-12-28T03:39:11 | step: 806300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.980784145416692e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.41 | consumed tokens: 412825600.0 | grad norm avg: 12.03 | grad norm last: 11.96 | 
2025-12-28T03:39:13 | step: 806400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.9799144865828566e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.78 | consumed tokens: 412876800.0 | grad norm avg: 12.21 | grad norm last: 12.76 | 
2025-12-28T03:39:15 | step: 806500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.9790453734458424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.16 | consumed tokens: 412928000.0 | grad norm avg: 11.97 | grad norm last: 10.06 | 
2025-12-28T03:39:17 | step: 806600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.9781764422077686e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 2.88 | consumed tokens: 412979200.0 | grad norm avg: 12.18 | grad norm last: 9.98 | 
2025-12-28T03:39:19 | step: 806700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.9773078747675754e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.55 | consumed tokens: 413030400.0 | grad norm avg: 12.63 | grad norm last: 13.36 | 
2025-12-28T03:39:21 | step: 806800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.976439671125263e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.25 | consumed tokens: 413081600.0 | grad norm avg: 11.91 | grad norm last: 9.97 | 
2025-12-28T03:39:23 | step: 806900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.9755718312808312e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.97 | consumed tokens: 413132800.0 | grad norm avg: 12.4 | grad norm last: 14.54 | 
2025-12-28T03:39:25 | step: 807000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.9747043552342802e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.84 | consumed tokens: 413184000.0 | grad norm avg: 12.23 | grad norm last: 12.21 | 
2025-12-28T03:39:27 | step: 807100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.97383724298561e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.39 | consumed tokens: 413235200.0 | grad norm avg: 12.31 | grad norm last: 10.84 | 
2025-12-28T03:39:29 | step: 807200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.97297031263588e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.41 | consumed tokens: 413286400.0 | grad norm avg: 12.35 | grad norm last: 11.63 | 
2025-12-28T03:39:31 | step: 807300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.9721037460840307e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.3 | consumed tokens: 413337600.0 | grad norm avg: 11.94 | grad norm last: 11.08 | 
2025-12-28T03:39:33 | step: 807400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.9712377252290025e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 4.12 | consumed tokens: 413388800.0 | grad norm avg: 12.03 | grad norm last: 12.86 | 
2025-12-28T03:39:35 | step: 807500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.9703718862729147e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.22 | consumed tokens: 413440000.0 | grad norm avg: 12.06 | grad norm last: 13.77 | 
2025-12-28T03:39:37 | step: 807600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.9695064111147076e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.7 | consumed tokens: 413491200.0 | grad norm avg: 12.11 | grad norm last: 12.54 | 
2025-12-28T03:39:39 | step: 807700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.9686412997543812e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.64 | consumed tokens: 413542400.0 | grad norm avg: 12.02 | grad norm last: 11.0 | 
2025-12-28T03:39:42 | step: 807800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.967776370292995e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.72 | consumed tokens: 413593600.0 | grad norm avg: 12.36 | grad norm last: 11.7 | 
2025-12-28T03:39:44 | step: 807900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.96691198652843e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.88 | consumed tokens: 413644800.0 | grad norm avg: 12.16 | grad norm last: 10.34 | 
2025-12-28T03:39:46 | step: 808000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.9660477846628055e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.41 | consumed tokens: 413696000.0 | grad norm avg: 12.23 | grad norm last: 10.93 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_808000-seen_tokens_413696000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_808000-seen_tokens_413696000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_808000-seen_tokens_413696000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_808000-seen_tokens_413696000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_808000-seen_tokens_413696000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_808000-seen_tokens_413696000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_808000-seen_tokens_413696000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_808000-seen_tokens_413696000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:39:48 | step: 808100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.965184128494002e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.22 | consumed tokens: 413747200.0 | grad norm avg: 12.16 | grad norm last: 12.7 | 
2025-12-28T03:39:50 | step: 808200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.9643206542241387e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.22 | consumed tokens: 413798400.0 | grad norm avg: 11.97 | grad norm last: 10.51 | 
2025-12-28T03:39:52 | step: 808300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.9634575437521562e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.31 | consumed tokens: 413849600.0 | grad norm avg: 12.19 | grad norm last: 10.39 | 
2025-12-28T03:39:54 | step: 808400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.9625947970780544e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.09 | consumed tokens: 413900800.0 | grad norm avg: 12.33 | grad norm last: 10.47 | 
2025-12-28T03:39:56 | step: 808500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.9617324142018333e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.31 | consumed tokens: 413952000.0 | grad norm avg: 12.0 | grad norm last: 12.26 | 
2025-12-28T03:39:58 | step: 808600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.9608702132245526e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.2 | consumed tokens: 414003200.0 | grad norm avg: 12.41 | grad norm last: 10.39 | 
2025-12-28T03:40:00 | step: 808700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.960008557944093e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.44 | consumed tokens: 414054400.0 | grad norm avg: 11.77 | grad norm last: 9.89 | 
2025-12-28T03:40:02 | step: 808800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.9591470845625736e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.88 | consumed tokens: 414105600.0 | grad norm avg: 12.2 | grad norm last: 13.89 | 
2025-12-28T03:40:04 | step: 808900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.958285974978935e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 2.97 | consumed tokens: 414156800.0 | grad norm avg: 12.26 | grad norm last: 11.1 | 
2025-12-28T03:40:06 | step: 809000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.9574254110921174e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.77 | consumed tokens: 414208000.0 | grad norm avg: 12.48 | grad norm last: 11.71 | 
2025-12-28T03:40:08 | step: 809100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.9565650291042402e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.06 | consumed tokens: 414259200.0 | grad norm avg: 12.29 | grad norm last: 10.65 | 
2025-12-28T03:40:10 | step: 809200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.9557050109142438e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.28 | consumed tokens: 414310400.0 | grad norm avg: 12.38 | grad norm last: 10.31 | 
2025-12-28T03:40:12 | step: 809300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.9548451746231876e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.08 | consumed tokens: 414361600.0 | grad norm avg: 11.74 | grad norm last: 10.8 | 
2025-12-28T03:40:14 | step: 809400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.9539858840289526e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.06 | consumed tokens: 414412800.0 | grad norm avg: 11.9 | grad norm last: 10.33 | 
2025-12-28T03:40:16 | step: 809500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.953126775333658e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.84 | consumed tokens: 414464000.0 | grad norm avg: 12.36 | grad norm last: 11.67 | 
2025-12-28T03:40:18 | step: 809600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.9522682123351842e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.25 | consumed tokens: 414515200.0 | grad norm avg: 12.11 | grad norm last: 11.62 | 
2025-12-28T03:40:20 | step: 809700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.951409831235651e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.41 | consumed tokens: 414566400.0 | grad norm avg: 12.05 | grad norm last: 13.73 | 
2025-12-28T03:40:22 | step: 809800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.9505518139339983e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.83 | consumed tokens: 414617600.0 | grad norm avg: 12.08 | grad norm last: 12.23 | 
2025-12-28T03:40:24 | step: 809900 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.9496941604302265e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.38 | consumed tokens: 414668800.0 | grad norm avg: 11.83 | grad norm last: 13.83 | 
2025-12-28T03:40:26 | step: 810000 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.9488368707243353e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.86 | consumed tokens: 414720000.0 | grad norm avg: 11.89 | grad norm last: 10.4 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_810000-seen_tokens_414720000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_810000-seen_tokens_414720000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_810000-seen_tokens_414720000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_810000-seen_tokens_414720000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_810000-seen_tokens_414720000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_810000-seen_tokens_414720000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_810000-seen_tokens_414720000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_810000-seen_tokens_414720000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:40:29 | step: 810100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.947979944816325e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.66 | train loss last: 3.88 | consumed tokens: 414771200.0 | grad norm avg: 11.97 | grad norm last: 12.12 | 
2025-12-28T03:40:31 | step: 810200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.947123382706195e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.02 | consumed tokens: 414822400.0 | grad norm avg: 12.23 | grad norm last: 12.18 | 
2025-12-28T03:40:33 | step: 810300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.9462670024950057e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.44 | consumed tokens: 414873600.0 | grad norm avg: 12.06 | grad norm last: 10.22 | 
2025-12-28T03:40:35 | step: 810400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.9454111679806374e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.47 | consumed tokens: 414924800.0 | grad norm avg: 11.9 | grad norm last: 11.1 | 
2025-12-28T03:40:37 | step: 810500 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.9445555153652094e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.19 | consumed tokens: 414976000.0 | grad norm avg: 12.03 | grad norm last: 12.94 | 
2025-12-28T03:40:39 | step: 810600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.943700226547662e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.47 | consumed tokens: 415027200.0 | grad norm avg: 12.22 | grad norm last: 12.23 | 
2025-12-28T03:40:41 | step: 810700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.9428453015279956e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.39 | consumed tokens: 415078400.0 | grad norm avg: 12.1 | grad norm last: 11.7 | 
2025-12-28T03:40:43 | step: 810800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.9419907403062098e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.59 | consumed tokens: 415129600.0 | grad norm avg: 12.19 | grad norm last: 11.68 | 
2025-12-28T03:40:45 | step: 810900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.9411365428823046e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.06 | consumed tokens: 415180800.0 | grad norm avg: 12.01 | grad norm last: 11.51 | 
2025-12-28T03:40:47 | step: 811000 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.9402827092562802e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.52 | consumed tokens: 415232000.0 | grad norm avg: 12.14 | grad norm last: 11.83 | 
2025-12-28T03:40:49 | step: 811100 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.939429057529196e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.53 | consumed tokens: 415283200.0 | grad norm avg: 11.91 | grad norm last: 11.96 | 
2025-12-28T03:40:51 | step: 811200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.938575951498933e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.47 | consumed tokens: 415334400.0 | grad norm avg: 12.35 | grad norm last: 11.88 | 
2025-12-28T03:40:53 | step: 811300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.9377230273676105e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 2.89 | consumed tokens: 415385600.0 | grad norm avg: 12.03 | grad norm last: 10.49 | 
2025-12-28T03:40:55 | step: 811400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.9368704670341685e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.02 | consumed tokens: 415436800.0 | grad norm avg: 12.06 | grad norm last: 10.69 | 
2025-12-28T03:40:57 | step: 811500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.9360182704986073e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.64 | consumed tokens: 415488000.0 | grad norm avg: 12.33 | grad norm last: 12.8 | 
2025-12-28T03:40:59 | step: 811600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.9351664377609268e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.11 | consumed tokens: 415539200.0 | grad norm avg: 12.28 | grad norm last: 11.44 | 
2025-12-28T03:41:01 | step: 811700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.934314968821127e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.42 | consumed tokens: 415590400.0 | grad norm avg: 12.09 | grad norm last: 11.18 | 
2025-12-28T03:41:04 | step: 811800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.933463863679208e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.03 | consumed tokens: 415641600.0 | grad norm avg: 12.35 | grad norm last: 11.9 | 
2025-12-28T03:41:06 | step: 811900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.9326131223351695e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.61 | consumed tokens: 415692800.0 | grad norm avg: 12.37 | grad norm last: 11.27 | 
2025-12-28T03:41:08 | step: 812000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.9317625628900714e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.66 | consumed tokens: 415744000.0 | grad norm avg: 12.24 | grad norm last: 12.27 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_812000-seen_tokens_415744000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_812000-seen_tokens_415744000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_812000-seen_tokens_415744000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_812000-seen_tokens_415744000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_812000-seen_tokens_415744000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_812000-seen_tokens_415744000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_812000-seen_tokens_415744000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_812000-seen_tokens_415744000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:41:10 | step: 812100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.930912367242854e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.62 | train loss last: 3.31 | consumed tokens: 415795200.0 | grad norm avg: 12.16 | grad norm last: 12.85 | 
2025-12-28T03:41:12 | step: 812200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.9300627172924578e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.0 | consumed tokens: 415846400.0 | grad norm avg: 12.11 | grad norm last: 10.42 | 
2025-12-28T03:41:14 | step: 812300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.929213249241002e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.5 | consumed tokens: 415897600.0 | grad norm avg: 12.06 | grad norm last: 11.06 | 
2025-12-28T03:41:16 | step: 812400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.9283641449874267e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.67 | consumed tokens: 415948800.0 | grad norm avg: 12.45 | grad norm last: 12.76 | 
2025-12-28T03:41:18 | step: 812500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.9275154045317322e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.34 | consumed tokens: 416000000.0 | grad norm avg: 12.09 | grad norm last: 11.65 | 
2025-12-28T03:41:20 | step: 812600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.9266670278739184e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 2.52 | consumed tokens: 416051200.0 | grad norm avg: 11.81 | grad norm last: 10.63 | 
2025-12-28T03:41:22 | step: 812700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.9258190150139853e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 2.91 | consumed tokens: 416102400.0 | grad norm avg: 12.42 | grad norm last: 9.94 | 
2025-12-28T03:41:24 | step: 812800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.9249711840529926e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.31 | consumed tokens: 416153600.0 | grad norm avg: 12.48 | grad norm last: 13.38 | 
2025-12-28T03:41:26 | step: 812900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.924123898788821e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.41 | consumed tokens: 416204800.0 | grad norm avg: 12.85 | grad norm last: 12.52 | 
2025-12-28T03:41:28 | step: 813000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.9232767954235896e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.69 | consumed tokens: 416256000.0 | grad norm avg: 12.53 | grad norm last: 11.16 | 
2025-12-28T03:41:30 | step: 813100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.9224302377551794e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.03 | consumed tokens: 416307200.0 | grad norm avg: 12.13 | grad norm last: 11.78 | 
2025-12-28T03:41:32 | step: 813200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.9215838619857095e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 2.91 | consumed tokens: 416358400.0 | grad norm avg: 12.13 | grad norm last: 11.13 | 
2025-12-28T03:41:34 | step: 813300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.9207378500141203e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.95 | consumed tokens: 416409600.0 | grad norm avg: 12.41 | grad norm last: 12.26 | 
2025-12-28T03:41:36 | step: 813400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.919892201840412e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.31 | consumed tokens: 416460800.0 | grad norm avg: 12.09 | grad norm last: 11.89 | 
2025-12-28T03:41:38 | step: 813500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.919046917464584e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.78 | consumed tokens: 416512000.0 | grad norm avg: 12.32 | grad norm last: 11.89 | 
2025-12-28T03:41:40 | step: 813600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.918201996886637e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.11 | consumed tokens: 416563200.0 | grad norm avg: 12.0 | grad norm last: 11.03 | 
2025-12-28T03:41:42 | step: 813700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.9173572582076304e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.0 | consumed tokens: 416614400.0 | grad norm avg: 12.09 | grad norm last: 12.66 | 
2025-12-28T03:41:44 | step: 813800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.9165130652254447e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.12 | consumed tokens: 416665600.0 | grad norm avg: 12.28 | grad norm last: 14.1 | 
2025-12-28T03:41:46 | step: 813900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.9156690541421995e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.91 | consumed tokens: 416716800.0 | grad norm avg: 12.59 | grad norm last: 12.72 | 
2025-12-28T03:41:48 | step: 814000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.9148255887557752e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.0 | consumed tokens: 416768000.0 | grad norm avg: 12.17 | grad norm last: 10.51 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_814000-seen_tokens_416768000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_814000-seen_tokens_416768000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_814000-seen_tokens_416768000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_814000-seen_tokens_416768000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_814000-seen_tokens_416768000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_814000-seen_tokens_416768000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_814000-seen_tokens_416768000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_814000-seen_tokens_416768000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:41:51 | step: 814100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.9139823052682914e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.69 | train loss last: 4.28 | consumed tokens: 416819200.0 | grad norm avg: 12.25 | grad norm last: 12.07 | 
2025-12-28T03:41:53 | step: 814200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.9131393855786882e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.55 | train loss last: 3.53 | consumed tokens: 416870400.0 | grad norm avg: 11.95 | grad norm last: 10.7 | 
2025-12-28T03:41:55 | step: 814300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.9122968296869658e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.3 | consumed tokens: 416921600.0 | grad norm avg: 12.13 | grad norm last: 10.67 | 
2025-12-28T03:41:57 | step: 814400 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 1.911454637593124e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 2.64 | consumed tokens: 416972800.0 | grad norm avg: 11.8 | grad norm last: 12.22 | 
2025-12-28T03:41:59 | step: 814500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.910612809297163e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.83 | consumed tokens: 417024000.0 | grad norm avg: 12.12 | grad norm last: 11.39 | 
2025-12-28T03:42:01 | step: 814600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.9097711629001424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.64 | consumed tokens: 417075200.0 | grad norm avg: 12.22 | grad norm last: 16.45 | 
2025-12-28T03:42:03 | step: 814700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.9089300621999428e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.28 | consumed tokens: 417126400.0 | grad norm avg: 12.07 | grad norm last: 11.94 | 
2025-12-28T03:42:05 | step: 814800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.908089325297624e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.28 | consumed tokens: 417177600.0 | grad norm avg: 12.28 | grad norm last: 10.47 | 
2025-12-28T03:42:07 | step: 814900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.9072487702942453e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.72 | consumed tokens: 417228800.0 | grad norm avg: 12.47 | grad norm last: 11.81 | 
2025-12-28T03:42:09 | step: 815000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.9064085790887475e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.59 | consumed tokens: 417280000.0 | grad norm avg: 12.26 | grad norm last: 13.21 | 
2025-12-28T03:42:11 | step: 815100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.9055689335800707e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.06 | consumed tokens: 417331200.0 | grad norm avg: 12.2 | grad norm last: 10.93 | 
2025-12-28T03:42:13 | step: 815200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.9047294699703343e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.77 | consumed tokens: 417382400.0 | grad norm avg: 12.2 | grad norm last: 12.47 | 
2025-12-28T03:42:15 | step: 815300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.9038903701584786e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.3 | consumed tokens: 417433600.0 | grad norm avg: 12.3 | grad norm last: 11.98 | 
2025-12-28T03:42:17 | step: 815400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.9030516341445036e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.14 | consumed tokens: 417484800.0 | grad norm avg: 12.46 | grad norm last: 12.2 | 
2025-12-28T03:42:19 | step: 815500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.9022132619284093e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.58 | consumed tokens: 417536000.0 | grad norm avg: 12.31 | grad norm last: 11.18 | 
2025-12-28T03:42:21 | step: 815600 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.9013750716112554e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.94 | consumed tokens: 417587200.0 | grad norm avg: 12.16 | grad norm last: 12.22 | 
2025-12-28T03:42:23 | step: 815700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.9005374269909225e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.41 | consumed tokens: 417638400.0 | grad norm avg: 12.21 | grad norm last: 10.75 | 
2025-12-28T03:42:25 | step: 815800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.89969996426953e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.09 | consumed tokens: 417689600.0 | grad norm avg: 12.26 | grad norm last: 11.39 | 
2025-12-28T03:42:27 | step: 815900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.8988630472449586e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.16 | consumed tokens: 417740800.0 | grad norm avg: 12.24 | grad norm last: 14.43 | 
2025-12-28T03:42:29 | step: 816000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.8980263121193275e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.81 | consumed tokens: 417792000.0 | grad norm avg: 11.93 | grad norm last: 11.81 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_816000-seen_tokens_417792000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_816000-seen_tokens_417792000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_816000-seen_tokens_417792000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_816000-seen_tokens_417792000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_816000-seen_tokens_417792000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_816000-seen_tokens_417792000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_816000-seen_tokens_417792000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_816000-seen_tokens_417792000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:42:32 | step: 816100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.8971901226905175e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.63 | train loss last: 3.89 | consumed tokens: 417843200.0 | grad norm avg: 11.97 | grad norm last: 11.7 | 
2025-12-28T03:42:34 | step: 816200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.8963541151606478e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.64 | consumed tokens: 417894400.0 | grad norm avg: 12.17 | grad norm last: 11.31 | 
2025-12-28T03:42:36 | step: 816300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.8955184714286588e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.3 | consumed tokens: 417945600.0 | grad norm avg: 11.87 | grad norm last: 10.85 | 
2025-12-28T03:42:38 | step: 816400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.8946831914945506e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.38 | consumed tokens: 417996800.0 | grad norm avg: 12.5 | grad norm last: 13.75 | 
2025-12-28T03:42:40 | step: 816500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.893848275358323e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.92 | consumed tokens: 418048000.0 | grad norm avg: 12.85 | grad norm last: 12.31 | 
2025-12-28T03:42:42 | step: 816600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.8930135411210358e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.36 | consumed tokens: 418099200.0 | grad norm avg: 12.37 | grad norm last: 10.86 | 
2025-12-28T03:42:44 | step: 816700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.8921793525805697e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.42 | consumed tokens: 418150400.0 | grad norm avg: 12.21 | grad norm last: 11.92 | 
2025-12-28T03:42:46 | step: 816800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.8913455278379843e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.34 | consumed tokens: 418201600.0 | grad norm avg: 12.13 | grad norm last: 11.32 | 
2025-12-28T03:42:48 | step: 816900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.8905118849943392e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.27 | consumed tokens: 418252800.0 | grad norm avg: 12.17 | grad norm last: 12.53 | 
2025-12-28T03:42:50 | step: 817000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.8896787878475152e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.45 | consumed tokens: 418304000.0 | grad norm avg: 12.42 | grad norm last: 11.13 | 
2025-12-28T03:42:52 | step: 817100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.8888458725996315e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.98 | consumed tokens: 418355200.0 | grad norm avg: 12.29 | grad norm last: 14.15 | 
2025-12-28T03:42:54 | step: 817200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.8880133211496286e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.77 | train loss last: 4.19 | consumed tokens: 418406400.0 | grad norm avg: 12.45 | grad norm last: 12.44 | 
2025-12-28T03:42:56 | step: 817300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.8871811334975064e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.91 | consumed tokens: 418457600.0 | grad norm avg: 12.31 | grad norm last: 12.22 | 
2025-12-28T03:42:58 | step: 817400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.886349309643265e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.44 | consumed tokens: 418508800.0 | grad norm avg: 12.31 | grad norm last: 12.72 | 
2025-12-28T03:43:00 | step: 817500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.885517849586904e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.25 | consumed tokens: 418560000.0 | grad norm avg: 12.0 | grad norm last: 10.39 | 
2025-12-28T03:43:02 | step: 817600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.884686753328424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.36 | consumed tokens: 418611200.0 | grad norm avg: 12.2 | grad norm last: 11.64 | 
2025-12-28T03:43:04 | step: 817700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.8838560208678246e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.7 | consumed tokens: 418662400.0 | grad norm avg: 12.17 | grad norm last: 11.66 | 
2025-12-28T03:43:06 | step: 817800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.883025652205106e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.22 | consumed tokens: 418713600.0 | grad norm avg: 12.48 | grad norm last: 12.35 | 
2025-12-28T03:43:08 | step: 817900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.8821954654413275e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.97 | consumed tokens: 418764800.0 | grad norm avg: 12.22 | grad norm last: 17.51 | 
2025-12-28T03:43:10 | step: 818000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.8813658243743703e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.61 | consumed tokens: 418816000.0 | grad norm avg: 12.3 | grad norm last: 10.59 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_818000-seen_tokens_418816000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_818000-seen_tokens_418816000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_818000-seen_tokens_418816000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_818000-seen_tokens_418816000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_818000-seen_tokens_418816000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_818000-seen_tokens_418816000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_818000-seen_tokens_418816000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_818000-seen_tokens_418816000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:43:13 | step: 818100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.8805363652063534e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 2.83 | consumed tokens: 418867200.0 | grad norm avg: 12.58 | grad norm last: 10.47 | 
2025-12-28T03:43:15 | step: 818200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.8797074517351575e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.77 | consumed tokens: 418918400.0 | grad norm avg: 12.13 | grad norm last: 18.68 | 
2025-12-28T03:43:17 | step: 818300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.878878720162902e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.5 | consumed tokens: 418969600.0 | grad norm avg: 12.12 | grad norm last: 11.17 | 
2025-12-28T03:43:19 | step: 818400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.8780503523885272e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.94 | consumed tokens: 419020800.0 | grad norm avg: 12.2 | grad norm last: 11.09 | 
2025-12-28T03:43:21 | step: 818500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.8772223484120332e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.55 | consumed tokens: 419072000.0 | grad norm avg: 12.22 | grad norm last: 14.71 | 
2025-12-28T03:43:23 | step: 818600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.8763947082334198e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.52 | consumed tokens: 419123200.0 | grad norm avg: 12.27 | grad norm last: 10.82 | 
2025-12-28T03:43:25 | step: 818700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.875567431852687e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.08 | consumed tokens: 419174400.0 | grad norm avg: 12.39 | grad norm last: 10.74 | 
2025-12-28T03:43:27 | step: 818800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.8747405192698352e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.41 | consumed tokens: 419225600.0 | grad norm avg: 12.3 | grad norm last: 10.95 | 
2025-12-28T03:43:29 | step: 818900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.873913970484864e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.38 | consumed tokens: 419276800.0 | grad norm avg: 12.32 | grad norm last: 10.69 | 
2025-12-28T03:43:31 | step: 819000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.873087603598833e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.39 | consumed tokens: 419328000.0 | grad norm avg: 12.45 | grad norm last: 10.44 | 
2025-12-28T03:43:33 | step: 819100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.8722617824096233e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.19 | consumed tokens: 419379200.0 | grad norm avg: 12.45 | grad norm last: 13.4 | 
2025-12-28T03:43:35 | step: 819200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.8714361431193538e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.55 | consumed tokens: 419430400.0 | grad norm avg: 11.84 | grad norm last: 12.89 | 
2025-12-28T03:43:37 | step: 819300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.8706110495259054e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.27 | consumed tokens: 419481600.0 | grad norm avg: 12.73 | grad norm last: 12.46 | 
2025-12-28T03:43:39 | step: 819400 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.8697861378313974e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.3 | consumed tokens: 419532800.0 | grad norm avg: 12.83 | grad norm last: 11.2 | 
2025-12-28T03:43:41 | step: 819500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.86896158993477e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.75 | consumed tokens: 419584000.0 | grad norm avg: 12.12 | grad norm last: 11.46 | 
2025-12-28T03:43:43 | step: 819600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.8681375877349637e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.88 | consumed tokens: 419635200.0 | grad norm avg: 12.16 | grad norm last: 14.42 | 
2025-12-28T03:43:45 | step: 819700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.8673137674340978e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.83 | consumed tokens: 419686400.0 | grad norm avg: 11.78 | grad norm last: 12.25 | 
2025-12-28T03:43:47 | step: 819800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.8664903109311126e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.05 | consumed tokens: 419737600.0 | grad norm avg: 12.02 | grad norm last: 10.95 | 
2025-12-28T03:43:49 | step: 819900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.865667218226008e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.55 | consumed tokens: 419788800.0 | grad norm avg: 12.18 | grad norm last: 10.98 | 
2025-12-28T03:43:51 | step: 820000 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.8648444893187843e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.06 | consumed tokens: 419840000.0 | grad norm avg: 12.59 | grad norm last: 12.48 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_820000-seen_tokens_419840000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_820000-seen_tokens_419840000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_820000-seen_tokens_419840000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_820000-seen_tokens_419840000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_820000-seen_tokens_419840000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_820000-seen_tokens_419840000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_820000-seen_tokens_419840000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_820000-seen_tokens_419840000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:43:54 | step: 820100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.864021942310501e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.53 | train loss last: 3.27 | consumed tokens: 419891200.0 | grad norm avg: 12.02 | grad norm last: 10.37 | 
2025-12-28T03:43:56 | step: 820200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.8631999409990385e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.66 | consumed tokens: 419942400.0 | grad norm avg: 12.13 | grad norm last: 14.54 | 
2025-12-28T03:43:58 | step: 820300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.862378303485457e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 4.06 | consumed tokens: 419993600.0 | grad norm avg: 12.32 | grad norm last: 13.03 | 
2025-12-28T03:44:00 | step: 820400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.8615568478708155e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.62 | consumed tokens: 420044800.0 | grad norm avg: 12.29 | grad norm last: 11.4 | 
2025-12-28T03:44:02 | step: 820500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.8607359379529953e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.83 | consumed tokens: 420096000.0 | grad norm avg: 11.99 | grad norm last: 11.5 | 
2025-12-28T03:44:04 | step: 820600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.8599152099341154e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.0 | consumed tokens: 420147200.0 | grad norm avg: 12.16 | grad norm last: 11.39 | 
2025-12-28T03:44:06 | step: 820700 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.8590948457131162e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.59 | consumed tokens: 420198400.0 | grad norm avg: 12.33 | grad norm last: 10.91 | 
2025-12-28T03:44:08 | step: 820800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.858275027188938e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.33 | consumed tokens: 420249600.0 | grad norm avg: 12.27 | grad norm last: 12.8 | 
2025-12-28T03:44:10 | step: 820900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.8574553905637003e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.56 | consumed tokens: 420300800.0 | grad norm avg: 12.6 | grad norm last: 14.76 | 
2025-12-28T03:44:12 | step: 821000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.8566361177363433e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.31 | consumed tokens: 420352000.0 | grad norm avg: 12.25 | grad norm last: 12.14 | 
2025-12-28T03:44:14 | step: 821100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.855817208706867e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.31 | consumed tokens: 420403200.0 | grad norm avg: 12.09 | grad norm last: 11.4 | 
2025-12-28T03:44:16 | step: 821200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.8549986634752713e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.7 | consumed tokens: 420454400.0 | grad norm avg: 12.9 | grad norm last: 13.93 | 
2025-12-28T03:44:18 | step: 821300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.8541804820415564e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.78 | consumed tokens: 420505600.0 | grad norm avg: 12.42 | grad norm last: 15.56 | 
2025-12-28T03:44:20 | step: 821400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.8533626644057222e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.23 | consumed tokens: 420556800.0 | grad norm avg: 12.24 | grad norm last: 12.75 | 
2025-12-28T03:44:22 | step: 821500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.8525450286688283e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.36 | consumed tokens: 420608000.0 | grad norm avg: 12.32 | grad norm last: 10.44 | 
2025-12-28T03:44:24 | step: 821600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.8517279386287555e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.56 | consumed tokens: 420659200.0 | grad norm avg: 12.52 | grad norm last: 14.32 | 
2025-12-28T03:44:26 | step: 821700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.8509112123865634e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.39 | consumed tokens: 420710400.0 | grad norm avg: 12.14 | grad norm last: 11.49 | 
2025-12-28T03:44:28 | step: 821800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.8500946680433117e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.75 | consumed tokens: 420761600.0 | grad norm avg: 12.11 | grad norm last: 11.66 | 
2025-12-28T03:44:30 | step: 821900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.849278669396881e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.77 | consumed tokens: 420812800.0 | grad norm avg: 11.94 | grad norm last: 10.81 | 
2025-12-28T03:44:32 | step: 822000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.8484628526493907e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.5 | consumed tokens: 420864000.0 | grad norm avg: 12.12 | grad norm last: 10.54 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_822000-seen_tokens_420864000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_822000-seen_tokens_420864000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_822000-seen_tokens_420864000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_822000-seen_tokens_420864000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_822000-seen_tokens_420864000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_822000-seen_tokens_420864000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_822000-seen_tokens_420864000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_822000-seen_tokens_420864000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:44:35 | step: 822100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.847647399699781e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.68 | train loss last: 3.2 | consumed tokens: 420915200.0 | grad norm avg: 12.39 | grad norm last: 12.41 | 
2025-12-28T03:44:37 | step: 822200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.8468324924469925e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.61 | consumed tokens: 420966400.0 | grad norm avg: 12.46 | grad norm last: 12.37 | 
2025-12-28T03:44:39 | step: 822300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.8460177670931444e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.38 | consumed tokens: 421017600.0 | grad norm avg: 12.48 | grad norm last: 11.34 | 
2025-12-28T03:44:41 | step: 822400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.845203405537177e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 2.88 | consumed tokens: 421068800.0 | grad norm avg: 11.94 | grad norm last: 11.14 | 
2025-12-28T03:44:43 | step: 822500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.84438940777909e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 2.92 | consumed tokens: 421120000.0 | grad norm avg: 12.13 | grad norm last: 10.48 | 
2025-12-28T03:44:45 | step: 822600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.843575773818884e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.75 | consumed tokens: 421171200.0 | grad norm avg: 12.3 | grad norm last: 11.65 | 
2025-12-28T03:44:47 | step: 822700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.8427625036565587e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 5.0 | consumed tokens: 421222400.0 | grad norm avg: 12.23 | grad norm last: 20.35 | 
2025-12-28T03:44:49 | step: 822800 | train samples/s: 98.4 | train mfu (16-bit): -1.0 | lr mean: 1.841949597292114e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.42 | consumed tokens: 421273600.0 | grad norm avg: 12.26 | grad norm last: 12.1 | 
2025-12-28T03:44:51 | step: 822900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.8411368728266098e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 2.89 | consumed tokens: 421324800.0 | grad norm avg: 11.94 | grad norm last: 11.08 | 
2025-12-28T03:44:53 | step: 823000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.8403246940579265e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.06 | consumed tokens: 421376000.0 | grad norm avg: 12.39 | grad norm last: 12.23 | 
2025-12-28T03:44:55 | step: 823100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.839512879087124e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.66 | consumed tokens: 421427200.0 | grad norm avg: 12.97 | grad norm last: 13.14 | 
2025-12-28T03:44:57 | step: 823200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.838701246015262e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 6.16 | consumed tokens: 421478400.0 | grad norm avg: 12.14 | grad norm last: 14.05 | 
2025-12-28T03:44:59 | step: 823300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.8378901586402208e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.03 | consumed tokens: 421529600.0 | grad norm avg: 12.47 | grad norm last: 11.79 | 
2025-12-28T03:45:01 | step: 823400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.83707925316412e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.09 | consumed tokens: 421580800.0 | grad norm avg: 12.25 | grad norm last: 12.57 | 
2025-12-28T03:45:03 | step: 823500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.8362688933848403e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.47 | consumed tokens: 421632000.0 | grad norm avg: 12.06 | grad norm last: 10.76 | 
2025-12-28T03:45:05 | step: 823600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.835458715504501e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.25 | consumed tokens: 421683200.0 | grad norm avg: 12.44 | grad norm last: 13.14 | 
2025-12-28T03:45:07 | step: 823700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.8346489014220424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.53 | consumed tokens: 421734400.0 | grad norm avg: 12.26 | grad norm last: 10.95 | 
2025-12-28T03:45:09 | step: 823800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.833839633036405e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.0 | consumed tokens: 421785600.0 | grad norm avg: 12.39 | grad norm last: 10.04 | 
2025-12-28T03:45:11 | step: 823900 | train samples/s: 97.0 | train mfu (16-bit): -1.0 | lr mean: 1.8330305465497077e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.22 | consumed tokens: 421836800.0 | grad norm avg: 12.19 | grad norm last: 12.9 | 
2025-12-28T03:45:14 | step: 824000 | train samples/s: 101.4 | train mfu (16-bit): -1.0 | lr mean: 1.832221823860891e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.64 | consumed tokens: 421888000.0 | grad norm avg: 12.84 | grad norm last: 11.96 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_824000-seen_tokens_421888000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_824000-seen_tokens_421888000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_824000-seen_tokens_421888000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_824000-seen_tokens_421888000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_824000-seen_tokens_421888000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_824000-seen_tokens_421888000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_824000-seen_tokens_421888000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_824000-seen_tokens_421888000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:45:16 | step: 824100 | train samples/s: 102.0 | train mfu (16-bit): -1.0 | lr mean: 1.8314134649699554e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.61 | train loss last: 3.48 | consumed tokens: 421939200.0 | grad norm avg: 12.11 | grad norm last: 12.29 | 
2025-12-28T03:45:18 | step: 824200 | train samples/s: 103.3 | train mfu (16-bit): -1.0 | lr mean: 1.8306054698769003e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.65 | train loss last: 3.47 | consumed tokens: 421990400.0 | grad norm avg: 12.71 | grad norm last: 11.1 | 
2025-12-28T03:45:20 | step: 824300 | train samples/s: 103.8 | train mfu (16-bit): -1.0 | lr mean: 1.829797838581726e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 5.06 | consumed tokens: 422041600.0 | grad norm avg: 12.52 | grad norm last: 13.9 | 
2025-12-28T03:45:22 | step: 824400 | train samples/s: 103.2 | train mfu (16-bit): -1.0 | lr mean: 1.8289905710844323e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.31 | consumed tokens: 422092800.0 | grad norm avg: 12.07 | grad norm last: 10.64 | 
2025-12-28T03:45:24 | step: 824500 | train samples/s: 102.2 | train mfu (16-bit): -1.0 | lr mean: 1.828183485486079e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.98 | consumed tokens: 422144000.0 | grad norm avg: 12.36 | grad norm last: 11.29 | 
2025-12-28T03:45:26 | step: 824600 | train samples/s: 102.7 | train mfu (16-bit): -1.0 | lr mean: 1.8273769455845468e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.62 | consumed tokens: 422195200.0 | grad norm avg: 12.32 | grad norm last: 11.55 | 
2025-12-28T03:45:29 | step: 824700 | train samples/s: 103.5 | train mfu (16-bit): -1.0 | lr mean: 1.8265707694808953e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.39 | consumed tokens: 422246400.0 | grad norm avg: 12.55 | grad norm last: 11.57 | 
2025-12-28T03:45:31 | step: 824800 | train samples/s: 103.8 | train mfu (16-bit): -1.0 | lr mean: 1.825764775276184e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.66 | consumed tokens: 422297600.0 | grad norm avg: 12.42 | grad norm last: 12.06 | 
2025-12-28T03:45:33 | step: 824900 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 1.824959326768294e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.2 | consumed tokens: 422348800.0 | grad norm avg: 12.55 | grad norm last: 11.75 | 
2025-12-28T03:45:35 | step: 825000 | train samples/s: 103.4 | train mfu (16-bit): -1.0 | lr mean: 1.8241540601593442e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.81 | consumed tokens: 422400000.0 | grad norm avg: 12.13 | grad norm last: 16.0 | 
2025-12-28T03:45:37 | step: 825100 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 1.8233493392472155e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.38 | consumed tokens: 422451200.0 | grad norm avg: 12.07 | grad norm last: 11.15 | 
2025-12-28T03:45:39 | step: 825200 | train samples/s: 103.4 | train mfu (16-bit): -1.0 | lr mean: 1.8225448002340272e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.75 | consumed tokens: 422502400.0 | grad norm avg: 12.04 | grad norm last: 11.81 | 
2025-12-28T03:45:41 | step: 825300 | train samples/s: 103.3 | train mfu (16-bit): -1.0 | lr mean: 1.82174080691766e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.05 | consumed tokens: 422553600.0 | grad norm avg: 12.37 | grad norm last: 13.05 | 
2025-12-28T03:45:43 | step: 825400 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 1.820936995500233e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.38 | consumed tokens: 422604800.0 | grad norm avg: 12.25 | grad norm last: 11.09 | 
2025-12-28T03:45:45 | step: 825500 | train samples/s: 103.3 | train mfu (16-bit): -1.0 | lr mean: 1.8201335478806868e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.45 | consumed tokens: 422656000.0 | grad norm avg: 12.33 | grad norm last: 10.73 | 
2025-12-28T03:45:47 | step: 825600 | train samples/s: 103.2 | train mfu (16-bit): -1.0 | lr mean: 1.8193304640590213e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.52 | consumed tokens: 422707200.0 | grad norm avg: 12.66 | grad norm last: 12.55 | 
2025-12-28T03:45:49 | step: 825700 | train samples/s: 103.6 | train mfu (16-bit): -1.0 | lr mean: 1.8185277440352365e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.27 | consumed tokens: 422758400.0 | grad norm avg: 12.1 | grad norm last: 11.71 | 
2025-12-28T03:45:51 | step: 825800 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 1.8177253878093325e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.3 | consumed tokens: 422809600.0 | grad norm avg: 12.09 | grad norm last: 11.87 | 
2025-12-28T03:45:53 | step: 825900 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 1.816923395381309e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.95 | consumed tokens: 422860800.0 | grad norm avg: 12.45 | grad norm last: 12.75 | 
2025-12-28T03:45:55 | step: 826000 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.8161217667511664e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.76 | train loss last: 3.83 | consumed tokens: 422912000.0 | grad norm avg: 12.75 | grad norm last: 14.64 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_826000-seen_tokens_422912000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_826000-seen_tokens_422912000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_826000-seen_tokens_422912000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_826000-seen_tokens_422912000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_826000-seen_tokens_422912000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_826000-seen_tokens_422912000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_826000-seen_tokens_422912000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_826000-seen_tokens_422912000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:45:58 | step: 826100 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 1.8153205019189045e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.56 | train loss last: 3.23 | consumed tokens: 422963200.0 | grad norm avg: 12.63 | grad norm last: 12.48 | 
2025-12-28T03:46:00 | step: 826200 | train samples/s: 103.8 | train mfu (16-bit): -1.0 | lr mean: 1.8145196008845232e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 2.88 | consumed tokens: 423014400.0 | grad norm avg: 12.22 | grad norm last: 9.93 | 
2025-12-28T03:46:02 | step: 826300 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 1.8137190636480227e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.7 | consumed tokens: 423065600.0 | grad norm avg: 12.46 | grad norm last: 12.51 | 
2025-12-28T03:46:04 | step: 826400 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 1.812918890209403e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.91 | consumed tokens: 423116800.0 | grad norm avg: 12.37 | grad norm last: 11.63 | 
2025-12-28T03:46:06 | step: 826500 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.8121188986697234e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.05 | consumed tokens: 423168000.0 | grad norm avg: 12.0 | grad norm last: 10.91 | 
2025-12-28T03:46:08 | step: 826600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.811319452826865e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.36 | consumed tokens: 423219200.0 | grad norm avg: 12.45 | grad norm last: 11.69 | 
2025-12-28T03:46:10 | step: 826700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.810520188882947e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 3.3 | consumed tokens: 423270400.0 | grad norm avg: 12.72 | grad norm last: 10.45 | 
2025-12-28T03:46:12 | step: 826800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.80972147063585e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.64 | consumed tokens: 423321600.0 | grad norm avg: 12.05 | grad norm last: 12.02 | 
2025-12-28T03:46:14 | step: 826900 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 1.8089231161866337e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.5 | consumed tokens: 423372800.0 | grad norm avg: 12.48 | grad norm last: 13.95 | 
2025-12-28T03:46:16 | step: 827000 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 1.8081249436363578e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.62 | consumed tokens: 423424000.0 | grad norm avg: 12.59 | grad norm last: 12.19 | 
2025-12-28T03:46:18 | step: 827100 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 1.8073271348839626e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.47 | consumed tokens: 423475200.0 | grad norm avg: 12.26 | grad norm last: 12.58 | 
2025-12-28T03:46:21 | step: 827200 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 1.8065298718283884e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.11 | consumed tokens: 423526400.0 | grad norm avg: 12.31 | grad norm last: 10.39 | 
2025-12-28T03:46:23 | step: 827300 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.8057327906717546e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.67 | consumed tokens: 423577600.0 | grad norm avg: 12.22 | grad norm last: 12.96 | 
2025-12-28T03:46:25 | step: 827400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.8049360733130015e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.78 | train loss last: 3.09 | consumed tokens: 423628800.0 | grad norm avg: 12.4 | grad norm last: 11.62 | 
2025-12-28T03:46:27 | step: 827500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.804139719752129e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 4.53 | consumed tokens: 423680000.0 | grad norm avg: 12.23 | grad norm last: 13.26 | 
2025-12-28T03:46:29 | step: 827600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.803343911888078e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 2.78 | consumed tokens: 423731200.0 | grad norm avg: 12.6 | grad norm last: 10.2 | 
2025-12-28T03:46:31 | step: 827700 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 1.802548285922967e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.33 | consumed tokens: 423782400.0 | grad norm avg: 12.29 | grad norm last: 12.92 | 
2025-12-28T03:46:33 | step: 827800 | train samples/s: 103.7 | train mfu (16-bit): -1.0 | lr mean: 1.8017530237557366e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.25 | consumed tokens: 423833600.0 | grad norm avg: 12.3 | grad norm last: 12.47 | 
2025-12-28T03:46:35 | step: 827900 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 1.800958125386387e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.28 | consumed tokens: 423884800.0 | grad norm avg: 12.13 | grad norm last: 10.12 | 
2025-12-28T03:46:37 | step: 828000 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 1.8001635908149183e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.42 | consumed tokens: 423936000.0 | grad norm avg: 12.35 | grad norm last: 10.53 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_828000-seen_tokens_423936000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_828000-seen_tokens_423936000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_828000-seen_tokens_423936000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_828000-seen_tokens_423936000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_828000-seen_tokens_423936000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_828000-seen_tokens_423936000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_828000-seen_tokens_423936000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_828000-seen_tokens_423936000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:46:39 | step: 828100 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 1.79936942004133e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 2.95 | consumed tokens: 423987200.0 | grad norm avg: 11.92 | grad norm last: 11.71 | 
2025-12-28T03:46:41 | step: 828200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.7985756130656227e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.48 | consumed tokens: 424038400.0 | grad norm avg: 12.5 | grad norm last: 11.44 | 
2025-12-28T03:46:43 | step: 828300 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.797782169887796e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.38 | consumed tokens: 424089600.0 | grad norm avg: 12.01 | grad norm last: 11.25 | 
2025-12-28T03:46:45 | step: 828400 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 1.7969889086089097e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.08 | consumed tokens: 424140800.0 | grad norm avg: 12.44 | grad norm last: 10.71 | 
2025-12-28T03:46:48 | step: 828500 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 1.7961961930268444e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.48 | consumed tokens: 424192000.0 | grad norm avg: 12.1 | grad norm last: 12.76 | 
2025-12-28T03:46:50 | step: 828600 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 1.79540384124266e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.64 | consumed tokens: 424243200.0 | grad norm avg: 12.89 | grad norm last: 10.85 | 
2025-12-28T03:46:52 | step: 828700 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 1.794611853256356e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.66 | consumed tokens: 424294400.0 | grad norm avg: 12.35 | grad norm last: 12.68 | 
2025-12-28T03:46:54 | step: 828800 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.7938200471689925e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.66 | consumed tokens: 424345600.0 | grad norm avg: 11.82 | grad norm last: 11.78 | 
2025-12-28T03:46:56 | step: 828900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.79302878677845e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.78 | consumed tokens: 424396800.0 | grad norm avg: 12.33 | grad norm last: 12.14 | 
2025-12-28T03:46:58 | step: 829000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.792237708286848e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.89 | consumed tokens: 424448000.0 | grad norm avg: 12.1 | grad norm last: 12.1 | 
2025-12-28T03:47:00 | step: 829100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.791447175492067e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.34 | consumed tokens: 424499200.0 | grad norm avg: 12.09 | grad norm last: 16.24 | 
2025-12-28T03:47:02 | step: 829200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.7906568245962262e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.77 | consumed tokens: 424550400.0 | grad norm avg: 12.17 | grad norm last: 12.75 | 
2025-12-28T03:47:04 | step: 829300 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 1.7898670193972066e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.0 | consumed tokens: 424601600.0 | grad norm avg: 12.34 | grad norm last: 12.85 | 
2025-12-28T03:47:06 | step: 829400 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 1.7890773960971273e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 2.94 | consumed tokens: 424652800.0 | grad norm avg: 12.2 | grad norm last: 11.74 | 
2025-12-28T03:47:08 | step: 829500 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 1.788288318493869e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.2 | consumed tokens: 424704000.0 | grad norm avg: 12.37 | grad norm last: 9.65 | 
2025-12-28T03:47:10 | step: 829600 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 1.7874994227895513e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.59 | consumed tokens: 424755200.0 | grad norm avg: 12.28 | grad norm last: 11.92 | 
2025-12-28T03:47:12 | step: 829700 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.7867108908831142e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.16 | consumed tokens: 424806400.0 | grad norm avg: 12.49 | grad norm last: 10.55 | 
2025-12-28T03:47:14 | step: 829800 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.7859227227745578e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.34 | consumed tokens: 424857600.0 | grad norm avg: 12.61 | grad norm last: 12.38 | 
2025-12-28T03:47:16 | step: 829900 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.7851351003628224e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.94 | consumed tokens: 424908800.0 | grad norm avg: 12.18 | grad norm last: 13.18 | 
2025-12-28T03:47:18 | step: 830000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.7843476598500274e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 5.28 | consumed tokens: 424960000.0 | grad norm avg: 12.47 | grad norm last: 31.23 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_830000-seen_tokens_424960000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_830000-seen_tokens_424960000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_830000-seen_tokens_424960000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_830000-seen_tokens_424960000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_830000-seen_tokens_424960000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_830000-seen_tokens_424960000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_830000-seen_tokens_424960000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_830000-seen_tokens_424960000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:47:21 | step: 830100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.783560583135113e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.61 | train loss last: 2.67 | consumed tokens: 425011200.0 | grad norm avg: 12.32 | grad norm last: 15.29 | 
2025-12-28T03:47:23 | step: 830200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.7827738702180795e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.91 | consumed tokens: 425062400.0 | grad norm avg: 12.61 | grad norm last: 18.06 | 
2025-12-28T03:47:25 | step: 830300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.7819875210989267e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.22 | consumed tokens: 425113600.0 | grad norm avg: 12.24 | grad norm last: 12.69 | 
2025-12-28T03:47:27 | step: 830400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.7812015357776545e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.28 | consumed tokens: 425164800.0 | grad norm avg: 12.18 | grad norm last: 10.47 | 
2025-12-28T03:47:29 | step: 830500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.780415914254263e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.14 | consumed tokens: 425216000.0 | grad norm avg: 12.6 | grad norm last: 11.3 | 
2025-12-28T03:47:31 | step: 830600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.7796306565287523e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.69 | consumed tokens: 425267200.0 | grad norm avg: 12.32 | grad norm last: 11.99 | 
2025-12-28T03:47:33 | step: 830700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.7788457626011223e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.14 | consumed tokens: 425318400.0 | grad norm avg: 12.38 | grad norm last: 11.77 | 
2025-12-28T03:47:35 | step: 830800 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.778061232471373e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.64 | consumed tokens: 425369600.0 | grad norm avg: 12.01 | grad norm last: 11.16 | 
2025-12-28T03:47:37 | step: 830900 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 1.7772770661395043e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.38 | consumed tokens: 425420800.0 | grad norm avg: 12.31 | grad norm last: 13.1 | 
2025-12-28T03:47:39 | step: 831000 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 1.7764932636055164e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.06 | consumed tokens: 425472000.0 | grad norm avg: 12.73 | grad norm last: 11.62 | 
2025-12-28T03:47:41 | step: 831100 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 1.7757098248694092e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 5.28 | consumed tokens: 425523200.0 | grad norm avg: 13.11 | grad norm last: 24.46 | 
2025-12-28T03:47:43 | step: 831200 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.7749265680322424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.06 | consumed tokens: 425574400.0 | grad norm avg: 12.73 | grad norm last: 12.84 | 
2025-12-28T03:47:45 | step: 831300 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.7741438568918966e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.66 | consumed tokens: 425625600.0 | grad norm avg: 12.31 | grad norm last: 12.24 | 
2025-12-28T03:47:47 | step: 831400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.7733615095494315e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.17 | consumed tokens: 425676800.0 | grad norm avg: 12.45 | grad norm last: 12.43 | 
2025-12-28T03:47:49 | step: 831500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.772579526004847e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 4.03 | consumed tokens: 425728000.0 | grad norm avg: 12.16 | grad norm last: 14.1 | 
2025-12-28T03:47:51 | step: 831600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.771797724359203e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.53 | consumed tokens: 425779200.0 | grad norm avg: 12.45 | grad norm last: 10.39 | 
2025-12-28T03:47:53 | step: 831700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.7710164684103802e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.28 | consumed tokens: 425830400.0 | grad norm avg: 12.19 | grad norm last: 11.41 | 
2025-12-28T03:47:55 | step: 831800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.770235576259438e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.98 | consumed tokens: 425881600.0 | grad norm avg: 12.03 | grad norm last: 12.02 | 
2025-12-28T03:47:57 | step: 831900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.769454866007436e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.48 | consumed tokens: 425932800.0 | grad norm avg: 12.39 | grad norm last: 11.23 | 
2025-12-28T03:47:59 | step: 832000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.7686747014522552e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 2.52 | consumed tokens: 425984000.0 | grad norm avg: 12.36 | grad norm last: 9.7 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_832000-seen_tokens_425984000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_832000-seen_tokens_425984000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_832000-seen_tokens_425984000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_832000-seen_tokens_425984000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_832000-seen_tokens_425984000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_832000-seen_tokens_425984000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_832000-seen_tokens_425984000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_832000-seen_tokens_425984000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:48:02 | step: 832100 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.7678947187960148e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.84 | consumed tokens: 426035200.0 | grad norm avg: 12.5 | grad norm last: 16.78 | 
2025-12-28T03:48:04 | step: 832200 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.7671152818365954e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.38 | consumed tokens: 426086400.0 | grad norm avg: 12.0 | grad norm last: 10.35 | 
2025-12-28T03:48:06 | step: 832300 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.7663360267761163e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.12 | consumed tokens: 426137600.0 | grad norm avg: 12.32 | grad norm last: 12.17 | 
2025-12-28T03:48:08 | step: 832400 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.7655573174124584e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.52 | consumed tokens: 426188800.0 | grad norm avg: 12.49 | grad norm last: 12.04 | 
2025-12-28T03:48:10 | step: 832500 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 1.7647787899477407e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.03 | consumed tokens: 426240000.0 | grad norm avg: 12.66 | grad norm last: 12.93 | 
2025-12-28T03:48:12 | step: 832600 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 1.7640006262809038e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.7 | consumed tokens: 426291200.0 | grad norm avg: 12.38 | grad norm last: 12.08 | 
2025-12-28T03:48:14 | step: 832700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.763223008310888e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.03 | consumed tokens: 426342400.0 | grad norm avg: 12.92 | grad norm last: 12.56 | 
2025-12-28T03:48:16 | step: 832800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.7624455722398125e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.52 | consumed tokens: 426393600.0 | grad norm avg: 12.62 | grad norm last: 12.8 | 
2025-12-28T03:48:18 | step: 832900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.7616684999666177e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.7 | consumed tokens: 426444800.0 | grad norm avg: 12.48 | grad norm last: 10.36 | 
2025-12-28T03:48:20 | step: 833000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.760891973390244e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.5 | consumed tokens: 426496000.0 | grad norm avg: 12.49 | grad norm last: 13.98 | 
2025-12-28T03:48:22 | step: 833100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.7601156287128106e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.23 | consumed tokens: 426547200.0 | grad norm avg: 12.43 | grad norm last: 11.37 | 
2025-12-28T03:48:24 | step: 833200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.759339647833258e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.59 | consumed tokens: 426598400.0 | grad norm avg: 12.44 | grad norm last: 20.81 | 
2025-12-28T03:48:26 | step: 833300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.7585642126505263e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.19 | consumed tokens: 426649600.0 | grad norm avg: 12.52 | grad norm last: 10.78 | 
2025-12-28T03:48:28 | step: 833400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.757788959366735e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.62 | consumed tokens: 426700800.0 | grad norm avg: 12.44 | grad norm last: 10.5 | 
2025-12-28T03:48:30 | step: 833500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.7570140698808245e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.36 | consumed tokens: 426752000.0 | grad norm avg: 12.45 | grad norm last: 11.41 | 
2025-12-28T03:48:32 | step: 833600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.7562395441927947e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.17 | consumed tokens: 426803200.0 | grad norm avg: 12.22 | grad norm last: 11.98 | 
2025-12-28T03:48:34 | step: 833700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.7554653823026456e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.95 | consumed tokens: 426854400.0 | grad norm avg: 12.65 | grad norm last: 11.77 | 
2025-12-28T03:48:36 | step: 833800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.7546915842103772e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.48 | consumed tokens: 426905600.0 | grad norm avg: 12.41 | grad norm last: 12.07 | 
2025-12-28T03:48:39 | step: 833900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.7539181499159895e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.78 | consumed tokens: 426956800.0 | grad norm avg: 12.73 | grad norm last: 11.64 | 
2025-12-28T03:48:41 | step: 834000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.753145261318423e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.12 | consumed tokens: 427008000.0 | grad norm avg: 12.89 | grad norm last: 10.9 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_834000-seen_tokens_427008000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_834000-seen_tokens_427008000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_834000-seen_tokens_427008000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_834000-seen_tokens_427008000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_834000-seen_tokens_427008000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_834000-seen_tokens_427008000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_834000-seen_tokens_427008000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_834000-seen_tokens_427008000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:48:43 | step: 834100 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.7523725546197966e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.56 | train loss last: 3.58 | consumed tokens: 427059200.0 | grad norm avg: 12.21 | grad norm last: 13.62 | 
2025-12-28T03:48:45 | step: 834200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.751600211719051e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.06 | consumed tokens: 427110400.0 | grad norm avg: 12.69 | grad norm last: 12.81 | 
2025-12-28T03:48:47 | step: 834300 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 1.750828232616186e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.69 | consumed tokens: 427161600.0 | grad norm avg: 12.28 | grad norm last: 10.96 | 
2025-12-28T03:48:49 | step: 834400 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.750056617311202e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.5 | consumed tokens: 427212800.0 | grad norm avg: 12.43 | grad norm last: 10.99 | 
2025-12-28T03:48:51 | step: 834500 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 1.7492853658040985e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.41 | consumed tokens: 427264000.0 | grad norm avg: 12.5 | grad norm last: 12.53 | 
2025-12-28T03:48:53 | step: 834600 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.7485144780948758e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.97 | consumed tokens: 427315200.0 | grad norm avg: 12.89 | grad norm last: 10.81 | 
2025-12-28T03:48:55 | step: 834700 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.7477439541835338e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.78 | consumed tokens: 427366400.0 | grad norm avg: 12.07 | grad norm last: 10.7 | 
2025-12-28T03:48:57 | step: 834800 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.7469737940700725e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.52 | consumed tokens: 427417600.0 | grad norm avg: 13.05 | grad norm last: 10.85 | 
2025-12-28T03:48:59 | step: 834900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.746203997754492e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.77 | consumed tokens: 427468800.0 | grad norm avg: 12.7 | grad norm last: 13.23 | 
2025-12-28T03:49:01 | step: 835000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.7454343833378516e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.14 | consumed tokens: 427520000.0 | grad norm avg: 12.41 | grad norm last: 13.24 | 
2025-12-28T03:49:03 | step: 835100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.7446653146180324e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.16 | consumed tokens: 427571200.0 | grad norm avg: 12.31 | grad norm last: 11.55 | 
2025-12-28T03:49:05 | step: 835200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.743896609696094e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 2.86 | consumed tokens: 427622400.0 | grad norm avg: 12.33 | grad norm last: 10.69 | 
2025-12-28T03:49:07 | step: 835300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.7431282685720362e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.19 | consumed tokens: 427673600.0 | grad norm avg: 12.84 | grad norm last: 10.59 | 
2025-12-28T03:49:10 | step: 835400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.742360291245859e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.27 | consumed tokens: 427724800.0 | grad norm avg: 13.56 | grad norm last: 11.05 | 
2025-12-28T03:49:12 | step: 835500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.7415926777175628e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.17 | consumed tokens: 427776000.0 | grad norm avg: 12.7 | grad norm last: 11.12 | 
2025-12-28T03:49:14 | step: 835600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.740825427987147e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.59 | consumed tokens: 427827200.0 | grad norm avg: 12.79 | grad norm last: 12.27 | 
2025-12-28T03:49:16 | step: 835700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.7400585420546122e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 5.16 | consumed tokens: 427878400.0 | grad norm avg: 13.31 | grad norm last: 21.99 | 
2025-12-28T03:49:18 | step: 835800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.7392918380210176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.45 | consumed tokens: 427929600.0 | grad norm avg: 12.97 | grad norm last: 11.86 | 
2025-12-28T03:49:20 | step: 835900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.738525679684244e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.52 | consumed tokens: 427980800.0 | grad norm avg: 12.45 | grad norm last: 12.83 | 
2025-12-28T03:49:22 | step: 836000 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.7377598851453513e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 2.81 | consumed tokens: 428032000.0 | grad norm avg: 12.71 | grad norm last: 10.89 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_836000-seen_tokens_428032000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_836000-seen_tokens_428032000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_836000-seen_tokens_428032000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_836000-seen_tokens_428032000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_836000-seen_tokens_428032000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_836000-seen_tokens_428032000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_836000-seen_tokens_428032000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_836000-seen_tokens_428032000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:49:24 | step: 836100 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.7369944544043392e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.91 | consumed tokens: 428083200.0 | grad norm avg: 12.6 | grad norm last: 16.07 | 
2025-12-28T03:49:26 | step: 836200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.7362292055622675e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.19 | consumed tokens: 428134400.0 | grad norm avg: 12.99 | grad norm last: 13.82 | 
2025-12-28T03:49:28 | step: 836300 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 1.7354645024170168e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.52 | consumed tokens: 428185600.0 | grad norm avg: 12.64 | grad norm last: 11.96 | 
2025-12-28T03:49:30 | step: 836400 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.7347001630696468e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.83 | consumed tokens: 428236800.0 | grad norm avg: 12.63 | grad norm last: 13.3 | 
2025-12-28T03:49:32 | step: 836500 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 1.7339361875201575e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 2.67 | consumed tokens: 428288000.0 | grad norm avg: 12.48 | grad norm last: 10.87 | 
2025-12-28T03:49:34 | step: 836600 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 1.7331723938696086e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.89 | consumed tokens: 428339200.0 | grad norm avg: 12.7 | grad norm last: 15.49 | 
2025-12-28T03:49:36 | step: 836700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.7324091459158808e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.16 | consumed tokens: 428390400.0 | grad norm avg: 12.77 | grad norm last: 12.95 | 
2025-12-28T03:49:38 | step: 836800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.7316462617600337e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.61 | consumed tokens: 428441600.0 | grad norm avg: 12.8 | grad norm last: 13.05 | 
2025-12-28T03:49:40 | step: 836900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.7308837414020672e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.59 | consumed tokens: 428492800.0 | grad norm avg: 12.27 | grad norm last: 11.92 | 
2025-12-28T03:49:43 | step: 837000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.7301214029430412e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 2.88 | consumed tokens: 428544000.0 | grad norm avg: 12.6 | grad norm last: 10.34 | 
2025-12-28T03:49:45 | step: 837100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.7293596101808362e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.89 | consumed tokens: 428595200.0 | grad norm avg: 12.66 | grad norm last: 12.47 | 
2025-12-28T03:49:47 | step: 837200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.728598181216512e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.19 | consumed tokens: 428646400.0 | grad norm avg: 12.65 | grad norm last: 12.89 | 
2025-12-28T03:49:49 | step: 837300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.727836934151128e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.2 | consumed tokens: 428697600.0 | grad norm avg: 12.71 | grad norm last: 11.44 | 
2025-12-28T03:49:51 | step: 837400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.727076232782565e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 5.06 | consumed tokens: 428748800.0 | grad norm avg: 12.92 | grad norm last: 13.5 | 
2025-12-28T03:49:53 | step: 837500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.726315895211883e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.36 | consumed tokens: 428800000.0 | grad norm avg: 12.77 | grad norm last: 11.03 | 
2025-12-28T03:49:55 | step: 837600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.725555739540141e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 6.03 | consumed tokens: 428851200.0 | grad norm avg: 12.92 | grad norm last: 54.2 | 
2025-12-28T03:49:57 | step: 837700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.7247961295652203e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.69 | consumed tokens: 428902400.0 | grad norm avg: 13.01 | grad norm last: 11.37 | 
2025-12-28T03:49:59 | step: 837800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.7240368833881803e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.75 | consumed tokens: 428953600.0 | grad norm avg: 12.73 | grad norm last: 14.54 | 
2025-12-28T03:50:01 | step: 837900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.7232778191100806e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.22 | consumed tokens: 429004800.0 | grad norm avg: 13.09 | grad norm last: 10.75 | 
2025-12-28T03:50:03 | step: 838000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.722519300528802e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.64 | consumed tokens: 429056000.0 | grad norm avg: 13.22 | grad norm last: 12.2 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_838000-seen_tokens_429056000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_838000-seen_tokens_429056000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_838000-seen_tokens_429056000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_838000-seen_tokens_429056000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_838000-seen_tokens_429056000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_838000-seen_tokens_429056000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_838000-seen_tokens_429056000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_838000-seen_tokens_429056000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:50:05 | step: 838100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.721761145745404e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.91 | consumed tokens: 429107200.0 | grad norm avg: 12.69 | grad norm last: 13.6 | 
2025-12-28T03:50:07 | step: 838200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.7210031728609465e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.47 | consumed tokens: 429158400.0 | grad norm avg: 12.82 | grad norm last: 11.62 | 
2025-12-28T03:50:09 | step: 838300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.72024574567331e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.06 | consumed tokens: 429209600.0 | grad norm avg: 12.73 | grad norm last: 14.11 | 
2025-12-28T03:50:11 | step: 838400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.719488500384614e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.38 | consumed tokens: 429260800.0 | grad norm avg: 12.88 | grad norm last: 20.11 | 
2025-12-28T03:50:13 | step: 838500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.7187318007927388e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.52 | consumed tokens: 429312000.0 | grad norm avg: 12.51 | grad norm last: 11.23 | 
2025-12-28T03:50:15 | step: 838600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.7179754649987444e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.08 | consumed tokens: 429363200.0 | grad norm avg: 13.17 | grad norm last: 11.47 | 
2025-12-28T03:50:17 | step: 838700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.7172193111036904e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.31 | consumed tokens: 429414400.0 | grad norm avg: 12.81 | grad norm last: 11.78 | 
2025-12-28T03:50:19 | step: 838800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.7164637029054575e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.03 | consumed tokens: 429465600.0 | grad norm avg: 12.7 | grad norm last: 13.53 | 
2025-12-28T03:50:21 | step: 838900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.7157084585051052e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 2.77 | consumed tokens: 429516800.0 | grad norm avg: 12.94 | grad norm last: 11.64 | 
2025-12-28T03:50:23 | step: 839000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.7149533960036933e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.39 | consumed tokens: 429568000.0 | grad norm avg: 12.86 | grad norm last: 10.55 | 
2025-12-28T03:50:25 | step: 839100 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.7141988791991025e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 2.86 | consumed tokens: 429619200.0 | grad norm avg: 13.19 | grad norm last: 10.61 | 
2025-12-28T03:50:28 | step: 839200 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.7134447261923924e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.14 | consumed tokens: 429670400.0 | grad norm avg: 12.5 | grad norm last: 11.7 | 
2025-12-28T03:50:30 | step: 839300 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.7126907550846227e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.56 | consumed tokens: 429721600.0 | grad norm avg: 13.21 | grad norm last: 10.66 | 
2025-12-28T03:50:32 | step: 839400 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 1.711937329673674e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.83 | consumed tokens: 429772800.0 | grad norm avg: 12.59 | grad norm last: 16.85 | 
2025-12-28T03:50:34 | step: 839500 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.7111840861616656e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.23 | consumed tokens: 429824000.0 | grad norm avg: 12.83 | grad norm last: 11.71 | 
2025-12-28T03:50:36 | step: 839600 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.7104313883464783e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.48 | consumed tokens: 429875200.0 | grad norm avg: 12.99 | grad norm last: 11.45 | 
2025-12-28T03:50:38 | step: 839700 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.7096790543291718e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.72 | consumed tokens: 429926400.0 | grad norm avg: 12.78 | grad norm last: 14.35 | 
2025-12-28T03:50:40 | step: 839800 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.7089269022108056e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.2 | consumed tokens: 429977600.0 | grad norm avg: 12.91 | grad norm last: 12.23 | 
2025-12-28T03:50:42 | step: 839900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.7081752957892604e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.06 | consumed tokens: 430028800.0 | grad norm avg: 12.31 | grad norm last: 11.23 | 
2025-12-28T03:50:44 | step: 840000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.707424053165596e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.17 | consumed tokens: 430080000.0 | grad norm avg: 12.75 | grad norm last: 11.23 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_840000-seen_tokens_430080000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_840000-seen_tokens_430080000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_840000-seen_tokens_430080000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_840000-seen_tokens_430080000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_840000-seen_tokens_430080000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_840000-seen_tokens_430080000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_840000-seen_tokens_430080000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_840000-seen_tokens_430080000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:50:46 | step: 840100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.706672992440872e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.53 | train loss last: 3.69 | consumed tokens: 430131200.0 | grad norm avg: 12.72 | grad norm last: 11.31 | 
2025-12-28T03:50:48 | step: 840200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.705922477412969e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.67 | consumed tokens: 430182400.0 | grad norm avg: 12.45 | grad norm last: 14.58 | 
2025-12-28T03:50:50 | step: 840300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.7051723261829466e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.97 | consumed tokens: 430233600.0 | grad norm avg: 13.33 | grad norm last: 11.05 | 
2025-12-28T03:50:52 | step: 840400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.7044223568518646e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.8 | consumed tokens: 430284800.0 | grad norm avg: 12.89 | grad norm last: 12.27 | 
2025-12-28T03:50:54 | step: 840500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.7036729332176037e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.14 | consumed tokens: 430336000.0 | grad norm avg: 12.53 | grad norm last: 10.42 | 
2025-12-28T03:50:56 | step: 840600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.7029238733812235e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.12 | consumed tokens: 430387200.0 | grad norm avg: 13.16 | grad norm last: 17.71 | 
2025-12-28T03:50:58 | step: 840700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.702175177342724e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.17 | consumed tokens: 430438400.0 | grad norm avg: 13.06 | grad norm last: 10.79 | 
2025-12-28T03:51:00 | step: 840800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.701426663203165e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.52 | consumed tokens: 430489600.0 | grad norm avg: 13.38 | grad norm last: 11.08 | 
2025-12-28T03:51:02 | step: 840900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.700678694760427e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.83 | consumed tokens: 430540800.0 | grad norm avg: 12.52 | grad norm last: 11.7 | 
2025-12-28T03:51:05 | step: 841000 | train samples/s: 98.5 | train mfu (16-bit): -1.0 | lr mean: 1.6999310901155695e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 2.95 | consumed tokens: 430592000.0 | grad norm avg: 12.81 | grad norm last: 10.74 | 
2025-12-28T03:51:07 | step: 841100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.699183849268593e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.5 | consumed tokens: 430643200.0 | grad norm avg: 13.08 | grad norm last: 11.83 | 
2025-12-28T03:51:09 | step: 841200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.6984367903205566e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 5.28 | consumed tokens: 430694400.0 | grad norm avg: 13.3 | grad norm last: 19.02 | 
2025-12-28T03:51:11 | step: 841300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.6976902770693414e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.16 | consumed tokens: 430745600.0 | grad norm avg: 12.96 | grad norm last: 16.24 | 
2025-12-28T03:51:13 | step: 841400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.696944127616007e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.44 | consumed tokens: 430796800.0 | grad norm avg: 12.66 | grad norm last: 12.21 | 
2025-12-28T03:51:15 | step: 841500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.696198341960553e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.62 | consumed tokens: 430848000.0 | grad norm avg: 12.79 | grad norm last: 12.95 | 
2025-12-28T03:51:17 | step: 841600 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.6954527382040396e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.89 | consumed tokens: 430899200.0 | grad norm avg: 12.57 | grad norm last: 12.73 | 
2025-12-28T03:51:19 | step: 841700 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 1.6947076801443473e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.25 | consumed tokens: 430950400.0 | grad norm avg: 12.53 | grad norm last: 14.27 | 
2025-12-28T03:51:21 | step: 841800 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.6939629858825356e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.34 | consumed tokens: 431001600.0 | grad norm avg: 12.51 | grad norm last: 12.95 | 
2025-12-28T03:51:23 | step: 841900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.6932186554186046e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.66 | consumed tokens: 431052800.0 | grad norm avg: 13.74 | grad norm last: 16.03 | 
2025-12-28T03:51:25 | step: 842000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.6924746887525544e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 4.03 | consumed tokens: 431104000.0 | grad norm avg: 12.92 | grad norm last: 12.6 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_842000-seen_tokens_431104000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_842000-seen_tokens_431104000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_842000-seen_tokens_431104000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_842000-seen_tokens_431104000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_842000-seen_tokens_431104000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_842000-seen_tokens_431104000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_842000-seen_tokens_431104000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_842000-seen_tokens_431104000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:51:27 | step: 842100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.6917310858843848e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.61 | train loss last: 2.94 | consumed tokens: 431155200.0 | grad norm avg: 12.84 | grad norm last: 10.69 | 
2025-12-28T03:51:29 | step: 842200 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.6909876649151556e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.45 | consumed tokens: 431206400.0 | grad norm avg: 12.62 | grad norm last: 14.18 | 
2025-12-28T03:51:31 | step: 842300 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.6902447896427475e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.72 | consumed tokens: 431257600.0 | grad norm avg: 12.91 | grad norm last: 14.72 | 
2025-12-28T03:51:34 | step: 842400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.68950227816822e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.61 | consumed tokens: 431308800.0 | grad norm avg: 12.85 | grad norm last: 11.18 | 
2025-12-28T03:51:36 | step: 842500 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.6887601304915734e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.16 | consumed tokens: 431360000.0 | grad norm avg: 13.7 | grad norm last: 10.65 | 
2025-12-28T03:51:38 | step: 842600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.6880183466128074e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.11 | consumed tokens: 431411200.0 | grad norm avg: 12.88 | grad norm last: 11.93 | 
2025-12-28T03:51:40 | step: 842700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.687276926531922e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.31 | consumed tokens: 431462400.0 | grad norm avg: 13.75 | grad norm last: 12.67 | 
2025-12-28T03:51:42 | step: 842800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.6865358702489175e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.11 | consumed tokens: 431513600.0 | grad norm avg: 12.87 | grad norm last: 11.0 | 
2025-12-28T03:51:44 | step: 842900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.6857951777637936e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 2.7 | consumed tokens: 431564800.0 | grad norm avg: 13.05 | grad norm last: 9.35 | 
2025-12-28T03:51:46 | step: 843000 | train samples/s: 103.4 | train mfu (16-bit): -1.0 | lr mean: 1.6850548490765505e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.59 | consumed tokens: 431616000.0 | grad norm avg: 12.87 | grad norm last: 12.25 | 
2025-12-28T03:51:48 | step: 843100 | train samples/s: 102.4 | train mfu (16-bit): -1.0 | lr mean: 1.684314884187188e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.08 | consumed tokens: 431667200.0 | grad norm avg: 12.77 | grad norm last: 10.82 | 
2025-12-28T03:51:50 | step: 843200 | train samples/s: 102.1 | train mfu (16-bit): -1.0 | lr mean: 1.6835752830957063e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.59 | consumed tokens: 431718400.0 | grad norm avg: 13.08 | grad norm last: 11.79 | 
2025-12-28T03:51:52 | step: 843300 | train samples/s: 102.4 | train mfu (16-bit): -1.0 | lr mean: 1.6828360458021052e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.34 | consumed tokens: 431769600.0 | grad norm avg: 12.54 | grad norm last: 13.62 | 
2025-12-28T03:51:54 | step: 843400 | train samples/s: 102.9 | train mfu (16-bit): -1.0 | lr mean: 1.682097172306385e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.2 | consumed tokens: 431820800.0 | grad norm avg: 12.69 | grad norm last: 11.81 | 
2025-12-28T03:51:56 | step: 843500 | train samples/s: 102.9 | train mfu (16-bit): -1.0 | lr mean: 1.6813586626085453e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 2.98 | consumed tokens: 431872000.0 | grad norm avg: 12.95 | grad norm last: 11.3 | 
2025-12-28T03:51:58 | step: 843600 | train samples/s: 103.3 | train mfu (16-bit): -1.0 | lr mean: 1.6806205167085864e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.27 | consumed tokens: 431923200.0 | grad norm avg: 12.78 | grad norm last: 11.26 | 
2025-12-28T03:52:00 | step: 843700 | train samples/s: 102.8 | train mfu (16-bit): -1.0 | lr mean: 1.679882734606508e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.81 | consumed tokens: 431974400.0 | grad norm avg: 13.13 | grad norm last: 14.0 | 
2025-12-28T03:52:03 | step: 843800 | train samples/s: 103.2 | train mfu (16-bit): -1.0 | lr mean: 1.679145498201251e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.52 | consumed tokens: 432025600.0 | grad norm avg: 12.77 | grad norm last: 13.79 | 
2025-12-28T03:52:05 | step: 843900 | train samples/s: 103.3 | train mfu (16-bit): -1.0 | lr mean: 1.6784084436949342e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.77 | consumed tokens: 432076800.0 | grad norm avg: 12.9 | grad norm last: 11.51 | 
2025-12-28T03:52:07 | step: 844000 | train samples/s: 103.3 | train mfu (16-bit): -1.0 | lr mean: 1.6776717529864982e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.25 | consumed tokens: 432128000.0 | grad norm avg: 12.84 | grad norm last: 11.65 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_844000-seen_tokens_432128000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_844000-seen_tokens_432128000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_844000-seen_tokens_432128000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_844000-seen_tokens_432128000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_844000-seen_tokens_432128000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_844000-seen_tokens_432128000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_844000-seen_tokens_432128000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_844000-seen_tokens_432128000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:52:09 | step: 844100 | train samples/s: 103.3 | train mfu (16-bit): -1.0 | lr mean: 1.6769354260759428e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 3.5 | consumed tokens: 432179200.0 | grad norm avg: 12.78 | grad norm last: 10.73 | 
2025-12-28T03:52:11 | step: 844200 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 1.676199462963268e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.36 | consumed tokens: 432230400.0 | grad norm avg: 12.65 | grad norm last: 10.94 | 
2025-12-28T03:52:13 | step: 844300 | train samples/s: 103.8 | train mfu (16-bit): -1.0 | lr mean: 1.6754640455474146e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.62 | consumed tokens: 432281600.0 | grad norm avg: 12.85 | grad norm last: 13.38 | 
2025-12-28T03:52:15 | step: 844400 | train samples/s: 103.5 | train mfu (16-bit): -1.0 | lr mean: 1.6747288100305013e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.31 | consumed tokens: 432332800.0 | grad norm avg: 12.74 | grad norm last: 14.02 | 
2025-12-28T03:52:17 | step: 844500 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 1.6739939383114688e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.59 | consumed tokens: 432384000.0 | grad norm avg: 12.41 | grad norm last: 11.33 | 
2025-12-28T03:52:19 | step: 844600 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 1.673259430390317e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.06 | consumed tokens: 432435200.0 | grad norm avg: 12.38 | grad norm last: 14.91 | 
2025-12-28T03:52:21 | step: 844700 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 1.6725254681659862e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.16 | consumed tokens: 432486400.0 | grad norm avg: 13.47 | grad norm last: 12.79 | 
2025-12-28T03:52:24 | step: 844800 | train samples/s: 103.8 | train mfu (16-bit): -1.0 | lr mean: 1.671791687840596e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.81 | consumed tokens: 432537600.0 | grad norm avg: 12.73 | grad norm last: 13.11 | 
2025-12-28T03:52:26 | step: 844900 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 1.671058271313086e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.91 | consumed tokens: 432588800.0 | grad norm avg: 12.86 | grad norm last: 12.42 | 
2025-12-28T03:52:28 | step: 845000 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 1.6703254004823975e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 4.12 | consumed tokens: 432640000.0 | grad norm avg: 12.81 | grad norm last: 12.47 | 
2025-12-28T03:52:30 | step: 845100 | train samples/s: 103.6 | train mfu (16-bit): -1.0 | lr mean: 1.6695927115506493e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.2 | consumed tokens: 432691200.0 | grad norm avg: 12.56 | grad norm last: 11.62 | 
2025-12-28T03:52:32 | step: 845200 | train samples/s: 103.6 | train mfu (16-bit): -1.0 | lr mean: 1.668860568315722e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.39 | consumed tokens: 432742400.0 | grad norm avg: 12.56 | grad norm last: 11.42 | 
2025-12-28T03:52:34 | step: 845300 | train samples/s: 103.5 | train mfu (16-bit): -1.0 | lr mean: 1.6681286069797352e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.48 | consumed tokens: 432793600.0 | grad norm avg: 12.76 | grad norm last: 11.1 | 
2025-12-28T03:52:36 | step: 845400 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 1.6673971913405694e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.33 | consumed tokens: 432844800.0 | grad norm avg: 12.8 | grad norm last: 12.1 | 
2025-12-28T03:52:38 | step: 845500 | train samples/s: 103.9 | train mfu (16-bit): -1.0 | lr mean: 1.666665957600344e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 5.81 | consumed tokens: 432896000.0 | grad norm avg: 12.75 | grad norm last: 14.45 | 
2025-12-28T03:52:40 | step: 845600 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 1.6659352695569396e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.05 | consumed tokens: 432947200.0 | grad norm avg: 12.88 | grad norm last: 12.27 | 
2025-12-28T03:52:42 | step: 845700 | train samples/s: 103.6 | train mfu (16-bit): -1.0 | lr mean: 1.6652047634124756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.84 | consumed tokens: 432998400.0 | grad norm avg: 13.21 | grad norm last: 14.81 | 
2025-12-28T03:52:44 | step: 845800 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.6644748029648326e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.69 | consumed tokens: 433049600.0 | grad norm avg: 12.92 | grad norm last: 13.95 | 
2025-12-28T03:52:46 | step: 845900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.6637452063150704e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.23 | consumed tokens: 433100800.0 | grad norm avg: 13.31 | grad norm last: 13.19 | 
2025-12-28T03:52:48 | step: 846000 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.6630157915642485e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.94 | consumed tokens: 433152000.0 | grad norm avg: 12.78 | grad norm last: 13.24 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_846000-seen_tokens_433152000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_846000-seen_tokens_433152000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_846000-seen_tokens_433152000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_846000-seen_tokens_433152000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_846000-seen_tokens_433152000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_846000-seen_tokens_433152000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_846000-seen_tokens_433152000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_846000-seen_tokens_433152000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:52:51 | step: 846100 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 1.6622869225102477e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 2.53 | consumed tokens: 433203200.0 | grad norm avg: 13.5 | grad norm last: 14.66 | 
2025-12-28T03:52:53 | step: 846200 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 1.6615584172541276e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.47 | consumed tokens: 433254400.0 | grad norm avg: 13.51 | grad norm last: 11.5 | 
2025-12-28T03:52:55 | step: 846300 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.660830275795888e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.02 | consumed tokens: 433305600.0 | grad norm avg: 13.01 | grad norm last: 11.0 | 
2025-12-28T03:52:57 | step: 846400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.660102316236589e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 2.61 | consumed tokens: 433356800.0 | grad norm avg: 13.31 | grad norm last: 11.37 | 
2025-12-28T03:52:59 | step: 846500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.659374902374111e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.67 | consumed tokens: 433408000.0 | grad norm avg: 13.14 | grad norm last: 11.36 | 
2025-12-28T03:53:01 | step: 846600 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 1.658647852309514e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.67 | consumed tokens: 433459200.0 | grad norm avg: 13.05 | grad norm last: 10.77 | 
2025-12-28T03:53:03 | step: 846700 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 1.6579211660427973e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.84 | consumed tokens: 433510400.0 | grad norm avg: 12.92 | grad norm last: 11.58 | 
2025-12-28T03:53:05 | step: 846800 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 1.6571948435739614e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.5 | consumed tokens: 433561600.0 | grad norm avg: 13.18 | grad norm last: 14.15 | 
2025-12-28T03:53:07 | step: 846900 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 1.6564688849030063e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 2.91 | consumed tokens: 433612800.0 | grad norm avg: 12.9 | grad norm last: 12.17 | 
2025-12-28T03:53:09 | step: 847000 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 1.6557432900299318e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.83 | consumed tokens: 433664000.0 | grad norm avg: 12.86 | grad norm last: 15.11 | 
2025-12-28T03:53:11 | step: 847100 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.655018058954738e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.45 | consumed tokens: 433715200.0 | grad norm avg: 12.97 | grad norm last: 13.04 | 
2025-12-28T03:53:13 | step: 847200 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.654293191677425e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.34 | consumed tokens: 433766400.0 | grad norm avg: 12.97 | grad norm last: 13.94 | 
2025-12-28T03:53:15 | step: 847300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.6535686881979927e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.64 | consumed tokens: 433817600.0 | grad norm avg: 13.12 | grad norm last: 14.37 | 
2025-12-28T03:53:17 | step: 847400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.652844548516441e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.3 | consumed tokens: 433868800.0 | grad norm avg: 13.46 | grad norm last: 11.97 | 
2025-12-28T03:53:19 | step: 847500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.6521207726327702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 2.91 | consumed tokens: 433920000.0 | grad norm avg: 12.86 | grad norm last: 11.05 | 
2025-12-28T03:53:22 | step: 847600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.65139736054698e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.47 | consumed tokens: 433971200.0 | grad norm avg: 12.72 | grad norm last: 10.99 | 
2025-12-28T03:53:24 | step: 847700 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.650674494158011e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.12 | consumed tokens: 434022400.0 | grad norm avg: 12.88 | grad norm last: 11.07 | 
2025-12-28T03:53:26 | step: 847800 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 1.649951809667982e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.88 | consumed tokens: 434073600.0 | grad norm avg: 13.14 | grad norm last: 13.63 | 
2025-12-28T03:53:28 | step: 847900 | train samples/s: 104.0 | train mfu (16-bit): -1.0 | lr mean: 1.649229488975834e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.77 | consumed tokens: 434124800.0 | grad norm avg: 12.9 | grad norm last: 11.39 | 
2025-12-28T03:53:30 | step: 848000 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 1.6485075320815668e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.95 | consumed tokens: 434176000.0 | grad norm avg: 12.3 | grad norm last: 13.76 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_848000-seen_tokens_434176000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_848000-seen_tokens_434176000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_848000-seen_tokens_434176000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_848000-seen_tokens_434176000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_848000-seen_tokens_434176000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_848000-seen_tokens_434176000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_848000-seen_tokens_434176000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_848000-seen_tokens_434176000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:53:32 | step: 848100 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 1.6477861208841205e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.48 | train loss last: 3.7 | consumed tokens: 434227200.0 | grad norm avg: 13.12 | grad norm last: 12.05 | 
2025-12-28T03:53:34 | step: 848200 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.6470648915856145e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.59 | consumed tokens: 434278400.0 | grad norm avg: 12.56 | grad norm last: 12.82 | 
2025-12-28T03:53:36 | step: 848300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.6463442079839297e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.81 | consumed tokens: 434329600.0 | grad norm avg: 13.23 | grad norm last: 13.58 | 
2025-12-28T03:53:38 | step: 848400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.645623706281185e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.77 | consumed tokens: 434380800.0 | grad norm avg: 12.72 | grad norm last: 12.43 | 
2025-12-28T03:53:40 | step: 848500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.6449037502752617e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.55 | consumed tokens: 434432000.0 | grad norm avg: 12.85 | grad norm last: 11.42 | 
2025-12-28T03:53:42 | step: 848600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.6441839761682786e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.31 | consumed tokens: 434483200.0 | grad norm avg: 12.79 | grad norm last: 13.05 | 
2025-12-28T03:53:44 | step: 848700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.6434647477581166e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.22 | consumed tokens: 434534400.0 | grad norm avg: 12.75 | grad norm last: 14.91 | 
2025-12-28T03:53:46 | step: 848800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.642745701246895e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.78 | consumed tokens: 434585600.0 | grad norm avg: 13.15 | grad norm last: 12.32 | 
2025-12-28T03:53:48 | step: 848900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.6420272004324943e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.08 | consumed tokens: 434636800.0 | grad norm avg: 12.68 | grad norm last: 10.55 | 
2025-12-28T03:53:50 | step: 849000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.6413090634159744e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.11 | consumed tokens: 434688000.0 | grad norm avg: 12.91 | grad norm last: 10.63 | 
2025-12-28T03:53:53 | step: 849100 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.6405911082983948e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.12 | consumed tokens: 434739200.0 | grad norm avg: 12.49 | grad norm last: 11.87 | 
2025-12-28T03:53:55 | step: 849200 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 1.6398736988776363e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.52 | consumed tokens: 434790400.0 | grad norm avg: 12.79 | grad norm last: 12.09 | 
2025-12-28T03:53:57 | step: 849300 | train samples/s: 104.1 | train mfu (16-bit): -1.0 | lr mean: 1.6391566532547586e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.12 | consumed tokens: 434841600.0 | grad norm avg: 12.92 | grad norm last: 14.81 | 
2025-12-28T03:53:59 | step: 849400 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 1.6384399714297615e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.81 | consumed tokens: 434892800.0 | grad norm avg: 12.96 | grad norm last: 18.22 | 
2025-12-28T03:54:01 | step: 849500 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.637723653402645e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.83 | consumed tokens: 434944000.0 | grad norm avg: 13.38 | grad norm last: 12.8 | 
2025-12-28T03:54:03 | step: 849600 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.6370076991734095e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.55 | consumed tokens: 434995200.0 | grad norm avg: 12.65 | grad norm last: 11.2 | 
2025-12-28T03:54:05 | step: 849700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.6362921087420546e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.06 | consumed tokens: 435046400.0 | grad norm avg: 12.75 | grad norm last: 12.25 | 
2025-12-28T03:54:07 | step: 849800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.6355768821085803e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.88 | consumed tokens: 435097600.0 | grad norm avg: 13.31 | grad norm last: 17.67 | 
2025-12-28T03:54:09 | step: 849900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.6348620192729868e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.41 | consumed tokens: 435148800.0 | grad norm avg: 12.87 | grad norm last: 12.84 | 
2025-12-28T03:54:11 | step: 850000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.634147520235274e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 5.03 | consumed tokens: 435200000.0 | grad norm avg: 13.1 | grad norm last: 15.22 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_850000-seen_tokens_435200000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_850000-seen_tokens_435200000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_850000-seen_tokens_435200000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_850000-seen_tokens_435200000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_850000-seen_tokens_435200000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_850000-seen_tokens_435200000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_850000-seen_tokens_435200000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_850000-seen_tokens_435200000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:54:13 | step: 850100 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.633433384995442e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.56 | consumed tokens: 435251200.0 | grad norm avg: 13.04 | grad norm last: 12.21 | 
2025-12-28T03:54:15 | step: 850200 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 1.6327196135534905e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.06 | consumed tokens: 435302400.0 | grad norm avg: 13.31 | grad norm last: 18.97 | 
2025-12-28T03:54:17 | step: 850300 | train samples/s: 103.8 | train mfu (16-bit): -1.0 | lr mean: 1.63200638780836e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.06 | consumed tokens: 435353600.0 | grad norm avg: 12.93 | grad norm last: 13.6 | 
2025-12-28T03:54:20 | step: 850400 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 1.6312933439621702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.36 | consumed tokens: 435404800.0 | grad norm avg: 13.11 | grad norm last: 12.15 | 
2025-12-28T03:54:22 | step: 850500 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.630580663913861e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.55 | consumed tokens: 435456000.0 | grad norm avg: 13.08 | grad norm last: 13.48 | 
2025-12-28T03:54:24 | step: 850600 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 1.6298685295623727e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.81 | consumed tokens: 435507200.0 | grad norm avg: 12.72 | grad norm last: 11.47 | 
2025-12-28T03:54:26 | step: 850700 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 1.629156577109825e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.81 | consumed tokens: 435558400.0 | grad norm avg: 13.1 | grad norm last: 13.41 | 
2025-12-28T03:54:28 | step: 850800 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.6284449884551577e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.08 | consumed tokens: 435609600.0 | grad norm avg: 13.06 | grad norm last: 11.35 | 
2025-12-28T03:54:30 | step: 850900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.6277339454973117e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.08 | consumed tokens: 435660800.0 | grad norm avg: 12.47 | grad norm last: 12.39 | 
2025-12-28T03:54:32 | step: 851000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.6270232663373463e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.19 | consumed tokens: 435712000.0 | grad norm avg: 13.33 | grad norm last: 12.48 | 
2025-12-28T03:54:34 | step: 851100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.6263127690763213e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.41 | consumed tokens: 435763200.0 | grad norm avg: 12.91 | grad norm last: 11.62 | 
2025-12-28T03:54:36 | step: 851200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.6256028175121173e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.03 | consumed tokens: 435814400.0 | grad norm avg: 13.13 | grad norm last: 14.02 | 
2025-12-28T03:54:38 | step: 851300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.624893229745794e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.66 | consumed tokens: 435865600.0 | grad norm avg: 13.0 | grad norm last: 14.53 | 
2025-12-28T03:54:40 | step: 851400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.6241838238784112e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.78 | consumed tokens: 435916800.0 | grad norm avg: 12.64 | grad norm last: 17.58 | 
2025-12-28T03:54:42 | step: 851500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.6234749637078494e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.31 | consumed tokens: 435968000.0 | grad norm avg: 12.8 | grad norm last: 12.47 | 
2025-12-28T03:54:44 | step: 851600 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.6227664673351683e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.86 | consumed tokens: 436019200.0 | grad norm avg: 13.07 | grad norm last: 11.51 | 
2025-12-28T03:54:46 | step: 851700 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 1.622058334760368e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.8 | consumed tokens: 436070400.0 | grad norm avg: 12.68 | grad norm last: 16.39 | 
2025-12-28T03:54:48 | step: 851800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.6213505659834482e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 2.94 | consumed tokens: 436121600.0 | grad norm avg: 13.25 | grad norm last: 10.63 | 
2025-12-28T03:54:50 | step: 851900 | train samples/s: 104.3 | train mfu (16-bit): -1.0 | lr mean: 1.6206431610044092e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.33 | consumed tokens: 436172800.0 | grad norm avg: 13.19 | grad norm last: 12.0 | 
2025-12-28T03:54:52 | step: 852000 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 1.619936119823251e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.16 | consumed tokens: 436224000.0 | grad norm avg: 13.01 | grad norm last: 14.08 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_852000-seen_tokens_436224000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_852000-seen_tokens_436224000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_852000-seen_tokens_436224000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_852000-seen_tokens_436224000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_852000-seen_tokens_436224000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_852000-seen_tokens_436224000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_852000-seen_tokens_436224000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_852000-seen_tokens_436224000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:54:55 | step: 852100 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 1.6192294424399734e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.62 | consumed tokens: 436275200.0 | grad norm avg: 13.33 | grad norm last: 11.73 | 
2025-12-28T03:54:57 | step: 852200 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.6185231288545765e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.61 | consumed tokens: 436326400.0 | grad norm avg: 13.48 | grad norm last: 15.71 | 
2025-12-28T03:54:59 | step: 852300 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.6178173609660007e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.46 | train loss last: 3.52 | consumed tokens: 436377600.0 | grad norm avg: 12.52 | grad norm last: 11.53 | 
2025-12-28T03:55:01 | step: 852400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.6171117749763653e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.45 | consumed tokens: 436428800.0 | grad norm avg: 12.94 | grad norm last: 11.27 | 
2025-12-28T03:55:03 | step: 852500 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.6164065527846105e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.09 | consumed tokens: 436480000.0 | grad norm avg: 12.86 | grad norm last: 14.17 | 
2025-12-28T03:55:05 | step: 852600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.615701876289677e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.31 | consumed tokens: 436531200.0 | grad norm avg: 12.73 | grad norm last: 11.39 | 
2025-12-28T03:55:07 | step: 852700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.6149973816936836e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.02 | consumed tokens: 436582400.0 | grad norm avg: 12.73 | grad norm last: 10.64 | 
2025-12-28T03:55:09 | step: 852800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.614293250895571e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.81 | consumed tokens: 436633600.0 | grad norm avg: 12.66 | grad norm last: 11.65 | 
2025-12-28T03:55:11 | step: 852900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.6135896657942794e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 5.12 | consumed tokens: 436684800.0 | grad norm avg: 12.7 | grad norm last: 13.43 | 
2025-12-28T03:55:13 | step: 853000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.6128864444908686e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.67 | consumed tokens: 436736000.0 | grad norm avg: 12.79 | grad norm last: 16.08 | 
2025-12-28T03:55:15 | step: 853100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.612183405086398e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.38 | consumed tokens: 436787200.0 | grad norm avg: 12.98 | grad norm last: 11.35 | 
2025-12-28T03:55:17 | step: 853200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.6114809113787487e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.91 | consumed tokens: 436838400.0 | grad norm avg: 12.9 | grad norm last: 13.51 | 
2025-12-28T03:55:19 | step: 853300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.61077878146898e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.97 | consumed tokens: 436889600.0 | grad norm avg: 12.36 | grad norm last: 12.0 | 
2025-12-28T03:55:21 | step: 853400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.610077015357092e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.53 | consumed tokens: 436940800.0 | grad norm avg: 13.32 | grad norm last: 12.69 | 
2025-12-28T03:55:23 | step: 853500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.6093754311441444e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.48 | consumed tokens: 436992000.0 | grad norm avg: 13.2 | grad norm last: 14.59 | 
2025-12-28T03:55:25 | step: 853600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.6086743926280178e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.38 | consumed tokens: 437043200.0 | grad norm avg: 12.65 | grad norm last: 12.33 | 
2025-12-28T03:55:27 | step: 853700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.607973717909772e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.66 | consumed tokens: 437094400.0 | grad norm avg: 12.69 | grad norm last: 13.36 | 
2025-12-28T03:55:29 | step: 853800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.6072734069894068e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.56 | consumed tokens: 437145600.0 | grad norm avg: 13.27 | grad norm last: 13.2 | 
2025-12-28T03:55:31 | step: 853900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.6065736417658627e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.52 | consumed tokens: 437196800.0 | grad norm avg: 12.87 | grad norm last: 11.59 | 
2025-12-28T03:55:33 | step: 854000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.605874058441259e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.0 | consumed tokens: 437248000.0 | grad norm avg: 12.58 | grad norm last: 12.46 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_854000-seen_tokens_437248000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_854000-seen_tokens_437248000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_854000-seen_tokens_437248000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_854000-seen_tokens_437248000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_854000-seen_tokens_437248000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_854000-seen_tokens_437248000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_854000-seen_tokens_437248000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_854000-seen_tokens_437248000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:55:36 | step: 854100 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.605174838914536e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.7 | train loss last: 3.23 | consumed tokens: 437299200.0 | grad norm avg: 12.98 | grad norm last: 10.91 | 
2025-12-28T03:55:38 | step: 854200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.6044759831856936e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 4.09 | consumed tokens: 437350400.0 | grad norm avg: 12.55 | grad norm last: 15.46 | 
2025-12-28T03:55:40 | step: 854300 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 1.6037776731536724e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.47 | train loss last: 3.5 | consumed tokens: 437401600.0 | grad norm avg: 12.46 | grad norm last: 13.23 | 
2025-12-28T03:55:42 | step: 854400 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.6030795450205915e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.2 | consumed tokens: 437452800.0 | grad norm avg: 13.2 | grad norm last: 12.32 | 
2025-12-28T03:55:44 | step: 854500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.6023817806853913e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.55 | consumed tokens: 437504000.0 | grad norm avg: 12.94 | grad norm last: 13.62 | 
2025-12-28T03:55:46 | step: 854600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.601684562047012e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.17 | consumed tokens: 437555200.0 | grad norm avg: 13.31 | grad norm last: 10.69 | 
2025-12-28T03:55:48 | step: 854700 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 1.6009877072065137e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.84 | consumed tokens: 437606400.0 | grad norm avg: 12.69 | grad norm last: 12.24 | 
2025-12-28T03:55:50 | step: 854800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.6002910342649557e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.34 | consumed tokens: 437657600.0 | grad norm avg: 13.66 | grad norm last: 13.57 | 
2025-12-28T03:55:52 | step: 854900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.5995949070202187e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.08 | consumed tokens: 437708800.0 | grad norm avg: 13.11 | grad norm last: 9.81 | 
2025-12-28T03:55:54 | step: 855000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.5988991435733624e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.0 | consumed tokens: 437760000.0 | grad norm avg: 13.05 | grad norm last: 11.5 | 
2025-12-28T03:55:56 | step: 855100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.5982037439243868e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.48 | consumed tokens: 437811200.0 | grad norm avg: 12.59 | grad norm last: 10.96 | 
2025-12-28T03:55:58 | step: 855200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.5975085261743516e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.2 | consumed tokens: 437862400.0 | grad norm avg: 12.7 | grad norm last: 11.64 | 
2025-12-28T03:56:00 | step: 855300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.5968138541211374e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.69 | consumed tokens: 437913600.0 | grad norm avg: 12.87 | grad norm last: 14.87 | 
2025-12-28T03:56:02 | step: 855400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.596119545865804e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.42 | consumed tokens: 437964800.0 | grad norm avg: 12.78 | grad norm last: 14.39 | 
2025-12-28T03:56:04 | step: 855500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.5954256014083512e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 2.83 | consumed tokens: 438016000.0 | grad norm avg: 12.54 | grad norm last: 11.08 | 
2025-12-28T03:56:06 | step: 855600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.5947322026477195e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.88 | consumed tokens: 438067200.0 | grad norm avg: 12.71 | grad norm last: 14.03 | 
2025-12-28T03:56:08 | step: 855700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.5940389857860282e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.25 | consumed tokens: 438118400.0 | grad norm avg: 13.26 | grad norm last: 13.64 | 
2025-12-28T03:56:10 | step: 855800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.5933461327222176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.69 | consumed tokens: 438169600.0 | grad norm avg: 13.23 | grad norm last: 18.12 | 
2025-12-28T03:56:12 | step: 855900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.5926536434562877e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.66 | consumed tokens: 438220800.0 | grad norm avg: 12.87 | grad norm last: 11.36 | 
2025-12-28T03:56:14 | step: 856000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.591961699887179e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.53 | consumed tokens: 438272000.0 | grad norm avg: 12.73 | grad norm last: 14.13 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_856000-seen_tokens_438272000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_856000-seen_tokens_438272000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_856000-seen_tokens_438272000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_856000-seen_tokens_438272000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_856000-seen_tokens_438272000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_856000-seen_tokens_438272000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_856000-seen_tokens_438272000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_856000-seen_tokens_438272000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:56:17 | step: 856100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.5912699382170103e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.19 | consumed tokens: 438323200.0 | grad norm avg: 13.01 | grad norm last: 13.68 | 
2025-12-28T03:56:19 | step: 856200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.590578722243663e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.73 | consumed tokens: 438374400.0 | grad norm avg: 12.72 | grad norm last: 13.19 | 
2025-12-28T03:56:21 | step: 856300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.5898878700681962e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.2 | consumed tokens: 438425600.0 | grad norm avg: 12.68 | grad norm last: 13.53 | 
2025-12-28T03:56:23 | step: 856400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.58919719979167e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.89 | consumed tokens: 438476800.0 | grad norm avg: 12.67 | grad norm last: 14.16 | 
2025-12-28T03:56:25 | step: 856500 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.5885070752119645e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.69 | consumed tokens: 438528000.0 | grad norm avg: 12.77 | grad norm last: 11.89 | 
2025-12-28T03:56:27 | step: 856600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.58781731443014e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.19 | consumed tokens: 438579200.0 | grad norm avg: 12.77 | grad norm last: 10.62 | 
2025-12-28T03:56:29 | step: 856700 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.587127917446196e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.31 | consumed tokens: 438630400.0 | grad norm avg: 12.91 | grad norm last: 14.23 | 
2025-12-28T03:56:31 | step: 856800 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.586438884260133e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 2.83 | consumed tokens: 438681600.0 | grad norm avg: 12.93 | grad norm last: 10.14 | 
2025-12-28T03:56:33 | step: 856900 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.5857502148719504e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.95 | consumed tokens: 438732800.0 | grad norm avg: 13.32 | grad norm last: 13.04 | 
2025-12-28T03:56:35 | step: 857000 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 1.5850619092816487e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.39 | consumed tokens: 438784000.0 | grad norm avg: 12.86 | grad norm last: 11.21 | 
2025-12-28T03:56:37 | step: 857100 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.5843739674892277e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.81 | consumed tokens: 438835200.0 | grad norm avg: 12.36 | grad norm last: 17.48 | 
2025-12-28T03:56:39 | step: 857200 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.5836863894946873e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.8 | consumed tokens: 438886400.0 | grad norm avg: 12.65 | grad norm last: 12.77 | 
2025-12-28T03:56:41 | step: 857300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.5829991752980277e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.19 | consumed tokens: 438937600.0 | grad norm avg: 12.79 | grad norm last: 13.02 | 
2025-12-28T03:56:43 | step: 857400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.582312506798189e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.98 | consumed tokens: 438988800.0 | grad norm avg: 12.73 | grad norm last: 15.61 | 
2025-12-28T03:56:45 | step: 857500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.581626020197291e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.84 | consumed tokens: 439040000.0 | grad norm avg: 13.19 | grad norm last: 12.54 | 
2025-12-28T03:56:47 | step: 857600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.5809400792932138e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.72 | consumed tokens: 439091200.0 | grad norm avg: 12.53 | grad norm last: 13.38 | 
2025-12-28T03:56:49 | step: 857700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.580254320288077e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.09 | consumed tokens: 439142400.0 | grad norm avg: 12.89 | grad norm last: 11.78 | 
2025-12-28T03:56:51 | step: 857800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.5795691069797613e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 6.03 | consumed tokens: 439193600.0 | grad norm avg: 12.72 | grad norm last: 29.45 | 
2025-12-28T03:56:54 | step: 857900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.5788842574693263e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.95 | consumed tokens: 439244800.0 | grad norm avg: 12.93 | grad norm last: 13.34 | 
2025-12-28T03:56:56 | step: 858000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.578199771756772e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.08 | consumed tokens: 439296000.0 | grad norm avg: 12.6 | grad norm last: 13.44 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_858000-seen_tokens_439296000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_858000-seen_tokens_439296000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_858000-seen_tokens_439296000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_858000-seen_tokens_439296000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_858000-seen_tokens_439296000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_858000-seen_tokens_439296000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_858000-seen_tokens_439296000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_858000-seen_tokens_439296000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:56:58 | step: 858100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.577515467943158e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.5 | train loss last: 2.8 | consumed tokens: 439347200.0 | grad norm avg: 12.56 | grad norm last: 10.45 | 
2025-12-28T03:57:00 | step: 858200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.576831709826365e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 2.91 | consumed tokens: 439398400.0 | grad norm avg: 13.19 | grad norm last: 11.42 | 
2025-12-28T03:57:02 | step: 858300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.576148315507453e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.59 | consumed tokens: 439449600.0 | grad norm avg: 12.35 | grad norm last: 12.35 | 
2025-12-28T03:57:04 | step: 858400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.5754654668853618e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 5.22 | consumed tokens: 439500800.0 | grad norm avg: 12.57 | grad norm last: 14.31 | 
2025-12-28T03:57:06 | step: 858500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.574782800162211e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.89 | consumed tokens: 439552000.0 | grad norm avg: 12.61 | grad norm last: 9.79 | 
2025-12-28T03:57:08 | step: 858600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.574100497236941e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.34 | consumed tokens: 439603200.0 | grad norm avg: 12.69 | grad norm last: 12.83 | 
2025-12-28T03:57:10 | step: 858700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.5734185581095517e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.19 | consumed tokens: 439654400.0 | grad norm avg: 12.51 | grad norm last: 11.5 | 
2025-12-28T03:57:12 | step: 858800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.5727371646789834e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.72 | consumed tokens: 439705600.0 | grad norm avg: 12.68 | grad norm last: 13.02 | 
2025-12-28T03:57:14 | step: 858900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.5720559531473555e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.09 | consumed tokens: 439756800.0 | grad norm avg: 12.71 | grad norm last: 15.07 | 
2025-12-28T03:57:16 | step: 859000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.5713752873125486e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.31 | consumed tokens: 439808000.0 | grad norm avg: 12.6 | grad norm last: 11.59 | 
2025-12-28T03:57:18 | step: 859100 | train samples/s: 97.8 | train mfu (16-bit): -1.0 | lr mean: 1.570694803376682e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.12 | consumed tokens: 439859200.0 | grad norm avg: 13.36 | grad norm last: 12.87 | 
2025-12-28T03:57:20 | step: 859200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.5700148651376367e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.84 | consumed tokens: 439910400.0 | grad norm avg: 13.11 | grad norm last: 12.36 | 
2025-12-28T03:57:22 | step: 859300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.569335290696472e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.59 | consumed tokens: 439961600.0 | grad norm avg: 13.02 | grad norm last: 13.41 | 
2025-12-28T03:57:24 | step: 859400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.568656080053188e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.55 | consumed tokens: 440012800.0 | grad norm avg: 12.91 | grad norm last: 13.13 | 
2025-12-28T03:57:26 | step: 859500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.5679772332077846e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.39 | consumed tokens: 440064000.0 | grad norm avg: 13.12 | grad norm last: 12.33 | 
2025-12-28T03:57:29 | step: 859600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.567298750160262e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.3 | consumed tokens: 440115200.0 | grad norm avg: 12.63 | grad norm last: 11.78 | 
2025-12-28T03:57:31 | step: 859700 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 1.56662063091062e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.91 | consumed tokens: 440166400.0 | grad norm avg: 14.31 | grad norm last: 10.2 | 
2025-12-28T03:57:33 | step: 859800 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.565942875458859e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.8 | consumed tokens: 440217600.0 | grad norm avg: 12.83 | grad norm last: 11.39 | 
2025-12-28T03:57:35 | step: 859900 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 1.5652654838049784e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.5 | consumed tokens: 440268800.0 | grad norm avg: 12.87 | grad norm last: 16.2 | 
2025-12-28T03:57:37 | step: 860000 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.564588637847919e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 2.98 | consumed tokens: 440320000.0 | grad norm avg: 12.55 | grad norm last: 12.93 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_860000-seen_tokens_440320000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_860000-seen_tokens_440320000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_860000-seen_tokens_440320000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_860000-seen_tokens_440320000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_860000-seen_tokens_440320000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_860000-seen_tokens_440320000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_860000-seen_tokens_440320000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_860000-seen_tokens_440320000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:57:39 | step: 860100 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.5639119737898e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.44 | train loss last: 3.0 | consumed tokens: 440371200.0 | grad norm avg: 12.28 | grad norm last: 11.58 | 
2025-12-28T03:57:41 | step: 860200 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.563235855428502e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.59 | consumed tokens: 440422400.0 | grad norm avg: 12.84 | grad norm last: 11.75 | 
2025-12-28T03:57:43 | step: 860300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.5625599189661443e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 2.97 | consumed tokens: 440473600.0 | grad norm avg: 12.46 | grad norm last: 10.52 | 
2025-12-28T03:57:45 | step: 860400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.5618845282006077e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.75 | consumed tokens: 440524800.0 | grad norm avg: 12.77 | grad norm last: 14.87 | 
2025-12-28T03:57:47 | step: 860500 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.561209501232952e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.23 | consumed tokens: 440576000.0 | grad norm avg: 12.31 | grad norm last: 11.48 | 
2025-12-28T03:57:49 | step: 860600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.5605348380631767e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.19 | consumed tokens: 440627200.0 | grad norm avg: 12.8 | grad norm last: 11.15 | 
2025-12-28T03:57:51 | step: 860700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.559860356792342e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.12 | consumed tokens: 440678400.0 | grad norm avg: 12.35 | grad norm last: 13.71 | 
2025-12-28T03:57:53 | step: 860800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.5591864212183282e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.48 | consumed tokens: 440729600.0 | grad norm avg: 12.98 | grad norm last: 13.06 | 
2025-12-28T03:57:55 | step: 860900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.5585130313411355e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.59 | consumed tokens: 440780800.0 | grad norm avg: 12.74 | grad norm last: 16.75 | 
2025-12-28T03:57:57 | step: 861000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.5578398233628832e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.69 | consumed tokens: 440832000.0 | grad norm avg: 12.83 | grad norm last: 12.15 | 
2025-12-28T03:57:59 | step: 861100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.5571669791825116e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.11 | consumed tokens: 440883200.0 | grad norm avg: 12.66 | grad norm last: 11.39 | 
2025-12-28T03:58:02 | step: 861200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.5564944988000207e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.81 | consumed tokens: 440934400.0 | grad norm avg: 12.89 | grad norm last: 12.78 | 
2025-12-28T03:58:04 | step: 861300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.5558225641143508e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.44 | consumed tokens: 440985600.0 | grad norm avg: 12.64 | grad norm last: 14.41 | 
2025-12-28T03:58:06 | step: 861400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.5551508113276213e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.19 | consumed tokens: 441036800.0 | grad norm avg: 12.43 | grad norm last: 11.81 | 
2025-12-28T03:58:08 | step: 861500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.554479604237713e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.17 | consumed tokens: 441088000.0 | grad norm avg: 12.79 | grad norm last: 12.42 | 
2025-12-28T03:58:10 | step: 861600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.5538087609456852e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.3 | consumed tokens: 441139200.0 | grad norm avg: 12.62 | grad norm last: 11.46 | 
2025-12-28T03:58:12 | step: 861700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.553138099552598e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.59 | consumed tokens: 441190400.0 | grad norm avg: 12.7 | grad norm last: 12.44 | 
2025-12-28T03:58:14 | step: 861800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.5524679838563316e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.58 | consumed tokens: 441241600.0 | grad norm avg: 12.48 | grad norm last: 11.32 | 
2025-12-28T03:58:16 | step: 861900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.551798231957946e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.06 | consumed tokens: 441292800.0 | grad norm avg: 12.8 | grad norm last: 11.85 | 
2025-12-28T03:58:18 | step: 862000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.551128843857441e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.09 | consumed tokens: 441344000.0 | grad norm avg: 13.14 | grad norm last: 12.45 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_862000-seen_tokens_441344000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_862000-seen_tokens_441344000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_862000-seen_tokens_441344000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_862000-seen_tokens_441344000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_862000-seen_tokens_441344000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_862000-seen_tokens_441344000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_862000-seen_tokens_441344000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_862000-seen_tokens_441344000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:58:20 | step: 862100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.550459819554817e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.61 | train loss last: 4.09 | consumed tokens: 441395200.0 | grad norm avg: 12.77 | grad norm last: 12.91 | 
2025-12-28T03:58:22 | step: 862200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.5497911590500735e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.44 | consumed tokens: 441446400.0 | grad norm avg: 12.71 | grad norm last: 12.11 | 
2025-12-28T03:58:24 | step: 862300 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.549123044242151e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.72 | consumed tokens: 441497600.0 | grad norm avg: 12.8 | grad norm last: 12.58 | 
2025-12-28T03:58:26 | step: 862400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.548455111333169e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.69 | consumed tokens: 441548800.0 | grad norm avg: 12.7 | grad norm last: 12.39 | 
2025-12-28T03:58:28 | step: 862500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.547787724121008e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.34 | consumed tokens: 441600000.0 | grad norm avg: 12.68 | grad norm last: 10.95 | 
2025-12-28T03:58:30 | step: 862600 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 1.5471205188077874e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.39 | consumed tokens: 441651200.0 | grad norm avg: 12.66 | grad norm last: 12.24 | 
2025-12-28T03:58:32 | step: 862700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.546453859191388e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.59 | consumed tokens: 441702400.0 | grad norm avg: 12.67 | grad norm last: 11.96 | 
2025-12-28T03:58:34 | step: 862800 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.545787563372869e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.16 | consumed tokens: 441753600.0 | grad norm avg: 13.05 | grad norm last: 16.49 | 
2025-12-28T03:58:36 | step: 862900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.5451214494532906e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.72 | consumed tokens: 441804800.0 | grad norm avg: 13.24 | grad norm last: 13.45 | 
2025-12-28T03:58:38 | step: 863000 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.544455881230533e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.52 | consumed tokens: 441856000.0 | grad norm avg: 12.52 | grad norm last: 18.61 | 
2025-12-28T03:58:41 | step: 863100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.5437906768056564e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.25 | consumed tokens: 441907200.0 | grad norm avg: 12.65 | grad norm last: 11.54 | 
2025-12-28T03:58:43 | step: 863200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.5431258361786604e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.75 | consumed tokens: 441958400.0 | grad norm avg: 12.7 | grad norm last: 11.8 | 
2025-12-28T03:58:45 | step: 863300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.5424615412484854e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.02 | consumed tokens: 442009600.0 | grad norm avg: 12.79 | grad norm last: 11.25 | 
2025-12-28T03:58:47 | step: 863400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.541797428217251e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.94 | consumed tokens: 442060800.0 | grad norm avg: 12.91 | grad norm last: 12.69 | 
2025-12-28T03:58:49 | step: 863500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.541133678983897e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.41 | consumed tokens: 442112000.0 | grad norm avg: 12.72 | grad norm last: 12.48 | 
2025-12-28T03:58:51 | step: 863600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.540470475447364e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.28 | consumed tokens: 442163200.0 | grad norm avg: 12.6 | grad norm last: 13.97 | 
2025-12-28T03:58:53 | step: 863700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.5398074538097717e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.19 | consumed tokens: 442214400.0 | grad norm avg: 12.87 | grad norm last: 13.17 | 
2025-12-28T03:58:55 | step: 863800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.5391449778690003e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.48 | consumed tokens: 442265600.0 | grad norm avg: 12.36 | grad norm last: 13.34 | 
2025-12-28T03:58:57 | step: 863900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.5384828657261096e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 2.83 | consumed tokens: 442316800.0 | grad norm avg: 12.63 | grad norm last: 10.71 | 
2025-12-28T03:58:59 | step: 864000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.5378211173810996e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.34 | consumed tokens: 442368000.0 | grad norm avg: 12.71 | grad norm last: 13.0 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_864000-seen_tokens_442368000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_864000-seen_tokens_442368000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_864000-seen_tokens_442368000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_864000-seen_tokens_442368000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_864000-seen_tokens_442368000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_864000-seen_tokens_442368000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_864000-seen_tokens_442368000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_864000-seen_tokens_442368000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:59:01 | step: 864100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.5371597328339703e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.63 | train loss last: 3.52 | consumed tokens: 442419200.0 | grad norm avg: 12.79 | grad norm last: 12.08 | 
2025-12-28T03:59:03 | step: 864200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.5364987120847218e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.98 | consumed tokens: 442470400.0 | grad norm avg: 12.89 | grad norm last: 10.12 | 
2025-12-28T03:59:05 | step: 864300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.535838055133354e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.91 | consumed tokens: 442521600.0 | grad norm avg: 13.19 | grad norm last: 14.19 | 
2025-12-28T03:59:07 | step: 864400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.5351777619798668e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.0 | consumed tokens: 442572800.0 | grad norm avg: 12.28 | grad norm last: 11.34 | 
2025-12-28T03:59:09 | step: 864500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.5345178326242603e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 4.38 | consumed tokens: 442624000.0 | grad norm avg: 12.58 | grad norm last: 15.53 | 
2025-12-28T03:59:11 | step: 864600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.533858448965475e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.38 | consumed tokens: 442675200.0 | grad norm avg: 12.57 | grad norm last: 12.22 | 
2025-12-28T03:59:13 | step: 864700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.53319924720563e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.55 | consumed tokens: 442726400.0 | grad norm avg: 13.09 | grad norm last: 11.91 | 
2025-12-28T03:59:15 | step: 864800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.532540591142606e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.12 | consumed tokens: 442777600.0 | grad norm avg: 12.5 | grad norm last: 14.38 | 
2025-12-28T03:59:17 | step: 864900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.5318822988774627e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 5.31 | consumed tokens: 442828800.0 | grad norm avg: 12.7 | grad norm last: 23.67 | 
2025-12-28T03:59:19 | step: 865000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.53122418851126e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 2.88 | consumed tokens: 442880000.0 | grad norm avg: 12.83 | grad norm last: 11.16 | 
2025-12-28T03:59:21 | step: 865100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.530566623841878e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.94 | consumed tokens: 442931200.0 | grad norm avg: 12.75 | grad norm last: 14.18 | 
2025-12-28T03:59:23 | step: 865200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.529909422970377e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.19 | consumed tokens: 442982400.0 | grad norm avg: 12.72 | grad norm last: 12.34 | 
2025-12-28T03:59:25 | step: 865300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.5292525858967565e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.27 | consumed tokens: 443033600.0 | grad norm avg: 12.63 | grad norm last: 12.28 | 
2025-12-28T03:59:27 | step: 865400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.528596294519957e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.28 | consumed tokens: 443084800.0 | grad norm avg: 12.92 | grad norm last: 11.6 | 
2025-12-28T03:59:30 | step: 865500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.527940185042098e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.34 | consumed tokens: 443136000.0 | grad norm avg: 12.56 | grad norm last: 13.76 | 
2025-12-28T03:59:32 | step: 865600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.52728443936212e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.41 | consumed tokens: 443187200.0 | grad norm avg: 12.47 | grad norm last: 11.95 | 
2025-12-28T03:59:34 | step: 865700 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.5266292393789627e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.61 | consumed tokens: 443238400.0 | grad norm avg: 13.06 | grad norm last: 13.4 | 
2025-12-28T03:59:36 | step: 865800 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.525974403193686e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.58 | consumed tokens: 443289600.0 | grad norm avg: 13.04 | grad norm last: 12.55 | 
2025-12-28T03:59:38 | step: 865900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.5253198398568202e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.98 | consumed tokens: 443340800.0 | grad norm avg: 12.69 | grad norm last: 18.96 | 
2025-12-28T03:59:40 | step: 866000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.5246656403178349e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.34 | consumed tokens: 443392000.0 | grad norm avg: 12.83 | grad norm last: 11.51 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_866000-seen_tokens_443392000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_866000-seen_tokens_443392000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_866000-seen_tokens_443392000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_866000-seen_tokens_443392000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_866000-seen_tokens_443392000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_866000-seen_tokens_443392000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_866000-seen_tokens_443392000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_866000-seen_tokens_443392000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T03:59:42 | step: 866100 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 1.5240118955262005e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 3.45 | consumed tokens: 443443200.0 | grad norm avg: 12.66 | grad norm last: 11.28 | 
2025-12-28T03:59:44 | step: 866200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.5233585145324469e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.5 | consumed tokens: 443494400.0 | grad norm avg: 12.59 | grad norm last: 12.72 | 
2025-12-28T03:59:46 | step: 866300 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.5227054973365739e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.61 | consumed tokens: 443545600.0 | grad norm avg: 12.67 | grad norm last: 11.68 | 
2025-12-28T03:59:48 | step: 866400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.5220529348880518e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.22 | consumed tokens: 443596800.0 | grad norm avg: 12.79 | grad norm last: 14.62 | 
2025-12-28T03:59:50 | step: 866500 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.5214006452879403e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.41 | consumed tokens: 443648000.0 | grad norm avg: 12.45 | grad norm last: 12.54 | 
2025-12-28T03:59:52 | step: 866600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.5207489013846498e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.58 | consumed tokens: 443699200.0 | grad norm avg: 12.82 | grad norm last: 15.07 | 
2025-12-28T03:59:54 | step: 866700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.5200973393802997e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.95 | consumed tokens: 443750400.0 | grad norm avg: 12.52 | grad norm last: 11.28 | 
2025-12-28T03:59:56 | step: 866800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.5194463230727706e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.44 | consumed tokens: 443801600.0 | grad norm avg: 12.64 | grad norm last: 11.98 | 
2025-12-28T03:59:58 | step: 866900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.5187954886641819e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.7 | consumed tokens: 443852800.0 | grad norm avg: 13.13 | grad norm last: 13.62 | 
2025-12-28T04:00:00 | step: 867000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.5181452909018844e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.38 | consumed tokens: 443904000.0 | grad norm avg: 12.98 | grad norm last: 11.68 | 
2025-12-28T04:00:03 | step: 867100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.5174952750385273e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.19 | consumed tokens: 443955200.0 | grad norm avg: 13.09 | grad norm last: 11.8 | 
2025-12-28T04:00:05 | step: 867200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.5168458048719913e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 5.38 | consumed tokens: 444006400.0 | grad norm avg: 12.93 | grad norm last: 20.3 | 
2025-12-28T04:00:07 | step: 867300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.5161965166043956e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.09 | consumed tokens: 444057600.0 | grad norm avg: 12.73 | grad norm last: 11.92 | 
2025-12-28T04:00:09 | step: 867400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.5155478649830911e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.23 | consumed tokens: 444108800.0 | grad norm avg: 12.86 | grad norm last: 10.92 | 
2025-12-28T04:00:11 | step: 867500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.5148994862101972e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.64 | consumed tokens: 444160000.0 | grad norm avg: 13.04 | grad norm last: 11.76 | 
2025-12-28T04:00:13 | step: 867600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.514251471235184e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.3 | consumed tokens: 444211200.0 | grad norm avg: 12.67 | grad norm last: 12.92 | 
2025-12-28T04:00:15 | step: 867700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.5136039110075217e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.34 | consumed tokens: 444262400.0 | grad norm avg: 12.86 | grad norm last: 14.91 | 
2025-12-28T04:00:17 | step: 867800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.5129565326787997e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 5.16 | consumed tokens: 444313600.0 | grad norm avg: 12.95 | grad norm last: 14.14 | 
2025-12-28T04:00:19 | step: 867900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.5123097000468988e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.56 | consumed tokens: 444364800.0 | grad norm avg: 12.56 | grad norm last: 19.52 | 
2025-12-28T04:00:21 | step: 868000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.5116632312128786e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.73 | consumed tokens: 444416000.0 | grad norm avg: 12.72 | grad norm last: 15.1 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_868000-seen_tokens_444416000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_868000-seen_tokens_444416000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_868000-seen_tokens_444416000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_868000-seen_tokens_444416000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_868000-seen_tokens_444416000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_868000-seen_tokens_444416000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_868000-seen_tokens_444416000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_868000-seen_tokens_444416000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:00:23 | step: 868100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.5110171261767391e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.6 | train loss last: 3.64 | consumed tokens: 444467200.0 | grad norm avg: 13.14 | grad norm last: 11.35 | 
2025-12-28T04:00:25 | step: 868200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.5103713849384803e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.0 | consumed tokens: 444518400.0 | grad norm avg: 13.08 | grad norm last: 12.37 | 
2025-12-28T04:00:27 | step: 868300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.5097260074981023e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.83 | consumed tokens: 444569600.0 | grad norm avg: 13.11 | grad norm last: 10.24 | 
2025-12-28T04:00:29 | step: 868400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.5090811757545453e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.86 | consumed tokens: 444620800.0 | grad norm avg: 12.44 | grad norm last: 11.71 | 
2025-12-28T04:00:31 | step: 868500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.5084365259099286e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.09 | consumed tokens: 444672000.0 | grad norm avg: 12.86 | grad norm last: 10.74 | 
2025-12-28T04:00:33 | step: 868600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.5077923308126628e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.22 | consumed tokens: 444723200.0 | grad norm avg: 12.63 | grad norm last: 10.57 | 
2025-12-28T04:00:35 | step: 868700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.5071486814122181e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 5.53 | consumed tokens: 444774400.0 | grad norm avg: 12.52 | grad norm last: 16.83 | 
2025-12-28T04:00:37 | step: 868800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.5065051229612436e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.42 | consumed tokens: 444825600.0 | grad norm avg: 12.8 | grad norm last: 11.39 | 
2025-12-28T04:00:39 | step: 868900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.5058621102070902e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.92 | consumed tokens: 444876800.0 | grad norm avg: 13.11 | grad norm last: 12.5 | 
2025-12-28T04:00:41 | step: 869000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.5052194612508174e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 2.84 | consumed tokens: 444928000.0 | grad norm avg: 12.92 | grad norm last: 11.12 | 
2025-12-28T04:00:43 | step: 869100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.5045771760924254e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.81 | consumed tokens: 444979200.0 | grad norm avg: 13.18 | grad norm last: 11.89 | 
2025-12-28T04:00:45 | step: 869200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.5039353456813842e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 2.84 | consumed tokens: 445030400.0 | grad norm avg: 12.9 | grad norm last: 11.17 | 
2025-12-28T04:00:47 | step: 869300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.5032938790682238e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.55 | consumed tokens: 445081600.0 | grad norm avg: 12.8 | grad norm last: 13.76 | 
2025-12-28T04:00:49 | step: 869400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.5026526853034738e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.94 | consumed tokens: 445132800.0 | grad norm avg: 12.92 | grad norm last: 16.16 | 
2025-12-28T04:00:51 | step: 869500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.502012037235545e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.23 | consumed tokens: 445184000.0 | grad norm avg: 12.61 | grad norm last: 11.71 | 
2025-12-28T04:00:53 | step: 869600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.5013716620160267e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 2.92 | consumed tokens: 445235200.0 | grad norm avg: 12.8 | grad norm last: 10.74 | 
2025-12-28T04:00:56 | step: 869700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.5007317415438592e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.73 | consumed tokens: 445286400.0 | grad norm avg: 13.07 | grad norm last: 12.18 | 
2025-12-28T04:00:58 | step: 869800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.5000920939201023e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.84 | consumed tokens: 445337600.0 | grad norm avg: 13.06 | grad norm last: 15.03 | 
2025-12-28T04:01:00 | step: 869900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.4994529919931665e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.75 | consumed tokens: 445388800.0 | grad norm avg: 12.66 | grad norm last: 13.16 | 
2025-12-28T04:01:02 | step: 870000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.4988141629146412e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 5.25 | consumed tokens: 445440000.0 | grad norm avg: 12.95 | grad norm last: 18.57 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_870000-seen_tokens_445440000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_870000-seen_tokens_445440000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_870000-seen_tokens_445440000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_870000-seen_tokens_445440000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_870000-seen_tokens_445440000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_870000-seen_tokens_445440000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_870000-seen_tokens_445440000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_870000-seen_tokens_445440000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:01:04 | step: 870100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.4981756976339966e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 2.98 | consumed tokens: 445491200.0 | grad norm avg: 12.49 | grad norm last: 14.12 | 
2025-12-28T04:01:06 | step: 870200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.4975376871007029e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.77 | consumed tokens: 445542400.0 | grad norm avg: 12.94 | grad norm last: 11.37 | 
2025-12-28T04:01:08 | step: 870300 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.4968999494158197e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.25 | consumed tokens: 445593600.0 | grad norm avg: 13.03 | grad norm last: 11.69 | 
2025-12-28T04:01:10 | step: 870400 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.4962627574277576e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.0 | consumed tokens: 445644800.0 | grad norm avg: 12.75 | grad norm last: 13.54 | 
2025-12-28T04:01:12 | step: 870500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.4956259292375762e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.17 | consumed tokens: 445696000.0 | grad norm avg: 13.15 | grad norm last: 12.48 | 
2025-12-28T04:01:14 | step: 870600 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.4949894648452755e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.09 | consumed tokens: 445747200.0 | grad norm avg: 13.19 | grad norm last: 11.77 | 
2025-12-28T04:01:16 | step: 870700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.4943533642508555e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.48 | consumed tokens: 445798400.0 | grad norm avg: 12.7 | grad norm last: 14.33 | 
2025-12-28T04:01:18 | step: 870800 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.4937176274543162e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.47 | consumed tokens: 445849600.0 | grad norm avg: 13.18 | grad norm last: 12.5 | 
2025-12-28T04:01:20 | step: 870900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.4930822544556577e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.03 | consumed tokens: 445900800.0 | grad norm avg: 12.77 | grad norm last: 13.57 | 
2025-12-28T04:01:22 | step: 871000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.49244733620435e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.95 | consumed tokens: 445952000.0 | grad norm avg: 12.78 | grad norm last: 10.67 | 
2025-12-28T04:01:24 | step: 871100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.491812781750923e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.44 | consumed tokens: 446003200.0 | grad norm avg: 13.36 | grad norm last: 13.28 | 
2025-12-28T04:01:26 | step: 871200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.491178682044847e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.41 | consumed tokens: 446054400.0 | grad norm avg: 12.65 | grad norm last: 11.34 | 
2025-12-28T04:01:29 | step: 871300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.4905447642377112e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.0 | consumed tokens: 446105600.0 | grad norm avg: 12.83 | grad norm last: 16.11 | 
2025-12-28T04:01:31 | step: 871400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.4899113921273965e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.61 | consumed tokens: 446156800.0 | grad norm avg: 12.69 | grad norm last: 11.67 | 
2025-12-28T04:01:33 | step: 871500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.4892783838149626e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.53 | consumed tokens: 446208000.0 | grad norm avg: 12.85 | grad norm last: 12.23 | 
2025-12-28T04:01:35 | step: 871600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.4886457393004093e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.33 | consumed tokens: 446259200.0 | grad norm avg: 12.93 | grad norm last: 12.2 | 
2025-12-28T04:01:37 | step: 871700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.4880134585837368e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 2.83 | consumed tokens: 446310400.0 | grad norm avg: 13.01 | grad norm last: 9.74 | 
2025-12-28T04:01:39 | step: 871800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.487381541664945e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.81 | consumed tokens: 446361600.0 | grad norm avg: 13.25 | grad norm last: 18.96 | 
2025-12-28T04:01:41 | step: 871900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.4867499885440338e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.34 | consumed tokens: 446412800.0 | grad norm avg: 12.62 | grad norm last: 11.8 | 
2025-12-28T04:01:43 | step: 872000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.486119072069414e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.45 | consumed tokens: 446464000.0 | grad norm avg: 12.96 | grad norm last: 12.11 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_872000-seen_tokens_446464000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_872000-seen_tokens_446464000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_872000-seen_tokens_446464000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_872000-seen_tokens_446464000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_872000-seen_tokens_446464000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_872000-seen_tokens_446464000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_872000-seen_tokens_446464000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_872000-seen_tokens_446464000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:01:45 | step: 872100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.4854883374937344e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 2.92 | consumed tokens: 446515200.0 | grad norm avg: 12.69 | grad norm last: 10.6 | 
2025-12-28T04:01:47 | step: 872200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.4848580576654058e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 2.39 | consumed tokens: 446566400.0 | grad norm avg: 12.81 | grad norm last: 12.33 | 
2025-12-28T04:01:49 | step: 872300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.4842280506854877e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.5 | consumed tokens: 446617600.0 | grad norm avg: 12.96 | grad norm last: 11.34 | 
2025-12-28T04:01:51 | step: 872400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.4835985894023906e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 2.77 | consumed tokens: 446668800.0 | grad norm avg: 12.58 | grad norm last: 10.72 | 
2025-12-28T04:01:53 | step: 872500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.4829694009677041e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.73 | consumed tokens: 446720000.0 | grad norm avg: 13.16 | grad norm last: 13.47 | 
2025-12-28T04:01:55 | step: 872600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.4823405763308983e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.06 | consumed tokens: 446771200.0 | grad norm avg: 12.98 | grad norm last: 9.8 | 
2025-12-28T04:01:57 | step: 872700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.4817121154919732e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.79 | train loss last: 3.72 | consumed tokens: 446822400.0 | grad norm avg: 13.38 | grad norm last: 14.36 | 
2025-12-28T04:01:59 | step: 872800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.4810842003498692e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.06 | consumed tokens: 446873600.0 | grad norm avg: 13.0 | grad norm last: 12.7 | 
2025-12-28T04:02:01 | step: 872900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.4804565580561757e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.66 | consumed tokens: 446924800.0 | grad norm avg: 13.33 | grad norm last: 19.04 | 
2025-12-28T04:02:03 | step: 873000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.4798293705098331e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.31 | consumed tokens: 446976000.0 | grad norm avg: 12.86 | grad norm last: 11.91 | 
2025-12-28T04:02:05 | step: 873100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.479202455811901e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.16 | consumed tokens: 447027200.0 | grad norm avg: 12.45 | grad norm last: 13.12 | 
2025-12-28T04:02:07 | step: 873200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.47857608681079e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 2.89 | consumed tokens: 447078400.0 | grad norm avg: 12.95 | grad norm last: 11.76 | 
2025-12-28T04:02:09 | step: 873300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.4779499906580895e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.61 | consumed tokens: 447129600.0 | grad norm avg: 13.15 | grad norm last: 13.51 | 
2025-12-28T04:02:11 | step: 873400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.4773242583032697e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.2 | consumed tokens: 447180800.0 | grad norm avg: 12.79 | grad norm last: 14.89 | 
2025-12-28T04:02:13 | step: 873500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.4766989806958009e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 2.75 | consumed tokens: 447232000.0 | grad norm avg: 12.97 | grad norm last: 12.14 | 
2025-12-28T04:02:15 | step: 873600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.4760739759367425e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.17 | consumed tokens: 447283200.0 | grad norm avg: 12.71 | grad norm last: 11.33 | 
2025-12-28T04:02:17 | step: 873700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.4754496078239754e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.36 | consumed tokens: 447334400.0 | grad norm avg: 12.83 | grad norm last: 12.54 | 
2025-12-28T04:02:19 | step: 873800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.4748254216101486e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.33 | consumed tokens: 447385600.0 | grad norm avg: 12.75 | grad norm last: 12.2 | 
2025-12-28T04:02:21 | step: 873900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.4742016901436727e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.88 | consumed tokens: 447436800.0 | grad norm avg: 12.84 | grad norm last: 13.27 | 
2025-12-28T04:02:23 | step: 874000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.4735783224750776e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.09 | consumed tokens: 447488000.0 | grad norm avg: 12.63 | grad norm last: 11.17 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_874000-seen_tokens_447488000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_874000-seen_tokens_447488000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_874000-seen_tokens_447488000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_874000-seen_tokens_447488000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_874000-seen_tokens_447488000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_874000-seen_tokens_447488000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_874000-seen_tokens_447488000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_874000-seen_tokens_447488000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:02:26 | step: 874100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.4729553186043631e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.67 | train loss last: 3.73 | consumed tokens: 447539200.0 | grad norm avg: 13.42 | grad norm last: 14.28 | 
2025-12-28T04:02:28 | step: 874200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.4723326785315294e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.67 | consumed tokens: 447590400.0 | grad norm avg: 12.35 | grad norm last: 13.36 | 
2025-12-28T04:02:30 | step: 874300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.4717105841555167e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 2.88 | consumed tokens: 447641600.0 | grad norm avg: 13.03 | grad norm last: 12.41 | 
2025-12-28T04:02:32 | step: 874400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.4710887626279145e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.23 | consumed tokens: 447692800.0 | grad norm avg: 13.21 | grad norm last: 13.48 | 
2025-12-28T04:02:34 | step: 874500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.4704673048981931e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.41 | consumed tokens: 447744000.0 | grad norm avg: 13.04 | grad norm last: 13.77 | 
2025-12-28T04:02:36 | step: 874600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.4698463019158226e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.89 | consumed tokens: 447795200.0 | grad norm avg: 12.74 | grad norm last: 12.95 | 
2025-12-28T04:02:38 | step: 874700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.4692256627313327e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.83 | consumed tokens: 447846400.0 | grad norm avg: 13.23 | grad norm last: 12.07 | 
2025-12-28T04:02:40 | step: 874800 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.4686053873447236e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.78 | consumed tokens: 447897600.0 | grad norm avg: 12.86 | grad norm last: 12.16 | 
2025-12-28T04:02:42 | step: 874900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.4679854757559951e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.42 | consumed tokens: 447948800.0 | grad norm avg: 13.08 | grad norm last: 12.14 | 
2025-12-28T04:02:44 | step: 875000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.4673660189146176e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.12 | consumed tokens: 448000000.0 | grad norm avg: 13.15 | grad norm last: 12.31 | 
2025-12-28T04:02:46 | step: 875100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.4667469258711208e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.7 | consumed tokens: 448051200.0 | grad norm avg: 12.88 | grad norm last: 14.5 | 
2025-12-28T04:02:48 | step: 875200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.4661282875749748e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.3 | consumed tokens: 448102400.0 | grad norm avg: 13.21 | grad norm last: 11.29 | 
2025-12-28T04:02:50 | step: 875300 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.4655099221272394e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.75 | consumed tokens: 448153600.0 | grad norm avg: 12.93 | grad norm last: 13.52 | 
2025-12-28T04:02:52 | step: 875400 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 1.4648919204773847e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.81 | consumed tokens: 448204800.0 | grad norm avg: 12.98 | grad norm last: 14.99 | 
2025-12-28T04:02:54 | step: 875500 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.4642743735748809e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.73 | consumed tokens: 448256000.0 | grad norm avg: 12.91 | grad norm last: 12.98 | 
2025-12-28T04:02:56 | step: 875600 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.4636573723691981e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.19 | consumed tokens: 448307200.0 | grad norm avg: 12.91 | grad norm last: 13.13 | 
2025-12-28T04:02:59 | step: 875700 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.4630404621129856e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.74 | train loss last: 3.48 | consumed tokens: 448358400.0 | grad norm avg: 13.42 | grad norm last: 12.07 | 
2025-12-28T04:03:01 | step: 875800 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.462424097553594e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.28 | consumed tokens: 448409600.0 | grad norm avg: 12.83 | grad norm last: 11.42 | 
2025-12-28T04:03:03 | step: 875900 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 1.461808005842613e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.44 | consumed tokens: 448460800.0 | grad norm avg: 12.95 | grad norm last: 12.34 | 
2025-12-28T04:03:05 | step: 876000 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.4611924598284531e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 2.39 | consumed tokens: 448512000.0 | grad norm avg: 12.82 | grad norm last: 11.67 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_876000-seen_tokens_448512000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_876000-seen_tokens_448512000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_876000-seen_tokens_448512000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_876000-seen_tokens_448512000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_876000-seen_tokens_448512000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_876000-seen_tokens_448512000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_876000-seen_tokens_448512000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_876000-seen_tokens_448512000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:03:07 | step: 876100 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.460577277612174e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 4.31 | consumed tokens: 448563200.0 | grad norm avg: 13.08 | grad norm last: 12.76 | 
2025-12-28T04:03:09 | step: 876200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.4599624591937754e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.55 | consumed tokens: 448614400.0 | grad norm avg: 12.94 | grad norm last: 12.24 | 
2025-12-28T04:03:11 | step: 876300 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.4593480045732576e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.92 | consumed tokens: 448665600.0 | grad norm avg: 12.89 | grad norm last: 12.53 | 
2025-12-28T04:03:13 | step: 876400 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.4587339137506206e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.56 | consumed tokens: 448716800.0 | grad norm avg: 13.03 | grad norm last: 13.61 | 
2025-12-28T04:03:15 | step: 876500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.4581203686248045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.3 | consumed tokens: 448768000.0 | grad norm avg: 13.11 | grad norm last: 11.08 | 
2025-12-28T04:03:17 | step: 876600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.4575070053979289e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.75 | consumed tokens: 448819200.0 | grad norm avg: 13.1 | grad norm last: 13.18 | 
2025-12-28T04:03:19 | step: 876700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.4568941878678743e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.66 | consumed tokens: 448870400.0 | grad norm avg: 13.16 | grad norm last: 13.45 | 
2025-12-28T04:03:21 | step: 876800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.4562817341357004e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.17 | consumed tokens: 448921600.0 | grad norm avg: 12.95 | grad norm last: 11.24 | 
2025-12-28T04:03:23 | step: 876900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.455669553251937e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.47 | train loss last: 3.27 | consumed tokens: 448972800.0 | grad norm avg: 12.75 | grad norm last: 12.15 | 
2025-12-28T04:03:25 | step: 877000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.4550579180649947e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.61 | consumed tokens: 449024000.0 | grad norm avg: 12.98 | grad norm last: 12.15 | 
2025-12-28T04:03:27 | step: 877100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.4544464647769928e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.08 | consumed tokens: 449075200.0 | grad norm avg: 13.04 | grad norm last: 11.6 | 
2025-12-28T04:03:29 | step: 877200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.453835557185812e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.36 | consumed tokens: 449126400.0 | grad norm avg: 12.79 | grad norm last: 12.01 | 
2025-12-28T04:03:31 | step: 877300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.453225104341982e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.11 | consumed tokens: 449177600.0 | grad norm avg: 13.1 | grad norm last: 11.88 | 
2025-12-28T04:03:34 | step: 877400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.4526148333970923e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.88 | consumed tokens: 449228800.0 | grad norm avg: 12.78 | grad norm last: 13.34 | 
2025-12-28T04:03:36 | step: 877500 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.4520051081490237e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.23 | consumed tokens: 449280000.0 | grad norm avg: 12.7 | grad norm last: 11.66 | 
2025-12-28T04:03:38 | step: 877600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.4513956557493657e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.03 | consumed tokens: 449331200.0 | grad norm avg: 12.95 | grad norm last: 11.73 | 
2025-12-28T04:03:40 | step: 877700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.4507866580970585e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.81 | consumed tokens: 449382400.0 | grad norm avg: 12.81 | grad norm last: 18.88 | 
2025-12-28T04:03:42 | step: 877800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.4501781151921023e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.78 | consumed tokens: 449433600.0 | grad norm avg: 12.87 | grad norm last: 12.21 | 
2025-12-28T04:03:44 | step: 877900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.4495698451355565e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 2.39 | consumed tokens: 449484800.0 | grad norm avg: 13.68 | grad norm last: 14.2 | 
2025-12-28T04:03:46 | step: 878000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.4489621207758319e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.39 | consumed tokens: 449536000.0 | grad norm avg: 13.22 | grad norm last: 11.28 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_878000-seen_tokens_449536000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_878000-seen_tokens_449536000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_878000-seen_tokens_449536000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_878000-seen_tokens_449536000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_878000-seen_tokens_449536000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_878000-seen_tokens_449536000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_878000-seen_tokens_449536000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_878000-seen_tokens_449536000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:03:48 | step: 878100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.4483545783150475e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.22 | consumed tokens: 449587200.0 | grad norm avg: 12.68 | grad norm last: 11.43 | 
2025-12-28T04:03:50 | step: 878200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.4477475815510843e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.67 | consumed tokens: 449638400.0 | grad norm avg: 13.1 | grad norm last: 13.5 | 
2025-12-28T04:03:52 | step: 878300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.4471409485850018e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.28 | consumed tokens: 449689600.0 | grad norm avg: 12.69 | grad norm last: 13.13 | 
2025-12-28T04:03:54 | step: 878400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.4465346794168e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.86 | consumed tokens: 449740800.0 | grad norm avg: 13.14 | grad norm last: 11.27 | 
2025-12-28T04:03:56 | step: 878500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.4459287740464788e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.27 | consumed tokens: 449792000.0 | grad norm avg: 12.97 | grad norm last: 12.38 | 
2025-12-28T04:03:58 | step: 878600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.4453234143729787e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 2.7 | consumed tokens: 449843200.0 | grad norm avg: 13.35 | grad norm last: 10.57 | 
2025-12-28T04:04:00 | step: 878700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.4447181456489488e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.55 | consumed tokens: 449894400.0 | grad norm avg: 12.72 | grad norm last: 11.49 | 
2025-12-28T04:04:02 | step: 878800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.4441135135712102e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.61 | consumed tokens: 449945600.0 | grad norm avg: 13.04 | grad norm last: 12.21 | 
2025-12-28T04:04:04 | step: 878900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.4435091543418821e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.72 | consumed tokens: 449996800.0 | grad norm avg: 13.06 | grad norm last: 13.2 | 
2025-12-28T04:04:07 | step: 879000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.4429052498599049e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.38 | consumed tokens: 450048000.0 | grad norm avg: 13.1 | grad norm last: 14.42 | 
2025-12-28T04:04:09 | step: 879100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.4423017091758084e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 4.0 | consumed tokens: 450099200.0 | grad norm avg: 12.93 | grad norm last: 13.6 | 
2025-12-28T04:04:11 | step: 879200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.4416985322895925e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.14 | consumed tokens: 450150400.0 | grad norm avg: 12.92 | grad norm last: 14.75 | 
2025-12-28T04:04:13 | step: 879300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.4410958101507276e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.69 | consumed tokens: 450201600.0 | grad norm avg: 12.8 | grad norm last: 14.98 | 
2025-12-28T04:04:15 | step: 879400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.4404934518097434e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 5.66 | consumed tokens: 450252800.0 | grad norm avg: 13.23 | grad norm last: 19.72 | 
2025-12-28T04:04:17 | step: 879500 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.4398913663171697e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 4.56 | consumed tokens: 450304000.0 | grad norm avg: 13.08 | grad norm last: 30.25 | 
2025-12-28T04:04:19 | step: 879600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.4392899174708873e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.64 | consumed tokens: 450355200.0 | grad norm avg: 13.22 | grad norm last: 14.01 | 
2025-12-28T04:04:21 | step: 879700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.4386886505235452e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 2.97 | consumed tokens: 450406400.0 | grad norm avg: 12.92 | grad norm last: 12.05 | 
2025-12-28T04:04:23 | step: 879800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.438087838323554e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.05 | consumed tokens: 450457600.0 | grad norm avg: 13.17 | grad norm last: 10.7 | 
2025-12-28T04:04:25 | step: 879900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.4374873899214435e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.0 | consumed tokens: 450508800.0 | grad norm avg: 13.32 | grad norm last: 14.07 | 
2025-12-28T04:04:27 | step: 880000 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.436887396266684e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.02 | consumed tokens: 450560000.0 | grad norm avg: 13.54 | grad norm last: 12.9 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_880000-seen_tokens_450560000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_880000-seen_tokens_450560000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_880000-seen_tokens_450560000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_880000-seen_tokens_450560000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_880000-seen_tokens_450560000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_880000-seen_tokens_450560000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_880000-seen_tokens_450560000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_880000-seen_tokens_450560000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:04:29 | step: 880100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.436287766409805e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 4.31 | consumed tokens: 450611200.0 | grad norm avg: 12.81 | grad norm last: 15.09 | 
2025-12-28T04:04:31 | step: 880200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.435688591300277e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.5 | consumed tokens: 450662400.0 | grad norm avg: 13.25 | grad norm last: 12.54 | 
2025-12-28T04:04:33 | step: 880300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.4350897799886297e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.59 | consumed tokens: 450713600.0 | grad norm avg: 13.14 | grad norm last: 12.65 | 
2025-12-28T04:04:35 | step: 880400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.4344911505759228e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.41 | consumed tokens: 450764800.0 | grad norm avg: 13.19 | grad norm last: 12.02 | 
2025-12-28T04:04:37 | step: 880500 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.433893066860037e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.7 | consumed tokens: 450816000.0 | grad norm avg: 12.93 | grad norm last: 12.86 | 
2025-12-28T04:04:39 | step: 880600 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.4332955288409721e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.47 | consumed tokens: 450867200.0 | grad norm avg: 13.87 | grad norm last: 12.59 | 
2025-12-28T04:04:42 | step: 880700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.4326982636703178e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.67 | consumed tokens: 450918400.0 | grad norm avg: 13.38 | grad norm last: 17.36 | 
2025-12-28T04:04:44 | step: 880800 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.4321013622975443e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.23 | consumed tokens: 450969600.0 | grad norm avg: 13.71 | grad norm last: 12.79 | 
2025-12-28T04:04:46 | step: 880900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.4315049156721216e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.06 | consumed tokens: 451020800.0 | grad norm avg: 13.04 | grad norm last: 12.67 | 
2025-12-28T04:04:48 | step: 881000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.4309087418951094e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.16 | consumed tokens: 451072000.0 | grad norm avg: 13.41 | grad norm last: 16.68 | 
2025-12-28T04:04:50 | step: 881100 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 1.4303131138149183e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.09 | consumed tokens: 451123200.0 | grad norm avg: 13.1 | grad norm last: 11.15 | 
2025-12-28T04:04:52 | step: 881200 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.4297176676336676e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.38 | consumed tokens: 451174400.0 | grad norm avg: 13.08 | grad norm last: 12.64 | 
2025-12-28T04:04:54 | step: 881300 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.429122767149238e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.91 | consumed tokens: 451225600.0 | grad norm avg: 13.79 | grad norm last: 17.72 | 
2025-12-28T04:04:56 | step: 881400 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.4285281395132188e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 3.78 | consumed tokens: 451276800.0 | grad norm avg: 13.41 | grad norm last: 11.1 | 
2025-12-28T04:04:58 | step: 881500 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.4279340575740207e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 5.31 | consumed tokens: 451328000.0 | grad norm avg: 13.06 | grad norm last: 15.34 | 
2025-12-28T04:05:00 | step: 881600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.4273402484832332e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.22 | consumed tokens: 451379200.0 | grad norm avg: 12.99 | grad norm last: 13.92 | 
2025-12-28T04:05:02 | step: 881700 | train samples/s: 104.2 | train mfu (16-bit): -1.0 | lr mean: 1.4267468941397965e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.55 | consumed tokens: 451430400.0 | grad norm avg: 13.78 | grad norm last: 11.27 | 
2025-12-28T04:05:04 | step: 881800 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.4261539035942405e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.36 | consumed tokens: 451481600.0 | grad norm avg: 13.73 | grad norm last: 12.88 | 
2025-12-28T04:05:06 | step: 881900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.4255613677960355e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.44 | consumed tokens: 451532800.0 | grad norm avg: 13.02 | grad norm last: 13.11 | 
2025-12-28T04:05:08 | step: 882000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.424969104846241e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.19 | consumed tokens: 451584000.0 | grad norm avg: 12.91 | grad norm last: 16.62 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_882000-seen_tokens_451584000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_882000-seen_tokens_451584000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_882000-seen_tokens_451584000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_882000-seen_tokens_451584000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_882000-seen_tokens_451584000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_882000-seen_tokens_451584000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_882000-seen_tokens_451584000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_882000-seen_tokens_451584000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:05:11 | step: 882100 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.4243773875932675e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.56 | train loss last: 3.62 | consumed tokens: 451635200.0 | grad norm avg: 13.44 | grad norm last: 12.5 | 
2025-12-28T04:05:13 | step: 882200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.4237859431887046e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.17 | consumed tokens: 451686400.0 | grad norm avg: 13.24 | grad norm last: 12.1 | 
2025-12-28T04:05:15 | step: 882300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.4231948625820223e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.78 | consumed tokens: 451737600.0 | grad norm avg: 13.34 | grad norm last: 15.58 | 
2025-12-28T04:05:17 | step: 882400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.422604236722691e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.44 | consumed tokens: 451788800.0 | grad norm avg: 13.25 | grad norm last: 13.68 | 
2025-12-28T04:05:19 | step: 882500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.4220141565601807e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.88 | consumed tokens: 451840000.0 | grad norm avg: 13.4 | grad norm last: 12.3 | 
2025-12-28T04:05:21 | step: 882600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.4214241673471406e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 5.34 | consumed tokens: 451891200.0 | grad norm avg: 13.32 | grad norm last: 15.07 | 
2025-12-28T04:05:23 | step: 882700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.4208347238309216e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.14 | consumed tokens: 451942400.0 | grad norm avg: 13.25 | grad norm last: 12.13 | 
2025-12-28T04:05:25 | step: 882800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.420245553163113e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.23 | consumed tokens: 451993600.0 | grad norm avg: 13.24 | grad norm last: 13.29 | 
2025-12-28T04:05:27 | step: 882900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.4196569281921256e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.39 | consumed tokens: 452044800.0 | grad norm avg: 13.42 | grad norm last: 11.81 | 
2025-12-28T04:05:29 | step: 883000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.4190688489179593e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.78 | consumed tokens: 452096000.0 | grad norm avg: 13.62 | grad norm last: 14.17 | 
2025-12-28T04:05:31 | step: 883100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.4184809515427332e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.27 | consumed tokens: 452147200.0 | grad norm avg: 13.69 | grad norm last: 9.19 | 
2025-12-28T04:05:33 | step: 883200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.4178932360664476e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 2.78 | consumed tokens: 452198400.0 | grad norm avg: 13.75 | grad norm last: 11.45 | 
2025-12-28T04:05:35 | step: 883300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.4173062481859233e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.33 | consumed tokens: 452249600.0 | grad norm avg: 13.17 | grad norm last: 14.52 | 
2025-12-28T04:05:37 | step: 883400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.4167195331538096e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.05 | consumed tokens: 452300800.0 | grad norm avg: 13.5 | grad norm last: 10.94 | 
2025-12-28T04:05:39 | step: 883500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.4161331819195766e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.83 | consumed tokens: 452352000.0 | grad norm avg: 13.3 | grad norm last: 12.72 | 
2025-12-28T04:05:41 | step: 883600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.4155473763821647e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.97 | consumed tokens: 452403200.0 | grad norm avg: 13.08 | grad norm last: 13.6 | 
2025-12-28T04:05:43 | step: 883700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.414961752743693e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.46 | train loss last: 3.47 | consumed tokens: 452454400.0 | grad norm avg: 13.17 | grad norm last: 13.12 | 
2025-12-28T04:05:45 | step: 883800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.4143766748020425e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.19 | consumed tokens: 452505600.0 | grad norm avg: 13.68 | grad norm last: 11.74 | 
2025-12-28T04:05:47 | step: 883900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.4137919606582727e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.59 | consumed tokens: 452556800.0 | grad norm avg: 13.36 | grad norm last: 12.27 | 
2025-12-28T04:05:49 | step: 884000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.4132075193629134e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.53 | consumed tokens: 452608000.0 | grad norm avg: 13.17 | grad norm last: 15.46 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_884000-seen_tokens_452608000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_884000-seen_tokens_452608000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_884000-seen_tokens_452608000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_884000-seen_tokens_452608000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_884000-seen_tokens_452608000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_884000-seen_tokens_452608000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_884000-seen_tokens_452608000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_884000-seen_tokens_452608000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:05:52 | step: 884100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.4126236237643752e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.56 | train loss last: 2.98 | consumed tokens: 452659200.0 | grad norm avg: 13.26 | grad norm last: 11.02 | 
2025-12-28T04:05:54 | step: 884200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.4120400919637177e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.3 | consumed tokens: 452710400.0 | grad norm avg: 13.4 | grad norm last: 12.03 | 
2025-12-28T04:05:56 | step: 884300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.4114569239609409e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.72 | consumed tokens: 452761600.0 | grad norm avg: 13.54 | grad norm last: 11.72 | 
2025-12-28T04:05:58 | step: 884400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.4108741197560448e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.77 | consumed tokens: 452812800.0 | grad norm avg: 13.24 | grad norm last: 10.8 | 
2025-12-28T04:06:00 | step: 884500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.4102918612479698e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.47 | consumed tokens: 452864000.0 | grad norm avg: 13.62 | grad norm last: 12.67 | 
2025-12-28T04:06:02 | step: 884600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.4097097846388351e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.62 | consumed tokens: 452915200.0 | grad norm avg: 13.38 | grad norm last: 11.5 | 
2025-12-28T04:06:04 | step: 884700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.4091281627770513e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.73 | train loss last: 4.0 | consumed tokens: 452966400.0 | grad norm avg: 13.91 | grad norm last: 13.08 | 
2025-12-28T04:06:06 | step: 884800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.4085470866120886e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.91 | consumed tokens: 453017600.0 | grad norm avg: 13.53 | grad norm last: 20.04 | 
2025-12-28T04:06:08 | step: 884900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.4079661923460662e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.72 | consumed tokens: 453068800.0 | grad norm avg: 13.69 | grad norm last: 15.13 | 
2025-12-28T04:06:10 | step: 885000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.407385843776865e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.16 | consumed tokens: 453120000.0 | grad norm avg: 13.62 | grad norm last: 11.72 | 
2025-12-28T04:06:12 | step: 885100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.406805677106604e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.38 | consumed tokens: 453171200.0 | grad norm avg: 13.5 | grad norm last: 11.87 | 
2025-12-28T04:06:14 | step: 885200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.4062260561331641e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.36 | consumed tokens: 453222400.0 | grad norm avg: 13.51 | grad norm last: 11.66 | 
2025-12-28T04:06:16 | step: 885300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.4056468899070751e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.98 | consumed tokens: 453273600.0 | grad norm avg: 13.85 | grad norm last: 17.39 | 
2025-12-28T04:06:18 | step: 885400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.4050679055799264e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.25 | consumed tokens: 453324800.0 | grad norm avg: 13.58 | grad norm last: 19.43 | 
2025-12-28T04:06:20 | step: 885500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.4044894669495989e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 5.16 | consumed tokens: 453376000.0 | grad norm avg: 14.36 | grad norm last: 28.22 | 
2025-12-28T04:06:22 | step: 885600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.4039115740160923e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.34 | consumed tokens: 453427200.0 | grad norm avg: 13.38 | grad norm last: 12.44 | 
2025-12-28T04:06:24 | step: 885700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.4033338629815262e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.41 | consumed tokens: 453478400.0 | grad norm avg: 13.41 | grad norm last: 11.85 | 
2025-12-28T04:06:26 | step: 885800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.4027566066943109e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.27 | consumed tokens: 453529600.0 | grad norm avg: 13.17 | grad norm last: 11.36 | 
2025-12-28T04:06:28 | step: 885900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.4021797142049763e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.16 | consumed tokens: 453580800.0 | grad norm avg: 14.03 | grad norm last: 17.08 | 
2025-12-28T04:06:30 | step: 886000 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.4016032764629927e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.06 | consumed tokens: 453632000.0 | grad norm avg: 13.56 | grad norm last: 14.1 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_886000-seen_tokens_453632000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_886000-seen_tokens_453632000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_886000-seen_tokens_453632000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_886000-seen_tokens_453632000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_886000-seen_tokens_453632000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_886000-seen_tokens_453632000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_886000-seen_tokens_453632000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_886000-seen_tokens_453632000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:06:33 | step: 886100 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.4010272025188897e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 3.64 | consumed tokens: 453683200.0 | grad norm avg: 14.06 | grad norm last: 12.39 | 
2025-12-28T04:06:35 | step: 886200 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.4004514923726674e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.92 | consumed tokens: 453734400.0 | grad norm avg: 13.09 | grad norm last: 14.77 | 
2025-12-28T04:06:37 | step: 886300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.3998761460243259e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.53 | consumed tokens: 453785600.0 | grad norm avg: 13.44 | grad norm last: 19.71 | 
2025-12-28T04:06:39 | step: 886400 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.3993012544233352e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.72 | train loss last: 4.09 | consumed tokens: 453836800.0 | grad norm avg: 14.04 | grad norm last: 14.2 | 
2025-12-28T04:06:41 | step: 886500 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 1.3987268175696954e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.22 | consumed tokens: 453888000.0 | grad norm avg: 13.68 | grad norm last: 17.5 | 
2025-12-28T04:06:43 | step: 886600 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 1.3981526535644662e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.64 | consumed tokens: 453939200.0 | grad norm avg: 13.56 | grad norm last: 13.26 | 
2025-12-28T04:06:45 | step: 886700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.3975789443065878e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.55 | consumed tokens: 453990400.0 | grad norm avg: 13.75 | grad norm last: 12.88 | 
2025-12-28T04:06:47 | step: 886800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.3970055988465901e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.25 | consumed tokens: 454041600.0 | grad norm avg: 13.71 | grad norm last: 13.25 | 
2025-12-28T04:06:49 | step: 886900 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.3964327081339434e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.5 | consumed tokens: 454092800.0 | grad norm avg: 13.34 | grad norm last: 16.73 | 
2025-12-28T04:06:51 | step: 887000 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.3958601812191773e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 5.56 | consumed tokens: 454144000.0 | grad norm avg: 13.72 | grad norm last: 25.47 | 
2025-12-28T04:06:53 | step: 887100 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 1.3952881090517621e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 2.98 | consumed tokens: 454195200.0 | grad norm avg: 13.21 | grad norm last: 12.52 | 
2025-12-28T04:06:55 | step: 887200 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.3947163097327575e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.45 | consumed tokens: 454246400.0 | grad norm avg: 13.85 | grad norm last: 14.25 | 
2025-12-28T04:06:57 | step: 887300 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.394145056110574e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.66 | consumed tokens: 454297600.0 | grad norm avg: 13.94 | grad norm last: 13.91 | 
2025-12-28T04:06:59 | step: 887400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.3935739843873307e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.59 | consumed tokens: 454348800.0 | grad norm avg: 13.5 | grad norm last: 14.74 | 
2025-12-28T04:07:01 | step: 887500 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.3930034583609086e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.45 | consumed tokens: 454400000.0 | grad norm avg: 13.84 | grad norm last: 13.08 | 
2025-12-28T04:07:03 | step: 887600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.392433205182897e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.81 | consumed tokens: 454451200.0 | grad norm avg: 13.48 | grad norm last: 13.09 | 
2025-12-28T04:07:05 | step: 887700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.3918634977017064e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.39 | consumed tokens: 454502400.0 | grad norm avg: 13.91 | grad norm last: 14.11 | 
2025-12-28T04:07:07 | step: 887800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.3912941540183965e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.03 | consumed tokens: 454553600.0 | grad norm avg: 13.37 | grad norm last: 13.18 | 
2025-12-28T04:07:09 | step: 887900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.3907251741329674e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.84 | consumed tokens: 454604800.0 | grad norm avg: 13.71 | grad norm last: 13.01 | 
2025-12-28T04:07:12 | step: 888000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.390156558045419e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.19 | consumed tokens: 454656000.0 | grad norm avg: 14.3 | grad norm last: 11.64 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_888000-seen_tokens_454656000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_888000-seen_tokens_454656000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_888000-seen_tokens_454656000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_888000-seen_tokens_454656000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_888000-seen_tokens_454656000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_888000-seen_tokens_454656000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_888000-seen_tokens_454656000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_888000-seen_tokens_454656000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:07:14 | step: 888100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.3895883057557512e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 4.28 | consumed tokens: 454707200.0 | grad norm avg: 13.61 | grad norm last: 14.83 | 
2025-12-28T04:07:16 | step: 888200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.3890205991629045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.0 | consumed tokens: 454758400.0 | grad norm avg: 13.46 | grad norm last: 10.75 | 
2025-12-28T04:07:18 | step: 888300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.3884531654184684e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.91 | consumed tokens: 454809600.0 | grad norm avg: 13.71 | grad norm last: 13.02 | 
2025-12-28T04:07:20 | step: 888400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.3878862773708533e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.45 | train loss last: 2.94 | consumed tokens: 454860800.0 | grad norm avg: 13.04 | grad norm last: 11.48 | 
2025-12-28T04:07:22 | step: 888500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.3873195712221786e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 2.67 | consumed tokens: 454912000.0 | grad norm avg: 13.96 | grad norm last: 12.06 | 
2025-12-28T04:07:24 | step: 888600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.386753410770325e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.44 | consumed tokens: 454963200.0 | grad norm avg: 13.63 | grad norm last: 12.14 | 
2025-12-28T04:07:26 | step: 888700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.3861875231668819e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.89 | consumed tokens: 455014400.0 | grad norm avg: 13.7 | grad norm last: 13.45 | 
2025-12-28T04:07:28 | step: 888800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.3856221812602598e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.92 | consumed tokens: 455065600.0 | grad norm avg: 13.39 | grad norm last: 14.32 | 
2025-12-28T04:07:30 | step: 888900 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.3850571122020483e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.56 | consumed tokens: 455116800.0 | grad norm avg: 13.19 | grad norm last: 12.7 | 
2025-12-28T04:07:32 | step: 889000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.3844924978911877e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.14 | consumed tokens: 455168000.0 | grad norm avg: 14.04 | grad norm last: 13.81 | 
2025-12-28T04:07:34 | step: 889100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.3839282473782077e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.59 | consumed tokens: 455219200.0 | grad norm avg: 13.24 | grad norm last: 13.56 | 
2025-12-28T04:07:36 | step: 889200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.3833644516125787e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.64 | consumed tokens: 455270400.0 | grad norm avg: 13.36 | grad norm last: 12.22 | 
2025-12-28T04:07:38 | step: 889300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.3828011105943006e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 2.66 | consumed tokens: 455321600.0 | grad norm avg: 14.01 | grad norm last: 12.44 | 
2025-12-28T04:07:40 | step: 889400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.3822379514749628e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.08 | consumed tokens: 455372800.0 | grad norm avg: 13.79 | grad norm last: 11.69 | 
2025-12-28T04:07:42 | step: 889500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.381675338052446e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 2.98 | consumed tokens: 455424000.0 | grad norm avg: 13.7 | grad norm last: 12.85 | 
2025-12-28T04:07:44 | step: 889600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.38111308842781e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.48 | consumed tokens: 455475200.0 | grad norm avg: 13.73 | grad norm last: 11.66 | 
2025-12-28T04:07:46 | step: 889700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.3805512026010547e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.2 | consumed tokens: 455526400.0 | grad norm avg: 13.86 | grad norm last: 13.12 | 
2025-12-28T04:07:48 | step: 889800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.3799897715216503e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.05 | consumed tokens: 455577600.0 | grad norm avg: 13.67 | grad norm last: 11.02 | 
2025-12-28T04:07:51 | step: 889900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.3794287042401265e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.73 | consumed tokens: 455628800.0 | grad norm avg: 13.44 | grad norm last: 13.4 | 
2025-12-28T04:07:53 | step: 890000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.3788679098070133e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.72 | consumed tokens: 455680000.0 | grad norm avg: 13.41 | grad norm last: 11.94 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_890000-seen_tokens_455680000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_890000-seen_tokens_455680000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_890000-seen_tokens_455680000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_890000-seen_tokens_455680000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_890000-seen_tokens_455680000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_890000-seen_tokens_455680000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_890000-seen_tokens_455680000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_890000-seen_tokens_455680000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:07:55 | step: 890100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.3783076610707212e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.06 | consumed tokens: 455731200.0 | grad norm avg: 13.65 | grad norm last: 15.15 | 
2025-12-28T04:07:57 | step: 890200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.3777479580312502e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.23 | consumed tokens: 455782400.0 | grad norm avg: 13.41 | grad norm last: 13.31 | 
2025-12-28T04:07:59 | step: 890300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.3771884368907195e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.69 | consumed tokens: 455833600.0 | grad norm avg: 14.46 | grad norm last: 17.86 | 
2025-12-28T04:08:01 | step: 890400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.3766292795480695e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.95 | consumed tokens: 455884800.0 | grad norm avg: 13.62 | grad norm last: 14.08 | 
2025-12-28T04:08:03 | step: 890500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.3760705769527704e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 2.92 | consumed tokens: 455936000.0 | grad norm avg: 13.34 | grad norm last: 12.82 | 
2025-12-28T04:08:05 | step: 890600 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.375512238155352e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.98 | consumed tokens: 455987200.0 | grad norm avg: 13.75 | grad norm last: 12.87 | 
2025-12-28T04:08:07 | step: 890700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.3749544450547546e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.5 | consumed tokens: 456038400.0 | grad norm avg: 13.84 | grad norm last: 13.28 | 
2025-12-28T04:08:09 | step: 890800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.3743968338530976e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.25 | consumed tokens: 456089600.0 | grad norm avg: 13.9 | grad norm last: 21.39 | 
2025-12-28T04:08:11 | step: 890900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.3738398592977319e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.31 | consumed tokens: 456140800.0 | grad norm avg: 13.46 | grad norm last: 14.7 | 
2025-12-28T04:08:13 | step: 891000 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.3732831575907767e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.7 | consumed tokens: 456192000.0 | grad norm avg: 13.9 | grad norm last: 13.26 | 
2025-12-28T04:08:15 | step: 891100 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 1.3727268196817022e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 2.89 | consumed tokens: 456243200.0 | grad norm avg: 14.39 | grad norm last: 23.34 | 
2025-12-28T04:08:17 | step: 891200 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.3721709365199786e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.28 | consumed tokens: 456294400.0 | grad norm avg: 13.65 | grad norm last: 12.5 | 
2025-12-28T04:08:19 | step: 891300 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.3716154171561357e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.67 | consumed tokens: 456345600.0 | grad norm avg: 14.33 | grad norm last: 12.61 | 
2025-12-28T04:08:21 | step: 891400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.3710603525396436e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.28 | consumed tokens: 456396800.0 | grad norm avg: 13.52 | grad norm last: 11.06 | 
2025-12-28T04:08:23 | step: 891500 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.3705055607715622e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 2.94 | consumed tokens: 456448000.0 | grad norm avg: 14.9 | grad norm last: 11.54 | 
2025-12-28T04:08:26 | step: 891600 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.3699512237508316e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.25 | consumed tokens: 456499200.0 | grad norm avg: 14.42 | grad norm last: 11.57 | 
2025-12-28T04:08:28 | step: 891700 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.3693973414774518e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.12 | consumed tokens: 456550400.0 | grad norm avg: 13.74 | grad norm last: 11.36 | 
2025-12-28T04:08:30 | step: 891800 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.3688438230019528e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.39 | consumed tokens: 456601600.0 | grad norm avg: 13.81 | grad norm last: 12.02 | 
2025-12-28T04:08:32 | step: 891900 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.3682906683243345e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.98 | consumed tokens: 456652800.0 | grad norm avg: 13.71 | grad norm last: 13.09 | 
2025-12-28T04:08:34 | step: 892000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.367737877444597e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.22 | consumed tokens: 456704000.0 | grad norm avg: 14.18 | grad norm last: 13.12 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_892000-seen_tokens_456704000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_892000-seen_tokens_456704000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_892000-seen_tokens_456704000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_892000-seen_tokens_456704000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_892000-seen_tokens_456704000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_892000-seen_tokens_456704000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_892000-seen_tokens_456704000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_892000-seen_tokens_456704000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:08:36 | step: 892100 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.3671856322616804e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.51 | train loss last: 3.92 | consumed tokens: 456755200.0 | grad norm avg: 13.71 | grad norm last: 13.87 | 
2025-12-28T04:08:38 | step: 892200 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.3666337508766446e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.91 | consumed tokens: 456806400.0 | grad norm avg: 13.77 | grad norm last: 17.62 | 
2025-12-28T04:08:40 | step: 892300 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.3660821423400193e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.75 | consumed tokens: 456857600.0 | grad norm avg: 13.25 | grad norm last: 12.16 | 
2025-12-28T04:08:42 | step: 892400 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.365530988550745e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.83 | consumed tokens: 456908800.0 | grad norm avg: 13.74 | grad norm last: 12.42 | 
2025-12-28T04:08:44 | step: 892500 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.3649802895088214e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.92 | consumed tokens: 456960000.0 | grad norm avg: 13.71 | grad norm last: 11.4 | 
2025-12-28T04:08:46 | step: 892600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.3644300452142488e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.14 | consumed tokens: 457011200.0 | grad norm avg: 13.7 | grad norm last: 12.32 | 
2025-12-28T04:08:48 | step: 892700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.3638799828186166e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 4.22 | consumed tokens: 457062400.0 | grad norm avg: 13.63 | grad norm last: 15.69 | 
2025-12-28T04:08:50 | step: 892800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.3633304661198054e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.64 | consumed tokens: 457113600.0 | grad norm avg: 14.09 | grad norm last: 15.01 | 
2025-12-28T04:08:52 | step: 892900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.3627813132188749e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.31 | consumed tokens: 457164800.0 | grad norm avg: 13.95 | grad norm last: 13.88 | 
2025-12-28T04:08:54 | step: 893000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.362232524115825e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.45 | consumed tokens: 457216000.0 | grad norm avg: 14.28 | grad norm last: 18.11 | 
2025-12-28T04:08:57 | step: 893100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.3616841897601262e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.16 | consumed tokens: 457267200.0 | grad norm avg: 14.09 | grad norm last: 13.92 | 
2025-12-28T04:08:59 | step: 893200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.361136219202308e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 2.77 | consumed tokens: 457318400.0 | grad norm avg: 14.14 | grad norm last: 11.21 | 
2025-12-28T04:09:01 | step: 893300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.3605887033918407e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.25 | consumed tokens: 457369600.0 | grad norm avg: 14.07 | grad norm last: 13.51 | 
2025-12-28T04:09:03 | step: 893400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.3600415513792541e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.33 | consumed tokens: 457420800.0 | grad norm avg: 13.87 | grad norm last: 13.27 | 
2025-12-28T04:09:05 | step: 893500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.3594947631645482e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.48 | consumed tokens: 457472000.0 | grad norm avg: 13.72 | grad norm last: 13.08 | 
2025-12-28T04:09:07 | step: 893600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.358948338747723e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.41 | consumed tokens: 457523200.0 | grad norm avg: 14.09 | grad norm last: 15.86 | 
2025-12-28T04:09:09 | step: 893700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.3584023690782487e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.66 | consumed tokens: 457574400.0 | grad norm avg: 14.29 | grad norm last: 13.09 | 
2025-12-28T04:09:11 | step: 893800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.3578569451055955e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.12 | consumed tokens: 457625600.0 | grad norm avg: 14.33 | grad norm last: 14.23 | 
2025-12-28T04:09:13 | step: 893900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.3573117030318826e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.94 | consumed tokens: 457676800.0 | grad norm avg: 13.47 | grad norm last: 12.48 | 
2025-12-28T04:09:15 | step: 894000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.3567670066549908e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.36 | consumed tokens: 457728000.0 | grad norm avg: 13.57 | grad norm last: 11.16 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_894000-seen_tokens_457728000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_894000-seen_tokens_457728000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_894000-seen_tokens_457728000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_894000-seen_tokens_457728000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_894000-seen_tokens_457728000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_894000-seen_tokens_457728000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_894000-seen_tokens_457728000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_894000-seen_tokens_457728000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:09:17 | step: 894100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.3562224921770394e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.88 | consumed tokens: 457779200.0 | grad norm avg: 14.12 | grad norm last: 14.29 | 
2025-12-28T04:09:19 | step: 894200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.355678523395909e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.69 | consumed tokens: 457830400.0 | grad norm avg: 14.18 | grad norm last: 21.24 | 
2025-12-28T04:09:21 | step: 894300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.3551350093621295e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 5.09 | consumed tokens: 457881600.0 | grad norm avg: 14.54 | grad norm last: 17.73 | 
2025-12-28T04:09:23 | step: 894400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.3545916772272903e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.78 | consumed tokens: 457932800.0 | grad norm avg: 14.09 | grad norm last: 13.05 | 
2025-12-28T04:09:25 | step: 894500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.3540488907892723e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.28 | consumed tokens: 457984000.0 | grad norm avg: 14.14 | grad norm last: 12.04 | 
2025-12-28T04:09:27 | step: 894600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.3535066500480752e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.53 | consumed tokens: 458035200.0 | grad norm avg: 14.55 | grad norm last: 15.34 | 
2025-12-28T04:09:29 | step: 894700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.3529646821552888e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.42 | consumed tokens: 458086400.0 | grad norm avg: 14.1 | grad norm last: 12.75 | 
2025-12-28T04:09:31 | step: 894800 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.352423078060383e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.09 | consumed tokens: 458137600.0 | grad norm avg: 13.98 | grad norm last: 17.27 | 
2025-12-28T04:09:33 | step: 894900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.3518819287128281e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 2.69 | consumed tokens: 458188800.0 | grad norm avg: 13.94 | grad norm last: 10.24 | 
2025-12-28T04:09:36 | step: 895000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.3513411431631539e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.62 | consumed tokens: 458240000.0 | grad norm avg: 13.99 | grad norm last: 13.71 | 
2025-12-28T04:09:38 | step: 895100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.3508007214113604e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.02 | consumed tokens: 458291200.0 | grad norm avg: 14.16 | grad norm last: 11.73 | 
2025-12-28T04:09:40 | step: 895200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.350260845356388e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.41 | consumed tokens: 458342400.0 | grad norm avg: 13.73 | grad norm last: 11.47 | 
2025-12-28T04:09:42 | step: 895300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.349721151200356e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.25 | consumed tokens: 458393600.0 | grad norm avg: 13.82 | grad norm last: 12.71 | 
2025-12-28T04:09:44 | step: 895400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.349182002741145e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.03 | consumed tokens: 458444800.0 | grad norm avg: 14.07 | grad norm last: 13.65 | 
2025-12-28T04:09:46 | step: 895500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.3486431271303445e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.8 | consumed tokens: 458496000.0 | grad norm avg: 14.09 | grad norm last: 13.06 | 
2025-12-28T04:09:48 | step: 895600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.3481047972163651e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.72 | consumed tokens: 458547200.0 | grad norm avg: 14.06 | grad norm last: 14.55 | 
2025-12-28T04:09:50 | step: 895700 | train samples/s: 97.3 | train mfu (16-bit): -1.0 | lr mean: 1.3475667401507962e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 2.31 | consumed tokens: 458598400.0 | grad norm avg: 13.98 | grad norm last: 10.88 | 
2025-12-28T04:09:52 | step: 895800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.3470292287820484e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.77 | consumed tokens: 458649600.0 | grad norm avg: 14.06 | grad norm last: 13.69 | 
2025-12-28T04:09:54 | step: 895900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.3464919902617112e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.39 | consumed tokens: 458700800.0 | grad norm avg: 14.15 | grad norm last: 11.0 | 
2025-12-28T04:09:56 | step: 896000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.3459551155392546e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 3.17 | consumed tokens: 458752000.0 | grad norm avg: 14.12 | grad norm last: 12.84 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_896000-seen_tokens_458752000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_896000-seen_tokens_458752000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_896000-seen_tokens_458752000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_896000-seen_tokens_458752000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_896000-seen_tokens_458752000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_896000-seen_tokens_458752000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_896000-seen_tokens_458752000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_896000-seen_tokens_458752000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:09:58 | step: 896100 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.3454187865136191e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.89 | consumed tokens: 458803200.0 | grad norm avg: 14.21 | grad norm last: 12.09 | 
2025-12-28T04:10:00 | step: 896200 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.3448828212858643e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.22 | consumed tokens: 458854400.0 | grad norm avg: 13.83 | grad norm last: 11.81 | 
2025-12-28T04:10:03 | step: 896300 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.34434712890652e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.11 | consumed tokens: 458905600.0 | grad norm avg: 14.66 | grad norm last: 13.24 | 
2025-12-28T04:10:05 | step: 896400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.3438121641229372e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 2.92 | consumed tokens: 458956800.0 | grad norm avg: 14.2 | grad norm last: 17.23 | 
2025-12-28T04:10:07 | step: 896500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.3432773812382948e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 4.19 | consumed tokens: 459008000.0 | grad norm avg: 13.94 | grad norm last: 12.97 | 
2025-12-28T04:10:09 | step: 896600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.3427427802525926e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.38 | consumed tokens: 459059200.0 | grad norm avg: 13.87 | grad norm last: 13.73 | 
2025-12-28T04:10:11 | step: 896700 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 1.3422087249637116e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.97 | consumed tokens: 459110400.0 | grad norm avg: 13.74 | grad norm last: 13.96 | 
2025-12-28T04:10:13 | step: 896800 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.3416753063211218e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.3 | consumed tokens: 459161600.0 | grad norm avg: 13.62 | grad norm last: 11.66 | 
2025-12-28T04:10:15 | step: 896900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.3411420695774723e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.22 | consumed tokens: 459212800.0 | grad norm avg: 15.28 | grad norm last: 13.54 | 
2025-12-28T04:10:17 | step: 897000 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.3406092875811737e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.44 | consumed tokens: 459264000.0 | grad norm avg: 13.82 | grad norm last: 14.27 | 
2025-12-28T04:10:19 | step: 897100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.3400768693827558e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.61 | consumed tokens: 459315200.0 | grad norm avg: 14.12 | grad norm last: 13.66 | 
2025-12-28T04:10:21 | step: 897200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.3395449059316888e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.78 | consumed tokens: 459366400.0 | grad norm avg: 13.82 | grad norm last: 14.95 | 
2025-12-28T04:10:23 | step: 897300 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 1.3390133062785026e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.59 | consumed tokens: 459417600.0 | grad norm avg: 13.97 | grad norm last: 12.5 | 
2025-12-28T04:10:25 | step: 897400 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.3384819794737268e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.8 | consumed tokens: 459468800.0 | grad norm avg: 14.58 | grad norm last: 16.34 | 
2025-12-28T04:10:27 | step: 897500 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.3379513802647125e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.3 | consumed tokens: 459520000.0 | grad norm avg: 14.11 | grad norm last: 12.11 | 
2025-12-28T04:10:29 | step: 897600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.3374209629546385e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.7 | consumed tokens: 459571200.0 | grad norm avg: 14.49 | grad norm last: 13.0 | 
2025-12-28T04:10:31 | step: 897700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.3368909094424453e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 4.28 | consumed tokens: 459622400.0 | grad norm avg: 14.33 | grad norm last: 15.21 | 
2025-12-28T04:10:33 | step: 897800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.3363613106776029e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 4.28 | consumed tokens: 459673600.0 | grad norm avg: 13.79 | grad norm last: 21.45 | 
2025-12-28T04:10:35 | step: 897900 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.3358320757106412e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.41 | consumed tokens: 459724800.0 | grad norm avg: 14.15 | grad norm last: 12.52 | 
2025-12-28T04:10:37 | step: 898000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.3353032954910304e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.47 | train loss last: 2.89 | consumed tokens: 459776000.0 | grad norm avg: 13.46 | grad norm last: 13.42 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_898000-seen_tokens_459776000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_898000-seen_tokens_459776000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_898000-seen_tokens_459776000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_898000-seen_tokens_459776000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_898000-seen_tokens_459776000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_898000-seen_tokens_459776000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_898000-seen_tokens_459776000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_898000-seen_tokens_459776000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:10:40 | step: 898100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.3347748790693004e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.25 | consumed tokens: 459827200.0 | grad norm avg: 13.95 | grad norm last: 12.87 | 
2025-12-28T04:10:42 | step: 898200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.3342469173949212e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.22 | consumed tokens: 459878400.0 | grad norm avg: 13.72 | grad norm last: 12.97 | 
2025-12-28T04:10:44 | step: 898300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.3337193195184227e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 4.62 | consumed tokens: 459929600.0 | grad norm avg: 13.88 | grad norm last: 19.3 | 
2025-12-28T04:10:46 | step: 898400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.3331921763892751e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 2.81 | consumed tokens: 459980800.0 | grad norm avg: 14.14 | grad norm last: 12.33 | 
2025-12-28T04:10:48 | step: 898500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.3326653970580082e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.61 | consumed tokens: 460032000.0 | grad norm avg: 14.22 | grad norm last: 13.16 | 
2025-12-28T04:10:50 | step: 898600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.332138981524622e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.98 | consumed tokens: 460083200.0 | grad norm avg: 14.01 | grad norm last: 11.16 | 
2025-12-28T04:10:52 | step: 898700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.3316130207385868e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.72 | consumed tokens: 460134400.0 | grad norm avg: 14.54 | grad norm last: 14.67 | 
2025-12-28T04:10:54 | step: 898800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.3310874237504322e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.38 | consumed tokens: 460185600.0 | grad norm avg: 14.2 | grad norm last: 15.76 | 
2025-12-28T04:10:56 | step: 898900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.3305620996106882e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.56 | consumed tokens: 460236800.0 | grad norm avg: 13.8 | grad norm last: 12.92 | 
2025-12-28T04:10:58 | step: 899000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.3300374121172354e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.78 | consumed tokens: 460288000.0 | grad norm avg: 14.35 | grad norm last: 13.32 | 
2025-12-28T04:11:00 | step: 899100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.3295130884216633e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.08 | consumed tokens: 460339200.0 | grad norm avg: 14.38 | grad norm last: 12.59 | 
2025-12-28T04:11:02 | step: 899200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.3289890375745017e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 6.09 | consumed tokens: 460390400.0 | grad norm avg: 14.19 | grad norm last: 21.82 | 
2025-12-28T04:11:04 | step: 899300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.3284655324241612e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 4.28 | consumed tokens: 460441600.0 | grad norm avg: 14.57 | grad norm last: 14.82 | 
2025-12-28T04:11:06 | step: 899400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.3279423001222312e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.47 | train loss last: 2.92 | consumed tokens: 460492800.0 | grad norm avg: 13.99 | grad norm last: 12.4 | 
2025-12-28T04:11:08 | step: 899500 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.3274195225676522e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.81 | consumed tokens: 460544000.0 | grad norm avg: 15.36 | grad norm last: 18.16 | 
2025-12-28T04:11:10 | step: 899600 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.326897199760424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.38 | consumed tokens: 460595200.0 | grad norm avg: 14.17 | grad norm last: 13.96 | 
2025-12-28T04:11:12 | step: 899700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.3263751498016063e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.47 | train loss last: 3.34 | consumed tokens: 460646400.0 | grad norm avg: 14.01 | grad norm last: 14.1 | 
2025-12-28T04:11:14 | step: 899800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.3258536455396097e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.75 | consumed tokens: 460697600.0 | grad norm avg: 13.86 | grad norm last: 12.49 | 
2025-12-28T04:11:16 | step: 899900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.3253324141260237e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.45 | consumed tokens: 460748800.0 | grad norm avg: 13.74 | grad norm last: 13.38 | 
2025-12-28T04:11:18 | step: 900000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.3248117284092586e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.45 | consumed tokens: 460800000.0 | grad norm avg: 13.84 | grad norm last: 16.05 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_900000-seen_tokens_460800000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_900000-seen_tokens_460800000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_900000-seen_tokens_460800000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_900000-seen_tokens_460800000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_900000-seen_tokens_460800000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_900000-seen_tokens_460800000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_900000-seen_tokens_460800000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_900000-seen_tokens_460800000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:11:21 | step: 900100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.3242913155409042e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 4.38 | consumed tokens: 460851200.0 | grad norm avg: 13.57 | grad norm last: 17.14 | 
2025-12-28T04:11:23 | step: 900200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.3237713574199006e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.12 | consumed tokens: 460902400.0 | grad norm avg: 14.53 | grad norm last: 10.75 | 
2025-12-28T04:11:25 | step: 900300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.3232517630967777e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.5 | consumed tokens: 460953600.0 | grad norm avg: 14.4 | grad norm last: 12.57 | 
2025-12-28T04:11:27 | step: 900400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.3227326235210057e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 2.83 | consumed tokens: 461004800.0 | grad norm avg: 13.86 | grad norm last: 10.67 | 
2025-12-28T04:11:29 | step: 900500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.3222138477431145e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.45 | consumed tokens: 461056000.0 | grad norm avg: 14.3 | grad norm last: 13.44 | 
2025-12-28T04:11:31 | step: 900600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.3216954357631039e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.14 | consumed tokens: 461107200.0 | grad norm avg: 13.9 | grad norm last: 10.99 | 
2025-12-28T04:11:33 | step: 900700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.3211774785304442e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.02 | consumed tokens: 461158400.0 | grad norm avg: 13.9 | grad norm last: 12.89 | 
2025-12-28T04:11:35 | step: 900800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.3206600669946056e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.28 | consumed tokens: 461209600.0 | grad norm avg: 13.79 | grad norm last: 21.33 | 
2025-12-28T04:11:37 | step: 900900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.3201427464082371e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.97 | consumed tokens: 461260800.0 | grad norm avg: 14.05 | grad norm last: 11.67 | 
2025-12-28T04:11:39 | step: 901000 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.3196261534176301e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.19 | consumed tokens: 461312000.0 | grad norm avg: 13.87 | grad norm last: 11.44 | 
2025-12-28T04:11:41 | step: 901100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.3191096513764933e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.78 | consumed tokens: 461363200.0 | grad norm avg: 13.88 | grad norm last: 10.51 | 
2025-12-28T04:11:43 | step: 901200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.3185936950321775e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.88 | consumed tokens: 461414400.0 | grad norm avg: 14.59 | grad norm last: 12.88 | 
2025-12-28T04:11:45 | step: 901300 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 1.3180781934352126e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.97 | consumed tokens: 461465600.0 | grad norm avg: 14.53 | grad norm last: 11.83 | 
2025-12-28T04:11:47 | step: 901400 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.3175630556361284e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.56 | consumed tokens: 461516800.0 | grad norm avg: 13.86 | grad norm last: 13.25 | 
2025-12-28T04:11:49 | step: 901500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.317048281634925e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.78 | consumed tokens: 461568000.0 | grad norm avg: 13.97 | grad norm last: 13.64 | 
2025-12-28T04:11:51 | step: 901600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.3165339623810723e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.09 | consumed tokens: 461619200.0 | grad norm avg: 14.05 | grad norm last: 14.72 | 
2025-12-28T04:11:53 | step: 901700 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.3160200069251005e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.36 | consumed tokens: 461670400.0 | grad norm avg: 13.95 | grad norm last: 12.44 | 
2025-12-28T04:11:55 | step: 901800 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.3155065062164795e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.16 | consumed tokens: 461721600.0 | grad norm avg: 13.77 | grad norm last: 11.32 | 
2025-12-28T04:11:57 | step: 901900 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.3149933693057392e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.08 | consumed tokens: 461772800.0 | grad norm avg: 13.79 | grad norm last: 11.29 | 
2025-12-28T04:11:59 | step: 902000 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.3144805961928796e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.89 | consumed tokens: 461824000.0 | grad norm avg: 13.85 | grad norm last: 16.72 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_902000-seen_tokens_461824000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_902000-seen_tokens_461824000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_902000-seen_tokens_461824000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_902000-seen_tokens_461824000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_902000-seen_tokens_461824000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_902000-seen_tokens_461824000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_902000-seen_tokens_461824000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_902000-seen_tokens_461824000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:12:02 | step: 902100 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.3139683687768411e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.52 | train loss last: 4.88 | consumed tokens: 461875200.0 | grad norm avg: 13.91 | grad norm last: 27.97 | 
2025-12-28T04:12:04 | step: 902200 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.313456323259743e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.84 | consumed tokens: 461926400.0 | grad norm avg: 14.31 | grad norm last: 13.19 | 
2025-12-28T04:12:06 | step: 902300 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.3129448234394658e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.81 | consumed tokens: 461977600.0 | grad norm avg: 14.4 | grad norm last: 13.05 | 
2025-12-28T04:12:08 | step: 902400 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.3124336874170695e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.64 | consumed tokens: 462028800.0 | grad norm avg: 14.62 | grad norm last: 11.7 | 
2025-12-28T04:12:10 | step: 902500 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.3119230970914941e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.38 | consumed tokens: 462080000.0 | grad norm avg: 13.6 | grad norm last: 14.6 | 
2025-12-28T04:12:12 | step: 902600 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.3114126886648592e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.3 | consumed tokens: 462131200.0 | grad norm avg: 14.43 | grad norm last: 11.8 | 
2025-12-28T04:12:14 | step: 902700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.310902734985575e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.52 | consumed tokens: 462182400.0 | grad norm avg: 13.74 | grad norm last: 12.76 | 
2025-12-28T04:12:16 | step: 902800 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.3103931451041717e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.56 | consumed tokens: 462233600.0 | grad norm avg: 13.83 | grad norm last: 12.11 | 
2025-12-28T04:12:18 | step: 902900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.3098841009195894e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.03 | consumed tokens: 462284800.0 | grad norm avg: 13.96 | grad norm last: 14.66 | 
2025-12-28T04:12:20 | step: 903000 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.3093754205328878e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.27 | consumed tokens: 462336000.0 | grad norm avg: 14.03 | grad norm last: 11.95 | 
2025-12-28T04:12:22 | step: 903100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.3088671948935371e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 2.97 | consumed tokens: 462387200.0 | grad norm avg: 14.05 | grad norm last: 13.35 | 
2025-12-28T04:12:24 | step: 903200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.3083593330520671e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 2.94 | consumed tokens: 462438400.0 | grad norm avg: 14.12 | grad norm last: 17.05 | 
2025-12-28T04:12:26 | step: 903300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.3078516531095374e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.78 | consumed tokens: 462489600.0 | grad norm avg: 14.11 | grad norm last: 12.8 | 
2025-12-28T04:12:28 | step: 903400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.3073445188638289e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.06 | consumed tokens: 462540800.0 | grad norm avg: 14.47 | grad norm last: 14.29 | 
2025-12-28T04:12:30 | step: 903500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.3068379303149413e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 2.77 | consumed tokens: 462592000.0 | grad norm avg: 14.18 | grad norm last: 12.85 | 
2025-12-28T04:12:33 | step: 903600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.3063316146144643e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 4.41 | consumed tokens: 462643200.0 | grad norm avg: 13.71 | grad norm last: 12.47 | 
2025-12-28T04:12:35 | step: 903700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.3058258446108084e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.0 | consumed tokens: 462694400.0 | grad norm avg: 15.46 | grad norm last: 13.85 | 
2025-12-28T04:12:37 | step: 903800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.3053202565060928e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.8 | consumed tokens: 462745600.0 | grad norm avg: 14.32 | grad norm last: 14.99 | 
2025-12-28T04:12:39 | step: 903900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.3048152140981983e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.3 | consumed tokens: 462796800.0 | grad norm avg: 14.25 | grad norm last: 12.42 | 
2025-12-28T04:12:41 | step: 904000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.3043104445387144e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.66 | consumed tokens: 462848000.0 | grad norm avg: 13.75 | grad norm last: 18.14 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_904000-seen_tokens_462848000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_904000-seen_tokens_462848000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_904000-seen_tokens_462848000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_904000-seen_tokens_462848000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_904000-seen_tokens_462848000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_904000-seen_tokens_462848000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_904000-seen_tokens_462848000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_904000-seen_tokens_462848000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:12:43 | step: 904100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.3038062206760515e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.03 | consumed tokens: 462899200.0 | grad norm avg: 13.63 | grad norm last: 13.41 | 
2025-12-28T04:12:45 | step: 904200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.3033025425102096e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.41 | consumed tokens: 462950400.0 | grad norm avg: 14.1 | grad norm last: 30.09 | 
2025-12-28T04:12:47 | step: 904300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.3027990462433081e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.14 | consumed tokens: 463001600.0 | grad norm avg: 14.6 | grad norm last: 19.05 | 
2025-12-28T04:12:49 | step: 904400 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.3022959137742873e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.67 | consumed tokens: 463052800.0 | grad norm avg: 14.01 | grad norm last: 12.75 | 
2025-12-28T04:12:51 | step: 904500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.3017932360526174e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.33 | consumed tokens: 463104000.0 | grad norm avg: 13.9 | grad norm last: 12.88 | 
2025-12-28T04:12:53 | step: 904600 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.3012909221288282e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.69 | consumed tokens: 463155200.0 | grad norm avg: 14.1 | grad norm last: 11.92 | 
2025-12-28T04:12:55 | step: 904700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.3007891539018601e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.91 | consumed tokens: 463206400.0 | grad norm avg: 14.6 | grad norm last: 17.41 | 
2025-12-28T04:12:57 | step: 904800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.3002875675738323e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.61 | consumed tokens: 463257600.0 | grad norm avg: 13.86 | grad norm last: 12.5 | 
2025-12-28T04:12:59 | step: 904900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.2997866178920958e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.39 | consumed tokens: 463308800.0 | grad norm avg: 14.4 | grad norm last: 11.18 | 
2025-12-28T04:13:01 | step: 905000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.29928603200824e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 2.88 | consumed tokens: 463360000.0 | grad norm avg: 13.78 | grad norm last: 12.68 | 
2025-12-28T04:13:03 | step: 905100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.2987858099222649e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.19 | consumed tokens: 463411200.0 | grad norm avg: 14.12 | grad norm last: 11.86 | 
2025-12-28T04:13:05 | step: 905200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.2982859516341705e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.53 | consumed tokens: 463462400.0 | grad norm avg: 13.91 | grad norm last: 14.34 | 
2025-12-28T04:13:07 | step: 905300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.2977866390428971e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.42 | consumed tokens: 463513600.0 | grad norm avg: 14.22 | grad norm last: 15.41 | 
2025-12-28T04:13:09 | step: 905400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.2972875083505642e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.58 | consumed tokens: 463564800.0 | grad norm avg: 13.42 | grad norm last: 13.57 | 
2025-12-28T04:13:11 | step: 905500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.2967889233550522e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.47 | consumed tokens: 463616000.0 | grad norm avg: 14.0 | grad norm last: 17.49 | 
2025-12-28T04:13:14 | step: 905600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.296290702157421e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.2 | consumed tokens: 463667200.0 | grad norm avg: 15.12 | grad norm last: 12.53 | 
2025-12-28T04:13:16 | step: 905700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.2957930266566109e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.12 | consumed tokens: 463718400.0 | grad norm avg: 13.89 | grad norm last: 11.22 | 
2025-12-28T04:13:18 | step: 905800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.2952955330547411e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 2.89 | consumed tokens: 463769600.0 | grad norm avg: 14.16 | grad norm last: 12.23 | 
2025-12-28T04:13:20 | step: 905900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.2947984942002222e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.09 | consumed tokens: 463820800.0 | grad norm avg: 13.94 | grad norm last: 16.14 | 
2025-12-28T04:13:22 | step: 906000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.2943019100930542e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.0 | consumed tokens: 463872000.0 | grad norm avg: 14.23 | grad norm last: 12.24 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_906000-seen_tokens_463872000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_906000-seen_tokens_463872000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_906000-seen_tokens_463872000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_906000-seen_tokens_463872000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_906000-seen_tokens_463872000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_906000-seen_tokens_463872000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_906000-seen_tokens_463872000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_906000-seen_tokens_463872000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:13:24 | step: 906100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.2938056897837669e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.54 | train loss last: 3.7 | consumed tokens: 463923200.0 | grad norm avg: 13.56 | grad norm last: 13.39 | 
2025-12-28T04:13:26 | step: 906200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.2933099242218304e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.36 | consumed tokens: 463974400.0 | grad norm avg: 14.29 | grad norm last: 14.26 | 
2025-12-28T04:13:28 | step: 906300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.2928144315083046e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.42 | consumed tokens: 464025600.0 | grad norm avg: 14.29 | grad norm last: 14.74 | 
2025-12-28T04:13:30 | step: 906400 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.2923195754410699e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.62 | consumed tokens: 464076800.0 | grad norm avg: 13.7 | grad norm last: 11.46 | 
2025-12-28T04:13:32 | step: 906500 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.2918249012727756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.34 | consumed tokens: 464128000.0 | grad norm avg: 13.88 | grad norm last: 14.39 | 
2025-12-28T04:13:34 | step: 906600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.2913308637507726e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.84 | consumed tokens: 464179200.0 | grad norm avg: 13.84 | grad norm last: 13.3 | 
2025-12-28T04:13:36 | step: 906700 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.29083709907718e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.46 | train loss last: 3.06 | consumed tokens: 464230400.0 | grad norm avg: 14.3 | grad norm last: 12.68 | 
2025-12-28T04:13:38 | step: 906800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.2903436982014682e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.72 | consumed tokens: 464281600.0 | grad norm avg: 13.47 | grad norm last: 13.65 | 
2025-12-28T04:13:40 | step: 906900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.2898507520731073e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.47 | train loss last: 4.16 | consumed tokens: 464332800.0 | grad norm avg: 13.81 | grad norm last: 14.13 | 
2025-12-28T04:13:42 | step: 907000 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.2893582606920972e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.33 | consumed tokens: 464384000.0 | grad norm avg: 14.3 | grad norm last: 14.44 | 
2025-12-28T04:13:44 | step: 907100 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.2888661331089679e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.67 | consumed tokens: 464435200.0 | grad norm avg: 13.66 | grad norm last: 14.37 | 
2025-12-28T04:13:46 | step: 907200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.2883744602731895e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.75 | consumed tokens: 464486400.0 | grad norm avg: 14.2 | grad norm last: 19.93 | 
2025-12-28T04:13:49 | step: 907300 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.2878830602858216e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.69 | consumed tokens: 464537600.0 | grad norm avg: 13.64 | grad norm last: 14.19 | 
2025-12-28T04:13:51 | step: 907400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.2873922059952747e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.73 | consumed tokens: 464588800.0 | grad norm avg: 13.94 | grad norm last: 11.57 | 
2025-12-28T04:13:53 | step: 907500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.2869015336036682e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.62 | consumed tokens: 464640000.0 | grad norm avg: 14.31 | grad norm last: 14.66 | 
2025-12-28T04:13:55 | step: 907600 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.286411497858353e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.67 | consumed tokens: 464691200.0 | grad norm avg: 13.93 | grad norm last: 12.61 | 
2025-12-28T04:13:57 | step: 907700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.2859217349614482e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 5.34 | consumed tokens: 464742400.0 | grad norm avg: 14.1 | grad norm last: 32.1 | 
2025-12-28T04:13:59 | step: 907800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.2854324268118944e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.64 | consumed tokens: 464793600.0 | grad norm avg: 14.17 | grad norm last: 10.87 | 
2025-12-28T04:14:01 | step: 907900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.2849435734096915e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.22 | consumed tokens: 464844800.0 | grad norm avg: 13.96 | grad norm last: 15.04 | 
2025-12-28T04:14:03 | step: 908000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.2844550838053692e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.33 | consumed tokens: 464896000.0 | grad norm avg: 13.61 | grad norm last: 12.52 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_908000-seen_tokens_464896000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_908000-seen_tokens_464896000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_908000-seen_tokens_464896000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_908000-seen_tokens_464896000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_908000-seen_tokens_464896000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_908000-seen_tokens_464896000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_908000-seen_tokens_464896000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_908000-seen_tokens_464896000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:14:05 | step: 908100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.2839668670494575e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.94 | consumed tokens: 464947200.0 | grad norm avg: 14.26 | grad norm last: 11.52 | 
2025-12-28T04:14:07 | step: 908200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.283479286939837e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 2.72 | consumed tokens: 464998400.0 | grad norm avg: 14.04 | grad norm last: 12.31 | 
2025-12-28T04:14:09 | step: 908300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.282991888729157e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.03 | consumed tokens: 465049600.0 | grad norm avg: 14.01 | grad norm last: 14.11 | 
2025-12-28T04:14:11 | step: 908400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.282505127164768e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.31 | consumed tokens: 465100800.0 | grad norm avg: 13.68 | grad norm last: 11.92 | 
2025-12-28T04:14:13 | step: 908500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.2820186384487897e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.66 | consumed tokens: 465152000.0 | grad norm avg: 13.96 | grad norm last: 13.81 | 
2025-12-28T04:14:15 | step: 908600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.2815326044801623e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.19 | consumed tokens: 465203200.0 | grad norm avg: 13.64 | grad norm last: 12.65 | 
2025-12-28T04:14:17 | step: 908700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.2810469343094155e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.03 | consumed tokens: 465254400.0 | grad norm avg: 14.02 | grad norm last: 15.51 | 
2025-12-28T04:14:19 | step: 908800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.2805617188860197e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.62 | consumed tokens: 465305600.0 | grad norm avg: 14.0 | grad norm last: 15.06 | 
2025-12-28T04:14:21 | step: 908900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2800769582099747e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.53 | consumed tokens: 465356800.0 | grad norm avg: 14.71 | grad norm last: 13.29 | 
2025-12-28T04:14:23 | step: 909000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.27959237943287e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.16 | consumed tokens: 465408000.0 | grad norm avg: 14.42 | grad norm last: 11.79 | 
2025-12-28T04:14:26 | step: 909100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2791083463525865e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.47 | consumed tokens: 465459200.0 | grad norm avg: 13.88 | grad norm last: 13.61 | 
2025-12-28T04:14:28 | step: 909200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.2786247680196539e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 2.61 | consumed tokens: 465510400.0 | grad norm avg: 13.92 | grad norm last: 10.8 | 
2025-12-28T04:14:30 | step: 909300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.2781415534846019e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.27 | consumed tokens: 465561600.0 | grad norm avg: 13.48 | grad norm last: 12.67 | 
2025-12-28T04:14:32 | step: 909400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.2776586117979605e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.91 | consumed tokens: 465612800.0 | grad norm avg: 13.94 | grad norm last: 16.31 | 
2025-12-28T04:14:34 | step: 909500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.2771762158081401e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.17 | consumed tokens: 465664000.0 | grad norm avg: 14.33 | grad norm last: 14.11 | 
2025-12-28T04:14:36 | step: 909600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.2766943655151408e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.66 | consumed tokens: 465715200.0 | grad norm avg: 14.31 | grad norm last: 17.46 | 
2025-12-28T04:14:38 | step: 909700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2762126971210819e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.98 | consumed tokens: 465766400.0 | grad norm avg: 13.67 | grad norm last: 12.44 | 
2025-12-28T04:14:40 | step: 909800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.2757314834743738e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.62 | consumed tokens: 465817600.0 | grad norm avg: 13.81 | grad norm last: 13.72 | 
2025-12-28T04:14:42 | step: 909900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.2752508155244868e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.61 | consumed tokens: 465868800.0 | grad norm avg: 14.26 | grad norm last: 13.0 | 
2025-12-28T04:14:44 | step: 910000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.2747703294735402e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.2 | consumed tokens: 465920000.0 | grad norm avg: 13.83 | grad norm last: 12.54 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_910000-seen_tokens_465920000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_910000-seen_tokens_465920000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_910000-seen_tokens_465920000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_910000-seen_tokens_465920000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_910000-seen_tokens_465920000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_910000-seen_tokens_465920000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_910000-seen_tokens_465920000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_910000-seen_tokens_465920000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:14:46 | step: 910100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.2742903891194146e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.56 | train loss last: 3.36 | consumed tokens: 465971200.0 | grad norm avg: 14.03 | grad norm last: 12.52 | 
2025-12-28T04:14:48 | step: 910200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.27381090351264e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.34 | consumed tokens: 466022400.0 | grad norm avg: 13.79 | grad norm last: 13.13 | 
2025-12-28T04:14:50 | step: 910300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2733315998048056e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.47 | consumed tokens: 466073600.0 | grad norm avg: 13.92 | grad norm last: 11.66 | 
2025-12-28T04:14:52 | step: 910400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2728528417937923e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.22 | consumed tokens: 466124800.0 | grad norm avg: 14.4 | grad norm last: 12.96 | 
2025-12-28T04:14:54 | step: 910500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.2723746294796001e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.72 | consumed tokens: 466176000.0 | grad norm avg: 14.12 | grad norm last: 14.33 | 
2025-12-28T04:14:56 | step: 910600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.2718965990643483e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.73 | consumed tokens: 466227200.0 | grad norm avg: 13.94 | grad norm last: 14.97 | 
2025-12-28T04:14:58 | step: 910700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2714191143459175e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.12 | consumed tokens: 466278400.0 | grad norm avg: 13.79 | grad norm last: 15.34 | 
2025-12-28T04:15:00 | step: 910800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.2709419934253674e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.36 | consumed tokens: 466329600.0 | grad norm avg: 13.66 | grad norm last: 14.63 | 
2025-12-28T04:15:02 | step: 910900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.270465236302698e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.3 | consumed tokens: 466380800.0 | grad norm avg: 13.57 | grad norm last: 12.54 | 
2025-12-28T04:15:04 | step: 911000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2699889339273795e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.12 | consumed tokens: 466432000.0 | grad norm avg: 13.74 | grad norm last: 13.07 | 
2025-12-28T04:15:06 | step: 911100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.2695129953499418e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.09 | consumed tokens: 466483200.0 | grad norm avg: 14.37 | grad norm last: 11.76 | 
2025-12-28T04:15:08 | step: 911200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.2690375115198549e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.8 | consumed tokens: 466534400.0 | grad norm avg: 13.91 | grad norm last: 12.35 | 
2025-12-28T04:15:10 | step: 911300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.2685624824371189e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 5.56 | consumed tokens: 466585600.0 | grad norm avg: 13.99 | grad norm last: 23.35 | 
2025-12-28T04:15:13 | step: 911400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.2680877262027934e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.0 | consumed tokens: 466636800.0 | grad norm avg: 13.76 | grad norm last: 12.99 | 
2025-12-28T04:15:15 | step: 911500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.2676134247158188e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 2.95 | consumed tokens: 466688000.0 | grad norm avg: 13.89 | grad norm last: 11.95 | 
2025-12-28T04:15:17 | step: 911600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.2671395779761951e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.31 | consumed tokens: 466739200.0 | grad norm avg: 13.57 | grad norm last: 17.77 | 
2025-12-28T04:15:19 | step: 911700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.2666660950344522e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.5 | consumed tokens: 466790400.0 | grad norm avg: 14.14 | grad norm last: 14.29 | 
2025-12-28T04:15:21 | step: 911800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.26619306684006e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.34 | consumed tokens: 466841600.0 | grad norm avg: 13.62 | grad norm last: 12.56 | 
2025-12-28T04:15:23 | step: 911900 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 1.2657204933930188e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.59 | consumed tokens: 466892800.0 | grad norm avg: 14.03 | grad norm last: 13.22 | 
2025-12-28T04:15:25 | step: 912000 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.2652481927943882e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 2.86 | consumed tokens: 466944000.0 | grad norm avg: 13.76 | grad norm last: 10.93 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_912000-seen_tokens_466944000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_912000-seen_tokens_466944000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_912000-seen_tokens_466944000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_912000-seen_tokens_466944000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_912000-seen_tokens_466944000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_912000-seen_tokens_466944000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_912000-seen_tokens_466944000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_912000-seen_tokens_466944000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:15:27 | step: 912100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.2647763469431084e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.6 | train loss last: 2.78 | consumed tokens: 466995200.0 | grad norm avg: 13.96 | grad norm last: 24.22 | 
2025-12-28T04:15:29 | step: 912200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.2643049558391795e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.72 | consumed tokens: 467046400.0 | grad norm avg: 13.78 | grad norm last: 13.52 | 
2025-12-28T04:15:31 | step: 912300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.2638339285331313e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.36 | consumed tokens: 467097600.0 | grad norm avg: 14.24 | grad norm last: 17.18 | 
2025-12-28T04:15:33 | step: 912400 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.263363355974434e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.42 | consumed tokens: 467148800.0 | grad norm avg: 13.78 | grad norm last: 12.44 | 
2025-12-28T04:15:35 | step: 912500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.2628931472136173e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.44 | consumed tokens: 467200000.0 | grad norm avg: 14.38 | grad norm last: 15.69 | 
2025-12-28T04:15:37 | step: 912600 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.2624233022506814e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.78 | consumed tokens: 467251200.0 | grad norm avg: 14.04 | grad norm last: 13.36 | 
2025-12-28T04:15:39 | step: 912700 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 1.2619540029845666e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.06 | consumed tokens: 467302400.0 | grad norm avg: 14.12 | grad norm last: 12.63 | 
2025-12-28T04:15:41 | step: 912800 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.2614848856173921e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.69 | consumed tokens: 467353600.0 | grad norm avg: 14.17 | grad norm last: 18.55 | 
2025-12-28T04:15:43 | step: 912900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.2610163139470387e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.12 | consumed tokens: 467404800.0 | grad norm avg: 13.55 | grad norm last: 12.78 | 
2025-12-28T04:15:46 | step: 913000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.2605482879735064e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.5 | consumed tokens: 467456000.0 | grad norm avg: 13.71 | grad norm last: 12.02 | 
2025-12-28T04:15:48 | step: 913100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.2600804438989144e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.33 | consumed tokens: 467507200.0 | grad norm avg: 14.14 | grad norm last: 11.19 | 
2025-12-28T04:15:50 | step: 913200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.2596130545716733e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.55 | consumed tokens: 467558400.0 | grad norm avg: 13.92 | grad norm last: 14.8 | 
2025-12-28T04:15:52 | step: 913300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.2591462109412532e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.92 | consumed tokens: 467609600.0 | grad norm avg: 14.58 | grad norm last: 16.52 | 
2025-12-28T04:15:54 | step: 913400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.2586796401592437e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.27 | consumed tokens: 467660800.0 | grad norm avg: 13.97 | grad norm last: 13.11 | 
2025-12-28T04:15:56 | step: 913500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.2582135241245851e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.06 | consumed tokens: 467712000.0 | grad norm avg: 13.77 | grad norm last: 23.4 | 
2025-12-28T04:15:58 | step: 913600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.2577477718878072e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.61 | consumed tokens: 467763200.0 | grad norm avg: 13.92 | grad norm last: 12.7 | 
2025-12-28T04:16:00 | step: 913700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.2572824743983801e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.44 | consumed tokens: 467814400.0 | grad norm avg: 14.49 | grad norm last: 15.32 | 
2025-12-28T04:16:02 | step: 913800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.2568175407068338e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.86 | consumed tokens: 467865600.0 | grad norm avg: 13.47 | grad norm last: 15.61 | 
2025-12-28T04:16:04 | step: 913900 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.2563530617626384e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.95 | consumed tokens: 467916800.0 | grad norm avg: 13.93 | grad norm last: 15.94 | 
2025-12-28T04:16:06 | step: 914000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.2558889466163237e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.28 | consumed tokens: 467968000.0 | grad norm avg: 13.73 | grad norm last: 13.32 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_914000-seen_tokens_467968000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_914000-seen_tokens_467968000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_914000-seen_tokens_467968000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_914000-seen_tokens_467968000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_914000-seen_tokens_467968000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_914000-seen_tokens_467968000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_914000-seen_tokens_467968000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_914000-seen_tokens_467968000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:16:08 | step: 914100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2554252862173598e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.55 | train loss last: 3.31 | consumed tokens: 468019200.0 | grad norm avg: 13.61 | grad norm last: 12.05 | 
2025-12-28T04:16:10 | step: 914200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.2549619896162767e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.51 | train loss last: 3.44 | consumed tokens: 468070400.0 | grad norm avg: 13.57 | grad norm last: 12.2 | 
2025-12-28T04:16:12 | step: 914300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.2544991477625445e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.56 | train loss last: 3.7 | consumed tokens: 468121600.0 | grad norm avg: 14.01 | grad norm last: 12.83 | 
2025-12-28T04:16:14 | step: 914400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.254036669706693e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 3.11 | consumed tokens: 468172800.0 | grad norm avg: 13.67 | grad norm last: 14.4 | 
2025-12-28T04:16:16 | step: 914500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.2535746463981923e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.5 | train loss last: 2.31 | consumed tokens: 468224000.0 | grad norm avg: 13.49 | grad norm last: 10.06 | 
2025-12-28T04:16:18 | step: 914600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.2531129868875723e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.6 | train loss last: 4.47 | consumed tokens: 468275200.0 | grad norm avg: 13.7 | grad norm last: 22.72 | 
2025-12-28T04:16:21 | step: 914700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2526517821243033e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.61 | train loss last: 4.34 | consumed tokens: 468326400.0 | grad norm avg: 14.06 | grad norm last: 15.83 | 
2025-12-28T04:16:23 | step: 914800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.252190941158915e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.43 | train loss last: 4.53 | consumed tokens: 468377600.0 | grad norm avg: 13.57 | grad norm last: 12.96 | 
2025-12-28T04:16:25 | step: 914900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.2517305549408775e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.49 | train loss last: 3.95 | consumed tokens: 468428800.0 | grad norm avg: 13.71 | grad norm last: 14.1 | 
2025-12-28T04:16:27 | step: 915000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.2512705325207207e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 2.98 | consumed tokens: 468480000.0 | grad norm avg: 13.86 | grad norm last: 11.24 | 
2025-12-28T04:16:29 | step: 915100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.2508109648479149e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.51 | train loss last: 3.3 | consumed tokens: 468531200.0 | grad norm avg: 13.57 | grad norm last: 13.45 | 
2025-12-28T04:16:31 | step: 915200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2503517609729897e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.5 | train loss last: 4.97 | consumed tokens: 468582400.0 | grad norm avg: 13.6 | grad norm last: 16.22 | 
2025-12-28T04:16:33 | step: 915300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.2498930118454155e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.65 | train loss last: 4.0 | consumed tokens: 468633600.0 | grad norm avg: 14.52 | grad norm last: 14.76 | 
2025-12-28T04:16:35 | step: 915400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.2494346265157219e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.55 | train loss last: 5.16 | consumed tokens: 468684800.0 | grad norm avg: 14.14 | grad norm last: 37.53 | 
2025-12-28T04:16:37 | step: 915500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.2489766959333792e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.52 | train loss last: 3.22 | consumed tokens: 468736000.0 | grad norm avg: 13.72 | grad norm last: 13.03 | 
2025-12-28T04:16:39 | step: 915600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2485191291489173e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 3.47 | consumed tokens: 468787200.0 | grad norm avg: 13.85 | grad norm last: 13.44 | 
2025-12-28T04:16:41 | step: 915700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2480620171118062e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.62 | train loss last: 4.19 | consumed tokens: 468838400.0 | grad norm avg: 13.77 | grad norm last: 13.41 | 
2025-12-28T04:16:43 | step: 915800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2476052688725758e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.6 | train loss last: 3.34 | consumed tokens: 468889600.0 | grad norm avg: 13.58 | grad norm last: 12.06 | 
2025-12-28T04:16:45 | step: 915900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.2471488844312262e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.62 | train loss last: 4.0 | consumed tokens: 468940800.0 | grad norm avg: 14.1 | grad norm last: 14.7 | 
2025-12-28T04:16:47 | step: 916000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2466928637877572e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.53 | train loss last: 4.25 | consumed tokens: 468992000.0 | grad norm avg: 13.74 | grad norm last: 15.57 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_916000-seen_tokens_468992000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_916000-seen_tokens_468992000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_916000-seen_tokens_468992000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_916000-seen_tokens_468992000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_916000-seen_tokens_468992000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_916000-seen_tokens_468992000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_916000-seen_tokens_468992000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_916000-seen_tokens_468992000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:16:49 | step: 916100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2462373888411094e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 3.64 | train loss last: 3.17 | consumed tokens: 469043200.0 | grad norm avg: 13.88 | grad norm last: 13.95 | 
2025-12-28T04:16:51 | step: 916200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.2457824595912825e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.56 | train loss last: 3.5 | consumed tokens: 469094400.0 | grad norm avg: 14.26 | grad norm last: 14.05 | 
2025-12-28T04:16:53 | step: 916300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.245327712240396e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.61 | train loss last: 3.28 | consumed tokens: 469145600.0 | grad norm avg: 13.81 | grad norm last: 14.06 | 
2025-12-28T04:16:55 | step: 916400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.2448734196368605e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.45 | train loss last: 3.27 | consumed tokens: 469196800.0 | grad norm avg: 13.49 | grad norm last: 11.98 | 
2025-12-28T04:16:57 | step: 916500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.244419672730146e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.52 | train loss last: 3.09 | consumed tokens: 469248000.0 | grad norm avg: 13.63 | grad norm last: 11.8 | 
2025-12-28T04:16:59 | step: 916600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.2439661077223718e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.6 | train loss last: 4.31 | consumed tokens: 469299200.0 | grad norm avg: 13.63 | grad norm last: 18.65 | 
2025-12-28T04:17:01 | step: 916700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.2435130884114187e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.54 | train loss last: 3.39 | consumed tokens: 469350400.0 | grad norm avg: 13.79 | grad norm last: 17.27 | 
2025-12-28T04:17:03 | step: 916800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.2430605238478165e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.47 | train loss last: 3.38 | consumed tokens: 469401600.0 | grad norm avg: 13.44 | grad norm last: 11.75 | 
2025-12-28T04:17:05 | step: 916900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.2426081411831547e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 5.09 | consumed tokens: 469452800.0 | grad norm avg: 13.6 | grad norm last: 17.89 | 
2025-12-28T04:17:07 | step: 917000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.2421563042153139e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.55 | train loss last: 3.73 | consumed tokens: 469504000.0 | grad norm avg: 14.11 | grad norm last: 14.29 | 
2025-12-28T04:17:09 | step: 917100 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.2417050129442941e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.63 | train loss last: 3.41 | consumed tokens: 469555200.0 | grad norm avg: 13.7 | grad norm last: 13.67 | 
2025-12-28T04:17:12 | step: 917200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.2412539035722148e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.56 | train loss last: 4.56 | consumed tokens: 469606400.0 | grad norm avg: 13.86 | grad norm last: 17.55 | 
2025-12-28T04:17:14 | step: 917300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.2408033398969565e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.55 | train loss last: 3.92 | consumed tokens: 469657600.0 | grad norm avg: 13.92 | grad norm last: 12.66 | 
2025-12-28T04:17:16 | step: 917400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.2403531400195789e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 3.8 | consumed tokens: 469708800.0 | grad norm avg: 13.63 | grad norm last: 12.61 | 
2025-12-28T04:17:18 | step: 917500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.2399034858390223e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.64 | train loss last: 3.11 | consumed tokens: 469760000.0 | grad norm avg: 13.79 | grad norm last: 13.02 | 
2025-12-28T04:17:20 | step: 917600 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.2394540135574061e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.6 | train loss last: 3.66 | consumed tokens: 469811200.0 | grad norm avg: 13.67 | grad norm last: 13.5 | 
2025-12-28T04:17:22 | step: 917700 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.239005086972611e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.59 | train loss last: 3.72 | consumed tokens: 469862400.0 | grad norm avg: 13.97 | grad norm last: 16.86 | 
2025-12-28T04:17:24 | step: 917800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.2385565241856966e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.51 | train loss last: 3.66 | consumed tokens: 469913600.0 | grad norm avg: 13.92 | grad norm last: 15.83 | 
2025-12-28T04:17:26 | step: 917900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.238108325196663e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.54 | train loss last: 3.36 | consumed tokens: 469964800.0 | grad norm avg: 13.81 | grad norm last: 12.69 | 
2025-12-28T04:17:28 | step: 918000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.2376606719044503e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 3.64 | consumed tokens: 470016000.0 | grad norm avg: 13.78 | grad norm last: 12.64 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_918000-seen_tokens_470016000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_918000-seen_tokens_470016000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_918000-seen_tokens_470016000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_918000-seen_tokens_470016000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_918000-seen_tokens_470016000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_918000-seen_tokens_470016000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_918000-seen_tokens_470016000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_918000-seen_tokens_470016000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:17:30 | step: 918100 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.2372132914606482e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.56 | train loss last: 3.36 | consumed tokens: 470067200.0 | grad norm avg: 14.15 | grad norm last: 13.53 | 
2025-12-28T04:17:32 | step: 918200 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.2367662748147268e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.52 | train loss last: 3.52 | consumed tokens: 470118400.0 | grad norm avg: 13.65 | grad norm last: 14.14 | 
2025-12-28T04:17:34 | step: 918300 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.2363198948150966e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.65 | train loss last: 4.12 | consumed tokens: 470169600.0 | grad norm avg: 14.14 | grad norm last: 13.2 | 
2025-12-28T04:17:36 | step: 918400 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.235873787663877e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.51 | train loss last: 3.27 | consumed tokens: 470220800.0 | grad norm avg: 13.63 | grad norm last: 12.13 | 
2025-12-28T04:17:38 | step: 918500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.2354281352600083e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.59 | train loss last: 3.95 | consumed tokens: 470272000.0 | grad norm avg: 13.76 | grad norm last: 14.25 | 
2025-12-28T04:17:40 | step: 918600 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.2349828466540202e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.54 | train loss last: 2.75 | consumed tokens: 470323200.0 | grad norm avg: 13.68 | grad norm last: 11.24 | 
2025-12-28T04:17:43 | step: 918700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.2345380127953831e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.54 | train loss last: 3.05 | consumed tokens: 470374400.0 | grad norm avg: 13.67 | grad norm last: 13.26 | 
2025-12-28T04:17:45 | step: 918800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.2340936336840969e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.59 | train loss last: 3.84 | consumed tokens: 470425600.0 | grad norm avg: 13.74 | grad norm last: 12.01 | 
2025-12-28T04:17:47 | step: 918900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.2336495274212211e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 3.58 | consumed tokens: 470476800.0 | grad norm avg: 14.27 | grad norm last: 12.95 | 
2025-12-28T04:17:49 | step: 919000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.2332059668551665e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.59 | train loss last: 3.3 | consumed tokens: 470528000.0 | grad norm avg: 13.73 | grad norm last: 11.71 | 
2025-12-28T04:17:51 | step: 919100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.2327626791375224e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.5 | train loss last: 3.47 | consumed tokens: 470579200.0 | grad norm avg: 13.39 | grad norm last: 13.16 | 
2025-12-28T04:17:53 | step: 919200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.2323199371166993e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.55 | train loss last: 3.36 | consumed tokens: 470630400.0 | grad norm avg: 13.99 | grad norm last: 13.73 | 
2025-12-28T04:17:55 | step: 919300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.2318774679442868e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.51 | train loss last: 3.66 | consumed tokens: 470681600.0 | grad norm avg: 13.6 | grad norm last: 12.66 | 
2025-12-28T04:17:57 | step: 919400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.2314355444686953e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.65 | train loss last: 3.94 | consumed tokens: 470732800.0 | grad norm avg: 14.5 | grad norm last: 15.31 | 
2025-12-28T04:17:59 | step: 919500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2309940757404547e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 2.88 | consumed tokens: 470784000.0 | grad norm avg: 13.85 | grad norm last: 11.7 | 
2025-12-28T04:18:01 | step: 919600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.2305527889111545e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.51 | train loss last: 2.97 | consumed tokens: 470835200.0 | grad norm avg: 13.3 | grad norm last: 11.8 | 
2025-12-28T04:18:03 | step: 919700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.2301120477786753e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.64 | train loss last: 3.91 | consumed tokens: 470886400.0 | grad norm avg: 13.85 | grad norm last: 15.03 | 
2025-12-28T04:18:05 | step: 919800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.2296716704440769e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.55 | train loss last: 3.92 | consumed tokens: 470937600.0 | grad norm avg: 13.64 | grad norm last: 13.64 | 
2025-12-28T04:18:07 | step: 919900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.2292318388062995e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.55 | train loss last: 2.69 | consumed tokens: 470988800.0 | grad norm avg: 13.65 | grad norm last: 10.73 | 
2025-12-28T04:18:09 | step: 920000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.2287923709664028e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.68 | train loss last: 4.09 | consumed tokens: 471040000.0 | grad norm avg: 13.99 | grad norm last: 14.4 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_920000-seen_tokens_471040000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_920000-seen_tokens_471040000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_920000-seen_tokens_471040000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_920000-seen_tokens_471040000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_920000-seen_tokens_471040000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_920000-seen_tokens_471040000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_920000-seen_tokens_471040000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_920000-seen_tokens_471040000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:18:11 | step: 920100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.2283530850254465e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 3.62 | train loss last: 4.25 | consumed tokens: 471091200.0 | grad norm avg: 13.63 | grad norm last: 15.1 | 
2025-12-28T04:18:13 | step: 920200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.2279143447813112e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.6 | train loss last: 3.14 | consumed tokens: 471142400.0 | grad norm avg: 13.92 | grad norm last: 11.9 | 
2025-12-28T04:18:15 | step: 920300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.227476150233997e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 3.28 | consumed tokens: 471193600.0 | grad norm avg: 14.05 | grad norm last: 12.08 | 
2025-12-28T04:18:17 | step: 920400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.2270382285350934e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.48 | train loss last: 4.28 | consumed tokens: 471244800.0 | grad norm avg: 13.71 | grad norm last: 14.45 | 
2025-12-28T04:18:19 | step: 920500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.2266008525330108e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.48 | train loss last: 3.56 | consumed tokens: 471296000.0 | grad norm avg: 13.39 | grad norm last: 13.89 | 
2025-12-28T04:18:21 | step: 920600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.2261637493793387e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.6 | train loss last: 3.53 | consumed tokens: 471347200.0 | grad norm avg: 14.56 | grad norm last: 14.56 | 
2025-12-28T04:18:23 | step: 920700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.2257271009730175e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.55 | train loss last: 3.39 | consumed tokens: 471398400.0 | grad norm avg: 13.51 | grad norm last: 15.07 | 
2025-12-28T04:18:25 | step: 920800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.2252909073140472e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.6 | train loss last: 3.58 | consumed tokens: 471449600.0 | grad norm avg: 13.9 | grad norm last: 14.14 | 
2025-12-28T04:18:27 | step: 920900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.2248550774529576e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.67 | train loss last: 3.12 | consumed tokens: 471500800.0 | grad norm avg: 14.72 | grad norm last: 12.45 | 
2025-12-28T04:18:29 | step: 921000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2244196113897488e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.59 | train loss last: 3.45 | consumed tokens: 471552000.0 | grad norm avg: 13.64 | grad norm last: 12.25 | 
2025-12-28T04:18:31 | step: 921100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.2239846000738908e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.6 | train loss last: 3.11 | consumed tokens: 471603200.0 | grad norm avg: 13.86 | grad norm last: 11.85 | 
2025-12-28T04:18:33 | step: 921200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.2235500435053837e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 3.78 | consumed tokens: 471654400.0 | grad norm avg: 13.6 | grad norm last: 14.94 | 
2025-12-28T04:18:35 | step: 921300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2231158507347573e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 3.7 | consumed tokens: 471705600.0 | grad norm avg: 13.43 | grad norm last: 14.47 | 
2025-12-28T04:18:38 | step: 921400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.2226821127114818e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.6 | train loss last: 3.67 | consumed tokens: 471756800.0 | grad norm avg: 14.18 | grad norm last: 14.3 | 
2025-12-28T04:18:40 | step: 921500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.222248738486087e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.5 | train loss last: 3.17 | consumed tokens: 471808000.0 | grad norm avg: 13.7 | grad norm last: 16.7 | 
2025-12-28T04:18:42 | step: 921600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.221815819008043e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.54 | train loss last: 3.67 | consumed tokens: 471859200.0 | grad norm avg: 13.81 | grad norm last: 11.63 | 
2025-12-28T04:18:44 | step: 921700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.2213832633278798e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.52 | train loss last: 3.67 | consumed tokens: 471910400.0 | grad norm avg: 13.77 | grad norm last: 13.04 | 
2025-12-28T04:18:46 | step: 921800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.2209511623950675e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 3.69 | consumed tokens: 471961600.0 | grad norm avg: 13.8 | grad norm last: 14.56 | 
2025-12-28T04:18:48 | step: 921900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.2205194252601359e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.55 | train loss last: 3.16 | consumed tokens: 472012800.0 | grad norm avg: 13.86 | grad norm last: 12.14 | 
2025-12-28T04:18:50 | step: 922000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.2200881428725552e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.52 | train loss last: 3.05 | consumed tokens: 472064000.0 | grad norm avg: 13.46 | grad norm last: 11.18 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_922000-seen_tokens_472064000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_922000-seen_tokens_472064000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_922000-seen_tokens_472064000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_922000-seen_tokens_472064000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_922000-seen_tokens_472064000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_922000-seen_tokens_472064000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_922000-seen_tokens_472064000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_922000-seen_tokens_472064000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:18:52 | step: 922100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.2196574061817955e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.7 | train loss last: 3.28 | consumed tokens: 472115200.0 | grad norm avg: 14.35 | grad norm last: 12.99 | 
2025-12-28T04:18:54 | step: 922200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.219226760440506e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.5 | train loss last: 2.84 | consumed tokens: 472166400.0 | grad norm avg: 13.55 | grad norm last: 10.72 | 
2025-12-28T04:18:56 | step: 922300 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.2187967513455078e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 3.52 | consumed tokens: 472217600.0 | grad norm avg: 14.03 | grad norm last: 14.14 | 
2025-12-28T04:18:58 | step: 922400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.2183671060483903e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.51 | train loss last: 3.69 | consumed tokens: 472268800.0 | grad norm avg: 13.47 | grad norm last: 14.15 | 
2025-12-28T04:19:00 | step: 922500 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.2179378245491534e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.55 | train loss last: 4.06 | consumed tokens: 472320000.0 | grad norm avg: 13.91 | grad norm last: 16.73 | 
2025-12-28T04:19:02 | step: 922600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.2175089977972675e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.56 | train loss last: 3.31 | consumed tokens: 472371200.0 | grad norm avg: 14.35 | grad norm last: 14.06 | 
2025-12-28T04:19:04 | step: 922700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.2170806257927325e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.67 | train loss last: 3.66 | consumed tokens: 472422400.0 | grad norm avg: 14.19 | grad norm last: 17.39 | 
2025-12-28T04:19:06 | step: 922800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.2166526175860781e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.53 | train loss last: 3.64 | consumed tokens: 472473600.0 | grad norm avg: 14.13 | grad norm last: 13.96 | 
2025-12-28T04:19:08 | step: 922900 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.2162250641267747e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.64 | train loss last: 3.75 | consumed tokens: 472524800.0 | grad norm avg: 13.93 | grad norm last: 14.89 | 
2025-12-28T04:19:10 | step: 923000 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.215797874465352e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 3.61 | consumed tokens: 472576000.0 | grad norm avg: 13.64 | grad norm last: 14.58 | 
2025-12-28T04:19:12 | step: 923100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.21537113955128e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.53 | train loss last: 4.41 | consumed tokens: 472627200.0 | grad norm avg: 13.6 | grad norm last: 14.98 | 
2025-12-28T04:19:15 | step: 923200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.214944768435089e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.49 | train loss last: 3.91 | consumed tokens: 472678400.0 | grad norm avg: 13.71 | grad norm last: 16.3 | 
2025-12-28T04:19:17 | step: 923300 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.2145187611167785e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 3.05 | consumed tokens: 472729600.0 | grad norm avg: 13.86 | grad norm last: 13.26 | 
2025-12-28T04:19:19 | step: 923400 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 1.214093208545819e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.47 | train loss last: 3.69 | consumed tokens: 472780800.0 | grad norm avg: 13.44 | grad norm last: 13.27 | 
2025-12-28T04:19:21 | step: 923500 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.21366801977274e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 4.41 | consumed tokens: 472832000.0 | grad norm avg: 14.06 | grad norm last: 13.04 | 
2025-12-28T04:19:23 | step: 923600 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.2132434676459525e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.48 | train loss last: 4.41 | consumed tokens: 472883200.0 | grad norm avg: 13.34 | grad norm last: 12.14 | 
2025-12-28T04:19:25 | step: 923700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.2128190974181052e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 1.93 | consumed tokens: 472934400.0 | grad norm avg: 13.69 | grad norm last: 11.13 | 
2025-12-28T04:19:27 | step: 923800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.212395272887079e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.52 | train loss last: 3.73 | consumed tokens: 472985600.0 | grad norm avg: 13.47 | grad norm last: 13.59 | 
2025-12-28T04:19:29 | step: 923900 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.2119718121539336e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.51 | train loss last: 3.8 | consumed tokens: 473036800.0 | grad norm avg: 13.58 | grad norm last: 13.07 | 
2025-12-28T04:19:31 | step: 924000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.2115487152186688e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.67 | train loss last: 3.55 | consumed tokens: 473088000.0 | grad norm avg: 13.8 | grad norm last: 12.86 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_924000-seen_tokens_473088000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_924000-seen_tokens_473088000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_924000-seen_tokens_473088000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_924000-seen_tokens_473088000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_924000-seen_tokens_473088000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_924000-seen_tokens_473088000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_924000-seen_tokens_473088000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_924000-seen_tokens_473088000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:19:33 | step: 924100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.211126073030755e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 3.49 | train loss last: 3.42 | consumed tokens: 473139200.0 | grad norm avg: 13.24 | grad norm last: 14.55 | 
2025-12-28T04:19:35 | step: 924200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.2107037946407218e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 3.51 | train loss last: 4.41 | consumed tokens: 473190400.0 | grad norm avg: 13.54 | grad norm last: 14.64 | 
2025-12-28T04:19:37 | step: 924300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.2102820619475096e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.53 | train loss last: 3.89 | consumed tokens: 473241600.0 | grad norm avg: 14.01 | grad norm last: 14.13 | 
2025-12-28T04:19:39 | step: 924400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.2098605111532379e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 3.41 | consumed tokens: 473292800.0 | grad norm avg: 13.52 | grad norm last: 12.12 | 
2025-12-28T04:19:41 | step: 924500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.2094395970052574e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.49 | train loss last: 3.42 | consumed tokens: 473344000.0 | grad norm avg: 13.52 | grad norm last: 12.73 | 
2025-12-28T04:19:43 | step: 924600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2090190466551576e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.54 | train loss last: 3.72 | consumed tokens: 473395200.0 | grad norm avg: 13.88 | grad norm last: 16.23 | 
2025-12-28T04:19:45 | step: 924700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2085988601029385e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.6 | train loss last: 3.41 | consumed tokens: 473446400.0 | grad norm avg: 14.01 | grad norm last: 13.98 | 
2025-12-28T04:19:47 | step: 924800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.2081790373486001e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 4.59 | consumed tokens: 473497600.0 | grad norm avg: 13.92 | grad norm last: 16.49 | 
2025-12-28T04:19:49 | step: 924900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.2077597602910828e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 4.06 | consumed tokens: 473548800.0 | grad norm avg: 14.5 | grad norm last: 16.58 | 
2025-12-28T04:19:52 | step: 925000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.2073408470314462e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 3.77 | consumed tokens: 473600000.0 | grad norm avg: 14.29 | grad norm last: 12.36 | 
2025-12-28T04:19:54 | step: 925100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2069222975696903e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.61 | train loss last: 3.52 | consumed tokens: 473651200.0 | grad norm avg: 13.73 | grad norm last: 13.37 | 
2025-12-28T04:19:56 | step: 925200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.206504111905815e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 3.66 | consumed tokens: 473702400.0 | grad norm avg: 13.91 | grad norm last: 13.87 | 
2025-12-28T04:19:58 | step: 925300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.206086471938761e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.59 | train loss last: 3.14 | consumed tokens: 473753600.0 | grad norm avg: 14.01 | grad norm last: 12.97 | 
2025-12-28T04:20:00 | step: 925400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.2056693776685279e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.52 | train loss last: 3.44 | consumed tokens: 473804800.0 | grad norm avg: 13.73 | grad norm last: 11.84 | 
2025-12-28T04:20:02 | step: 925500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.2052524652972352e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 4.28 | consumed tokens: 473856000.0 | grad norm avg: 13.86 | grad norm last: 14.17 | 
2025-12-28T04:20:04 | step: 925600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.2048359167238232e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 4.41 | consumed tokens: 473907200.0 | grad norm avg: 13.85 | grad norm last: 16.54 | 
2025-12-28T04:20:06 | step: 925700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.2044199138472322e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.54 | train loss last: 4.78 | consumed tokens: 473958400.0 | grad norm avg: 13.59 | grad norm last: 14.93 | 
2025-12-28T04:20:08 | step: 925800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.204004274768522e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 3.95 | consumed tokens: 474009600.0 | grad norm avg: 13.72 | grad norm last: 15.35 | 
2025-12-28T04:20:10 | step: 925900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.2035891813866328e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.49 | train loss last: 3.27 | consumed tokens: 474060800.0 | grad norm avg: 13.49 | grad norm last: 12.14 | 
2025-12-28T04:20:12 | step: 926000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.203174269903684e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.5 | train loss last: 2.98 | consumed tokens: 474112000.0 | grad norm avg: 13.29 | grad norm last: 12.18 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_926000-seen_tokens_474112000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_926000-seen_tokens_474112000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_926000-seen_tokens_474112000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_926000-seen_tokens_474112000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_926000-seen_tokens_474112000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_926000-seen_tokens_474112000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_926000-seen_tokens_474112000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_926000-seen_tokens_474112000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:20:14 | step: 926100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.2027599041175563e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 3.51 | train loss last: 3.59 | consumed tokens: 474163200.0 | grad norm avg: 13.68 | grad norm last: 12.12 | 
2025-12-28T04:20:16 | step: 926200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.2023459021293093e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.56 | train loss last: 4.06 | consumed tokens: 474214400.0 | grad norm avg: 13.8 | grad norm last: 14.8 | 
2025-12-28T04:20:18 | step: 926300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.2019324458378833e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.54 | train loss last: 3.66 | consumed tokens: 474265600.0 | grad norm avg: 14.49 | grad norm last: 13.05 | 
2025-12-28T04:20:20 | step: 926400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 1.2015191714453977e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.56 | train loss last: 2.98 | consumed tokens: 474316800.0 | grad norm avg: 13.6 | grad norm last: 13.12 | 
2025-12-28T04:20:22 | step: 926500 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 1.2011064427497331e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.55 | train loss last: 3.16 | consumed tokens: 474368000.0 | grad norm avg: 13.88 | grad norm last: 11.91 | 
2025-12-28T04:20:24 | step: 926600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 1.2006941688014194e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.55 | train loss last: 3.2 | consumed tokens: 474419200.0 | grad norm avg: 13.67 | grad norm last: 12.92 | 
2025-12-28T04:20:26 | step: 926700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.2002822586509865e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.51 | train loss last: 3.94 | consumed tokens: 474470400.0 | grad norm avg: 13.43 | grad norm last: 14.37 | 
2025-12-28T04:20:28 | step: 926800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 1.199870621348964e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.47 | train loss last: 3.66 | consumed tokens: 474521600.0 | grad norm avg: 13.71 | grad norm last: 16.55 | 
2025-12-28T04:20:30 | step: 926900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.1994595297437627e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 3.67 | consumed tokens: 474572800.0 | grad norm avg: 13.56 | grad norm last: 12.04 | 
2025-12-28T04:20:32 | step: 927000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.1990489838353824e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.53 | train loss last: 2.98 | consumed tokens: 474624000.0 | grad norm avg: 14.01 | grad norm last: 11.52 | 
2025-12-28T04:20:34 | step: 927100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.1986387107754126e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.56 | train loss last: 3.08 | consumed tokens: 474675200.0 | grad norm avg: 14.18 | grad norm last: 12.62 | 
2025-12-28T04:20:36 | step: 927200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.1982289834122639e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.52 | train loss last: 3.48 | consumed tokens: 474726400.0 | grad norm avg: 14.27 | grad norm last: 11.97 | 
2025-12-28T04:20:38 | step: 927300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.1978194379480556e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.61 | train loss last: 4.5 | consumed tokens: 474777600.0 | grad norm avg: 13.97 | grad norm last: 20.15 | 
2025-12-28T04:20:40 | step: 927400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.1974104381806683e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.59 | train loss last: 3.38 | consumed tokens: 474828800.0 | grad norm avg: 14.15 | grad norm last: 13.09 | 
2025-12-28T04:20:42 | step: 927500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.1970018931606319e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.5 | train loss last: 3.2 | consumed tokens: 474880000.0 | grad norm avg: 13.44 | grad norm last: 11.47 | 
2025-12-28T04:20:44 | step: 927600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.1965937119384762e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.55 | train loss last: 3.91 | consumed tokens: 474931200.0 | grad norm avg: 14.05 | grad norm last: 13.17 | 
2025-12-28T04:20:46 | step: 927700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.1961858945142012e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.55 | train loss last: 3.75 | consumed tokens: 474982400.0 | grad norm avg: 13.65 | grad norm last: 12.69 | 
2025-12-28T04:20:48 | step: 927800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.1957785318372771e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.59 | train loss last: 3.8 | consumed tokens: 475033600.0 | grad norm avg: 14.11 | grad norm last: 13.41 | 
2025-12-28T04:20:50 | step: 927900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.195371714857174e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.59 | train loss last: 3.61 | consumed tokens: 475084800.0 | grad norm avg: 13.84 | grad norm last: 13.87 | 
2025-12-28T04:20:53 | step: 928000 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.1949650797760114e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.64 | train loss last: 3.64 | consumed tokens: 475136000.0 | grad norm avg: 14.01 | grad norm last: 12.4 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_928000-seen_tokens_475136000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_928000-seen_tokens_475136000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_928000-seen_tokens_475136000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_928000-seen_tokens_475136000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_928000-seen_tokens_475136000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_928000-seen_tokens_475136000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_928000-seen_tokens_475136000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_928000-seen_tokens_475136000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:20:55 | step: 928100 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.1945589903916698e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 3.51 | train loss last: 3.94 | consumed tokens: 475187200.0 | grad norm avg: 13.62 | grad norm last: 11.98 | 
2025-12-28T04:20:57 | step: 928200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.1941531738557387e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.5 | train loss last: 4.28 | consumed tokens: 475238400.0 | grad norm avg: 13.29 | grad norm last: 12.19 | 
2025-12-28T04:20:59 | step: 928300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.1937479030166287e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 3.84 | consumed tokens: 475289600.0 | grad norm avg: 14.05 | grad norm last: 15.37 | 
2025-12-28T04:21:01 | step: 928400 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.1933431778743397e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.6 | train loss last: 3.34 | consumed tokens: 475340800.0 | grad norm avg: 14.36 | grad norm last: 11.75 | 
2025-12-28T04:21:03 | step: 928500 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.1929386346309911e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.6 | train loss last: 3.47 | consumed tokens: 475392000.0 | grad norm avg: 13.78 | grad norm last: 16.15 | 
2025-12-28T04:21:05 | step: 928600 | train samples/s: 104.6 | train mfu (16-bit): -1.0 | lr mean: 1.1925346370844636e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.68 | train loss last: 3.17 | consumed tokens: 475443200.0 | grad norm avg: 14.4 | grad norm last: 12.41 | 
2025-12-28T04:21:07 | step: 928700 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.1921310033358168e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.66 | train loss last: 3.06 | consumed tokens: 475494400.0 | grad norm avg: 14.05 | grad norm last: 13.1 | 
2025-12-28T04:21:09 | step: 928800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.1917277333850507e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.53 | train loss last: 3.67 | consumed tokens: 475545600.0 | grad norm avg: 13.62 | grad norm last: 14.58 | 
2025-12-28T04:21:11 | step: 928900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.1913250091311056e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 3.5 | consumed tokens: 475596800.0 | grad norm avg: 14.1 | grad norm last: 15.42 | 
2025-12-28T04:21:13 | step: 929000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.1909225577255711e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.52 | train loss last: 4.19 | consumed tokens: 475648000.0 | grad norm avg: 13.46 | grad norm last: 13.68 | 
2025-12-28T04:21:15 | step: 929100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.1905206520168576e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.6 | train loss last: 3.62 | consumed tokens: 475699200.0 | grad norm avg: 13.93 | grad norm last: 12.91 | 
2025-12-28T04:21:17 | step: 929200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.1901190191565547e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.63 | train loss last: 3.91 | consumed tokens: 475750400.0 | grad norm avg: 13.83 | grad norm last: 15.54 | 
2025-12-28T04:21:19 | step: 929300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.1897179319930729e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.48 | train loss last: 2.72 | consumed tokens: 475801600.0 | grad norm avg: 13.51 | grad norm last: 11.07 | 
2025-12-28T04:21:21 | step: 929400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.1893172086274717e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.53 | train loss last: 3.25 | consumed tokens: 475852800.0 | grad norm avg: 13.88 | grad norm last: 12.2 | 
2025-12-28T04:21:23 | step: 929500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.1889168490597513e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.59 | train loss last: 3.19 | consumed tokens: 475904000.0 | grad norm avg: 13.82 | grad norm last: 11.74 | 
2025-12-28T04:21:26 | step: 929600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.1885170351888519e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.5 | train loss last: 2.95 | consumed tokens: 475955200.0 | grad norm avg: 13.62 | grad norm last: 13.23 | 
2025-12-28T04:21:28 | step: 929700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.1881175851158332e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.66 | train loss last: 3.17 | consumed tokens: 476006400.0 | grad norm avg: 14.05 | grad norm last: 11.94 | 
2025-12-28T04:21:30 | step: 929800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.1877183169417549e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.62 | train loss last: 3.73 | consumed tokens: 476057600.0 | grad norm avg: 13.8 | grad norm last: 13.93 | 
2025-12-28T04:21:32 | step: 929900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.187319776363438e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.55 | train loss last: 3.27 | consumed tokens: 476108800.0 | grad norm avg: 14.1 | grad norm last: 13.61 | 
2025-12-28T04:21:34 | step: 930000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.1869215086335316e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.6 | train loss last: 3.02 | consumed tokens: 476160000.0 | grad norm avg: 14.22 | grad norm last: 13.83 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_930000-seen_tokens_476160000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_930000-seen_tokens_476160000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_930000-seen_tokens_476160000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_930000-seen_tokens_476160000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_930000-seen_tokens_476160000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_930000-seen_tokens_476160000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_930000-seen_tokens_476160000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_930000-seen_tokens_476160000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:21:36 | step: 930100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.186523604701506e-05 | peak memory rank 0 (MB): 767.52 | train loss avg: 3.63 | train loss last: 2.97 | consumed tokens: 476211200.0 | grad norm avg: 14.15 | grad norm last: 11.49 | 
2025-12-28T04:21:38 | step: 930200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.1861262464663014e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.59 | train loss last: 3.48 | consumed tokens: 476262400.0 | grad norm avg: 13.98 | grad norm last: 15.14 | 
2025-12-28T04:21:40 | step: 930300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.1857292520289775e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.43 | train loss last: 3.36 | consumed tokens: 476313600.0 | grad norm avg: 13.65 | grad norm last: 12.91 | 
2025-12-28T04:21:42 | step: 930400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.1853327123390045e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 3.59 | consumed tokens: 476364800.0 | grad norm avg: 13.66 | grad norm last: 14.35 | 
2025-12-28T04:21:44 | step: 930500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.1849365364469122e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.54 | train loss last: 3.95 | consumed tokens: 476416000.0 | grad norm avg: 13.62 | grad norm last: 13.89 | 
2025-12-28T04:21:46 | step: 930600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.1845408153021708e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.52 | train loss last: 3.42 | consumed tokens: 476467200.0 | grad norm avg: 13.5 | grad norm last: 12.69 | 
2025-12-28T04:21:48 | step: 930700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.1841454579553101e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.54 | train loss last: 2.84 | consumed tokens: 476518400.0 | grad norm avg: 13.93 | grad norm last: 12.56 | 
2025-12-28T04:21:50 | step: 930800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.1837505553558003e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 3.75 | consumed tokens: 476569600.0 | grad norm avg: 14.21 | grad norm last: 13.43 | 
2025-12-28T04:21:52 | step: 930900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.1833560165541712e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.61 | train loss last: 3.58 | consumed tokens: 476620800.0 | grad norm avg: 13.99 | grad norm last: 12.16 | 
2025-12-28T04:21:54 | step: 931000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.182961932499893e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.6 | train loss last: 5.03 | consumed tokens: 476672000.0 | grad norm avg: 13.75 | grad norm last: 20.56 | 
2025-12-28T04:21:56 | step: 931100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.1825683031929657e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.62 | train loss last: 4.44 | consumed tokens: 476723200.0 | grad norm avg: 13.94 | grad norm last: 14.69 | 
2025-12-28T04:21:58 | step: 931200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.182175037683919e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.63 | train loss last: 2.78 | consumed tokens: 476774400.0 | grad norm avg: 14.32 | grad norm last: 12.6 | 
2025-12-28T04:22:00 | step: 931300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.1817821359727532e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.7 | train loss last: 3.22 | consumed tokens: 476825600.0 | grad norm avg: 14.21 | grad norm last: 13.09 | 
2025-12-28T04:22:02 | step: 931400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.1813896890089381e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.59 | train loss last: 3.62 | consumed tokens: 476876800.0 | grad norm avg: 14.24 | grad norm last: 12.73 | 
2025-12-28T04:22:04 | step: 931500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.180997696792474e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.53 | train loss last: 2.84 | consumed tokens: 476928000.0 | grad norm avg: 13.45 | grad norm last: 11.53 | 
2025-12-28T04:22:06 | step: 931600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.1806060683738906e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.54 | train loss last: 3.59 | consumed tokens: 476979200.0 | grad norm avg: 13.66 | grad norm last: 13.23 | 
2025-12-28T04:22:08 | step: 931700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.180214894702658e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.48 | train loss last: 3.72 | consumed tokens: 477030400.0 | grad norm avg: 13.53 | grad norm last: 17.2 | 
2025-12-28T04:22:10 | step: 931800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.1798241757787764e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.53 | train loss last: 3.12 | consumed tokens: 477081600.0 | grad norm avg: 13.59 | grad norm last: 11.72 | 
2025-12-28T04:22:12 | step: 931900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.1794338206527755e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.52 | train loss last: 3.41 | consumed tokens: 477132800.0 | grad norm avg: 13.68 | grad norm last: 12.46 | 
2025-12-28T04:22:14 | step: 932000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.1790439202741254e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.6 | train loss last: 3.16 | consumed tokens: 477184000.0 | grad norm avg: 13.92 | grad norm last: 13.04 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_932000-seen_tokens_477184000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_932000-seen_tokens_477184000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_932000-seen_tokens_477184000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_932000-seen_tokens_477184000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_932000-seen_tokens_477184000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_932000-seen_tokens_477184000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_932000-seen_tokens_477184000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_932000-seen_tokens_477184000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:22:17 | step: 932100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.1786544746428262e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.53 | train loss last: 3.98 | consumed tokens: 477235200.0 | grad norm avg: 13.71 | grad norm last: 12.79 | 
2025-12-28T04:22:19 | step: 932200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.1782652109104674e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.56 | train loss last: 3.16 | consumed tokens: 477286400.0 | grad norm avg: 13.88 | grad norm last: 12.44 | 
2025-12-28T04:22:21 | step: 932300 | train samples/s: 97.7 | train mfu (16-bit): -1.0 | lr mean: 1.17787667477387e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.75 | train loss last: 3.19 | consumed tokens: 477337600.0 | grad norm avg: 14.82 | grad norm last: 11.79 | 
2025-12-28T04:22:23 | step: 932400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.177488320536213e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.97 | consumed tokens: 477388800.0 | grad norm avg: 14.15 | grad norm last: 14.96 | 
2025-12-28T04:22:25 | step: 932500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.1771004210459068e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.39 | consumed tokens: 477440000.0 | grad norm avg: 13.77 | grad norm last: 12.34 | 
2025-12-28T04:22:27 | step: 932600 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.1767129763029516e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.31 | consumed tokens: 477491200.0 | grad norm avg: 13.76 | grad norm last: 11.83 | 
2025-12-28T04:22:29 | step: 932700 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.1763259863073472e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 5.44 | consumed tokens: 477542400.0 | grad norm avg: 14.16 | grad norm last: 20.76 | 
2025-12-28T04:22:31 | step: 932800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.1759392691601533e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.52 | consumed tokens: 477593600.0 | grad norm avg: 14.19 | grad norm last: 13.61 | 
2025-12-28T04:22:33 | step: 932900 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.1755531886592507e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 5.03 | consumed tokens: 477644800.0 | grad norm avg: 14.09 | grad norm last: 18.12 | 
2025-12-28T04:22:35 | step: 933000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.1751672900572885e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.14 | consumed tokens: 477696000.0 | grad norm avg: 13.89 | grad norm last: 11.65 | 
2025-12-28T04:22:37 | step: 933100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.1747820281016175e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.34 | consumed tokens: 477747200.0 | grad norm avg: 13.84 | grad norm last: 13.74 | 
2025-12-28T04:22:39 | step: 933200 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.174397038994357e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.5 | consumed tokens: 477798400.0 | grad norm avg: 13.93 | grad norm last: 13.66 | 
2025-12-28T04:22:41 | step: 933300 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.1740125046344474e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.08 | consumed tokens: 477849600.0 | grad norm avg: 13.69 | grad norm last: 11.77 | 
2025-12-28T04:22:43 | step: 933400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.1736284250218887e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.53 | consumed tokens: 477900800.0 | grad norm avg: 14.16 | grad norm last: 13.42 | 
2025-12-28T04:22:46 | step: 933500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.1732448001566809e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.2 | consumed tokens: 477952000.0 | grad norm avg: 14.2 | grad norm last: 13.77 | 
2025-12-28T04:22:48 | step: 933600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.1728614481398836e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.48 | consumed tokens: 478003200.0 | grad norm avg: 13.81 | grad norm last: 12.99 | 
2025-12-28T04:22:50 | step: 933700 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.1724786418199074e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.44 | train loss last: 3.02 | consumed tokens: 478054400.0 | grad norm avg: 13.77 | grad norm last: 11.17 | 
2025-12-28T04:22:52 | step: 933800 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.1720961083483417e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.05 | consumed tokens: 478105600.0 | grad norm avg: 13.69 | grad norm last: 11.67 | 
2025-12-28T04:22:54 | step: 933900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.171714120573597e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.3 | consumed tokens: 478156800.0 | grad norm avg: 14.06 | grad norm last: 12.55 | 
2025-12-28T04:22:56 | step: 934000 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.1713324965967331e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.41 | consumed tokens: 478208000.0 | grad norm avg: 13.99 | grad norm last: 14.32 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_934000-seen_tokens_478208000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_934000-seen_tokens_478208000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_934000-seen_tokens_478208000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_934000-seen_tokens_478208000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_934000-seen_tokens_478208000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_934000-seen_tokens_478208000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_934000-seen_tokens_478208000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_934000-seen_tokens_478208000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:22:58 | step: 934100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.1709512364177499e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.41 | train loss last: 3.81 | consumed tokens: 478259200.0 | grad norm avg: 13.51 | grad norm last: 13.87 | 
2025-12-28T04:23:00 | step: 934200 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.1705703400366474e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.61 | train loss last: 3.28 | consumed tokens: 478310400.0 | grad norm avg: 13.8 | grad norm last: 13.2 | 
2025-12-28T04:23:02 | step: 934300 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.1701900803018361e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.69 | consumed tokens: 478361600.0 | grad norm avg: 13.86 | grad norm last: 15.01 | 
2025-12-28T04:23:04 | step: 934400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.1698101843649056e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.78 | consumed tokens: 478412800.0 | grad norm avg: 14.09 | grad norm last: 13.57 | 
2025-12-28T04:23:06 | step: 934500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.1694307431753259e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.98 | consumed tokens: 478464000.0 | grad norm avg: 13.99 | grad norm last: 14.8 | 
2025-12-28T04:23:08 | step: 934600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.1690514838846866e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.22 | consumed tokens: 478515200.0 | grad norm avg: 14.11 | grad norm last: 11.28 | 
2025-12-28T04:23:10 | step: 934700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.1686727702908684e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.34 | consumed tokens: 478566400.0 | grad norm avg: 14.01 | grad norm last: 13.53 | 
2025-12-28T04:23:12 | step: 934800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.1682944204949308e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.31 | consumed tokens: 478617600.0 | grad norm avg: 13.79 | grad norm last: 16.83 | 
2025-12-28T04:23:14 | step: 934900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.1679166163958143e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.92 | consumed tokens: 478668800.0 | grad norm avg: 13.81 | grad norm last: 15.22 | 
2025-12-28T04:23:16 | step: 935000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.1675391760945786e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.55 | consumed tokens: 478720000.0 | grad norm avg: 13.81 | grad norm last: 15.06 | 
2025-12-28T04:23:18 | step: 935100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.1671620995912235e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.42 | consumed tokens: 478771200.0 | grad norm avg: 14.11 | grad norm last: 12.64 | 
2025-12-28T04:23:21 | step: 935200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.1667853868857492e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 2.86 | consumed tokens: 478822400.0 | grad norm avg: 13.8 | grad norm last: 13.35 | 
2025-12-28T04:23:23 | step: 935300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.1664092198770959e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.81 | consumed tokens: 478873600.0 | grad norm avg: 13.46 | grad norm last: 14.31 | 
2025-12-28T04:23:25 | step: 935400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.1660335985652637e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.62 | consumed tokens: 478924800.0 | grad norm avg: 14.12 | grad norm last: 13.35 | 
2025-12-28T04:23:27 | step: 935500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.1656581591523718e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.47 | consumed tokens: 478976000.0 | grad norm avg: 13.38 | grad norm last: 13.32 | 
2025-12-28T04:23:29 | step: 935600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.1652831744868308e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.25 | consumed tokens: 479027200.0 | grad norm avg: 13.51 | grad norm last: 11.11 | 
2025-12-28T04:23:31 | step: 935700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.164908735518111e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 4.5 | consumed tokens: 479078400.0 | grad norm avg: 16.54 | grad norm last: 16.92 | 
2025-12-28T04:23:33 | step: 935800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.1645345693978015e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.12 | consumed tokens: 479129600.0 | grad norm avg: 13.88 | grad norm last: 11.52 | 
2025-12-28T04:23:35 | step: 935900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.164160858024843e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.0 | consumed tokens: 479180800.0 | grad norm avg: 13.99 | grad norm last: 12.37 | 
2025-12-28T04:23:37 | step: 936000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.1637876013992354e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.09 | consumed tokens: 479232000.0 | grad norm avg: 14.27 | grad norm last: 15.85 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_936000-seen_tokens_479232000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_936000-seen_tokens_479232000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_936000-seen_tokens_479232000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_936000-seen_tokens_479232000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_936000-seen_tokens_479232000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_936000-seen_tokens_479232000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_936000-seen_tokens_479232000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_936000-seen_tokens_479232000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:23:39 | step: 936100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.1634147085715085e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.67 | train loss last: 4.31 | consumed tokens: 479283200.0 | grad norm avg: 14.21 | grad norm last: 16.48 | 
2025-12-28T04:23:41 | step: 936200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.1630422704911325e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 4.09 | consumed tokens: 479334400.0 | grad norm avg: 13.75 | grad norm last: 13.23 | 
2025-12-28T04:23:43 | step: 936300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.162670105259167e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.88 | consumed tokens: 479385600.0 | grad norm avg: 14.45 | grad norm last: 11.39 | 
2025-12-28T04:23:45 | step: 936400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 1.1622985766734928e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.75 | consumed tokens: 479436800.0 | grad norm avg: 14.12 | grad norm last: 12.57 | 
2025-12-28T04:23:47 | step: 936500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.1619274118856993e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.38 | consumed tokens: 479488000.0 | grad norm avg: 13.75 | grad norm last: 17.92 | 
2025-12-28T04:23:49 | step: 936600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.1615567018452566e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.52 | consumed tokens: 479539200.0 | grad norm avg: 13.89 | grad norm last: 13.3 | 
2025-12-28T04:23:51 | step: 936700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.1611863556026947e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 2.97 | consumed tokens: 479590400.0 | grad norm avg: 13.9 | grad norm last: 13.27 | 
2025-12-28T04:23:53 | step: 936800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.1608161912590731e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.47 | consumed tokens: 479641600.0 | grad norm avg: 13.95 | grad norm last: 17.42 | 
2025-12-28T04:23:55 | step: 936900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.160446754511213e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.77 | consumed tokens: 479692800.0 | grad norm avg: 13.86 | grad norm last: 13.99 | 
2025-12-28T04:23:57 | step: 937000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.1600776815612335e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.11 | consumed tokens: 479744000.0 | grad norm avg: 13.89 | grad norm last: 12.5 | 
2025-12-28T04:23:59 | step: 937100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.1597089724091347e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.69 | consumed tokens: 479795200.0 | grad norm avg: 14.2 | grad norm last: 13.09 | 
2025-12-28T04:24:01 | step: 937200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.1593406270549167e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.73 | consumed tokens: 479846400.0 | grad norm avg: 13.79 | grad norm last: 12.56 | 
2025-12-28T04:24:03 | step: 937300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.1589728273975197e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.84 | consumed tokens: 479897600.0 | grad norm avg: 13.84 | grad norm last: 13.1 | 
2025-12-28T04:24:05 | step: 937400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.1586053915380035e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.52 | consumed tokens: 479948800.0 | grad norm avg: 13.78 | grad norm last: 12.9 | 
2025-12-28T04:24:07 | step: 937500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.1582383194763679e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.7 | consumed tokens: 480000000.0 | grad norm avg: 13.93 | grad norm last: 15.35 | 
2025-12-28T04:24:09 | step: 937600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.157871611212613e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.27 | consumed tokens: 480051200.0 | grad norm avg: 14.22 | grad norm last: 12.28 | 
2025-12-28T04:24:11 | step: 937700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.1575055395951495e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.48 | consumed tokens: 480102400.0 | grad norm avg: 13.97 | grad norm last: 12.47 | 
2025-12-28T04:24:13 | step: 937800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.1571396498766262e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.06 | consumed tokens: 480153600.0 | grad norm avg: 14.06 | grad norm last: 13.88 | 
2025-12-28T04:24:15 | step: 937900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.1567743968043942e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.95 | consumed tokens: 480204800.0 | grad norm avg: 13.69 | grad norm last: 15.34 | 
2025-12-28T04:24:18 | step: 938000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.1564095075300429e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 4.28 | consumed tokens: 480256000.0 | grad norm avg: 13.76 | grad norm last: 15.46 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_938000-seen_tokens_480256000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_938000-seen_tokens_480256000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_938000-seen_tokens_480256000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_938000-seen_tokens_480256000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_938000-seen_tokens_480256000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_938000-seen_tokens_480256000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_938000-seen_tokens_480256000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_938000-seen_tokens_480256000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:24:20 | step: 938100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.1560449820535723e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.61 | train loss last: 4.09 | consumed tokens: 480307200.0 | grad norm avg: 14.17 | grad norm last: 17.09 | 
2025-12-28T04:24:22 | step: 938200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.1556808203749824e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.12 | consumed tokens: 480358400.0 | grad norm avg: 14.01 | grad norm last: 12.49 | 
2025-12-28T04:24:24 | step: 938300 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.1553170224942733e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.72 | consumed tokens: 480409600.0 | grad norm avg: 14.18 | grad norm last: 16.65 | 
2025-12-28T04:24:26 | step: 938400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.1549538612598553e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.53 | consumed tokens: 480460800.0 | grad norm avg: 13.95 | grad norm last: 12.21 | 
2025-12-28T04:24:28 | step: 938500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.1545910638233181e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.39 | consumed tokens: 480512000.0 | grad norm avg: 14.15 | grad norm last: 12.63 | 
2025-12-28T04:24:30 | step: 938600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.1542285392351914e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.47 | train loss last: 2.86 | consumed tokens: 480563200.0 | grad norm avg: 13.94 | grad norm last: 11.24 | 
2025-12-28T04:24:32 | step: 938700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.1538665603438858e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.03 | consumed tokens: 480614400.0 | grad norm avg: 13.73 | grad norm last: 13.57 | 
2025-12-28T04:24:34 | step: 938800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.1535051271494012e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.22 | consumed tokens: 480665600.0 | grad norm avg: 13.67 | grad norm last: 13.34 | 
2025-12-28T04:24:36 | step: 938900 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.1531436939549167e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.83 | consumed tokens: 480716800.0 | grad norm avg: 14.12 | grad norm last: 19.93 | 
2025-12-28T04:24:38 | step: 939000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.1527830793056637e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.05 | consumed tokens: 480768000.0 | grad norm avg: 14.16 | grad norm last: 11.76 | 
2025-12-28T04:24:40 | step: 939100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.1524226465553511e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.61 | consumed tokens: 480819200.0 | grad norm avg: 14.08 | grad norm last: 12.34 | 
2025-12-28T04:24:42 | step: 939200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.1520627595018595e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.25 | consumed tokens: 480870400.0 | grad norm avg: 13.88 | grad norm last: 12.7 | 
2025-12-28T04:24:44 | step: 939300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.1517033271957189e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.62 | consumed tokens: 480921600.0 | grad norm avg: 14.16 | grad norm last: 25.02 | 
2025-12-28T04:24:46 | step: 939400 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.1513441677379888e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.38 | consumed tokens: 480972800.0 | grad norm avg: 13.98 | grad norm last: 12.06 | 
2025-12-28T04:24:48 | step: 939500 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.1509855539770797e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.28 | consumed tokens: 481024000.0 | grad norm avg: 14.29 | grad norm last: 17.14 | 
2025-12-28T04:24:50 | step: 939600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.1506273040140513e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.31 | consumed tokens: 481075200.0 | grad norm avg: 14.1 | grad norm last: 12.76 | 
2025-12-28T04:24:53 | step: 939700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.1502695087983739e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.62 | consumed tokens: 481126400.0 | grad norm avg: 14.53 | grad norm last: 13.44 | 
2025-12-28T04:24:55 | step: 939800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.1499120773805771e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.56 | consumed tokens: 481177600.0 | grad norm avg: 14.12 | grad norm last: 13.3 | 
2025-12-28T04:24:57 | step: 939900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.149555009760661e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.03 | consumed tokens: 481228800.0 | grad norm avg: 13.95 | grad norm last: 12.16 | 
2025-12-28T04:24:59 | step: 940000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.149198487837566e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.94 | consumed tokens: 481280000.0 | grad norm avg: 14.01 | grad norm last: 17.8 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_940000-seen_tokens_481280000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_940000-seen_tokens_481280000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_940000-seen_tokens_481280000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_940000-seen_tokens_481280000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_940000-seen_tokens_481280000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_940000-seen_tokens_481280000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_940000-seen_tokens_481280000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_940000-seen_tokens_481280000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:25:01 | step: 940100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.1488423297123518e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.47 | train loss last: 3.58 | consumed tokens: 481331200.0 | grad norm avg: 13.75 | grad norm last: 12.92 | 
2025-12-28T04:25:03 | step: 940200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.1484865353850182e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.7 | train loss last: 4.38 | consumed tokens: 481382400.0 | grad norm avg: 14.37 | grad norm last: 14.2 | 
2025-12-28T04:25:05 | step: 940300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.1481312867545057e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.23 | consumed tokens: 481433600.0 | grad norm avg: 14.06 | grad norm last: 18.98 | 
2025-12-28T04:25:07 | step: 940400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.1477762200229336e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.8 | consumed tokens: 481484800.0 | grad norm avg: 14.2 | grad norm last: 22.98 | 
2025-12-28T04:25:09 | step: 940500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.1474218808871228e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.91 | consumed tokens: 481536000.0 | grad norm avg: 13.98 | grad norm last: 15.23 | 
2025-12-28T04:25:11 | step: 940600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.1470678145997226e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.64 | consumed tokens: 481587200.0 | grad norm avg: 14.04 | grad norm last: 14.82 | 
2025-12-28T04:25:13 | step: 940700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.1467141121102031e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.91 | consumed tokens: 481638400.0 | grad norm avg: 14.21 | grad norm last: 14.6 | 
2025-12-28T04:25:15 | step: 940800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.1463609553175047e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.52 | consumed tokens: 481689600.0 | grad norm avg: 13.86 | grad norm last: 16.13 | 
2025-12-28T04:25:17 | step: 940900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.1460080713732168e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.31 | consumed tokens: 481740800.0 | grad norm avg: 14.15 | grad norm last: 12.66 | 
2025-12-28T04:25:19 | step: 941000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.1456558240752202e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.12 | consumed tokens: 481792000.0 | grad norm avg: 13.63 | grad norm last: 11.42 | 
2025-12-28T04:25:21 | step: 941100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.1453037586761639e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.64 | consumed tokens: 481843200.0 | grad norm avg: 14.14 | grad norm last: 13.35 | 
2025-12-28T04:25:23 | step: 941200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.1449522389739286e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.3 | consumed tokens: 481894400.0 | grad norm avg: 13.78 | grad norm last: 14.07 | 
2025-12-28T04:25:25 | step: 941300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.1446009921201039e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.0 | consumed tokens: 481945600.0 | grad norm avg: 14.2 | grad norm last: 13.17 | 
2025-12-28T04:25:27 | step: 941400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.1442502909631003e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.53 | consumed tokens: 481996800.0 | grad norm avg: 13.97 | grad norm last: 12.01 | 
2025-12-28T04:25:29 | step: 941500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.1439001355029177e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.22 | consumed tokens: 482048000.0 | grad norm avg: 13.93 | grad norm last: 11.17 | 
2025-12-28T04:25:31 | step: 941600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.1435501619416755e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.42 | consumed tokens: 482099200.0 | grad norm avg: 13.69 | grad norm last: 13.75 | 
2025-12-28T04:25:33 | step: 941700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.1432007340772543e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.41 | consumed tokens: 482150400.0 | grad norm avg: 14.08 | grad norm last: 17.01 | 
2025-12-28T04:25:35 | step: 941800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.1428516700107139e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.42 | consumed tokens: 482201600.0 | grad norm avg: 14.14 | grad norm last: 11.84 | 
2025-12-28T04:25:37 | step: 941900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.1425031516409945e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.0 | consumed tokens: 482252800.0 | grad norm avg: 13.93 | grad norm last: 14.79 | 
2025-12-28T04:25:39 | step: 942000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.1421548151702154e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.89 | consumed tokens: 482304000.0 | grad norm avg: 13.66 | grad norm last: 13.29 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_942000-seen_tokens_482304000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_942000-seen_tokens_482304000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_942000-seen_tokens_482304000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_942000-seen_tokens_482304000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_942000-seen_tokens_482304000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_942000-seen_tokens_482304000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_942000-seen_tokens_482304000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_942000-seen_tokens_482304000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:25:42 | step: 942100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.1418070243962575e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.02 | consumed tokens: 482355200.0 | grad norm avg: 13.74 | grad norm last: 12.9 | 
2025-12-28T04:25:44 | step: 942200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.1414597793191206e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.3 | consumed tokens: 482406400.0 | grad norm avg: 13.78 | grad norm last: 13.0 | 
2025-12-28T04:25:46 | step: 942300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.141112716140924e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.19 | consumed tokens: 482457600.0 | grad norm avg: 13.77 | grad norm last: 14.03 | 
2025-12-28T04:25:48 | step: 942400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.1407661986595485e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.61 | consumed tokens: 482508800.0 | grad norm avg: 13.9 | grad norm last: 13.54 | 
2025-12-28T04:25:50 | step: 942500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.140420135925524e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.56 | consumed tokens: 482560000.0 | grad norm avg: 13.54 | grad norm last: 14.17 | 
2025-12-28T04:25:52 | step: 942600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.14007443698938e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.47 | consumed tokens: 482611200.0 | grad norm avg: 13.66 | grad norm last: 14.41 | 
2025-12-28T04:25:54 | step: 942700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.139729192800587e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.22 | consumed tokens: 482662400.0 | grad norm avg: 14.13 | grad norm last: 15.11 | 
2025-12-28T04:25:56 | step: 942800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.1393843124096747e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.92 | consumed tokens: 482713600.0 | grad norm avg: 13.58 | grad norm last: 14.87 | 
2025-12-28T04:25:58 | step: 942900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.1390398867661133e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.33 | consumed tokens: 482764800.0 | grad norm avg: 14.09 | grad norm last: 16.33 | 
2025-12-28T04:26:00 | step: 943000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.1386958249204326e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.47 | consumed tokens: 482816000.0 | grad norm avg: 14.18 | grad norm last: 19.14 | 
2025-12-28T04:26:02 | step: 943100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.138352308771573e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.3 | consumed tokens: 482867200.0 | grad norm avg: 13.91 | grad norm last: 15.74 | 
2025-12-28T04:26:04 | step: 943200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.1380089745216537e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.47 | consumed tokens: 482918400.0 | grad norm avg: 14.21 | grad norm last: 16.84 | 
2025-12-28T04:26:06 | step: 943300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.1376662769180257e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.2 | consumed tokens: 482969600.0 | grad norm avg: 14.3 | grad norm last: 12.32 | 
2025-12-28T04:26:08 | step: 943400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.1373241250112187e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 4.34 | consumed tokens: 483020800.0 | grad norm avg: 13.75 | grad norm last: 21.82 | 
2025-12-28T04:26:10 | step: 943500 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.1369821550033521e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.3 | consumed tokens: 483072000.0 | grad norm avg: 13.99 | grad norm last: 11.41 | 
2025-12-28T04:26:12 | step: 943600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.1366406397428364e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.22 | consumed tokens: 483123200.0 | grad norm avg: 14.37 | grad norm last: 15.21 | 
2025-12-28T04:26:14 | step: 943700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.1362996701791417e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 4.19 | consumed tokens: 483174400.0 | grad norm avg: 13.79 | grad norm last: 13.77 | 
2025-12-28T04:26:16 | step: 943800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.1359588825143874e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.75 | consumed tokens: 483225600.0 | grad norm avg: 13.68 | grad norm last: 13.78 | 
2025-12-28T04:26:18 | step: 943900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.1356186405464541e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.14 | consumed tokens: 483276800.0 | grad norm avg: 14.44 | grad norm last: 12.02 | 
2025-12-28T04:26:20 | step: 944000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.1352788533258718e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 2.83 | consumed tokens: 483328000.0 | grad norm avg: 14.13 | grad norm last: 11.95 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_944000-seen_tokens_483328000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_944000-seen_tokens_483328000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_944000-seen_tokens_483328000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_944000-seen_tokens_483328000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_944000-seen_tokens_483328000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_944000-seen_tokens_483328000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_944000-seen_tokens_483328000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_944000-seen_tokens_483328000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:26:23 | step: 944100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.1349394299031701e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.56 | train loss last: 3.39 | consumed tokens: 483379200.0 | grad norm avg: 14.14 | grad norm last: 12.16 | 
2025-12-28T04:26:25 | step: 944200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.1346004612278193e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.72 | consumed tokens: 483430400.0 | grad norm avg: 14.28 | grad norm last: 14.13 | 
2025-12-28T04:26:27 | step: 944300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.1342618563503493e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.69 | consumed tokens: 483481600.0 | grad norm avg: 14.04 | grad norm last: 19.45 | 
2025-12-28T04:26:29 | step: 944400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.1339237971697003e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.34 | consumed tokens: 483532800.0 | grad norm avg: 14.05 | grad norm last: 14.73 | 
2025-12-28T04:26:31 | step: 944500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.133586101786932e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.94 | consumed tokens: 483584000.0 | grad norm avg: 14.05 | grad norm last: 14.25 | 
2025-12-28T04:26:33 | step: 944600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.1332488611515146e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.64 | consumed tokens: 483635200.0 | grad norm avg: 14.12 | grad norm last: 13.85 | 
2025-12-28T04:26:35 | step: 944700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.1329119843139779e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.66 | consumed tokens: 483686400.0 | grad norm avg: 13.92 | grad norm last: 12.48 | 
2025-12-28T04:26:37 | step: 944800 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.1325754712743219e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 4.19 | consumed tokens: 483737600.0 | grad norm avg: 13.99 | grad norm last: 23.94 | 
2025-12-28T04:26:39 | step: 944900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.1322394129820168e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.56 | consumed tokens: 483788800.0 | grad norm avg: 13.68 | grad norm last: 15.65 | 
2025-12-28T04:26:41 | step: 945000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.1319037184875924e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 5.06 | consumed tokens: 483840000.0 | grad norm avg: 13.96 | grad norm last: 20.1 | 
2025-12-28T04:26:43 | step: 945100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.1315685696899891e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.44 | consumed tokens: 483891200.0 | grad norm avg: 13.99 | grad norm last: 14.72 | 
2025-12-28T04:26:45 | step: 945200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.1312337846902665e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.59 | consumed tokens: 483942400.0 | grad norm avg: 13.85 | grad norm last: 12.87 | 
2025-12-28T04:26:47 | step: 945300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.1308994544378947e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.12 | consumed tokens: 483993600.0 | grad norm avg: 14.19 | grad norm last: 13.89 | 
2025-12-28T04:26:49 | step: 945400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.1305655789328739e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.53 | consumed tokens: 484044800.0 | grad norm avg: 14.0 | grad norm last: 13.39 | 
2025-12-28T04:26:51 | step: 945500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.1302320672257338e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.22 | consumed tokens: 484096000.0 | grad norm avg: 14.12 | grad norm last: 12.76 | 
2025-12-28T04:26:53 | step: 945600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.1298990102659445e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.09 | consumed tokens: 484147200.0 | grad norm avg: 14.22 | grad norm last: 12.82 | 
2025-12-28T04:26:55 | step: 945700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.1295662261545658e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.89 | consumed tokens: 484198400.0 | grad norm avg: 14.37 | grad norm last: 15.7 | 
2025-12-28T04:26:57 | step: 945800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.1292339877400082e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 2.72 | consumed tokens: 484249600.0 | grad norm avg: 13.91 | grad norm last: 11.96 | 
2025-12-28T04:26:59 | step: 945900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.1289022040728014e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.45 | train loss last: 3.22 | consumed tokens: 484300800.0 | grad norm avg: 13.76 | grad norm last: 13.09 | 
2025-12-28T04:27:01 | step: 946000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.1285707842034753e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.43 | train loss last: 3.75 | consumed tokens: 484352000.0 | grad norm avg: 13.71 | grad norm last: 13.78 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_946000-seen_tokens_484352000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_946000-seen_tokens_484352000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_946000-seen_tokens_484352000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_946000-seen_tokens_484352000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_946000-seen_tokens_484352000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_946000-seen_tokens_484352000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_946000-seen_tokens_484352000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_946000-seen_tokens_484352000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:27:03 | step: 946100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.12823972813203e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.5 | train loss last: 2.56 | consumed tokens: 484403200.0 | grad norm avg: 14.0 | grad norm last: 11.65 | 
2025-12-28T04:27:05 | step: 946200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.1279092177574057e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.23 | consumed tokens: 484454400.0 | grad norm avg: 13.87 | grad norm last: 12.19 | 
2025-12-28T04:27:07 | step: 946300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.1275790711806621e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.61 | consumed tokens: 484505600.0 | grad norm avg: 14.52 | grad norm last: 14.84 | 
2025-12-28T04:27:09 | step: 946400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.1272492884017993e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.45 | train loss last: 3.14 | consumed tokens: 484556800.0 | grad norm avg: 13.61 | grad norm last: 11.68 | 
2025-12-28T04:27:12 | step: 946500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.1269199603702873e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.28 | consumed tokens: 484608000.0 | grad norm avg: 14.28 | grad norm last: 13.48 | 
2025-12-28T04:27:14 | step: 946600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.1265910870861262e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.72 | consumed tokens: 484659200.0 | grad norm avg: 14.23 | grad norm last: 12.16 | 
2025-12-28T04:27:16 | step: 946700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.126262668549316e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.91 | consumed tokens: 484710400.0 | grad norm avg: 14.17 | grad norm last: 17.16 | 
2025-12-28T04:27:18 | step: 946800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.1259345228609163e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 5.06 | consumed tokens: 484761600.0 | grad norm avg: 13.65 | grad norm last: 14.33 | 
2025-12-28T04:27:20 | step: 946900 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 1.1256070138188079e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.23 | consumed tokens: 484812800.0 | grad norm avg: 13.68 | grad norm last: 12.15 | 
2025-12-28T04:27:22 | step: 947000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.1252796866756398e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.05 | consumed tokens: 484864000.0 | grad norm avg: 14.18 | grad norm last: 11.5 | 
2025-12-28T04:27:24 | step: 947100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.124952996178763e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.34 | consumed tokens: 484915200.0 | grad norm avg: 15.03 | grad norm last: 16.01 | 
2025-12-28T04:27:26 | step: 947200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.1246265785302967e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.0 | consumed tokens: 484966400.0 | grad norm avg: 14.28 | grad norm last: 27.21 | 
2025-12-28T04:27:28 | step: 947300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.1243007065786514e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.53 | consumed tokens: 485017600.0 | grad norm avg: 13.92 | grad norm last: 13.95 | 
2025-12-28T04:27:30 | step: 947400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 1.1239751074754167e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.81 | consumed tokens: 485068800.0 | grad norm avg: 13.92 | grad norm last: 13.66 | 
2025-12-28T04:27:32 | step: 947500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.1236500540690031e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.56 | consumed tokens: 485120000.0 | grad norm avg: 14.12 | grad norm last: 13.42 | 
2025-12-28T04:27:34 | step: 947600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.1233253644604702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.39 | consumed tokens: 485171200.0 | grad norm avg: 14.03 | grad norm last: 11.42 | 
2025-12-28T04:27:36 | step: 947700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.1230011295992881e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 2.92 | consumed tokens: 485222400.0 | grad norm avg: 14.45 | grad norm last: 11.51 | 
2025-12-28T04:27:38 | step: 947800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.1226772585359868e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.36 | consumed tokens: 485273600.0 | grad norm avg: 14.04 | grad norm last: 14.62 | 
2025-12-28T04:27:40 | step: 947900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.1223538422200363e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.48 | consumed tokens: 485324800.0 | grad norm avg: 14.21 | grad norm last: 14.64 | 
2025-12-28T04:27:42 | step: 948000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.1220308806514367e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.81 | consumed tokens: 485376000.0 | grad norm avg: 13.8 | grad norm last: 12.4 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_948000-seen_tokens_485376000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_948000-seen_tokens_485376000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_948000-seen_tokens_485376000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_948000-seen_tokens_485376000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_948000-seen_tokens_485376000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_948000-seen_tokens_485376000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_948000-seen_tokens_485376000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_948000-seen_tokens_485376000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:27:44 | step: 948100 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.1217082828807179e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.65 | train loss last: 3.23 | consumed tokens: 485427200.0 | grad norm avg: 14.86 | grad norm last: 14.68 | 
2025-12-28T04:27:46 | step: 948200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.12138613985735e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.53 | consumed tokens: 485478400.0 | grad norm avg: 14.32 | grad norm last: 13.1 | 
2025-12-28T04:27:48 | step: 948300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.1210643606318627e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.05 | consumed tokens: 485529600.0 | grad norm avg: 14.09 | grad norm last: 11.4 | 
2025-12-28T04:27:50 | step: 948400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.1207430361537263e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.86 | consumed tokens: 485580800.0 | grad norm avg: 14.29 | grad norm last: 13.36 | 
2025-12-28T04:27:52 | step: 948500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.1204221664229408e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.78 | consumed tokens: 485632000.0 | grad norm avg: 14.01 | grad norm last: 13.51 | 
2025-12-28T04:27:54 | step: 948600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.120101660490036e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.89 | consumed tokens: 485683200.0 | grad norm avg: 14.5 | grad norm last: 14.34 | 
2025-12-28T04:27:56 | step: 948700 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.1197816093044821e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.11 | consumed tokens: 485734400.0 | grad norm avg: 14.07 | grad norm last: 13.31 | 
2025-12-28T04:27:58 | step: 948800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.1194620128662791e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.42 | consumed tokens: 485785600.0 | grad norm avg: 13.81 | grad norm last: 12.61 | 
2025-12-28T04:28:00 | step: 948900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.1191427802259568e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.47 | consumed tokens: 485836800.0 | grad norm avg: 14.49 | grad norm last: 12.15 | 
2025-12-28T04:28:03 | step: 949000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.1188240023329854e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.98 | consumed tokens: 485888000.0 | grad norm avg: 13.88 | grad norm last: 11.54 | 
2025-12-28T04:28:05 | step: 949100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.1185056791873649e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.45 | train loss last: 2.94 | consumed tokens: 485939200.0 | grad norm avg: 13.82 | grad norm last: 12.94 | 
2025-12-28T04:28:07 | step: 949200 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.118187719839625e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.11 | consumed tokens: 485990400.0 | grad norm avg: 13.66 | grad norm last: 13.13 | 
2025-12-28T04:28:09 | step: 949300 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.1178702152392361e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.45 | consumed tokens: 486041600.0 | grad norm avg: 13.67 | grad norm last: 14.08 | 
2025-12-28T04:28:11 | step: 949400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.1175531653861981e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.16 | consumed tokens: 486092800.0 | grad norm avg: 14.18 | grad norm last: 13.25 | 
2025-12-28T04:28:13 | step: 949500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.1172363883815706e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.91 | consumed tokens: 486144000.0 | grad norm avg: 14.09 | grad norm last: 13.8 | 
2025-12-28T04:28:15 | step: 949600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.1169201570737641e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.0 | consumed tokens: 486195200.0 | grad norm avg: 13.97 | grad norm last: 12.5 | 
2025-12-28T04:28:17 | step: 949700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.1166043805133086e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.59 | consumed tokens: 486246400.0 | grad norm avg: 13.71 | grad norm last: 14.17 | 
2025-12-28T04:28:19 | step: 949800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.1162887858517934e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.3 | consumed tokens: 486297600.0 | grad norm avg: 13.77 | grad norm last: 12.55 | 
2025-12-28T04:28:21 | step: 949900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.1159739187860396e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.16 | consumed tokens: 486348800.0 | grad norm avg: 13.97 | grad norm last: 11.26 | 
2025-12-28T04:28:23 | step: 950000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.1156593245686963e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.09 | consumed tokens: 486400000.0 | grad norm avg: 16.45 | grad norm last: 12.45 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_950000-seen_tokens_486400000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_950000-seen_tokens_486400000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_950000-seen_tokens_486400000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_950000-seen_tokens_486400000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_950000-seen_tokens_486400000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_950000-seen_tokens_486400000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_950000-seen_tokens_486400000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_950000-seen_tokens_486400000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:28:25 | step: 950100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.1153450941492338e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.59 | train loss last: 3.17 | consumed tokens: 486451200.0 | grad norm avg: 14.19 | grad norm last: 12.85 | 
2025-12-28T04:28:27 | step: 950200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.1150315003760625e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.66 | consumed tokens: 486502400.0 | grad norm avg: 13.97 | grad norm last: 13.59 | 
2025-12-28T04:28:29 | step: 950300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.1147181794513017e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.58 | consumed tokens: 486553600.0 | grad norm avg: 13.83 | grad norm last: 15.62 | 
2025-12-28T04:28:31 | step: 950400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.1144053132738918e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.98 | consumed tokens: 486604800.0 | grad norm avg: 13.87 | grad norm last: 12.62 | 
2025-12-28T04:28:33 | step: 950500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.1140928108943626e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.48 | consumed tokens: 486656000.0 | grad norm avg: 13.86 | grad norm last: 12.23 | 
2025-12-28T04:28:35 | step: 950600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.1137807632621843e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.62 | consumed tokens: 486707200.0 | grad norm avg: 14.08 | grad norm last: 12.74 | 
2025-12-28T04:28:38 | step: 950700 | train samples/s: 98.7 | train mfu (16-bit): -1.0 | lr mean: 1.113469170377357e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.22 | consumed tokens: 486758400.0 | grad norm avg: 14.13 | grad norm last: 12.81 | 
2025-12-28T04:28:40 | step: 950800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.1131579412904102e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 5.19 | consumed tokens: 486809600.0 | grad norm avg: 14.11 | grad norm last: 23.47 | 
2025-12-28T04:28:42 | step: 950900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.1128471669508144e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.42 | consumed tokens: 486860800.0 | grad norm avg: 14.02 | grad norm last: 14.35 | 
2025-12-28T04:28:44 | step: 951000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.1125368473585695e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.33 | consumed tokens: 486912000.0 | grad norm avg: 14.06 | grad norm last: 13.23 | 
2025-12-28T04:28:46 | step: 951100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.1122268915642053e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.88 | consumed tokens: 486963200.0 | grad norm avg: 13.8 | grad norm last: 11.62 | 
2025-12-28T04:28:48 | step: 951200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.111917390517192e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.75 | consumed tokens: 487014400.0 | grad norm avg: 14.1 | grad norm last: 16.39 | 
2025-12-28T04:28:50 | step: 951300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.1116081623185892e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.25 | consumed tokens: 487065600.0 | grad norm avg: 14.15 | grad norm last: 11.64 | 
2025-12-28T04:28:52 | step: 951400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.1112996617157478e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.62 | consumed tokens: 487116800.0 | grad norm avg: 14.5 | grad norm last: 14.04 | 
2025-12-28T04:28:54 | step: 951500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.1109913430118468e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.45 | train loss last: 3.62 | consumed tokens: 487168000.0 | grad norm avg: 13.52 | grad norm last: 13.82 | 
2025-12-28T04:28:56 | step: 951600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.1106835700047668e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.31 | consumed tokens: 487219200.0 | grad norm avg: 14.28 | grad norm last: 11.65 | 
2025-12-28T04:28:58 | step: 951700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.1103761607955676e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.3 | consumed tokens: 487270400.0 | grad norm avg: 13.88 | grad norm last: 13.52 | 
2025-12-28T04:29:00 | step: 951800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.1100692063337192e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.02 | consumed tokens: 487321600.0 | grad norm avg: 13.71 | grad norm last: 12.67 | 
2025-12-28T04:29:02 | step: 951900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.1097626156697515e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.41 | consumed tokens: 487372800.0 | grad norm avg: 14.12 | grad norm last: 24.89 | 
2025-12-28T04:29:04 | step: 952000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.1094564797531348e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.41 | consumed tokens: 487424000.0 | grad norm avg: 13.93 | grad norm last: 12.2 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_952000-seen_tokens_487424000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_952000-seen_tokens_487424000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_952000-seen_tokens_487424000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_952000-seen_tokens_487424000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_952000-seen_tokens_487424000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_952000-seen_tokens_487424000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_952000-seen_tokens_487424000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_952000-seen_tokens_487424000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:29:06 | step: 952100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.109150889533339e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.56 | train loss last: 3.31 | consumed tokens: 487475200.0 | grad norm avg: 13.85 | grad norm last: 11.71 | 
2025-12-28T04:29:08 | step: 952200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.1088454812124837e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.19 | consumed tokens: 487526400.0 | grad norm avg: 14.29 | grad norm last: 15.21 | 
2025-12-28T04:29:10 | step: 952300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.1085406185884494e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.23 | consumed tokens: 487577600.0 | grad norm avg: 13.68 | grad norm last: 12.66 | 
2025-12-28T04:29:12 | step: 952400 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 1.1082363016612362e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.46 | train loss last: 3.72 | consumed tokens: 487628800.0 | grad norm avg: 13.19 | grad norm last: 12.16 | 
2025-12-28T04:29:14 | step: 952500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.1079321666329633e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.33 | consumed tokens: 487680000.0 | grad norm avg: 13.98 | grad norm last: 13.09 | 
2025-12-28T04:29:16 | step: 952600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.1076285773015115e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.94 | consumed tokens: 487731200.0 | grad norm avg: 13.85 | grad norm last: 12.71 | 
2025-12-28T04:29:18 | step: 952700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.1073253517679404e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.59 | consumed tokens: 487782400.0 | grad norm avg: 13.93 | grad norm last: 14.07 | 
2025-12-28T04:29:20 | step: 952800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.1070226719311904e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 4.47 | consumed tokens: 487833600.0 | grad norm avg: 13.54 | grad norm last: 15.21 | 
2025-12-28T04:29:22 | step: 952900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.1067201739933807e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.5 | consumed tokens: 487884800.0 | grad norm avg: 13.91 | grad norm last: 14.3 | 
2025-12-28T04:29:24 | step: 953000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.1064184036513325e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 2.92 | consumed tokens: 487936000.0 | grad norm avg: 14.06 | grad norm last: 12.96 | 
2025-12-28T04:29:26 | step: 953100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.1061169061576948e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.22 | consumed tokens: 487987200.0 | grad norm avg: 14.08 | grad norm last: 12.89 | 
2025-12-28T04:29:28 | step: 953200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.1058157724619377e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.78 | consumed tokens: 488038400.0 | grad norm avg: 14.16 | grad norm last: 12.76 | 
2025-12-28T04:29:30 | step: 953300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.1055151844630018e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.12 | consumed tokens: 488089600.0 | grad norm avg: 13.92 | grad norm last: 12.16 | 
2025-12-28T04:29:32 | step: 953400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.1052149602619465e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.75 | consumed tokens: 488140800.0 | grad norm avg: 14.56 | grad norm last: 18.08 | 
2025-12-28T04:29:34 | step: 953500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.1049151908082422e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.03 | consumed tokens: 488192000.0 | grad norm avg: 13.85 | grad norm last: 13.1 | 
2025-12-28T04:29:37 | step: 953600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.1046157851524185e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.69 | consumed tokens: 488243200.0 | grad norm avg: 13.91 | grad norm last: 13.08 | 
2025-12-28T04:29:39 | step: 953700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.1043168342439458e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.81 | consumed tokens: 488294400.0 | grad norm avg: 13.86 | grad norm last: 12.82 | 
2025-12-28T04:29:41 | step: 953800 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.104018429032294e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.27 | consumed tokens: 488345600.0 | grad norm avg: 13.87 | grad norm last: 15.42 | 
2025-12-28T04:29:43 | step: 953900 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.1037202057195827e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.7 | consumed tokens: 488396800.0 | grad norm avg: 13.92 | grad norm last: 13.56 | 
2025-12-28T04:29:45 | step: 954000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.1034225281036925e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.59 | consumed tokens: 488448000.0 | grad norm avg: 14.61 | grad norm last: 13.15 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_954000-seen_tokens_488448000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_954000-seen_tokens_488448000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_954000-seen_tokens_488448000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_954000-seen_tokens_488448000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_954000-seen_tokens_488448000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_954000-seen_tokens_488448000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_954000-seen_tokens_488448000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_954000-seen_tokens_488448000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:29:47 | step: 954100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.103125305235153e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 3.36 | consumed tokens: 488499200.0 | grad norm avg: 13.94 | grad norm last: 13.58 | 
2025-12-28T04:29:49 | step: 954200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.1028284461644944e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.72 | consumed tokens: 488550400.0 | grad norm avg: 14.3 | grad norm last: 14.17 | 
2025-12-28T04:29:51 | step: 954300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.1025320418411866e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 4.19 | consumed tokens: 488601600.0 | grad norm avg: 14.09 | grad norm last: 14.46 | 
2025-12-28T04:29:53 | step: 954400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.1022360013157595e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.69 | consumed tokens: 488652800.0 | grad norm avg: 13.71 | grad norm last: 13.29 | 
2025-12-28T04:29:55 | step: 954500 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.1019405064871535e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.17 | consumed tokens: 488704000.0 | grad norm avg: 13.69 | grad norm last: 11.77 | 
2025-12-28T04:29:57 | step: 954600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.1016453754564282e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 2.89 | consumed tokens: 488755200.0 | grad norm avg: 13.8 | grad norm last: 12.68 | 
2025-12-28T04:29:59 | step: 954700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.1013505172741134e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.25 | consumed tokens: 488806400.0 | grad norm avg: 14.62 | grad norm last: 13.22 | 
2025-12-28T04:30:01 | step: 954800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.10105638668756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.55 | consumed tokens: 488857600.0 | grad norm avg: 13.78 | grad norm last: 13.38 | 
2025-12-28T04:30:03 | step: 954900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.100762437999947e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.34 | consumed tokens: 488908800.0 | grad norm avg: 13.85 | grad norm last: 13.24 | 
2025-12-28T04:30:05 | step: 955000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.1004689440596849e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.02 | consumed tokens: 488960000.0 | grad norm avg: 14.28 | grad norm last: 11.4 | 
2025-12-28T04:30:07 | step: 955100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.1001759958162438e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 4.41 | consumed tokens: 489011200.0 | grad norm avg: 14.3 | grad norm last: 15.3 | 
2025-12-28T04:30:09 | step: 955200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0998833204212133e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.44 | consumed tokens: 489062400.0 | grad norm avg: 13.66 | grad norm last: 14.53 | 
2025-12-28T04:30:11 | step: 955300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0995911907230038e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.7 | consumed tokens: 489113600.0 | grad norm avg: 13.61 | grad norm last: 13.11 | 
2025-12-28T04:30:13 | step: 955400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.099299424822675e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.39 | consumed tokens: 489164800.0 | grad norm avg: 13.73 | grad norm last: 14.24 | 
2025-12-28T04:30:16 | step: 955500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0990082046191674e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.78 | consumed tokens: 489216000.0 | grad norm avg: 14.16 | grad norm last: 12.99 | 
2025-12-28T04:30:18 | step: 955600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0987171663146e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.92 | consumed tokens: 489267200.0 | grad norm avg: 13.96 | grad norm last: 15.77 | 
2025-12-28T04:30:20 | step: 955700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0984266737068538e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.23 | consumed tokens: 489318400.0 | grad norm avg: 14.07 | grad norm last: 13.69 | 
2025-12-28T04:30:22 | step: 955800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0981366358464584e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.42 | consumed tokens: 489369600.0 | grad norm avg: 14.0 | grad norm last: 12.6 | 
2025-12-28T04:30:24 | step: 955900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0978469617839437e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 2.84 | consumed tokens: 489420800.0 | grad norm avg: 14.65 | grad norm last: 11.28 | 
2025-12-28T04:30:26 | step: 956000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0975577424687799e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.47 | train loss last: 2.83 | consumed tokens: 489472000.0 | grad norm avg: 13.74 | grad norm last: 12.16 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_956000-seen_tokens_489472000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_956000-seen_tokens_489472000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_956000-seen_tokens_489472000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_956000-seen_tokens_489472000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_956000-seen_tokens_489472000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_956000-seen_tokens_489472000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_956000-seen_tokens_489472000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_956000-seen_tokens_489472000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:30:28 | step: 956100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.097268977900967e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.66 | consumed tokens: 489523200.0 | grad norm avg: 14.22 | grad norm last: 19.09 | 
2025-12-28T04:30:30 | step: 956200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0969805771310348e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 4.0 | consumed tokens: 489574400.0 | grad norm avg: 13.63 | grad norm last: 15.06 | 
2025-12-28T04:30:32 | step: 956300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0966926311084535e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.0 | consumed tokens: 489625600.0 | grad norm avg: 13.7 | grad norm last: 14.6 | 
2025-12-28T04:30:34 | step: 956400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0964050488837529e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.28 | consumed tokens: 489676800.0 | grad norm avg: 13.96 | grad norm last: 12.02 | 
2025-12-28T04:30:36 | step: 956500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0961180123558734e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.83 | consumed tokens: 489728000.0 | grad norm avg: 14.08 | grad norm last: 13.26 | 
2025-12-28T04:30:38 | step: 956600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0958313396258745e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.06 | consumed tokens: 489779200.0 | grad norm avg: 14.08 | grad norm last: 12.48 | 
2025-12-28T04:30:40 | step: 956700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0955450306937564e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.33 | consumed tokens: 489830400.0 | grad norm avg: 13.83 | grad norm last: 13.32 | 
2025-12-28T04:30:42 | step: 956800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.095259085559519e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 2.72 | consumed tokens: 489881600.0 | grad norm avg: 13.77 | grad norm last: 13.48 | 
2025-12-28T04:30:44 | step: 956900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0949737770715728e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.36 | consumed tokens: 489932800.0 | grad norm avg: 13.84 | grad norm last: 13.23 | 
2025-12-28T04:30:46 | step: 957000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0946888323815074e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.31 | consumed tokens: 489984000.0 | grad norm avg: 14.04 | grad norm last: 13.21 | 
2025-12-28T04:30:48 | step: 957100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0944041605398525e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.78 | consumed tokens: 490035200.0 | grad norm avg: 13.95 | grad norm last: 22.02 | 
2025-12-28T04:30:50 | step: 957200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.094120216293959e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.81 | consumed tokens: 490086400.0 | grad norm avg: 13.8 | grad norm last: 19.64 | 
2025-12-28T04:30:52 | step: 957300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0938364539470058e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 2.55 | consumed tokens: 490137600.0 | grad norm avg: 14.03 | grad norm last: 11.12 | 
2025-12-28T04:30:54 | step: 957400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0935531463474035e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.84 | consumed tokens: 490188800.0 | grad norm avg: 14.03 | grad norm last: 13.33 | 
2025-12-28T04:30:56 | step: 957500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0932703844446223e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.44 | consumed tokens: 490240000.0 | grad norm avg: 13.95 | grad norm last: 15.97 | 
2025-12-28T04:30:58 | step: 957600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0929878044407815e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.44 | train loss last: 4.28 | consumed tokens: 490291200.0 | grad norm avg: 13.9 | grad norm last: 16.61 | 
2025-12-28T04:31:00 | step: 957700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0927057701337617e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.25 | consumed tokens: 490342400.0 | grad norm avg: 13.98 | grad norm last: 13.5 | 
2025-12-28T04:31:02 | step: 957800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0924241905740928e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.42 | consumed tokens: 490393600.0 | grad norm avg: 13.67 | grad norm last: 12.48 | 
2025-12-28T04:31:04 | step: 957900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0921430657617748e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.28 | consumed tokens: 490444800.0 | grad norm avg: 14.64 | grad norm last: 13.65 | 
2025-12-28T04:31:06 | step: 958000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0918623047473375e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.41 | consumed tokens: 490496000.0 | grad norm avg: 13.85 | grad norm last: 16.05 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_958000-seen_tokens_490496000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_958000-seen_tokens_490496000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_958000-seen_tokens_490496000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_958000-seen_tokens_490496000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_958000-seen_tokens_490496000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_958000-seen_tokens_490496000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_958000-seen_tokens_490496000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_958000-seen_tokens_490496000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:31:09 | step: 958100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.091581998480251e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.59 | train loss last: 3.5 | consumed tokens: 490547200.0 | grad norm avg: 13.77 | grad norm last: 12.06 | 
2025-12-28T04:31:11 | step: 958200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0913020560110454e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.48 | consumed tokens: 490598400.0 | grad norm avg: 14.06 | grad norm last: 16.35 | 
2025-12-28T04:31:13 | step: 958300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0910225682891905e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.86 | consumed tokens: 490649600.0 | grad norm avg: 13.66 | grad norm last: 11.37 | 
2025-12-28T04:31:15 | step: 958400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0907435353146866e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.03 | consumed tokens: 490700800.0 | grad norm avg: 13.66 | grad norm last: 12.3 | 
2025-12-28T04:31:17 | step: 958500 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0904648661380634e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.5 | consumed tokens: 490752000.0 | grad norm avg: 13.89 | grad norm last: 12.72 | 
2025-12-28T04:31:19 | step: 958600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0901868336077314e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 2.95 | consumed tokens: 490803200.0 | grad norm avg: 14.05 | grad norm last: 12.95 | 
2025-12-28T04:31:21 | step: 958700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0899088920268696e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 4.03 | consumed tokens: 490854400.0 | grad norm avg: 13.57 | grad norm last: 16.01 | 
2025-12-28T04:31:23 | step: 958800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0896316780417692e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.62 | consumed tokens: 490905600.0 | grad norm avg: 14.01 | grad norm last: 13.57 | 
2025-12-28T04:31:25 | step: 958900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0893546459556092e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.14 | consumed tokens: 490956800.0 | grad norm avg: 13.86 | grad norm last: 12.39 | 
2025-12-28T04:31:27 | step: 959000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0890781595662702e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.78 | consumed tokens: 491008000.0 | grad norm avg: 13.51 | grad norm last: 18.94 | 
2025-12-28T04:31:29 | step: 959100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.088802036974812e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.61 | consumed tokens: 491059200.0 | grad norm avg: 14.08 | grad norm last: 13.6 | 
2025-12-28T04:31:31 | step: 959200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0885264600801747e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.09 | consumed tokens: 491110400.0 | grad norm avg: 13.79 | grad norm last: 13.46 | 
2025-12-28T04:31:33 | step: 959300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.088251156033948e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.41 | consumed tokens: 491161600.0 | grad norm avg: 13.89 | grad norm last: 15.03 | 
2025-12-28T04:31:35 | step: 959400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0879763976845425e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.41 | consumed tokens: 491212800.0 | grad norm avg: 13.85 | grad norm last: 12.63 | 
2025-12-28T04:31:37 | step: 959500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0877020940824877e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.34 | consumed tokens: 491264000.0 | grad norm avg: 13.5 | grad norm last: 11.96 | 
2025-12-28T04:31:39 | step: 959600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.0874279723793734e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.28 | consumed tokens: 491315200.0 | grad norm avg: 13.82 | grad norm last: 11.35 | 
2025-12-28T04:31:41 | step: 959700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.0871543963730801e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.34 | consumed tokens: 491366400.0 | grad norm avg: 13.94 | grad norm last: 14.69 | 
2025-12-28T04:31:43 | step: 959800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0868813660636079e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.11 | consumed tokens: 491417600.0 | grad norm avg: 14.03 | grad norm last: 12.68 | 
2025-12-28T04:31:45 | step: 959900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0866086995520163e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.84 | consumed tokens: 491468800.0 | grad norm avg: 14.01 | grad norm last: 15.63 | 
2025-12-28T04:31:47 | step: 960000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0863363968383055e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 2.7 | consumed tokens: 491520000.0 | grad norm avg: 14.13 | grad norm last: 12.25 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_960000-seen_tokens_491520000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_960000-seen_tokens_491520000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_960000-seen_tokens_491520000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_960000-seen_tokens_491520000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_960000-seen_tokens_491520000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_960000-seen_tokens_491520000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_960000-seen_tokens_491520000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_960000-seen_tokens_491520000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:31:50 | step: 960100 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.0860644579224754e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.44 | consumed tokens: 491571200.0 | grad norm avg: 14.24 | grad norm last: 12.91 | 
2025-12-28T04:31:52 | step: 960200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0857930647034664e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.19 | consumed tokens: 491622400.0 | grad norm avg: 14.05 | grad norm last: 12.18 | 
2025-12-28T04:31:54 | step: 960300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0855222171812784e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.09 | consumed tokens: 491673600.0 | grad norm avg: 13.92 | grad norm last: 13.54 | 
2025-12-28T04:31:56 | step: 960400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0852515515580308e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.12 | consumed tokens: 491724800.0 | grad norm avg: 13.9 | grad norm last: 12.1 | 
2025-12-28T04:31:58 | step: 960500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0849814316316042e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.44 | consumed tokens: 491776000.0 | grad norm avg: 13.74 | grad norm last: 13.06 | 
2025-12-28T04:32:00 | step: 960600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0847117664525285e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.56 | consumed tokens: 491827200.0 | grad norm avg: 14.48 | grad norm last: 12.5 | 
2025-12-28T04:32:02 | step: 960700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0844424650713336e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 4.0 | consumed tokens: 491878400.0 | grad norm avg: 13.81 | grad norm last: 15.89 | 
2025-12-28T04:32:04 | step: 960800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0841736184374895e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.66 | consumed tokens: 491929600.0 | grad norm avg: 13.75 | grad norm last: 13.88 | 
2025-12-28T04:32:06 | step: 960900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0839051356015261e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 2.83 | consumed tokens: 491980800.0 | grad norm avg: 14.11 | grad norm last: 13.12 | 
2025-12-28T04:32:08 | step: 961000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0836371075129136e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.56 | consumed tokens: 492032000.0 | grad norm avg: 14.35 | grad norm last: 18.8 | 
2025-12-28T04:32:10 | step: 961100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0833694432221819e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.06 | consumed tokens: 492083200.0 | grad norm avg: 14.12 | grad norm last: 13.67 | 
2025-12-28T04:32:12 | step: 961200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0831023246282712e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.42 | consumed tokens: 492134400.0 | grad norm avg: 14.11 | grad norm last: 13.08 | 
2025-12-28T04:32:14 | step: 961300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0828355698322412e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 5.91 | consumed tokens: 492185600.0 | grad norm avg: 13.86 | grad norm last: 35.52 | 
2025-12-28T04:32:16 | step: 961400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.082569269783562e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.44 | consumed tokens: 492236800.0 | grad norm avg: 13.65 | grad norm last: 13.12 | 
2025-12-28T04:32:18 | step: 961500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0823034244822338e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.52 | consumed tokens: 492288000.0 | grad norm avg: 13.81 | grad norm last: 12.76 | 
2025-12-28T04:32:20 | step: 961600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0820379429787863e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.95 | consumed tokens: 492339200.0 | grad norm avg: 14.29 | grad norm last: 18.78 | 
2025-12-28T04:32:22 | step: 961700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0817729162226897e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.98 | consumed tokens: 492390400.0 | grad norm avg: 14.28 | grad norm last: 14.78 | 
2025-12-28T04:32:24 | step: 961800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0815082532644738e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.36 | consumed tokens: 492441600.0 | grad norm avg: 13.81 | grad norm last: 12.31 | 
2025-12-28T04:32:26 | step: 961900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0812440450536087e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.03 | consumed tokens: 492492800.0 | grad norm avg: 13.66 | grad norm last: 12.05 | 
2025-12-28T04:32:28 | step: 962000 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0809802915900946e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 2.94 | consumed tokens: 492544000.0 | grad norm avg: 13.53 | grad norm last: 11.76 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_962000-seen_tokens_492544000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_962000-seen_tokens_492544000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_962000-seen_tokens_492544000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_962000-seen_tokens_492544000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_962000-seen_tokens_492544000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_962000-seen_tokens_492544000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_962000-seen_tokens_492544000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_962000-seen_tokens_492544000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:32:31 | step: 962100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0807169928739313e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.86 | consumed tokens: 492595200.0 | grad norm avg: 13.85 | grad norm last: 17.39 | 
2025-12-28T04:32:33 | step: 962200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0804539670061786e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.55 | consumed tokens: 492646400.0 | grad norm avg: 13.84 | grad norm last: 15.85 | 
2025-12-28T04:32:35 | step: 962300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.080191577784717e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.36 | consumed tokens: 492697600.0 | grad norm avg: 13.62 | grad norm last: 13.26 | 
2025-12-28T04:32:37 | step: 962400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.079929370462196e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.8 | consumed tokens: 492748800.0 | grad norm avg: 14.32 | grad norm last: 12.22 | 
2025-12-28T04:32:39 | step: 962500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.079667799785966e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.5 | consumed tokens: 492800000.0 | grad norm avg: 13.62 | grad norm last: 14.06 | 
2025-12-28T04:32:41 | step: 962600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0794065929076169e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.67 | consumed tokens: 492851200.0 | grad norm avg: 13.49 | grad norm last: 16.23 | 
2025-12-28T04:32:43 | step: 962700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0791457498271484e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.45 | consumed tokens: 492902400.0 | grad norm avg: 14.41 | grad norm last: 12.28 | 
2025-12-28T04:32:45 | step: 962800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.078885452443501e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.12 | consumed tokens: 492953600.0 | grad norm avg: 13.63 | grad norm last: 11.79 | 
2025-12-28T04:32:47 | step: 962900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0786255188577343e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.05 | consumed tokens: 493004800.0 | grad norm avg: 14.12 | grad norm last: 12.65 | 
2025-12-28T04:32:49 | step: 963000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0783660400193185e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 2.98 | consumed tokens: 493056000.0 | grad norm avg: 14.87 | grad norm last: 15.82 | 
2025-12-28T04:32:51 | step: 963100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0781069249787834e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.8 | consumed tokens: 493107200.0 | grad norm avg: 14.27 | grad norm last: 15.19 | 
2025-12-28T04:32:53 | step: 963200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0778482646855991e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.52 | consumed tokens: 493158400.0 | grad norm avg: 14.34 | grad norm last: 14.97 | 
2025-12-28T04:32:55 | step: 963300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0775899681902956e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.61 | consumed tokens: 493209600.0 | grad norm avg: 13.85 | grad norm last: 13.91 | 
2025-12-28T04:32:57 | step: 963400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0773322173918132e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 4.0 | consumed tokens: 493260800.0 | grad norm avg: 13.56 | grad norm last: 14.24 | 
2025-12-28T04:32:59 | step: 963500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0770748303912114e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.64 | consumed tokens: 493312000.0 | grad norm avg: 13.69 | grad norm last: 11.99 | 
2025-12-28T04:33:01 | step: 963600 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 1.0768178071884904e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.31 | consumed tokens: 493363200.0 | grad norm avg: 14.06 | grad norm last: 14.57 | 
2025-12-28T04:33:03 | step: 963700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.0765612387331203e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 2.75 | consumed tokens: 493414400.0 | grad norm avg: 13.82 | grad norm last: 11.05 | 
2025-12-28T04:33:05 | step: 963800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.076305125025101e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.52 | consumed tokens: 493465600.0 | grad norm avg: 13.79 | grad norm last: 13.05 | 
2025-12-28T04:33:07 | step: 963900 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0760494660644326e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.88 | consumed tokens: 493516800.0 | grad norm avg: 13.8 | grad norm last: 13.66 | 
2025-12-28T04:33:09 | step: 964000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0757942618511152e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.28 | consumed tokens: 493568000.0 | grad norm avg: 13.64 | grad norm last: 14.72 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_964000-seen_tokens_493568000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_964000-seen_tokens_493568000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_964000-seen_tokens_493568000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_964000-seen_tokens_493568000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_964000-seen_tokens_493568000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_964000-seen_tokens_493568000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_964000-seen_tokens_493568000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_964000-seen_tokens_493568000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:33:12 | step: 964100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0755393304862082e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.59 | train loss last: 3.27 | consumed tokens: 493619200.0 | grad norm avg: 15.05 | grad norm last: 11.9 | 
2025-12-28T04:33:14 | step: 964200 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.0752849448181223e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 4.22 | consumed tokens: 493670400.0 | grad norm avg: 13.63 | grad norm last: 14.53 | 
2025-12-28T04:33:16 | step: 964300 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.0750310138973873e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.31 | consumed tokens: 493721600.0 | grad norm avg: 14.07 | grad norm last: 14.13 | 
2025-12-28T04:33:18 | step: 964400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.074777446774533e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 4.28 | consumed tokens: 493772800.0 | grad norm avg: 13.93 | grad norm last: 16.98 | 
2025-12-28T04:33:20 | step: 964500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0745242434495594e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.97 | consumed tokens: 493824000.0 | grad norm avg: 14.07 | grad norm last: 11.23 | 
2025-12-28T04:33:22 | step: 964600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.074271585821407e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.69 | consumed tokens: 493875200.0 | grad norm avg: 13.54 | grad norm last: 12.0 | 
2025-12-28T04:33:24 | step: 964700 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0740192919911351e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.64 | consumed tokens: 493926400.0 | grad norm avg: 13.58 | grad norm last: 14.28 | 
2025-12-28T04:33:26 | step: 964800 | train samples/s: 104.7 | train mfu (16-bit): -1.0 | lr mean: 1.073767361958744e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.88 | consumed tokens: 493977600.0 | grad norm avg: 13.85 | grad norm last: 15.51 | 
2025-12-28T04:33:28 | step: 964900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.073515977623174e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.28 | consumed tokens: 494028800.0 | grad norm avg: 13.64 | grad norm last: 13.45 | 
2025-12-28T04:33:30 | step: 965000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0732649570854846e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.22 | consumed tokens: 494080000.0 | grad norm avg: 14.06 | grad norm last: 12.93 | 
2025-12-28T04:33:32 | step: 965100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.073014300345676e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.3 | consumed tokens: 494131200.0 | grad norm avg: 13.85 | grad norm last: 11.97 | 
2025-12-28T04:33:34 | step: 965200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0727642802521586e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.44 | consumed tokens: 494182400.0 | grad norm avg: 13.91 | grad norm last: 11.2 | 
2025-12-28T04:33:36 | step: 965300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0725144420575816e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.53 | consumed tokens: 494233600.0 | grad norm avg: 13.95 | grad norm last: 12.01 | 
2025-12-28T04:33:38 | step: 965400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0722652405092958e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.75 | consumed tokens: 494284800.0 | grad norm avg: 13.74 | grad norm last: 17.34 | 
2025-12-28T04:33:40 | step: 965500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0720163118094206e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.55 | consumed tokens: 494336000.0 | grad norm avg: 14.15 | grad norm last: 14.51 | 
2025-12-28T04:33:42 | step: 965600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0717678378568962e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.56 | consumed tokens: 494387200.0 | grad norm avg: 14.09 | grad norm last: 14.25 | 
2025-12-28T04:33:44 | step: 965700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0715198186517227e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.09 | consumed tokens: 494438400.0 | grad norm avg: 13.68 | grad norm last: 12.17 | 
2025-12-28T04:33:46 | step: 965800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0712722541939002e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.44 | consumed tokens: 494489600.0 | grad norm avg: 13.58 | grad norm last: 13.23 | 
2025-12-28T04:33:48 | step: 965900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0710250535339583e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.22 | consumed tokens: 494540800.0 | grad norm avg: 13.74 | grad norm last: 14.02 | 
2025-12-28T04:33:50 | step: 966000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0707783076213673e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.09 | consumed tokens: 494592000.0 | grad norm avg: 13.75 | grad norm last: 15.49 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_966000-seen_tokens_494592000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_966000-seen_tokens_494592000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_966000-seen_tokens_494592000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_966000-seen_tokens_494592000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_966000-seen_tokens_494592000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_966000-seen_tokens_494592000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_966000-seen_tokens_494592000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_966000-seen_tokens_494592000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:33:53 | step: 966100 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0705320164561272e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.12 | consumed tokens: 494643200.0 | grad norm avg: 13.69 | grad norm last: 13.37 | 
2025-12-28T04:33:55 | step: 966200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0702860890887678e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.41 | consumed tokens: 494694400.0 | grad norm avg: 14.09 | grad norm last: 12.49 | 
2025-12-28T04:33:57 | step: 966300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0700406164687593e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.92 | consumed tokens: 494745600.0 | grad norm avg: 14.07 | grad norm last: 13.17 | 
2025-12-28T04:33:59 | step: 966400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0697955985961016e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 4.19 | consumed tokens: 494796800.0 | grad norm avg: 14.13 | grad norm last: 15.21 | 
2025-12-28T04:34:01 | step: 966500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0695509445213247e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 2.73 | consumed tokens: 494848000.0 | grad norm avg: 13.63 | grad norm last: 12.37 | 
2025-12-28T04:34:03 | step: 966600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0693067451938987e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.44 | consumed tokens: 494899200.0 | grad norm avg: 13.98 | grad norm last: 18.68 | 
2025-12-28T04:34:05 | step: 966700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0690630006138235e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.3 | consumed tokens: 494950400.0 | grad norm avg: 14.03 | grad norm last: 13.87 | 
2025-12-28T04:34:07 | step: 966800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0688196198316291e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.36 | consumed tokens: 495001600.0 | grad norm avg: 13.35 | grad norm last: 14.32 | 
2025-12-28T04:34:09 | step: 966900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0685766937967855e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.69 | consumed tokens: 495052800.0 | grad norm avg: 13.49 | grad norm last: 13.08 | 
2025-12-28T04:34:11 | step: 967000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0683342225092929e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.62 | consumed tokens: 495104000.0 | grad norm avg: 13.79 | grad norm last: 14.55 | 
2025-12-28T04:34:13 | step: 967100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.068092115019681e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.66 | consumed tokens: 495155200.0 | grad norm avg: 13.91 | grad norm last: 15.68 | 
2025-12-28T04:34:15 | step: 967200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.06785055322689e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.48 | consumed tokens: 495206400.0 | grad norm avg: 13.89 | grad norm last: 16.37 | 
2025-12-28T04:34:17 | step: 967300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0676093552319799e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 2.83 | consumed tokens: 495257600.0 | grad norm avg: 13.84 | grad norm last: 12.47 | 
2025-12-28T04:34:19 | step: 967400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0673685210349504e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.44 | consumed tokens: 495308800.0 | grad norm avg: 13.69 | grad norm last: 14.14 | 
2025-12-28T04:34:21 | step: 967500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.067128232534742e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.59 | consumed tokens: 495360000.0 | grad norm avg: 13.6 | grad norm last: 12.97 | 
2025-12-28T04:34:23 | step: 967600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0668882168829441e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.39 | consumed tokens: 495411200.0 | grad norm avg: 13.8 | grad norm last: 12.91 | 
2025-12-28T04:34:25 | step: 967700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0666487469279673e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.42 | consumed tokens: 495462400.0 | grad norm avg: 13.62 | grad norm last: 13.73 | 
2025-12-28T04:34:27 | step: 967800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0664097317203414e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.61 | consumed tokens: 495513600.0 | grad norm avg: 13.55 | grad norm last: 12.65 | 
2025-12-28T04:34:29 | step: 967900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0661710803105962e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.41 | consumed tokens: 495564800.0 | grad norm avg: 13.5 | grad norm last: 12.1 | 
2025-12-28T04:34:31 | step: 968000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0659327926987316e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.97 | consumed tokens: 495616000.0 | grad norm avg: 14.0 | grad norm last: 13.24 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_968000-seen_tokens_495616000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_968000-seen_tokens_495616000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_968000-seen_tokens_495616000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_968000-seen_tokens_495616000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_968000-seen_tokens_495616000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_968000-seen_tokens_495616000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_968000-seen_tokens_495616000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_968000-seen_tokens_495616000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:34:33 | step: 968100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.065694959834218e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.55 | train loss last: 3.17 | consumed tokens: 495667200.0 | grad norm avg: 13.73 | grad norm last: 12.06 | 
2025-12-28T04:34:35 | step: 968200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0654574907675851e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.44 | train loss last: 3.95 | consumed tokens: 495718400.0 | grad norm avg: 13.62 | grad norm last: 13.12 | 
2025-12-28T04:34:37 | step: 968300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0652206583472434e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.23 | consumed tokens: 495769600.0 | grad norm avg: 13.94 | grad norm last: 13.06 | 
2025-12-28T04:34:39 | step: 968400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0649841897247825e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.11 | consumed tokens: 495820800.0 | grad norm avg: 13.81 | grad norm last: 12.68 | 
2025-12-28T04:34:41 | step: 968500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0647480849002022e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.22 | consumed tokens: 495872000.0 | grad norm avg: 13.48 | grad norm last: 11.17 | 
2025-12-28T04:34:43 | step: 968600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0645123438735027e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.61 | consumed tokens: 495923200.0 | grad norm avg: 13.82 | grad norm last: 11.15 | 
2025-12-28T04:34:46 | step: 968700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0642771485436242e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.27 | consumed tokens: 495974400.0 | grad norm avg: 13.97 | grad norm last: 13.3 | 
2025-12-28T04:34:48 | step: 968800 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.0640423170116264e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.62 | consumed tokens: 496025600.0 | grad norm avg: 13.59 | grad norm last: 14.37 | 
2025-12-28T04:34:50 | step: 968900 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.0638079402269796e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.39 | consumed tokens: 496076800.0 | grad norm avg: 13.9 | grad norm last: 12.45 | 
2025-12-28T04:34:52 | step: 969000 | train samples/s: 97.6 | train mfu (16-bit): -1.0 | lr mean: 1.0635740181896836e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.97 | consumed tokens: 496128000.0 | grad norm avg: 13.75 | grad norm last: 13.57 | 
2025-12-28T04:34:54 | step: 969100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0633404599502683e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.91 | consumed tokens: 496179200.0 | grad norm avg: 13.4 | grad norm last: 13.09 | 
2025-12-28T04:34:56 | step: 969200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0631073564582039e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.36 | consumed tokens: 496230400.0 | grad norm avg: 14.29 | grad norm last: 12.36 | 
2025-12-28T04:34:58 | step: 969300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0628747077134904e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.11 | consumed tokens: 496281600.0 | grad norm avg: 13.61 | grad norm last: 11.48 | 
2025-12-28T04:35:00 | step: 969400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.0626424227666575e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 4.81 | consumed tokens: 496332800.0 | grad norm avg: 13.76 | grad norm last: 17.29 | 
2025-12-28T04:35:02 | step: 969500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.0624105925671756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.56 | consumed tokens: 496384000.0 | grad norm avg: 13.87 | grad norm last: 13.72 | 
2025-12-28T04:35:04 | step: 969600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0621792171150446e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.28 | consumed tokens: 496435200.0 | grad norm avg: 13.87 | grad norm last: 15.26 | 
2025-12-28T04:35:06 | step: 969700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0619482054607943e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.41 | consumed tokens: 496486400.0 | grad norm avg: 13.65 | grad norm last: 13.63 | 
2025-12-28T04:35:08 | step: 969800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0617176485538948e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.84 | consumed tokens: 496537600.0 | grad norm avg: 13.81 | grad norm last: 15.75 | 
2025-12-28T04:35:10 | step: 969900 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.0614875463943463e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.03 | consumed tokens: 496588800.0 | grad norm avg: 13.61 | grad norm last: 16.1 | 
2025-12-28T04:35:12 | step: 970000 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0612578080326784e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.53 | consumed tokens: 496640000.0 | grad norm avg: 13.73 | grad norm last: 15.02 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_970000-seen_tokens_496640000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_970000-seen_tokens_496640000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_970000-seen_tokens_496640000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_970000-seen_tokens_496640000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_970000-seen_tokens_496640000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_970000-seen_tokens_496640000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_970000-seen_tokens_496640000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_970000-seen_tokens_496640000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:35:15 | step: 970100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0610286153678317e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.02 | consumed tokens: 496691200.0 | grad norm avg: 13.64 | grad norm last: 14.24 | 
2025-12-28T04:35:17 | step: 970200 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0607997865008656e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 2.88 | consumed tokens: 496742400.0 | grad norm avg: 13.7 | grad norm last: 12.58 | 
2025-12-28T04:35:19 | step: 970300 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0605713214317802e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.47 | train loss last: 3.36 | consumed tokens: 496793600.0 | grad norm avg: 13.67 | grad norm last: 13.99 | 
2025-12-28T04:35:21 | step: 970400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0603432201605756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 5.84 | consumed tokens: 496844800.0 | grad norm avg: 13.68 | grad norm last: 17.17 | 
2025-12-28T04:35:23 | step: 970500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0601157555356622e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 2.92 | consumed tokens: 496896000.0 | grad norm avg: 13.56 | grad norm last: 10.66 | 
2025-12-28T04:35:25 | step: 970600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0598886547086295e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.38 | consumed tokens: 496947200.0 | grad norm avg: 13.89 | grad norm last: 12.38 | 
2025-12-28T04:35:27 | step: 970700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0596620086289477e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.7 | consumed tokens: 496998400.0 | grad norm avg: 13.87 | grad norm last: 14.03 | 
2025-12-28T04:35:29 | step: 970800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0594357263471466e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.47 | consumed tokens: 497049600.0 | grad norm avg: 13.53 | grad norm last: 11.5 | 
2025-12-28T04:35:31 | step: 970900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0592098078632262e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.33 | consumed tokens: 497100800.0 | grad norm avg: 14.1 | grad norm last: 15.61 | 
2025-12-28T04:35:33 | step: 971000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0589844350761268e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.66 | consumed tokens: 497152000.0 | grad norm avg: 14.28 | grad norm last: 35.18 | 
2025-12-28T04:35:35 | step: 971100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0587594260869082e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 4.81 | consumed tokens: 497203200.0 | grad norm avg: 14.14 | grad norm last: 21.87 | 
2025-12-28T04:35:37 | step: 971200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0585349627945106e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.69 | consumed tokens: 497254400.0 | grad norm avg: 14.51 | grad norm last: 11.6 | 
2025-12-28T04:35:39 | step: 971300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0583106814010534e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.59 | consumed tokens: 497305600.0 | grad norm avg: 14.36 | grad norm last: 14.2 | 
2025-12-28T04:35:41 | step: 971400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0580869457044173e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.09 | consumed tokens: 497356800.0 | grad norm avg: 14.41 | grad norm last: 13.77 | 
2025-12-28T04:35:43 | step: 971500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0578635738056619e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.78 | consumed tokens: 497408000.0 | grad norm avg: 13.83 | grad norm last: 13.24 | 
2025-12-28T04:35:45 | step: 971600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0576408385531977e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.77 | consumed tokens: 497459200.0 | grad norm avg: 14.13 | grad norm last: 13.65 | 
2025-12-28T04:35:47 | step: 971700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0574182851996738e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.27 | consumed tokens: 497510400.0 | grad norm avg: 13.72 | grad norm last: 12.72 | 
2025-12-28T04:35:49 | step: 971800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0571963684924413e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 5.59 | consumed tokens: 497561600.0 | grad norm avg: 13.92 | grad norm last: 17.09 | 
2025-12-28T04:35:51 | step: 971900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0569748155830894e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.72 | consumed tokens: 497612800.0 | grad norm avg: 13.77 | grad norm last: 14.03 | 
2025-12-28T04:35:53 | step: 972000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0567536264716182e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.53 | consumed tokens: 497664000.0 | grad norm avg: 14.06 | grad norm last: 12.88 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_972000-seen_tokens_497664000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_972000-seen_tokens_497664000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_972000-seen_tokens_497664000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_972000-seen_tokens_497664000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_972000-seen_tokens_497664000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_972000-seen_tokens_497664000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_972000-seen_tokens_497664000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_972000-seen_tokens_497664000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:35:55 | step: 972100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.056532983056968e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.59 | train loss last: 3.78 | consumed tokens: 497715200.0 | grad norm avg: 13.92 | grad norm last: 12.71 | 
2025-12-28T04:35:57 | step: 972200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0563126124907285e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.97 | consumed tokens: 497766400.0 | grad norm avg: 13.81 | grad norm last: 11.63 | 
2025-12-28T04:35:59 | step: 972300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.05609278762131e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.17 | consumed tokens: 497817600.0 | grad norm avg: 14.2 | grad norm last: 17.26 | 
2025-12-28T04:36:01 | step: 972400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0558734174992424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 4.09 | consumed tokens: 497868800.0 | grad norm avg: 13.71 | grad norm last: 16.17 | 
2025-12-28T04:36:03 | step: 972500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0556544111750554e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 5.03 | consumed tokens: 497920000.0 | grad norm avg: 14.3 | grad norm last: 29.09 | 
2025-12-28T04:36:05 | step: 972600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0554357686487492e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.43 | train loss last: 2.92 | consumed tokens: 497971200.0 | grad norm avg: 13.86 | grad norm last: 12.08 | 
2025-12-28T04:36:08 | step: 972700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0552175808697939e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.8 | consumed tokens: 498022400.0 | grad norm avg: 13.98 | grad norm last: 12.43 | 
2025-12-28T04:36:10 | step: 972800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0549997568887193e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.44 | consumed tokens: 498073600.0 | grad norm avg: 14.53 | grad norm last: 12.5 | 
2025-12-28T04:36:12 | step: 972900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0547825695539359e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.12 | consumed tokens: 498124800.0 | grad norm avg: 13.71 | grad norm last: 15.13 | 
2025-12-28T04:36:14 | step: 973000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.054565655067563e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.08 | consumed tokens: 498176000.0 | grad norm avg: 13.72 | grad norm last: 12.83 | 
2025-12-28T04:36:16 | step: 973100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0543491953285411e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.19 | consumed tokens: 498227200.0 | grad norm avg: 14.0 | grad norm last: 14.23 | 
2025-12-28T04:36:18 | step: 973200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.05413319033687e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.92 | consumed tokens: 498278400.0 | grad norm avg: 13.89 | grad norm last: 11.11 | 
2025-12-28T04:36:20 | step: 973300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0539176400925498e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 2.72 | consumed tokens: 498329600.0 | grad norm avg: 13.79 | grad norm last: 12.03 | 
2025-12-28T04:36:22 | step: 973400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0537024536461104e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.52 | consumed tokens: 498380800.0 | grad norm avg: 13.97 | grad norm last: 13.69 | 
2025-12-28T04:36:24 | step: 973500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0534877219470218e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.94 | consumed tokens: 498432000.0 | grad norm avg: 13.69 | grad norm last: 13.5 | 
2025-12-28T04:36:26 | step: 973600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0532733540458139e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 4.59 | consumed tokens: 498483200.0 | grad norm avg: 13.92 | grad norm last: 18.6 | 
2025-12-28T04:36:28 | step: 973700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0530595318414271e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.64 | consumed tokens: 498534400.0 | grad norm avg: 13.53 | grad norm last: 13.88 | 
2025-12-28T04:36:30 | step: 973800 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.052846073434921e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.67 | consumed tokens: 498585600.0 | grad norm avg: 14.09 | grad norm last: 11.75 | 
2025-12-28T04:36:32 | step: 973900 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.0526328878768254e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 2.7 | consumed tokens: 498636800.0 | grad norm avg: 14.06 | grad norm last: 11.68 | 
2025-12-28T04:36:34 | step: 974000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0524204299144913e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 5.03 | consumed tokens: 498688000.0 | grad norm avg: 13.7 | grad norm last: 17.71 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_974000-seen_tokens_498688000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_974000-seen_tokens_498688000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_974000-seen_tokens_498688000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_974000-seen_tokens_498688000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_974000-seen_tokens_498688000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_974000-seen_tokens_498688000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_974000-seen_tokens_498688000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_974000-seen_tokens_498688000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:36:36 | step: 974100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0522082448005676e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.69 | consumed tokens: 498739200.0 | grad norm avg: 13.79 | grad norm last: 13.74 | 
2025-12-28T04:36:38 | step: 974200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0519965144339949e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 4.41 | consumed tokens: 498790400.0 | grad norm avg: 13.76 | grad norm last: 15.23 | 
2025-12-28T04:36:40 | step: 974300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0517851478653029e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 2.61 | consumed tokens: 498841600.0 | grad norm avg: 13.31 | grad norm last: 12.47 | 
2025-12-28T04:36:42 | step: 974400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0515742360439617e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 2.84 | consumed tokens: 498892800.0 | grad norm avg: 13.55 | grad norm last: 12.48 | 
2025-12-28T04:36:44 | step: 974500 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0513637789699715e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.36 | consumed tokens: 498944000.0 | grad norm avg: 14.22 | grad norm last: 12.35 | 
2025-12-28T04:36:46 | step: 974600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.051153685693862e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.0 | consumed tokens: 498995200.0 | grad norm avg: 14.42 | grad norm last: 11.97 | 
2025-12-28T04:36:48 | step: 974700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0509441381145734e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.97 | consumed tokens: 499046400.0 | grad norm avg: 14.0 | grad norm last: 12.04 | 
2025-12-28T04:36:50 | step: 974800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0507349543331657e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 4.03 | consumed tokens: 499097600.0 | grad norm avg: 14.24 | grad norm last: 13.56 | 
2025-12-28T04:36:53 | step: 974900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.050526316248579e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.33 | consumed tokens: 499148800.0 | grad norm avg: 14.05 | grad norm last: 13.18 | 
2025-12-28T04:36:55 | step: 975000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0503179510124028e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.38 | consumed tokens: 499200000.0 | grad norm avg: 13.75 | grad norm last: 11.91 | 
2025-12-28T04:36:57 | step: 975100 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.0501101314730477e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 5.41 | consumed tokens: 499251200.0 | grad norm avg: 14.59 | grad norm last: 26.62 | 
2025-12-28T04:36:59 | step: 975200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.049902584782103e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 2.81 | consumed tokens: 499302400.0 | grad norm avg: 13.83 | grad norm last: 14.53 | 
2025-12-28T04:37:01 | step: 975300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0496954928385094e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.78 | consumed tokens: 499353600.0 | grad norm avg: 13.89 | grad norm last: 13.35 | 
2025-12-28T04:37:03 | step: 975400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0494889465917367e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.62 | consumed tokens: 499404800.0 | grad norm avg: 14.15 | grad norm last: 13.92 | 
2025-12-28T04:37:05 | step: 975500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.049282855092315e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.05 | consumed tokens: 499456000.0 | grad norm avg: 13.39 | grad norm last: 13.21 | 
2025-12-28T04:37:07 | step: 975600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0490769454918336e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.12 | consumed tokens: 499507200.0 | grad norm avg: 14.63 | grad norm last: 13.25 | 
2025-12-28T04:37:09 | step: 975700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0488717634871136e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.77 | consumed tokens: 499558400.0 | grad norm avg: 13.98 | grad norm last: 12.77 | 
2025-12-28T04:37:11 | step: 975800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.048666763381334e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.77 | consumed tokens: 499609600.0 | grad norm avg: 13.71 | grad norm last: 13.96 | 
2025-12-28T04:37:13 | step: 975900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0484623089723755e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.95 | consumed tokens: 499660800.0 | grad norm avg: 14.18 | grad norm last: 14.4 | 
2025-12-28T04:37:15 | step: 976000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0482582183612976e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.56 | consumed tokens: 499712000.0 | grad norm avg: 14.08 | grad norm last: 15.34 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_976000-seen_tokens_499712000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_976000-seen_tokens_499712000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_976000-seen_tokens_499712000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_976000-seen_tokens_499712000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_976000-seen_tokens_499712000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_976000-seen_tokens_499712000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_976000-seen_tokens_499712000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_976000-seen_tokens_499712000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:37:17 | step: 976100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0480546734470408e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.8 | consumed tokens: 499763200.0 | grad norm avg: 13.74 | grad norm last: 12.67 | 
2025-12-28T04:37:19 | step: 976200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0478514013811946e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.22 | consumed tokens: 499814400.0 | grad norm avg: 13.64 | grad norm last: 13.94 | 
2025-12-28T04:37:21 | step: 976300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0476486750121694e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 2.94 | consumed tokens: 499865600.0 | grad norm avg: 13.68 | grad norm last: 11.9 | 
2025-12-28T04:37:23 | step: 976400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0474464033904951e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 2.81 | consumed tokens: 499916800.0 | grad norm avg: 13.9 | grad norm last: 12.96 | 
2025-12-28T04:37:25 | step: 976500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0472443136677612e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.53 | consumed tokens: 499968000.0 | grad norm avg: 13.79 | grad norm last: 14.6 | 
2025-12-28T04:37:27 | step: 976600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0470429515407886e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.52 | consumed tokens: 500019200.0 | grad norm avg: 13.9 | grad norm last: 13.94 | 
2025-12-28T04:37:29 | step: 976700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0468419532116968e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.36 | consumed tokens: 500070400.0 | grad norm avg: 14.04 | grad norm last: 16.05 | 
2025-12-28T04:37:31 | step: 976800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0466413186804857e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.98 | consumed tokens: 500121600.0 | grad norm avg: 13.45 | grad norm last: 12.46 | 
2025-12-28T04:37:33 | step: 976900 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0464410479471553e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.41 | consumed tokens: 500172800.0 | grad norm avg: 13.66 | grad norm last: 14.23 | 
2025-12-28T04:37:36 | step: 977000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.046241322910646e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.45 | consumed tokens: 500224000.0 | grad norm avg: 13.94 | grad norm last: 14.47 | 
2025-12-28T04:37:38 | step: 977100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0460421435709577e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 2.58 | consumed tokens: 500275200.0 | grad norm avg: 13.71 | grad norm last: 10.41 | 
2025-12-28T04:37:40 | step: 977200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0458431461302098e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.17 | consumed tokens: 500326400.0 | grad norm avg: 14.93 | grad norm last: 13.85 | 
2025-12-28T04:37:42 | step: 977300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0456446034368128e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.19 | consumed tokens: 500377600.0 | grad norm avg: 13.93 | grad norm last: 12.65 | 
2025-12-28T04:37:44 | step: 977400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0454466064402368e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.41 | consumed tokens: 500428800.0 | grad norm avg: 14.32 | grad norm last: 11.92 | 
2025-12-28T04:37:46 | step: 977500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0452490641910117e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.62 | consumed tokens: 500480000.0 | grad norm avg: 14.33 | grad norm last: 14.7 | 
2025-12-28T04:37:48 | step: 977600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0450518857396673e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.8 | consumed tokens: 500531200.0 | grad norm avg: 14.25 | grad norm last: 13.14 | 
2025-12-28T04:37:50 | step: 977700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0448550710862037e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.19 | consumed tokens: 500582400.0 | grad norm avg: 13.9 | grad norm last: 12.83 | 
2025-12-28T04:37:52 | step: 977800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0446587111800909e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.48 | consumed tokens: 500633600.0 | grad norm avg: 14.07 | grad norm last: 15.62 | 
2025-12-28T04:37:54 | step: 977900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0444627150718588e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.86 | consumed tokens: 500684800.0 | grad norm avg: 14.44 | grad norm last: 14.02 | 
2025-12-28T04:37:56 | step: 978000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.044267355609918e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 2.61 | consumed tokens: 500736000.0 | grad norm avg: 14.17 | grad norm last: 11.75 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_978000-seen_tokens_500736000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_978000-seen_tokens_500736000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_978000-seen_tokens_500736000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_978000-seen_tokens_500736000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_978000-seen_tokens_500736000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_978000-seen_tokens_500736000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_978000-seen_tokens_500736000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_978000-seen_tokens_500736000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:37:58 | step: 978100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0440722689963877e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.54 | train loss last: 4.06 | consumed tokens: 500787200.0 | grad norm avg: 13.73 | grad norm last: 13.27 | 
2025-12-28T04:38:00 | step: 978200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0438776371302083e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.17 | consumed tokens: 500838400.0 | grad norm avg: 13.72 | grad norm last: 12.66 | 
2025-12-28T04:38:02 | step: 978300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0436834600113798e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.56 | consumed tokens: 500889600.0 | grad norm avg: 13.72 | grad norm last: 15.59 | 
2025-12-28T04:38:04 | step: 978400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0434897376399022e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 6.56 | consumed tokens: 500940800.0 | grad norm avg: 14.56 | grad norm last: 19.13 | 
2025-12-28T04:38:06 | step: 978500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0432963790663052e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.33 | consumed tokens: 500992000.0 | grad norm avg: 14.03 | grad norm last: 12.11 | 
2025-12-28T04:38:08 | step: 978600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0431034752400592e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.08 | consumed tokens: 501043200.0 | grad norm avg: 14.01 | grad norm last: 13.74 | 
2025-12-28T04:38:10 | step: 978700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.042911026161164e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.06 | consumed tokens: 501094400.0 | grad norm avg: 13.8 | grad norm last: 15.29 | 
2025-12-28T04:38:12 | step: 978800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0427189408801496e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.8 | consumed tokens: 501145600.0 | grad norm avg: 13.82 | grad norm last: 14.63 | 
2025-12-28T04:38:14 | step: 978900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.042527310346486e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.44 | consumed tokens: 501196800.0 | grad norm avg: 14.35 | grad norm last: 12.53 | 
2025-12-28T04:38:16 | step: 979000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0423361345601734e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.25 | consumed tokens: 501248000.0 | grad norm avg: 14.14 | grad norm last: 15.69 | 
2025-12-28T04:38:18 | step: 979100 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.0421453225717414e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.88 | consumed tokens: 501299200.0 | grad norm avg: 13.66 | grad norm last: 13.45 | 
2025-12-28T04:38:20 | step: 979200 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0419550562801305e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.84 | consumed tokens: 501350400.0 | grad norm avg: 14.3 | grad norm last: 13.56 | 
2025-12-28T04:38:22 | step: 979300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0417651537864003e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.5 | consumed tokens: 501401600.0 | grad norm avg: 14.35 | grad norm last: 14.75 | 
2025-12-28T04:38:24 | step: 979400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0415756150905509e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.88 | consumed tokens: 501452800.0 | grad norm avg: 14.19 | grad norm last: 13.38 | 
2025-12-28T04:38:27 | step: 979500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0413866220915224e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 5.09 | consumed tokens: 501504000.0 | grad norm avg: 13.87 | grad norm last: 23.88 | 
2025-12-28T04:38:29 | step: 979600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0411979928903747e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.11 | consumed tokens: 501555200.0 | grad norm avg: 14.08 | grad norm last: 11.8 | 
2025-12-28T04:38:31 | step: 979700 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.041009818436578e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.46 | train loss last: 3.38 | consumed tokens: 501606400.0 | grad norm avg: 13.9 | grad norm last: 13.96 | 
2025-12-28T04:38:33 | step: 979800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0408220077806618e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.2 | consumed tokens: 501657600.0 | grad norm avg: 13.98 | grad norm last: 14.17 | 
2025-12-28T04:38:35 | step: 979900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0406347428215668e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.16 | consumed tokens: 501708800.0 | grad norm avg: 13.94 | grad norm last: 12.01 | 
2025-12-28T04:38:37 | step: 980000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0404478416603524e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 4.16 | consumed tokens: 501760000.0 | grad norm avg: 14.02 | grad norm last: 14.76 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_980000-seen_tokens_501760000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_980000-seen_tokens_501760000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_980000-seen_tokens_501760000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_980000-seen_tokens_501760000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_980000-seen_tokens_501760000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_980000-seen_tokens_501760000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_980000-seen_tokens_501760000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_980000-seen_tokens_501760000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:38:39 | step: 980100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.040261395246489e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.52 | consumed tokens: 501811200.0 | grad norm avg: 14.55 | grad norm last: 12.68 | 
2025-12-28T04:38:41 | step: 980200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0400753126305062e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 2.95 | consumed tokens: 501862400.0 | grad norm avg: 14.03 | grad norm last: 14.14 | 
2025-12-28T04:38:43 | step: 980300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0398896847618744e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 2.89 | consumed tokens: 501913600.0 | grad norm avg: 14.12 | grad norm last: 12.42 | 
2025-12-28T04:38:45 | step: 980400 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0397045116405934e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.31 | consumed tokens: 501964800.0 | grad norm avg: 14.46 | grad norm last: 13.3 | 
2025-12-28T04:38:47 | step: 980500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0395197023171932e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.25 | consumed tokens: 502016000.0 | grad norm avg: 13.81 | grad norm last: 12.3 | 
2025-12-28T04:38:49 | step: 980600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0393353477411438e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.64 | consumed tokens: 502067200.0 | grad norm avg: 14.26 | grad norm last: 12.75 | 
2025-12-28T04:38:51 | step: 980700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0391515388619155e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.52 | consumed tokens: 502118400.0 | grad norm avg: 13.82 | grad norm last: 12.55 | 
2025-12-28T04:38:53 | step: 980800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0389679118816275e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.02 | consumed tokens: 502169600.0 | grad norm avg: 13.97 | grad norm last: 13.06 | 
2025-12-28T04:38:55 | step: 980900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0387851034465712e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.5 | consumed tokens: 502220800.0 | grad norm avg: 14.11 | grad norm last: 12.97 | 
2025-12-28T04:38:57 | step: 981000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0386024769104552e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 2.5 | consumed tokens: 502272000.0 | grad norm avg: 14.02 | grad norm last: 10.13 | 
2025-12-28T04:38:59 | step: 981100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0384202141722199e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.22 | consumed tokens: 502323200.0 | grad norm avg: 14.09 | grad norm last: 13.72 | 
2025-12-28T04:39:01 | step: 981200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0382384061813354e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.06 | consumed tokens: 502374400.0 | grad norm avg: 13.9 | grad norm last: 11.32 | 
2025-12-28T04:39:03 | step: 981300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0380571438872721e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.89 | consumed tokens: 502425600.0 | grad norm avg: 14.21 | grad norm last: 11.08 | 
2025-12-28T04:39:05 | step: 981400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0378763363405596e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.44 | consumed tokens: 502476800.0 | grad norm avg: 13.95 | grad norm last: 12.6 | 
2025-12-28T04:39:07 | step: 981500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0376957106927875e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 5.41 | consumed tokens: 502528000.0 | grad norm avg: 14.11 | grad norm last: 14.98 | 
2025-12-28T04:39:09 | step: 981600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0375156307418365e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.77 | consumed tokens: 502579200.0 | grad norm avg: 14.17 | grad norm last: 18.37 | 
2025-12-28T04:39:12 | step: 981700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0373360964877065e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.45 | train loss last: 3.38 | consumed tokens: 502630400.0 | grad norm avg: 13.73 | grad norm last: 13.11 | 
2025-12-28T04:39:14 | step: 981800 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0371569260314573e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.33 | consumed tokens: 502681600.0 | grad norm avg: 14.4 | grad norm last: 15.3 | 
2025-12-28T04:39:16 | step: 981900 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0369782103225589e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.25 | consumed tokens: 502732800.0 | grad norm avg: 14.47 | grad norm last: 12.12 | 
2025-12-28T04:39:18 | step: 982000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0367998584115412e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.47 | train loss last: 2.81 | consumed tokens: 502784000.0 | grad norm avg: 13.81 | grad norm last: 12.45 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_982000-seen_tokens_502784000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_982000-seen_tokens_502784000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_982000-seen_tokens_502784000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_982000-seen_tokens_502784000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_982000-seen_tokens_502784000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_982000-seen_tokens_502784000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_982000-seen_tokens_502784000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_982000-seen_tokens_502784000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:39:20 | step: 982100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0366219612478744e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.49 | train loss last: 3.59 | consumed tokens: 502835200.0 | grad norm avg: 13.8 | grad norm last: 14.5 | 
2025-12-28T04:39:22 | step: 982200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0364445188315585e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.59 | consumed tokens: 502886400.0 | grad norm avg: 14.21 | grad norm last: 12.2 | 
2025-12-28T04:39:24 | step: 982300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0362674402131233e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.14 | consumed tokens: 502937600.0 | grad norm avg: 13.93 | grad norm last: 14.32 | 
2025-12-28T04:39:26 | step: 982400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.036090816342039e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.34 | consumed tokens: 502988800.0 | grad norm avg: 14.12 | grad norm last: 15.61 | 
2025-12-28T04:39:28 | step: 982500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0359147381677758e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.45 | consumed tokens: 503040000.0 | grad norm avg: 13.91 | grad norm last: 14.53 | 
2025-12-28T04:39:30 | step: 982600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0357388418924529e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.52 | consumed tokens: 503091200.0 | grad norm avg: 14.38 | grad norm last: 12.27 | 
2025-12-28T04:39:32 | step: 982700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0355634913139511e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.12 | consumed tokens: 503142400.0 | grad norm avg: 14.03 | grad norm last: 12.35 | 
2025-12-28T04:39:34 | step: 982800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0353887773817405e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.47 | consumed tokens: 503193600.0 | grad norm avg: 14.05 | grad norm last: 12.83 | 
2025-12-28T04:39:36 | step: 982900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0352142453484703e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.67 | consumed tokens: 503244800.0 | grad norm avg: 13.9 | grad norm last: 12.96 | 
2025-12-28T04:39:38 | step: 983000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0350402590120211e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.19 | consumed tokens: 503296000.0 | grad norm avg: 13.72 | grad norm last: 11.82 | 
2025-12-28T04:39:40 | step: 983100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0348666364734527e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.44 | consumed tokens: 503347200.0 | grad norm avg: 13.87 | grad norm last: 12.61 | 
2025-12-28T04:39:42 | step: 983200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0346934686822351e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.73 | consumed tokens: 503398400.0 | grad norm avg: 14.25 | grad norm last: 14.1 | 
2025-12-28T04:39:44 | step: 983300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0345207556383684e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.02 | consumed tokens: 503449600.0 | grad norm avg: 13.89 | grad norm last: 13.33 | 
2025-12-28T04:39:46 | step: 983400 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0343484063923825e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.31 | consumed tokens: 503500800.0 | grad norm avg: 13.74 | grad norm last: 15.14 | 
2025-12-28T04:39:48 | step: 983500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0341765118937474e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.12 | consumed tokens: 503552000.0 | grad norm avg: 14.12 | grad norm last: 12.57 | 
2025-12-28T04:39:50 | step: 983600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.034004981192993e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.31 | consumed tokens: 503603200.0 | grad norm avg: 14.18 | grad norm last: 12.15 | 
2025-12-28T04:39:52 | step: 983700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0338339961890597e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.47 | consumed tokens: 503654400.0 | grad norm avg: 13.65 | grad norm last: 12.43 | 
2025-12-28T04:39:54 | step: 983800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0336635568819474e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.09 | consumed tokens: 503705600.0 | grad norm avg: 14.62 | grad norm last: 15.74 | 
2025-12-28T04:39:56 | step: 983900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0334932994737756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.78 | consumed tokens: 503756800.0 | grad norm avg: 13.82 | grad norm last: 16.43 | 
2025-12-28T04:39:58 | step: 984000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0333235877624247e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 4.38 | consumed tokens: 503808000.0 | grad norm avg: 13.85 | grad norm last: 17.41 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_984000-seen_tokens_503808000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_984000-seen_tokens_503808000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_984000-seen_tokens_503808000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_984000-seen_tokens_503808000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_984000-seen_tokens_503808000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_984000-seen_tokens_503808000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_984000-seen_tokens_503808000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_984000-seen_tokens_503808000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:40:01 | step: 984100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0331543307984248e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.88 | consumed tokens: 503859200.0 | grad norm avg: 13.75 | grad norm last: 13.75 | 
2025-12-28T04:40:03 | step: 984200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0329854376323055e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.7 | consumed tokens: 503910400.0 | grad norm avg: 14.45 | grad norm last: 21.35 | 
2025-12-28T04:40:05 | step: 984300 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.0328169992135372e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.58 | consumed tokens: 503961600.0 | grad norm avg: 14.46 | grad norm last: 13.14 | 
2025-12-28T04:40:07 | step: 984400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.0326489245926496e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.39 | consumed tokens: 504012800.0 | grad norm avg: 14.17 | grad norm last: 12.65 | 
2025-12-28T04:40:09 | step: 984500 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.032481395668583e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.38 | consumed tokens: 504064000.0 | grad norm avg: 14.03 | grad norm last: 15.1 | 
2025-12-28T04:40:11 | step: 984600 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 1.0323142305423971e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.48 | consumed tokens: 504115200.0 | grad norm avg: 14.01 | grad norm last: 12.18 | 
2025-12-28T04:40:13 | step: 984700 | train samples/s: 104.5 | train mfu (16-bit): -1.0 | lr mean: 1.032147429214092e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.55 | consumed tokens: 504166400.0 | grad norm avg: 14.29 | grad norm last: 13.13 | 
2025-12-28T04:40:15 | step: 984800 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 1.0319811735826079e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.47 | consumed tokens: 504217600.0 | grad norm avg: 14.51 | grad norm last: 15.77 | 
2025-12-28T04:40:17 | step: 984900 | train samples/s: 104.4 | train mfu (16-bit): -1.0 | lr mean: 1.0318152817490045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.08 | consumed tokens: 504268800.0 | grad norm avg: 13.91 | grad norm last: 13.47 | 
2025-12-28T04:40:19 | step: 985000 | train samples/s: 104.8 | train mfu (16-bit): -1.0 | lr mean: 1.0316497537132818e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.59 | consumed tokens: 504320000.0 | grad norm avg: 13.98 | grad norm last: 14.3 | 
2025-12-28T04:40:21 | step: 985100 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.0314848623238504e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.64 | consumed tokens: 504371200.0 | grad norm avg: 14.05 | grad norm last: 12.37 | 
2025-12-28T04:40:23 | step: 985200 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.0313203347322997e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.52 | consumed tokens: 504422400.0 | grad norm avg: 13.81 | grad norm last: 12.85 | 
2025-12-28T04:40:25 | step: 985300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0311562618880998e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.5 | consumed tokens: 504473600.0 | grad norm avg: 14.13 | grad norm last: 14.45 | 
2025-12-28T04:40:27 | step: 985400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0309925528417807e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.11 | consumed tokens: 504524800.0 | grad norm avg: 14.21 | grad norm last: 13.17 | 
2025-12-28T04:40:29 | step: 985500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.030829025694402e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 2.55 | consumed tokens: 504576000.0 | grad norm avg: 13.89 | grad norm last: 11.96 | 
2025-12-28T04:40:31 | step: 985600 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0306663170922548e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.17 | consumed tokens: 504627200.0 | grad norm avg: 14.29 | grad norm last: 12.18 | 
2025-12-28T04:40:33 | step: 985700 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.030503790389048e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.64 | consumed tokens: 504678400.0 | grad norm avg: 13.92 | grad norm last: 13.16 | 
2025-12-28T04:40:35 | step: 985800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0303419003321324e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 5.25 | consumed tokens: 504729600.0 | grad norm avg: 13.52 | grad norm last: 14.97 | 
2025-12-28T04:40:38 | step: 985900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0301802831236273e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.41 | consumed tokens: 504780800.0 | grad norm avg: 13.83 | grad norm last: 15.62 | 
2025-12-28T04:40:40 | step: 986000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0300191206624731e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 4.25 | consumed tokens: 504832000.0 | grad norm avg: 13.61 | grad norm last: 16.47 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_986000-seen_tokens_504832000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_986000-seen_tokens_504832000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_986000-seen_tokens_504832000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_986000-seen_tokens_504832000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_986000-seen_tokens_504832000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_986000-seen_tokens_504832000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_986000-seen_tokens_504832000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_986000-seen_tokens_504832000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:40:42 | step: 986100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0298584129486699e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.6 | train loss last: 3.53 | consumed tokens: 504883200.0 | grad norm avg: 14.19 | grad norm last: 14.11 | 
2025-12-28T04:40:44 | step: 986200 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0296981599822175e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.44 | consumed tokens: 504934400.0 | grad norm avg: 14.53 | grad norm last: 14.4 | 
2025-12-28T04:40:46 | step: 986300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0295382708136458e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.89 | consumed tokens: 504985600.0 | grad norm avg: 14.22 | grad norm last: 16.72 | 
2025-12-28T04:40:48 | step: 986400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0293789273418952e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 4.25 | consumed tokens: 505036800.0 | grad norm avg: 13.71 | grad norm last: 21.38 | 
2025-12-28T04:40:50 | step: 986500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0292199476680253e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 2.95 | consumed tokens: 505088000.0 | grad norm avg: 13.88 | grad norm last: 12.24 | 
2025-12-28T04:40:52 | step: 986600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.029061331792036e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.28 | consumed tokens: 505139200.0 | grad norm avg: 14.18 | grad norm last: 15.65 | 
2025-12-28T04:40:54 | step: 986700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.028903261612868e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.23 | consumed tokens: 505190400.0 | grad norm avg: 14.19 | grad norm last: 14.26 | 
2025-12-28T04:40:56 | step: 986800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0287455552315805e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.5 | consumed tokens: 505241600.0 | grad norm avg: 14.06 | grad norm last: 12.56 | 
2025-12-28T04:40:58 | step: 986900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0285882126481738e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.47 | consumed tokens: 505292800.0 | grad norm avg: 13.86 | grad norm last: 14.1 | 
2025-12-28T04:41:00 | step: 987000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0284314157615881e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.5 | consumed tokens: 505344000.0 | grad norm avg: 14.34 | grad norm last: 13.17 | 
2025-12-28T04:41:02 | step: 987100 | train samples/s: 98.0 | train mfu (16-bit): -1.0 | lr mean: 1.0282749826728832e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.02 | consumed tokens: 505395200.0 | grad norm avg: 14.01 | grad norm last: 12.8 | 
2025-12-28T04:41:04 | step: 987200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0281190043315291e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.14 | consumed tokens: 505446400.0 | grad norm avg: 13.66 | grad norm last: 12.03 | 
2025-12-28T04:41:06 | step: 987300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0279635716869961e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.38 | consumed tokens: 505497600.0 | grad norm avg: 13.92 | grad norm last: 16.8 | 
2025-12-28T04:41:08 | step: 987400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0278083209414035e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.92 | consumed tokens: 505548800.0 | grad norm avg: 14.48 | grad norm last: 15.16 | 
2025-12-28T04:41:10 | step: 987500 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0276537068421021e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.12 | consumed tokens: 505600000.0 | grad norm avg: 13.86 | grad norm last: 11.86 | 
2025-12-28T04:41:12 | step: 987600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0274994565406814e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.7 | consumed tokens: 505651200.0 | grad norm avg: 14.07 | grad norm last: 12.98 | 
2025-12-28T04:41:14 | step: 987700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0273455700371414e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.61 | consumed tokens: 505702400.0 | grad norm avg: 14.14 | grad norm last: 15.19 | 
2025-12-28T04:41:16 | step: 987800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0271923201798927e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.5 | consumed tokens: 505753600.0 | grad norm avg: 13.88 | grad norm last: 12.21 | 
2025-12-28T04:41:18 | step: 987900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0270392522215843e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.2 | consumed tokens: 505804800.0 | grad norm avg: 13.97 | grad norm last: 13.06 | 
2025-12-28T04:41:20 | step: 988000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.026886729960097e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.27 | consumed tokens: 505856000.0 | grad norm avg: 14.44 | grad norm last: 15.05 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_988000-seen_tokens_505856000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_988000-seen_tokens_505856000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_988000-seen_tokens_505856000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_988000-seen_tokens_505856000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_988000-seen_tokens_505856000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_988000-seen_tokens_505856000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_988000-seen_tokens_505856000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_988000-seen_tokens_505856000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:41:23 | step: 988100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0267346624459606e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.97 | consumed tokens: 505907200.0 | grad norm avg: 14.4 | grad norm last: 17.44 | 
2025-12-28T04:41:25 | step: 988200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0265827768307645e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.46 | train loss last: 3.88 | consumed tokens: 505958400.0 | grad norm avg: 14.37 | grad norm last: 15.15 | 
2025-12-28T04:41:27 | step: 988300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0264316188113298e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.92 | consumed tokens: 506009600.0 | grad norm avg: 13.67 | grad norm last: 11.3 | 
2025-12-28T04:41:29 | step: 988400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0262808245897759e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.45 | consumed tokens: 506060800.0 | grad norm avg: 14.32 | grad norm last: 12.3 | 
2025-12-28T04:41:31 | step: 988500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0261304851155728e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.5 | consumed tokens: 506112000.0 | grad norm avg: 14.27 | grad norm last: 12.85 | 
2025-12-28T04:41:33 | step: 988600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0259805094392505e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.45 | train loss last: 3.03 | consumed tokens: 506163200.0 | grad norm avg: 14.39 | grad norm last: 12.51 | 
2025-12-28T04:41:35 | step: 988700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.025830988510279e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.09 | consumed tokens: 506214400.0 | grad norm avg: 14.29 | grad norm last: 16.89 | 
2025-12-28T04:41:37 | step: 988800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0256818313791882e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.16 | consumed tokens: 506265600.0 | grad norm avg: 14.16 | grad norm last: 14.84 | 
2025-12-28T04:41:39 | step: 988900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0255332199449185e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.47 | consumed tokens: 506316800.0 | grad norm avg: 14.11 | grad norm last: 13.9 | 
2025-12-28T04:41:41 | step: 989000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0253849723085295e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.62 | consumed tokens: 506368000.0 | grad norm avg: 14.32 | grad norm last: 14.0 | 
2025-12-28T04:41:43 | step: 989100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0252372703689616e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.5 | consumed tokens: 506419200.0 | grad norm avg: 14.34 | grad norm last: 14.55 | 
2025-12-28T04:41:45 | step: 989200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.025089750328334e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.14 | consumed tokens: 506470400.0 | grad norm avg: 13.93 | grad norm last: 11.92 | 
2025-12-28T04:41:47 | step: 989300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0249427759845275e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.45 | consumed tokens: 506521600.0 | grad norm avg: 14.43 | grad norm last: 13.86 | 
2025-12-28T04:41:49 | step: 989400 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.0247963473375421e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.12 | consumed tokens: 506572800.0 | grad norm avg: 14.36 | grad norm last: 13.58 | 
2025-12-28T04:41:51 | step: 989500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.0246502824884374e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.88 | consumed tokens: 506624000.0 | grad norm avg: 14.37 | grad norm last: 13.99 | 
2025-12-28T04:41:53 | step: 989600 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.0245045814372133e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.88 | consumed tokens: 506675200.0 | grad norm avg: 14.24 | grad norm last: 15.33 | 
2025-12-28T04:41:55 | step: 989700 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.02435924418387e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.91 | consumed tokens: 506726400.0 | grad norm avg: 13.73 | grad norm last: 14.04 | 
2025-12-28T04:41:57 | step: 989800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0242144526273478e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.09 | consumed tokens: 506777600.0 | grad norm avg: 14.23 | grad norm last: 15.63 | 
2025-12-28T04:41:59 | step: 989900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0240702067676466e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.5 | consumed tokens: 506828800.0 | grad norm avg: 14.24 | grad norm last: 13.88 | 
2025-12-28T04:42:01 | step: 990000 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.023926233756356e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.89 | consumed tokens: 506880000.0 | grad norm avg: 14.25 | grad norm last: 12.22 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_990000-seen_tokens_506880000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_990000-seen_tokens_506880000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_990000-seen_tokens_506880000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_990000-seen_tokens_506880000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_990000-seen_tokens_506880000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_990000-seen_tokens_506880000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_990000-seen_tokens_506880000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_990000-seen_tokens_506880000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:42:04 | step: 990100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0237828064418864e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 3.64 | consumed tokens: 506931200.0 | grad norm avg: 14.23 | grad norm last: 16.85 | 
2025-12-28T04:42:06 | step: 990200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0236396519758273e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 3.2 | consumed tokens: 506982400.0 | grad norm avg: 14.18 | grad norm last: 14.3 | 
2025-12-28T04:42:08 | step: 990300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0234970432065893e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.58 | consumed tokens: 507033600.0 | grad norm avg: 13.83 | grad norm last: 12.77 | 
2025-12-28T04:42:10 | step: 990400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0233549801341724e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.19 | consumed tokens: 507084800.0 | grad norm avg: 13.86 | grad norm last: 13.24 | 
2025-12-28T04:42:12 | step: 990500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0232130989606958e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.39 | consumed tokens: 507136000.0 | grad norm avg: 13.72 | grad norm last: 12.63 | 
2025-12-28T04:42:14 | step: 990600 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0230717634840403e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.19 | consumed tokens: 507187200.0 | grad norm avg: 14.28 | grad norm last: 14.57 | 
2025-12-28T04:42:16 | step: 990700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0229307918052655e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.08 | consumed tokens: 507238400.0 | grad norm avg: 14.49 | grad norm last: 12.24 | 
2025-12-28T04:42:18 | step: 990800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0227903658233117e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.61 | consumed tokens: 507289600.0 | grad norm avg: 14.16 | grad norm last: 13.3 | 
2025-12-28T04:42:20 | step: 990900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0226503036392387e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.61 | consumed tokens: 507340800.0 | grad norm avg: 13.77 | grad norm last: 15.08 | 
2025-12-28T04:42:22 | step: 991000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0225106052530464e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 4.03 | consumed tokens: 507392000.0 | grad norm avg: 14.06 | grad norm last: 15.36 | 
2025-12-28T04:42:24 | step: 991100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0223714525636751e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.25 | consumed tokens: 507443200.0 | grad norm avg: 14.36 | grad norm last: 13.23 | 
2025-12-28T04:42:26 | step: 991200 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0222326636721846e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.52 | consumed tokens: 507494400.0 | grad norm avg: 13.98 | grad norm last: 13.73 | 
2025-12-28T04:42:28 | step: 991300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0220942385785747e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 2.95 | consumed tokens: 507545600.0 | grad norm avg: 13.57 | grad norm last: 13.5 | 
2025-12-28T04:42:30 | step: 991400 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0219565410807263e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 5.91 | consumed tokens: 507596800.0 | grad norm avg: 14.12 | grad norm last: 29.33 | 
2025-12-28T04:42:32 | step: 991500 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0218190254818182e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.55 | consumed tokens: 507648000.0 | grad norm avg: 14.2 | grad norm last: 13.15 | 
2025-12-28T04:42:34 | step: 991600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.021681964630261e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.06 | consumed tokens: 507699200.0 | grad norm avg: 13.9 | grad norm last: 11.48 | 
2025-12-28T04:42:36 | step: 991700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.021545449475525e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.91 | consumed tokens: 507750400.0 | grad norm avg: 13.64 | grad norm last: 18.84 | 
2025-12-28T04:42:38 | step: 991800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0214091162197292e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.25 | consumed tokens: 507801600.0 | grad norm avg: 14.43 | grad norm last: 15.49 | 
2025-12-28T04:42:40 | step: 991900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0212734196102247e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.41 | consumed tokens: 507852800.0 | grad norm avg: 14.5 | grad norm last: 12.06 | 
2025-12-28T04:42:42 | step: 992000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0211380867986009e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.38 | consumed tokens: 507904000.0 | grad norm avg: 14.43 | grad norm last: 13.43 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_992000-seen_tokens_507904000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_992000-seen_tokens_507904000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_992000-seen_tokens_507904000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_992000-seen_tokens_507904000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_992000-seen_tokens_507904000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_992000-seen_tokens_507904000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_992000-seen_tokens_507904000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_992000-seen_tokens_507904000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:42:45 | step: 992100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.021003208734328e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.59 | train loss last: 2.98 | consumed tokens: 507955200.0 | grad norm avg: 14.31 | grad norm last: 11.45 | 
2025-12-28T04:42:47 | step: 992200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0208687854174059e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.38 | consumed tokens: 508006400.0 | grad norm avg: 13.89 | grad norm last: 14.93 | 
2025-12-28T04:42:49 | step: 992300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0207347258983646e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.22 | consumed tokens: 508057600.0 | grad norm avg: 14.03 | grad norm last: 13.24 | 
2025-12-28T04:42:51 | step: 992400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0206011211266741e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.44 | consumed tokens: 508108800.0 | grad norm avg: 14.29 | grad norm last: 14.3 | 
2025-12-28T04:42:53 | step: 992500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0204679711023346e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.78 | consumed tokens: 508160000.0 | grad norm avg: 14.31 | grad norm last: 13.95 | 
2025-12-28T04:42:55 | step: 992600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0203351848758757e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.5 | consumed tokens: 508211200.0 | grad norm avg: 14.26 | grad norm last: 14.81 | 
2025-12-28T04:42:57 | step: 992700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0202028533967678e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.38 | consumed tokens: 508262400.0 | grad norm avg: 13.97 | grad norm last: 13.21 | 
2025-12-28T04:42:59 | step: 992800 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 1.0200709766650107e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.36 | consumed tokens: 508313600.0 | grad norm avg: 14.81 | grad norm last: 13.41 | 
2025-12-28T04:43:01 | step: 992900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0199396456300747e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.67 | consumed tokens: 508364800.0 | grad norm avg: 14.93 | grad norm last: 14.97 | 
2025-12-28T04:43:03 | step: 993000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0198086783930194e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.33 | consumed tokens: 508416000.0 | grad norm avg: 14.21 | grad norm last: 13.01 | 
2025-12-28T04:43:05 | step: 993100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0196778930549044e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.47 | train loss last: 3.39 | consumed tokens: 508467200.0 | grad norm avg: 13.48 | grad norm last: 12.37 | 
2025-12-28T04:43:07 | step: 993200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0195478353125509e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.27 | consumed tokens: 508518400.0 | grad norm avg: 14.33 | grad norm last: 12.93 | 
2025-12-28T04:43:09 | step: 993300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.019418141368078e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.56 | consumed tokens: 508569600.0 | grad norm avg: 14.3 | grad norm last: 43.98 | 
2025-12-28T04:43:11 | step: 993400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.019288811221486e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.47 | consumed tokens: 508620800.0 | grad norm avg: 14.37 | grad norm last: 20.54 | 
2025-12-28T04:43:13 | step: 993500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0191598448727746e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.64 | consumed tokens: 508672000.0 | grad norm avg: 14.5 | grad norm last: 13.87 | 
2025-12-28T04:43:15 | step: 993600 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0190316061198246e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.81 | consumed tokens: 508723200.0 | grad norm avg: 14.72 | grad norm last: 13.9 | 
2025-12-28T04:43:17 | step: 993700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.018903549265815e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 2.8 | consumed tokens: 508774400.0 | grad norm avg: 14.2 | grad norm last: 15.43 | 
2025-12-28T04:43:19 | step: 993800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0187759471591562e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.8 | consumed tokens: 508825600.0 | grad norm avg: 14.29 | grad norm last: 11.35 | 
2025-12-28T04:43:21 | step: 993900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0186488907493185e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.46 | train loss last: 3.09 | consumed tokens: 508876800.0 | grad norm avg: 13.97 | grad norm last: 14.18 | 
2025-12-28T04:43:23 | step: 994000 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0185221071878914e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.3 | consumed tokens: 508928000.0 | grad norm avg: 13.66 | grad norm last: 14.1 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_994000-seen_tokens_508928000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_994000-seen_tokens_508928000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_994000-seen_tokens_508928000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_994000-seen_tokens_508928000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_994000-seen_tokens_508928000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_994000-seen_tokens_508928000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_994000-seen_tokens_508928000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_994000-seen_tokens_508928000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:43:25 | step: 994100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0183958693232853e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.86 | consumed tokens: 508979200.0 | grad norm avg: 13.97 | grad norm last: 10.6 | 
2025-12-28T04:43:27 | step: 994200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.01826999525656e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 5.03 | consumed tokens: 509030400.0 | grad norm avg: 14.52 | grad norm last: 20.73 | 
2025-12-28T04:43:29 | step: 994300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0181446668866556e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.46 | train loss last: 3.56 | consumed tokens: 509081600.0 | grad norm avg: 13.75 | grad norm last: 14.27 | 
2025-12-28T04:43:31 | step: 994400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0180196113651618e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.27 | consumed tokens: 509132800.0 | grad norm avg: 14.13 | grad norm last: 12.24 | 
2025-12-28T04:43:34 | step: 994500 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.0178951015404891e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 2.86 | consumed tokens: 509184000.0 | grad norm avg: 14.41 | grad norm last: 13.37 | 
2025-12-28T04:43:36 | step: 994600 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.017770864564227e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.44 | consumed tokens: 509235200.0 | grad norm avg: 14.26 | grad norm last: 14.28 | 
2025-12-28T04:43:38 | step: 994700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.0176471732847858e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.47 | consumed tokens: 509286400.0 | grad norm avg: 14.28 | grad norm last: 11.98 | 
2025-12-28T04:43:40 | step: 994800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0175240277021658e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.62 | consumed tokens: 509337600.0 | grad norm avg: 14.26 | grad norm last: 13.28 | 
2025-12-28T04:43:42 | step: 994900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0174012459174264e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.33 | consumed tokens: 509388800.0 | grad norm avg: 14.49 | grad norm last: 14.32 | 
2025-12-28T04:43:44 | step: 995000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0172788279305678e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.61 | consumed tokens: 509440000.0 | grad norm avg: 14.64 | grad norm last: 13.66 | 
2025-12-28T04:43:46 | step: 995100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.01715686469106e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.45 | consumed tokens: 509491200.0 | grad norm avg: 13.93 | grad norm last: 15.79 | 
2025-12-28T04:43:48 | step: 995200 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0170353561989032e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 4.06 | consumed tokens: 509542400.0 | grad norm avg: 13.71 | grad norm last: 15.88 | 
2025-12-28T04:43:50 | step: 995300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.016914211504627e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.91 | consumed tokens: 509593600.0 | grad norm avg: 14.07 | grad norm last: 14.58 | 
2025-12-28T04:43:52 | step: 995400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.016793612507172e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.22 | consumed tokens: 509644800.0 | grad norm avg: 14.06 | grad norm last: 12.21 | 
2025-12-28T04:43:54 | step: 995500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0166733773075975e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.45 | consumed tokens: 509696000.0 | grad norm avg: 14.29 | grad norm last: 12.18 | 
2025-12-28T04:43:56 | step: 995600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0165535059059039e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.27 | consumed tokens: 509747200.0 | grad norm avg: 14.12 | grad norm last: 16.02 | 
2025-12-28T04:43:58 | step: 995700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0164341802010313e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.3 | consumed tokens: 509798400.0 | grad norm avg: 14.23 | grad norm last: 12.63 | 
2025-12-28T04:44:00 | step: 995800 | train samples/s: 104.9 | train mfu (16-bit): -1.0 | lr mean: 1.0163152182940394e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.59 | consumed tokens: 509849600.0 | grad norm avg: 14.21 | grad norm last: 15.6 | 
2025-12-28T04:44:02 | step: 995900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0161967111343984e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.69 | consumed tokens: 509900800.0 | grad norm avg: 14.24 | grad norm last: 13.81 | 
2025-12-28T04:44:04 | step: 996000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0160786587221082e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.88 | consumed tokens: 509952000.0 | grad norm avg: 14.48 | grad norm last: 16.09 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_996000-seen_tokens_509952000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_996000-seen_tokens_509952000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_996000-seen_tokens_509952000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_996000-seen_tokens_509952000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_996000-seen_tokens_509952000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_996000-seen_tokens_509952000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_996000-seen_tokens_509952000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_996000-seen_tokens_509952000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:44:06 | step: 996100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0159609701076988e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.61 | train loss last: 3.11 | consumed tokens: 510003200.0 | grad norm avg: 14.64 | grad norm last: 13.5 | 
2025-12-28T04:44:08 | step: 996200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0158437362406403e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.46 | train loss last: 3.89 | consumed tokens: 510054400.0 | grad norm avg: 13.58 | grad norm last: 13.81 | 
2025-12-28T04:44:11 | step: 996300 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0157269571209326e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.91 | consumed tokens: 510105600.0 | grad norm avg: 14.4 | grad norm last: 17.06 | 
2025-12-28T04:44:13 | step: 996400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0156106327485759e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.77 | consumed tokens: 510156800.0 | grad norm avg: 14.32 | grad norm last: 14.0 | 
2025-12-28T04:44:15 | step: 996500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0154946721740998e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.47 | train loss last: 3.81 | consumed tokens: 510208000.0 | grad norm avg: 14.01 | grad norm last: 13.62 | 
2025-12-28T04:44:17 | step: 996600 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0153791663469747e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.8 | consumed tokens: 510259200.0 | grad norm avg: 14.35 | grad norm last: 14.31 | 
2025-12-28T04:44:19 | step: 996700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0152641152672004e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.97 | consumed tokens: 510310400.0 | grad norm avg: 14.32 | grad norm last: 13.08 | 
2025-12-28T04:44:21 | step: 996800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.015149518934777e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.05 | consumed tokens: 510361600.0 | grad norm avg: 13.99 | grad norm last: 12.28 | 
2025-12-28T04:44:23 | step: 996900 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0150352864002343e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 2.47 | consumed tokens: 510412800.0 | grad norm avg: 13.95 | grad norm last: 18.56 | 
2025-12-28T04:44:25 | step: 997000 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0149215086130425e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.03 | consumed tokens: 510464000.0 | grad norm avg: 14.11 | grad norm last: 11.25 | 
2025-12-28T04:44:27 | step: 997100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0148081855732016e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.52 | consumed tokens: 510515200.0 | grad norm avg: 13.9 | grad norm last: 13.8 | 
2025-12-28T04:44:29 | step: 997200 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0146953172807116e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.55 | consumed tokens: 510566400.0 | grad norm avg: 14.11 | grad norm last: 12.71 | 
2025-12-28T04:44:31 | step: 997300 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0145828127861023e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.09 | consumed tokens: 510617600.0 | grad norm avg: 14.63 | grad norm last: 19.51 | 
2025-12-28T04:44:33 | step: 997400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0144707630388439e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 5.03 | consumed tokens: 510668800.0 | grad norm avg: 14.21 | grad norm last: 19.76 | 
2025-12-28T04:44:35 | step: 997500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0143591680389363e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.45 | train loss last: 3.11 | consumed tokens: 510720000.0 | grad norm avg: 14.01 | grad norm last: 12.24 | 
2025-12-28T04:44:37 | step: 997600 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 1.0142480277863797e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.11 | consumed tokens: 510771200.0 | grad norm avg: 14.16 | grad norm last: 14.29 | 
2025-12-28T04:44:39 | step: 997700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0141372513317037e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.75 | consumed tokens: 510822400.0 | grad norm avg: 13.96 | grad norm last: 15.87 | 
2025-12-28T04:44:41 | step: 997800 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0140269296243787e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.73 | consumed tokens: 510873600.0 | grad norm avg: 14.23 | grad norm last: 14.15 | 
2025-12-28T04:44:43 | step: 997900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0139170626644045e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.46 | train loss last: 3.48 | consumed tokens: 510924800.0 | grad norm avg: 13.7 | grad norm last: 11.98 | 
2025-12-28T04:44:45 | step: 998000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 1.013807559502311e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.75 | consumed tokens: 510976000.0 | grad norm avg: 14.16 | grad norm last: 13.35 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_998000-seen_tokens_510976000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_998000-seen_tokens_510976000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_998000-seen_tokens_510976000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_998000-seen_tokens_510976000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_998000-seen_tokens_510976000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_998000-seen_tokens_510976000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_998000-seen_tokens_510976000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_998000-seen_tokens_510976000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:44:47 | step: 998100 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0136986020370387e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.51 | train loss last: 4.25 | consumed tokens: 511027200.0 | grad norm avg: 14.36 | grad norm last: 14.98 | 
2025-12-28T04:44:49 | step: 998200 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 1.013590008369647e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.34 | consumed tokens: 511078400.0 | grad norm avg: 14.7 | grad norm last: 17.13 | 
2025-12-28T04:44:51 | step: 998300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0134818694496062e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.47 | consumed tokens: 511129600.0 | grad norm avg: 14.41 | grad norm last: 12.45 | 
2025-12-28T04:44:53 | step: 998400 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 1.013374094327446e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.23 | consumed tokens: 511180800.0 | grad norm avg: 14.09 | grad norm last: 11.37 | 
2025-12-28T04:44:55 | step: 998500 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0132667739526369e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.22 | consumed tokens: 511232000.0 | grad norm avg: 14.17 | grad norm last: 12.23 | 
2025-12-28T04:44:57 | step: 998600 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0131599083251785e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.36 | consumed tokens: 511283200.0 | grad norm avg: 13.82 | grad norm last: 13.95 | 
2025-12-28T04:44:59 | step: 998700 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 1.0130534974450711e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.66 | consumed tokens: 511334400.0 | grad norm avg: 14.82 | grad norm last: 14.6 | 
2025-12-28T04:45:01 | step: 998800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0129475413123146e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 2.97 | consumed tokens: 511385600.0 | grad norm avg: 15.13 | grad norm last: 12.85 | 
2025-12-28T04:45:03 | step: 998900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0128419489774387e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.19 | consumed tokens: 511436800.0 | grad norm avg: 13.74 | grad norm last: 15.78 | 
2025-12-28T04:45:05 | step: 999000 | train samples/s: 107.1 | train mfu (16-bit): -1.0 | lr mean: 1.0127368113899138e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.45 | consumed tokens: 511488000.0 | grad norm avg: 14.87 | grad norm last: 13.34 | 
2025-12-28T04:45:07 | step: 999100 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0126321285497397e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 4.16 | consumed tokens: 511539200.0 | grad norm avg: 14.31 | grad norm last: 12.98 | 
2025-12-28T04:45:09 | step: 999200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0125278095074464e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.55 | consumed tokens: 511590400.0 | grad norm avg: 14.17 | grad norm last: 12.86 | 
2025-12-28T04:45:11 | step: 999300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0124239452125039e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.09 | consumed tokens: 511641600.0 | grad norm avg: 13.82 | grad norm last: 14.57 | 
2025-12-28T04:45:13 | step: 999400 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0123205356649123e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.38 | consumed tokens: 511692800.0 | grad norm avg: 14.26 | grad norm last: 14.07 | 
2025-12-28T04:45:15 | step: 999500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0122175808646716e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.75 | consumed tokens: 511744000.0 | grad norm avg: 14.0 | grad norm last: 12.64 | 
2025-12-28T04:45:18 | step: 999600 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0121149898623116e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.86 | consumed tokens: 511795200.0 | grad norm avg: 14.22 | grad norm last: 15.03 | 
2025-12-28T04:45:20 | step: 999700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0120129445567727e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.5 | consumed tokens: 511846400.0 | grad norm avg: 14.38 | grad norm last: 17.29 | 
2025-12-28T04:45:22 | step: 999800 | train samples/s: 105.0 | train mfu (16-bit): -1.0 | lr mean: 1.0119112630491145e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.75 | consumed tokens: 511897600.0 | grad norm avg: 14.52 | grad norm last: 31.34 | 
2025-12-28T04:45:24 | step: 999900 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.011809945339337e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.47 | consumed tokens: 511948800.0 | grad norm avg: 14.26 | grad norm last: 12.94 | 
2025-12-28T04:45:26 | step: 1000000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.0117091733263806e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.78 | consumed tokens: 512000000.0 | grad norm avg: 14.87 | grad norm last: 25.23 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1000000-seen_tokens_512000000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1000000-seen_tokens_512000000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1000000-seen_tokens_512000000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1000000-seen_tokens_512000000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1000000-seen_tokens_512000000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1000000-seen_tokens_512000000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1000000-seen_tokens_512000000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1000000-seen_tokens_512000000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:45:28 | step: 1000100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0116087651113048e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.58 | train loss last: 3.31 | consumed tokens: 512051200.0 | grad norm avg: 14.7 | grad norm last: 13.02 | 
2025-12-28T04:45:30 | step: 1000200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.01150881164358e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.61 | train loss last: 3.03 | consumed tokens: 512102400.0 | grad norm avg: 14.39 | grad norm last: 11.88 | 
2025-12-28T04:45:32 | step: 1000300 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.011409312923206e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.36 | consumed tokens: 512153600.0 | grad norm avg: 14.28 | grad norm last: 12.9 | 
2025-12-28T04:45:34 | step: 1000400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.0113101780007128e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 2.67 | consumed tokens: 512204800.0 | grad norm avg: 14.16 | grad norm last: 12.2 | 
2025-12-28T04:45:36 | step: 1000500 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.0112114978255704e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.92 | consumed tokens: 512256000.0 | grad norm avg: 14.41 | grad norm last: 14.64 | 
2025-12-28T04:45:38 | step: 1000600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.011113272397779e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 2.97 | consumed tokens: 512307200.0 | grad norm avg: 14.36 | grad norm last: 12.14 | 
2025-12-28T04:45:40 | step: 1000700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0110155017173383e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.03 | consumed tokens: 512358400.0 | grad norm avg: 14.06 | grad norm last: 12.38 | 
2025-12-28T04:45:42 | step: 1000800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0109180948347785e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.88 | consumed tokens: 512409600.0 | grad norm avg: 14.07 | grad norm last: 13.57 | 
2025-12-28T04:45:44 | step: 1000900 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0108211426995695e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.03 | consumed tokens: 512460800.0 | grad norm avg: 14.67 | grad norm last: 13.09 | 
2025-12-28T04:45:46 | step: 1001000 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.0107246453117114e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.98 | consumed tokens: 512512000.0 | grad norm avg: 14.61 | grad norm last: 15.91 | 
2025-12-28T04:45:48 | step: 1001100 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0106286026712041e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.89 | consumed tokens: 512563200.0 | grad norm avg: 14.34 | grad norm last: 12.75 | 
2025-12-28T04:45:50 | step: 1001200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0105329238285776e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.86 | consumed tokens: 512614400.0 | grad norm avg: 14.21 | grad norm last: 15.55 | 
2025-12-28T04:45:53 | step: 1001300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.010437699733302e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.84 | consumed tokens: 512665600.0 | grad norm avg: 14.7 | grad norm last: 15.63 | 
2025-12-28T04:45:55 | step: 1001400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0103429303853773e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.38 | consumed tokens: 512716800.0 | grad norm avg: 14.13 | grad norm last: 13.22 | 
2025-12-28T04:45:57 | step: 1001500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0102486157848034e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.16 | consumed tokens: 512768000.0 | grad norm avg: 14.31 | grad norm last: 12.35 | 
2025-12-28T04:45:59 | step: 1001600 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.0101546649821103e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.02 | consumed tokens: 512819200.0 | grad norm avg: 14.47 | grad norm last: 14.96 | 
2025-12-28T04:46:01 | step: 1001700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.0100612598762382e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.28 | consumed tokens: 512870400.0 | grad norm avg: 14.1 | grad norm last: 13.72 | 
2025-12-28T04:46:03 | step: 1001800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0099681276187766e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.03 | consumed tokens: 512921600.0 | grad norm avg: 14.2 | grad norm last: 14.31 | 
2025-12-28T04:46:05 | step: 1001900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0098755410581362e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.62 | consumed tokens: 512972800.0 | grad norm avg: 14.43 | grad norm last: 15.67 | 
2025-12-28T04:46:07 | step: 1002000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0097833182953764e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.42 | consumed tokens: 513024000.0 | grad norm avg: 13.89 | grad norm last: 13.15 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1002000-seen_tokens_513024000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1002000-seen_tokens_513024000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1002000-seen_tokens_513024000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1002000-seen_tokens_513024000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1002000-seen_tokens_513024000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1002000-seen_tokens_513024000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1002000-seen_tokens_513024000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1002000-seen_tokens_513024000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:46:09 | step: 1002100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0096916412294377e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 3.77 | consumed tokens: 513075200.0 | grad norm avg: 14.56 | grad norm last: 16.74 | 
2025-12-28T04:46:11 | step: 1002200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0096002370119095e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.45 | consumed tokens: 513126400.0 | grad norm avg: 14.28 | grad norm last: 15.63 | 
2025-12-28T04:46:13 | step: 1002300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0095093784912024e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.09 | consumed tokens: 513177600.0 | grad norm avg: 14.12 | grad norm last: 12.26 | 
2025-12-28T04:46:15 | step: 1002400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0094189747178461e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.56 | consumed tokens: 513228800.0 | grad norm avg: 14.46 | grad norm last: 15.23 | 
2025-12-28T04:46:17 | step: 1002500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0093289347423706e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 4.06 | consumed tokens: 513280000.0 | grad norm avg: 14.05 | grad norm last: 15.67 | 
2025-12-28T04:46:19 | step: 1002600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.009239349514246e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.78 | consumed tokens: 513331200.0 | grad norm avg: 14.0 | grad norm last: 14.32 | 
2025-12-28T04:46:21 | step: 1002700 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.009150128084002e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.92 | consumed tokens: 513382400.0 | grad norm avg: 14.35 | grad norm last: 11.23 | 
2025-12-28T04:46:23 | step: 1002800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0090614523505792e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 4.12 | consumed tokens: 513433600.0 | grad norm avg: 14.21 | grad norm last: 16.07 | 
2025-12-28T04:46:25 | step: 1002900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.008973140415037e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.56 | consumed tokens: 513484800.0 | grad norm avg: 14.53 | grad norm last: 16.31 | 
2025-12-28T04:46:27 | step: 1003000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0088851922773756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.8 | consumed tokens: 513536000.0 | grad norm avg: 13.93 | grad norm last: 13.04 | 
2025-12-28T04:46:29 | step: 1003100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0087977898365352e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.44 | consumed tokens: 513587200.0 | grad norm avg: 14.9 | grad norm last: 15.22 | 
2025-12-28T04:46:31 | step: 1003200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0087107511935756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.81 | consumed tokens: 513638400.0 | grad norm avg: 14.42 | grad norm last: 17.33 | 
2025-12-28T04:46:33 | step: 1003300 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.008624258247437e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 2.98 | consumed tokens: 513689600.0 | grad norm avg: 14.37 | grad norm last: 12.78 | 
2025-12-28T04:46:35 | step: 1003400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0085380381497089e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.02 | consumed tokens: 513740800.0 | grad norm avg: 14.29 | grad norm last: 13.51 | 
2025-12-28T04:46:37 | step: 1003500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0084523637488019e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 4.19 | consumed tokens: 513792000.0 | grad norm avg: 14.25 | grad norm last: 15.73 | 
2025-12-28T04:46:39 | step: 1003600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0083670531457756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.36 | consumed tokens: 513843200.0 | grad norm avg: 14.58 | grad norm last: 12.97 | 
2025-12-28T04:46:41 | step: 1003700 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0082822882395703e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 5.47 | consumed tokens: 513894400.0 | grad norm avg: 14.84 | grad norm last: 26.12 | 
2025-12-28T04:46:43 | step: 1003800 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0081977961817756e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.86 | consumed tokens: 513945600.0 | grad norm avg: 13.78 | grad norm last: 14.81 | 
2025-12-28T04:46:45 | step: 1003900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.008113849820802e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 4.34 | consumed tokens: 513996800.0 | grad norm avg: 14.96 | grad norm last: 15.09 | 
2025-12-28T04:46:47 | step: 1004000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.008030267257709e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.53 | consumed tokens: 514048000.0 | grad norm avg: 14.69 | grad norm last: 15.25 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1004000-seen_tokens_514048000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1004000-seen_tokens_514048000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1004000-seen_tokens_514048000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1004000-seen_tokens_514048000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1004000-seen_tokens_514048000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1004000-seen_tokens_514048000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1004000-seen_tokens_514048000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1004000-seen_tokens_514048000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:46:50 | step: 1004100 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0079472303914372e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.22 | consumed tokens: 514099200.0 | grad norm avg: 14.23 | grad norm last: 14.55 | 
2025-12-28T04:46:52 | step: 1004200 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0078644663735759e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.44 | consumed tokens: 514150400.0 | grad norm avg: 14.21 | grad norm last: 12.74 | 
2025-12-28T04:46:54 | step: 1004300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0077822480525356e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 2.7 | consumed tokens: 514201600.0 | grad norm avg: 14.37 | grad norm last: 13.78 | 
2025-12-28T04:46:56 | step: 1004400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.007700393529376e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.22 | consumed tokens: 514252800.0 | grad norm avg: 14.43 | grad norm last: 12.6 | 
2025-12-28T04:46:58 | step: 1004500 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0076189937535673e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.33 | consumed tokens: 514304000.0 | grad norm avg: 14.2 | grad norm last: 14.21 | 
2025-12-28T04:47:00 | step: 1004600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0075380487251095e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.72 | consumed tokens: 514355200.0 | grad norm avg: 14.44 | grad norm last: 12.87 | 
2025-12-28T04:47:02 | step: 1004700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0074575584440026e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 2.86 | consumed tokens: 514406400.0 | grad norm avg: 14.45 | grad norm last: 17.41 | 
2025-12-28T04:47:04 | step: 1004800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0073774319607764e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 2.98 | consumed tokens: 514457600.0 | grad norm avg: 13.98 | grad norm last: 14.84 | 
2025-12-28T04:47:06 | step: 1004900 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0072977602249011e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.28 | consumed tokens: 514508800.0 | grad norm avg: 14.49 | grad norm last: 14.03 | 
2025-12-28T04:47:08 | step: 1005000 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.0072185432363767e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.8 | consumed tokens: 514560000.0 | grad norm avg: 14.76 | grad norm last: 14.02 | 
2025-12-28T04:47:10 | step: 1005100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0071397809952032e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.16 | consumed tokens: 514611200.0 | grad norm avg: 14.31 | grad norm last: 13.02 | 
2025-12-28T04:47:12 | step: 1005200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0070613825519104e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.69 | consumed tokens: 514662400.0 | grad norm avg: 14.1 | grad norm last: 15.46 | 
2025-12-28T04:47:14 | step: 1005300 | train samples/s: 97.9 | train mfu (16-bit): -1.0 | lr mean: 1.0069834388559684e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.45 | train loss last: 3.2 | consumed tokens: 514713600.0 | grad norm avg: 14.16 | grad norm last: 14.18 | 
2025-12-28T04:47:16 | step: 1005400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0069059499073774e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.66 | consumed tokens: 514764800.0 | grad norm avg: 14.43 | grad norm last: 16.67 | 
2025-12-28T04:47:18 | step: 1005500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0068289157061372e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.12 | consumed tokens: 514816000.0 | grad norm avg: 14.17 | grad norm last: 12.29 | 
2025-12-28T04:47:20 | step: 1005600 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.0067522453027777e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.75 | consumed tokens: 514867200.0 | grad norm avg: 14.73 | grad norm last: 13.97 | 
2025-12-28T04:47:22 | step: 1005700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0066760296467692e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.62 | consumed tokens: 514918400.0 | grad norm avg: 14.26 | grad norm last: 13.83 | 
2025-12-28T04:47:25 | step: 1005800 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0066002687381115e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.3 | consumed tokens: 514969600.0 | grad norm avg: 14.85 | grad norm last: 13.05 | 
2025-12-28T04:47:27 | step: 1005900 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0065249625768047e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.31 | consumed tokens: 515020800.0 | grad norm avg: 14.21 | grad norm last: 12.68 | 
2025-12-28T04:47:29 | step: 1006000 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0064500202133786e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.3 | consumed tokens: 515072000.0 | grad norm avg: 14.47 | grad norm last: 14.43 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1006000-seen_tokens_515072000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1006000-seen_tokens_515072000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1006000-seen_tokens_515072000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1006000-seen_tokens_515072000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1006000-seen_tokens_515072000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1006000-seen_tokens_515072000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1006000-seen_tokens_515072000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1006000-seen_tokens_515072000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:47:31 | step: 1006100 | train samples/s: 105.1 | train mfu (16-bit): -1.0 | lr mean: 1.0063755325973034e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.16 | consumed tokens: 515123200.0 | grad norm avg: 14.12 | grad norm last: 13.85 | 
2025-12-28T04:47:33 | step: 1006200 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.006301499728579e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.66 | consumed tokens: 515174400.0 | grad norm avg: 14.46 | grad norm last: 12.95 | 
2025-12-28T04:47:35 | step: 1006300 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.0062279216072056e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 5.09 | consumed tokens: 515225600.0 | grad norm avg: 14.49 | grad norm last: 16.57 | 
2025-12-28T04:47:37 | step: 1006400 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.006154707283713e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.19 | consumed tokens: 515276800.0 | grad norm avg: 14.74 | grad norm last: 12.75 | 
2025-12-28T04:47:39 | step: 1006500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.0060820386570413e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.08 | consumed tokens: 515328000.0 | grad norm avg: 14.27 | grad norm last: 17.12 | 
2025-12-28T04:47:41 | step: 1006600 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0060096428787801e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.69 | consumed tokens: 515379200.0 | grad norm avg: 14.2 | grad norm last: 12.44 | 
2025-12-28T04:47:43 | step: 1006700 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.00593779279734e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.16 | consumed tokens: 515430400.0 | grad norm avg: 14.48 | grad norm last: 14.15 | 
2025-12-28T04:47:45 | step: 1006800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0058663065137807e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.75 | train loss last: 3.09 | consumed tokens: 515481600.0 | grad norm avg: 14.96 | grad norm last: 13.44 | 
2025-12-28T04:47:47 | step: 1006900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0057953659270424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.06 | consumed tokens: 515532800.0 | grad norm avg: 14.4 | grad norm last: 13.24 | 
2025-12-28T04:47:49 | step: 1007000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0057246981887147e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.95 | consumed tokens: 515584000.0 | grad norm avg: 14.78 | grad norm last: 18.25 | 
2025-12-28T04:47:51 | step: 1007100 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.005654576147208e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.97 | consumed tokens: 515635200.0 | grad norm avg: 14.49 | grad norm last: 15.3 | 
2025-12-28T04:47:53 | step: 1007200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0055849088530522e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.77 | consumed tokens: 515686400.0 | grad norm avg: 14.49 | grad norm last: 12.83 | 
2025-12-28T04:47:55 | step: 1007300 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0055156053567771e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.44 | consumed tokens: 515737600.0 | grad norm avg: 14.6 | grad norm last: 18.5 | 
2025-12-28T04:47:57 | step: 1007400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0054467566078529e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.52 | consumed tokens: 515788800.0 | grad norm avg: 14.38 | grad norm last: 13.41 | 
2025-12-28T04:48:00 | step: 1007500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0053782716568094e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.81 | consumed tokens: 515840000.0 | grad norm avg: 14.25 | grad norm last: 14.12 | 
2025-12-28T04:48:02 | step: 1007600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.005310332402587e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.28 | consumed tokens: 515891200.0 | grad norm avg: 14.43 | grad norm last: 12.94 | 
2025-12-28T04:48:04 | step: 1007700 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0052427569462452e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 4.12 | consumed tokens: 515942400.0 | grad norm avg: 14.33 | grad norm last: 16.3 | 
2025-12-28T04:48:06 | step: 1007800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0051756362372544e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.3 | consumed tokens: 515993600.0 | grad norm avg: 14.24 | grad norm last: 12.51 | 
2025-12-28T04:48:08 | step: 1007900 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0051088793261442e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.61 | consumed tokens: 516044800.0 | grad norm avg: 14.2 | grad norm last: 15.3 | 
2025-12-28T04:48:10 | step: 1008000 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0050426681118552e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.31 | consumed tokens: 516096000.0 | grad norm avg: 14.35 | grad norm last: 15.38 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1008000-seen_tokens_516096000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1008000-seen_tokens_516096000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1008000-seen_tokens_516096000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1008000-seen_tokens_516096000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1008000-seen_tokens_516096000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1008000-seen_tokens_516096000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1008000-seen_tokens_516096000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1008000-seen_tokens_516096000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:48:12 | step: 1008100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0049768206954468e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.53 | train loss last: 3.39 | consumed tokens: 516147200.0 | grad norm avg: 14.17 | grad norm last: 12.86 | 
2025-12-28T04:48:14 | step: 1008200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0049114280263893e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.61 | consumed tokens: 516198400.0 | grad norm avg: 14.47 | grad norm last: 13.75 | 
2025-12-28T04:48:16 | step: 1008300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0048464901046827e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.58 | consumed tokens: 516249600.0 | grad norm avg: 14.44 | grad norm last: 14.39 | 
2025-12-28T04:48:18 | step: 1008400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0047819159808569e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.92 | consumed tokens: 516300800.0 | grad norm avg: 14.65 | grad norm last: 16.31 | 
2025-12-28T04:48:20 | step: 1008500 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0047177966043819e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.03 | consumed tokens: 516352000.0 | grad norm avg: 14.38 | grad norm last: 28.74 | 
2025-12-28T04:48:22 | step: 1008600 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0046541319752578e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 4.0 | consumed tokens: 516403200.0 | grad norm avg: 14.68 | grad norm last: 15.29 | 
2025-12-28T04:48:24 | step: 1008700 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0045909220934846e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.12 | consumed tokens: 516454400.0 | grad norm avg: 15.05 | grad norm last: 13.37 | 
2025-12-28T04:48:26 | step: 1008800 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.004528076009592e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.73 | consumed tokens: 516505600.0 | grad norm avg: 14.29 | grad norm last: 11.05 | 
2025-12-28T04:48:28 | step: 1008900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0044657756225206e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.64 | consumed tokens: 516556800.0 | grad norm avg: 14.42 | grad norm last: 12.23 | 
2025-12-28T04:48:30 | step: 1009000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0044038390333299e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.27 | consumed tokens: 516608000.0 | grad norm avg: 14.48 | grad norm last: 13.15 | 
2025-12-28T04:48:32 | step: 1009100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0043422662420198e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.33 | consumed tokens: 516659200.0 | grad norm avg: 14.14 | grad norm last: 14.15 | 
2025-12-28T04:48:34 | step: 1009200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0042812391475309e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 4.53 | consumed tokens: 516710400.0 | grad norm avg: 14.39 | grad norm last: 41.79 | 
2025-12-28T04:48:36 | step: 1009300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0042205758509226e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.45 | consumed tokens: 516761600.0 | grad norm avg: 14.51 | grad norm last: 14.54 | 
2025-12-28T04:48:38 | step: 1009400 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0041603673016652e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.42 | consumed tokens: 516812800.0 | grad norm avg: 14.27 | grad norm last: 14.46 | 
2025-12-28T04:48:40 | step: 1009500 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0041006134997588e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.86 | consumed tokens: 516864000.0 | grad norm avg: 14.25 | grad norm last: 13.91 | 
2025-12-28T04:48:42 | step: 1009600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.004041223495733e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.97 | consumed tokens: 516915200.0 | grad norm avg: 14.13 | grad norm last: 13.2 | 
2025-12-28T04:48:44 | step: 1009700 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0039822882390581e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 2.52 | consumed tokens: 516966400.0 | grad norm avg: 14.27 | grad norm last: 10.99 | 
2025-12-28T04:48:46 | step: 1009800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0039238077297341e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.34 | consumed tokens: 517017600.0 | grad norm avg: 14.45 | grad norm last: 11.86 | 
2025-12-28T04:48:48 | step: 1009900 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.003865781967761e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.59 | consumed tokens: 517068800.0 | grad norm avg: 14.46 | grad norm last: 14.53 | 
2025-12-28T04:48:50 | step: 1010000 | train samples/s: 107.0 | train mfu (16-bit): -1.0 | lr mean: 1.0038082109531388e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.0 | consumed tokens: 517120000.0 | grad norm avg: 14.25 | grad norm last: 12.56 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1010000-seen_tokens_517120000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1010000-seen_tokens_517120000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1010000-seen_tokens_517120000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1010000-seen_tokens_517120000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1010000-seen_tokens_517120000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1010000-seen_tokens_517120000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1010000-seen_tokens_517120000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1010000-seen_tokens_517120000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:48:53 | step: 1010100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0037510037363973e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.6 | train loss last: 2.91 | consumed tokens: 517171200.0 | grad norm avg: 14.4 | grad norm last: 11.83 | 
2025-12-28T04:48:55 | step: 1010200 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0036942512670066e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.54 | train loss last: 3.75 | consumed tokens: 517222400.0 | grad norm avg: 14.87 | grad norm last: 13.92 | 
2025-12-28T04:48:57 | step: 1010300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0036379535449669e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 2.81 | consumed tokens: 517273600.0 | grad norm avg: 14.51 | grad norm last: 12.74 | 
2025-12-28T04:48:59 | step: 1010400 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0035820196208078e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.78 | consumed tokens: 517324800.0 | grad norm avg: 14.67 | grad norm last: 15.54 | 
2025-12-28T04:49:01 | step: 1010500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0035265404439997e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.61 | consumed tokens: 517376000.0 | grad norm avg: 14.56 | grad norm last: 13.43 | 
2025-12-28T04:49:03 | step: 1010600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0034715160145424e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.34 | consumed tokens: 517427200.0 | grad norm avg: 15.06 | grad norm last: 12.89 | 
2025-12-28T04:49:05 | step: 1010700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.003416946332436e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.94 | consumed tokens: 517478400.0 | grad norm avg: 14.55 | grad norm last: 18.25 | 
2025-12-28T04:49:07 | step: 1010800 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0033628313976806e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.28 | consumed tokens: 517529600.0 | grad norm avg: 14.81 | grad norm last: 16.08 | 
2025-12-28T04:49:09 | step: 1010900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0033090802608058e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.44 | consumed tokens: 517580800.0 | grad norm avg: 14.85 | grad norm last: 18.67 | 
2025-12-28T04:49:11 | step: 1011000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0032557838712819e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.61 | consumed tokens: 517632000.0 | grad norm avg: 14.11 | grad norm last: 15.48 | 
2025-12-28T04:49:13 | step: 1011100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0032029422291089e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.91 | consumed tokens: 517683200.0 | grad norm avg: 14.62 | grad norm last: 13.76 | 
2025-12-28T04:49:15 | step: 1011200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0031505553342868e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.45 | consumed tokens: 517734400.0 | grad norm avg: 14.34 | grad norm last: 12.64 | 
2025-12-28T04:49:17 | step: 1011300 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.0030985322373454e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 4.19 | consumed tokens: 517785600.0 | grad norm avg: 14.39 | grad norm last: 15.19 | 
2025-12-28T04:49:19 | step: 1011400 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0030469638877548e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.89 | consumed tokens: 517836800.0 | grad norm avg: 14.58 | grad norm last: 12.94 | 
2025-12-28T04:49:21 | step: 1011500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0029958502855152e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.47 | train loss last: 4.06 | consumed tokens: 517888000.0 | grad norm avg: 14.41 | grad norm last: 14.17 | 
2025-12-28T04:49:23 | step: 1011600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0029451004811563e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.17 | consumed tokens: 517939200.0 | grad norm avg: 14.68 | grad norm last: 12.25 | 
2025-12-28T04:49:25 | step: 1011700 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0028948963736184e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.64 | consumed tokens: 517990400.0 | grad norm avg: 14.61 | grad norm last: 16.89 | 
2025-12-28T04:49:27 | step: 1011800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0028450560639612e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.17 | consumed tokens: 518041600.0 | grad norm avg: 14.11 | grad norm last: 13.23 | 
2025-12-28T04:49:29 | step: 1011900 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.002795670501655e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.77 | consumed tokens: 518092800.0 | grad norm avg: 14.54 | grad norm last: 14.06 | 
2025-12-28T04:49:31 | step: 1012000 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0027466487372294e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 4.16 | consumed tokens: 518144000.0 | grad norm avg: 14.55 | grad norm last: 16.06 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1012000-seen_tokens_518144000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1012000-seen_tokens_518144000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1012000-seen_tokens_518144000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1012000-seen_tokens_518144000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1012000-seen_tokens_518144000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1012000-seen_tokens_518144000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1012000-seen_tokens_518144000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1012000-seen_tokens_518144000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:49:34 | step: 1012100 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0026981726696249e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.57 | train loss last: 3.83 | consumed tokens: 518195200.0 | grad norm avg: 14.15 | grad norm last: 12.58 | 
2025-12-28T04:49:36 | step: 1012200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0026500603999011e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.16 | consumed tokens: 518246400.0 | grad norm avg: 14.37 | grad norm last: 12.72 | 
2025-12-28T04:49:38 | step: 1012300 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.002602311928058e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.43 | train loss last: 3.25 | consumed tokens: 518297600.0 | grad norm avg: 13.88 | grad norm last: 12.93 | 
2025-12-28T04:49:40 | step: 1012400 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.002555109153036e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.19 | consumed tokens: 518348800.0 | grad norm avg: 15.7 | grad norm last: 13.54 | 
2025-12-28T04:49:42 | step: 1012500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0025082701758947e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.09 | consumed tokens: 518400000.0 | grad norm avg: 17.05 | grad norm last: 30.81 | 
2025-12-28T04:49:44 | step: 1012600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0024619768955745e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 2.59 | consumed tokens: 518451200.0 | grad norm avg: 14.65 | grad norm last: 12.8 | 
2025-12-28T04:49:46 | step: 1012700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.002416047413135e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.11 | consumed tokens: 518502400.0 | grad norm avg: 14.11 | grad norm last: 12.89 | 
2025-12-28T04:49:48 | step: 1012800 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0023704817285761e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.38 | consumed tokens: 518553600.0 | grad norm avg: 14.4 | grad norm last: 12.48 | 
2025-12-28T04:49:50 | step: 1012900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0023254617408384e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.56 | consumed tokens: 518604800.0 | grad norm avg: 14.58 | grad norm last: 13.11 | 
2025-12-28T04:49:52 | step: 1013000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0022808055509813e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 2.84 | consumed tokens: 518656000.0 | grad norm avg: 14.5 | grad norm last: 13.22 | 
2025-12-28T04:49:54 | step: 1013100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0022366041084751e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 2.69 | consumed tokens: 518707200.0 | grad norm avg: 14.23 | grad norm last: 14.55 | 
2025-12-28T04:49:56 | step: 1013200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0021927664638497e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.95 | consumed tokens: 518758400.0 | grad norm avg: 14.54 | grad norm last: 14.12 | 
2025-12-28T04:49:58 | step: 1013300 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0021494745160453e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.44 | train loss last: 4.31 | consumed tokens: 518809600.0 | grad norm avg: 14.1 | grad norm last: 13.08 | 
2025-12-28T04:50:00 | step: 1013400 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0021065463661216e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.36 | consumed tokens: 518860800.0 | grad norm avg: 14.12 | grad norm last: 13.44 | 
2025-12-28T04:50:02 | step: 1013500 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0020640729635488e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.78 | consumed tokens: 518912000.0 | grad norm avg: 14.77 | grad norm last: 12.37 | 
2025-12-28T04:50:04 | step: 1013600 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0020220543083269e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.67 | consumed tokens: 518963200.0 | grad norm avg: 14.13 | grad norm last: 13.08 | 
2025-12-28T04:50:06 | step: 1013700 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0019803994509857e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.19 | consumed tokens: 519014400.0 | grad norm avg: 14.67 | grad norm last: 13.91 | 
2025-12-28T04:50:08 | step: 1013800 | train samples/s: 107.2 | train mfu (16-bit): -1.0 | lr mean: 1.0019391993409954e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.02 | consumed tokens: 519065600.0 | grad norm avg: 14.56 | grad norm last: 11.9 | 
2025-12-28T04:50:10 | step: 1013900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.001898453978356e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.89 | consumed tokens: 519116800.0 | grad norm avg: 15.06 | grad norm last: 15.59 | 
2025-12-28T04:50:12 | step: 1014000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0018581633630674e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.73 | consumed tokens: 519168000.0 | grad norm avg: 14.61 | grad norm last: 13.94 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1014000-seen_tokens_519168000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1014000-seen_tokens_519168000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1014000-seen_tokens_519168000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1014000-seen_tokens_519168000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1014000-seen_tokens_519168000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1014000-seen_tokens_519168000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1014000-seen_tokens_519168000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1014000-seen_tokens_519168000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:50:15 | step: 1014100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0018182365456596e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.02 | consumed tokens: 519219200.0 | grad norm avg: 14.48 | grad norm last: 13.85 | 
2025-12-28T04:50:17 | step: 1014200 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0017788554250728e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.33 | consumed tokens: 519270400.0 | grad norm avg: 14.42 | grad norm last: 14.45 | 
2025-12-28T04:50:19 | step: 1014300 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0017398381023668e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.38 | consumed tokens: 519321600.0 | grad norm avg: 14.24 | grad norm last: 16.57 | 
2025-12-28T04:50:21 | step: 1014400 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0017011845775414e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.72 | consumed tokens: 519372800.0 | grad norm avg: 14.59 | grad norm last: 11.83 | 
2025-12-28T04:50:23 | step: 1014500 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0016630767495371e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.88 | consumed tokens: 519424000.0 | grad norm avg: 14.8 | grad norm last: 16.19 | 
2025-12-28T04:50:25 | step: 1014600 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0016253327194136e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.44 | consumed tokens: 519475200.0 | grad norm avg: 14.41 | grad norm last: 16.01 | 
2025-12-28T04:50:27 | step: 1014700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0015880434366409e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 2.58 | consumed tokens: 519526400.0 | grad norm avg: 14.69 | grad norm last: 13.23 | 
2025-12-28T04:50:29 | step: 1014800 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.001551208901219e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.38 | consumed tokens: 519577600.0 | grad norm avg: 14.26 | grad norm last: 13.8 | 
2025-12-28T04:50:31 | step: 1014900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.001514738163678e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.45 | consumed tokens: 519628800.0 | grad norm avg: 14.54 | grad norm last: 13.13 | 
2025-12-28T04:50:33 | step: 1015000 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.001478813122958e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.36 | consumed tokens: 519680000.0 | grad norm avg: 14.58 | grad norm last: 13.38 | 
2025-12-28T04:50:35 | step: 1015100 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0014432518801186e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.64 | consumed tokens: 519731200.0 | grad norm avg: 14.32 | grad norm last: 15.53 | 
2025-12-28T04:50:37 | step: 1015200 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0014081453846302e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.91 | consumed tokens: 519782400.0 | grad norm avg: 14.91 | grad norm last: 11.72 | 
2025-12-28T04:50:39 | step: 1015300 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0013734026870225e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 3.06 | consumed tokens: 519833600.0 | grad norm avg: 14.59 | grad norm last: 11.92 | 
2025-12-28T04:50:41 | step: 1015400 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0013391147367656e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 4.09 | consumed tokens: 519884800.0 | grad norm avg: 14.65 | grad norm last: 13.63 | 
2025-12-28T04:50:43 | step: 1015500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0013052815338597e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.44 | consumed tokens: 519936000.0 | grad norm avg: 14.73 | grad norm last: 12.67 | 
2025-12-28T04:50:45 | step: 1015600 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0012719030783046e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.68 | train loss last: 3.36 | consumed tokens: 519987200.0 | grad norm avg: 15.5 | grad norm last: 14.55 | 
2025-12-28T04:50:47 | step: 1015700 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0012389793701004e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 4.31 | consumed tokens: 520038400.0 | grad norm avg: 14.13 | grad norm last: 16.93 | 
2025-12-28T04:50:49 | step: 1015800 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.001206419459777e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 2.88 | consumed tokens: 520089600.0 | grad norm avg: 14.71 | grad norm last: 11.7 | 
2025-12-28T04:50:51 | step: 1015900 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.0011743142968044e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.47 | train loss last: 3.61 | consumed tokens: 520140800.0 | grad norm avg: 14.05 | grad norm last: 14.47 | 
2025-12-28T04:50:53 | step: 1016000 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0011426638811827e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 4.06 | consumed tokens: 520192000.0 | grad norm avg: 14.29 | grad norm last: 15.81 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1016000-seen_tokens_520192000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1016000-seen_tokens_520192000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1016000-seen_tokens_520192000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1016000-seen_tokens_520192000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1016000-seen_tokens_520192000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1016000-seen_tokens_520192000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1016000-seen_tokens_520192000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1016000-seen_tokens_520192000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:50:55 | step: 1016100 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0011114682129119e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.52 | train loss last: 3.09 | consumed tokens: 520243200.0 | grad norm avg: 14.5 | grad norm last: 12.79 | 
2025-12-28T04:50:58 | step: 1016200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0010806363425218e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.59 | train loss last: 3.73 | consumed tokens: 520294400.0 | grad norm avg: 14.69 | grad norm last: 14.26 | 
2025-12-28T04:51:00 | step: 1016300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0010502592194825e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.53 | consumed tokens: 520345600.0 | grad norm avg: 14.92 | grad norm last: 13.39 | 
2025-12-28T04:51:02 | step: 1016400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0010203368437942e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.8 | consumed tokens: 520396800.0 | grad norm avg: 15.19 | grad norm last: 13.72 | 
2025-12-28T04:51:04 | step: 1016500 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.0009908692154568e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.67 | consumed tokens: 520448000.0 | grad norm avg: 14.59 | grad norm last: 14.85 | 
2025-12-28T04:51:06 | step: 1016600 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.000961765385e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 3.23 | consumed tokens: 520499200.0 | grad norm avg: 15.23 | grad norm last: 13.21 | 
2025-12-28T04:51:08 | step: 1016700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0009331163018942e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.44 | consumed tokens: 520550400.0 | grad norm avg: 14.42 | grad norm last: 13.02 | 
2025-12-28T04:51:10 | step: 1016800 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.0009049219661392e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.48 | consumed tokens: 520601600.0 | grad norm avg: 14.82 | grad norm last: 14.58 | 
2025-12-28T04:51:12 | step: 1016900 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0008771823777352e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.67 | train loss last: 3.23 | consumed tokens: 520652800.0 | grad norm avg: 15.59 | grad norm last: 13.64 | 
2025-12-28T04:51:14 | step: 1017000 | train samples/s: 105.2 | train mfu (16-bit): -1.0 | lr mean: 1.0008498065872118e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 2.67 | consumed tokens: 520704000.0 | grad norm avg: 14.66 | grad norm last: 10.81 | 
2025-12-28T04:51:16 | step: 1017100 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.0008229764935095e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.46 | train loss last: 3.25 | consumed tokens: 520755200.0 | grad norm avg: 14.43 | grad norm last: 14.83 | 
2025-12-28T04:51:18 | step: 1017200 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0007965101976879e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.51 | train loss last: 3.7 | consumed tokens: 520806400.0 | grad norm avg: 14.28 | grad norm last: 14.45 | 
2025-12-28T04:51:20 | step: 1017300 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.000770407699747e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 4.09 | consumed tokens: 520857600.0 | grad norm avg: 14.48 | grad norm last: 15.36 | 
2025-12-28T04:51:22 | step: 1017400 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0007448508986272e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 6.06 | consumed tokens: 520908800.0 | grad norm avg: 14.46 | grad norm last: 22.14 | 
2025-12-28T04:51:24 | step: 1017500 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.000719657895388e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.48 | consumed tokens: 520960000.0 | grad norm avg: 15.28 | grad norm last: 14.6 | 
2025-12-28T04:51:26 | step: 1017600 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.0006949196394999e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 4.06 | consumed tokens: 521011200.0 | grad norm avg: 14.85 | grad norm last: 22.6 | 
2025-12-28T04:51:28 | step: 1017700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.0006706361309625e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.39 | consumed tokens: 521062400.0 | grad norm avg: 14.33 | grad norm last: 14.53 | 
2025-12-28T04:51:30 | step: 1017800 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0006467164203059e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.38 | consumed tokens: 521113600.0 | grad norm avg: 14.69 | grad norm last: 13.21 | 
2025-12-28T04:51:32 | step: 1017900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0006232514570002e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 3.66 | consumed tokens: 521164800.0 | grad norm avg: 14.83 | grad norm last: 13.22 | 
2025-12-28T04:51:34 | step: 1018000 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0006002412410453e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 2.8 | consumed tokens: 521216000.0 | grad norm avg: 14.82 | grad norm last: 13.58 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1018000-seen_tokens_521216000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1018000-seen_tokens_521216000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1018000-seen_tokens_521216000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1018000-seen_tokens_521216000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1018000-seen_tokens_521216000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1018000-seen_tokens_521216000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1018000-seen_tokens_521216000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1018000-seen_tokens_521216000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:51:37 | step: 1018100 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0005776857724413e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 3.31 | consumed tokens: 521267200.0 | grad norm avg: 15.47 | grad norm last: 13.6 | 
2025-12-28T04:51:39 | step: 1018200 | train samples/s: 106.5 | train mfu (16-bit): -1.0 | lr mean: 1.0005555850511882e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.69 | train loss last: 3.61 | consumed tokens: 521318400.0 | grad norm avg: 15.07 | grad norm last: 15.01 | 
2025-12-28T04:51:41 | step: 1018300 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0005338481278159e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.62 | train loss last: 4.0 | consumed tokens: 521369600.0 | grad norm avg: 14.74 | grad norm last: 14.06 | 
2025-12-28T04:51:43 | step: 1018400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0005125659517944e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 4.09 | consumed tokens: 521420800.0 | grad norm avg: 14.86 | grad norm last: 18.19 | 
2025-12-28T04:51:45 | step: 1018500 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0004917385231238e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 4.75 | consumed tokens: 521472000.0 | grad norm avg: 14.54 | grad norm last: 20.91 | 
2025-12-28T04:51:47 | step: 1018600 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0004712748923339e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.19 | consumed tokens: 521523200.0 | grad norm avg: 14.61 | grad norm last: 12.73 | 
2025-12-28T04:51:49 | step: 1018700 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.000451356958365e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.0 | consumed tokens: 521574400.0 | grad norm avg: 14.47 | grad norm last: 12.33 | 
2025-12-28T04:51:51 | step: 1018800 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.000431802822277e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.64 | consumed tokens: 521625600.0 | grad norm avg: 14.74 | grad norm last: 13.76 | 
2025-12-28T04:51:53 | step: 1018900 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.0004127034335397e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 4.62 | consumed tokens: 521676800.0 | grad norm avg: 14.97 | grad norm last: 38.29 | 
2025-12-28T04:51:55 | step: 1019000 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0003939678426832e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.09 | consumed tokens: 521728000.0 | grad norm avg: 14.22 | grad norm last: 12.17 | 
2025-12-28T04:51:57 | step: 1019100 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0003756869991776e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.44 | consumed tokens: 521779200.0 | grad norm avg: 14.44 | grad norm last: 14.75 | 
2025-12-28T04:51:59 | step: 1019200 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.000357951852493e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.25 | consumed tokens: 521830400.0 | grad norm avg: 15.05 | grad norm last: 14.12 | 
2025-12-28T04:52:01 | step: 1019300 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.000340489554219e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.06 | consumed tokens: 521881600.0 | grad norm avg: 14.55 | grad norm last: 13.18 | 
2025-12-28T04:52:03 | step: 1019400 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.000323572952766e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 4.06 | consumed tokens: 521932800.0 | grad norm avg: 14.51 | grad norm last: 16.26 | 
2025-12-28T04:52:05 | step: 1019500 | train samples/s: 106.7 | train mfu (16-bit): -1.0 | lr mean: 1.0003070201491937e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.61 | train loss last: 4.22 | consumed tokens: 521984000.0 | grad norm avg: 15.08 | grad norm last: 14.84 | 
2025-12-28T04:52:07 | step: 1019600 | train samples/s: 106.6 | train mfu (16-bit): -1.0 | lr mean: 1.0002910130424425e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.16 | consumed tokens: 522035200.0 | grad norm avg: 15.02 | grad norm last: 13.5 | 
2025-12-28T04:52:09 | step: 1019700 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0002752787841018e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 3.17 | consumed tokens: 522086400.0 | grad norm avg: 14.43 | grad norm last: 13.4 | 
2025-12-28T04:52:11 | step: 1019800 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0002600902225822e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.64 | train loss last: 3.64 | consumed tokens: 522137600.0 | grad norm avg: 15.03 | grad norm last: 16.86 | 
2025-12-28T04:52:13 | step: 1019900 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0002452654589433e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.59 | consumed tokens: 522188800.0 | grad norm avg: 14.36 | grad norm last: 13.59 | 
2025-12-28T04:52:15 | step: 1020000 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0002309863921255e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 2.94 | consumed tokens: 522240000.0 | grad norm avg: 15.03 | grad norm last: 14.46 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1020000-seen_tokens_522240000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1020000-seen_tokens_522240000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1020000-seen_tokens_522240000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1020000-seen_tokens_522240000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1020000-seen_tokens_522240000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1020000-seen_tokens_522240000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1020000-seen_tokens_522240000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1020000-seen_tokens_522240000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:52:17 | step: 1020100 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0002170711231884e-05 | peak memory rank 0 (MB): 660.48 | train loss avg: 3.54 | train loss last: 4.19 | consumed tokens: 522291200.0 | grad norm avg: 14.96 | grad norm last: 13.81 | 
2025-12-28T04:52:19 | step: 1020200 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.000203519652132e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.45 | consumed tokens: 522342400.0 | grad norm avg: 14.31 | grad norm last: 12.13 | 
2025-12-28T04:52:21 | step: 1020300 | train samples/s: 106.8 | train mfu (16-bit): -1.0 | lr mean: 1.0001905138778966e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.14 | consumed tokens: 522393600.0 | grad norm avg: 14.56 | grad norm last: 11.76 | 
2025-12-28T04:52:23 | step: 1020400 | train samples/s: 106.9 | train mfu (16-bit): -1.0 | lr mean: 1.000177871901542e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 4.59 | consumed tokens: 522444800.0 | grad norm avg: 14.76 | grad norm last: 18.93 | 
2025-12-28T04:52:25 | step: 1020500 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.0001656846725382e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.7 | consumed tokens: 522496000.0 | grad norm avg: 14.17 | grad norm last: 14.8 | 
2025-12-28T04:52:28 | step: 1020600 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0001539521908853e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 2.94 | consumed tokens: 522547200.0 | grad norm avg: 14.4 | grad norm last: 13.25 | 
2025-12-28T04:52:30 | step: 1020700 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0001425835071132e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.44 | consumed tokens: 522598400.0 | grad norm avg: 14.17 | grad norm last: 13.99 | 
2025-12-28T04:52:32 | step: 1020800 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0001316695706919e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.34 | consumed tokens: 522649600.0 | grad norm avg: 14.64 | grad norm last: 12.8 | 
2025-12-28T04:52:34 | step: 1020900 | train samples/s: 106.4 | train mfu (16-bit): -1.0 | lr mean: 1.0001212103816215e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 2.69 | consumed tokens: 522700800.0 | grad norm avg: 14.56 | grad norm last: 11.21 | 
2025-12-28T04:52:36 | step: 1021000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.000111205939902e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.43 | train loss last: 3.03 | consumed tokens: 522752000.0 | grad norm avg: 14.35 | grad norm last: 13.64 | 
2025-12-28T04:52:38 | step: 1021100 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0001016562455334e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.47 | train loss last: 3.45 | consumed tokens: 522803200.0 | grad norm avg: 14.4 | grad norm last: 14.04 | 
2025-12-28T04:52:40 | step: 1021200 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.0000924703490455e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.57 | train loss last: 3.44 | consumed tokens: 522854400.0 | grad norm avg: 15.05 | grad norm last: 15.05 | 
2025-12-28T04:52:42 | step: 1021300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0000837391999085e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 2.92 | consumed tokens: 522905600.0 | grad norm avg: 14.26 | grad norm last: 12.68 | 
2025-12-28T04:52:44 | step: 1021400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0000754627981223e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.47 | consumed tokens: 522956800.0 | grad norm avg: 14.83 | grad norm last: 16.34 | 
2025-12-28T04:52:46 | step: 1021500 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0000675501942169e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.27 | consumed tokens: 523008000.0 | grad norm avg: 14.8 | grad norm last: 13.02 | 
2025-12-28T04:52:48 | step: 1021600 | train samples/s: 105.3 | train mfu (16-bit): -1.0 | lr mean: 1.0000600923376624e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.63 | train loss last: 4.75 | consumed tokens: 523059200.0 | grad norm avg: 14.82 | grad norm last: 21.55 | 
2025-12-28T04:52:50 | step: 1021700 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.0000530892284587e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.5 | train loss last: 3.27 | consumed tokens: 523110400.0 | grad norm avg: 14.62 | grad norm last: 13.7 | 
2025-12-28T04:52:52 | step: 1021800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.000046540866606e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.53 | train loss last: 3.12 | consumed tokens: 523161600.0 | grad norm avg: 14.16 | grad norm last: 12.35 | 
2025-12-28T04:52:54 | step: 1021900 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.000040447252104e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.65 | train loss last: 3.44 | consumed tokens: 523212800.0 | grad norm avg: 14.92 | grad norm last: 12.45 | 
2025-12-28T04:52:56 | step: 1022000 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0000347174354829e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.77 | consumed tokens: 523264000.0 | grad norm avg: 14.82 | grad norm last: 14.12 | 
main - INFO - Gathering model and optimizer checkpoint...
INFO:main:Gathering model and optimizer checkpoint...
main - INFO - Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1022000-seen_tokens_523264000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving model checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1022000-seen_tokens_523264000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Model checkpoint saved.
INFO:main:Model checkpoint saved.
main - INFO - Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1022000-seen_tokens_523264000-target_steps_1023268-target_tokens_523913216.bin...
INFO:main:Saving optimizer checkpoint to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1022000-seen_tokens_523264000-target_steps_1023268-target_tokens_523913216.bin...
main - INFO - Optimizer checkpoint saved.
INFO:main:Optimizer checkpoint saved.
main - INFO - Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1022000-seen_tokens_523264000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1022000-seen_tokens_523264000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
INFO:main:Saving checkpoint info {'model_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-model-seen_steps_1022000-seen_tokens_523264000-target_steps_1023268-target_tokens_523913216.bin', 'optimizer_checkpoint_path': '/home/s472389/modalities_test/data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1/eid_2025-12-27__23-05-14_a535941fb82852f1-optimizer-seen_steps_1022000-seen_tokens_523264000-target_steps_1023268-target_tokens_523913216.bin'} to data/checkpoints/2025-12-27__23-05-14_a535941fb82852f1...
main - INFO - Checkpoint info saved.
INFO:main:Checkpoint info saved.
2025-12-28T04:52:58 | step: 1022100 | train samples/s: 106.0 | train mfu (16-bit): -1.0 | lr mean: 1.0000294423662126e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.2 | consumed tokens: 523315200.0 | grad norm avg: 14.73 | grad norm last: 13.83 | 
2025-12-28T04:53:00 | step: 1022200 | train samples/s: 105.4 | train mfu (16-bit): -1.0 | lr mean: 1.0000246220442932e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 3.17 | consumed tokens: 523366400.0 | grad norm avg: 14.71 | grad norm last: 13.18 | 
2025-12-28T04:53:02 | step: 1022300 | train samples/s: 105.6 | train mfu (16-bit): -1.0 | lr mean: 1.0000202564697247e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.71 | train loss last: 3.53 | consumed tokens: 523417600.0 | grad norm avg: 14.81 | grad norm last: 15.09 | 
2025-12-28T04:53:05 | step: 1022400 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0000162546930369e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.58 | train loss last: 3.33 | consumed tokens: 523468800.0 | grad norm avg: 14.76 | grad norm last: 12.64 | 
2025-12-28T04:53:07 | step: 1022500 | train samples/s: 105.9 | train mfu (16-bit): -1.0 | lr mean: 1.0000127076637e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.55 | train loss last: 4.22 | consumed tokens: 523520000.0 | grad norm avg: 14.45 | grad norm last: 16.47 | 
2025-12-28T04:53:09 | step: 1022600 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.000009615381714e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.56 | train loss last: 2.52 | consumed tokens: 523571200.0 | grad norm avg: 14.68 | grad norm last: 11.57 | 
2025-12-28T04:53:11 | step: 1022700 | train samples/s: 105.7 | train mfu (16-bit): -1.0 | lr mean: 1.0000069778470788e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.49 | train loss last: 3.19 | consumed tokens: 523622400.0 | grad norm avg: 14.78 | grad norm last: 13.03 | 
2025-12-28T04:53:13 | step: 1022800 | train samples/s: 105.5 | train mfu (16-bit): -1.0 | lr mean: 1.0000047041103244e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.66 | train loss last: 3.12 | consumed tokens: 523673600.0 | grad norm avg: 15.24 | grad norm last: 12.77 | 
2025-12-28T04:53:15 | step: 1022900 | train samples/s: 105.8 | train mfu (16-bit): -1.0 | lr mean: 1.0000028851209208e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.6 | train loss last: 3.06 | consumed tokens: 523724800.0 | grad norm avg: 14.53 | grad norm last: 14.45 | 
2025-12-28T04:53:17 | step: 1023000 | train samples/s: 106.1 | train mfu (16-bit): -1.0 | lr mean: 1.0000015208788682e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.48 | train loss last: 3.09 | consumed tokens: 523776000.0 | grad norm avg: 14.72 | grad norm last: 17.02 | 
2025-12-28T04:53:19 | step: 1023100 | train samples/s: 106.3 | train mfu (16-bit): -1.0 | lr mean: 1.0000006113841664e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.52 | train loss last: 3.83 | consumed tokens: 523827200.0 | grad norm avg: 15.39 | grad norm last: 14.54 | 
2025-12-28T04:53:21 | step: 1023200 | train samples/s: 106.2 | train mfu (16-bit): -1.0 | lr mean: 1.0000000656873453e-05 | peak memory rank 0 (MB): 553.43 | train loss avg: 3.54 | train loss last: 2.91 | consumed tokens: 523878400.0 | grad norm avg: 15.15 | grad norm last: 12.12 | 
Training done at 2025-12-28 04:53:22.798500.
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /home/s472389/modalities_test/wandb_storage/wandb/offline-run-20251227_230515-l3fzp0zw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb_storage/wandb/offline-run-20251227_230515-l3fzp0zw/logs[0m
